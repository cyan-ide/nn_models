W0605 22:35:26.965000 335066 torch/distributed/run.py:793] 
W0605 22:35:26.965000 335066 torch/distributed/run.py:793] *****************************************
W0605 22:35:26.965000 335066 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0605 22:35:26.965000 335066 torch/distributed/run.py:793] *****************************************
Total desired batch size: 524288 tokens / 4 steps


GPT-2 training configuration
------------------------------------------------------------------------------------
MAX_LR:          0.0006
MIN_LR:          5.9999999999999995e-05
WARMUP_STEPS:    715
------------------------------------------------------------------------------------
MAX_STEPS:       19073
------------------------------------------------------------------------------------
MICRO_BATCH_SIZE (samples in a batch):           64
MICRO_BATCH_TOKEN_COUNT (total tokens in batch): 1024

[Gradient Acculumation to match GPT2 batch sizes]
ACCUM_BATCH_SIZE:                                4
ACCUM_BATCH_TOKEN_COUNT:                         524288

EVAL_EVERY_STEPS:                              250
EVAL_HELLASWAG_EVERY_STEPS:                      1000
GEN_EVERY_STEPS:                                 250
------------------------------------------------------------------------------------
DATASET_PATH:    /mnt/data/backup/adam/llm_train_data/fineweb_edu_10BT/
------------------------------------------------------------------------------------
DISTRUBTED:      True
OPTIMIZE_SPEED:  True
USE_COMPILE:     True
------------------------------------------------------------------------------------


Found 99 files. Current file - loaded 100000000 tokens (1 epoch= 1525 steps / 1 step = 65536 tokens)
Found 1 files. Current file - loaded 100000000 tokens (1 epoch= 1525 steps / 1 step = 65536 tokens)

WEIGHT DECAY CONFIG:
* Number of tensors with weight decay / without weight decay: 50 (124354560 params)/ 98 (121344 params)
* Using fused AdamW: True

/mnt/ssd/home/adam/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/mnt/ssd/home/adam/.local/lib/python3.10/site-packages/torch/autograd/graph.py:825: UserWarning: cuDNN SDPA backward got grad_output.strides() != output.strides(), attempting to materialize a grad_output with matching strides... (Triggered internally at ../aten/src/ATen/native/cudnn/MHA.cpp:674.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Step:     0, loss: 10.948713, norm: 15.4590, time(ms): 371568.27, token/sec:1411.01, val_loss: 10.9512, hellaswag_acc: 0.0000
Step:     1, loss: 10.904423, norm: 14.7237, time(ms): 766.24, token/sec:684238.86, hellaswag_acc: 0.0000
Step:     2, loss: 10.802341, norm: 14.5360, time(ms): 789.21, token/sec:664318.14, hellaswag_acc: 0.0000
Step:     3, loss: 10.667301, norm: 12.9459, time(ms): 787.29, token/sec:665937.42, hellaswag_acc: 0.0000
Step:     4, loss: 10.515677, norm: 10.8499, time(ms): 784.88, token/sec:667988.23, hellaswag_acc: 0.0000
Step:     5, loss: 10.380291, norm: 8.7738, time(ms): 781.76, token/sec:670652.29, hellaswag_acc: 0.0000
Step:     6, loss: 10.262073, norm: 7.4186, time(ms): 786.60, token/sec:666528.23, hellaswag_acc: 0.0000
Step:     7, loss: 10.142210, norm: 6.4447, time(ms): 785.96, token/sec:667064.23, hellaswag_acc: 0.0000
Step:     8, loss: 10.033997, norm: 5.4875, time(ms): 783.12, token/sec:669484.19, hellaswag_acc: 0.0000
Step:     9, loss: 9.956217, norm: 4.5403, time(ms): 783.61, token/sec:669064.99, hellaswag_acc: 0.0000
Step:    10, loss: 9.854263, norm: 3.9801, time(ms): 787.66, token/sec:665626.59, hellaswag_acc: 0.0000
Step:    11, loss: 9.827222, norm: 3.4051, time(ms): 786.47, token/sec:666634.71, hellaswag_acc: 0.0000
Step:    12, loss: 9.790810, norm: 3.0149, time(ms): 781.11, token/sec:671205.60, hellaswag_acc: 0.0000
Step:    13, loss: 9.730668, norm: 2.7778, time(ms): 783.28, token/sec:669352.96, hellaswag_acc: 0.0000
Step:    14, loss: 9.665405, norm: 2.6349, time(ms): 788.24, token/sec:665138.16, hellaswag_acc: 0.0000
Step:    15, loss: 9.665062, norm: 2.4265, time(ms): 787.47, token/sec:665788.62, hellaswag_acc: 0.0000
Step:    16, loss: 9.649315, norm: 2.3637, time(ms): 779.86, token/sec:672287.63, hellaswag_acc: 0.0000
Step:    17, loss: 9.603853, norm: 2.3215, time(ms): 783.11, token/sec:669496.01, hellaswag_acc: 0.0000
Step:    18, loss: 9.596613, norm: 2.2784, time(ms): 787.58, token/sec:665693.09, hellaswag_acc: 0.0000
Step:    19, loss: 9.589342, norm: 2.2494, time(ms): 787.94, token/sec:665387.12, hellaswag_acc: 0.0000
Step:    20, loss: 9.543335, norm: 2.2887, time(ms): 781.48, token/sec:670888.41, hellaswag_acc: 0.0000
Step:    21, loss: 9.527528, norm: 2.3267, time(ms): 778.54, token/sec:673425.32, hellaswag_acc: 0.0000
Step:    22, loss: 9.515333, norm: 2.2337, time(ms): 784.90, token/sec:667971.18, hellaswag_acc: 0.0000
Step:    23, loss: 9.501919, norm: 2.2180, time(ms): 789.59, token/sec:664003.81, hellaswag_acc: 0.0000
Step:    24, loss: 9.440711, norm: 2.2242, time(ms): 785.85, token/sec:667160.56, hellaswag_acc: 0.0000
Step:    25, loss: 9.430010, norm: 2.0835, time(ms): 778.99, token/sec:673033.10, hellaswag_acc: 0.0000
Step:    26, loss: 9.409225, norm: 2.0833, time(ms): 783.44, token/sec:669213.83, hellaswag_acc: 0.0000
Step:    27, loss: 9.343845, norm: 2.1044, time(ms): 787.71, token/sec:665584.49, hellaswag_acc: 0.0000
Step:    28, loss: 9.306889, norm: 2.0873, time(ms): 788.44, token/sec:664972.03, hellaswag_acc: 0.0000
Step:    29, loss: 9.279373, norm: 2.0287, time(ms): 781.15, token/sec:671177.74, hellaswag_acc: 0.0000
Step:    30, loss: 9.249758, norm: 2.1285, time(ms): 784.20, token/sec:668563.17, hellaswag_acc: 0.0000
Step:    31, loss: 9.197683, norm: 2.0759, time(ms): 790.02, token/sec:663635.10, hellaswag_acc: 0.0000
Step:    32, loss: 9.163758, norm: 2.4471, time(ms): 784.05, token/sec:668695.51, hellaswag_acc: 0.0000
Step:    33, loss: 9.154900, norm: 2.6628, time(ms): 784.32, token/sec:668461.14, hellaswag_acc: 0.0000
Step:    34, loss: 9.101561, norm: 1.9274, time(ms): 786.15, token/sec:666902.59, hellaswag_acc: 0.0000
Step:    35, loss: 9.085192, norm: 2.3012, time(ms): 794.21, token/sec:660134.61, hellaswag_acc: 0.0000
Step:    36, loss: 9.022797, norm: 2.2790, time(ms): 789.53, token/sec:664054.94, hellaswag_acc: 0.0000
Step:    37, loss: 9.026548, norm: 1.8984, time(ms): 785.89, token/sec:667125.95, hellaswag_acc: 0.0000
Step:    38, loss: 8.972677, norm: 1.9290, time(ms): 778.47, token/sec:673481.01, hellaswag_acc: 0.0000
Step:    39, loss: 8.957323, norm: 2.0930, time(ms): 781.36, token/sec:670997.72, hellaswag_acc: 0.0000
Step:    40, loss: 8.928755, norm: 1.9409, time(ms): 783.70, token/sec:668988.46, hellaswag_acc: 0.0000
Step:    41, loss: 8.884451, norm: 1.8095, time(ms): 783.24, token/sec:669387.59, hellaswag_acc: 0.0000
Step:    42, loss: 8.833866, norm: 1.8324, time(ms): 787.21, token/sec:666008.01, hellaswag_acc: 0.0000
Step:    43, loss: 8.818431, norm: 1.7571, time(ms): 785.28, token/sec:667641.22, hellaswag_acc: 0.0000
Step:    44, loss: 8.753340, norm: 1.6804, time(ms): 776.62, token/sec:675086.87, hellaswag_acc: 0.0000
Step:    45, loss: 8.724131, norm: 1.6676, time(ms): 781.93, token/sec:670508.94, hellaswag_acc: 0.0000
Step:    46, loss: 8.709345, norm: 1.6657, time(ms): 779.20, token/sec:672856.82, hellaswag_acc: 0.0000
Step:    47, loss: 8.669304, norm: 1.6435, time(ms): 781.41, token/sec:670953.70, hellaswag_acc: 0.0000
Step:    48, loss: 8.634758, norm: 1.6824, time(ms): 782.43, token/sec:670072.73, hellaswag_acc: 0.0000
Step:    49, loss: 8.559719, norm: 1.6729, time(ms): 786.50, token/sec:666612.68, hellaswag_acc: 0.0000
Step:    50, loss: 8.509928, norm: 1.6519, time(ms): 787.39, token/sec:665853.74, hellaswag_acc: 0.0000
Step:    51, loss: 8.520998, norm: 1.5546, time(ms): 781.81, token/sec:670604.02, hellaswag_acc: 0.0000
Step:    52, loss: 8.433772, norm: 1.6536, time(ms): 779.35, token/sec:672725.90, hellaswag_acc: 0.0000
Step:    53, loss: 8.418097, norm: 1.9193, time(ms): 779.70, token/sec:672425.98, hellaswag_acc: 0.0000
Step:    54, loss: 8.377090, norm: 1.9805, time(ms): 779.77, token/sec:672366.56, hellaswag_acc: 0.0000
Step:    55, loss: 8.344234, norm: 1.5544, time(ms): 783.15, token/sec:669463.61, hellaswag_acc: 0.0000
Step:    56, loss: 8.318502, norm: 1.7885, time(ms): 780.30, token/sec:671909.25, hellaswag_acc: 0.0000
Step:    57, loss: 8.280386, norm: 1.8816, time(ms): 783.18, token/sec:669438.54, hellaswag_acc: 0.0000
Step:    58, loss: 8.282869, norm: 1.4982, time(ms): 781.80, token/sec:670614.04, hellaswag_acc: 0.0000
Step:    59, loss: 8.232944, norm: 1.4254, time(ms): 786.18, token/sec:666879.33, hellaswag_acc: 0.0000
Step:    60, loss: 8.191813, norm: 1.5583, time(ms): 786.36, token/sec:666731.32, hellaswag_acc: 0.0000
Step:    61, loss: 8.115217, norm: 1.4880, time(ms): 783.99, token/sec:668747.17, hellaswag_acc: 0.0000
Step:    62, loss: 8.100914, norm: 1.3647, time(ms): 783.64, token/sec:669043.21, hellaswag_acc: 0.0000
Step:    63, loss: 8.060112, norm: 1.4084, time(ms): 788.15, token/sec:665215.43, hellaswag_acc: 0.0000
Step:    64, loss: 7.999232, norm: 1.5373, time(ms): 781.80, token/sec:670617.11, hellaswag_acc: 0.0000
Step:    65, loss: 8.004589, norm: 1.3422, time(ms): 780.20, token/sec:671993.64, hellaswag_acc: 0.0000
Step:    66, loss: 7.969398, norm: 1.3861, time(ms): 781.55, token/sec:670828.03, hellaswag_acc: 0.0000
Step:    67, loss: 7.903766, norm: 1.6009, time(ms): 785.32, token/sec:667613.86, hellaswag_acc: 0.0000
Step:    68, loss: 7.880602, norm: 1.5245, time(ms): 785.55, token/sec:667417.52, hellaswag_acc: 0.0000
Step:    69, loss: 7.817898, norm: 1.3270, time(ms): 784.63, token/sec:668199.53, hellaswag_acc: 0.0000
Step:    70, loss: 7.831277, norm: 1.4387, time(ms): 782.97, token/sec:669615.48, hellaswag_acc: 0.0000
Step:    71, loss: 7.857738, norm: 1.1878, time(ms): 779.77, token/sec:672366.56, hellaswag_acc: 0.0000
Step:    72, loss: 7.827041, norm: 1.3280, time(ms): 782.96, token/sec:669625.88, hellaswag_acc: 0.0000
Step:    73, loss: 7.790071, norm: 1.2958, time(ms): 783.88, token/sec:668841.14, hellaswag_acc: 0.0000
Step:    74, loss: 7.789637, norm: 1.2526, time(ms): 784.72, token/sec:668120.35, hellaswag_acc: 0.0000
Step:    75, loss: 7.738389, norm: 1.2404, time(ms): 785.26, token/sec:667658.25, hellaswag_acc: 0.0000
Step:    76, loss: 7.694947, norm: 1.2749, time(ms): 782.82, token/sec:669741.10, hellaswag_acc: 0.0000
Step:    77, loss: 7.653426, norm: 1.1691, time(ms): 779.98, token/sec:672184.88, hellaswag_acc: 0.0000
Step:    78, loss: 7.609809, norm: 1.3378, time(ms): 787.13, token/sec:666074.58, hellaswag_acc: 0.0000
Step:    79, loss: 7.622285, norm: 1.1960, time(ms): 788.75, token/sec:664703.49, hellaswag_acc: 0.0000
Step:    80, loss: 7.577666, norm: 1.0515, time(ms): 781.98, token/sec:670458.65, hellaswag_acc: 0.0000
Step:    81, loss: 7.569144, norm: 1.4229, time(ms): 781.67, token/sec:670725.52, hellaswag_acc: 0.0000
Step:    82, loss: 7.463022, norm: 0.9510, time(ms): 783.36, token/sec:669282.26, hellaswag_acc: 0.0000
Step:    83, loss: 7.491364, norm: 1.0688, time(ms): 783.48, token/sec:669180.84, hellaswag_acc: 0.0000
Step:    84, loss: 7.392866, norm: 1.2193, time(ms): 787.14, token/sec:666063.49, hellaswag_acc: 0.0000
Step:    85, loss: 7.445176, norm: 1.6082, time(ms): 786.09, token/sec:666959.83, hellaswag_acc: 0.0000
Step:    86, loss: 7.379429, norm: 1.1056, time(ms): 781.66, token/sec:670733.30, hellaswag_acc: 0.0000
Step:    87, loss: 7.337632, norm: 0.9120, time(ms): 787.41, token/sec:665836.20, hellaswag_acc: 0.0000
Step:    88, loss: 7.320106, norm: 1.2405, time(ms): 789.09, token/sec:664421.11, hellaswag_acc: 0.0000
Step:    89, loss: 7.296384, norm: 1.0438, time(ms): 784.11, token/sec:668640.21, hellaswag_acc: 0.0000
Step:    90, loss: 7.348505, norm: 1.0671, time(ms): 788.02, token/sec:665322.70, hellaswag_acc: 0.0000
Step:    91, loss: 7.309654, norm: 1.0949, time(ms): 787.27, token/sec:665961.02, hellaswag_acc: 0.0000
Step:    92, loss: 7.238445, norm: 1.0011, time(ms): 780.77, token/sec:671497.88, hellaswag_acc: 0.0000
Step:    93, loss: 7.218161, norm: 1.2152, time(ms): 782.53, token/sec:669994.75, hellaswag_acc: 0.0000
Step:    94, loss: 7.172393, norm: 0.8973, time(ms): 786.33, token/sec:666749.52, hellaswag_acc: 0.0000
Step:    95, loss: 7.164873, norm: 1.2294, time(ms): 785.82, token/sec:667185.26, hellaswag_acc: 0.0000
Step:    96, loss: 7.174910, norm: 0.9534, time(ms): 784.58, token/sec:668242.37, hellaswag_acc: 0.0000
Step:    97, loss: 7.227675, norm: 1.4268, time(ms): 779.54, token/sec:672558.42, hellaswag_acc: 0.0000
Step:    98, loss: 7.128704, norm: 0.7892, time(ms): 790.37, token/sec:663341.82, hellaswag_acc: 0.0000
Step:    99, loss: 7.151557, norm: 0.7922, time(ms): 788.77, token/sec:664693.24, hellaswag_acc: 0.0000
Step:   100, loss: 7.083848, norm: 1.0422, time(ms): 784.52, token/sec:668287.66, hellaswag_acc: 0.0000
Step:   101, loss: 7.153913, norm: 0.9830, time(ms): 785.65, token/sec:667326.98, hellaswag_acc: 0.0000
Step:   102, loss: 7.030961, norm: 0.8389, time(ms): 790.36, token/sec:663351.03, hellaswag_acc: 0.0000
Step:   103, loss: 7.055312, norm: 0.9571, time(ms): 785.03, token/sec:667857.78, hellaswag_acc: 0.0000
Step:   104, loss: 7.064635, norm: 1.2232, time(ms): 790.50, token/sec:663231.99, hellaswag_acc: 0.0000
Step:   105, loss: 6.966728, norm: 0.9476, time(ms): 784.05, token/sec:668689.82, hellaswag_acc: 0.0000
Step:   106, loss: 7.120828, norm: 0.9639, time(ms): 785.82, token/sec:667183.64, hellaswag_acc: 0.0000
Step:   107, loss: 7.085196, norm: 1.0292, time(ms): 790.32, token/sec:663384.65, hellaswag_acc: 0.0000
Step:   108, loss: 7.094488, norm: 1.0643, time(ms): 787.54, token/sec:665728.76, hellaswag_acc: 0.0000
Step:   109, loss: 7.079370, norm: 0.8880, time(ms): 786.30, token/sec:666778.83, hellaswag_acc: 0.0000
Step:   110, loss: 7.078757, norm: 1.2738, time(ms): 788.12, token/sec:665236.35, hellaswag_acc: 0.0000
Step:   111, loss: 7.123342, norm: 0.5884, time(ms): 783.51, token/sec:669154.98, hellaswag_acc: 0.0000
Step:   112, loss: 6.936164, norm: 1.2135, time(ms): 781.84, token/sec:670578.46, hellaswag_acc: 0.0000
Step:   113, loss: 7.019642, norm: 1.0676, time(ms): 787.13, token/sec:666078.42, hellaswag_acc: 0.0000
Step:   114, loss: 7.047748, norm: 1.6706, time(ms): 793.18, token/sec:660997.57, hellaswag_acc: 0.0000
Step:   115, loss: 7.018157, norm: 1.2615, time(ms): 790.15, token/sec:663531.57, hellaswag_acc: 0.0000
Step:   116, loss: 6.988589, norm: 1.0180, time(ms): 783.83, token/sec:668880.81, hellaswag_acc: 0.0000
Step:   117, loss: 6.986054, norm: 0.5842, time(ms): 781.75, token/sec:670662.11, hellaswag_acc: 0.0000
Step:   118, loss: 6.842205, norm: 0.8136, time(ms): 789.53, token/sec:664048.93, hellaswag_acc: 0.0000
Step:   119, loss: 6.925503, norm: 0.8979, time(ms): 801.06, token/sec:654494.00, hellaswag_acc: 0.0000
Step:   120, loss: 6.823090, norm: 0.9016, time(ms): 795.32, token/sec:659215.79, hellaswag_acc: 0.0000
Step:   121, loss: 6.876423, norm: 0.9124, time(ms): 791.62, token/sec:662294.36, hellaswag_acc: 0.0000
Step:   122, loss: 6.827488, norm: 0.9762, time(ms): 782.62, token/sec:669910.45, hellaswag_acc: 0.0000
Step:   123, loss: 6.833963, norm: 1.1013, time(ms): 788.63, token/sec:664811.80, hellaswag_acc: 0.0000
Step:   124, loss: 6.827550, norm: 0.9982, time(ms): 792.39, token/sec:661651.31, hellaswag_acc: 0.0000
Step:   125, loss: 6.830053, norm: 1.2579, time(ms): 791.32, token/sec:662551.97, hellaswag_acc: 0.0000
Step:   126, loss: 6.786904, norm: 1.0501, time(ms): 786.11, token/sec:666938.79, hellaswag_acc: 0.0000
Step:   127, loss: 6.794399, norm: 0.4716, time(ms): 783.01, token/sec:669582.45, hellaswag_acc: 0.0000
Step:   128, loss: 6.863198, norm: 0.9360, time(ms): 790.03, token/sec:663634.50, hellaswag_acc: 0.0000
Step:   129, loss: 6.774741, norm: 1.2844, time(ms): 791.55, token/sec:662360.19, hellaswag_acc: 0.0000
Step:   130, loss: 6.760365, norm: 1.1218, time(ms): 791.92, token/sec:662046.92, hellaswag_acc: 0.0000
Step:   131, loss: 6.747313, norm: 0.7599, time(ms): 781.10, token/sec:671219.12, hellaswag_acc: 0.0000
Step:   132, loss: 6.773279, norm: 0.9885, time(ms): 784.58, token/sec:668242.98, hellaswag_acc: 0.0000
Step:   133, loss: 6.710327, norm: 1.1534, time(ms): 790.69, token/sec:663076.40, hellaswag_acc: 0.0000
Step:   134, loss: 6.677239, norm: 0.7249, time(ms): 793.23, token/sec:660952.48, hellaswag_acc: 0.0000
Step:   135, loss: 6.700419, norm: 1.1863, time(ms): 789.18, token/sec:664346.64, hellaswag_acc: 0.0000
Step:   136, loss: 6.691838, norm: 1.0591, time(ms): 781.25, token/sec:671085.98, hellaswag_acc: 0.0000
Step:   137, loss: 6.684881, norm: 1.0965, time(ms): 784.23, token/sec:668537.56, hellaswag_acc: 0.0000
Step:   138, loss: 6.644494, norm: 0.9047, time(ms): 789.27, token/sec:664271.38, hellaswag_acc: 0.0000
Step:   139, loss: 6.727861, norm: 0.9085, time(ms): 786.56, token/sec:666559.74, hellaswag_acc: 0.0000
Step:   140, loss: 6.654795, norm: 0.7595, time(ms): 782.92, token/sec:669656.46, hellaswag_acc: 0.0000
Step:   141, loss: 6.612243, norm: 1.2620, time(ms): 791.62, token/sec:662301.54, hellaswag_acc: 0.0000
Step:   142, loss: 6.701418, norm: 1.2350, time(ms): 792.90, token/sec:661231.31, hellaswag_acc: 0.0000
Step:   143, loss: 6.742632, norm: 0.7745, time(ms): 788.06, token/sec:665289.08, hellaswag_acc: 0.0000
Step:   144, loss: 6.733963, norm: 0.9249, time(ms): 783.87, token/sec:668849.48, hellaswag_acc: 0.0000
Step:   145, loss: 6.764839, norm: 1.0060, time(ms): 784.26, token/sec:668509.10, hellaswag_acc: 0.0000
Step:   146, loss: 6.678727, norm: 1.1050, time(ms): 787.95, token/sec:665385.91, hellaswag_acc: 0.0000
Step:   147, loss: 6.662635, norm: 1.0539, time(ms): 786.63, token/sec:666500.35, hellaswag_acc: 0.0000
Step:   148, loss: 6.679296, norm: 1.0907, time(ms): 780.14, token/sec:672047.65, hellaswag_acc: 0.0000
Step:   149, loss: 6.737229, norm: 1.3780, time(ms): 782.04, token/sec:670411.84, hellaswag_acc: 0.0000
Step:   150, loss: 6.705016, norm: 0.9840, time(ms): 786.45, token/sec:666655.53, hellaswag_acc: 0.0000
Step:   151, loss: 6.667469, norm: 1.5573, time(ms): 791.07, token/sec:662756.05, hellaswag_acc: 0.0000
Step:   152, loss: 6.650591, norm: 0.7859, time(ms): 785.34, token/sec:667595.42, hellaswag_acc: 0.0000
Step:   153, loss: 6.646338, norm: 1.0115, time(ms): 788.92, token/sec:664568.29, hellaswag_acc: 0.0000
Step:   154, loss: 6.565071, norm: 0.8284, time(ms): 788.73, token/sec:664726.99, hellaswag_acc: 0.0000
Step:   155, loss: 6.576468, norm: 0.7492, time(ms): 792.09, token/sec:661908.62, hellaswag_acc: 0.0000
Step:   156, loss: 6.596255, norm: 0.9802, time(ms): 790.88, token/sec:662913.49, hellaswag_acc: 0.0000
Step:   157, loss: 6.515159, norm: 0.9452, time(ms): 793.57, token/sec:660670.10, hellaswag_acc: 0.0000
Step:   158, loss: 6.497689, norm: 1.1387, time(ms): 790.30, token/sec:663405.66, hellaswag_acc: 0.0000
Step:   159, loss: 6.467506, norm: 1.1162, time(ms): 792.11, token/sec:661887.70, hellaswag_acc: 0.0000
Step:   160, loss: 6.490344, norm: 0.7536, time(ms): 790.36, token/sec:663350.23, hellaswag_acc: 0.0000
Step:   161, loss: 6.563000, norm: 0.6069, time(ms): 786.10, token/sec:666952.14, hellaswag_acc: 0.0000
Step:   162, loss: 6.518199, norm: 0.6448, time(ms): 788.30, token/sec:665084.65, hellaswag_acc: 0.0000
Step:   163, loss: 6.525258, norm: 0.9384, time(ms): 786.82, token/sec:666336.76, hellaswag_acc: 0.0000
Step:   164, loss: 6.482535, norm: 1.5057, time(ms): 787.48, token/sec:665777.54, hellaswag_acc: 0.0000
Step:   165, loss: 6.493376, norm: 0.7954, time(ms): 790.45, token/sec:663277.40, hellaswag_acc: 0.0000
Step:   166, loss: 6.434711, norm: 0.7863, time(ms): 793.06, token/sec:661098.72, hellaswag_acc: 0.0000
Step:   167, loss: 6.426723, norm: 1.1286, time(ms): 793.11, token/sec:661056.59, hellaswag_acc: 0.0000
Step:   168, loss: 6.434416, norm: 1.0152, time(ms): 790.78, token/sec:662999.03, hellaswag_acc: 0.0000
Step:   169, loss: 6.391573, norm: 0.9992, time(ms): 791.60, token/sec:662315.51, hellaswag_acc: 0.0000
Step:   170, loss: 6.366384, norm: 0.8921, time(ms): 788.44, token/sec:664971.22, hellaswag_acc: 0.0000
Step:   171, loss: 6.377125, norm: 1.0945, time(ms): 787.38, token/sec:665861.20, hellaswag_acc: 0.0000
Step:   172, loss: 6.413901, norm: 0.9487, time(ms): 791.06, token/sec:662763.04, hellaswag_acc: 0.0000
Step:   173, loss: 6.430937, norm: 1.0611, time(ms): 791.71, token/sec:662225.95, hellaswag_acc: 0.0000
Step:   174, loss: 6.349895, norm: 1.2356, time(ms): 790.22, token/sec:663473.32, hellaswag_acc: 0.0000
Step:   175, loss: 6.436266, norm: 1.1766, time(ms): 787.18, token/sec:666035.85, hellaswag_acc: 0.0000
Step:   176, loss: 6.367878, norm: 1.1932, time(ms): 785.92, token/sec:667100.86, hellaswag_acc: 0.0000
Step:   177, loss: 6.490822, norm: 1.1964, time(ms): 795.76, token/sec:658855.93, hellaswag_acc: 0.0000
Step:   178, loss: 6.520049, norm: 1.0594, time(ms): 793.07, token/sec:661084.81, hellaswag_acc: 0.0000
Step:   179, loss: 6.458097, norm: 1.0552, time(ms): 790.81, token/sec:662977.84, hellaswag_acc: 0.0000
Step:   180, loss: 6.530641, norm: 0.9231, time(ms): 788.91, token/sec:664575.93, hellaswag_acc: 0.0000
Step:   181, loss: 6.495340, norm: 0.9340, time(ms): 787.84, token/sec:665478.14, hellaswag_acc: 0.0000
Step:   182, loss: 6.519377, norm: 0.9933, time(ms): 791.90, token/sec:662065.65, hellaswag_acc: 0.0000
Step:   183, loss: 6.461112, norm: 1.1567, time(ms): 794.97, token/sec:659510.38, hellaswag_acc: 0.0000
Step:   184, loss: 6.468554, norm: 1.0554, time(ms): 799.48, token/sec:655787.27, hellaswag_acc: 0.0000
Step:   185, loss: 6.550359, norm: 1.3113, time(ms): 803.98, token/sec:652119.50, hellaswag_acc: 0.0000
Step:   186, loss: 6.474373, norm: 0.8333, time(ms): 793.84, token/sec:660448.26, hellaswag_acc: 0.0000
Step:   187, loss: 6.490345, norm: 0.9671, time(ms): 797.33, token/sec:657558.01, hellaswag_acc: 0.0000
Step:   188, loss: 6.485872, norm: 1.2418, time(ms): 787.81, token/sec:665497.67, hellaswag_acc: 0.0000
Step:   189, loss: 6.467158, norm: 0.8036, time(ms): 788.15, token/sec:665210.80, hellaswag_acc: 0.0000
Step:   190, loss: 6.358188, norm: 0.7561, time(ms): 1247.70, token/sec:420204.47, hellaswag_acc: 0.0000
Step:   191, loss: 6.272770, norm: 0.8893, time(ms): 803.31, token/sec:652660.66, hellaswag_acc: 0.0000
Step:   192, loss: 6.313708, norm: 1.0289, time(ms): 791.00, token/sec:662814.18, hellaswag_acc: 0.0000
Step:   193, loss: 6.334470, norm: 1.0047, time(ms): 773.50, token/sec:677814.03, hellaswag_acc: 0.0000
Step:   194, loss: 6.335767, norm: 1.0426, time(ms): 784.45, token/sec:668352.45, hellaswag_acc: 0.0000
Step:   195, loss: 6.314926, norm: 1.0967, time(ms): 794.11, token/sec:660218.45, hellaswag_acc: 0.0000
Step:   196, loss: 6.270820, norm: 1.1911, time(ms): 783.28, token/sec:669349.29, hellaswag_acc: 0.0000
Step:   197, loss: 6.235691, norm: 1.0718, time(ms): 781.33, token/sec:671016.35, hellaswag_acc: 0.0000
Step:   198, loss: 6.340923, norm: 1.0800, time(ms): 783.76, token/sec:668939.21, hellaswag_acc: 0.0000
Step:   199, loss: 6.214824, norm: 0.9183, time(ms): 789.10, token/sec:664409.07, hellaswag_acc: 0.0000
Step:   200, loss: 6.260222, norm: 0.7774, time(ms): 785.76, token/sec:667237.49, hellaswag_acc: 0.0000
Step:   201, loss: 6.228245, norm: 0.9377, time(ms): 783.43, token/sec:669224.42, hellaswag_acc: 0.0000
Step:   202, loss: 6.246223, norm: 0.8117, time(ms): 789.35, token/sec:664201.16, hellaswag_acc: 0.0000
Step:   203, loss: 6.244241, norm: 1.0244, time(ms): 795.18, token/sec:659331.82, hellaswag_acc: 0.0000
Step:   204, loss: 6.226014, norm: 1.0836, time(ms): 791.98, token/sec:661998.48, hellaswag_acc: 0.0000
Step:   205, loss: 6.220798, norm: 1.1004, time(ms): 786.99, token/sec:666191.42, hellaswag_acc: 0.0000
Step:   206, loss: 6.193213, norm: 1.0934, time(ms): 793.62, token/sec:660631.80, hellaswag_acc: 0.0000
Step:   207, loss: 6.431930, norm: 0.9383, time(ms): 787.33, token/sec:665905.56, hellaswag_acc: 0.0000
Step:   208, loss: 6.374064, norm: 1.4181, time(ms): 788.68, token/sec:664764.17, hellaswag_acc: 0.0000
Step:   209, loss: 6.374982, norm: 1.1171, time(ms): 787.65, token/sec:665633.65, hellaswag_acc: 0.0000
Step:   210, loss: 6.445192, norm: 1.2158, time(ms): 797.55, token/sec:657371.27, hellaswag_acc: 0.0000
Step:   211, loss: 6.290109, norm: 1.1616, time(ms): 788.87, token/sec:664603.64, hellaswag_acc: 0.0000
Step:   212, loss: 6.348207, norm: 1.0596, time(ms): 788.52, token/sec:664902.06, hellaswag_acc: 0.0000
Step:   213, loss: 6.343219, norm: 1.0034, time(ms): 789.26, token/sec:664274.19, hellaswag_acc: 0.0000
Step:   214, loss: 6.314807, norm: 1.2535, time(ms): 792.77, token/sec:661338.90, hellaswag_acc: 0.0000
Step:   215, loss: 6.353573, norm: 1.0401, time(ms): 791.65, token/sec:662270.83, hellaswag_acc: 0.0000
Step:   216, loss: 6.296448, norm: 0.9174, time(ms): 790.54, token/sec:663201.58, hellaswag_acc: 0.0000
Step:   217, loss: 6.343599, norm: 0.9470, time(ms): 788.44, token/sec:664966.80, hellaswag_acc: 0.0000
Step:   218, loss: 6.301745, norm: 1.1586, time(ms): 785.69, token/sec:667296.00, hellaswag_acc: 0.0000
Step:   219, loss: 6.216379, norm: 1.0438, time(ms): 791.36, token/sec:662517.24, hellaswag_acc: 0.0000
Step:   220, loss: 6.241860, norm: 0.7870, time(ms): 797.59, token/sec:657338.26, hellaswag_acc: 0.0000
Step:   221, loss: 6.230164, norm: 0.8621, time(ms): 805.04, token/sec:651257.37, hellaswag_acc: 0.0000
Step:   222, loss: 6.224360, norm: 0.9628, time(ms): 793.38, token/sec:660829.73, hellaswag_acc: 0.0000
Step:   223, loss: 6.206102, norm: 0.9272, time(ms): 795.21, token/sec:659308.10, hellaswag_acc: 0.0000
Step:   224, loss: 6.201440, norm: 0.7306, time(ms): 791.55, token/sec:662358.60, hellaswag_acc: 0.0000
Step:   225, loss: 6.202613, norm: 0.6622, time(ms): 787.31, token/sec:665919.47, hellaswag_acc: 0.0000
Step:   226, loss: 6.224485, norm: 0.7328, time(ms): 785.45, token/sec:667501.80, hellaswag_acc: 0.0000
Step:   227, loss: 6.143647, norm: 0.9490, time(ms): 800.00, token/sec:655360.82, hellaswag_acc: 0.0000
Step:   228, loss: 6.242753, norm: 0.9261, time(ms): 796.09, token/sec:658575.74, hellaswag_acc: 0.0000
Step:   229, loss: 6.158106, norm: 1.1193, time(ms): 792.39, token/sec:661653.10, hellaswag_acc: 0.0000
Step:   230, loss: 6.162459, norm: 1.1434, time(ms): 783.81, token/sec:668893.02, hellaswag_acc: 0.0000
Step:   231, loss: 6.132524, norm: 0.7637, time(ms): 782.43, token/sec:670072.73, hellaswag_acc: 0.0000
Step:   232, loss: 6.136715, norm: 1.1425, time(ms): 790.08, token/sec:663586.84, hellaswag_acc: 0.0000
Step:   233, loss: 6.087635, norm: 0.7997, time(ms): 799.64, token/sec:655654.70, hellaswag_acc: 0.0000
Step:   234, loss: 6.162709, norm: 0.9456, time(ms): 792.55, token/sec:661519.34, hellaswag_acc: 0.0000
Step:   235, loss: 6.163906, norm: 1.0152, time(ms): 802.79, token/sec:653085.54, hellaswag_acc: 0.0000
Step:   236, loss: 6.112797, norm: 0.7239, time(ms): 803.91, token/sec:652173.07, hellaswag_acc: 0.0000
Step:   237, loss: 6.122175, norm: 0.8297, time(ms): 795.66, token/sec:658937.27, hellaswag_acc: 0.0000
Step:   238, loss: 6.061737, norm: 1.0888, time(ms): 794.24, token/sec:660114.60, hellaswag_acc: 0.0000
Step:   239, loss: 6.060003, norm: 0.8923, time(ms): 788.38, token/sec:665021.50, hellaswag_acc: 0.0000
Step:   240, loss: 6.108042, norm: 0.8693, time(ms): 786.91, token/sec:666261.26, hellaswag_acc: 0.0000
Step:   241, loss: 6.089389, norm: 0.6035, time(ms): 792.05, token/sec:661936.91, hellaswag_acc: 0.0000
Step:   242, loss: 6.196283, norm: 0.7892, time(ms): 790.79, token/sec:662993.83, hellaswag_acc: 0.0000
Step:   243, loss: 6.314973, norm: 0.9476, time(ms): 790.50, token/sec:663238.79, hellaswag_acc: 0.0000
Step:   244, loss: 6.207075, norm: 0.9409, time(ms): 791.81, token/sec:662140.41, hellaswag_acc: 0.0000
Step:   245, loss: 6.244442, norm: 0.9330, time(ms): 788.85, token/sec:664624.33, hellaswag_acc: 0.0000
Step:   246, loss: 6.222776, norm: 0.8303, time(ms): 786.97, token/sec:666207.36, hellaswag_acc: 0.0000
Step:   247, loss: 6.239784, norm: 0.7885, time(ms): 788.69, token/sec:664760.95, hellaswag_acc: 0.0000
Step:   248, loss: 6.203608, norm: 0.7797, time(ms): 800.85, token/sec:654663.12, hellaswag_acc: 0.0000
Step:   249, loss: 6.203844, norm: 0.8946, time(ms): 801.67, token/sec:653996.09, hellaswag_acc: 0.0000
rank 0 sample 0: Hello, I'm a language model, though the only a new time in all:1. He is still very a small to his wife and in the fact
rank 0 sample 1: Hello, I'm a language model, to work, and to develop, our children and your way. The question to be able to the person is good and
rank 0 sample 2: Hello, I'm a language model, I was his place? But our faith,’s I had not have, he’s not a small
rank 0 sample 3: Hello, I'm a language model, a more so a few year. The same group of the problem-the word page for more about my's the question
rank 1 sample 0: Hello, I'm a language model, you might.
For the case would not all that your hands.
’ve learned to the way to the
rank 1 sample 1: Hello, I'm a language model, we can have.
The report on:
We must be that may include only not being developed by the same.
rank 1 sample 2: Hello, I'm a language model, a short. But the idea of the same time, which I can’t be found it, I am really
rank 1 sample 3: Hello, I'm a language model, we all the world, if you think which is very low is important than only in place: The last new case,
Step:   250, loss: 6.186526, norm: 1.1383, time(ms): 3816.73, token/sec:137365.69, val_loss: 6.1825, hellaswag_acc: 0.0000
Step:   251, loss: 6.237109, norm: 1.0628, time(ms): 785.75, token/sec:667243.15, hellaswag_acc: 0.0000
Step:   252, loss: 6.187697, norm: 0.9311, time(ms): 795.81, token/sec:658813.49, hellaswag_acc: 0.0000
Step:   253, loss: 6.070400, norm: 1.0125, time(ms): 802.08, token/sec:653662.11, hellaswag_acc: 0.0000
Step:   254, loss: 6.125452, norm: 0.9935, time(ms): 783.92, token/sec:668807.17, hellaswag_acc: 0.0000
Step:   255, loss: 6.072181, norm: 1.0788, time(ms): 784.12, token/sec:668634.92, hellaswag_acc: 0.0000
Step:   256, loss: 6.041253, norm: 1.2731, time(ms): 790.21, token/sec:663480.12, hellaswag_acc: 0.0000
Step:   257, loss: 6.152744, norm: 1.0738, time(ms): 796.85, token/sec:657948.54, hellaswag_acc: 0.0000
Step:   258, loss: 6.113269, norm: 0.9965, time(ms): 789.87, token/sec:663766.11, hellaswag_acc: 0.0000
Step:   259, loss: 6.108019, norm: 0.8443, time(ms): 788.22, token/sec:665157.07, hellaswag_acc: 0.0000
Step:   260, loss: 6.013598, norm: 0.7915, time(ms): 801.80, token/sec:653889.32, hellaswag_acc: 0.0000
Step:   261, loss: 6.071226, norm: 0.8262, time(ms): 793.94, token/sec:660358.62, hellaswag_acc: 0.0000
Step:   262, loss: 6.050607, norm: 0.9143, time(ms): 788.74, token/sec:664716.14, hellaswag_acc: 0.0000
Step:   263, loss: 6.015775, norm: 0.9827, time(ms): 790.95, token/sec:662855.54, hellaswag_acc: 0.0000
Step:   264, loss: 6.053898, norm: 0.7425, time(ms): 789.97, token/sec:663682.37, hellaswag_acc: 0.0000
Step:   265, loss: 6.030460, norm: 0.6285, time(ms): 794.64, token/sec:659781.07, hellaswag_acc: 0.0000
Step:   266, loss: 6.016406, norm: 0.7275, time(ms): 801.37, token/sec:654235.80, hellaswag_acc: 0.0000
Step:   267, loss: 5.980115, norm: 0.7247, time(ms): 802.76, token/sec:653110.56, hellaswag_acc: 0.0000
Step:   268, loss: 6.052133, norm: 0.8251, time(ms): 792.30, token/sec:661730.75, hellaswag_acc: 0.0000
Step:   269, loss: 5.960801, norm: 0.9700, time(ms): 803.65, token/sec:652383.77, hellaswag_acc: 0.0000
Step:   270, loss: 5.974255, norm: 1.0825, time(ms): 803.49, token/sec:652509.79, hellaswag_acc: 0.0000
Step:   271, loss: 5.987391, norm: 0.9351, time(ms): 799.25, token/sec:655973.50, hellaswag_acc: 0.0000
Step:   272, loss: 6.057320, norm: 1.0295, time(ms): 792.02, token/sec:661963.61, hellaswag_acc: 0.0000
Step:   273, loss: 5.941640, norm: 0.8480, time(ms): 803.61, token/sec:652418.03, hellaswag_acc: 0.0000
Step:   274, loss: 5.963849, norm: 0.7851, time(ms): 804.49, token/sec:651700.51, hellaswag_acc: 0.0000
Step:   275, loss: 5.965928, norm: 0.7227, time(ms): 796.18, token/sec:658500.60, hellaswag_acc: 0.0000
Step:   276, loss: 5.906415, norm: 0.7346, time(ms): 793.64, token/sec:660613.93, hellaswag_acc: 0.0000
Step:   277, loss: 6.160982, norm: 0.7489, time(ms): 789.81, token/sec:663815.60, hellaswag_acc: 0.0000
Step:   278, loss: 6.084810, norm: 0.9699, time(ms): 790.84, token/sec:662947.46, hellaswag_acc: 0.0000
Step:   279, loss: 6.106772, norm: 1.0336, time(ms): 787.31, token/sec:665926.93, hellaswag_acc: 0.0000
Step:   280, loss: 6.086260, norm: 1.0203, time(ms): 794.03, token/sec:660290.41, hellaswag_acc: 0.0000
Step:   281, loss: 6.073422, norm: 1.1822, time(ms): 792.93, token/sec:661205.27, hellaswag_acc: 0.0000
Step:   282, loss: 6.062742, norm: 1.0869, time(ms): 791.24, token/sec:662616.26, hellaswag_acc: 0.0000
Step:   283, loss: 6.060085, norm: 0.9970, time(ms): 792.63, token/sec:661457.46, hellaswag_acc: 0.0000
Step:   284, loss: 6.057564, norm: 1.0279, time(ms): 789.44, token/sec:664127.54, hellaswag_acc: 0.0000
Step:   285, loss: 6.108200, norm: 0.8621, time(ms): 792.26, token/sec:661760.62, hellaswag_acc: 0.0000
Step:   286, loss: 6.085135, norm: 0.8356, time(ms): 791.42, token/sec:662468.94, hellaswag_acc: 0.0000
Step:   287, loss: 6.008798, norm: 0.8344, time(ms): 787.86, token/sec:665458.00, hellaswag_acc: 0.0000
Step:   288, loss: 5.942832, norm: 0.8008, time(ms): 802.80, token/sec:653070.80, hellaswag_acc: 0.0000
Step:   289, loss: 6.017517, norm: 0.7398, time(ms): 804.62, token/sec:651601.06, hellaswag_acc: 0.0000
Step:   290, loss: 5.988348, norm: 0.6318, time(ms): 797.48, token/sec:657431.61, hellaswag_acc: 0.0000
Step:   291, loss: 5.919830, norm: 0.5813, time(ms): 793.56, token/sec:660680.42, hellaswag_acc: 0.0000
Step:   292, loss: 5.932857, norm: 0.6561, time(ms): 792.53, token/sec:661539.84, hellaswag_acc: 0.0000
Step:   293, loss: 5.935568, norm: 0.7758, time(ms): 786.13, token/sec:666921.80, hellaswag_acc: 0.0000
Step:   294, loss: 5.888703, norm: 0.9426, time(ms): 791.28, token/sec:662580.32, hellaswag_acc: 0.0000
Step:   295, loss: 5.931600, norm: 0.9943, time(ms): 789.67, token/sec:663932.64, hellaswag_acc: 0.0000
Step:   296, loss: 5.904236, norm: 0.9366, time(ms): 792.29, token/sec:661736.72, hellaswag_acc: 0.0000
Step:   297, loss: 5.919297, norm: 1.0586, time(ms): 788.25, token/sec:665129.71, hellaswag_acc: 0.0000
Step:   298, loss: 5.921560, norm: 1.1336, time(ms): 792.18, token/sec:661829.73, hellaswag_acc: 0.0000
Step:   299, loss: 5.852930, norm: 0.9372, time(ms): 785.97, token/sec:667057.75, hellaswag_acc: 0.0000
Step:   300, loss: 5.911256, norm: 0.9605, time(ms): 790.36, token/sec:663353.23, hellaswag_acc: 0.0000
Step:   301, loss: 5.902514, norm: 0.9133, time(ms): 799.50, token/sec:655772.80, hellaswag_acc: 0.0000
Step:   302, loss: 5.925557, norm: 1.1070, time(ms): 791.01, token/sec:662811.99, hellaswag_acc: 0.0000
Step:   303, loss: 5.867062, norm: 0.8055, time(ms): 801.62, token/sec:654033.82, hellaswag_acc: 0.0000
Step:   304, loss: 5.854210, norm: 0.7035, time(ms): 796.43, token/sec:658293.82, hellaswag_acc: 0.0000
Step:   305, loss: 5.833346, norm: 0.7569, time(ms): 791.06, token/sec:662769.44, hellaswag_acc: 0.0000
Step:   306, loss: 5.810535, norm: 0.7727, time(ms): 783.20, token/sec:669419.38, hellaswag_acc: 0.0000
Step:   307, loss: 5.826926, norm: 0.8770, time(ms): 790.84, token/sec:662954.06, hellaswag_acc: 0.0000
Step:   308, loss: 5.855060, norm: 0.9260, time(ms): 793.12, token/sec:661044.87, hellaswag_acc: 0.0000
Step:   309, loss: 5.889401, norm: 0.9197, time(ms): 790.78, token/sec:663000.43, hellaswag_acc: 0.0000
Step:   310, loss: 5.885395, norm: 0.9148, time(ms): 789.44, token/sec:664125.54, hellaswag_acc: 0.0000
Step:   311, loss: 5.987056, norm: 0.9606, time(ms): 787.88, token/sec:665443.70, hellaswag_acc: 0.0000
Step:   312, loss: 6.031534, norm: 1.1945, time(ms): 789.53, token/sec:664053.34, hellaswag_acc: 0.0000
Step:   313, loss: 5.993066, norm: 0.9672, time(ms): 794.06, token/sec:660266.02, hellaswag_acc: 0.0000
Step:   314, loss: 6.011284, norm: 0.8961, time(ms): 791.84, token/sec:662111.90, hellaswag_acc: 0.0000
Step:   315, loss: 5.973689, norm: 0.8538, time(ms): 800.26, token/sec:655146.24, hellaswag_acc: 0.0000
Step:   316, loss: 5.931529, norm: 1.0642, time(ms): 801.63, token/sec:654024.29, hellaswag_acc: 0.0000
Step:   317, loss: 5.951317, norm: 0.8645, time(ms): 802.79, token/sec:653084.76, hellaswag_acc: 0.0000
Step:   318, loss: 5.952875, norm: 0.6548, time(ms): 793.50, token/sec:660730.25, hellaswag_acc: 0.0000
Step:   319, loss: 5.912010, norm: 0.7860, time(ms): 800.26, token/sec:655150.34, hellaswag_acc: 0.0000
Step:   320, loss: 5.903130, norm: 0.7928, time(ms): 796.16, token/sec:658518.55, hellaswag_acc: 0.0000
Step:   321, loss: 5.901669, norm: 1.1682, time(ms): 790.49, token/sec:663243.99, hellaswag_acc: 0.0000
Step:   322, loss: 5.854522, norm: 1.7336, time(ms): 786.79, token/sec:666363.01, hellaswag_acc: 0.0000
Step:   323, loss: 5.832585, norm: 1.0694, time(ms): 787.76, token/sec:665543.80, hellaswag_acc: 0.0000
Step:   324, loss: 5.858712, norm: 1.2747, time(ms): 801.26, token/sec:654326.32, hellaswag_acc: 0.0000
Step:   325, loss: 5.840304, norm: 1.0354, time(ms): 801.42, token/sec:654196.09, hellaswag_acc: 0.0000
Step:   326, loss: 5.828139, norm: 1.3175, time(ms): 796.07, token/sec:658591.52, hellaswag_acc: 0.0000
Step:   327, loss: 5.869952, norm: 1.2708, time(ms): 791.02, token/sec:662800.40, hellaswag_acc: 0.0000
Step:   328, loss: 5.840828, norm: 1.0841, time(ms): 790.34, token/sec:663372.44, hellaswag_acc: 0.0000
Step:   329, loss: 5.898814, norm: 1.0968, time(ms): 799.06, token/sec:656132.63, hellaswag_acc: 0.0000
Step:   330, loss: 5.817998, norm: 0.9594, time(ms): 789.54, token/sec:664043.91, hellaswag_acc: 0.0000
Step:   331, loss: 5.829856, norm: 1.1011, time(ms): 782.19, token/sec:670285.35, hellaswag_acc: 0.0000
Step:   332, loss: 5.786331, norm: 1.2925, time(ms): 789.02, token/sec:664483.75, hellaswag_acc: 0.0000
Step:   333, loss: 5.775645, norm: 0.7910, time(ms): 799.35, token/sec:655891.13, hellaswag_acc: 0.0000
Step:   334, loss: 5.733233, norm: 0.8686, time(ms): 802.77, token/sec:653096.21, hellaswag_acc: 0.0000
Step:   335, loss: 5.750812, norm: 1.1174, time(ms): 801.21, token/sec:654367.60, hellaswag_acc: 0.0000
Step:   336, loss: 5.753774, norm: 0.9597, time(ms): 793.58, token/sec:660662.16, hellaswag_acc: 0.0000
Step:   337, loss: 5.749166, norm: 0.9062, time(ms): 802.72, token/sec:653136.17, hellaswag_acc: 0.0000
Step:   338, loss: 5.747582, norm: 0.8834, time(ms): 802.03, token/sec:653700.39, hellaswag_acc: 0.0000
Step:   339, loss: 5.702670, norm: 0.8971, time(ms): 797.01, token/sec:657820.22, hellaswag_acc: 0.0000
Step:   340, loss: 5.772282, norm: 0.9594, time(ms): 798.07, token/sec:656946.88, hellaswag_acc: 0.0000
Step:   341, loss: 5.769662, norm: 1.3613, time(ms): 796.24, token/sec:658456.83, hellaswag_acc: 0.0000
Step:   342, loss: 5.801395, norm: 1.0789, time(ms): 788.74, token/sec:664714.94, hellaswag_acc: 0.0000
Step:   343, loss: 5.706290, norm: 1.0986, time(ms): 791.31, token/sec:662553.57, hellaswag_acc: 0.0000
Step:   344, loss: 5.805407, norm: 1.0202, time(ms): 791.21, token/sec:662641.82, hellaswag_acc: 0.0000
Step:   345, loss: 5.759419, norm: 0.7813, time(ms): 788.45, token/sec:664957.55, hellaswag_acc: 0.0000
Step:   346, loss: 5.833834, norm: 0.7681, time(ms): 792.16, token/sec:661842.68, hellaswag_acc: 0.0000
Step:   347, loss: 5.817538, norm: 0.8322, time(ms): 791.86, token/sec:662100.74, hellaswag_acc: 0.0000
Step:   348, loss: 5.836903, norm: 0.7893, time(ms): 795.46, token/sec:659096.26, hellaswag_acc: 0.0000
Step:   349, loss: 5.826366, norm: 0.8667, time(ms): 788.00, token/sec:665336.39, hellaswag_acc: 0.0000
Step:   350, loss: 5.888126, norm: 1.1799, time(ms): 789.14, token/sec:664381.36, hellaswag_acc: 0.0000
Step:   351, loss: 5.829165, norm: 1.2172, time(ms): 789.52, token/sec:664060.76, hellaswag_acc: 0.0000
Step:   352, loss: 5.808289, norm: 1.2860, time(ms): 795.14, token/sec:659365.82, hellaswag_acc: 0.0000
Step:   353, loss: 5.833761, norm: 1.2225, time(ms): 801.70, token/sec:653968.27, hellaswag_acc: 0.0000
Step:   354, loss: 5.796144, norm: 1.5242, time(ms): 806.49, token/sec:650082.95, hellaswag_acc: 0.0000
Step:   355, loss: 5.818254, norm: 1.0579, time(ms): 791.81, token/sec:662142.60, hellaswag_acc: 0.0000
Step:   356, loss: 5.859970, norm: 1.3392, time(ms): 798.30, token/sec:656759.31, hellaswag_acc: 0.0000
Step:   357, loss: 5.805436, norm: 1.1992, time(ms): 791.72, token/sec:662210.00, hellaswag_acc: 0.0000
Step:   358, loss: 5.736989, norm: 0.9383, time(ms): 787.19, token/sec:666025.76, hellaswag_acc: 0.0000
Step:   359, loss: 5.673895, norm: 0.9902, time(ms): 790.51, token/sec:663229.99, hellaswag_acc: 0.0000
Step:   360, loss: 5.705235, norm: 0.8616, time(ms): 793.61, token/sec:660634.57, hellaswag_acc: 0.0000
Step:   361, loss: 5.715663, norm: 1.0358, time(ms): 792.49, token/sec:661570.49, hellaswag_acc: 0.0000
Step:   362, loss: 5.706026, norm: 1.3652, time(ms): 790.84, token/sec:662946.66, hellaswag_acc: 0.0000
Step:   363, loss: 5.733088, norm: 1.3058, time(ms): 789.44, token/sec:664124.33, hellaswag_acc: 0.0000
Step:   364, loss: 5.712120, norm: 1.0284, time(ms): 788.66, token/sec:664779.24, hellaswag_acc: 0.0000
Step:   365, loss: 5.671474, norm: 1.0314, time(ms): 790.13, token/sec:663549.79, hellaswag_acc: 0.0000
Step:   366, loss: 5.695251, norm: 1.1791, time(ms): 792.16, token/sec:661842.28, hellaswag_acc: 0.0000
Step:   367, loss: 5.726241, norm: 0.9983, time(ms): 791.79, token/sec:662155.36, hellaswag_acc: 0.0000
Step:   368, loss: 5.676559, norm: 0.9316, time(ms): 789.50, token/sec:664072.99, hellaswag_acc: 0.0000
Step:   369, loss: 5.665856, norm: 1.3577, time(ms): 787.31, token/sec:665925.93, hellaswag_acc: 0.0000
Step:   370, loss: 5.622413, norm: 0.9538, time(ms): 790.40, token/sec:663318.21, hellaswag_acc: 0.0000
Step:   371, loss: 5.673524, norm: 0.9914, time(ms): 790.55, token/sec:663190.58, hellaswag_acc: 0.0000
Step:   372, loss: 5.627959, norm: 1.0003, time(ms): 789.90, token/sec:663741.26, hellaswag_acc: 0.0000
Step:   373, loss: 5.618732, norm: 0.8285, time(ms): 784.82, token/sec:668032.06, hellaswag_acc: 0.0000
Step:   374, loss: 5.622916, norm: 0.7606, time(ms): 785.99, token/sec:667041.57, hellaswag_acc: 0.0000
Step:   375, loss: 5.546151, norm: 0.8151, time(ms): 792.38, token/sec:661660.86, hellaswag_acc: 0.0000
Step:   376, loss: 5.622063, norm: 0.7153, time(ms): 790.22, token/sec:663467.11, hellaswag_acc: 0.0000
Step:   377, loss: 5.582855, norm: 0.7541, time(ms): 805.38, token/sec:650980.90, hellaswag_acc: 0.0000
Step:   378, loss: 5.590758, norm: 1.0955, time(ms): 794.02, token/sec:660298.93, hellaswag_acc: 0.0000
Step:   379, loss: 5.591857, norm: 1.2150, time(ms): 798.29, token/sec:656763.62, hellaswag_acc: 0.0000
Step:   380, loss: 5.635774, norm: 0.8552, time(ms): 1271.11, token/sec:412463.75, hellaswag_acc: 0.0000
Step:   381, loss: 5.760181, norm: 0.9133, time(ms): 767.67, token/sec:682955.96, hellaswag_acc: 0.0000
Step:   382, loss: 5.634206, norm: 1.3475, time(ms): 790.42, token/sec:663299.41, hellaswag_acc: 0.0000
Step:   383, loss: 5.685076, norm: 1.0935, time(ms): 796.72, token/sec:658061.95, hellaswag_acc: 0.0000
Step:   384, loss: 5.669783, norm: 1.1236, time(ms): 786.75, token/sec:666394.51, hellaswag_acc: 0.0000
Step:   385, loss: 5.629096, norm: 1.1992, time(ms): 781.55, token/sec:670833.15, hellaswag_acc: 0.0000
Step:   386, loss: 5.624445, norm: 0.8361, time(ms): 779.88, token/sec:672269.75, hellaswag_acc: 0.0000
Step:   387, loss: 5.560433, norm: 0.8511, time(ms): 792.40, token/sec:661646.53, hellaswag_acc: 0.0000
Step:   388, loss: 5.635652, norm: 1.1393, time(ms): 791.56, token/sec:662344.83, hellaswag_acc: 0.0000
Step:   389, loss: 5.598413, norm: 1.1156, time(ms): 790.33, token/sec:663380.65, hellaswag_acc: 0.0000
Step:   390, loss: 5.589000, norm: 1.0229, time(ms): 785.55, token/sec:667411.24, hellaswag_acc: 0.0000
Step:   391, loss: 5.519119, norm: 0.9607, time(ms): 788.96, token/sec:664528.93, hellaswag_acc: 0.0000
Step:   392, loss: 5.540447, norm: 1.0301, time(ms): 789.30, token/sec:664240.89, hellaswag_acc: 0.0000
Step:   393, loss: 5.560978, norm: 0.8822, time(ms): 791.44, token/sec:662450.98, hellaswag_acc: 0.0000
Step:   394, loss: 5.512427, norm: 0.9861, time(ms): 795.16, token/sec:659350.20, hellaswag_acc: 0.0000
Step:   395, loss: 5.553020, norm: 0.9934, time(ms): 802.06, token/sec:653676.29, hellaswag_acc: 0.0000
Step:   396, loss: 5.586743, norm: 1.1775, time(ms): 799.18, token/sec:656033.00, hellaswag_acc: 0.0000
Step:   397, loss: 5.516770, norm: 1.0446, time(ms): 790.41, token/sec:663313.81, hellaswag_acc: 0.0000
Step:   398, loss: 5.512263, norm: 1.1808, time(ms): 786.43, token/sec:666669.27, hellaswag_acc: 0.0000
Step:   399, loss: 5.517447, norm: 1.0748, time(ms): 791.82, token/sec:662132.63, hellaswag_acc: 0.0000
Step:   400, loss: 5.556890, norm: 1.0124, time(ms): 791.19, token/sec:662660.59, hellaswag_acc: 0.0000
Step:   401, loss: 5.496057, norm: 0.7857, time(ms): 799.21, token/sec:656006.77, hellaswag_acc: 0.0000
Step:   402, loss: 5.626974, norm: 0.6443, time(ms): 799.74, token/sec:655576.52, hellaswag_acc: 0.0000
Step:   403, loss: 5.617666, norm: 0.8084, time(ms): 795.69, token/sec:658912.00, hellaswag_acc: 0.0000
Step:   404, loss: 5.692745, norm: 1.0704, time(ms): 792.13, token/sec:661872.76, hellaswag_acc: 0.0000
Step:   405, loss: 5.635270, norm: 1.5555, time(ms): 785.33, token/sec:667600.89, hellaswag_acc: 0.0000
Step:   406, loss: 5.641332, norm: 0.9310, time(ms): 785.55, token/sec:667415.90, hellaswag_acc: 0.0000
Step:   407, loss: 5.620290, norm: 0.9242, time(ms): 794.27, token/sec:660085.87, hellaswag_acc: 0.0000
Step:   408, loss: 5.665018, norm: 0.8875, time(ms): 791.28, token/sec:662583.52, hellaswag_acc: 0.0000
Step:   409, loss: 5.616416, norm: 1.0720, time(ms): 792.32, token/sec:661709.04, hellaswag_acc: 0.0000
Step:   410, loss: 5.598673, norm: 0.9079, time(ms): 797.97, token/sec:657023.82, hellaswag_acc: 0.0000
Step:   411, loss: 5.621023, norm: 1.0170, time(ms): 797.66, token/sec:657282.66, hellaswag_acc: 0.0000
Step:   412, loss: 5.619648, norm: 0.9694, time(ms): 789.59, token/sec:663997.60, hellaswag_acc: 0.0000
Step:   413, loss: 5.650002, norm: 0.9084, time(ms): 787.31, token/sec:665924.72, hellaswag_acc: 0.0000
Step:   414, loss: 5.503923, norm: 1.0361, time(ms): 787.05, token/sec:666143.59, hellaswag_acc: 0.0000
Step:   415, loss: 5.488313, norm: 1.0806, time(ms): 802.60, token/sec:653239.00, hellaswag_acc: 0.0000
Step:   416, loss: 5.497911, norm: 1.0956, time(ms): 798.97, token/sec:656208.01, hellaswag_acc: 0.0000
Step:   417, loss: 5.491224, norm: 1.0910, time(ms): 795.29, token/sec:659244.85, hellaswag_acc: 0.0000
Step:   418, loss: 5.520017, norm: 0.8594, time(ms): 790.44, token/sec:663289.80, hellaswag_acc: 0.0000
Step:   419, loss: 5.473234, norm: 0.9164, time(ms): 795.37, token/sec:659171.33, hellaswag_acc: 0.0000
Step:   420, loss: 5.502495, norm: 0.9811, time(ms): 792.68, token/sec:661415.88, hellaswag_acc: 0.0000
Step:   421, loss: 5.505424, norm: 1.0107, time(ms): 786.50, token/sec:666605.41, hellaswag_acc: 0.0000
Step:   422, loss: 5.473049, norm: 1.0107, time(ms): 789.90, token/sec:663741.06, hellaswag_acc: 0.0000
Step:   423, loss: 5.451310, norm: 1.2363, time(ms): 792.36, token/sec:661680.17, hellaswag_acc: 0.0000
Step:   424, loss: 5.497607, norm: 0.9904, time(ms): 790.25, token/sec:663445.49, hellaswag_acc: 0.0000
Step:   425, loss: 5.413522, norm: 0.8110, time(ms): 790.49, token/sec:663248.19, hellaswag_acc: 0.0000
Step:   426, loss: 5.445877, norm: 0.8215, time(ms): 787.23, token/sec:665993.49, hellaswag_acc: 0.0000
Step:   427, loss: 5.424617, norm: 0.8458, time(ms): 788.72, token/sec:664730.81, hellaswag_acc: 0.0000
Step:   428, loss: 5.417612, norm: 1.1980, time(ms): 794.94, token/sec:659532.13, hellaswag_acc: 0.0000
Step:   429, loss: 5.426454, norm: 1.0767, time(ms): 790.40, token/sec:663316.41, hellaswag_acc: 0.0000
Step:   430, loss: 5.422707, norm: 1.1815, time(ms): 787.55, token/sec:665717.27, hellaswag_acc: 0.0000
Step:   431, loss: 5.411183, norm: 0.9487, time(ms): 785.84, token/sec:667165.42, hellaswag_acc: 0.0000
Step:   432, loss: 5.426617, norm: 0.6713, time(ms): 793.28, token/sec:660912.55, hellaswag_acc: 0.0000
Step:   433, loss: 5.378161, norm: 0.7403, time(ms): 790.28, token/sec:663419.87, hellaswag_acc: 0.0000
Step:   434, loss: 5.420634, norm: 0.7823, time(ms): 798.22, token/sec:656820.12, hellaswag_acc: 0.0000
Step:   435, loss: 5.386208, norm: 0.8831, time(ms): 792.56, token/sec:661514.57, hellaswag_acc: 0.0000
Step:   436, loss: 5.387960, norm: 0.9285, time(ms): 797.27, token/sec:657607.37, hellaswag_acc: 0.0000
Step:   437, loss: 5.489460, norm: 1.1296, time(ms): 792.27, token/sec:661756.24, hellaswag_acc: 0.0000
Step:   438, loss: 5.498072, norm: 1.3455, time(ms): 784.68, token/sec:668153.44, hellaswag_acc: 0.0000
Step:   439, loss: 5.501572, norm: 1.1042, time(ms): 789.58, token/sec:664006.02, hellaswag_acc: 0.0000
Step:   440, loss: 5.486286, norm: 0.9104, time(ms): 797.05, token/sec:657788.93, hellaswag_acc: 0.0000
Step:   441, loss: 5.518826, norm: 1.0291, time(ms): 804.71, token/sec:651525.57, hellaswag_acc: 0.0000
Step:   442, loss: 5.471064, norm: 1.1456, time(ms): 788.04, token/sec:665302.17, hellaswag_acc: 0.0000
Step:   443, loss: 5.444109, norm: 0.9303, time(ms): 790.13, token/sec:663547.79, hellaswag_acc: 0.0000
Step:   444, loss: 5.462451, norm: 1.1619, time(ms): 795.01, token/sec:659469.44, hellaswag_acc: 0.0000
Step:   445, loss: 5.570692, norm: 1.1344, time(ms): 791.92, token/sec:662045.72, hellaswag_acc: 0.0000
Step:   446, loss: 5.495564, norm: 0.9268, time(ms): 783.38, token/sec:669261.89, hellaswag_acc: 0.0000
Step:   447, loss: 5.446212, norm: 1.2573, time(ms): 788.85, token/sec:664622.93, hellaswag_acc: 0.0000
Step:   448, loss: 5.436701, norm: 1.1860, time(ms): 798.77, token/sec:656371.75, hellaswag_acc: 0.0000
Step:   449, loss: 5.381846, norm: 0.9924, time(ms): 805.11, token/sec:651204.33, hellaswag_acc: 0.0000
Step:   450, loss: 5.412269, norm: 1.1715, time(ms): 794.83, token/sec:659625.71, hellaswag_acc: 0.0000
Step:   451, loss: 5.357121, norm: 0.9249, time(ms): 797.24, token/sec:657630.38, hellaswag_acc: 0.0000
Step:   452, loss: 5.426422, norm: 1.1028, time(ms): 799.98, token/sec:655373.71, hellaswag_acc: 0.0000
Step:   453, loss: 5.380352, norm: 0.8852, time(ms): 797.12, token/sec:657731.87, hellaswag_acc: 0.0000
Step:   454, loss: 5.333233, norm: 0.8899, time(ms): 790.98, token/sec:662834.56, hellaswag_acc: 0.0000
Step:   455, loss: 5.384567, norm: 0.9556, time(ms): 785.33, token/sec:667598.26, hellaswag_acc: 0.0000
Step:   456, loss: 5.354022, norm: 0.8505, time(ms): 784.97, token/sec:667908.70, hellaswag_acc: 0.0000
Step:   457, loss: 5.354044, norm: 0.7955, time(ms): 796.08, token/sec:658585.01, hellaswag_acc: 0.0000
Step:   458, loss: 5.328251, norm: 0.8788, time(ms): 792.04, token/sec:661945.88, hellaswag_acc: 0.0000
Step:   459, loss: 5.380167, norm: 0.8814, time(ms): 789.73, token/sec:663880.13, hellaswag_acc: 0.0000
Step:   460, loss: 5.320148, norm: 0.8845, time(ms): 784.42, token/sec:668376.42, hellaswag_acc: 0.0000
Step:   461, loss: 5.277642, norm: 0.9973, time(ms): 790.69, token/sec:663076.40, hellaswag_acc: 0.0000
Step:   462, loss: 5.292807, norm: 1.1093, time(ms): 788.77, token/sec:664686.81, hellaswag_acc: 0.0000
Step:   463, loss: 5.302293, norm: 0.9867, time(ms): 797.72, token/sec:657230.99, hellaswag_acc: 0.0000
Step:   464, loss: 5.379887, norm: 1.0402, time(ms): 806.14, token/sec:650369.43, hellaswag_acc: 0.0000
Step:   465, loss: 5.371768, norm: 1.1169, time(ms): 797.17, token/sec:657684.66, hellaswag_acc: 0.0000
Step:   466, loss: 5.309225, norm: 0.9129, time(ms): 793.87, token/sec:660423.67, hellaswag_acc: 0.0000
Step:   467, loss: 5.284795, norm: 0.9128, time(ms): 791.68, token/sec:662250.28, hellaswag_acc: 0.0000
Step:   468, loss: 5.292321, norm: 0.8009, time(ms): 782.95, token/sec:669632.61, hellaswag_acc: 0.0000
Step:   469, loss: 5.295853, norm: 0.8374, time(ms): 792.06, token/sec:661929.74, hellaswag_acc: 0.0000
Step:   470, loss: 5.278233, norm: 1.0074, time(ms): 795.73, token/sec:658877.06, hellaswag_acc: 0.0000
Step:   471, loss: 5.308585, norm: 1.2493, time(ms): 802.65, token/sec:653199.41, hellaswag_acc: 0.0000
Step:   472, loss: 5.409586, norm: 0.9440, time(ms): 795.43, token/sec:659127.67, hellaswag_acc: 0.0000
Step:   473, loss: 5.410320, norm: 0.8907, time(ms): 789.02, token/sec:664483.35, hellaswag_acc: 0.0000
Step:   474, loss: 5.392979, norm: 0.9692, time(ms): 788.13, token/sec:665227.10, hellaswag_acc: 0.0000
Step:   475, loss: 5.475721, norm: 1.2660, time(ms): 789.50, token/sec:664079.21, hellaswag_acc: 0.0000
Step:   476, loss: 5.376712, norm: 1.0326, time(ms): 789.35, token/sec:664201.56, hellaswag_acc: 0.0000
Step:   477, loss: 5.366698, norm: 0.9297, time(ms): 788.40, token/sec:665002.59, hellaswag_acc: 0.0000
Step:   478, loss: 5.359861, norm: 0.8261, time(ms): 792.66, token/sec:661431.79, hellaswag_acc: 0.0000
Step:   479, loss: 5.418998, norm: 0.9238, time(ms): 790.44, token/sec:663283.80, hellaswag_acc: 0.0000
Step:   480, loss: 5.384878, norm: 0.9792, time(ms): 786.86, token/sec:666300.42, hellaswag_acc: 0.0000
Step:   481, loss: 5.383598, norm: 0.9783, time(ms): 789.63, token/sec:663966.52, hellaswag_acc: 0.0000
Step:   482, loss: 5.389587, norm: 1.1783, time(ms): 793.72, token/sec:660545.27, hellaswag_acc: 0.0000
Step:   483, loss: 5.359399, norm: 1.0150, time(ms): 791.89, token/sec:662072.43, hellaswag_acc: 0.0000
Step:   484, loss: 5.316784, norm: 1.2191, time(ms): 785.15, token/sec:667753.95, hellaswag_acc: 0.0000
Step:   485, loss: 5.306133, norm: 1.0516, time(ms): 782.00, token/sec:670442.91, hellaswag_acc: 0.0000
Step:   486, loss: 5.287154, norm: 1.1347, time(ms): 791.13, token/sec:662711.51, hellaswag_acc: 0.0000
Step:   487, loss: 5.276365, norm: 1.0683, time(ms): 792.14, token/sec:661859.41, hellaswag_acc: 0.0000
Step:   488, loss: 5.240810, norm: 0.8988, time(ms): 796.43, token/sec:658294.41, hellaswag_acc: 0.0000
Step:   489, loss: 5.258189, norm: 0.7778, time(ms): 794.23, token/sec:660117.77, hellaswag_acc: 0.0000
Step:   490, loss: 5.239264, norm: 0.8182, time(ms): 791.82, token/sec:662126.45, hellaswag_acc: 0.0000
Step:   491, loss: 5.218916, norm: 0.9118, time(ms): 788.25, token/sec:665125.49, hellaswag_acc: 0.0000
Step:   492, loss: 5.282038, norm: 0.9723, time(ms): 792.83, token/sec:661282.81, hellaswag_acc: 0.0000
Step:   493, loss: 5.250566, norm: 1.0587, time(ms): 796.45, token/sec:658282.98, hellaswag_acc: 0.0000
Step:   494, loss: 5.260172, norm: 1.3121, time(ms): 802.47, token/sec:653345.94, hellaswag_acc: 0.0000
Step:   495, loss: 5.217153, norm: 0.9655, time(ms): 800.52, token/sec:654933.56, hellaswag_acc: 0.0000
Step:   496, loss: 5.270018, norm: 1.0872, time(ms): 791.43, token/sec:662459.76, hellaswag_acc: 0.0000
Step:   497, loss: 5.185198, norm: 1.1124, time(ms): 792.19, token/sec:661824.15, hellaswag_acc: 0.0000
Step:   498, loss: 5.129579, norm: 0.9504, time(ms): 790.92, token/sec:662887.71, hellaswag_acc: 0.0000
Step:   499, loss: 5.150320, norm: 0.9339, time(ms): 794.91, token/sec:659554.69, hellaswag_acc: 0.0000
rank 0 sample 0: Hello, I'm a language model, but I was a very rare than, too is more like I wonder who were my friends. They had a lot.
rank 0 sample 1: Hello, I'm a language model, and this activity, and I will put it a real task, the picture the image of the object which the elements in
rank 0 sample 2: Hello, I'm a language model, and I need to go and other in the story.
It has an important role in the history of the world,
rank 0 sample 3: Hello, I'm a language model, I could be seen in the world I will allow it to play your understanding. With that in my way, the people
rank 1 sample 0: Hello, I'm a language model, in a special field, and I say I was not one by the best practices. And the other words, I am
rank 1 sample 1: Hello, I'm a language model, my eyes and more than my mind to go to. As I put my life more or me around, I am not
rank 1 sample 2: Hello, I'm a language model, I wanted my eyes, I am not my eyes, my name I would give me, and you will not make and
rank 1 sample 3: Hello, I'm a language model, but I am the same of my head’s with the original. To my home has an extra-day,
Step:   500, loss: 5.134887, norm: 1.0410, time(ms): 3777.73, token/sec:138783.87, val_loss: 5.3257, hellaswag_acc: 0.0000
Step:   501, loss: 5.150893, norm: 0.9115, time(ms): 780.67, token/sec:671585.03, hellaswag_acc: 0.0000
Step:   502, loss: 5.225290, norm: 1.2297, time(ms): 784.44, token/sec:668357.53, hellaswag_acc: 0.0000
Step:   503, loss: 5.166535, norm: 1.0123, time(ms): 797.96, token/sec:657031.87, hellaswag_acc: 0.0000
Step:   504, loss: 5.202356, norm: 0.9915, time(ms): 792.26, token/sec:661761.41, hellaswag_acc: 0.0000
Step:   505, loss: 5.144652, norm: 0.8949, time(ms): 785.13, token/sec:667772.80, hellaswag_acc: 0.0000
Step:   506, loss: 5.162246, norm: 0.8266, time(ms): 783.22, token/sec:669399.21, hellaswag_acc: 0.0000
Step:   507, loss: 5.253273, norm: 0.8813, time(ms): 788.84, token/sec:664631.56, hellaswag_acc: 0.0000
Step:   508, loss: 5.267037, norm: 0.8985, time(ms): 792.12, token/sec:661882.92, hellaswag_acc: 0.0000
Step:   509, loss: 5.265078, norm: 0.9914, time(ms): 790.91, token/sec:662892.31, hellaswag_acc: 0.0000
Step:   510, loss: 5.297862, norm: 0.9556, time(ms): 789.28, token/sec:664261.95, hellaswag_acc: 0.0000
Step:   511, loss: 5.328890, norm: 1.0602, time(ms): 802.15, token/sec:653606.15, hellaswag_acc: 0.0000
Step:   512, loss: 5.277502, norm: 1.0230, time(ms): 805.60, token/sec:650803.08, hellaswag_acc: 0.0000
Step:   513, loss: 5.301979, norm: 1.0061, time(ms): 784.14, token/sec:668616.83, hellaswag_acc: 0.0000
Step:   514, loss: 5.271647, norm: 0.9889, time(ms): 784.94, token/sec:667935.07, hellaswag_acc: 0.0000
Step:   515, loss: 5.340439, norm: 1.0645, time(ms): 790.15, token/sec:663532.97, hellaswag_acc: 0.0000
Step:   516, loss: 5.253150, norm: 1.0436, time(ms): 798.82, token/sec:656331.99, hellaswag_acc: 0.0000
Step:   517, loss: 5.249968, norm: 1.0213, time(ms): 787.31, token/sec:665920.48, hellaswag_acc: 0.0000
Step:   518, loss: 5.209430, norm: 0.9848, time(ms): 789.39, token/sec:664169.46, hellaswag_acc: 0.0000
Step:   519, loss: 5.137192, norm: 0.9886, time(ms): 795.75, token/sec:658858.70, hellaswag_acc: 0.0000
Step:   520, loss: 5.174816, norm: 1.1175, time(ms): 789.95, token/sec:663698.39, hellaswag_acc: 0.0000
Step:   521, loss: 5.124640, norm: 0.6866, time(ms): 783.61, token/sec:669070.08, hellaswag_acc: 0.0000
Step:   522, loss: 5.191209, norm: 0.6477, time(ms): 786.12, token/sec:666927.87, hellaswag_acc: 0.0000
Step:   523, loss: 5.137806, norm: 0.6752, time(ms): 799.55, token/sec:655729.58, hellaswag_acc: 0.0000
Step:   524, loss: 5.168894, norm: 0.8963, time(ms): 808.24, token/sec:648680.57, hellaswag_acc: 0.0000
Step:   525, loss: 5.138820, norm: 1.0890, time(ms): 782.68, token/sec:669863.11, hellaswag_acc: 0.0000
Step:   526, loss: 5.119084, norm: 0.8634, time(ms): 785.50, token/sec:667457.22, hellaswag_acc: 0.0000
Step:   527, loss: 5.128340, norm: 0.9469, time(ms): 789.87, token/sec:663764.30, hellaswag_acc: 0.0000
Step:   528, loss: 5.159956, norm: 0.9391, time(ms): 800.22, token/sec:655179.62, hellaswag_acc: 0.0000
Step:   529, loss: 5.141517, norm: 0.9413, time(ms): 791.07, token/sec:662758.85, hellaswag_acc: 0.0000
Step:   530, loss: 5.089842, norm: 0.8976, time(ms): 794.32, token/sec:660043.86, hellaswag_acc: 0.0000
Step:   531, loss: 5.075485, norm: 0.8160, time(ms): 794.20, token/sec:660145.71, hellaswag_acc: 0.0000
Step:   532, loss: 5.088397, norm: 0.7878, time(ms): 795.31, token/sec:659225.87, hellaswag_acc: 0.0000
Step:   533, loss: 5.065136, norm: 0.7344, time(ms): 793.93, token/sec:660374.28, hellaswag_acc: 0.0000
Step:   534, loss: 5.111274, norm: 0.8599, time(ms): 790.86, token/sec:662937.27, hellaswag_acc: 0.0000
Step:   535, loss: 5.091122, norm: 1.2593, time(ms): 788.71, token/sec:664737.44, hellaswag_acc: 0.0000
Step:   536, loss: 5.034584, norm: 0.9351, time(ms): 791.37, token/sec:662508.06, hellaswag_acc: 0.0000
Step:   537, loss: 5.065763, norm: 0.8735, time(ms): 791.12, token/sec:662717.70, hellaswag_acc: 0.0000
Step:   538, loss: 5.077654, norm: 0.8195, time(ms): 801.21, token/sec:654370.52, hellaswag_acc: 0.0000
Step:   539, loss: 5.054786, norm: 0.8460, time(ms): 804.75, token/sec:651487.74, hellaswag_acc: 0.0000
Step:   540, loss: 5.068960, norm: 0.9629, time(ms): 793.17, token/sec:661003.73, hellaswag_acc: 0.0000
Step:   541, loss: 5.143537, norm: 1.0791, time(ms): 793.44, token/sec:660780.68, hellaswag_acc: 0.0000
Step:   542, loss: 5.202980, norm: 1.2574, time(ms): 787.44, token/sec:665813.01, hellaswag_acc: 0.0000
Step:   543, loss: 5.181691, norm: 1.0050, time(ms): 791.50, token/sec:662396.70, hellaswag_acc: 0.0000
Step:   544, loss: 5.194062, norm: 1.0423, time(ms): 792.06, token/sec:661926.75, hellaswag_acc: 0.0000
Step:   545, loss: 5.159363, norm: 1.0493, time(ms): 792.98, token/sec:661165.51, hellaswag_acc: 0.0000
Step:   546, loss: 5.209105, norm: 1.1647, time(ms): 789.11, token/sec:664402.04, hellaswag_acc: 0.0000
Step:   547, loss: 5.167997, norm: 0.8253, time(ms): 795.49, token/sec:659075.52, hellaswag_acc: 0.0000
Step:   548, loss: 5.136942, norm: 0.6983, time(ms): 794.11, token/sec:660221.22, hellaswag_acc: 0.0000
Step:   549, loss: 5.153027, norm: 0.7249, time(ms): 788.80, token/sec:664666.52, hellaswag_acc: 0.0000
Step:   550, loss: 5.199970, norm: 0.6808, time(ms): 791.29, token/sec:662570.34, hellaswag_acc: 0.0000
Step:   551, loss: 5.180849, norm: 0.8289, time(ms): 789.50, token/sec:664078.21, hellaswag_acc: 0.0000
Step:   552, loss: 5.108332, norm: 0.9932, time(ms): 799.97, token/sec:655383.28, hellaswag_acc: 0.0000
Step:   553, loss: 5.013745, norm: 1.0414, time(ms): 795.18, token/sec:659328.46, hellaswag_acc: 0.0000
Step:   554, loss: 5.086169, norm: 0.9562, time(ms): 799.05, token/sec:656141.83, hellaswag_acc: 0.0000
Step:   555, loss: 5.079508, norm: 1.0189, time(ms): 805.12, token/sec:651188.71, hellaswag_acc: 0.0000
Step:   556, loss: 5.088043, norm: 0.9968, time(ms): 801.38, token/sec:654229.96, hellaswag_acc: 0.0000
Step:   557, loss: 5.077612, norm: 1.0692, time(ms): 796.57, token/sec:658181.51, hellaswag_acc: 0.0000
Step:   558, loss: 5.041776, norm: 1.0259, time(ms): 797.35, token/sec:657540.12, hellaswag_acc: 0.0000
Step:   559, loss: 5.193663, norm: 0.8631, time(ms): 800.02, token/sec:655347.15, hellaswag_acc: 0.0000
Step:   560, loss: 5.027419, norm: 0.8354, time(ms): 803.95, token/sec:652137.49, hellaswag_acc: 0.0000
Step:   561, loss: 5.063698, norm: 0.8474, time(ms): 795.29, token/sec:659244.45, hellaswag_acc: 0.0000
Step:   562, loss: 5.042438, norm: 0.7652, time(ms): 798.38, token/sec:656686.55, hellaswag_acc: 0.0000
Step:   563, loss: 5.024264, norm: 0.8528, time(ms): 807.08, token/sec:649610.73, hellaswag_acc: 0.0000
Step:   564, loss: 4.974109, norm: 0.9315, time(ms): 785.21, token/sec:667701.03, hellaswag_acc: 0.0000
Step:   565, loss: 5.025802, norm: 0.9418, time(ms): 787.09, token/sec:666110.90, hellaswag_acc: 0.0000
Step:   566, loss: 4.989614, norm: 0.9305, time(ms): 794.92, token/sec:659551.12, hellaswag_acc: 0.0000
Step:   567, loss: 4.977300, norm: 0.9202, time(ms): 791.73, token/sec:662203.42, hellaswag_acc: 0.0000
Step:   568, loss: 4.960464, norm: 1.0042, time(ms): 791.06, token/sec:662762.44, hellaswag_acc: 0.0000
Step:   569, loss: 4.976276, norm: 0.8544, time(ms): 792.58, token/sec:661496.85, hellaswag_acc: 0.0000
Step:   570, loss: 5.009778, norm: 0.7978, time(ms): 793.05, token/sec:661104.09, hellaswag_acc: 0.0000
Step:   571, loss: 5.032532, norm: 0.8573, time(ms): 1277.52, token/sec:410393.86, hellaswag_acc: 0.0000
Step:   572, loss: 5.057313, norm: 0.9167, time(ms): 793.12, token/sec:661042.08, hellaswag_acc: 0.0000
Step:   573, loss: 5.076392, norm: 0.9021, time(ms): 782.57, token/sec:669959.84, hellaswag_acc: 0.0000
Step:   574, loss: 5.025120, norm: 0.7539, time(ms): 779.10, token/sec:672938.15, hellaswag_acc: 0.0000
Step:   575, loss: 5.032050, norm: 0.8310, time(ms): 800.25, token/sec:655152.49, hellaswag_acc: 0.0000
Step:   576, loss: 5.021689, norm: 0.8434, time(ms): 791.88, token/sec:662084.19, hellaswag_acc: 0.0000
Step:   577, loss: 5.029586, norm: 0.8041, time(ms): 783.26, token/sec:669369.66, hellaswag_acc: 0.0000
Step:   578, loss: 5.016272, norm: 0.7676, time(ms): 781.55, token/sec:670830.49, hellaswag_acc: 0.0000
Step:   579, loss: 4.938413, norm: 0.8206, time(ms): 784.44, token/sec:668363.83, hellaswag_acc: 0.0000
Step:   580, loss: 4.989599, norm: 0.8749, time(ms): 790.24, token/sec:663451.30, hellaswag_acc: 0.0000
Step:   581, loss: 4.929410, norm: 0.8456, time(ms): 783.72, token/sec:668970.95, hellaswag_acc: 0.0000
Step:   582, loss: 4.962652, norm: 0.9039, time(ms): 782.28, token/sec:670205.89, hellaswag_acc: 0.0000
Step:   583, loss: 4.920978, norm: 0.8884, time(ms): 791.86, token/sec:662100.94, hellaswag_acc: 0.0000
Step:   584, loss: 4.990132, norm: 0.7923, time(ms): 793.14, token/sec:661027.18, hellaswag_acc: 0.0000
Step:   585, loss: 4.947221, norm: 0.7082, time(ms): 795.41, token/sec:659140.51, hellaswag_acc: 0.0000
Step:   586, loss: 4.912251, norm: 0.7415, time(ms): 791.96, token/sec:662015.62, hellaswag_acc: 0.0000
Step:   587, loss: 4.901815, norm: 0.7244, time(ms): 788.08, token/sec:665271.17, hellaswag_acc: 0.0000
Step:   588, loss: 4.929006, norm: 0.7407, time(ms): 788.85, token/sec:664621.12, hellaswag_acc: 0.0000
Step:   589, loss: 4.889718, norm: 0.6084, time(ms): 791.73, token/sec:662204.81, hellaswag_acc: 0.0000
Step:   590, loss: 4.898643, norm: 0.5902, time(ms): 790.29, token/sec:663409.67, hellaswag_acc: 0.0000
Step:   591, loss: 5.116605, norm: 0.5735, time(ms): 782.85, token/sec:669717.04, hellaswag_acc: 0.0000
Step:   592, loss: 5.040131, norm: 0.7220, time(ms): 789.67, token/sec:663935.05, hellaswag_acc: 0.0000
Step:   593, loss: 5.018990, norm: 1.0135, time(ms): 792.31, token/sec:661720.39, hellaswag_acc: 0.0000
Step:   594, loss: 5.069394, norm: 1.0889, time(ms): 793.44, token/sec:660774.72, hellaswag_acc: 0.0000
Step:   595, loss: 5.100708, norm: 0.9643, time(ms): 788.27, token/sec:665114.42, hellaswag_acc: 0.0000
Step:   596, loss: 5.075815, norm: 0.9869, time(ms): 791.81, token/sec:662135.42, hellaswag_acc: 0.0000
Step:   597, loss: 5.087164, norm: 0.9783, time(ms): 795.74, token/sec:658866.00, hellaswag_acc: 0.0000
Step:   598, loss: 5.135209, norm: 1.1396, time(ms): 792.70, token/sec:661397.18, hellaswag_acc: 0.0000
Step:   599, loss: 5.081397, norm: 1.0336, time(ms): 789.14, token/sec:664376.75, hellaswag_acc: 0.0000
Step:   600, loss: 5.096673, norm: 0.9056, time(ms): 791.02, token/sec:662799.40, hellaswag_acc: 0.0000
Step:   601, loss: 5.063862, norm: 0.8743, time(ms): 790.38, token/sec:663333.42, hellaswag_acc: 0.0000
Step:   602, loss: 4.982467, norm: 0.9640, time(ms): 787.10, token/sec:666103.43, hellaswag_acc: 0.0000
Step:   603, loss: 5.044466, norm: 1.1146, time(ms): 788.93, token/sec:664555.04, hellaswag_acc: 0.0000
Step:   604, loss: 5.030782, norm: 0.9159, time(ms): 791.09, token/sec:662738.28, hellaswag_acc: 0.0000
Step:   605, loss: 5.018913, norm: 0.9306, time(ms): 791.53, token/sec:662372.36, hellaswag_acc: 0.0000
Step:   606, loss: 4.989869, norm: 1.0132, time(ms): 790.48, token/sec:663250.59, hellaswag_acc: 0.0000
Step:   607, loss: 5.028273, norm: 0.9187, time(ms): 790.23, token/sec:663461.31, hellaswag_acc: 0.0000
Step:   608, loss: 5.001030, norm: 0.7205, time(ms): 794.72, token/sec:659713.18, hellaswag_acc: 0.0000
Step:   609, loss: 4.949321, norm: 0.7898, time(ms): 792.99, token/sec:661151.99, hellaswag_acc: 0.0000
Step:   610, loss: 4.947684, norm: 0.7126, time(ms): 787.23, token/sec:665989.05, hellaswag_acc: 0.0000
Step:   611, loss: 4.911635, norm: 0.7077, time(ms): 788.29, token/sec:665094.11, hellaswag_acc: 0.0000
Step:   612, loss: 4.921823, norm: 0.6272, time(ms): 790.14, token/sec:663536.58, hellaswag_acc: 0.0000
Step:   613, loss: 4.923575, norm: 0.6306, time(ms): 795.07, token/sec:659421.58, hellaswag_acc: 0.0000
Step:   614, loss: 4.869614, norm: 0.8333, time(ms): 804.61, token/sec:651605.31, hellaswag_acc: 0.0000
Step:   615, loss: 4.900391, norm: 0.9077, time(ms): 800.73, token/sec:654761.56, hellaswag_acc: 0.0000
Step:   616, loss: 4.871768, norm: 0.7811, time(ms): 795.65, token/sec:658939.25, hellaswag_acc: 0.0000
Step:   617, loss: 4.867615, norm: 0.8248, time(ms): 799.97, token/sec:655386.80, hellaswag_acc: 0.0000
Step:   618, loss: 4.838792, norm: 0.8766, time(ms): 806.46, token/sec:650106.78, hellaswag_acc: 0.0000
Step:   619, loss: 4.854291, norm: 0.8243, time(ms): 795.89, token/sec:658744.02, hellaswag_acc: 0.0000
Step:   620, loss: 4.876153, norm: 0.8803, time(ms): 793.67, token/sec:660588.14, hellaswag_acc: 0.0000
Step:   621, loss: 4.793310, norm: 0.8182, time(ms): 788.85, token/sec:664623.73, hellaswag_acc: 0.0000
Step:   622, loss: 4.832611, norm: 0.7710, time(ms): 788.20, token/sec:665172.37, hellaswag_acc: 0.0000
Step:   623, loss: 4.845487, norm: 0.7061, time(ms): 791.54, token/sec:662366.38, hellaswag_acc: 0.0000
Step:   624, loss: 4.804501, norm: 0.7044, time(ms): 797.08, token/sec:657760.01, hellaswag_acc: 0.0000
Step:   625, loss: 4.865719, norm: 0.6954, time(ms): 800.09, token/sec:655290.12, hellaswag_acc: 0.0000
Step:   626, loss: 4.914548, norm: 0.6290, time(ms): 800.23, token/sec:655174.74, hellaswag_acc: 0.0000
Step:   627, loss: 4.932844, norm: 0.6153, time(ms): 795.70, token/sec:658901.73, hellaswag_acc: 0.0000
Step:   628, loss: 4.957373, norm: 0.7792, time(ms): 798.10, token/sec:656916.85, hellaswag_acc: 0.0000
Step:   629, loss: 4.959206, norm: 1.0079, time(ms): 792.77, token/sec:661334.32, hellaswag_acc: 0.0000
Step:   630, loss: 4.970020, norm: 0.9899, time(ms): 790.15, token/sec:663528.37, hellaswag_acc: 0.0000
Step:   631, loss: 4.952419, norm: 1.1342, time(ms): 794.92, token/sec:659546.18, hellaswag_acc: 0.0000
Step:   632, loss: 4.945081, norm: 0.7759, time(ms): 788.79, token/sec:664673.35, hellaswag_acc: 0.0000
Step:   633, loss: 4.955823, norm: 0.8094, time(ms): 789.45, token/sec:664118.12, hellaswag_acc: 0.0000
Step:   634, loss: 4.907546, norm: 0.9165, time(ms): 791.39, token/sec:662490.10, hellaswag_acc: 0.0000
Step:   635, loss: 5.019343, norm: 0.8424, time(ms): 790.04, token/sec:663622.48, hellaswag_acc: 0.0000
Step:   636, loss: 4.922661, norm: 0.7185, time(ms): 789.66, token/sec:663938.66, hellaswag_acc: 0.0000
Step:   637, loss: 4.875446, norm: 0.7742, time(ms): 787.44, token/sec:665817.25, hellaswag_acc: 0.0000
Step:   638, loss: 4.935949, norm: 0.7380, time(ms): 785.51, token/sec:667450.54, hellaswag_acc: 0.0000
Step:   639, loss: 4.871375, norm: 0.7774, time(ms): 797.27, token/sec:657606.97, hellaswag_acc: 0.0000
Step:   640, loss: 4.866382, norm: 0.7168, time(ms): 791.35, token/sec:662524.03, hellaswag_acc: 0.0000
Step:   641, loss: 4.850822, norm: 0.6516, time(ms): 790.13, token/sec:663545.39, hellaswag_acc: 0.0000
Step:   642, loss: 4.852264, norm: 0.6410, time(ms): 788.97, token/sec:664521.70, hellaswag_acc: 0.0000
Step:   643, loss: 4.845244, norm: 0.7255, time(ms): 790.31, token/sec:663394.86, hellaswag_acc: 0.0000
Step:   644, loss: 4.867057, norm: 0.7351, time(ms): 792.45, token/sec:661601.54, hellaswag_acc: 0.0000
Step:   645, loss: 4.799793, norm: 0.7184, time(ms): 790.50, token/sec:663238.59, hellaswag_acc: 0.0000
Step:   646, loss: 4.881491, norm: 0.6049, time(ms): 801.58, token/sec:654068.84, hellaswag_acc: 0.0000
Step:   647, loss: 4.806274, norm: 0.6689, time(ms): 801.53, token/sec:654110.08, hellaswag_acc: 0.0000
Step:   648, loss: 4.826821, norm: 0.7347, time(ms): 793.76, token/sec:660509.36, hellaswag_acc: 0.0000
Step:   649, loss: 4.774487, norm: 0.7802, time(ms): 791.31, token/sec:662553.77, hellaswag_acc: 0.0000
Step:   650, loss: 4.818157, norm: 0.7731, time(ms): 785.47, token/sec:667482.55, hellaswag_acc: 0.0000
Step:   651, loss: 4.770996, norm: 0.6296, time(ms): 793.08, token/sec:661080.24, hellaswag_acc: 0.0000
Step:   652, loss: 4.730880, norm: 0.5758, time(ms): 791.38, token/sec:662498.48, hellaswag_acc: 0.0000
Step:   653, loss: 4.819379, norm: 0.6480, time(ms): 802.89, token/sec:653005.06, hellaswag_acc: 0.0000
Step:   654, loss: 4.770742, norm: 0.7754, time(ms): 798.31, token/sec:656748.72, hellaswag_acc: 0.0000
Step:   655, loss: 4.762027, norm: 0.9675, time(ms): 791.30, token/sec:662564.15, hellaswag_acc: 0.0000
Step:   656, loss: 4.749513, norm: 0.8075, time(ms): 788.28, token/sec:665103.56, hellaswag_acc: 0.0000
Step:   657, loss: 4.804700, norm: 0.8217, time(ms): 801.81, token/sec:653878.24, hellaswag_acc: 0.0000
Step:   658, loss: 4.768952, norm: 1.0467, time(ms): 795.45, token/sec:659104.75, hellaswag_acc: 0.0000
Step:   659, loss: 4.756198, norm: 0.9909, time(ms): 792.72, token/sec:661376.49, hellaswag_acc: 0.0000
Step:   660, loss: 4.900565, norm: 0.9352, time(ms): 781.29, token/sec:671055.67, hellaswag_acc: 0.0000
Step:   661, loss: 4.902927, norm: 1.0011, time(ms): 790.69, token/sec:663078.00, hellaswag_acc: 0.0000
Step:   662, loss: 4.956070, norm: 0.9811, time(ms): 794.85, token/sec:659607.51, hellaswag_acc: 0.0000
Step:   663, loss: 4.872200, norm: 0.9213, time(ms): 802.25, token/sec:653524.37, hellaswag_acc: 0.0000
Step:   664, loss: 4.860353, norm: 0.9872, time(ms): 798.20, token/sec:656834.64, hellaswag_acc: 0.0000
Step:   665, loss: 4.881235, norm: 0.9913, time(ms): 806.49, token/sec:650086.61, hellaswag_acc: 0.0000
Step:   666, loss: 4.916967, norm: 0.9405, time(ms): 794.86, token/sec:659597.22, hellaswag_acc: 0.0000
Step:   667, loss: 4.914648, norm: 0.8627, time(ms): 795.02, token/sec:659465.88, hellaswag_acc: 0.0000
Step:   668, loss: 4.842526, norm: 0.7963, time(ms): 790.16, token/sec:663518.96, hellaswag_acc: 0.0000
Step:   669, loss: 4.899801, norm: 0.8975, time(ms): 788.31, token/sec:665078.42, hellaswag_acc: 0.0000
Step:   670, loss: 4.911613, norm: 0.8105, time(ms): 791.40, token/sec:662478.52, hellaswag_acc: 0.0000
Step:   671, loss: 4.877703, norm: 0.6831, time(ms): 792.36, token/sec:661682.16, hellaswag_acc: 0.0000
Step:   672, loss: 4.786362, norm: 0.6542, time(ms): 801.79, token/sec:653893.80, hellaswag_acc: 0.0000
Step:   673, loss: 4.781333, norm: 0.7359, time(ms): 796.31, token/sec:658392.96, hellaswag_acc: 0.0000
Step:   674, loss: 4.793586, norm: 0.7687, time(ms): 792.57, token/sec:661504.02, hellaswag_acc: 0.0000
Step:   675, loss: 4.772103, norm: 0.6664, time(ms): 785.43, token/sec:667519.63, hellaswag_acc: 0.0000
Step:   676, loss: 4.751306, norm: 0.6075, time(ms): 788.83, token/sec:664639.60, hellaswag_acc: 0.0000
Step:   677, loss: 4.763762, norm: 0.6219, time(ms): 794.79, token/sec:659656.78, hellaswag_acc: 0.0000
Step:   678, loss: 4.810277, norm: 0.6093, time(ms): 790.90, token/sec:662902.10, hellaswag_acc: 0.0000
Step:   679, loss: 4.784801, norm: 0.6228, time(ms): 782.74, token/sec:669815.16, hellaswag_acc: 0.0000
Step:   680, loss: 4.754203, norm: 0.7420, time(ms): 790.57, token/sec:663180.38, hellaswag_acc: 0.0000
Step:   681, loss: 4.770655, norm: 0.7621, time(ms): 790.50, token/sec:663236.19, hellaswag_acc: 0.0000
Step:   682, loss: 4.780450, norm: 0.7409, time(ms): 791.38, token/sec:662496.48, hellaswag_acc: 0.0000
Step:   683, loss: 4.608788, norm: 0.6901, time(ms): 789.32, token/sec:664231.26, hellaswag_acc: 0.0000
Step:   684, loss: 4.690653, norm: 0.6289, time(ms): 791.03, token/sec:662789.21, hellaswag_acc: 0.0000
Step:   685, loss: 4.653559, norm: 0.6373, time(ms): 794.73, token/sec:659701.90, hellaswag_acc: 0.0000
Step:   686, loss: 4.639327, norm: 0.6954, time(ms): 791.31, token/sec:662553.97, hellaswag_acc: 0.0000
Step:   687, loss: 4.653700, norm: 0.6712, time(ms): 788.89, token/sec:664588.18, hellaswag_acc: 0.0000
Step:   688, loss: 4.658635, norm: 0.7730, time(ms): 793.06, token/sec:661097.93, hellaswag_acc: 0.0000
Step:   689, loss: 4.642778, norm: 0.7238, time(ms): 788.17, token/sec:665199.13, hellaswag_acc: 0.0000
Step:   690, loss: 4.651672, norm: 0.8305, time(ms): 799.10, token/sec:656097.78, hellaswag_acc: 0.0000
Step:   691, loss: 4.628757, norm: 1.1324, time(ms): 799.62, token/sec:655667.61, hellaswag_acc: 0.0000
Step:   692, loss: 4.688756, norm: 1.0211, time(ms): 796.24, token/sec:658450.92, hellaswag_acc: 0.0000
Step:   693, loss: 4.665761, norm: 0.8107, time(ms): 806.97, token/sec:649696.33, hellaswag_acc: 0.0000
Step:   694, loss: 4.774272, norm: 0.7366, time(ms): 794.05, token/sec:660273.16, hellaswag_acc: 0.0000
Step:   695, loss: 4.815320, norm: 0.5910, time(ms): 804.08, token/sec:652031.33, hellaswag_acc: 0.0000
Step:   696, loss: 4.744049, norm: 0.6571, time(ms): 797.69, token/sec:657256.13, hellaswag_acc: 0.0000
Step:   697, loss: 4.795971, norm: 0.7385, time(ms): 795.21, token/sec:659304.34, hellaswag_acc: 0.0000
Step:   698, loss: 4.709730, norm: 0.8535, time(ms): 799.59, token/sec:655696.74, hellaswag_acc: 0.0000
Step:   699, loss: 4.716990, norm: 0.7184, time(ms): 806.49, token/sec:650088.33, hellaswag_acc: 0.0000
Step:   700, loss: 4.759750, norm: 0.6937, time(ms): 798.08, token/sec:656934.12, hellaswag_acc: 0.0000
Step:   701, loss: 4.767493, norm: 0.9106, time(ms): 795.62, token/sec:658967.29, hellaswag_acc: 0.0000
Step:   702, loss: 4.792090, norm: 1.0716, time(ms): 802.02, token/sec:653710.10, hellaswag_acc: 0.0000
Step:   703, loss: 4.784116, norm: 0.8307, time(ms): 804.05, token/sec:652056.46, hellaswag_acc: 0.0000
Step:   704, loss: 4.793368, norm: 0.8306, time(ms): 798.10, token/sec:656917.25, hellaswag_acc: 0.0000
Step:   705, loss: 4.732203, norm: 0.9226, time(ms): 795.09, token/sec:659407.34, hellaswag_acc: 0.0000
Step:   706, loss: 4.781860, norm: 0.9159, time(ms): 805.68, token/sec:650741.07, hellaswag_acc: 0.0000
Step:   707, loss: 4.734325, norm: 0.7652, time(ms): 800.18, token/sec:655215.54, hellaswag_acc: 0.0000
Step:   708, loss: 4.702569, norm: 0.8106, time(ms): 800.02, token/sec:655341.48, hellaswag_acc: 0.0000
Step:   709, loss: 4.709584, norm: 0.7593, time(ms): 791.64, token/sec:662277.41, hellaswag_acc: 0.0000
Step:   710, loss: 4.693707, norm: 0.7423, time(ms): 804.03, token/sec:652074.83, hellaswag_acc: 0.0000
Step:   711, loss: 4.649555, norm: 0.6457, time(ms): 805.72, token/sec:650703.71, hellaswag_acc: 0.0000
Step:   712, loss: 4.647905, norm: 0.5368, time(ms): 784.41, token/sec:668382.51, hellaswag_acc: 0.0000
Step:   713, loss: 4.626045, norm: 0.5179, time(ms): 783.72, token/sec:668970.75, hellaswag_acc: 0.0000
Step:   714, loss: 4.684124, norm: 0.4916, time(ms): 790.24, token/sec:663454.50, hellaswag_acc: 0.0000
Step:   715, loss: 4.605050, norm: 0.5995, time(ms): 798.15, token/sec:656880.55, hellaswag_acc: 0.0000
Step:   716, loss: 4.640570, norm: 0.6600, time(ms): 787.65, token/sec:665638.88, hellaswag_acc: 0.0000
Step:   717, loss: 4.617224, norm: 0.6826, time(ms): 791.50, token/sec:662400.70, hellaswag_acc: 0.0000
Step:   718, loss: 4.591576, norm: 0.6180, time(ms): 797.83, token/sec:657144.57, hellaswag_acc: 0.0000
Step:   719, loss: 4.553312, norm: 0.6637, time(ms): 793.39, token/sec:660821.19, hellaswag_acc: 0.0000
Step:   720, loss: 4.582145, norm: 0.7020, time(ms): 786.57, token/sec:666546.01, hellaswag_acc: 0.0000
Step:   721, loss: 4.616090, norm: 0.6808, time(ms): 790.25, token/sec:663449.09, hellaswag_acc: 0.0000
Step:   722, loss: 4.537342, norm: 0.6955, time(ms): 790.74, token/sec:663036.61, hellaswag_acc: 0.0000
Step:   723, loss: 4.560861, norm: 0.7455, time(ms): 796.86, token/sec:657942.83, hellaswag_acc: 0.0000
Step:   724, loss: 4.546725, norm: 0.7372, time(ms): 803.48, token/sec:652522.38, hellaswag_acc: 0.0000
Step:   725, loss: 4.545107, norm: 0.7769, time(ms): 797.57, token/sec:657354.37, hellaswag_acc: 0.0000
Step:   726, loss: 4.607279, norm: 0.8008, time(ms): 797.89, token/sec:657096.86, hellaswag_acc: 0.0000
Step:   727, loss: 4.541852, norm: 0.8748, time(ms): 800.88, token/sec:654638.37, hellaswag_acc: 0.0000
Step:   728, loss: 4.652069, norm: 0.9340, time(ms): 804.56, token/sec:651647.59, hellaswag_acc: 0.0000
Step:   729, loss: 4.727332, norm: 0.8189, time(ms): 792.31, token/sec:661717.01, hellaswag_acc: 0.0000
Step:   730, loss: 4.736640, norm: 0.7595, time(ms): 799.09, token/sec:656109.14, hellaswag_acc: 0.0000
Step:   731, loss: 4.619105, norm: 0.8271, time(ms): 797.81, token/sec:657161.46, hellaswag_acc: 0.0000
Step:   732, loss: 4.662663, norm: 0.6533, time(ms): 791.46, token/sec:662434.02, hellaswag_acc: 0.0000
Step:   733, loss: 4.675969, norm: 0.6455, time(ms): 785.28, token/sec:667646.70, hellaswag_acc: 0.0000
Step:   734, loss: 4.656846, norm: 0.5498, time(ms): 790.74, token/sec:663036.61, hellaswag_acc: 0.0000
Step:   735, loss: 4.603011, norm: 0.5652, time(ms): 792.94, token/sec:661195.33, hellaswag_acc: 0.0000
Step:   736, loss: 4.648449, norm: 0.6000, time(ms): 790.95, token/sec:662855.74, hellaswag_acc: 0.0000
Step:   737, loss: 4.601562, norm: 0.6458, time(ms): 786.46, token/sec:666638.75, hellaswag_acc: 0.0000
Step:   738, loss: 4.661332, norm: 0.7767, time(ms): 783.75, token/sec:668950.60, hellaswag_acc: 0.0000
Step:   739, loss: 4.658161, norm: 0.9000, time(ms): 791.43, token/sec:662456.97, hellaswag_acc: 0.0000
Step:   740, loss: 4.599552, norm: 0.8569, time(ms): 786.75, token/sec:666397.14, hellaswag_acc: 0.0000
Step:   741, loss: 4.569728, norm: 0.7556, time(ms): 796.13, token/sec:658543.99, hellaswag_acc: 0.0000
Step:   742, loss: 4.598388, norm: 0.7762, time(ms): 788.40, token/sec:665005.21, hellaswag_acc: 0.0000
Step:   743, loss: 4.556830, norm: 0.5966, time(ms): 789.40, token/sec:664163.25, hellaswag_acc: 0.0000
Step:   744, loss: 4.519381, norm: 0.6000, time(ms): 791.34, token/sec:662534.81, hellaswag_acc: 0.0000
Step:   745, loss: 4.552160, norm: 0.7267, time(ms): 793.24, token/sec:660948.90, hellaswag_acc: 0.0000
Step:   746, loss: 4.605552, norm: 0.7764, time(ms): 788.99, token/sec:664506.64, hellaswag_acc: 0.0000
Step:   747, loss: 4.612418, norm: 0.7942, time(ms): 791.82, token/sec:662130.04, hellaswag_acc: 0.0000
Step:   748, loss: 4.569785, norm: 0.8140, time(ms): 789.84, token/sec:663789.95, hellaswag_acc: 0.0000
Step:   749, loss: 4.581650, norm: 0.7611, time(ms): 786.10, token/sec:666949.51, hellaswag_acc: 0.0000
rank 0 sample 0: Hello, I'm a language model, and I'll work on me in, too. I'll work through music as I have myself I've never seen my
rank 0 sample 1: Hello, I'm a language model, if something the language gets a different style, the teacher feels a good reason and the language, the English language is the
rank 0 sample 2: Hello, I'm a language model, I'm more like anything of it. I use it to say something. I use it to do it, I recommend
rank 0 sample 3: Hello, I'm a language model, that a language has a language, in fact, in fact, this can mean how you understand. What is it and
rank 1 sample 0: Hello, I'm a language model, how the key is to be written properly in an academic paper so that the difference between questions in this paper can be used
rank 1 sample 1: Hello, I'm a language model, it is not completely understood. But in his words, to them, I do want us to focus more on the language
rank 1 sample 2: Hello, I'm a language model, but your computer needs to be a problem.
We can think about what’s happening and what we think.
rank 1 sample 3: Hello, I'm a language model, and I'm still know when I get confused. I did something pretty I feel that’s about. I am
Step:   750, loss: 4.513196, norm: 0.6503, time(ms): 3779.63, token/sec:138714.02, val_loss: 4.5935, hellaswag_acc: 0.0000
Step:   751, loss: 4.531017, norm: 0.5708, time(ms): 784.48, token/sec:668322.79, hellaswag_acc: 0.0000
Step:   752, loss: 4.473418, norm: 0.5556, time(ms): 790.78, token/sec:663001.03, hellaswag_acc: 0.0000
Step:   753, loss: 4.462748, norm: 0.5882, time(ms): 795.04, token/sec:659447.88, hellaswag_acc: 0.0000
Step:   754, loss: 4.469438, norm: 0.6315, time(ms): 794.43, token/sec:659958.68, hellaswag_acc: 0.0000
Step:   755, loss: 4.446018, norm: 0.5588, time(ms): 797.24, token/sec:657632.34, hellaswag_acc: 0.0000
Step:   756, loss: 4.477497, norm: 0.5352, time(ms): 792.88, token/sec:661245.03, hellaswag_acc: 0.0000
Step:   757, loss: 4.475320, norm: 0.6908, time(ms): 784.48, token/sec:668322.18, hellaswag_acc: 0.0000
Step:   758, loss: 4.486651, norm: 1.0524, time(ms): 784.40, token/sec:668389.83, hellaswag_acc: 0.0000
Step:   759, loss: 4.449891, norm: 0.9764, time(ms): 791.22, token/sec:662636.23, hellaswag_acc: 0.0000
Step:   760, loss: 4.507249, norm: 0.9047, time(ms): 791.60, token/sec:662315.11, hellaswag_acc: 0.0000
Step:   761, loss: 4.456599, norm: 0.9019, time(ms): 1252.90, token/sec:418461.20, hellaswag_acc: 0.0000
Step:   762, loss: 4.567441, norm: 0.8396, time(ms): 760.23, token/sec:689643.22, hellaswag_acc: 0.0000
Step:   763, loss: 4.451589, norm: 0.7594, time(ms): 787.32, token/sec:665912.62, hellaswag_acc: 0.0000
Step:   764, loss: 4.509154, norm: 0.5681, time(ms): 802.65, token/sec:653197.47, hellaswag_acc: 0.0000
Step:   765, loss: 4.498216, norm: 0.5170, time(ms): 787.65, token/sec:665638.28, hellaswag_acc: 0.0000
Step:   766, loss: 4.463894, norm: 0.4847, time(ms): 780.57, token/sec:671673.85, hellaswag_acc: 0.0000
Step:   767, loss: 4.465925, norm: 0.4967, time(ms): 790.88, token/sec:662913.29, hellaswag_acc: 0.0000
Step:   768, loss: 4.474465, norm: 0.4701, time(ms): 796.60, token/sec:658153.54, hellaswag_acc: 0.0000
Step:   769, loss: 4.488345, norm: 0.4608, time(ms): 802.19, token/sec:653572.35, hellaswag_acc: 0.0000
Step:   770, loss: 4.421844, norm: 0.4797, time(ms): 792.33, token/sec:661703.67, hellaswag_acc: 0.0000
Step:   771, loss: 4.535948, norm: 0.6791, time(ms): 793.75, token/sec:660517.89, hellaswag_acc: 0.0000
Step:   772, loss: 4.501146, norm: 0.9173, time(ms): 790.85, token/sec:662944.47, hellaswag_acc: 0.0000
Step:   773, loss: 4.440221, norm: 0.8466, time(ms): 793.53, token/sec:660705.04, hellaswag_acc: 0.0000
Step:   774, loss: 4.440347, norm: 0.7468, time(ms): 790.83, token/sec:662959.86, hellaswag_acc: 0.0000
Step:   775, loss: 4.400461, norm: 0.6463, time(ms): 787.30, token/sec:665932.18, hellaswag_acc: 0.0000
Step:   776, loss: 4.395221, norm: 0.5804, time(ms): 785.81, token/sec:667195.38, hellaswag_acc: 0.0000
Step:   777, loss: 4.430226, norm: 0.5975, time(ms): 804.37, token/sec:651796.51, hellaswag_acc: 0.0000
Step:   778, loss: 4.450642, norm: 0.5895, time(ms): 800.76, token/sec:654737.19, hellaswag_acc: 0.0000
Step:   779, loss: 4.342444, norm: 0.5349, time(ms): 796.90, token/sec:657909.17, hellaswag_acc: 0.0000
Step:   780, loss: 4.363721, norm: 0.4607, time(ms): 797.65, token/sec:657291.30, hellaswag_acc: 0.0000
Step:   781, loss: 4.355255, norm: 0.4599, time(ms): 804.47, token/sec:651719.82, hellaswag_acc: 0.0000
Step:   782, loss: 4.415499, norm: 0.4563, time(ms): 801.26, token/sec:654326.52, hellaswag_acc: 0.0000
Step:   783, loss: 4.371119, norm: 0.5528, time(ms): 795.11, token/sec:659393.90, hellaswag_acc: 0.0000
Step:   784, loss: 4.352820, norm: 0.6636, time(ms): 799.28, token/sec:655946.31, hellaswag_acc: 0.0000
Step:   785, loss: 4.480343, norm: 0.8083, time(ms): 800.94, token/sec:654588.10, hellaswag_acc: 0.0000
Step:   786, loss: 4.465341, norm: 0.8145, time(ms): 803.06, token/sec:652865.66, hellaswag_acc: 0.0000
Step:   787, loss: 4.481458, norm: 0.7193, time(ms): 799.83, token/sec:655501.87, hellaswag_acc: 0.0000
Step:   788, loss: 4.525098, norm: 0.6170, time(ms): 789.83, token/sec:663800.57, hellaswag_acc: 0.0000
Step:   789, loss: 4.463123, norm: 0.5471, time(ms): 788.84, token/sec:664630.76, hellaswag_acc: 0.0000
Step:   790, loss: 4.475391, norm: 0.5369, time(ms): 789.89, token/sec:663748.88, hellaswag_acc: 0.0000
Step:   791, loss: 4.502674, norm: 0.5811, time(ms): 792.54, token/sec:661527.50, hellaswag_acc: 0.0000
Step:   792, loss: 4.555975, norm: 0.5800, time(ms): 795.69, token/sec:658913.58, hellaswag_acc: 0.0000
Step:   793, loss: 4.498154, norm: 0.7099, time(ms): 797.07, token/sec:657766.70, hellaswag_acc: 0.0000
Step:   794, loss: 4.505314, norm: 0.8219, time(ms): 801.43, token/sec:654191.62, hellaswag_acc: 0.0000
Step:   795, loss: 4.551888, norm: 0.9333, time(ms): 795.76, token/sec:658849.22, hellaswag_acc: 0.0000
Step:   796, loss: 4.508124, norm: 0.8125, time(ms): 793.73, token/sec:660537.73, hellaswag_acc: 0.0000
Step:   797, loss: 4.428048, norm: 0.7476, time(ms): 789.30, token/sec:664246.30, hellaswag_acc: 0.0000
Step:   798, loss: 4.402489, norm: 0.9055, time(ms): 793.85, token/sec:660435.37, hellaswag_acc: 0.0000
Step:   799, loss: 4.414772, norm: 0.8470, time(ms): 791.16, token/sec:662683.55, hellaswag_acc: 0.0000
Step:   800, loss: 4.428347, norm: 0.7106, time(ms): 791.57, token/sec:662339.84, hellaswag_acc: 0.0000
Step:   801, loss: 4.404567, norm: 0.5677, time(ms): 791.42, token/sec:662460.76, hellaswag_acc: 0.0000
Step:   802, loss: 4.398981, norm: 0.4723, time(ms): 790.56, token/sec:663184.18, hellaswag_acc: 0.0000
Step:   803, loss: 4.438751, norm: 0.4895, time(ms): 803.84, token/sec:652229.75, hellaswag_acc: 0.0000
Step:   804, loss: 4.418029, norm: 0.4981, time(ms): 801.47, token/sec:654155.81, hellaswag_acc: 0.0000
Step:   805, loss: 4.393303, norm: 0.5146, time(ms): 790.82, token/sec:662968.25, hellaswag_acc: 0.0000
Step:   806, loss: 4.413261, norm: 0.5550, time(ms): 801.04, token/sec:654509.78, hellaswag_acc: 0.0000
Step:   807, loss: 4.429395, norm: 0.5609, time(ms): 805.66, token/sec:650755.32, hellaswag_acc: 0.0000
Step:   808, loss: 4.319697, norm: 0.5545, time(ms): 798.86, token/sec:656295.94, hellaswag_acc: 0.0000
Step:   809, loss: 4.325740, norm: 0.6089, time(ms): 796.65, token/sec:658114.14, hellaswag_acc: 0.0000
Step:   810, loss: 4.313401, norm: 0.5772, time(ms): 804.98, token/sec:651308.68, hellaswag_acc: 0.0000
Step:   811, loss: 4.367679, norm: 0.5169, time(ms): 801.03, token/sec:654517.18, hellaswag_acc: 0.0000
Step:   812, loss: 4.386068, norm: 0.5460, time(ms): 793.85, token/sec:660438.54, hellaswag_acc: 0.0000
Step:   813, loss: 4.320508, norm: 0.6084, time(ms): 798.22, token/sec:656818.55, hellaswag_acc: 0.0000
Step:   814, loss: 4.322027, norm: 0.6359, time(ms): 806.10, token/sec:650401.94, hellaswag_acc: 0.0000
Step:   815, loss: 4.330288, norm: 0.6135, time(ms): 787.93, token/sec:665401.21, hellaswag_acc: 0.0000
Step:   816, loss: 4.315313, norm: 0.6344, time(ms): 786.03, token/sec:667007.98, hellaswag_acc: 0.0000
Step:   817, loss: 4.339096, norm: 0.5694, time(ms): 794.74, token/sec:659694.57, hellaswag_acc: 0.0000
Step:   818, loss: 4.299345, norm: 0.5165, time(ms): 792.84, token/sec:661278.44, hellaswag_acc: 0.0000
Step:   819, loss: 4.360924, norm: 0.5318, time(ms): 794.38, token/sec:659995.33, hellaswag_acc: 0.0000
Step:   820, loss: 4.420538, norm: 0.6115, time(ms): 798.33, token/sec:656732.83, hellaswag_acc: 0.0000
Step:   821, loss: 4.406678, norm: 0.7907, time(ms): 803.07, token/sec:652853.26, hellaswag_acc: 0.0000
Step:   822, loss: 4.386961, norm: 0.8093, time(ms): 799.16, token/sec:656048.85, hellaswag_acc: 0.0000
Step:   823, loss: 4.528243, norm: 0.7322, time(ms): 800.76, token/sec:654738.17, hellaswag_acc: 0.0000
Step:   824, loss: 4.402202, norm: 0.8678, time(ms): 797.34, token/sec:657550.34, hellaswag_acc: 0.0000
Step:   825, loss: 4.462815, norm: 0.8420, time(ms): 802.65, token/sec:653194.76, hellaswag_acc: 0.0000
Step:   826, loss: 4.444851, norm: 0.7034, time(ms): 797.54, token/sec:657378.54, hellaswag_acc: 0.0000
Step:   827, loss: 4.388733, norm: 0.5507, time(ms): 795.63, token/sec:658959.39, hellaswag_acc: 0.0000
Step:   828, loss: 4.416741, norm: 0.4969, time(ms): 791.64, token/sec:662282.99, hellaswag_acc: 0.0000
Step:   829, loss: 4.371636, norm: 0.5100, time(ms): 792.35, token/sec:661686.54, hellaswag_acc: 0.0000
Step:   830, loss: 4.483184, norm: 0.4821, time(ms): 794.69, token/sec:659738.31, hellaswag_acc: 0.0000
Step:   831, loss: 4.391145, norm: 0.5421, time(ms): 789.35, token/sec:664200.16, hellaswag_acc: 0.0000
Step:   832, loss: 4.374221, norm: 0.6157, time(ms): 787.95, token/sec:665384.70, hellaswag_acc: 0.0000
Step:   833, loss: 4.390008, norm: 0.6863, time(ms): 790.36, token/sec:663356.83, hellaswag_acc: 0.0000
Step:   834, loss: 4.341525, norm: 0.6173, time(ms): 794.17, token/sec:660169.29, hellaswag_acc: 0.0000
Step:   835, loss: 4.336468, norm: 0.5986, time(ms): 806.30, token/sec:650238.66, hellaswag_acc: 0.0000
Step:   836, loss: 4.331526, norm: 0.6518, time(ms): 801.20, token/sec:654379.28, hellaswag_acc: 0.0000
Step:   837, loss: 4.378112, norm: 0.5339, time(ms): 793.21, token/sec:660968.77, hellaswag_acc: 0.0000
Step:   838, loss: 4.361626, norm: 0.5049, time(ms): 799.27, token/sec:655962.35, hellaswag_acc: 0.0000
Step:   839, loss: 4.284989, norm: 0.5246, time(ms): 805.88, token/sec:650581.85, hellaswag_acc: 0.0000
Step:   840, loss: 4.331560, norm: 0.5670, time(ms): 796.20, token/sec:658486.60, hellaswag_acc: 0.0000
Step:   841, loss: 4.338559, norm: 0.6392, time(ms): 796.37, token/sec:658344.86, hellaswag_acc: 0.0000
Step:   842, loss: 4.330890, norm: 0.6678, time(ms): 803.30, token/sec:652666.47, hellaswag_acc: 0.0000
Step:   843, loss: 4.297349, norm: 0.6524, time(ms): 802.47, token/sec:653342.25, hellaswag_acc: 0.0000
Step:   844, loss: 4.289005, norm: 0.4744, time(ms): 791.13, token/sec:662708.72, hellaswag_acc: 0.0000
Step:   845, loss: 4.234341, norm: 0.4550, time(ms): 790.18, token/sec:663508.55, hellaswag_acc: 0.0000
Step:   846, loss: 4.245755, norm: 0.4704, time(ms): 789.31, token/sec:664239.08, hellaswag_acc: 0.0000
Step:   847, loss: 4.251796, norm: 0.4511, time(ms): 790.95, token/sec:662859.14, hellaswag_acc: 0.0000
Step:   848, loss: 4.232407, norm: 0.4551, time(ms): 789.77, token/sec:663851.07, hellaswag_acc: 0.0000
Step:   849, loss: 4.239223, norm: 0.4790, time(ms): 794.45, token/sec:659934.52, hellaswag_acc: 0.0000
Step:   850, loss: 4.296437, norm: 0.5250, time(ms): 793.95, token/sec:660351.08, hellaswag_acc: 0.0000
Step:   851, loss: 4.269808, norm: 0.6238, time(ms): 793.19, token/sec:660984.26, hellaswag_acc: 0.0000
Step:   852, loss: 4.293366, norm: 0.6958, time(ms): 792.21, token/sec:661801.05, hellaswag_acc: 0.0000
Step:   853, loss: 4.267980, norm: 0.6672, time(ms): 787.23, token/sec:665987.84, hellaswag_acc: 0.0000
Step:   854, loss: 4.255755, norm: 0.5904, time(ms): 791.72, token/sec:662211.19, hellaswag_acc: 0.0000
Step:   855, loss: 4.296568, norm: 0.6424, time(ms): 790.67, token/sec:663091.80, hellaswag_acc: 0.0000
Step:   856, loss: 4.374494, norm: 0.6679, time(ms): 802.50, token/sec:653315.65, hellaswag_acc: 0.0000
Step:   857, loss: 4.372493, norm: 0.6554, time(ms): 802.94, token/sec:652957.36, hellaswag_acc: 0.0000
Step:   858, loss: 4.289403, norm: 0.6131, time(ms): 798.67, token/sec:656453.46, hellaswag_acc: 0.0000
Step:   859, loss: 4.385636, norm: 0.6534, time(ms): 792.00, token/sec:661979.55, hellaswag_acc: 0.0000
Step:   860, loss: 4.319145, norm: 0.5878, time(ms): 802.47, token/sec:653341.86, hellaswag_acc: 0.0000
Step:   861, loss: 4.307308, norm: 0.5282, time(ms): 804.23, token/sec:651911.10, hellaswag_acc: 0.0000
Step:   862, loss: 4.389313, norm: 0.5510, time(ms): 793.17, token/sec:661006.91, hellaswag_acc: 0.0000
Step:   863, loss: 4.325038, norm: 0.5596, time(ms): 803.72, token/sec:652325.52, hellaswag_acc: 0.0000
Step:   864, loss: 4.311672, norm: 0.4796, time(ms): 802.78, token/sec:653088.64, hellaswag_acc: 0.0000
Step:   865, loss: 4.337430, norm: 0.5243, time(ms): 802.46, token/sec:653352.15, hellaswag_acc: 0.0000
Step:   866, loss: 4.410546, norm: 0.5636, time(ms): 792.55, token/sec:661516.95, hellaswag_acc: 0.0000
Step:   867, loss: 4.281449, norm: 0.6093, time(ms): 804.30, token/sec:651856.99, hellaswag_acc: 0.0000
Step:   868, loss: 4.268594, norm: 0.6085, time(ms): 800.71, token/sec:654781.64, hellaswag_acc: 0.0000
Step:   869, loss: 4.282164, norm: 0.5770, time(ms): 797.26, token/sec:657609.14, hellaswag_acc: 0.0000
Step:   870, loss: 4.257258, norm: 0.6621, time(ms): 797.34, token/sec:657548.18, hellaswag_acc: 0.0000
Step:   871, loss: 4.259866, norm: 0.6290, time(ms): 802.63, token/sec:653209.50, hellaswag_acc: 0.0000
Step:   872, loss: 4.246621, norm: 0.6089, time(ms): 803.13, token/sec:652807.71, hellaswag_acc: 0.0000
Step:   873, loss: 4.288900, norm: 0.6599, time(ms): 799.39, token/sec:655859.83, hellaswag_acc: 0.0000
Step:   874, loss: 4.276067, norm: 0.6803, time(ms): 788.93, token/sec:664553.23, hellaswag_acc: 0.0000
Step:   875, loss: 4.277312, norm: 0.5252, time(ms): 791.27, token/sec:662587.31, hellaswag_acc: 0.0000
Step:   876, loss: 4.275020, norm: 0.4947, time(ms): 790.56, token/sec:663188.98, hellaswag_acc: 0.0000
Step:   877, loss: 4.256190, norm: 0.4749, time(ms): 790.75, token/sec:663023.42, hellaswag_acc: 0.0000
Step:   878, loss: 4.267526, norm: 0.3888, time(ms): 797.23, token/sec:657641.00, hellaswag_acc: 0.0000
Step:   879, loss: 4.158105, norm: 0.3994, time(ms): 787.44, token/sec:665814.83, hellaswag_acc: 0.0000
Step:   880, loss: 4.248904, norm: 0.4471, time(ms): 790.97, token/sec:662844.15, hellaswag_acc: 0.0000
Step:   881, loss: 4.240752, norm: 0.5702, time(ms): 797.07, token/sec:657770.24, hellaswag_acc: 0.0000
Step:   882, loss: 4.220914, norm: 0.6880, time(ms): 794.37, token/sec:660003.85, hellaswag_acc: 0.0000
Step:   883, loss: 4.199972, norm: 0.6951, time(ms): 787.54, token/sec:665727.95, hellaswag_acc: 0.0000
Step:   884, loss: 4.232863, norm: 0.7996, time(ms): 794.00, token/sec:660309.05, hellaswag_acc: 0.0000
Step:   885, loss: 4.261463, norm: 0.7176, time(ms): 796.47, token/sec:658268.59, hellaswag_acc: 0.0000
Step:   886, loss: 4.188026, norm: 0.5314, time(ms): 792.08, token/sec:661910.61, hellaswag_acc: 0.0000
Step:   887, loss: 4.211082, norm: 0.4820, time(ms): 798.04, token/sec:656968.27, hellaswag_acc: 0.0000
Step:   888, loss: 4.178862, norm: 0.4865, time(ms): 789.82, token/sec:663805.18, hellaswag_acc: 0.0000
Step:   889, loss: 4.189384, norm: 0.4915, time(ms): 791.10, token/sec:662736.88, hellaswag_acc: 0.0000
Step:   890, loss: 4.308195, norm: 0.4724, time(ms): 790.02, token/sec:663639.10, hellaswag_acc: 0.0000
Step:   891, loss: 4.319105, norm: 0.5251, time(ms): 791.19, token/sec:662657.79, hellaswag_acc: 0.0000
Step:   892, loss: 4.308203, norm: 0.5216, time(ms): 789.73, token/sec:663885.54, hellaswag_acc: 0.0000
Step:   893, loss: 4.290687, norm: 0.6918, time(ms): 798.44, token/sec:656638.70, hellaswag_acc: 0.0000
Step:   894, loss: 4.308387, norm: 0.7050, time(ms): 793.25, token/sec:660936.98, hellaswag_acc: 0.0000
Step:   895, loss: 4.367224, norm: 0.6654, time(ms): 796.75, token/sec:658037.14, hellaswag_acc: 0.0000
Step:   896, loss: 4.261910, norm: 0.6419, time(ms): 789.58, token/sec:664008.62, hellaswag_acc: 0.0000
Step:   897, loss: 4.247064, norm: 0.5351, time(ms): 791.90, token/sec:662066.25, hellaswag_acc: 0.0000
Step:   898, loss: 4.241258, norm: 0.5316, time(ms): 793.55, token/sec:660688.16, hellaswag_acc: 0.0000
Step:   899, loss: 4.299349, norm: 0.5624, time(ms): 792.71, token/sec:661390.21, hellaswag_acc: 0.0000
Step:   900, loss: 4.286570, norm: 0.4770, time(ms): 790.57, token/sec:663179.98, hellaswag_acc: 0.0000
Step:   901, loss: 4.256738, norm: 0.4670, time(ms): 799.35, token/sec:655891.13, hellaswag_acc: 0.0000
Step:   902, loss: 4.228528, norm: 0.4399, time(ms): 793.38, token/sec:660830.72, hellaswag_acc: 0.0000
Step:   903, loss: 4.266132, norm: 0.4734, time(ms): 801.88, token/sec:653826.14, hellaswag_acc: 0.0000
Step:   904, loss: 4.221285, norm: 0.5139, time(ms): 800.61, token/sec:654860.81, hellaswag_acc: 0.0000
Step:   905, loss: 4.282093, norm: 0.5493, time(ms): 798.63, token/sec:656487.17, hellaswag_acc: 0.0000
Step:   906, loss: 4.260551, norm: 0.6526, time(ms): 804.84, token/sec:651420.00, hellaswag_acc: 0.0000
Step:   907, loss: 4.197587, norm: 0.6685, time(ms): 798.77, token/sec:656365.68, hellaswag_acc: 0.0000
Step:   908, loss: 4.267144, norm: 0.5741, time(ms): 797.47, token/sec:657435.73, hellaswag_acc: 0.0000
Step:   909, loss: 4.193803, norm: 0.5087, time(ms): 796.17, token/sec:658509.08, hellaswag_acc: 0.0000
Step:   910, loss: 4.156013, norm: 0.4512, time(ms): 803.83, token/sec:652238.46, hellaswag_acc: 0.0000
Step:   911, loss: 4.273681, norm: 0.4363, time(ms): 804.72, token/sec:651518.43, hellaswag_acc: 0.0000
Step:   912, loss: 4.208465, norm: 0.4541, time(ms): 793.83, token/sec:660455.21, hellaswag_acc: 0.0000
Step:   913, loss: 4.195092, norm: 0.5405, time(ms): 796.86, token/sec:657945.00, hellaswag_acc: 0.0000
Step:   914, loss: 4.214841, norm: 0.4791, time(ms): 806.45, token/sec:650119.28, hellaswag_acc: 0.0000
Step:   915, loss: 4.155168, norm: 0.4333, time(ms): 791.79, token/sec:662152.17, hellaswag_acc: 0.0000
Step:   916, loss: 4.132699, norm: 0.4508, time(ms): 802.36, token/sec:653433.10, hellaswag_acc: 0.0000
Step:   917, loss: 4.182375, norm: 0.4973, time(ms): 803.46, token/sec:652540.19, hellaswag_acc: 0.0000
Step:   918, loss: 4.196869, norm: 0.6250, time(ms): 802.42, token/sec:653385.93, hellaswag_acc: 0.0000
Step:   919, loss: 4.168735, norm: 0.5691, time(ms): 795.34, token/sec:659201.96, hellaswag_acc: 0.0000
Step:   920, loss: 4.150509, norm: 0.4782, time(ms): 802.31, token/sec:653471.36, hellaswag_acc: 0.0000
Step:   921, loss: 4.176454, norm: 0.4546, time(ms): 801.53, token/sec:654106.58, hellaswag_acc: 0.0000
Step:   922, loss: 4.161112, norm: 0.4514, time(ms): 797.82, token/sec:657153.61, hellaswag_acc: 0.0000
Step:   923, loss: 4.108741, norm: 0.5249, time(ms): 799.57, token/sec:655714.72, hellaswag_acc: 0.0000
Step:   924, loss: 4.162919, norm: 0.5850, time(ms): 801.27, token/sec:654317.36, hellaswag_acc: 0.0000
Step:   925, loss: 4.204450, norm: 0.5621, time(ms): 799.16, token/sec:656046.11, hellaswag_acc: 0.0000
Step:   926, loss: 4.205922, norm: 0.5440, time(ms): 799.41, token/sec:655840.27, hellaswag_acc: 0.0000
Step:   927, loss: 4.288208, norm: 0.6464, time(ms): 795.43, token/sec:659129.05, hellaswag_acc: 0.0000
Step:   928, loss: 4.233847, norm: 0.6758, time(ms): 806.11, token/sec:650395.78, hellaswag_acc: 0.0000
Step:   929, loss: 4.244921, norm: 0.5440, time(ms): 801.43, token/sec:654194.15, hellaswag_acc: 0.0000
Step:   930, loss: 4.260520, norm: 0.5552, time(ms): 792.84, token/sec:661277.44, hellaswag_acc: 0.0000
Step:   931, loss: 4.297508, norm: 0.5838, time(ms): 804.64, token/sec:651578.47, hellaswag_acc: 0.0000
Step:   932, loss: 4.208764, norm: 0.4933, time(ms): 800.99, token/sec:654551.08, hellaswag_acc: 0.0000
Step:   933, loss: 4.188274, norm: 0.5440, time(ms): 794.13, token/sec:660200.41, hellaswag_acc: 0.0000
Step:   934, loss: 4.222034, norm: 0.4981, time(ms): 804.80, token/sec:651448.18, hellaswag_acc: 0.0000
Step:   935, loss: 4.262669, norm: 0.5327, time(ms): 798.47, token/sec:656619.68, hellaswag_acc: 0.0000
Step:   936, loss: 4.237319, norm: 0.5630, time(ms): 800.28, token/sec:655126.92, hellaswag_acc: 0.0000
Step:   937, loss: 4.267148, norm: 0.4834, time(ms): 802.25, token/sec:653517.97, hellaswag_acc: 0.0000
Step:   938, loss: 4.192548, norm: 0.4469, time(ms): 794.58, token/sec:659833.93, hellaswag_acc: 0.0000
Step:   939, loss: 4.168862, norm: 0.5268, time(ms): 798.11, token/sec:656914.30, hellaswag_acc: 0.0000
Step:   940, loss: 4.189665, norm: 0.5425, time(ms): 805.68, token/sec:650737.79, hellaswag_acc: 0.0000
Step:   941, loss: 4.205784, norm: 0.4514, time(ms): 792.27, token/sec:661756.24, hellaswag_acc: 0.0000
Step:   942, loss: 4.131274, norm: 0.4701, time(ms): 795.07, token/sec:659420.39, hellaswag_acc: 0.0000
Step:   943, loss: 4.183333, norm: 0.5082, time(ms): 791.27, token/sec:662588.51, hellaswag_acc: 0.0000
Step:   944, loss: 4.177907, norm: 0.5083, time(ms): 788.13, token/sec:665231.12, hellaswag_acc: 0.0000
Step:   945, loss: 4.197192, norm: 0.5083, time(ms): 789.60, token/sec:663988.77, hellaswag_acc: 0.0000
Step:   946, loss: 4.186185, norm: 0.5588, time(ms): 796.98, token/sec:657845.01, hellaswag_acc: 0.0000
Step:   947, loss: 4.171042, norm: 0.5689, time(ms): 801.48, token/sec:654149.97, hellaswag_acc: 0.0000
Step:   948, loss: 4.138454, norm: 0.5847, time(ms): 804.85, token/sec:651414.79, hellaswag_acc: 0.0000
Step:   949, loss: 4.155581, norm: 0.4857, time(ms): 796.53, token/sec:658211.26, hellaswag_acc: 0.0000
Step:   950, loss: 4.190980, norm: 0.4475, time(ms): 793.43, token/sec:660790.01, hellaswag_acc: 0.0000
Step:   951, loss: 4.020824, norm: 0.4483, time(ms): 792.18, token/sec:661827.34, hellaswag_acc: 0.0000
Step:   952, loss: 4.179358, norm: 0.4701, time(ms): 1287.99, token/sec:407057.83, hellaswag_acc: 0.0000
Step:   953, loss: 4.220411, norm: 0.5210, time(ms): 800.08, token/sec:655295.01, hellaswag_acc: 0.0000
Step:   954, loss: 4.159706, norm: 0.4914, time(ms): 779.93, token/sec:672224.13, hellaswag_acc: 0.0000
Step:   955, loss: 4.204832, norm: 0.5715, time(ms): 784.02, token/sec:668715.44, hellaswag_acc: 0.0000
Step:   956, loss: 4.208058, norm: 0.5790, time(ms): 796.49, token/sec:658250.86, hellaswag_acc: 0.0000
Step:   957, loss: 4.230580, norm: 0.5306, time(ms): 808.67, token/sec:648334.22, hellaswag_acc: 0.0000
Step:   958, loss: 4.188494, norm: 0.5785, time(ms): 784.75, token/sec:668092.34, hellaswag_acc: 0.0000
Step:   959, loss: 4.127416, norm: 0.5316, time(ms): 782.08, token/sec:670373.83, hellaswag_acc: 0.0000
Step:   960, loss: 4.136839, norm: 0.5210, time(ms): 789.64, token/sec:663960.71, hellaswag_acc: 0.0000
Step:   961, loss: 4.146401, norm: 0.4960, time(ms): 799.62, token/sec:655671.91, hellaswag_acc: 0.0000
Step:   962, loss: 4.120101, norm: 0.4681, time(ms): 800.34, token/sec:655078.32, hellaswag_acc: 0.0000
Step:   963, loss: 4.147142, norm: 0.3749, time(ms): 792.61, token/sec:661474.37, hellaswag_acc: 0.0000
Step:   964, loss: 4.138872, norm: 0.3949, time(ms): 794.49, token/sec:659908.18, hellaswag_acc: 0.0000
Step:   965, loss: 4.090252, norm: 0.3798, time(ms): 789.81, token/sec:663819.00, hellaswag_acc: 0.0000
Step:   966, loss: 4.106301, norm: 0.4018, time(ms): 797.66, token/sec:657285.41, hellaswag_acc: 0.0000
Step:   967, loss: 4.067805, norm: 0.4413, time(ms): 796.43, token/sec:658299.14, hellaswag_acc: 0.0000
Step:   968, loss: 4.088890, norm: 0.4606, time(ms): 788.96, token/sec:664532.95, hellaswag_acc: 0.0000
Step:   969, loss: 4.114136, norm: 0.5417, time(ms): 789.45, token/sec:664117.92, hellaswag_acc: 0.0000
Step:   970, loss: 4.105503, norm: 0.6280, time(ms): 792.54, token/sec:661528.30, hellaswag_acc: 0.0000
Step:   971, loss: 4.115886, norm: 0.7265, time(ms): 796.80, token/sec:657993.63, hellaswag_acc: 0.0000
Step:   972, loss: 4.048145, norm: 0.5758, time(ms): 798.43, token/sec:656645.56, hellaswag_acc: 0.0000
Step:   973, loss: 4.096569, norm: 0.5298, time(ms): 803.00, token/sec:652911.22, hellaswag_acc: 0.0000
Step:   974, loss: 4.008605, norm: 0.4440, time(ms): 796.95, token/sec:657864.30, hellaswag_acc: 0.0000
Step:   975, loss: 4.088625, norm: 0.4121, time(ms): 796.99, token/sec:657831.04, hellaswag_acc: 0.0000
Step:   976, loss: 4.093113, norm: 0.4027, time(ms): 805.56, token/sec:650837.37, hellaswag_acc: 0.0000
Step:   977, loss: 4.077440, norm: 0.3718, time(ms): 793.41, token/sec:660807.09, hellaswag_acc: 0.0000
Step:   978, loss: 4.098126, norm: 0.3613, time(ms): 805.19, token/sec:651134.14, hellaswag_acc: 0.0000
Step:   979, loss: 4.041332, norm: 0.4079, time(ms): 801.15, token/sec:654422.90, hellaswag_acc: 0.0000
Step:   980, loss: 4.087215, norm: 0.4673, time(ms): 796.38, token/sec:658337.17, hellaswag_acc: 0.0000
Step:   981, loss: 4.083334, norm: 0.5031, time(ms): 800.17, token/sec:655217.30, hellaswag_acc: 0.0000
Step:   982, loss: 4.058667, norm: 0.5194, time(ms): 802.20, token/sec:653565.16, hellaswag_acc: 0.0000
Step:   983, loss: 4.139055, norm: 0.5237, time(ms): 799.20, token/sec:656019.88, hellaswag_acc: 0.0000
Step:   984, loss: 4.145812, norm: 0.5460, time(ms): 793.10, token/sec:661064.94, hellaswag_acc: 0.0000
Step:   985, loss: 4.201491, norm: 0.5238, time(ms): 806.46, token/sec:650108.71, hellaswag_acc: 0.0000
Step:   986, loss: 4.203245, norm: 0.5338, time(ms): 799.95, token/sec:655401.64, hellaswag_acc: 0.0000
Step:   987, loss: 4.205839, norm: 0.6899, time(ms): 790.56, token/sec:663187.78, hellaswag_acc: 0.0000
Step:   988, loss: 4.121321, norm: 0.6250, time(ms): 793.22, token/sec:660963.60, hellaswag_acc: 0.0000
Step:   989, loss: 4.186469, norm: 0.4962, time(ms): 785.43, token/sec:667513.55, hellaswag_acc: 0.0000
Step:   990, loss: 4.179474, norm: 0.4751, time(ms): 789.16, token/sec:664364.30, hellaswag_acc: 0.0000
Step:   991, loss: 4.140336, norm: 0.4470, time(ms): 796.44, token/sec:658288.50, hellaswag_acc: 0.0000
Step:   992, loss: 4.099067, norm: 0.4498, time(ms): 803.80, token/sec:652263.22, hellaswag_acc: 0.0000
Step:   993, loss: 4.138616, norm: 0.5204, time(ms): 801.92, token/sec:653789.01, hellaswag_acc: 0.0000
Step:   994, loss: 4.104688, norm: 0.5220, time(ms): 791.39, token/sec:662493.89, hellaswag_acc: 0.0000
Step:   995, loss: 4.120054, norm: 0.4244, time(ms): 798.99, token/sec:656187.84, hellaswag_acc: 0.0000
Step:   996, loss: 4.088843, norm: 0.4362, time(ms): 799.16, token/sec:656050.41, hellaswag_acc: 0.0000
Step:   997, loss: 4.106384, norm: 0.4248, time(ms): 791.87, token/sec:662084.59, hellaswag_acc: 0.0000
Step:   998, loss: 4.039546, norm: 0.4664, time(ms): 784.70, token/sec:668134.36, hellaswag_acc: 0.0000
Step:   999, loss: 4.139271, norm: 0.4988, time(ms): 786.10, token/sec:666947.49, hellaswag_acc: 0.0000
rank 0 sample 0: Hello, I'm a language model, and I really want it to get out this world. I am in Python in Python that I know, but I really
rank 0 sample 1: Hello, I'm a language model, just this is a language model of it. It basically requires the user on an internet network or the virtual machine.

rank 0 sample 2: Hello, I'm a language model, I'm working to try for a moment. There are many examples.
I'm not sure what I'm doing it
rank 0 sample 3: Hello, I'm a language model, it uses a different language, which it can turn on a similar language. I love language knowledge that, especially if all
rank 1 sample 0: Hello, I'm a language model, we just went to the old word where the sound came from us.
My first words have not been translated into English
rank 1 sample 1: Hello, I'm a language model, a model for creating a new language of 3D languages at the centre of the 20th century. I'm a language
rank 1 sample 2: Hello, I'm a language model, but since you will be able to make a copy of your book you are more likely to use a text file for the
rank 1 sample 3: Hello, I'm a language model, and I'm very interested in the other program.
Today it might be seen that
There are many languages spoken in
Step:  1000, loss: 4.088115, norm: 0.5222, time(ms): 364217.30, token/sec:1439.49, val_loss: 4.1532, hellaswag_acc: 0.2556
Step:  1001, loss: 4.082670, norm: 0.5004, time(ms): 790.18, token/sec:663506.15, hellaswag_acc: 0.2556
Step:  1002, loss: 4.058732, norm: 0.5078, time(ms): 792.56, token/sec:661513.97, hellaswag_acc: 0.2556
Step:  1003, loss: 4.093904, norm: 0.4435, time(ms): 790.90, token/sec:662899.30, hellaswag_acc: 0.2556
Step:  1004, loss: 4.067206, norm: 0.3905, time(ms): 790.77, token/sec:663011.43, hellaswag_acc: 0.2556
Step:  1005, loss: 4.033433, norm: 0.3672, time(ms): 799.76, token/sec:655558.15, hellaswag_acc: 0.2556
Step:  1006, loss: 4.010887, norm: 0.4085, time(ms): 806.05, token/sec:650438.49, hellaswag_acc: 0.2556
Step:  1007, loss: 3.993098, norm: 0.4256, time(ms): 802.17, token/sec:653591.00, hellaswag_acc: 0.2556
Step:  1008, loss: 4.034185, norm: 0.4669, time(ms): 793.07, token/sec:661084.41, hellaswag_acc: 0.2556
Step:  1009, loss: 4.027096, norm: 0.5343, time(ms): 800.80, token/sec:654704.25, hellaswag_acc: 0.2556
Step:  1010, loss: 3.990175, norm: 0.6420, time(ms): 803.65, token/sec:652382.03, hellaswag_acc: 0.2556
Step:  1011, loss: 4.037750, norm: 0.5706, time(ms): 801.23, token/sec:654350.66, hellaswag_acc: 0.2556
Step:  1012, loss: 3.984277, norm: 0.6008, time(ms): 799.75, token/sec:655567.53, hellaswag_acc: 0.2556
Step:  1013, loss: 4.027631, norm: 0.5182, time(ms): 792.19, token/sec:661821.96, hellaswag_acc: 0.2556
Step:  1014, loss: 3.974369, norm: 0.4343, time(ms): 805.51, token/sec:650874.93, hellaswag_acc: 0.2556
Step:  1015, loss: 4.034883, norm: 0.4373, time(ms): 802.73, token/sec:653129.76, hellaswag_acc: 0.2556
Step:  1016, loss: 4.004949, norm: 0.4314, time(ms): 794.01, token/sec:660303.10, hellaswag_acc: 0.2556
Step:  1017, loss: 3.997824, norm: 0.4396, time(ms): 804.69, token/sec:651540.25, hellaswag_acc: 0.2556
Step:  1018, loss: 4.114354, norm: 0.4595, time(ms): 799.65, token/sec:655644.54, hellaswag_acc: 0.2556
Step:  1019, loss: 4.163867, norm: 0.6041, time(ms): 798.43, token/sec:656650.47, hellaswag_acc: 0.2556
Step:  1020, loss: 4.115548, norm: 0.6151, time(ms): 800.87, token/sec:654651.43, hellaswag_acc: 0.2556
Step:  1021, loss: 4.125322, norm: 0.6234, time(ms): 797.23, token/sec:657636.87, hellaswag_acc: 0.2556
Step:  1022, loss: 4.165905, norm: 0.5878, time(ms): 802.34, token/sec:653450.77, hellaswag_acc: 0.2556
Step:  1023, loss: 4.122112, norm: 0.5794, time(ms): 797.12, token/sec:657727.15, hellaswag_acc: 0.2556
Step:  1024, loss: 4.133222, norm: 0.5500, time(ms): 799.64, token/sec:655652.75, hellaswag_acc: 0.2556
Step:  1025, loss: 4.111915, norm: 0.4460, time(ms): 802.66, token/sec:653186.61, hellaswag_acc: 0.2556
Step:  1026, loss: 4.108355, norm: 0.4006, time(ms): 799.73, token/sec:655582.77, hellaswag_acc: 0.2556
Step:  1027, loss: 4.075824, norm: 0.4128, time(ms): 794.26, token/sec:660099.14, hellaswag_acc: 0.2556
Step:  1028, loss: 4.120982, norm: 0.4069, time(ms): 805.67, token/sec:650747.61, hellaswag_acc: 0.2556
Step:  1029, loss: 4.104470, norm: 0.3636, time(ms): 799.87, token/sec:655469.43, hellaswag_acc: 0.2556
Step:  1030, loss: 4.011988, norm: 0.3430, time(ms): 798.96, token/sec:656214.86, hellaswag_acc: 0.2556
Step:  1031, loss: 4.092707, norm: 0.3613, time(ms): 795.63, token/sec:658958.20, hellaswag_acc: 0.2556
Step:  1032, loss: 4.062001, norm: 0.3653, time(ms): 806.35, token/sec:650202.70, hellaswag_acc: 0.2556
Step:  1033, loss: 4.044752, norm: 0.3972, time(ms): 797.93, token/sec:657058.57, hellaswag_acc: 0.2556
Step:  1034, loss: 4.043033, norm: 0.4313, time(ms): 797.75, token/sec:657211.74, hellaswag_acc: 0.2556
Step:  1035, loss: 4.003394, norm: 0.4518, time(ms): 802.16, token/sec:653599.16, hellaswag_acc: 0.2556
Step:  1036, loss: 4.047557, norm: 0.4585, time(ms): 799.83, token/sec:655498.94, hellaswag_acc: 0.2556
Step:  1037, loss: 4.020557, norm: 0.4837, time(ms): 801.33, token/sec:654273.95, hellaswag_acc: 0.2556
Step:  1038, loss: 4.072732, norm: 0.4977, time(ms): 797.41, token/sec:657491.95, hellaswag_acc: 0.2556
Step:  1039, loss: 4.007644, norm: 0.4765, time(ms): 799.03, token/sec:656154.36, hellaswag_acc: 0.2556
Step:  1040, loss: 4.057896, norm: 0.4071, time(ms): 800.79, token/sec:654711.66, hellaswag_acc: 0.2556
Step:  1041, loss: 3.998632, norm: 0.4483, time(ms): 801.67, token/sec:653991.22, hellaswag_acc: 0.2556
Step:  1042, loss: 3.956499, norm: 0.4670, time(ms): 794.14, token/sec:660199.22, hellaswag_acc: 0.2556
Step:  1043, loss: 3.963030, norm: 0.4969, time(ms): 798.96, token/sec:656211.93, hellaswag_acc: 0.2556
Step:  1044, loss: 3.974143, norm: 0.4325, time(ms): 805.78, token/sec:650660.39, hellaswag_acc: 0.2556
Step:  1045, loss: 4.021973, norm: 0.4404, time(ms): 800.91, token/sec:654617.33, hellaswag_acc: 0.2556
Step:  1046, loss: 4.058317, norm: 0.4018, time(ms): 793.14, token/sec:661027.78, hellaswag_acc: 0.2556
Step:  1047, loss: 4.058621, norm: 0.4111, time(ms): 804.59, token/sec:651617.66, hellaswag_acc: 0.2556
Step:  1048, loss: 3.953341, norm: 0.8189, time(ms): 801.78, token/sec:653907.80, hellaswag_acc: 0.2556
Step:  1049, loss: 4.016179, norm: 0.8150, time(ms): 798.90, token/sec:656261.08, hellaswag_acc: 0.2556
Step:  1050, loss: 4.046465, norm: 1.0224, time(ms): 792.83, token/sec:661284.01, hellaswag_acc: 0.2556
Step:  1051, loss: 3.979152, norm: 0.6847, time(ms): 805.44, token/sec:650935.04, hellaswag_acc: 0.2556
Step:  1052, loss: 3.994516, norm: 0.5832, time(ms): 801.71, token/sec:653964.38, hellaswag_acc: 0.2556
Step:  1053, loss: 4.120163, norm: 0.5569, time(ms): 793.83, token/sec:660456.40, hellaswag_acc: 0.2556
Step:  1054, loss: 4.170450, norm: 0.6432, time(ms): 801.49, token/sec:654140.63, hellaswag_acc: 0.2556
Step:  1055, loss: 4.152447, norm: 0.7237, time(ms): 803.86, token/sec:652209.44, hellaswag_acc: 0.2556
Step:  1056, loss: 4.093614, norm: 0.5714, time(ms): 800.31, token/sec:655104.86, hellaswag_acc: 0.2556
Step:  1057, loss: 4.073287, norm: 0.4994, time(ms): 792.43, token/sec:661617.26, hellaswag_acc: 0.2556
Step:  1058, loss: 4.105039, norm: 0.4512, time(ms): 803.03, token/sec:652886.40, hellaswag_acc: 0.2556
Step:  1059, loss: 4.065621, norm: 0.4180, time(ms): 803.73, token/sec:652319.33, hellaswag_acc: 0.2556
Step:  1060, loss: 4.106727, norm: 0.4178, time(ms): 800.75, token/sec:654743.24, hellaswag_acc: 0.2556
Step:  1061, loss: 4.070615, norm: 0.3862, time(ms): 792.87, token/sec:661255.37, hellaswag_acc: 0.2556
Step:  1062, loss: 4.081720, norm: 0.3620, time(ms): 804.46, token/sec:651726.01, hellaswag_acc: 0.2556
Step:  1063, loss: 4.064926, norm: 0.3657, time(ms): 800.99, token/sec:654548.35, hellaswag_acc: 0.2556
Step:  1064, loss: 4.016721, norm: 0.3721, time(ms): 798.98, token/sec:656198.41, hellaswag_acc: 0.2556
Step:  1065, loss: 4.040890, norm: 0.3699, time(ms): 791.92, token/sec:662046.72, hellaswag_acc: 0.2556
Step:  1066, loss: 4.088949, norm: 0.3781, time(ms): 807.70, token/sec:649111.40, hellaswag_acc: 0.2556
Step:  1067, loss: 4.003524, norm: 0.4058, time(ms): 802.57, token/sec:653258.40, hellaswag_acc: 0.2556
Step:  1068, loss: 4.059677, norm: 0.4304, time(ms): 785.89, token/sec:667127.17, hellaswag_acc: 0.2556
Step:  1069, loss: 4.056164, norm: 0.4926, time(ms): 789.74, token/sec:663870.91, hellaswag_acc: 0.2556
Step:  1070, loss: 4.050979, norm: 0.5420, time(ms): 792.13, token/sec:661872.36, hellaswag_acc: 0.2556
Step:  1071, loss: 4.017878, norm: 0.6061, time(ms): 791.26, token/sec:662601.68, hellaswag_acc: 0.2556
Step:  1072, loss: 4.045303, norm: 0.5472, time(ms): 793.65, token/sec:660600.64, hellaswag_acc: 0.2556
Step:  1073, loss: 4.024286, norm: 0.4417, time(ms): 795.31, token/sec:659221.13, hellaswag_acc: 0.2556
Step:  1074, loss: 4.030021, norm: 0.4069, time(ms): 794.52, token/sec:659877.29, hellaswag_acc: 0.2556
Step:  1075, loss: 4.013863, norm: 0.3849, time(ms): 790.40, token/sec:663320.21, hellaswag_acc: 0.2556
Step:  1076, loss: 4.037359, norm: 0.3442, time(ms): 789.83, token/sec:663797.16, hellaswag_acc: 0.2556
Step:  1077, loss: 3.930658, norm: 0.3307, time(ms): 788.41, token/sec:664997.36, hellaswag_acc: 0.2556
Step:  1078, loss: 3.904468, norm: 0.3306, time(ms): 794.68, token/sec:659749.79, hellaswag_acc: 0.2556
Step:  1079, loss: 3.957829, norm: 0.3219, time(ms): 790.89, token/sec:662910.29, hellaswag_acc: 0.2556
Step:  1080, loss: 3.913599, norm: 0.3471, time(ms): 799.21, token/sec:656009.71, hellaswag_acc: 0.2556
Step:  1081, loss: 3.899599, norm: 0.3806, time(ms): 797.29, token/sec:657583.97, hellaswag_acc: 0.2556
Step:  1082, loss: 3.897078, norm: 0.3954, time(ms): 799.45, token/sec:655810.15, hellaswag_acc: 0.2556
Step:  1083, loss: 3.947223, norm: 0.4169, time(ms): 802.91, token/sec:652985.86, hellaswag_acc: 0.2556
Step:  1084, loss: 3.923787, norm: 0.4685, time(ms): 799.71, token/sec:655593.91, hellaswag_acc: 0.2556
Step:  1085, loss: 3.950210, norm: 0.4388, time(ms): 798.22, token/sec:656825.42, hellaswag_acc: 0.2556
Step:  1086, loss: 3.965811, norm: 0.4070, time(ms): 800.54, token/sec:654918.93, hellaswag_acc: 0.2556
Step:  1087, loss: 3.959687, norm: 0.4390, time(ms): 796.06, token/sec:658606.91, hellaswag_acc: 0.2556
Step:  1088, loss: 4.012677, norm: 0.4071, time(ms): 806.39, token/sec:650165.02, hellaswag_acc: 0.2556
Step:  1089, loss: 4.026747, norm: 0.3555, time(ms): 795.10, token/sec:659398.64, hellaswag_acc: 0.2556
Step:  1090, loss: 4.045801, norm: 0.3654, time(ms): 795.81, token/sec:658807.97, hellaswag_acc: 0.2556
Step:  1091, loss: 4.068799, norm: 0.4114, time(ms): 806.89, token/sec:649767.16, hellaswag_acc: 0.2556
Step:  1092, loss: 4.046276, norm: 0.4304, time(ms): 801.36, token/sec:654244.17, hellaswag_acc: 0.2556
Step:  1093, loss: 4.034215, norm: 0.4405, time(ms): 792.93, token/sec:661204.27, hellaswag_acc: 0.2556
Step:  1094, loss: 4.022367, norm: 0.4387, time(ms): 802.03, token/sec:653704.47, hellaswag_acc: 0.2556
Step:  1095, loss: 4.037280, norm: 0.5113, time(ms): 803.35, token/sec:652626.76, hellaswag_acc: 0.2556
Step:  1096, loss: 4.008426, norm: 0.5621, time(ms): 798.71, token/sec:656422.31, hellaswag_acc: 0.2556
Step:  1097, loss: 4.050520, norm: 0.5845, time(ms): 793.13, token/sec:661036.12, hellaswag_acc: 0.2556
Step:  1098, loss: 4.051371, norm: 0.5107, time(ms): 804.04, token/sec:652067.48, hellaswag_acc: 0.2556
Step:  1099, loss: 4.015702, norm: 0.4768, time(ms): 803.80, token/sec:652259.54, hellaswag_acc: 0.2556
Step:  1100, loss: 3.989985, norm: 0.4288, time(ms): 799.51, token/sec:655764.00, hellaswag_acc: 0.2556
Step:  1101, loss: 4.019868, norm: 0.4393, time(ms): 788.33, token/sec:665063.53, hellaswag_acc: 0.2556
Step:  1102, loss: 4.036868, norm: 0.4020, time(ms): 791.38, token/sec:662501.07, hellaswag_acc: 0.2556
Step:  1103, loss: 4.007742, norm: 0.4085, time(ms): 790.91, token/sec:662888.91, hellaswag_acc: 0.2556
Step:  1104, loss: 4.006112, norm: 0.5103, time(ms): 792.29, token/sec:661734.33, hellaswag_acc: 0.2556
Step:  1105, loss: 3.965888, norm: 0.5563, time(ms): 787.12, token/sec:666085.28, hellaswag_acc: 0.2556
Step:  1106, loss: 4.027462, norm: 0.5337, time(ms): 799.19, token/sec:656020.27, hellaswag_acc: 0.2556
Step:  1107, loss: 4.005250, norm: 0.4942, time(ms): 793.59, token/sec:660653.83, hellaswag_acc: 0.2556
Step:  1108, loss: 4.024962, norm: 0.4891, time(ms): 793.89, token/sec:660407.60, hellaswag_acc: 0.2556
Step:  1109, loss: 3.983578, norm: 0.4281, time(ms): 791.31, token/sec:662556.17, hellaswag_acc: 0.2556
Step:  1110, loss: 3.974123, norm: 0.4496, time(ms): 788.85, token/sec:664622.32, hellaswag_acc: 0.2556
Step:  1111, loss: 3.989501, norm: 0.4437, time(ms): 792.05, token/sec:661941.29, hellaswag_acc: 0.2556
Step:  1112, loss: 3.927038, norm: 0.4438, time(ms): 793.22, token/sec:660959.43, hellaswag_acc: 0.2556
Step:  1113, loss: 3.905293, norm: 0.4037, time(ms): 795.59, token/sec:658991.38, hellaswag_acc: 0.2556
Step:  1114, loss: 3.913226, norm: 0.3790, time(ms): 789.42, token/sec:664146.60, hellaswag_acc: 0.2556
Step:  1115, loss: 3.929000, norm: 0.3595, time(ms): 792.08, token/sec:661912.40, hellaswag_acc: 0.2556
Step:  1116, loss: 3.901622, norm: 0.3675, time(ms): 791.78, token/sec:662167.13, hellaswag_acc: 0.2556
Step:  1117, loss: 3.933626, norm: 0.3997, time(ms): 791.19, token/sec:662661.59, hellaswag_acc: 0.2556
Step:  1118, loss: 3.889042, norm: 0.4146, time(ms): 792.62, token/sec:661460.64, hellaswag_acc: 0.2556
Step:  1119, loss: 3.928826, norm: 0.4437, time(ms): 797.32, token/sec:657566.86, hellaswag_acc: 0.2556
Step:  1120, loss: 3.895208, norm: 0.4259, time(ms): 802.68, token/sec:653173.41, hellaswag_acc: 0.2556
Step:  1121, loss: 3.885676, norm: 0.4224, time(ms): 801.59, token/sec:654056.39, hellaswag_acc: 0.2556
Step:  1122, loss: 3.942846, norm: 0.4407, time(ms): 793.62, token/sec:660627.83, hellaswag_acc: 0.2556
Step:  1123, loss: 3.997220, norm: 0.4226, time(ms): 800.08, token/sec:655293.44, hellaswag_acc: 0.2556
Step:  1124, loss: 4.038261, norm: 0.4196, time(ms): 806.33, token/sec:650215.01, hellaswag_acc: 0.2556
Step:  1125, loss: 3.977882, norm: 0.4105, time(ms): 799.22, token/sec:656003.64, hellaswag_acc: 0.2556
Step:  1126, loss: 3.950315, norm: 0.4322, time(ms): 794.86, token/sec:659600.98, hellaswag_acc: 0.2556
Step:  1127, loss: 4.026620, norm: 0.4333, time(ms): 801.76, token/sec:653921.41, hellaswag_acc: 0.2556
Step:  1128, loss: 3.999100, norm: 0.4150, time(ms): 800.98, token/sec:654560.43, hellaswag_acc: 0.2556
Step:  1129, loss: 4.019275, norm: 0.4141, time(ms): 802.15, token/sec:653600.32, hellaswag_acc: 0.2556
Step:  1130, loss: 3.989845, norm: 0.4888, time(ms): 795.77, token/sec:658847.44, hellaswag_acc: 0.2556
Step:  1131, loss: 3.990180, norm: 0.5341, time(ms): 801.15, token/sec:654417.06, hellaswag_acc: 0.2556
Step:  1132, loss: 3.967678, norm: 0.5147, time(ms): 799.09, token/sec:656108.75, hellaswag_acc: 0.2556
Step:  1133, loss: 3.995155, norm: 0.5433, time(ms): 799.63, token/sec:655659.39, hellaswag_acc: 0.2556
Step:  1134, loss: 3.979999, norm: 0.5078, time(ms): 803.18, token/sec:652768.18, hellaswag_acc: 0.2556
Step:  1135, loss: 4.004052, norm: 0.4538, time(ms): 799.39, token/sec:655863.16, hellaswag_acc: 0.2556
Step:  1136, loss: 3.985314, norm: 0.4593, time(ms): 797.22, token/sec:657645.13, hellaswag_acc: 0.2556
Step:  1137, loss: 4.001627, norm: 0.4520, time(ms): 803.20, token/sec:652745.90, hellaswag_acc: 0.2556
Step:  1138, loss: 3.992445, norm: 0.4641, time(ms): 799.75, token/sec:655564.79, hellaswag_acc: 0.2556
Step:  1139, loss: 3.971757, norm: 0.4519, time(ms): 795.88, token/sec:658754.48, hellaswag_acc: 0.2556
Step:  1140, loss: 3.979342, norm: 0.3833, time(ms): 801.25, token/sec:654338.39, hellaswag_acc: 0.2556
Step:  1141, loss: 3.968628, norm: 0.3304, time(ms): 802.86, token/sec:653024.83, hellaswag_acc: 0.2556
Step:  1142, loss: 3.948328, norm: 0.3331, time(ms): 1292.29, token/sec:405705.66, hellaswag_acc: 0.2556
Step:  1143, loss: 4.017031, norm: 0.3770, time(ms): 772.80, token/sec:678428.20, hellaswag_acc: 0.2556
Step:  1144, loss: 4.004106, norm: 0.4298, time(ms): 794.21, token/sec:660136.00, hellaswag_acc: 0.2556
Step:  1145, loss: 4.054914, norm: 0.5274, time(ms): 799.81, token/sec:655512.42, hellaswag_acc: 0.2556
Step:  1146, loss: 4.018394, norm: 0.5449, time(ms): 791.43, token/sec:662455.97, hellaswag_acc: 0.2556
Step:  1147, loss: 3.987613, norm: 0.5487, time(ms): 781.54, token/sec:670836.22, hellaswag_acc: 0.2556
Step:  1148, loss: 4.037596, norm: 0.5323, time(ms): 792.84, token/sec:661280.63, hellaswag_acc: 0.2556
Step:  1149, loss: 4.002646, norm: 0.4734, time(ms): 792.87, token/sec:661251.79, hellaswag_acc: 0.2556
Step:  1150, loss: 4.036731, norm: 0.4164, time(ms): 788.32, token/sec:665071.38, hellaswag_acc: 0.2556
Step:  1151, loss: 4.029004, norm: 0.3906, time(ms): 789.61, token/sec:663981.36, hellaswag_acc: 0.2556
Step:  1152, loss: 3.999996, norm: 0.3778, time(ms): 796.45, token/sec:658277.46, hellaswag_acc: 0.2556
Step:  1153, loss: 3.983079, norm: 0.3832, time(ms): 801.38, token/sec:654230.15, hellaswag_acc: 0.2556
Step:  1154, loss: 3.983790, norm: 0.4131, time(ms): 804.95, token/sec:651332.79, hellaswag_acc: 0.2556
Step:  1155, loss: 3.976249, norm: 0.4283, time(ms): 789.92, token/sec:663726.44, hellaswag_acc: 0.2556
Step:  1156, loss: 3.969343, norm: 0.3966, time(ms): 798.64, token/sec:656472.28, hellaswag_acc: 0.2556
Step:  1157, loss: 3.999374, norm: 0.3548, time(ms): 791.11, token/sec:662727.49, hellaswag_acc: 0.2556
Step:  1158, loss: 3.984450, norm: 0.3269, time(ms): 791.91, token/sec:662055.09, hellaswag_acc: 0.2556
Step:  1159, loss: 3.973562, norm: 0.3346, time(ms): 790.62, token/sec:663137.39, hellaswag_acc: 0.2556
Step:  1160, loss: 3.949809, norm: 0.3539, time(ms): 788.54, token/sec:664884.36, hellaswag_acc: 0.2556
Step:  1161, loss: 3.936551, norm: 0.3766, time(ms): 789.89, token/sec:663748.47, hellaswag_acc: 0.2556
Step:  1162, loss: 3.932116, norm: 0.4010, time(ms): 794.51, token/sec:659887.59, hellaswag_acc: 0.2556
Step:  1163, loss: 4.025997, norm: 0.4462, time(ms): 799.81, token/sec:655515.94, hellaswag_acc: 0.2556
Step:  1164, loss: 3.950627, norm: 0.4663, time(ms): 802.73, token/sec:653130.35, hellaswag_acc: 0.2556
Step:  1165, loss: 3.948616, norm: 0.4770, time(ms): 794.14, token/sec:660195.26, hellaswag_acc: 0.2556
Step:  1166, loss: 3.968319, norm: 0.5025, time(ms): 797.78, token/sec:657183.85, hellaswag_acc: 0.2556
Step:  1167, loss: 3.918773, norm: 0.5424, time(ms): 805.34, token/sec:651013.47, hellaswag_acc: 0.2556
Step:  1168, loss: 3.959351, norm: 0.4934, time(ms): 802.87, token/sec:653017.27, hellaswag_acc: 0.2556
Step:  1169, loss: 3.952428, norm: 0.5421, time(ms): 792.53, token/sec:661540.44, hellaswag_acc: 0.2556
Step:  1170, loss: 3.949458, norm: 0.5337, time(ms): 800.69, token/sec:654796.85, hellaswag_acc: 0.2556
Step:  1171, loss: 3.929783, norm: 0.4641, time(ms): 805.70, token/sec:650721.23, hellaswag_acc: 0.2556
Step:  1172, loss: 3.961165, norm: 0.4286, time(ms): 788.42, token/sec:664982.28, hellaswag_acc: 0.2556
Step:  1173, loss: 3.935396, norm: 0.4302, time(ms): 791.19, token/sec:662654.20, hellaswag_acc: 0.2556
Step:  1174, loss: 3.970010, norm: 0.3965, time(ms): 787.41, token/sec:665836.80, hellaswag_acc: 0.2556
Step:  1175, loss: 3.909172, norm: 0.3460, time(ms): 793.40, token/sec:660815.03, hellaswag_acc: 0.2556
Step:  1176, loss: 3.994941, norm: 0.3990, time(ms): 796.91, token/sec:657902.88, hellaswag_acc: 0.2556
Step:  1177, loss: 4.010785, norm: 0.4315, time(ms): 798.09, token/sec:656926.47, hellaswag_acc: 0.2556
Step:  1178, loss: 3.967451, norm: 0.4277, time(ms): 800.42, token/sec:655020.18, hellaswag_acc: 0.2556
Step:  1179, loss: 4.019040, norm: 0.4458, time(ms): 800.69, token/sec:654794.12, hellaswag_acc: 0.2556
Step:  1180, loss: 4.009044, norm: 0.4724, time(ms): 802.51, token/sec:653306.73, hellaswag_acc: 0.2556
Step:  1181, loss: 4.014150, norm: 0.4584, time(ms): 795.27, token/sec:659257.30, hellaswag_acc: 0.2556
Step:  1182, loss: 4.006436, norm: 0.4253, time(ms): 799.94, token/sec:655408.87, hellaswag_acc: 0.2556
Step:  1183, loss: 3.977206, norm: 0.4114, time(ms): 801.16, token/sec:654413.17, hellaswag_acc: 0.2556
Step:  1184, loss: 3.996042, norm: 0.3771, time(ms): 799.21, token/sec:656003.84, hellaswag_acc: 0.2556
Step:  1185, loss: 3.992145, norm: 0.3625, time(ms): 801.51, token/sec:654124.68, hellaswag_acc: 0.2556
Step:  1186, loss: 3.965578, norm: 0.3360, time(ms): 800.21, token/sec:655190.75, hellaswag_acc: 0.2556
Step:  1187, loss: 3.938019, norm: 0.3395, time(ms): 797.80, token/sec:657166.96, hellaswag_acc: 0.2556
Step:  1188, loss: 3.926627, norm: 0.3436, time(ms): 799.11, token/sec:656090.74, hellaswag_acc: 0.2556
Step:  1189, loss: 3.965952, norm: 0.3205, time(ms): 796.93, token/sec:657882.60, hellaswag_acc: 0.2556
Step:  1190, loss: 3.903246, norm: 0.3938, time(ms): 797.52, token/sec:657396.43, hellaswag_acc: 0.2556
Step:  1191, loss: 3.945035, norm: 0.4375, time(ms): 795.28, token/sec:659246.43, hellaswag_acc: 0.2556
Step:  1192, loss: 3.914425, norm: 0.3890, time(ms): 793.23, token/sec:660952.08, hellaswag_acc: 0.2556
Step:  1193, loss: 3.919523, norm: 0.3361, time(ms): 789.77, token/sec:663844.85, hellaswag_acc: 0.2556
Step:  1194, loss: 3.894663, norm: 0.3716, time(ms): 790.25, token/sec:663447.89, hellaswag_acc: 0.2556
Step:  1195, loss: 3.919492, norm: 0.4018, time(ms): 790.40, token/sec:663321.21, hellaswag_acc: 0.2556
Step:  1196, loss: 3.945326, norm: 0.4401, time(ms): 791.95, token/sec:662024.39, hellaswag_acc: 0.2556
Step:  1197, loss: 3.816095, norm: 0.5409, time(ms): 789.26, token/sec:664278.41, hellaswag_acc: 0.2556
Step:  1198, loss: 3.923778, norm: 0.4094, time(ms): 805.30, token/sec:651043.35, hellaswag_acc: 0.2556
Step:  1199, loss: 3.879529, norm: 0.4597, time(ms): 802.48, token/sec:653337.59, hellaswag_acc: 0.2556
Step:  1200, loss: 3.897027, norm: 0.4165, time(ms): 799.83, token/sec:655496.00, hellaswag_acc: 0.2556
Step:  1201, loss: 3.918915, norm: 0.4289, time(ms): 793.50, token/sec:660724.29, hellaswag_acc: 0.2556
Step:  1202, loss: 3.925230, norm: 0.4642, time(ms): 800.22, token/sec:655181.96, hellaswag_acc: 0.2556
Step:  1203, loss: 3.868178, norm: 0.5392, time(ms): 805.49, token/sec:650890.34, hellaswag_acc: 0.2556
Step:  1204, loss: 3.939934, norm: 0.4833, time(ms): 800.59, token/sec:654877.78, hellaswag_acc: 0.2556
Step:  1205, loss: 3.873811, norm: 0.3745, time(ms): 790.30, token/sec:663407.26, hellaswag_acc: 0.2556
Step:  1206, loss: 3.926593, norm: 0.3570, time(ms): 804.16, token/sec:651968.31, hellaswag_acc: 0.2556
Step:  1207, loss: 3.881771, norm: 0.3576, time(ms): 805.45, token/sec:650927.33, hellaswag_acc: 0.2556
Step:  1208, loss: 3.879705, norm: 0.3851, time(ms): 798.69, token/sec:656438.76, hellaswag_acc: 0.2556
Step:  1209, loss: 3.861314, norm: 0.4520, time(ms): 794.38, token/sec:659994.73, hellaswag_acc: 0.2556
Step:  1210, loss: 3.939362, norm: 0.4337, time(ms): 800.95, token/sec:654579.33, hellaswag_acc: 0.2556
Step:  1211, loss: 3.954096, norm: 0.3856, time(ms): 804.17, token/sec:651959.61, hellaswag_acc: 0.2556
Step:  1212, loss: 3.996665, norm: 0.4050, time(ms): 785.99, token/sec:667039.54, hellaswag_acc: 0.2556
Step:  1213, loss: 3.923260, norm: 0.4321, time(ms): 788.48, token/sec:664933.42, hellaswag_acc: 0.2556
Step:  1214, loss: 4.000035, norm: 0.4055, time(ms): 797.08, token/sec:657761.38, hellaswag_acc: 0.2556
Step:  1215, loss: 4.055120, norm: 0.4041, time(ms): 790.44, token/sec:663290.00, hellaswag_acc: 0.2556
Step:  1216, loss: 3.998760, norm: 0.3773, time(ms): 787.84, token/sec:665476.93, hellaswag_acc: 0.2556
Step:  1217, loss: 3.912909, norm: 0.4052, time(ms): 793.28, token/sec:660909.37, hellaswag_acc: 0.2556
Step:  1218, loss: 3.994861, norm: 0.3959, time(ms): 792.52, token/sec:661548.40, hellaswag_acc: 0.2556
Step:  1219, loss: 3.985754, norm: 0.3916, time(ms): 801.87, token/sec:653835.66, hellaswag_acc: 0.2556
Step:  1220, loss: 4.025000, norm: 0.4853, time(ms): 790.61, token/sec:663146.79, hellaswag_acc: 0.2556
Step:  1221, loss: 3.957747, norm: 0.6026, time(ms): 790.34, token/sec:663373.64, hellaswag_acc: 0.2556
Step:  1222, loss: 3.949713, norm: 0.5443, time(ms): 788.39, token/sec:665014.26, hellaswag_acc: 0.2556
Step:  1223, loss: 3.910937, norm: 0.4271, time(ms): 789.03, token/sec:664467.89, hellaswag_acc: 0.2556
Step:  1224, loss: 3.932178, norm: 0.3856, time(ms): 799.22, token/sec:656000.31, hellaswag_acc: 0.2556
Step:  1225, loss: 3.937525, norm: 0.3604, time(ms): 803.15, token/sec:652786.59, hellaswag_acc: 0.2556
Step:  1226, loss: 4.039926, norm: 0.3603, time(ms): 797.75, token/sec:657210.96, hellaswag_acc: 0.2556
Step:  1227, loss: 3.905808, norm: 0.3787, time(ms): 794.86, token/sec:659596.03, hellaswag_acc: 0.2556
Step:  1228, loss: 3.925513, norm: 0.3830, time(ms): 805.11, token/sec:651197.20, hellaswag_acc: 0.2556
Step:  1229, loss: 3.908289, norm: 0.3769, time(ms): 800.30, token/sec:655113.26, hellaswag_acc: 0.2556
Step:  1230, loss: 3.913557, norm: 0.4278, time(ms): 801.00, token/sec:654538.02, hellaswag_acc: 0.2556
Step:  1231, loss: 3.925196, norm: 0.4775, time(ms): 788.78, token/sec:664685.20, hellaswag_acc: 0.2556
Step:  1232, loss: 3.930540, norm: 0.4913, time(ms): 792.76, token/sec:661349.04, hellaswag_acc: 0.2556
Step:  1233, loss: 3.968253, norm: 0.4918, time(ms): 787.66, token/sec:665631.03, hellaswag_acc: 0.2556
Step:  1234, loss: 3.854214, norm: 0.4234, time(ms): 791.92, token/sec:662045.92, hellaswag_acc: 0.2556
Step:  1235, loss: 3.922327, norm: 0.4510, time(ms): 792.83, token/sec:661288.98, hellaswag_acc: 0.2556
Step:  1236, loss: 3.877251, norm: 0.4325, time(ms): 797.14, token/sec:657715.15, hellaswag_acc: 0.2556
Step:  1237, loss: 3.810868, norm: 0.4087, time(ms): 805.39, token/sec:650975.89, hellaswag_acc: 0.2556
Step:  1238, loss: 3.904692, norm: 0.4189, time(ms): 798.89, token/sec:656267.15, hellaswag_acc: 0.2556
Step:  1239, loss: 3.883744, norm: 0.4739, time(ms): 793.63, token/sec:660619.89, hellaswag_acc: 0.2556
Step:  1240, loss: 3.910493, norm: 0.4991, time(ms): 805.67, token/sec:650744.15, hellaswag_acc: 0.2556
Step:  1241, loss: 3.841938, norm: 0.4428, time(ms): 803.09, token/sec:652836.40, hellaswag_acc: 0.2556
Step:  1242, loss: 3.849645, norm: 0.3640, time(ms): 791.39, token/sec:662491.89, hellaswag_acc: 0.2556
Step:  1243, loss: 3.847822, norm: 0.3670, time(ms): 797.01, token/sec:657820.41, hellaswag_acc: 0.2556
Step:  1244, loss: 3.866722, norm: 0.3462, time(ms): 791.25, token/sec:662609.27, hellaswag_acc: 0.2556
Step:  1245, loss: 3.923268, norm: 0.3467, time(ms): 796.22, token/sec:658469.84, hellaswag_acc: 0.2556
Step:  1246, loss: 3.915656, norm: 0.4447, time(ms): 792.97, token/sec:661168.69, hellaswag_acc: 0.2556
Step:  1247, loss: 3.979890, norm: 0.4445, time(ms): 789.73, token/sec:663879.53, hellaswag_acc: 0.2556
Step:  1248, loss: 3.945952, norm: 0.4312, time(ms): 790.56, token/sec:663186.98, hellaswag_acc: 0.2556
Step:  1249, loss: 4.026520, norm: 0.3974, time(ms): 790.48, token/sec:663250.99, hellaswag_acc: 0.2556
rank 0 sample 0: Hello, I'm a language model, but I am not sure whether this may improve one's voice, that "there is a more complete picture" than if
rank 0 sample 1: Hello, I'm a language model, and can't be seen as being written. The two methods of "concentrating," i.e., "con
rank 0 sample 2: Hello, I'm a language model, and I see a set of methods of the time. I know, for example, the best way to do the exercises
rank 0 sample 3: Hello, I'm a language model, and can't afford to have the tools I hope can't afford. And it would be easy, a method, some
rank 1 sample 0: Hello, I'm a language model, but I haven't heard about it already: how many letters would you like?
It's hard to see how many
rank 1 sample 1: Hello, I'm a language model, which is used for the purpose of understanding.
A second language model is to "develop" other people's lives.
rank 1 sample 2: Hello, I'm a language model, I started a couple of years ago. I'm a little nervous. But I'm a lot different than the average school
rank 1 sample 3: Hello, I'm a language model, but I'm really interested in the fact that I need knowledge in these ways without the extra reason I can't think of
Step:  1250, loss: 4.034741, norm: 0.4332, time(ms): 3785.92, token/sec:138483.69, val_loss: 3.9502, hellaswag_acc: 0.2556
Step:  1251, loss: 4.012057, norm: 0.4954, time(ms): 785.69, token/sec:667299.65, hellaswag_acc: 0.2556
Step:  1252, loss: 4.019424, norm: 0.4216, time(ms): 792.32, token/sec:661713.03, hellaswag_acc: 0.2556
Step:  1253, loss: 3.990122, norm: 0.4265, time(ms): 794.14, token/sec:660199.82, hellaswag_acc: 0.2556
Step:  1254, loss: 4.001806, norm: 0.4378, time(ms): 802.05, token/sec:653686.20, hellaswag_acc: 0.2556
Step:  1255, loss: 3.974946, norm: 0.3985, time(ms): 794.60, token/sec:659810.57, hellaswag_acc: 0.2556
Step:  1256, loss: 4.006504, norm: 0.4255, time(ms): 794.21, token/sec:660139.37, hellaswag_acc: 0.2556
Step:  1257, loss: 3.898671, norm: 0.4518, time(ms): 797.83, token/sec:657141.23, hellaswag_acc: 0.2556
Step:  1258, loss: 3.916526, norm: 0.4552, time(ms): 793.00, token/sec:661143.24, hellaswag_acc: 0.2556
Step:  1259, loss: 3.930409, norm: 0.4266, time(ms): 787.51, token/sec:665755.16, hellaswag_acc: 0.2556
Step:  1260, loss: 3.910945, norm: 0.3916, time(ms): 790.51, token/sec:663230.19, hellaswag_acc: 0.2556
Step:  1261, loss: 3.971234, norm: 0.3539, time(ms): 792.14, token/sec:661865.59, hellaswag_acc: 0.2556
Step:  1262, loss: 3.977497, norm: 0.3852, time(ms): 792.45, token/sec:661601.54, hellaswag_acc: 0.2556
Step:  1263, loss: 3.867653, norm: 0.3450, time(ms): 789.90, token/sec:663738.86, hellaswag_acc: 0.2556
Step:  1264, loss: 3.907190, norm: 0.3247, time(ms): 798.44, token/sec:656641.64, hellaswag_acc: 0.2556
Step:  1265, loss: 3.921890, norm: 0.3337, time(ms): 804.49, token/sec:651701.28, hellaswag_acc: 0.2556
Step:  1266, loss: 3.905965, norm: 0.3354, time(ms): 791.83, token/sec:662123.26, hellaswag_acc: 0.2556
Step:  1267, loss: 3.865568, norm: 0.3595, time(ms): 801.95, token/sec:653765.49, hellaswag_acc: 0.2556
Step:  1268, loss: 3.903483, norm: 0.3552, time(ms): 804.80, token/sec:651454.93, hellaswag_acc: 0.2556
Step:  1269, loss: 3.871690, norm: 0.3796, time(ms): 803.25, token/sec:652711.41, hellaswag_acc: 0.2556
Step:  1270, loss: 3.909225, norm: 0.4061, time(ms): 788.47, token/sec:664944.88, hellaswag_acc: 0.2556
Step:  1271, loss: 3.814481, norm: 0.3960, time(ms): 800.12, token/sec:655263.57, hellaswag_acc: 0.2556
Step:  1272, loss: 3.868901, norm: 0.4199, time(ms): 792.39, token/sec:661654.09, hellaswag_acc: 0.2556
Step:  1273, loss: 3.842398, norm: 0.4647, time(ms): 786.33, token/sec:666754.77, hellaswag_acc: 0.2556
Step:  1274, loss: 3.852980, norm: 0.4233, time(ms): 790.66, token/sec:663098.59, hellaswag_acc: 0.2556
Step:  1275, loss: 3.898999, norm: 0.3956, time(ms): 791.69, token/sec:662241.11, hellaswag_acc: 0.2556
Step:  1276, loss: 3.799918, norm: 0.3653, time(ms): 807.24, token/sec:649482.18, hellaswag_acc: 0.2556
Step:  1277, loss: 3.885415, norm: 0.3684, time(ms): 798.15, token/sec:656876.82, hellaswag_acc: 0.2556
Step:  1278, loss: 3.812667, norm: 0.3677, time(ms): 793.16, token/sec:661013.87, hellaswag_acc: 0.2556
Step:  1279, loss: 3.811524, norm: 0.3675, time(ms): 805.40, token/sec:650966.26, hellaswag_acc: 0.2556
Step:  1280, loss: 3.797996, norm: 0.3816, time(ms): 802.87, token/sec:653020.37, hellaswag_acc: 0.2556
Step:  1281, loss: 3.864954, norm: 0.4271, time(ms): 797.43, token/sec:657469.94, hellaswag_acc: 0.2556
Step:  1282, loss: 3.883971, norm: 0.4133, time(ms): 800.57, token/sec:654891.23, hellaswag_acc: 0.2556
Step:  1283, loss: 3.899888, norm: 0.3956, time(ms): 798.96, token/sec:656212.32, hellaswag_acc: 0.2556
Step:  1284, loss: 3.855909, norm: 0.4259, time(ms): 797.70, token/sec:657247.10, hellaswag_acc: 0.2556
Step:  1285, loss: 3.917702, norm: 0.4394, time(ms): 802.32, token/sec:653466.89, hellaswag_acc: 0.2556
Step:  1286, loss: 3.892182, norm: 0.4256, time(ms): 797.49, token/sec:657419.22, hellaswag_acc: 0.2556
Step:  1287, loss: 3.909285, norm: 0.4307, time(ms): 804.25, token/sec:651895.06, hellaswag_acc: 0.2556
Step:  1288, loss: 3.935035, norm: 0.4064, time(ms): 798.97, token/sec:656207.62, hellaswag_acc: 0.2556
Step:  1289, loss: 3.988856, norm: 0.4283, time(ms): 791.40, token/sec:662484.91, hellaswag_acc: 0.2556
Step:  1290, loss: 3.902266, norm: 0.4346, time(ms): 794.71, token/sec:659718.72, hellaswag_acc: 0.2556
Step:  1291, loss: 3.926239, norm: 0.3977, time(ms): 793.05, token/sec:661099.91, hellaswag_acc: 0.2556
Step:  1292, loss: 3.922610, norm: 0.3619, time(ms): 795.92, token/sec:658715.81, hellaswag_acc: 0.2556
Step:  1293, loss: 3.885066, norm: 0.3717, time(ms): 800.63, token/sec:654846.38, hellaswag_acc: 0.2556
Step:  1294, loss: 3.870677, norm: 0.3634, time(ms): 800.05, token/sec:655319.42, hellaswag_acc: 0.2556
Step:  1295, loss: 3.902393, norm: 0.3733, time(ms): 795.00, token/sec:659477.74, hellaswag_acc: 0.2556
Step:  1296, loss: 3.939434, norm: 0.3625, time(ms): 792.95, token/sec:661182.60, hellaswag_acc: 0.2556
Step:  1297, loss: 3.895846, norm: 0.4322, time(ms): 791.25, token/sec:662605.68, hellaswag_acc: 0.2556
Step:  1298, loss: 3.915213, norm: 0.4406, time(ms): 791.79, token/sec:662158.95, hellaswag_acc: 0.2556
Step:  1299, loss: 3.886923, norm: 0.3956, time(ms): 793.15, token/sec:661016.45, hellaswag_acc: 0.2556
Step:  1300, loss: 3.887835, norm: 0.3766, time(ms): 798.48, token/sec:656607.33, hellaswag_acc: 0.2556
Step:  1301, loss: 3.836742, norm: 0.3876, time(ms): 798.85, token/sec:656303.00, hellaswag_acc: 0.2556
Step:  1302, loss: 3.873722, norm: 0.3952, time(ms): 800.15, token/sec:655237.21, hellaswag_acc: 0.2556
Step:  1303, loss: 3.916331, norm: 0.3991, time(ms): 800.19, token/sec:655201.29, hellaswag_acc: 0.2556
Step:  1304, loss: 3.858339, norm: 0.3704, time(ms): 800.35, token/sec:655075.59, hellaswag_acc: 0.2556
Step:  1305, loss: 3.805951, norm: 0.3583, time(ms): 800.05, token/sec:655318.05, hellaswag_acc: 0.2556
Step:  1306, loss: 3.840877, norm: 0.3934, time(ms): 794.51, token/sec:659891.75, hellaswag_acc: 0.2556
Step:  1307, loss: 3.834295, norm: 0.3523, time(ms): 804.13, token/sec:651993.82, hellaswag_acc: 0.2556
Step:  1308, loss: 3.858149, norm: 0.3365, time(ms): 801.71, token/sec:653960.69, hellaswag_acc: 0.2556
Step:  1309, loss: 3.770485, norm: 0.3257, time(ms): 790.73, token/sec:663039.81, hellaswag_acc: 0.2556
Step:  1310, loss: 3.809536, norm: 0.3645, time(ms): 803.82, token/sec:652249.48, hellaswag_acc: 0.2556
Step:  1311, loss: 3.859820, norm: 0.3382, time(ms): 804.03, token/sec:652076.77, hellaswag_acc: 0.2556
Step:  1312, loss: 3.824343, norm: 0.3310, time(ms): 795.78, token/sec:658834.61, hellaswag_acc: 0.2556
Step:  1313, loss: 3.825709, norm: 0.3564, time(ms): 803.85, token/sec:652223.75, hellaswag_acc: 0.2556
Step:  1314, loss: 3.801812, norm: 0.3782, time(ms): 799.91, token/sec:655433.09, hellaswag_acc: 0.2556
Step:  1315, loss: 3.857650, norm: 0.3639, time(ms): 800.14, token/sec:655246.97, hellaswag_acc: 0.2556
Step:  1316, loss: 3.938169, norm: 0.4584, time(ms): 794.31, token/sec:660053.17, hellaswag_acc: 0.2556
Step:  1317, loss: 3.842873, norm: 0.4854, time(ms): 804.99, token/sec:651296.14, hellaswag_acc: 0.2556
Step:  1318, loss: 3.893889, norm: 0.4688, time(ms): 800.75, token/sec:654745.77, hellaswag_acc: 0.2556
Step:  1319, loss: 3.911497, norm: 0.4407, time(ms): 800.15, token/sec:655239.94, hellaswag_acc: 0.2556
Step:  1320, loss: 3.889917, norm: 0.3871, time(ms): 794.55, token/sec:659857.49, hellaswag_acc: 0.2556
Step:  1321, loss: 3.884462, norm: 0.3608, time(ms): 803.16, token/sec:652784.07, hellaswag_acc: 0.2556
Step:  1322, loss: 3.849147, norm: 0.3990, time(ms): 801.56, token/sec:654088.10, hellaswag_acc: 0.2556
Step:  1323, loss: 4.069359, norm: 0.4769, time(ms): 800.37, token/sec:655060.57, hellaswag_acc: 0.2556
Step:  1324, loss: 3.913640, norm: 0.4789, time(ms): 791.80, token/sec:662145.39, hellaswag_acc: 0.2556
Step:  1325, loss: 3.851180, norm: 0.4637, time(ms): 805.39, token/sec:650971.08, hellaswag_acc: 0.2556
Step:  1326, loss: 3.876342, norm: 0.4377, time(ms): 801.01, token/sec:654531.40, hellaswag_acc: 0.2556
Step:  1327, loss: 3.931857, norm: 0.4024, time(ms): 800.60, token/sec:654868.61, hellaswag_acc: 0.2556
Step:  1328, loss: 3.871801, norm: 0.4155, time(ms): 797.14, token/sec:657710.43, hellaswag_acc: 0.2556
Step:  1329, loss: 3.848174, norm: 0.3893, time(ms): 800.03, token/sec:655332.50, hellaswag_acc: 0.2556
Step:  1330, loss: 3.854077, norm: 0.3470, time(ms): 801.55, token/sec:654090.43, hellaswag_acc: 0.2556
Step:  1331, loss: 3.890893, norm: 0.3443, time(ms): 795.75, token/sec:658861.26, hellaswag_acc: 0.2556
Step:  1332, loss: 3.855830, norm: 0.3494, time(ms): 799.04, token/sec:656149.27, hellaswag_acc: 0.2556
Step:  1333, loss: 3.916396, norm: 0.3611, time(ms): 1294.03, token/sec:405160.36, hellaswag_acc: 0.2556
Step:  1334, loss: 3.899095, norm: 0.3500, time(ms): 797.68, token/sec:657265.37, hellaswag_acc: 0.2556
Step:  1335, loss: 3.993885, norm: 0.3948, time(ms): 786.85, token/sec:666311.73, hellaswag_acc: 0.2556
Step:  1336, loss: 3.910143, norm: 0.4914, time(ms): 786.87, token/sec:666292.55, hellaswag_acc: 0.2556
Step:  1337, loss: 3.854648, norm: 0.4357, time(ms): 792.03, token/sec:661958.23, hellaswag_acc: 0.2556
Step:  1338, loss: 3.895403, norm: 0.4252, time(ms): 808.33, token/sec:648605.19, hellaswag_acc: 0.2556
Step:  1339, loss: 3.916262, norm: 0.3810, time(ms): 784.79, token/sec:668058.44, hellaswag_acc: 0.2556
Step:  1340, loss: 3.940822, norm: 0.3565, time(ms): 785.64, token/sec:667336.91, hellaswag_acc: 0.2556
Step:  1341, loss: 3.929705, norm: 0.3961, time(ms): 785.81, token/sec:667193.15, hellaswag_acc: 0.2556
Step:  1342, loss: 3.810466, norm: 0.4089, time(ms): 792.05, token/sec:661937.71, hellaswag_acc: 0.2556
Step:  1343, loss: 3.854707, norm: 0.3779, time(ms): 791.09, token/sec:662742.27, hellaswag_acc: 0.2556
Step:  1344, loss: 3.920106, norm: 0.3425, time(ms): 788.86, token/sec:664614.69, hellaswag_acc: 0.2556
Step:  1345, loss: 3.936621, norm: 0.3278, time(ms): 791.93, token/sec:662042.33, hellaswag_acc: 0.2556
Step:  1346, loss: 3.903863, norm: 0.3102, time(ms): 788.56, token/sec:664870.09, hellaswag_acc: 0.2556
Step:  1347, loss: 3.957273, norm: 0.3341, time(ms): 792.77, token/sec:661336.11, hellaswag_acc: 0.2556
Step:  1348, loss: 3.949398, norm: 0.3718, time(ms): 791.91, token/sec:662053.29, hellaswag_acc: 0.2556
Step:  1349, loss: 3.951145, norm: 0.3883, time(ms): 794.82, token/sec:659633.23, hellaswag_acc: 0.2556
Step:  1350, loss: 3.964521, norm: 0.3849, time(ms): 797.55, token/sec:657376.77, hellaswag_acc: 0.2556
Step:  1351, loss: 3.958852, norm: 0.3995, time(ms): 792.60, token/sec:661479.15, hellaswag_acc: 0.2556
Step:  1352, loss: 3.919663, norm: 0.5411, time(ms): 789.77, token/sec:663847.46, hellaswag_acc: 0.2556
Step:  1353, loss: 3.934119, norm: 0.5725, time(ms): 792.49, token/sec:661568.30, hellaswag_acc: 0.2556
Step:  1354, loss: 3.953894, norm: 0.5269, time(ms): 795.26, token/sec:659262.44, hellaswag_acc: 0.2556
Step:  1355, loss: 3.912992, norm: 0.4830, time(ms): 791.30, token/sec:662569.14, hellaswag_acc: 0.2556
Step:  1356, loss: 3.852413, norm: 0.4888, time(ms): 788.56, token/sec:664864.06, hellaswag_acc: 0.2556
Step:  1357, loss: 3.863739, norm: 0.4065, time(ms): 796.98, token/sec:657846.39, hellaswag_acc: 0.2556
Step:  1358, loss: 3.882776, norm: 0.3850, time(ms): 800.86, token/sec:654655.33, hellaswag_acc: 0.2556
Step:  1359, loss: 3.826821, norm: 0.3242, time(ms): 801.68, token/sec:653990.06, hellaswag_acc: 0.2556
Step:  1360, loss: 3.816711, norm: 0.2893, time(ms): 800.41, token/sec:655023.69, hellaswag_acc: 0.2556
Step:  1361, loss: 3.788548, norm: 0.3388, time(ms): 795.43, token/sec:659122.73, hellaswag_acc: 0.2556
Step:  1362, loss: 3.838840, norm: 0.3466, time(ms): 798.77, token/sec:656367.05, hellaswag_acc: 0.2556
Step:  1363, loss: 3.858432, norm: 0.3355, time(ms): 806.23, token/sec:650298.84, hellaswag_acc: 0.2556
Step:  1364, loss: 3.809160, norm: 0.3173, time(ms): 797.69, token/sec:657254.17, hellaswag_acc: 0.2556
Step:  1365, loss: 3.856169, norm: 0.3043, time(ms): 794.96, token/sec:659512.55, hellaswag_acc: 0.2556
Step:  1366, loss: 3.886456, norm: 0.2984, time(ms): 804.30, token/sec:651856.99, hellaswag_acc: 0.2556
Step:  1367, loss: 3.849597, norm: 0.2918, time(ms): 801.86, token/sec:653840.13, hellaswag_acc: 0.2556
Step:  1368, loss: 3.885492, norm: 0.3047, time(ms): 794.45, token/sec:659940.46, hellaswag_acc: 0.2556
Step:  1369, loss: 3.865032, norm: 0.3302, time(ms): 803.27, token/sec:652692.62, hellaswag_acc: 0.2556
Step:  1370, loss: 3.881227, norm: 0.3992, time(ms): 799.54, token/sec:655737.01, hellaswag_acc: 0.2556
Step:  1371, loss: 3.900014, norm: 0.4551, time(ms): 802.20, token/sec:653562.06, hellaswag_acc: 0.2556
Step:  1372, loss: 3.941270, norm: 0.5088, time(ms): 793.94, token/sec:660363.58, hellaswag_acc: 0.2556
Step:  1373, loss: 3.852842, norm: 0.4916, time(ms): 801.38, token/sec:654229.18, hellaswag_acc: 0.2556
Step:  1374, loss: 3.913597, norm: 0.4504, time(ms): 804.01, token/sec:652092.43, hellaswag_acc: 0.2556
Step:  1375, loss: 3.866878, norm: 0.3905, time(ms): 794.13, token/sec:660201.20, hellaswag_acc: 0.2556
Step:  1376, loss: 3.851321, norm: 0.3360, time(ms): 797.92, token/sec:657069.96, hellaswag_acc: 0.2556
Step:  1377, loss: 3.867715, norm: 0.3497, time(ms): 805.68, token/sec:650742.61, hellaswag_acc: 0.2556
Step:  1378, loss: 3.918756, norm: 0.3531, time(ms): 801.91, token/sec:653798.92, hellaswag_acc: 0.2556
Step:  1379, loss: 3.907687, norm: 0.3933, time(ms): 786.80, token/sec:666358.97, hellaswag_acc: 0.2556
Step:  1380, loss: 3.883601, norm: 0.3636, time(ms): 789.82, token/sec:663804.18, hellaswag_acc: 0.2556
Step:  1381, loss: 4.018951, norm: 0.4000, time(ms): 792.44, token/sec:661612.09, hellaswag_acc: 0.2556
Step:  1382, loss: 3.929914, norm: 0.4135, time(ms): 791.37, token/sec:662510.06, hellaswag_acc: 0.2556
Step:  1383, loss: 3.894854, norm: 0.3952, time(ms): 789.19, token/sec:664337.61, hellaswag_acc: 0.2556
Step:  1384, loss: 3.898738, norm: 0.3344, time(ms): 798.28, token/sec:656772.84, hellaswag_acc: 0.2556
Step:  1385, loss: 3.877132, norm: 0.3251, time(ms): 793.28, token/sec:660912.94, hellaswag_acc: 0.2556
Step:  1386, loss: 3.834665, norm: 0.3452, time(ms): 794.74, token/sec:659701.50, hellaswag_acc: 0.2556
Step:  1387, loss: 3.879142, norm: 0.3542, time(ms): 792.15, token/sec:661854.63, hellaswag_acc: 0.2556
Step:  1388, loss: 3.871992, norm: 0.3380, time(ms): 790.93, token/sec:662877.12, hellaswag_acc: 0.2556
Step:  1389, loss: 3.882563, norm: 0.3288, time(ms): 795.62, token/sec:658967.88, hellaswag_acc: 0.2556
Step:  1390, loss: 3.898690, norm: 0.3233, time(ms): 792.00, token/sec:661975.97, hellaswag_acc: 0.2556
Step:  1391, loss: 3.825754, norm: 0.3248, time(ms): 784.19, token/sec:668572.52, hellaswag_acc: 0.2556
Step:  1392, loss: 3.808449, norm: 0.3098, time(ms): 806.46, token/sec:650111.97, hellaswag_acc: 0.2556
Step:  1393, loss: 3.862457, norm: 0.3818, time(ms): 799.30, token/sec:655931.04, hellaswag_acc: 0.2556
Step:  1394, loss: 3.867764, norm: 0.4276, time(ms): 797.21, token/sec:657653.58, hellaswag_acc: 0.2556
Step:  1395, loss: 3.835196, norm: 0.4427, time(ms): 800.56, token/sec:654902.35, hellaswag_acc: 0.2556
Step:  1396, loss: 3.819764, norm: 0.4152, time(ms): 800.18, token/sec:655209.68, hellaswag_acc: 0.2556
Step:  1397, loss: 3.867894, norm: 0.3653, time(ms): 800.27, token/sec:655138.63, hellaswag_acc: 0.2556
Step:  1398, loss: 3.945336, norm: 0.3378, time(ms): 798.93, token/sec:656239.93, hellaswag_acc: 0.2556
Step:  1399, loss: 3.835233, norm: 0.3646, time(ms): 800.25, token/sec:655151.90, hellaswag_acc: 0.2556
Step:  1400, loss: 3.909967, norm: 0.3490, time(ms): 800.84, token/sec:654675.79, hellaswag_acc: 0.2556
Step:  1401, loss: 3.825987, norm: 0.3571, time(ms): 799.54, token/sec:655735.64, hellaswag_acc: 0.2556
Step:  1402, loss: 3.843797, norm: 0.3808, time(ms): 798.28, token/sec:656773.82, hellaswag_acc: 0.2556
Step:  1403, loss: 3.838706, norm: 0.4308, time(ms): 796.81, token/sec:657986.34, hellaswag_acc: 0.2556
Step:  1404, loss: 3.883249, norm: 0.4124, time(ms): 805.89, token/sec:650569.72, hellaswag_acc: 0.2556
Step:  1405, loss: 3.873703, norm: 0.4599, time(ms): 799.54, token/sec:655735.06, hellaswag_acc: 0.2556
Step:  1406, loss: 3.864725, norm: 0.4848, time(ms): 790.36, token/sec:663352.83, hellaswag_acc: 0.2556
Step:  1407, loss: 3.881420, norm: 0.4362, time(ms): 805.63, token/sec:650778.62, hellaswag_acc: 0.2556
Step:  1408, loss: 3.872979, norm: 0.4687, time(ms): 803.76, token/sec:652297.08, hellaswag_acc: 0.2556
Step:  1409, loss: 3.922464, norm: 0.5454, time(ms): 795.10, token/sec:659397.85, hellaswag_acc: 0.2556
Step:  1410, loss: 3.904597, norm: 0.4777, time(ms): 801.06, token/sec:654496.33, hellaswag_acc: 0.2556
Step:  1411, loss: 3.855237, norm: 0.4187, time(ms): 802.27, token/sec:653505.92, hellaswag_acc: 0.2556
Step:  1412, loss: 3.838544, norm: 0.4031, time(ms): 800.12, token/sec:655265.33, hellaswag_acc: 0.2556
Step:  1413, loss: 3.877003, norm: 0.3871, time(ms): 800.23, token/sec:655172.40, hellaswag_acc: 0.2556
Step:  1414, loss: 3.916291, norm: 0.4313, time(ms): 797.68, token/sec:657263.01, hellaswag_acc: 0.2556
Step:  1415, loss: 3.848873, norm: 0.3869, time(ms): 800.93, token/sec:654599.20, hellaswag_acc: 0.2556
Step:  1416, loss: 3.881749, norm: 0.3648, time(ms): 798.36, token/sec:656708.12, hellaswag_acc: 0.2556
Step:  1417, loss: 3.857264, norm: 0.3352, time(ms): 803.43, token/sec:652563.82, hellaswag_acc: 0.2556
Step:  1418, loss: 3.852297, norm: 0.3555, time(ms): 793.62, token/sec:660632.59, hellaswag_acc: 0.2556
Step:  1419, loss: 3.888414, norm: 0.3500, time(ms): 801.65, token/sec:654008.53, hellaswag_acc: 0.2556
Step:  1420, loss: 3.856990, norm: 0.3052, time(ms): 804.03, token/sec:652076.19, hellaswag_acc: 0.2556
Step:  1421, loss: 3.873135, norm: 0.2989, time(ms): 800.12, token/sec:655265.13, hellaswag_acc: 0.2556
Step:  1422, loss: 3.828183, norm: 0.3042, time(ms): 788.33, token/sec:665065.54, hellaswag_acc: 0.2556
Step:  1423, loss: 3.842168, norm: 0.3240, time(ms): 792.21, token/sec:661808.22, hellaswag_acc: 0.2556
Step:  1424, loss: 3.894963, norm: 0.3334, time(ms): 789.00, token/sec:664494.79, hellaswag_acc: 0.2556
Step:  1425, loss: 3.868454, norm: 0.3709, time(ms): 792.20, token/sec:661813.79, hellaswag_acc: 0.2556
Step:  1426, loss: 3.870126, norm: 0.3707, time(ms): 791.39, token/sec:662493.29, hellaswag_acc: 0.2556
Step:  1427, loss: 3.861141, norm: 0.3792, time(ms): 795.96, token/sec:658682.26, hellaswag_acc: 0.2556
Step:  1428, loss: 3.770370, norm: 0.4220, time(ms): 808.91, token/sec:648140.27, hellaswag_acc: 0.2556
Step:  1429, loss: 3.789194, norm: 0.3489, time(ms): 788.49, token/sec:664924.77, hellaswag_acc: 0.2556
Step:  1430, loss: 3.825250, norm: 0.3839, time(ms): 792.32, token/sec:661710.04, hellaswag_acc: 0.2556
Step:  1431, loss: 3.813854, norm: 0.3562, time(ms): 793.61, token/sec:660636.36, hellaswag_acc: 0.2556
Step:  1432, loss: 3.788445, norm: 0.3212, time(ms): 800.95, token/sec:654583.23, hellaswag_acc: 0.2556
Step:  1433, loss: 3.790520, norm: 0.3264, time(ms): 801.81, token/sec:653877.27, hellaswag_acc: 0.2556
Step:  1434, loss: 3.766831, norm: 0.3610, time(ms): 795.36, token/sec:659186.75, hellaswag_acc: 0.2556
Step:  1435, loss: 3.849421, norm: 0.4037, time(ms): 797.21, token/sec:657650.44, hellaswag_acc: 0.2556
Step:  1436, loss: 3.790035, norm: 0.4367, time(ms): 793.92, token/sec:660380.04, hellaswag_acc: 0.2556
Step:  1437, loss: 3.809160, norm: 0.4338, time(ms): 791.35, token/sec:662523.83, hellaswag_acc: 0.2556
Step:  1438, loss: 3.789476, norm: 0.4168, time(ms): 790.39, token/sec:663328.42, hellaswag_acc: 0.2556
Step:  1439, loss: 3.884238, norm: 0.3819, time(ms): 790.39, token/sec:663329.42, hellaswag_acc: 0.2556
Step:  1440, loss: 3.886065, norm: 0.3868, time(ms): 800.59, token/sec:654873.68, hellaswag_acc: 0.2556
Step:  1441, loss: 3.853717, norm: 0.3706, time(ms): 796.99, token/sec:657833.99, hellaswag_acc: 0.2556
Step:  1442, loss: 3.877278, norm: 0.3412, time(ms): 804.29, token/sec:651867.23, hellaswag_acc: 0.2556
Step:  1443, loss: 3.809404, norm: 0.3714, time(ms): 800.68, token/sec:654805.04, hellaswag_acc: 0.2556
Step:  1444, loss: 3.874010, norm: 0.4112, time(ms): 788.07, token/sec:665277.21, hellaswag_acc: 0.2556
Step:  1445, loss: 3.828778, norm: 0.4374, time(ms): 796.82, token/sec:657977.68, hellaswag_acc: 0.2556
Step:  1446, loss: 3.844056, norm: 0.4332, time(ms): 791.88, token/sec:662081.40, hellaswag_acc: 0.2556
Step:  1447, loss: 3.786674, norm: 0.4005, time(ms): 792.56, token/sec:661511.38, hellaswag_acc: 0.2556
Step:  1448, loss: 3.910833, norm: 0.4008, time(ms): 794.64, token/sec:659779.68, hellaswag_acc: 0.2556
Step:  1449, loss: 3.866601, norm: 0.3836, time(ms): 792.31, token/sec:661721.39, hellaswag_acc: 0.2556
Step:  1450, loss: 3.868929, norm: 0.3557, time(ms): 801.49, token/sec:654143.16, hellaswag_acc: 0.2556
Step:  1451, loss: 3.819293, norm: 0.3769, time(ms): 798.29, token/sec:656761.86, hellaswag_acc: 0.2556
Step:  1452, loss: 3.880861, norm: 0.3362, time(ms): 798.32, token/sec:656739.50, hellaswag_acc: 0.2556
Step:  1453, loss: 3.848898, norm: 0.3518, time(ms): 799.21, token/sec:656010.49, hellaswag_acc: 0.2556
Step:  1454, loss: 3.847623, norm: 0.3242, time(ms): 800.75, token/sec:654746.36, hellaswag_acc: 0.2556
Step:  1455, loss: 3.859224, norm: 0.3282, time(ms): 803.05, token/sec:652870.70, hellaswag_acc: 0.2556
Step:  1456, loss: 3.839901, norm: 0.3293, time(ms): 796.13, token/sec:658544.78, hellaswag_acc: 0.2556
Step:  1457, loss: 3.842445, norm: 0.3157, time(ms): 800.33, token/sec:655090.62, hellaswag_acc: 0.2556
Step:  1458, loss: 3.831365, norm: 0.2939, time(ms): 800.58, token/sec:654883.43, hellaswag_acc: 0.2556
Step:  1459, loss: 3.821313, norm: 0.3012, time(ms): 802.21, token/sec:653552.34, hellaswag_acc: 0.2556
Step:  1460, loss: 3.845650, norm: 0.3022, time(ms): 799.40, token/sec:655852.40, hellaswag_acc: 0.2556
Step:  1461, loss: 3.864146, norm: 0.3299, time(ms): 796.27, token/sec:658429.23, hellaswag_acc: 0.2556
Step:  1462, loss: 3.865338, norm: 0.3608, time(ms): 798.49, token/sec:656603.41, hellaswag_acc: 0.2556
Step:  1463, loss: 3.826838, norm: 0.3480, time(ms): 804.97, token/sec:651314.46, hellaswag_acc: 0.2556
Step:  1464, loss: 3.802522, norm: 0.3216, time(ms): 799.97, token/sec:655384.26, hellaswag_acc: 0.2556
Step:  1465, loss: 3.765594, norm: 0.3010, time(ms): 790.00, token/sec:663658.13, hellaswag_acc: 0.2556
Step:  1466, loss: 3.844850, norm: 0.3129, time(ms): 799.73, token/sec:655583.36, hellaswag_acc: 0.2556
Step:  1467, loss: 3.814084, norm: 0.3563, time(ms): 793.56, token/sec:660681.81, hellaswag_acc: 0.2556
Step:  1468, loss: 3.770017, norm: 0.3600, time(ms): 786.40, token/sec:666690.29, hellaswag_acc: 0.2556
Step:  1469, loss: 3.796110, norm: 0.3484, time(ms): 790.37, token/sec:663349.03, hellaswag_acc: 0.2556
Step:  1470, loss: 3.814218, norm: 0.3597, time(ms): 795.88, token/sec:658750.14, hellaswag_acc: 0.2556
Step:  1471, loss: 3.835563, norm: 0.3729, time(ms): 793.18, token/sec:660992.01, hellaswag_acc: 0.2556
Step:  1472, loss: 3.789415, norm: 0.3934, time(ms): 789.87, token/sec:663768.91, hellaswag_acc: 0.2556
Step:  1473, loss: 3.779343, norm: 0.4210, time(ms): 800.17, token/sec:655224.72, hellaswag_acc: 0.2556
Step:  1474, loss: 3.793452, norm: 0.3993, time(ms): 793.88, token/sec:660413.95, hellaswag_acc: 0.2556
Step:  1475, loss: 3.808463, norm: 0.3737, time(ms): 802.98, token/sec:652925.76, hellaswag_acc: 0.2556
Step:  1476, loss: 3.857937, norm: 0.4020, time(ms): 802.45, token/sec:653360.30, hellaswag_acc: 0.2556
Step:  1477, loss: 3.775780, norm: 0.3661, time(ms): 799.28, token/sec:655951.98, hellaswag_acc: 0.2556
Step:  1478, loss: 3.824419, norm: 0.3431, time(ms): 799.54, token/sec:655733.69, hellaswag_acc: 0.2556
Step:  1479, loss: 3.803057, norm: 0.3235, time(ms): 793.94, token/sec:660359.61, hellaswag_acc: 0.2556
Step:  1480, loss: 3.844862, norm: 0.3137, time(ms): 803.97, token/sec:652127.43, hellaswag_acc: 0.2556
Step:  1481, loss: 3.798832, norm: 0.3434, time(ms): 801.98, token/sec:653742.95, hellaswag_acc: 0.2556
Step:  1482, loss: 3.815599, norm: 0.3325, time(ms): 800.23, token/sec:655172.01, hellaswag_acc: 0.2556
Step:  1483, loss: 3.843407, norm: 0.2965, time(ms): 797.05, token/sec:657782.24, hellaswag_acc: 0.2556
Step:  1484, loss: 3.782914, norm: 0.3247, time(ms): 799.00, token/sec:656183.14, hellaswag_acc: 0.2556
Step:  1485, loss: 3.886681, norm: 0.3667, time(ms): 803.14, token/sec:652798.80, hellaswag_acc: 0.2556
Step:  1486, loss: 3.840935, norm: 0.4559, time(ms): 799.47, token/sec:655790.60, hellaswag_acc: 0.2556
Step:  1487, loss: 3.844374, norm: 0.4553, time(ms): 793.87, token/sec:660416.73, hellaswag_acc: 0.2556
Step:  1488, loss: 3.836977, norm: 0.4044, time(ms): 805.83, token/sec:650614.77, hellaswag_acc: 0.2556
Step:  1489, loss: 3.853487, norm: 0.3855, time(ms): 800.66, token/sec:654819.27, hellaswag_acc: 0.2556
Step:  1490, loss: 3.839273, norm: 0.3928, time(ms): 794.38, token/sec:659994.93, hellaswag_acc: 0.2556
Step:  1491, loss: 3.827866, norm: 0.3512, time(ms): 798.28, token/sec:656770.88, hellaswag_acc: 0.2556
Step:  1492, loss: 3.832249, norm: 0.3349, time(ms): 806.44, token/sec:650125.04, hellaswag_acc: 0.2556
Step:  1493, loss: 3.828926, norm: 0.3320, time(ms): 800.07, token/sec:655302.23, hellaswag_acc: 0.2556
Step:  1494, loss: 3.826201, norm: 0.3477, time(ms): 791.21, token/sec:662643.41, hellaswag_acc: 0.2556
Step:  1495, loss: 3.846032, norm: 0.3706, time(ms): 807.01, token/sec:649667.53, hellaswag_acc: 0.2556
Step:  1496, loss: 3.824744, norm: 0.3619, time(ms): 801.67, token/sec:653997.84, hellaswag_acc: 0.2556
Step:  1497, loss: 3.834127, norm: 0.3481, time(ms): 799.10, token/sec:656094.85, hellaswag_acc: 0.2556
Step:  1498, loss: 3.760543, norm: 0.3617, time(ms): 792.27, token/sec:661751.66, hellaswag_acc: 0.2556
Step:  1499, loss: 3.774112, norm: 0.4011, time(ms): 803.57, token/sec:652449.78, hellaswag_acc: 0.2556
rank 0 sample 0: Hello, I'm a language model, and I’ve just finished an initial study with a new and better way of working. This was the first language
rank 0 sample 1: Hello, I'm a language model, if someone is a language model, whether it be sound or sound, an audio model is only one or the same language
rank 0 sample 2: Hello, I'm a language model, but I really need to show that this is because I'm in my own language. I'm a language model because it
rank 0 sample 3: Hello, I'm a language model, a very formalized language. I know the number of words in a language model model (see Figure 1). The three
rank 1 sample 0: Hello, I'm a language model, for instance, where language is a metaphor of one of the words that the verb is spoken is an example of a word
rank 1 sample 1: Hello, I'm a language model, which I have had in my class read all of the articles on the topic (from class members to class members).

rank 1 sample 2: Hello, I'm a language model, I's talking about the future of the language model. It includes an overview of the language model from its perspective (but
rank 1 sample 3: Hello, I'm a language model, and I'm just starting here. My definition is like if it wasn't true, to it it was a simple,
Step:  1500, loss: 3.815780, norm: 0.3938, time(ms): 3791.55, token/sec:138277.89, val_loss: 3.8196, hellaswag_acc: 0.2556
Step:  1501, loss: 3.791266, norm: 0.3506, time(ms): 786.41, token/sec:666686.25, hellaswag_acc: 0.2556
Step:  1502, loss: 3.759322, norm: 0.3183, time(ms): 794.05, token/sec:660267.81, hellaswag_acc: 0.2556
Step:  1503, loss: 3.779934, norm: 0.3215, time(ms): 791.16, token/sec:662679.76, hellaswag_acc: 0.2556
Step:  1504, loss: 3.702036, norm: 0.3430, time(ms): 798.92, token/sec:656245.02, hellaswag_acc: 0.2556
Step:  1505, loss: 3.752824, norm: 0.3359, time(ms): 790.15, token/sec:663528.37, hellaswag_acc: 0.2556
Step:  1506, loss: 3.734907, norm: 0.3274, time(ms): 790.67, token/sec:663091.60, hellaswag_acc: 0.2556
Step:  1507, loss: 3.786319, norm: 0.3272, time(ms): 799.70, token/sec:655607.40, hellaswag_acc: 0.2556
Step:  1508, loss: 3.773757, norm: 0.3324, time(ms): 793.82, token/sec:660465.92, hellaswag_acc: 0.2556
Step:  1509, loss: 3.726914, norm: 0.3303, time(ms): 799.90, token/sec:655439.93, hellaswag_acc: 0.2556
Step:  1510, loss: 3.803135, norm: 0.3031, time(ms): 803.91, token/sec:652171.91, hellaswag_acc: 0.2556
Step:  1511, loss: 3.909386, norm: 0.3348, time(ms): 796.66, token/sec:658109.42, hellaswag_acc: 0.2556
Step:  1512, loss: 3.829805, norm: 0.4234, time(ms): 795.21, token/sec:659305.53, hellaswag_acc: 0.2556
Step:  1513, loss: 3.872849, norm: 0.4655, time(ms): 789.92, token/sec:663727.04, hellaswag_acc: 0.2556
Step:  1514, loss: 3.904140, norm: 0.4305, time(ms): 793.38, token/sec:660824.56, hellaswag_acc: 0.2556
Step:  1515, loss: 3.784947, norm: 0.3726, time(ms): 793.00, token/sec:661146.42, hellaswag_acc: 0.2556
Step:  1516, loss: 3.830474, norm: 0.3492, time(ms): 789.11, token/sec:664405.85, hellaswag_acc: 0.2556
Step:  1517, loss: 3.823136, norm: 0.3368, time(ms): 803.09, token/sec:652839.88, hellaswag_acc: 0.2556
Step:  1518, loss: 3.775286, norm: 0.3403, time(ms): 800.18, token/sec:655211.24, hellaswag_acc: 0.2556
Step:  1519, loss: 3.827690, norm: 0.3542, time(ms): 796.77, token/sec:658018.04, hellaswag_acc: 0.2556
Step:  1520, loss: 3.797469, norm: 0.3289, time(ms): 802.82, token/sec:653058.77, hellaswag_acc: 0.2556
Step:  1521, loss: 3.807559, norm: 0.3002, time(ms): 797.29, token/sec:657587.90, hellaswag_acc: 0.2556
Step:  1522, loss: 3.808209, norm: 0.3535, time(ms): 801.58, token/sec:654070.98, hellaswag_acc: 0.2556
Step:  1523, loss: 3.758389, norm: 0.3769, time(ms): 1294.52, token/sec:405006.64, hellaswag_acc: 0.2556
Step:  1524, loss: 3.814397, norm: 0.3515, time(ms): 766.30, token/sec:684182.23, hellaswag_acc: 0.2556
Step:  1525, loss: 3.834871, norm: 0.3311, time(ms): 784.64, token/sec:668192.83, hellaswag_acc: 0.2556
Step:  1526, loss: 3.760520, norm: 0.3059, time(ms): 799.92, token/sec:655421.76, hellaswag_acc: 0.2556
Step:  1527, loss: 3.864570, norm: 0.3540, time(ms): 787.16, token/sec:666048.56, hellaswag_acc: 0.2556
Step:  1528, loss: 3.801328, norm: 0.3630, time(ms): 784.05, token/sec:668693.68, hellaswag_acc: 0.2556
Step:  1529, loss: 3.848962, norm: 0.3796, time(ms): 786.06, token/sec:666982.49, hellaswag_acc: 0.2556
Step:  1530, loss: 3.797148, norm: 0.4025, time(ms): 796.39, token/sec:658329.29, hellaswag_acc: 0.2556
Step:  1531, loss: 3.763957, norm: 0.3914, time(ms): 789.50, token/sec:664075.20, hellaswag_acc: 0.2556
Step:  1532, loss: 3.781481, norm: 0.4567, time(ms): 785.43, token/sec:667513.55, hellaswag_acc: 0.2556
Step:  1533, loss: 3.786045, norm: 0.5045, time(ms): 793.75, token/sec:660518.49, hellaswag_acc: 0.2556
Step:  1534, loss: 3.821517, norm: 0.3867, time(ms): 792.85, token/sec:661266.91, hellaswag_acc: 0.2556
Step:  1535, loss: 3.753126, norm: 0.3594, time(ms): 797.51, token/sec:657409.20, hellaswag_acc: 0.2556
Step:  1536, loss: 3.766226, norm: 0.3258, time(ms): 793.67, token/sec:660583.77, hellaswag_acc: 0.2556
Step:  1537, loss: 3.751863, norm: 0.3227, time(ms): 802.19, token/sec:653574.10, hellaswag_acc: 0.2556
Step:  1538, loss: 3.697894, norm: 0.3242, time(ms): 805.66, token/sec:650759.36, hellaswag_acc: 0.2556
Step:  1539, loss: 3.729784, norm: 0.3311, time(ms): 790.69, token/sec:663078.60, hellaswag_acc: 0.2556
Step:  1540, loss: 3.741935, norm: 0.3935, time(ms): 794.58, token/sec:659830.17, hellaswag_acc: 0.2556
Step:  1541, loss: 3.750463, norm: 0.3605, time(ms): 792.61, token/sec:661472.18, hellaswag_acc: 0.2556
Step:  1542, loss: 3.873266, norm: 0.3480, time(ms): 798.58, token/sec:656529.11, hellaswag_acc: 0.2556
Step:  1543, loss: 3.833233, norm: 0.3481, time(ms): 793.07, token/sec:661084.61, hellaswag_acc: 0.2556
Step:  1544, loss: 3.780451, norm: 0.3422, time(ms): 793.43, token/sec:660787.03, hellaswag_acc: 0.2556
Step:  1545, loss: 3.768795, norm: 0.3449, time(ms): 792.10, token/sec:661892.28, hellaswag_acc: 0.2556
Step:  1546, loss: 3.763735, norm: 0.3279, time(ms): 791.33, token/sec:662543.19, hellaswag_acc: 0.2556
Step:  1547, loss: 3.752366, norm: 0.3216, time(ms): 789.95, token/sec:663696.59, hellaswag_acc: 0.2556
Step:  1548, loss: 3.795803, norm: 0.3081, time(ms): 801.19, token/sec:654386.49, hellaswag_acc: 0.2556
Step:  1549, loss: 3.794271, norm: 0.3132, time(ms): 798.29, token/sec:656761.47, hellaswag_acc: 0.2556
Step:  1550, loss: 3.797194, norm: 0.3392, time(ms): 789.88, token/sec:663752.88, hellaswag_acc: 0.2556
Step:  1551, loss: 3.849665, norm: 0.4186, time(ms): 790.77, token/sec:663013.02, hellaswag_acc: 0.2556
Step:  1552, loss: 3.782160, norm: 0.4220, time(ms): 789.00, token/sec:664497.40, hellaswag_acc: 0.2556
Step:  1553, loss: 3.829461, norm: 0.3942, time(ms): 790.66, token/sec:663104.99, hellaswag_acc: 0.2556
Step:  1554, loss: 3.836989, norm: 0.3500, time(ms): 794.51, token/sec:659886.99, hellaswag_acc: 0.2556
Step:  1555, loss: 3.752953, norm: 0.3457, time(ms): 800.16, token/sec:655232.13, hellaswag_acc: 0.2556
Step:  1556, loss: 3.789486, norm: 0.4188, time(ms): 805.79, token/sec:650649.61, hellaswag_acc: 0.2556
Step:  1557, loss: 3.818778, norm: 0.4371, time(ms): 794.93, token/sec:659539.45, hellaswag_acc: 0.2556
Step:  1558, loss: 3.812867, norm: 0.4181, time(ms): 800.58, token/sec:654885.38, hellaswag_acc: 0.2556
Step:  1559, loss: 3.740045, norm: 0.4700, time(ms): 800.95, token/sec:654580.89, hellaswag_acc: 0.2556
Step:  1560, loss: 3.721864, norm: 0.3967, time(ms): 802.95, token/sec:652950.76, hellaswag_acc: 0.2556
Step:  1561, loss: 3.771385, norm: 0.3602, time(ms): 790.80, token/sec:662987.64, hellaswag_acc: 0.2556
Step:  1562, loss: 3.788894, norm: 0.3234, time(ms): 798.97, token/sec:656206.84, hellaswag_acc: 0.2556
Step:  1563, loss: 3.753845, norm: 0.3099, time(ms): 806.23, token/sec:650294.04, hellaswag_acc: 0.2556
Step:  1564, loss: 3.741764, norm: 0.3166, time(ms): 803.72, token/sec:652329.78, hellaswag_acc: 0.2556
Step:  1565, loss: 3.791571, norm: 0.3343, time(ms): 789.60, token/sec:663992.38, hellaswag_acc: 0.2556
Step:  1566, loss: 3.777712, norm: 0.3536, time(ms): 799.81, token/sec:655516.72, hellaswag_acc: 0.2556
Step:  1567, loss: 3.808547, norm: 0.3452, time(ms): 799.45, token/sec:655814.06, hellaswag_acc: 0.2556
Step:  1568, loss: 3.779516, norm: 0.3354, time(ms): 795.54, token/sec:659034.04, hellaswag_acc: 0.2556
Step:  1569, loss: 3.787291, norm: 0.3346, time(ms): 795.12, token/sec:659385.00, hellaswag_acc: 0.2556
Step:  1570, loss: 3.747025, norm: 0.3092, time(ms): 793.19, token/sec:660986.05, hellaswag_acc: 0.2556
Step:  1571, loss: 3.779140, norm: 0.3397, time(ms): 799.75, token/sec:655563.23, hellaswag_acc: 0.2556
Step:  1572, loss: 3.807838, norm: 0.4026, time(ms): 802.84, token/sec:653044.03, hellaswag_acc: 0.2556
Step:  1573, loss: 3.793530, norm: 0.3762, time(ms): 797.53, token/sec:657393.28, hellaswag_acc: 0.2556
Step:  1574, loss: 3.739285, norm: 0.4023, time(ms): 801.36, token/sec:654244.95, hellaswag_acc: 0.2556
Step:  1575, loss: 3.796610, norm: 0.4491, time(ms): 799.99, token/sec:655368.24, hellaswag_acc: 0.2556
Step:  1576, loss: 3.749492, norm: 0.3887, time(ms): 798.44, token/sec:656641.64, hellaswag_acc: 0.2556
Step:  1577, loss: 3.768516, norm: 0.3767, time(ms): 795.57, token/sec:659009.55, hellaswag_acc: 0.2556
Step:  1578, loss: 3.732811, norm: 0.3303, time(ms): 791.10, token/sec:662732.48, hellaswag_acc: 0.2556
Step:  1579, loss: 3.790398, norm: 0.2972, time(ms): 789.78, token/sec:663844.05, hellaswag_acc: 0.2556
Step:  1580, loss: 3.797975, norm: 0.3030, time(ms): 789.42, token/sec:664146.20, hellaswag_acc: 0.2556
Step:  1581, loss: 3.836720, norm: 0.3281, time(ms): 794.39, token/sec:659990.77, hellaswag_acc: 0.2556
Step:  1582, loss: 3.755388, norm: 0.3270, time(ms): 795.55, token/sec:659023.96, hellaswag_acc: 0.2556
Step:  1583, loss: 3.787338, norm: 0.3142, time(ms): 808.09, token/sec:648795.98, hellaswag_acc: 0.2556
Step:  1584, loss: 3.768319, norm: 0.2994, time(ms): 787.30, token/sec:665928.95, hellaswag_acc: 0.2556
Step:  1585, loss: 3.759089, norm: 0.3144, time(ms): 791.14, token/sec:662698.13, hellaswag_acc: 0.2556
Step:  1586, loss: 3.761896, norm: 0.3062, time(ms): 791.27, token/sec:662590.90, hellaswag_acc: 0.2556
Step:  1587, loss: 3.758148, norm: 0.2952, time(ms): 794.40, token/sec:659982.85, hellaswag_acc: 0.2556
Step:  1588, loss: 3.775972, norm: 0.2929, time(ms): 794.55, token/sec:659856.30, hellaswag_acc: 0.2556
Step:  1589, loss: 3.808729, norm: 0.3231, time(ms): 790.36, token/sec:663355.43, hellaswag_acc: 0.2556
Step:  1590, loss: 3.779809, norm: 0.3704, time(ms): 800.63, token/sec:654847.35, hellaswag_acc: 0.2556
Step:  1591, loss: 3.773762, norm: 0.3524, time(ms): 804.78, token/sec:651468.44, hellaswag_acc: 0.2556
Step:  1592, loss: 3.843671, norm: 0.2867, time(ms): 799.65, token/sec:655643.17, hellaswag_acc: 0.2556
Step:  1593, loss: 3.737203, norm: 0.3161, time(ms): 800.55, token/sec:654911.52, hellaswag_acc: 0.2556
Step:  1594, loss: 3.812512, norm: 0.3037, time(ms): 800.31, token/sec:655104.08, hellaswag_acc: 0.2556
Step:  1595, loss: 3.770084, norm: 0.2975, time(ms): 801.99, token/sec:653732.84, hellaswag_acc: 0.2556
Step:  1596, loss: 3.743145, norm: 0.3138, time(ms): 797.79, token/sec:657172.07, hellaswag_acc: 0.2556
Step:  1597, loss: 3.735034, norm: 0.3319, time(ms): 798.77, token/sec:656371.36, hellaswag_acc: 0.2556
Step:  1598, loss: 3.927355, norm: 0.4205, time(ms): 799.65, token/sec:655645.71, hellaswag_acc: 0.2556
Step:  1599, loss: 3.784045, norm: 0.4907, time(ms): 804.31, token/sec:651847.71, hellaswag_acc: 0.2556
Step:  1600, loss: 3.757685, norm: 0.5079, time(ms): 796.99, token/sec:657838.12, hellaswag_acc: 0.2556
Step:  1601, loss: 3.754608, norm: 0.5063, time(ms): 792.94, token/sec:661196.32, hellaswag_acc: 0.2556
Step:  1602, loss: 3.760658, norm: 0.4602, time(ms): 805.27, token/sec:651069.56, hellaswag_acc: 0.2556
Step:  1603, loss: 3.718294, norm: 0.3828, time(ms): 804.35, token/sec:651818.35, hellaswag_acc: 0.2556
Step:  1604, loss: 3.723828, norm: 0.3321, time(ms): 794.76, token/sec:659680.13, hellaswag_acc: 0.2556
Step:  1605, loss: 3.738807, norm: 0.2841, time(ms): 801.48, token/sec:654152.89, hellaswag_acc: 0.2556
Step:  1606, loss: 3.758570, norm: 0.3080, time(ms): 795.80, token/sec:658819.61, hellaswag_acc: 0.2556
Step:  1607, loss: 3.801385, norm: 0.2963, time(ms): 807.38, token/sec:649369.21, hellaswag_acc: 0.2556
Step:  1608, loss: 3.749591, norm: 0.3418, time(ms): 795.31, token/sec:659226.66, hellaswag_acc: 0.2556
Step:  1609, loss: 3.812071, norm: 0.3616, time(ms): 794.62, token/sec:659798.09, hellaswag_acc: 0.2556
Step:  1610, loss: 3.728635, norm: 0.3954, time(ms): 806.18, token/sec:650338.85, hellaswag_acc: 0.2556
Step:  1611, loss: 3.782730, norm: 0.3951, time(ms): 802.42, token/sec:653381.85, hellaswag_acc: 0.2556
Step:  1612, loss: 3.755385, norm: 0.3192, time(ms): 791.30, token/sec:662567.95, hellaswag_acc: 0.2556
Step:  1613, loss: 3.807586, norm: 0.3292, time(ms): 804.41, token/sec:651769.66, hellaswag_acc: 0.2556
Step:  1614, loss: 3.779048, norm: 0.3418, time(ms): 804.55, token/sec:651653.00, hellaswag_acc: 0.2556
Step:  1615, loss: 3.726347, norm: 0.3366, time(ms): 794.90, token/sec:659567.94, hellaswag_acc: 0.2556
Step:  1616, loss: 3.794521, norm: 0.3297, time(ms): 797.93, token/sec:657059.55, hellaswag_acc: 0.2556
Step:  1617, loss: 3.819035, norm: 0.3064, time(ms): 805.86, token/sec:650594.55, hellaswag_acc: 0.2556
Step:  1618, loss: 3.783605, norm: 0.3161, time(ms): 801.28, token/sec:654316.59, hellaswag_acc: 0.2556
Step:  1619, loss: 3.775688, norm: 0.3181, time(ms): 791.08, token/sec:662746.46, hellaswag_acc: 0.2556
Step:  1620, loss: 3.736319, norm: 0.3489, time(ms): 797.42, token/sec:657484.09, hellaswag_acc: 0.2556
Step:  1621, loss: 3.730607, norm: 0.2989, time(ms): 791.97, token/sec:662008.45, hellaswag_acc: 0.2556
Step:  1622, loss: 3.753622, norm: 0.2934, time(ms): 798.71, token/sec:656419.17, hellaswag_acc: 0.2556
Step:  1623, loss: 3.757870, norm: 0.3025, time(ms): 789.85, token/sec:663784.94, hellaswag_acc: 0.2556
Step:  1624, loss: 3.741769, norm: 0.2783, time(ms): 796.98, token/sec:657842.06, hellaswag_acc: 0.2556
Step:  1625, loss: 3.719571, norm: 0.2870, time(ms): 790.08, token/sec:663591.44, hellaswag_acc: 0.2556
Step:  1626, loss: 3.762348, norm: 0.3077, time(ms): 789.14, token/sec:664380.36, hellaswag_acc: 0.2556
Step:  1627, loss: 3.773403, norm: 0.3205, time(ms): 792.41, token/sec:661639.36, hellaswag_acc: 0.2556
Step:  1628, loss: 3.844025, norm: 0.3364, time(ms): 791.74, token/sec:662194.05, hellaswag_acc: 0.2556
Step:  1629, loss: 3.765588, norm: 0.3395, time(ms): 806.43, token/sec:650137.73, hellaswag_acc: 0.2556
Step:  1630, loss: 3.732305, norm: 0.4014, time(ms): 802.44, token/sec:653367.68, hellaswag_acc: 0.2556
Step:  1631, loss: 3.705549, norm: 0.4013, time(ms): 792.56, token/sec:661516.16, hellaswag_acc: 0.2556
Step:  1632, loss: 3.729873, norm: 0.4149, time(ms): 796.32, token/sec:658391.77, hellaswag_acc: 0.2556
Step:  1633, loss: 3.819828, norm: 0.4495, time(ms): 808.98, token/sec:648083.92, hellaswag_acc: 0.2556
Step:  1634, loss: 3.747045, norm: 0.3483, time(ms): 800.94, token/sec:654588.29, hellaswag_acc: 0.2556
Step:  1635, loss: 3.770344, norm: 0.3501, time(ms): 794.91, token/sec:659557.45, hellaswag_acc: 0.2556
Step:  1636, loss: 3.756975, norm: 0.3411, time(ms): 802.57, token/sec:653258.01, hellaswag_acc: 0.2556
Step:  1637, loss: 3.762378, norm: 0.3657, time(ms): 800.48, token/sec:654967.50, hellaswag_acc: 0.2556
Step:  1638, loss: 3.657040, norm: 0.3680, time(ms): 800.38, token/sec:655044.96, hellaswag_acc: 0.2556
Step:  1639, loss: 3.739569, norm: 0.3806, time(ms): 789.45, token/sec:664114.10, hellaswag_acc: 0.2556
Step:  1640, loss: 3.698158, norm: 0.3756, time(ms): 791.68, token/sec:662249.29, hellaswag_acc: 0.2556
Step:  1641, loss: 3.727209, norm: 0.3668, time(ms): 788.38, token/sec:665016.67, hellaswag_acc: 0.2556
Step:  1642, loss: 3.733797, norm: 0.3670, time(ms): 792.34, token/sec:661698.29, hellaswag_acc: 0.2556
Step:  1643, loss: 3.784065, norm: 0.3961, time(ms): 797.24, token/sec:657625.26, hellaswag_acc: 0.2556
Step:  1644, loss: 3.771409, norm: 0.3621, time(ms): 794.32, token/sec:660042.28, hellaswag_acc: 0.2556
Step:  1645, loss: 3.704131, norm: 0.3538, time(ms): 800.30, token/sec:655111.89, hellaswag_acc: 0.2556
Step:  1646, loss: 3.787271, norm: 0.3521, time(ms): 806.24, token/sec:650284.81, hellaswag_acc: 0.2556
Step:  1647, loss: 3.798754, norm: 0.3393, time(ms): 793.13, token/sec:661033.14, hellaswag_acc: 0.2556
Step:  1648, loss: 3.772220, norm: 0.3547, time(ms): 796.06, token/sec:658606.31, hellaswag_acc: 0.2556
Step:  1649, loss: 3.762618, norm: 0.3089, time(ms): 802.66, token/sec:653190.49, hellaswag_acc: 0.2556
Step:  1650, loss: 3.843251, norm: 0.3177, time(ms): 806.75, token/sec:649877.58, hellaswag_acc: 0.2556
Step:  1651, loss: 3.728676, norm: 0.3470, time(ms): 794.42, token/sec:659962.05, hellaswag_acc: 0.2556
Step:  1652, loss: 3.771647, norm: 0.3725, time(ms): 795.37, token/sec:659171.93, hellaswag_acc: 0.2556
Step:  1653, loss: 3.740502, norm: 0.3426, time(ms): 805.38, token/sec:650981.48, hellaswag_acc: 0.2556
Step:  1654, loss: 3.740431, norm: 0.3520, time(ms): 803.97, token/sec:652126.66, hellaswag_acc: 0.2556
Step:  1655, loss: 3.742100, norm: 0.3162, time(ms): 791.86, token/sec:662100.34, hellaswag_acc: 0.2556
Step:  1656, loss: 3.773362, norm: 0.2756, time(ms): 801.51, token/sec:654122.15, hellaswag_acc: 0.2556
Step:  1657, loss: 3.762226, norm: 0.2904, time(ms): 805.07, token/sec:651236.54, hellaswag_acc: 0.2556
Step:  1658, loss: 3.723278, norm: 0.3055, time(ms): 799.51, token/sec:655758.91, hellaswag_acc: 0.2556
Step:  1659, loss: 3.688738, norm: 0.3296, time(ms): 795.45, token/sec:659110.68, hellaswag_acc: 0.2556
Step:  1660, loss: 3.724053, norm: 0.3297, time(ms): 802.73, token/sec:653135.00, hellaswag_acc: 0.2556
Step:  1661, loss: 3.726523, norm: 0.3227, time(ms): 799.17, token/sec:656037.89, hellaswag_acc: 0.2556
Step:  1662, loss: 3.750904, norm: 0.3204, time(ms): 804.21, token/sec:651931.58, hellaswag_acc: 0.2556
Step:  1663, loss: 3.734467, norm: 0.3170, time(ms): 788.57, token/sec:664859.64, hellaswag_acc: 0.2556
Step:  1664, loss: 3.756157, norm: 0.3139, time(ms): 792.91, token/sec:661216.00, hellaswag_acc: 0.2556
Step:  1665, loss: 3.740745, norm: 0.3180, time(ms): 795.08, token/sec:659415.45, hellaswag_acc: 0.2556
Step:  1666, loss: 3.736529, norm: 0.3286, time(ms): 797.56, token/sec:657367.14, hellaswag_acc: 0.2556
Step:  1667, loss: 3.717354, norm: 0.3122, time(ms): 799.61, token/sec:655676.21, hellaswag_acc: 0.2556
Step:  1668, loss: 3.731596, norm: 0.3034, time(ms): 795.69, token/sec:658908.25, hellaswag_acc: 0.2556
Step:  1669, loss: 3.704836, norm: 0.3143, time(ms): 795.40, token/sec:659148.81, hellaswag_acc: 0.2556
Step:  1670, loss: 3.715498, norm: 0.3129, time(ms): 791.48, token/sec:662412.07, hellaswag_acc: 0.2556
Step:  1671, loss: 3.713481, norm: 0.3239, time(ms): 791.35, token/sec:662524.03, hellaswag_acc: 0.2556
Step:  1672, loss: 3.711050, norm: 0.2832, time(ms): 790.85, token/sec:662938.27, hellaswag_acc: 0.2556
Step:  1673, loss: 3.686058, norm: 0.2750, time(ms): 795.49, token/sec:659075.71, hellaswag_acc: 0.2556
Step:  1674, loss: 3.756731, norm: 0.3010, time(ms): 800.36, token/sec:655061.54, hellaswag_acc: 0.2556
Step:  1675, loss: 3.679783, norm: 0.3288, time(ms): 802.10, token/sec:653644.23, hellaswag_acc: 0.2556
Step:  1676, loss: 3.673913, norm: 0.3276, time(ms): 800.58, token/sec:654887.72, hellaswag_acc: 0.2556
Step:  1677, loss: 3.744465, norm: 0.3217, time(ms): 796.24, token/sec:658452.10, hellaswag_acc: 0.2556
Step:  1678, loss: 3.731049, norm: 0.3294, time(ms): 801.15, token/sec:654420.96, hellaswag_acc: 0.2556
Step:  1679, loss: 3.706164, norm: 0.4492, time(ms): 801.98, token/sec:653743.92, hellaswag_acc: 0.2556
Step:  1680, loss: 3.774897, norm: 0.5169, time(ms): 799.63, token/sec:655666.43, hellaswag_acc: 0.2556
Step:  1681, loss: 3.799319, norm: 0.4177, time(ms): 797.73, token/sec:657228.04, hellaswag_acc: 0.2556
Step:  1682, loss: 3.765840, norm: 0.4236, time(ms): 797.48, token/sec:657432.39, hellaswag_acc: 0.2556
Step:  1683, loss: 3.742178, norm: 0.3590, time(ms): 804.48, token/sec:651713.45, hellaswag_acc: 0.2556
Step:  1684, loss: 3.757178, norm: 0.3732, time(ms): 800.62, token/sec:654848.91, hellaswag_acc: 0.2556
Step:  1685, loss: 3.770378, norm: 0.3387, time(ms): 793.65, token/sec:660602.42, hellaswag_acc: 0.2556
Step:  1686, loss: 3.742700, norm: 0.3402, time(ms): 797.91, token/sec:657077.22, hellaswag_acc: 0.2556
Step:  1687, loss: 3.741697, norm: 0.3289, time(ms): 807.42, token/sec:649338.73, hellaswag_acc: 0.2556
Step:  1688, loss: 3.783372, norm: 0.3418, time(ms): 800.54, token/sec:654915.61, hellaswag_acc: 0.2556
Step:  1689, loss: 3.739785, norm: 0.3284, time(ms): 789.19, token/sec:664336.61, hellaswag_acc: 0.2556
Step:  1690, loss: 3.922177, norm: 0.3377, time(ms): 806.69, token/sec:649921.75, hellaswag_acc: 0.2556
Step:  1691, loss: 3.742128, norm: 0.3784, time(ms): 803.78, token/sec:652281.41, hellaswag_acc: 0.2556
Step:  1692, loss: 3.780281, norm: 0.3725, time(ms): 798.31, token/sec:656746.56, hellaswag_acc: 0.2556
Step:  1693, loss: 3.725746, norm: 0.4231, time(ms): 792.04, token/sec:661944.88, hellaswag_acc: 0.2556
Step:  1694, loss: 3.827418, norm: 0.4703, time(ms): 806.12, token/sec:650386.16, hellaswag_acc: 0.2556
Step:  1695, loss: 3.748553, norm: 0.4696, time(ms): 802.91, token/sec:652983.53, hellaswag_acc: 0.2556
Step:  1696, loss: 3.796300, norm: 0.3560, time(ms): 789.84, token/sec:663793.96, hellaswag_acc: 0.2556
Step:  1697, loss: 3.788395, norm: 0.3707, time(ms): 807.24, token/sec:649484.86, hellaswag_acc: 0.2556
Step:  1698, loss: 3.770857, norm: 0.3316, time(ms): 800.82, token/sec:654685.73, hellaswag_acc: 0.2556
Step:  1699, loss: 3.770611, norm: 0.3099, time(ms): 800.51, token/sec:654944.87, hellaswag_acc: 0.2556
Step:  1700, loss: 3.739395, norm: 0.2932, time(ms): 795.77, token/sec:658842.11, hellaswag_acc: 0.2556
Step:  1701, loss: 3.722656, norm: 0.2899, time(ms): 804.24, token/sec:651908.78, hellaswag_acc: 0.2556
Step:  1702, loss: 3.700873, norm: 0.2919, time(ms): 799.03, token/sec:656156.12, hellaswag_acc: 0.2556
Step:  1703, loss: 3.707309, norm: 0.3065, time(ms): 794.99, token/sec:659492.38, hellaswag_acc: 0.2556
Step:  1704, loss: 3.750614, norm: 0.2877, time(ms): 803.34, token/sec:652639.16, hellaswag_acc: 0.2556
Step:  1705, loss: 3.632915, norm: 0.2866, time(ms): 801.65, token/sec:654008.73, hellaswag_acc: 0.2556
Step:  1706, loss: 3.661953, norm: 0.2868, time(ms): 794.75, token/sec:659692.99, hellaswag_acc: 0.2556
Step:  1707, loss: 3.721245, norm: 0.2676, time(ms): 801.39, token/sec:654224.51, hellaswag_acc: 0.2556
Step:  1708, loss: 3.723479, norm: 0.2583, time(ms): 802.43, token/sec:653373.31, hellaswag_acc: 0.2556
Step:  1709, loss: 3.686922, norm: 0.3289, time(ms): 801.01, token/sec:654533.93, hellaswag_acc: 0.2556
Step:  1710, loss: 3.680240, norm: 0.3888, time(ms): 788.84, token/sec:664630.56, hellaswag_acc: 0.2556
Step:  1711, loss: 3.680851, norm: 0.4011, time(ms): 792.73, token/sec:661368.53, hellaswag_acc: 0.2556
Step:  1712, loss: 3.703693, norm: 0.3497, time(ms): 790.18, token/sec:663501.94, hellaswag_acc: 0.2556
Step:  1713, loss: 3.740471, norm: 0.3083, time(ms): 793.70, token/sec:660560.95, hellaswag_acc: 0.2556
Step:  1714, loss: 3.758212, norm: 0.3646, time(ms): 1277.18, token/sec:410505.40, hellaswag_acc: 0.2556
Step:  1715, loss: 3.738848, norm: 0.2994, time(ms): 799.49, token/sec:655780.43, hellaswag_acc: 0.2556
Step:  1716, loss: 3.804054, norm: 0.6559, time(ms): 792.44, token/sec:661612.49, hellaswag_acc: 0.2556
Step:  1717, loss: 3.699612, norm: 0.3389, time(ms): 785.93, token/sec:667089.32, hellaswag_acc: 0.2556
Step:  1718, loss: 3.810674, norm: 0.3125, time(ms): 792.99, token/sec:661153.78, hellaswag_acc: 0.2556
Step:  1719, loss: 3.718441, norm: 0.3357, time(ms): 803.62, token/sec:652411.84, hellaswag_acc: 0.2556
Step:  1720, loss: 3.714341, norm: 0.3398, time(ms): 789.56, token/sec:664022.26, hellaswag_acc: 0.2556
Step:  1721, loss: 3.745950, norm: 0.3754, time(ms): 788.89, token/sec:664589.18, hellaswag_acc: 0.2556
Step:  1722, loss: 3.742633, norm: 0.4508, time(ms): 794.48, token/sec:659914.92, hellaswag_acc: 0.2556
Step:  1723, loss: 3.728638, norm: 0.4315, time(ms): 805.16, token/sec:651161.72, hellaswag_acc: 0.2556
Step:  1724, loss: 3.747814, norm: 0.3342, time(ms): 798.58, token/sec:656527.15, hellaswag_acc: 0.2556
Step:  1725, loss: 3.754792, norm: 0.3404, time(ms): 797.25, token/sec:657623.10, hellaswag_acc: 0.2556
Step:  1726, loss: 3.724357, norm: 0.3363, time(ms): 804.09, token/sec:652024.95, hellaswag_acc: 0.2556
Step:  1727, loss: 3.703322, norm: 0.3310, time(ms): 800.86, token/sec:654652.41, hellaswag_acc: 0.2556
Step:  1728, loss: 3.686060, norm: 0.3213, time(ms): 796.27, token/sec:658431.99, hellaswag_acc: 0.2556
Step:  1729, loss: 3.698542, norm: 0.3280, time(ms): 802.89, token/sec:652999.04, hellaswag_acc: 0.2556
Step:  1730, loss: 3.641811, norm: 0.3517, time(ms): 801.05, token/sec:654504.52, hellaswag_acc: 0.2556
Step:  1731, loss: 3.692250, norm: 0.3782, time(ms): 797.86, token/sec:657118.65, hellaswag_acc: 0.2556
Step:  1732, loss: 3.699475, norm: 0.3450, time(ms): 802.04, token/sec:653690.28, hellaswag_acc: 0.2556
Step:  1733, loss: 3.585090, norm: 0.3192, time(ms): 793.76, token/sec:660511.74, hellaswag_acc: 0.2556
Step:  1734, loss: 3.574729, norm: 0.3046, time(ms): 804.35, token/sec:651819.12, hellaswag_acc: 0.2556
Step:  1735, loss: 3.586691, norm: 0.3083, time(ms): 801.65, token/sec:654013.01, hellaswag_acc: 0.2556
Step:  1736, loss: 3.636069, norm: 0.2810, time(ms): 797.86, token/sec:657116.30, hellaswag_acc: 0.2556
Step:  1737, loss: 3.684429, norm: 0.3237, time(ms): 788.06, token/sec:665289.89, hellaswag_acc: 0.2556
Step:  1738, loss: 3.624594, norm: 0.3685, time(ms): 791.08, token/sec:662747.86, hellaswag_acc: 0.2556
Step:  1739, loss: 3.656693, norm: 0.4354, time(ms): 791.10, token/sec:662731.88, hellaswag_acc: 0.2556
Step:  1740, loss: 3.635233, norm: 0.4254, time(ms): 791.18, token/sec:662668.38, hellaswag_acc: 0.2556
Step:  1741, loss: 3.675578, norm: 0.3627, time(ms): 795.46, token/sec:659103.76, hellaswag_acc: 0.2556
Step:  1742, loss: 3.734983, norm: 0.4050, time(ms): 800.52, token/sec:654932.58, hellaswag_acc: 0.2556
Step:  1743, loss: 3.749691, norm: 0.3711, time(ms): 803.50, token/sec:652509.21, hellaswag_acc: 0.2556
Step:  1744, loss: 3.744526, norm: 0.3316, time(ms): 798.50, token/sec:656592.82, hellaswag_acc: 0.2556
Step:  1745, loss: 3.764027, norm: 0.3550, time(ms): 796.89, token/sec:657919.02, hellaswag_acc: 0.2556
Step:  1746, loss: 3.770636, norm: 0.3426, time(ms): 802.84, token/sec:653043.45, hellaswag_acc: 0.2556
Step:  1747, loss: 3.854243, norm: 2.9658, time(ms): 797.55, token/sec:657375.40, hellaswag_acc: 0.2556
Step:  1748, loss: 3.777856, norm: 0.4645, time(ms): 800.22, token/sec:655183.72, hellaswag_acc: 0.2556
Step:  1749, loss: 3.785251, norm: 0.4940, time(ms): 799.29, token/sec:655943.17, hellaswag_acc: 0.2556
rank 0 sample 0: Hello, I'm a language model, I'm doing it. In a sentence structure where you specify a term from "to." [See "A" for
rank 0 sample 1: Hello, I'm a language model, and here's a nice idea, from the very elementary education program: an approach to teaching a new language to a new
rank 0 sample 2: Hello, I'm a language model, but I won't put your computer to the left.
In my experience, I used the "U" approach,
rank 0 sample 3: Hello, I'm a language model, and as a teacher, I think I've decided to make a teaching language for students of any language as a second language
rank 1 sample 0: Hello, I'm a language model, and you're using it in a nontechnical manner, to define the language at the interface between words and sentences.

rank 1 sample 1: Hello, I'm a language model, you're trying to get a good picture of what's right, for example, is like the concept that's right,
rank 1 sample 2: Hello, I'm a language model, and like a human, I'm a language model, and all I think is a human. So it is not all
rank 1 sample 3: Hello, I'm a language model, you can use an object you want to set up like x?t = p?ct - ?
[This is
Step:  1750, loss: 3.782921, norm: 0.6124, time(ms): 3790.33, token/sec:138322.54, val_loss: 3.7603, hellaswag_acc: 0.2556
Step:  1751, loss: 3.800026, norm: 0.8972, time(ms): 794.15, token/sec:660183.76, hellaswag_acc: 0.2556
Step:  1752, loss: 3.802613, norm: 0.6896, time(ms): 788.59, token/sec:664846.17, hellaswag_acc: 0.2556
Step:  1753, loss: 3.793366, norm: 0.4921, time(ms): 804.72, token/sec:651514.76, hellaswag_acc: 0.2556
Step:  1754, loss: 3.816111, norm: 0.3748, time(ms): 796.15, token/sec:658529.39, hellaswag_acc: 0.2556
Step:  1755, loss: 3.780599, norm: 0.3712, time(ms): 791.90, token/sec:662065.65, hellaswag_acc: 0.2556
Step:  1756, loss: 3.819198, norm: 0.3700, time(ms): 789.22, token/sec:664315.33, hellaswag_acc: 0.2556
Step:  1757, loss: 3.774045, norm: 0.3139, time(ms): 788.15, token/sec:665212.41, hellaswag_acc: 0.2556
Step:  1758, loss: 3.740644, norm: 0.3083, time(ms): 796.06, token/sec:658603.36, hellaswag_acc: 0.2556
Step:  1759, loss: 3.775349, norm: 0.3074, time(ms): 801.80, token/sec:653891.07, hellaswag_acc: 0.2556
Step:  1760, loss: 3.802469, norm: 0.2862, time(ms): 797.97, token/sec:657027.55, hellaswag_acc: 0.2556
Step:  1761, loss: 3.776202, norm: 0.3115, time(ms): 801.42, token/sec:654196.48, hellaswag_acc: 0.2556
Step:  1762, loss: 3.723916, norm: 0.3389, time(ms): 800.54, token/sec:654913.86, hellaswag_acc: 0.2556
Step:  1763, loss: 3.744667, norm: 0.3379, time(ms): 796.47, token/sec:658262.29, hellaswag_acc: 0.2556
Step:  1764, loss: 3.716154, norm: 0.3347, time(ms): 800.64, token/sec:654832.92, hellaswag_acc: 0.2556
Step:  1765, loss: 3.715176, norm: 0.2953, time(ms): 802.80, token/sec:653070.99, hellaswag_acc: 0.2556
Step:  1766, loss: 3.716635, norm: 0.2959, time(ms): 794.78, token/sec:659665.09, hellaswag_acc: 0.2556
Step:  1767, loss: 3.705673, norm: 0.2665, time(ms): 803.15, token/sec:652790.47, hellaswag_acc: 0.2556
Step:  1768, loss: 3.667615, norm: 0.2673, time(ms): 801.25, token/sec:654334.50, hellaswag_acc: 0.2556
Step:  1769, loss: 3.692935, norm: 0.2741, time(ms): 798.56, token/sec:656541.66, hellaswag_acc: 0.2556
Step:  1770, loss: 3.700778, norm: 0.2520, time(ms): 800.06, token/sec:655307.89, hellaswag_acc: 0.2556
Step:  1771, loss: 3.712957, norm: 0.2792, time(ms): 796.96, token/sec:657856.23, hellaswag_acc: 0.2556
Step:  1772, loss: 3.699228, norm: 0.2545, time(ms): 804.04, token/sec:652068.06, hellaswag_acc: 0.2556
Step:  1773, loss: 3.709925, norm: 0.2766, time(ms): 800.01, token/sec:655350.27, hellaswag_acc: 0.2556
Step:  1774, loss: 3.769638, norm: 0.3052, time(ms): 794.06, token/sec:660261.27, hellaswag_acc: 0.2556
Step:  1775, loss: 3.610098, norm: 0.2937, time(ms): 797.30, token/sec:657582.00, hellaswag_acc: 0.2556
Step:  1776, loss: 3.569782, norm: 0.2772, time(ms): 807.87, token/sec:648975.96, hellaswag_acc: 0.2556
Step:  1777, loss: 3.607983, norm: 0.2914, time(ms): 800.06, token/sec:655307.50, hellaswag_acc: 0.2556
Step:  1778, loss: 3.573494, norm: 0.2765, time(ms): 791.05, token/sec:662771.83, hellaswag_acc: 0.2556
Step:  1779, loss: 3.624002, norm: 0.3174, time(ms): 806.28, token/sec:650252.50, hellaswag_acc: 0.2556
Step:  1780, loss: 3.634643, norm: 0.3150, time(ms): 802.40, token/sec:653400.68, hellaswag_acc: 0.2556
Step:  1781, loss: 3.615545, norm: 0.3091, time(ms): 789.33, token/sec:664222.03, hellaswag_acc: 0.2556
Step:  1782, loss: 3.549609, norm: 0.2842, time(ms): 800.52, token/sec:654932.58, hellaswag_acc: 0.2556
Step:  1783, loss: 3.579075, norm: 0.2924, time(ms): 807.02, token/sec:649660.82, hellaswag_acc: 0.2556
Step:  1784, loss: 3.494545, norm: 0.3076, time(ms): 803.16, token/sec:652783.49, hellaswag_acc: 0.2556
Step:  1785, loss: 3.558432, norm: 0.3075, time(ms): 783.48, token/sec:669178.60, hellaswag_acc: 0.2556
Step:  1786, loss: 3.582453, norm: 0.2911, time(ms): 788.29, token/sec:665096.92, hellaswag_acc: 0.2556
Step:  1787, loss: 3.735341, norm: 0.2869, time(ms): 795.26, token/sec:659264.81, hellaswag_acc: 0.2556
Step:  1788, loss: 3.680438, norm: 0.3007, time(ms): 793.32, token/sec:660877.79, hellaswag_acc: 0.2556
Step:  1789, loss: 3.713354, norm: 0.3161, time(ms): 795.44, token/sec:659115.82, hellaswag_acc: 0.2556
Step:  1790, loss: 3.760619, norm: 0.3380, time(ms): 792.29, token/sec:661734.93, hellaswag_acc: 0.2556
Step:  1791, loss: 3.754489, norm: 0.3029, time(ms): 791.11, token/sec:662726.09, hellaswag_acc: 0.2556
Step:  1792, loss: 3.705111, norm: 0.2800, time(ms): 797.05, token/sec:657786.57, hellaswag_acc: 0.2556
Step:  1793, loss: 3.793691, norm: 0.2845, time(ms): 794.95, token/sec:659519.87, hellaswag_acc: 0.2556
Step:  1794, loss: 3.719990, norm: 0.2895, time(ms): 796.20, token/sec:658490.74, hellaswag_acc: 0.2556
Step:  1795, loss: 3.771389, norm: 0.3692, time(ms): 789.77, token/sec:663850.47, hellaswag_acc: 0.2556
Step:  1796, loss: 3.743252, norm: 0.3638, time(ms): 789.56, token/sec:664026.27, hellaswag_acc: 0.2556
Step:  1797, loss: 3.744115, norm: 0.4268, time(ms): 785.51, token/sec:667446.49, hellaswag_acc: 0.2556
Step:  1798, loss: 3.765953, norm: 0.4143, time(ms): 796.82, token/sec:657972.56, hellaswag_acc: 0.2556
Step:  1799, loss: 3.806183, norm: 0.3967, time(ms): 805.15, token/sec:651169.04, hellaswag_acc: 0.2556
Step:  1800, loss: 3.785900, norm: 0.3401, time(ms): 802.36, token/sec:653428.44, hellaswag_acc: 0.2556
Step:  1801, loss: 3.767903, norm: 0.3781, time(ms): 799.73, token/sec:655583.55, hellaswag_acc: 0.2556
Step:  1802, loss: 3.753429, norm: 0.4203, time(ms): 793.17, token/sec:661002.54, hellaswag_acc: 0.2556
Step:  1803, loss: 3.723191, norm: 0.3458, time(ms): 799.13, token/sec:656072.34, hellaswag_acc: 0.2556
Step:  1804, loss: 3.832576, norm: 0.3262, time(ms): 807.60, token/sec:649193.99, hellaswag_acc: 0.2556
Step:  1805, loss: 3.746005, norm: 0.3524, time(ms): 800.17, token/sec:655224.32, hellaswag_acc: 0.2556
Step:  1806, loss: 3.725441, norm: 0.3246, time(ms): 788.80, token/sec:664666.52, hellaswag_acc: 0.2556
Step:  1807, loss: 3.753426, norm: 0.3122, time(ms): 802.46, token/sec:653353.31, hellaswag_acc: 0.2556
Step:  1808, loss: 3.728889, norm: 0.3259, time(ms): 808.22, token/sec:648691.86, hellaswag_acc: 0.2556
Step:  1809, loss: 3.769944, norm: 0.4109, time(ms): 799.61, token/sec:655680.31, hellaswag_acc: 0.2556
Step:  1810, loss: 3.708533, norm: 0.4268, time(ms): 787.31, token/sec:665921.89, hellaswag_acc: 0.2556
Step:  1811, loss: 3.685581, norm: 0.3827, time(ms): 792.15, token/sec:661856.62, hellaswag_acc: 0.2556
Step:  1812, loss: 3.699305, norm: 0.3624, time(ms): 787.83, token/sec:665483.57, hellaswag_acc: 0.2556
Step:  1813, loss: 3.694054, norm: 0.3878, time(ms): 791.05, token/sec:662777.23, hellaswag_acc: 0.2556
Step:  1814, loss: 3.721871, norm: 0.3338, time(ms): 794.20, token/sec:660149.87, hellaswag_acc: 0.2556
Step:  1815, loss: 3.693521, norm: 0.3191, time(ms): 800.84, token/sec:654673.26, hellaswag_acc: 0.2556
Step:  1816, loss: 3.673141, norm: 0.3081, time(ms): 804.84, token/sec:651422.70, hellaswag_acc: 0.2556
Step:  1817, loss: 3.643364, norm: 0.3111, time(ms): 799.33, token/sec:655913.04, hellaswag_acc: 0.2556
Step:  1818, loss: 3.697835, norm: 0.3347, time(ms): 794.14, token/sec:660193.67, hellaswag_acc: 0.2556
Step:  1819, loss: 3.703779, norm: 0.3296, time(ms): 802.48, token/sec:653336.42, hellaswag_acc: 0.2556
Step:  1820, loss: 3.622945, norm: 0.2925, time(ms): 805.39, token/sec:650971.65, hellaswag_acc: 0.2556
Step:  1821, loss: 3.596407, norm: 0.2833, time(ms): 789.07, token/sec:664434.56, hellaswag_acc: 0.2556
Step:  1822, loss: 3.566169, norm: 0.2912, time(ms): 800.10, token/sec:655280.95, hellaswag_acc: 0.2556
Step:  1823, loss: 3.558646, norm: 0.3096, time(ms): 797.84, token/sec:657130.63, hellaswag_acc: 0.2556
Step:  1824, loss: 3.578929, norm: 0.3139, time(ms): 789.42, token/sec:664142.59, hellaswag_acc: 0.2556
Step:  1825, loss: 3.600401, norm: 0.3021, time(ms): 801.12, token/sec:654447.05, hellaswag_acc: 0.2556
Step:  1826, loss: 3.520363, norm: 0.3304, time(ms): 787.73, token/sec:665570.79, hellaswag_acc: 0.2556
Step:  1827, loss: 3.535070, norm: 0.3062, time(ms): 784.35, token/sec:668435.74, hellaswag_acc: 0.2556
Step:  1828, loss: 3.560281, norm: 0.3502, time(ms): 800.37, token/sec:655054.52, hellaswag_acc: 0.2556
Step:  1829, loss: 3.600544, norm: 0.3374, time(ms): 793.62, token/sec:660629.02, hellaswag_acc: 0.2556
Step:  1830, loss: 3.628027, norm: 0.3126, time(ms): 793.97, token/sec:660333.43, hellaswag_acc: 0.2556
Step:  1831, loss: 3.525975, norm: 0.3138, time(ms): 795.06, token/sec:659430.48, hellaswag_acc: 0.2556
Step:  1832, loss: 3.642615, norm: 0.3302, time(ms): 792.88, token/sec:661244.44, hellaswag_acc: 0.2556
Step:  1833, loss: 3.718120, norm: 0.3454, time(ms): 791.34, token/sec:662533.41, hellaswag_acc: 0.2556
Step:  1834, loss: 3.860106, norm: 0.3216, time(ms): 790.30, token/sec:663407.06, hellaswag_acc: 0.2556
Step:  1835, loss: 3.770947, norm: 0.3514, time(ms): 792.90, token/sec:661231.31, hellaswag_acc: 0.2556
Step:  1836, loss: 3.710380, norm: 0.3534, time(ms): 794.32, token/sec:660044.46, hellaswag_acc: 0.2556
Step:  1837, loss: 3.755752, norm: 0.3822, time(ms): 796.69, token/sec:658086.57, hellaswag_acc: 0.2556
Step:  1838, loss: 3.689747, norm: 0.3728, time(ms): 801.44, token/sec:654186.17, hellaswag_acc: 0.2556
Step:  1839, loss: 3.787141, norm: 0.3837, time(ms): 802.42, token/sec:653379.71, hellaswag_acc: 0.2556
Step:  1840, loss: 3.749808, norm: 0.3386, time(ms): 800.10, token/sec:655276.85, hellaswag_acc: 0.2556
Step:  1841, loss: 3.705325, norm: 0.3304, time(ms): 792.22, token/sec:661797.66, hellaswag_acc: 0.2556
Step:  1842, loss: 3.722475, norm: 0.2991, time(ms): 801.49, token/sec:654138.30, hellaswag_acc: 0.2556
Step:  1843, loss: 3.726140, norm: 0.2975, time(ms): 804.47, token/sec:651722.53, hellaswag_acc: 0.2556
Step:  1844, loss: 3.755884, norm: 0.2792, time(ms): 799.67, token/sec:655631.44, hellaswag_acc: 0.2556
Step:  1845, loss: 3.691903, norm: 0.2962, time(ms): 797.64, token/sec:657298.18, hellaswag_acc: 0.2556
Step:  1846, loss: 3.700565, norm: 0.3030, time(ms): 799.95, token/sec:655400.47, hellaswag_acc: 0.2556
Step:  1847, loss: 3.744897, norm: 0.3019, time(ms): 801.64, token/sec:654016.70, hellaswag_acc: 0.2556
Step:  1848, loss: 3.717144, norm: 0.2888, time(ms): 798.28, token/sec:656774.81, hellaswag_acc: 0.2556
Step:  1849, loss: 3.685369, norm: 0.3157, time(ms): 799.65, token/sec:655650.79, hellaswag_acc: 0.2556
Step:  1850, loss: 3.703864, norm: 0.3296, time(ms): 802.79, token/sec:653080.11, hellaswag_acc: 0.2556
Step:  1851, loss: 3.677497, norm: 0.3279, time(ms): 795.63, token/sec:658956.43, hellaswag_acc: 0.2556
Step:  1852, loss: 3.740137, norm: 0.3155, time(ms): 794.47, token/sec:659920.46, hellaswag_acc: 0.2556
Step:  1853, loss: 3.736835, norm: 0.2979, time(ms): 792.37, token/sec:661672.81, hellaswag_acc: 0.2556
Step:  1854, loss: 3.687024, norm: 0.2900, time(ms): 792.29, token/sec:661737.52, hellaswag_acc: 0.2556
Step:  1855, loss: 3.677360, norm: 0.2961, time(ms): 790.27, token/sec:663425.88, hellaswag_acc: 0.2556
Step:  1856, loss: 3.660163, norm: 0.2809, time(ms): 791.12, token/sec:662716.11, hellaswag_acc: 0.2556
Step:  1857, loss: 3.678566, norm: 0.3180, time(ms): 793.00, token/sec:661146.23, hellaswag_acc: 0.2556
Step:  1858, loss: 3.689869, norm: 0.3422, time(ms): 794.14, token/sec:660197.44, hellaswag_acc: 0.2556
Step:  1859, loss: 3.645977, norm: 0.3031, time(ms): 794.44, token/sec:659948.78, hellaswag_acc: 0.2556
Step:  1860, loss: 3.627578, norm: 0.3111, time(ms): 785.27, token/sec:667654.00, hellaswag_acc: 0.2556
Step:  1861, loss: 3.675193, norm: 0.2949, time(ms): 791.66, token/sec:662265.44, hellaswag_acc: 0.2556
Step:  1862, loss: 3.734330, norm: 0.3538, time(ms): 794.09, token/sec:660239.26, hellaswag_acc: 0.2556
Step:  1863, loss: 3.688508, norm: 0.3957, time(ms): 793.53, token/sec:660700.87, hellaswag_acc: 0.2556
Step:  1864, loss: 3.687096, norm: 0.3571, time(ms): 794.47, token/sec:659925.02, hellaswag_acc: 0.2556
Step:  1865, loss: 3.734651, norm: 0.3270, time(ms): 796.05, token/sec:658609.86, hellaswag_acc: 0.2556
Step:  1866, loss: 3.629875, norm: 0.3285, time(ms): 802.63, token/sec:653214.93, hellaswag_acc: 0.2556
Step:  1867, loss: 3.544577, norm: 0.2955, time(ms): 802.87, token/sec:653019.99, hellaswag_acc: 0.2556
Step:  1868, loss: 3.560744, norm: 0.3165, time(ms): 793.63, token/sec:660618.10, hellaswag_acc: 0.2556
Step:  1869, loss: 3.558845, norm: 0.3095, time(ms): 802.08, token/sec:653658.41, hellaswag_acc: 0.2556
Step:  1870, loss: 3.581591, norm: 0.2770, time(ms): 800.83, token/sec:654680.28, hellaswag_acc: 0.2556
Step:  1871, loss: 3.520431, norm: 0.2830, time(ms): 801.83, token/sec:653865.99, hellaswag_acc: 0.2556
Step:  1872, loss: 3.551648, norm: 0.2875, time(ms): 795.90, token/sec:658738.70, hellaswag_acc: 0.2556
Step:  1873, loss: 3.575250, norm: 0.2902, time(ms): 800.19, token/sec:655205.39, hellaswag_acc: 0.2556
Step:  1874, loss: 3.558806, norm: 0.3063, time(ms): 803.66, token/sec:652373.71, hellaswag_acc: 0.2556
Step:  1875, loss: 3.585392, norm: 0.3212, time(ms): 797.06, token/sec:657775.75, hellaswag_acc: 0.2556
Step:  1876, loss: 3.587627, norm: 0.3396, time(ms): 795.81, token/sec:658808.36, hellaswag_acc: 0.2556
Step:  1877, loss: 3.575179, norm: 0.3283, time(ms): 803.84, token/sec:652229.75, hellaswag_acc: 0.2556
Step:  1878, loss: 3.645591, norm: 0.3570, time(ms): 803.83, token/sec:652234.39, hellaswag_acc: 0.2556
Step:  1879, loss: 3.773601, norm: 0.3924, time(ms): 789.97, token/sec:663681.57, hellaswag_acc: 0.2556
Step:  1880, loss: 3.723754, norm: 0.3818, time(ms): 798.17, token/sec:656860.34, hellaswag_acc: 0.2556
Step:  1881, loss: 3.695719, norm: 0.3635, time(ms): 789.24, token/sec:664291.05, hellaswag_acc: 0.2556
Step:  1882, loss: 3.703452, norm: 0.3400, time(ms): 798.51, token/sec:656586.35, hellaswag_acc: 0.2556
Step:  1883, loss: 3.715043, norm: 0.3221, time(ms): 788.17, token/sec:665197.72, hellaswag_acc: 0.2556
Step:  1884, loss: 3.718028, norm: 0.3521, time(ms): 790.79, token/sec:662991.04, hellaswag_acc: 0.2556
Step:  1885, loss: 3.763863, norm: 0.3599, time(ms): 793.38, token/sec:660826.35, hellaswag_acc: 0.2556
Step:  1886, loss: 3.756845, norm: 0.3564, time(ms): 790.93, token/sec:662873.12, hellaswag_acc: 0.2556
Step:  1887, loss: 3.761937, norm: 0.3115, time(ms): 792.61, token/sec:661472.38, hellaswag_acc: 0.2556
Step:  1888, loss: 3.702502, norm: 0.3096, time(ms): 802.63, token/sec:653208.53, hellaswag_acc: 0.2556
Step:  1889, loss: 3.718079, norm: 0.3134, time(ms): 801.33, token/sec:654268.31, hellaswag_acc: 0.2556
Step:  1890, loss: 3.755943, norm: 0.3366, time(ms): 801.85, token/sec:653844.41, hellaswag_acc: 0.2556
Step:  1891, loss: 3.751928, norm: 0.3754, time(ms): 793.72, token/sec:660543.29, hellaswag_acc: 0.2556
Step:  1892, loss: 3.720170, norm: 0.3776, time(ms): 801.09, token/sec:654465.75, hellaswag_acc: 0.2556
Step:  1893, loss: 3.733416, norm: 0.3198, time(ms): 804.79, token/sec:651459.18, hellaswag_acc: 0.2556
Step:  1894, loss: 3.761398, norm: 0.3041, time(ms): 795.28, token/sec:659249.19, hellaswag_acc: 0.2556
Step:  1895, loss: 3.729803, norm: 0.2887, time(ms): 794.45, token/sec:659942.25, hellaswag_acc: 0.2556
Step:  1896, loss: 3.686394, norm: 0.2866, time(ms): 807.36, token/sec:649388.39, hellaswag_acc: 0.2556
Step:  1897, loss: 3.715068, norm: 0.2968, time(ms): 801.58, token/sec:654064.56, hellaswag_acc: 0.2556
Step:  1898, loss: 3.697354, norm: 0.3011, time(ms): 797.44, token/sec:657465.61, hellaswag_acc: 0.2556
Step:  1899, loss: 3.753106, norm: 0.3015, time(ms): 793.46, token/sec:660764.60, hellaswag_acc: 0.2556
Step:  1900, loss: 3.717396, norm: 0.2832, time(ms): 808.12, token/sec:648773.39, hellaswag_acc: 0.2556
Step:  1901, loss: 3.668311, norm: 0.2931, time(ms): 800.45, token/sec:654994.23, hellaswag_acc: 0.2556
Step:  1902, loss: 3.698467, norm: 0.3177, time(ms): 794.41, token/sec:659974.73, hellaswag_acc: 0.2556
Step:  1903, loss: 3.681844, norm: 0.3245, time(ms): 798.32, token/sec:656742.64, hellaswag_acc: 0.2556
Step:  1904, loss: 3.595222, norm: 0.3044, time(ms): 1314.18, token/sec:398947.19, hellaswag_acc: 0.2556
Step:  1905, loss: 3.720119, norm: 0.2877, time(ms): 767.63, token/sec:682995.62, hellaswag_acc: 0.2556
Step:  1906, loss: 3.667568, norm: 0.2941, time(ms): 788.85, token/sec:664624.73, hellaswag_acc: 0.2556
Step:  1907, loss: 3.706124, norm: 0.3474, time(ms): 803.69, token/sec:652354.16, hellaswag_acc: 0.2556
Step:  1908, loss: 3.694443, norm: 0.3486, time(ms): 789.40, token/sec:664159.84, hellaswag_acc: 0.2556
Step:  1909, loss: 3.687549, norm: 0.3508, time(ms): 787.86, token/sec:665460.01, hellaswag_acc: 0.2556
Step:  1910, loss: 3.702806, norm: 0.3543, time(ms): 785.39, token/sec:667553.87, hellaswag_acc: 0.2556
Step:  1911, loss: 3.660631, norm: 0.2932, time(ms): 800.42, token/sec:655016.08, hellaswag_acc: 0.2556
Step:  1912, loss: 3.638781, norm: 0.2946, time(ms): 791.98, token/sec:661999.68, hellaswag_acc: 0.2556
Step:  1913, loss: 3.595296, norm: 0.2876, time(ms): 792.85, token/sec:661269.69, hellaswag_acc: 0.2556
Step:  1914, loss: 3.642745, norm: 0.3318, time(ms): 787.03, token/sec:666160.54, hellaswag_acc: 0.2556
Step:  1915, loss: 3.597435, norm: 0.2982, time(ms): 792.77, token/sec:661337.70, hellaswag_acc: 0.2556
Step:  1916, loss: 3.610476, norm: 0.3022, time(ms): 800.49, token/sec:654956.97, hellaswag_acc: 0.2556
Step:  1917, loss: 3.615137, norm: 0.3046, time(ms): 802.82, token/sec:653057.61, hellaswag_acc: 0.2556
Step:  1918, loss: 3.587014, norm: 0.2864, time(ms): 792.55, token/sec:661518.74, hellaswag_acc: 0.2556
Step:  1919, loss: 3.590983, norm: 0.2904, time(ms): 801.72, token/sec:653952.91, hellaswag_acc: 0.2556
Step:  1920, loss: 3.644139, norm: 0.2982, time(ms): 803.46, token/sec:652538.84, hellaswag_acc: 0.2556
Step:  1921, loss: 3.634881, norm: 0.3101, time(ms): 797.80, token/sec:657165.19, hellaswag_acc: 0.2556
Step:  1922, loss: 3.657302, norm: 0.3508, time(ms): 798.57, token/sec:656533.82, hellaswag_acc: 0.2556
Step:  1923, loss: 3.684829, norm: 0.3529, time(ms): 803.89, token/sec:652188.35, hellaswag_acc: 0.2556
Step:  1924, loss: 3.692796, norm: 0.3398, time(ms): 798.61, token/sec:656503.44, hellaswag_acc: 0.2556
Step:  1925, loss: 3.656611, norm: 0.3113, time(ms): 800.40, token/sec:655030.91, hellaswag_acc: 0.2556
Step:  1926, loss: 3.683227, norm: 0.3018, time(ms): 798.45, token/sec:656631.05, hellaswag_acc: 0.2556
Step:  1927, loss: 3.769438, norm: 0.3251, time(ms): 800.56, token/sec:654904.69, hellaswag_acc: 0.2556
Step:  1928, loss: 3.621887, norm: 0.3102, time(ms): 802.58, token/sec:653257.04, hellaswag_acc: 0.2556
Step:  1929, loss: 3.625232, norm: 0.2915, time(ms): 793.35, token/sec:660849.39, hellaswag_acc: 0.2556
Step:  1930, loss: 3.679200, norm: 0.3069, time(ms): 799.19, token/sec:656026.73, hellaswag_acc: 0.2556
Step:  1931, loss: 3.653179, norm: 0.2834, time(ms): 806.20, token/sec:650319.04, hellaswag_acc: 0.2556
Step:  1932, loss: 3.679846, norm: 0.3112, time(ms): 799.68, token/sec:655622.84, hellaswag_acc: 0.2556
Step:  1933, loss: 3.661192, norm: 0.3122, time(ms): 796.71, token/sec:658067.07, hellaswag_acc: 0.2556
Step:  1934, loss: 3.677060, norm: 0.3389, time(ms): 800.70, token/sec:654783.01, hellaswag_acc: 0.2556
Step:  1935, loss: 3.700010, norm: 0.3899, time(ms): 801.42, token/sec:654196.87, hellaswag_acc: 0.2556
Step:  1936, loss: 3.592346, norm: 0.4206, time(ms): 801.59, token/sec:654059.31, hellaswag_acc: 0.2556
Step:  1937, loss: 3.682734, norm: 0.3473, time(ms): 792.46, token/sec:661598.95, hellaswag_acc: 0.2556
Step:  1938, loss: 3.709521, norm: 0.3468, time(ms): 804.24, token/sec:651900.86, hellaswag_acc: 0.2556
Step:  1939, loss: 3.686015, norm: 0.3095, time(ms): 800.66, token/sec:654815.76, hellaswag_acc: 0.2556
Step:  1940, loss: 3.746706, norm: 0.3221, time(ms): 801.28, token/sec:654310.94, hellaswag_acc: 0.2556
Step:  1941, loss: 3.676010, norm: 0.2983, time(ms): 794.16, token/sec:660176.23, hellaswag_acc: 0.2556
Step:  1942, loss: 3.681370, norm: 0.2753, time(ms): 803.45, token/sec:652547.16, hellaswag_acc: 0.2556
Step:  1943, loss: 3.692519, norm: 0.2726, time(ms): 800.74, token/sec:654756.30, hellaswag_acc: 0.2556
Step:  1944, loss: 3.679502, norm: 0.2875, time(ms): 797.19, token/sec:657672.66, hellaswag_acc: 0.2556
Step:  1945, loss: 3.703121, norm: 0.3088, time(ms): 798.10, token/sec:656921.96, hellaswag_acc: 0.2556
Step:  1946, loss: 3.697714, norm: 0.2661, time(ms): 805.16, token/sec:651160.75, hellaswag_acc: 0.2556
Step:  1947, loss: 3.675887, norm: 0.2849, time(ms): 798.28, token/sec:656775.20, hellaswag_acc: 0.2556
Step:  1948, loss: 3.633906, norm: 0.3010, time(ms): 793.47, token/sec:660755.26, hellaswag_acc: 0.2556
Step:  1949, loss: 3.606184, norm: 0.2996, time(ms): 806.22, token/sec:650301.15, hellaswag_acc: 0.2556
Step:  1950, loss: 3.501880, norm: 0.3118, time(ms): 801.70, token/sec:653969.64, hellaswag_acc: 0.2556
Step:  1951, loss: 3.648187, norm: 0.3251, time(ms): 798.42, token/sec:656656.54, hellaswag_acc: 0.2556
Step:  1952, loss: 3.630352, norm: 0.3047, time(ms): 791.39, token/sec:662486.70, hellaswag_acc: 0.2556
Step:  1953, loss: 3.670194, norm: 0.2627, time(ms): 803.67, token/sec:652371.19, hellaswag_acc: 0.2556
Step:  1954, loss: 3.660394, norm: 0.2758, time(ms): 805.91, token/sec:650554.91, hellaswag_acc: 0.2556
Step:  1955, loss: 3.615242, norm: 0.2939, time(ms): 796.44, token/sec:658292.83, hellaswag_acc: 0.2556
Step:  1956, loss: 3.587267, norm: 0.3189, time(ms): 802.00, token/sec:653722.93, hellaswag_acc: 0.2556
Step:  1957, loss: 3.606954, norm: 0.3388, time(ms): 799.51, token/sec:655762.43, hellaswag_acc: 0.2556
Step:  1958, loss: 3.588761, norm: 0.3052, time(ms): 799.31, token/sec:655926.54, hellaswag_acc: 0.2556
Step:  1959, loss: 3.691553, norm: 0.3253, time(ms): 801.82, token/sec:653872.99, hellaswag_acc: 0.2556
Step:  1960, loss: 3.673112, norm: 0.2832, time(ms): 799.17, token/sec:656037.89, hellaswag_acc: 0.2556
Step:  1961, loss: 3.582289, norm: 0.3345, time(ms): 796.08, token/sec:658589.55, hellaswag_acc: 0.2556
Step:  1962, loss: 3.652916, norm: 0.3846, time(ms): 801.36, token/sec:654247.67, hellaswag_acc: 0.2556
Step:  1963, loss: 3.659484, norm: 0.4454, time(ms): 802.90, token/sec:652993.42, hellaswag_acc: 0.2556
Step:  1964, loss: 3.666715, norm: 0.4333, time(ms): 797.70, token/sec:657246.90, hellaswag_acc: 0.2556
Step:  1965, loss: 3.655476, norm: 0.4116, time(ms): 799.85, token/sec:655482.91, hellaswag_acc: 0.2556
Step:  1966, loss: 3.653163, norm: 0.3855, time(ms): 795.86, token/sec:658767.31, hellaswag_acc: 0.2556
Step:  1967, loss: 3.663854, norm: 0.3601, time(ms): 803.44, token/sec:652555.88, hellaswag_acc: 0.2556
Step:  1968, loss: 3.651128, norm: 0.3089, time(ms): 802.37, token/sec:653421.07, hellaswag_acc: 0.2556
Step:  1969, loss: 3.638871, norm: 0.3029, time(ms): 792.61, token/sec:661467.41, hellaswag_acc: 0.2556
Step:  1970, loss: 3.666041, norm: 0.2989, time(ms): 804.08, token/sec:652032.49, hellaswag_acc: 0.2556
Step:  1971, loss: 3.711852, norm: 0.2858, time(ms): 802.37, token/sec:653427.28, hellaswag_acc: 0.2556
Step:  1972, loss: 3.693305, norm: 0.2925, time(ms): 799.69, token/sec:655614.63, hellaswag_acc: 0.2556
Step:  1973, loss: 3.685634, norm: 0.2977, time(ms): 793.64, token/sec:660611.75, hellaswag_acc: 0.2556
Step:  1974, loss: 3.655658, norm: 0.2824, time(ms): 804.22, token/sec:651917.67, hellaswag_acc: 0.2556
Step:  1975, loss: 3.669539, norm: 0.2833, time(ms): 802.41, token/sec:653395.44, hellaswag_acc: 0.2556
Step:  1976, loss: 3.682200, norm: 0.2751, time(ms): 794.13, token/sec:660201.80, hellaswag_acc: 0.2556
Step:  1977, loss: 3.656178, norm: 0.2706, time(ms): 797.04, token/sec:657797.00, hellaswag_acc: 0.2556
Step:  1978, loss: 3.675385, norm: 0.2810, time(ms): 805.53, token/sec:650862.60, hellaswag_acc: 0.2556
Step:  1979, loss: 3.695930, norm: 0.3184, time(ms): 802.75, token/sec:653110.95, hellaswag_acc: 0.2556
Step:  1980, loss: 3.704069, norm: 0.3039, time(ms): 798.44, token/sec:656643.41, hellaswag_acc: 0.2556
Step:  1981, loss: 3.629247, norm: 0.2748, time(ms): 792.03, token/sec:661951.46, hellaswag_acc: 0.2556
Step:  1982, loss: 3.610677, norm: 0.2997, time(ms): 805.56, token/sec:650836.40, hellaswag_acc: 0.2556
Step:  1983, loss: 3.653284, norm: 0.2964, time(ms): 802.17, token/sec:653584.39, hellaswag_acc: 0.2556
Step:  1984, loss: 3.672176, norm: 0.2865, time(ms): 800.95, token/sec:654585.76, hellaswag_acc: 0.2556
Step:  1985, loss: 3.577743, norm: 0.2723, time(ms): 789.13, token/sec:664391.00, hellaswag_acc: 0.2556
Step:  1986, loss: 3.684025, norm: 0.2539, time(ms): 800.82, token/sec:654688.07, hellaswag_acc: 0.2556
Step:  1987, loss: 3.657521, norm: 0.2951, time(ms): 791.54, token/sec:662364.78, hellaswag_acc: 0.2556
Step:  1988, loss: 3.588983, norm: 0.3129, time(ms): 787.31, token/sec:665924.92, hellaswag_acc: 0.2556
Step:  1989, loss: 3.642845, norm: 0.3036, time(ms): 791.88, token/sec:662079.61, hellaswag_acc: 0.2556
Step:  1990, loss: 3.597213, norm: 0.3252, time(ms): 795.28, token/sec:659250.58, hellaswag_acc: 0.2556
Step:  1991, loss: 3.615620, norm: 0.3366, time(ms): 796.43, token/sec:658298.94, hellaswag_acc: 0.2556
Step:  1992, loss: 3.614506, norm: 0.3515, time(ms): 803.07, token/sec:652851.51, hellaswag_acc: 0.2556
Step:  1993, loss: 3.585812, norm: 0.3475, time(ms): 802.55, token/sec:653280.33, hellaswag_acc: 0.2556
Step:  1994, loss: 3.621197, norm: 0.3054, time(ms): 794.29, token/sec:660067.24, hellaswag_acc: 0.2556
Step:  1995, loss: 3.658412, norm: 0.3094, time(ms): 799.28, token/sec:655954.33, hellaswag_acc: 0.2556
Step:  1996, loss: 3.627324, norm: 0.3159, time(ms): 803.08, token/sec:652847.25, hellaswag_acc: 0.2556
Step:  1997, loss: 3.669511, norm: 0.3185, time(ms): 802.53, token/sec:653292.17, hellaswag_acc: 0.2556
Step:  1998, loss: 3.665443, norm: 0.3378, time(ms): 790.95, token/sec:662856.54, hellaswag_acc: 0.2556
Step:  1999, loss: 3.631863, norm: 0.3165, time(ms): 803.10, token/sec:652829.03, hellaswag_acc: 0.2556
rank 0 sample 0: Hello, I'm a language model, and I was a linguist with a dialect I could refer to or have had. In what manner did it come from
rank 0 sample 1: Hello, I'm a language model, but here's a good point of application. The output has the name ``a'', a name representing a variety of
rank 0 sample 2: Hello, I'm a language model, but I could easily assign two names and a simple feature. If a character is a sequence, it's a simple syntax
rank 0 sample 3: Hello, I'm a language model, and when I look at the picture of the story, I think that we can still remember this story if we can learn
rank 1 sample 0: Hello, I'm a language model, and the concepts are still very complicated the next decade, we want to go back to this section because it's a very
rank 1 sample 1: Hello, I'm a language model, a model. So, I want to visualize the way different languages were used: they'd have been written in the past
rank 1 sample 2: Hello, I'm a language model, so by now I'm going to go to the one where in my code, I'm going to use a new interface
rank 1 sample 3: Hello, I'm a language model, and I'm looking for people who would build a very practical library library."The library became a place of interest among the
Step:  2000, loss: 3.661558, norm: 0.2761, time(ms): 364482.74, token/sec:1438.44, val_loss: 3.6549, hellaswag_acc: 0.2597
Step:  2001, loss: 3.733869, norm: 0.3541, time(ms): 806.92, token/sec:649743.36, hellaswag_acc: 0.2597
Step:  2002, loss: 3.654125, norm: 0.3646, time(ms): 799.94, token/sec:655407.70, hellaswag_acc: 0.2597
Step:  2003, loss: 3.649066, norm: 0.3812, time(ms): 789.71, token/sec:663896.36, hellaswag_acc: 0.2597
Step:  2004, loss: 3.679379, norm: 0.3475, time(ms): 797.20, token/sec:657665.78, hellaswag_acc: 0.2597
Step:  2005, loss: 3.667388, norm: 0.3295, time(ms): 791.60, token/sec:662314.91, hellaswag_acc: 0.2597
Step:  2006, loss: 3.678596, norm: 0.2889, time(ms): 787.88, token/sec:665440.08, hellaswag_acc: 0.2597
Step:  2007, loss: 3.680355, norm: 0.2899, time(ms): 791.53, token/sec:662373.76, hellaswag_acc: 0.2597
Step:  2008, loss: 3.729878, norm: 0.3465, time(ms): 800.32, token/sec:655095.30, hellaswag_acc: 0.2597
Step:  2009, loss: 3.671830, norm: 0.3779, time(ms): 799.82, token/sec:655508.51, hellaswag_acc: 0.2597
Step:  2010, loss: 3.672527, norm: 0.3890, time(ms): 798.06, token/sec:656949.04, hellaswag_acc: 0.2597
Step:  2011, loss: 3.664719, norm: 0.3819, time(ms): 798.39, token/sec:656683.80, hellaswag_acc: 0.2597
Step:  2012, loss: 3.660807, norm: 0.3322, time(ms): 801.70, token/sec:653972.94, hellaswag_acc: 0.2597
Step:  2013, loss: 3.640695, norm: 0.3220, time(ms): 802.03, token/sec:653703.11, hellaswag_acc: 0.2597
Step:  2014, loss: 3.685696, norm: 0.3196, time(ms): 795.84, token/sec:658781.92, hellaswag_acc: 0.2597
Step:  2015, loss: 3.687026, norm: 0.2822, time(ms): 801.03, token/sec:654514.45, hellaswag_acc: 0.2597
Step:  2016, loss: 3.680028, norm: 0.2844, time(ms): 801.52, token/sec:654115.53, hellaswag_acc: 0.2597
Step:  2017, loss: 3.647407, norm: 0.3192, time(ms): 799.70, token/sec:655602.51, hellaswag_acc: 0.2597
Step:  2018, loss: 3.558783, norm: 0.2939, time(ms): 794.09, token/sec:660237.68, hellaswag_acc: 0.2597
Step:  2019, loss: 3.627552, norm: 0.2740, time(ms): 805.86, token/sec:650595.32, hellaswag_acc: 0.2597
Step:  2020, loss: 3.592661, norm: 0.2741, time(ms): 800.08, token/sec:655297.55, hellaswag_acc: 0.2597
Step:  2021, loss: 3.637790, norm: 0.2873, time(ms): 799.89, token/sec:655453.41, hellaswag_acc: 0.2597
Step:  2022, loss: 3.633323, norm: 0.3038, time(ms): 797.30, token/sec:657577.28, hellaswag_acc: 0.2597
Step:  2023, loss: 3.614652, norm: 0.2804, time(ms): 801.66, token/sec:654004.64, hellaswag_acc: 0.2597
Step:  2024, loss: 3.604985, norm: 0.2890, time(ms): 800.41, token/sec:655025.44, hellaswag_acc: 0.2597
Step:  2025, loss: 3.610162, norm: 0.3172, time(ms): 798.48, token/sec:656610.47, hellaswag_acc: 0.2597
Step:  2026, loss: 3.617227, norm: 0.3476, time(ms): 793.33, token/sec:660868.85, hellaswag_acc: 0.2597
Step:  2027, loss: 3.595151, norm: 0.3272, time(ms): 807.63, token/sec:649168.70, hellaswag_acc: 0.2597
Step:  2028, loss: 3.653046, norm: 0.3207, time(ms): 800.17, token/sec:655223.35, hellaswag_acc: 0.2597
Step:  2029, loss: 3.600565, norm: 0.3826, time(ms): 784.04, token/sec:668697.34, hellaswag_acc: 0.2597
Step:  2030, loss: 3.581957, norm: 0.3488, time(ms): 790.45, token/sec:663275.40, hellaswag_acc: 0.2597
Step:  2031, loss: 3.634915, norm: 0.3107, time(ms): 799.01, token/sec:656172.76, hellaswag_acc: 0.2597
Step:  2032, loss: 3.662498, norm: 0.3277, time(ms): 795.25, token/sec:659270.34, hellaswag_acc: 0.2597
Step:  2033, loss: 3.688119, norm: 0.2949, time(ms): 792.20, token/sec:661814.79, hellaswag_acc: 0.2597
Step:  2034, loss: 3.712349, norm: 0.3231, time(ms): 787.90, token/sec:665425.98, hellaswag_acc: 0.2597
Step:  2035, loss: 3.691114, norm: 0.3132, time(ms): 805.80, token/sec:650645.57, hellaswag_acc: 0.2597
Step:  2036, loss: 3.681304, norm: 0.2939, time(ms): 804.09, token/sec:652029.59, hellaswag_acc: 0.2597
Step:  2037, loss: 3.632360, norm: 0.2969, time(ms): 800.48, token/sec:654963.01, hellaswag_acc: 0.2597
Step:  2038, loss: 3.650533, norm: 0.3288, time(ms): 788.72, token/sec:664731.62, hellaswag_acc: 0.2597
Step:  2039, loss: 3.632498, norm: 0.3245, time(ms): 799.46, token/sec:655801.94, hellaswag_acc: 0.2597
Step:  2040, loss: 3.608809, norm: 0.2903, time(ms): 793.14, token/sec:661024.40, hellaswag_acc: 0.2597
Step:  2041, loss: 3.648971, norm: 0.2886, time(ms): 796.59, token/sec:658167.13, hellaswag_acc: 0.2597
Step:  2042, loss: 3.625858, norm: 0.2828, time(ms): 792.97, token/sec:661171.67, hellaswag_acc: 0.2597
Step:  2043, loss: 3.618728, norm: 0.2913, time(ms): 804.18, token/sec:651957.29, hellaswag_acc: 0.2597
Step:  2044, loss: 3.673558, norm: 0.3073, time(ms): 803.60, token/sec:652420.94, hellaswag_acc: 0.2597
Step:  2045, loss: 3.721668, norm: 0.3072, time(ms): 794.60, token/sec:659816.70, hellaswag_acc: 0.2597
Step:  2046, loss: 3.730289, norm: 0.2878, time(ms): 796.31, token/sec:658397.88, hellaswag_acc: 0.2597
Step:  2047, loss: 3.664983, norm: 0.3139, time(ms): 804.51, token/sec:651687.38, hellaswag_acc: 0.2597
Step:  2048, loss: 3.679159, norm: 0.2965, time(ms): 804.26, token/sec:651890.03, hellaswag_acc: 0.2597
Step:  2049, loss: 3.678665, norm: 0.2709, time(ms): 793.53, token/sec:660706.43, hellaswag_acc: 0.2597
Step:  2050, loss: 3.647914, norm: 0.2473, time(ms): 799.31, token/sec:655924.20, hellaswag_acc: 0.2597
Step:  2051, loss: 3.659991, norm: 0.2537, time(ms): 802.76, token/sec:653102.80, hellaswag_acc: 0.2597
Step:  2052, loss: 3.582529, norm: 0.2877, time(ms): 802.18, token/sec:653578.18, hellaswag_acc: 0.2597
Step:  2053, loss: 3.576991, norm: 0.2921, time(ms): 794.72, token/sec:659711.00, hellaswag_acc: 0.2597
Step:  2054, loss: 3.596709, norm: 0.3633, time(ms): 801.44, token/sec:654180.14, hellaswag_acc: 0.2597
Step:  2055, loss: 3.581262, norm: 0.4386, time(ms): 800.89, token/sec:654631.16, hellaswag_acc: 0.2597
Step:  2056, loss: 3.595268, norm: 0.3632, time(ms): 803.00, token/sec:652907.92, hellaswag_acc: 0.2597
Step:  2057, loss: 3.579151, norm: 0.3189, time(ms): 790.86, token/sec:662931.48, hellaswag_acc: 0.2597
Step:  2058, loss: 3.544877, norm: 0.3421, time(ms): 802.38, token/sec:653415.05, hellaswag_acc: 0.2597
Step:  2059, loss: 3.638144, norm: 0.3094, time(ms): 803.16, token/sec:652779.42, hellaswag_acc: 0.2597
Step:  2060, loss: 3.641073, norm: 0.3076, time(ms): 802.60, token/sec:653235.70, hellaswag_acc: 0.2597
Step:  2061, loss: 3.628213, norm: 0.2791, time(ms): 794.55, token/sec:659853.53, hellaswag_acc: 0.2597
Step:  2062, loss: 3.570700, norm: 0.2820, time(ms): 800.94, token/sec:654587.71, hellaswag_acc: 0.2597
Step:  2063, loss: 3.575008, norm: 0.2995, time(ms): 800.66, token/sec:654820.64, hellaswag_acc: 0.2597
Step:  2064, loss: 3.593142, norm: 0.3063, time(ms): 802.58, token/sec:653249.28, hellaswag_acc: 0.2597
Step:  2065, loss: 3.656891, norm: 0.2844, time(ms): 796.56, token/sec:658188.80, hellaswag_acc: 0.2597
Step:  2066, loss: 3.654751, norm: 0.2837, time(ms): 799.83, token/sec:655495.61, hellaswag_acc: 0.2597
Step:  2067, loss: 3.683744, norm: 0.3041, time(ms): 803.73, token/sec:652318.36, hellaswag_acc: 0.2597
Step:  2068, loss: 3.610605, norm: 0.2892, time(ms): 798.45, token/sec:656631.05, hellaswag_acc: 0.2597
Step:  2069, loss: 3.686489, norm: 0.3243, time(ms): 797.86, token/sec:657115.90, hellaswag_acc: 0.2597
Step:  2070, loss: 3.642186, norm: 0.3229, time(ms): 799.45, token/sec:655811.72, hellaswag_acc: 0.2597
Step:  2071, loss: 3.639813, norm: 0.3001, time(ms): 801.43, token/sec:654194.34, hellaswag_acc: 0.2597
Step:  2072, loss: 3.622834, norm: 0.3314, time(ms): 797.23, token/sec:657639.03, hellaswag_acc: 0.2597
Step:  2073, loss: 3.668621, norm: 0.3353, time(ms): 801.44, token/sec:654179.94, hellaswag_acc: 0.2597
Step:  2074, loss: 3.639316, norm: 0.3078, time(ms): 802.53, token/sec:653294.89, hellaswag_acc: 0.2597
Step:  2075, loss: 3.659506, norm: 0.3228, time(ms): 798.16, token/sec:656871.13, hellaswag_acc: 0.2597
Step:  2076, loss: 3.707200, norm: 0.2970, time(ms): 797.78, token/sec:657186.01, hellaswag_acc: 0.2597
Step:  2077, loss: 3.662526, norm: 0.3164, time(ms): 797.15, token/sec:657700.01, hellaswag_acc: 0.2597
Step:  2078, loss: 3.621098, norm: 0.3271, time(ms): 796.10, token/sec:658570.81, hellaswag_acc: 0.2597
Step:  2079, loss: 3.653043, norm: 0.2942, time(ms): 791.16, token/sec:662679.96, hellaswag_acc: 0.2597
Step:  2080, loss: 3.648727, norm: 0.3031, time(ms): 792.24, token/sec:661778.14, hellaswag_acc: 0.2597
Step:  2081, loss: 3.673711, norm: 0.3273, time(ms): 787.39, token/sec:665851.92, hellaswag_acc: 0.2597
Step:  2082, loss: 3.673358, norm: 0.4142, time(ms): 797.06, token/sec:657775.75, hellaswag_acc: 0.2597
Step:  2083, loss: 3.615406, norm: 0.2742, time(ms): 801.19, token/sec:654385.51, hellaswag_acc: 0.2597
Step:  2084, loss: 3.755941, norm: 0.3062, time(ms): 800.35, token/sec:655076.96, hellaswag_acc: 0.2597
Step:  2085, loss: 3.694890, norm: 0.3180, time(ms): 794.76, token/sec:659679.34, hellaswag_acc: 0.2597
Step:  2086, loss: 3.646638, norm: 0.3174, time(ms): 801.24, token/sec:654342.48, hellaswag_acc: 0.2597
Step:  2087, loss: 3.605207, norm: 0.2829, time(ms): 804.00, token/sec:652097.26, hellaswag_acc: 0.2597
Step:  2088, loss: 3.572900, norm: 0.2930, time(ms): 799.77, token/sec:655552.28, hellaswag_acc: 0.2597
Step:  2089, loss: 3.605912, norm: 0.2941, time(ms): 793.19, token/sec:660984.26, hellaswag_acc: 0.2597
Step:  2090, loss: 3.567840, norm: 0.2741, time(ms): 803.72, token/sec:652330.36, hellaswag_acc: 0.2597
Step:  2091, loss: 3.563230, norm: 0.3086, time(ms): 802.01, token/sec:653714.18, hellaswag_acc: 0.2597
Step:  2092, loss: 3.560071, norm: 0.4212, time(ms): 800.90, token/sec:654621.81, hellaswag_acc: 0.2597
Step:  2093, loss: 3.624561, norm: 0.5325, time(ms): 787.74, token/sec:665557.09, hellaswag_acc: 0.2597
Step:  2094, loss: 3.623751, norm: 0.4497, time(ms): 799.78, token/sec:655544.27, hellaswag_acc: 0.2597
Step:  2095, loss: 3.649938, norm: 0.5113, time(ms): 1269.00, token/sec:413149.95, hellaswag_acc: 0.2597
Step:  2096, loss: 3.693645, norm: 0.4939, time(ms): 802.67, token/sec:653178.65, hellaswag_acc: 0.2597
Step:  2097, loss: 3.618797, norm: 0.3805, time(ms): 788.11, token/sec:665250.04, hellaswag_acc: 0.2597
Step:  2098, loss: 3.517155, norm: 0.3490, time(ms): 785.58, token/sec:667391.19, hellaswag_acc: 0.2597
Step:  2099, loss: 3.564433, norm: 0.3168, time(ms): 796.88, token/sec:657924.33, hellaswag_acc: 0.2597
Step:  2100, loss: 3.536617, norm: 0.2939, time(ms): 796.85, token/sec:657953.66, hellaswag_acc: 0.2597
Step:  2101, loss: 3.538912, norm: 0.2889, time(ms): 791.39, token/sec:662488.10, hellaswag_acc: 0.2597
Step:  2102, loss: 3.494841, norm: 0.2614, time(ms): 784.63, token/sec:668201.56, hellaswag_acc: 0.2597
Step:  2103, loss: 3.576657, norm: 0.2958, time(ms): 791.58, token/sec:662331.07, hellaswag_acc: 0.2597
Step:  2104, loss: 3.561580, norm: 0.2770, time(ms): 802.32, token/sec:653466.31, hellaswag_acc: 0.2597
Step:  2105, loss: 3.508540, norm: 0.2507, time(ms): 801.28, token/sec:654313.08, hellaswag_acc: 0.2597
Step:  2106, loss: 3.524428, norm: 0.2467, time(ms): 798.88, token/sec:656281.06, hellaswag_acc: 0.2597
Step:  2107, loss: 3.507737, norm: 0.2498, time(ms): 790.58, token/sec:663167.98, hellaswag_acc: 0.2597
Step:  2108, loss: 3.654960, norm: 0.2908, time(ms): 809.02, token/sec:648052.98, hellaswag_acc: 0.2597
Step:  2109, loss: 3.581214, norm: 0.3332, time(ms): 800.72, token/sec:654769.75, hellaswag_acc: 0.2597
Step:  2110, loss: 3.676850, norm: 0.2805, time(ms): 794.08, token/sec:660244.81, hellaswag_acc: 0.2597
Step:  2111, loss: 3.596804, norm: 0.2622, time(ms): 803.12, token/sec:652814.30, hellaswag_acc: 0.2597
Step:  2112, loss: 3.650669, norm: 0.2732, time(ms): 801.99, token/sec:653737.31, hellaswag_acc: 0.2597
Step:  2113, loss: 3.640165, norm: 0.2652, time(ms): 798.56, token/sec:656544.99, hellaswag_acc: 0.2597
Step:  2114, loss: 3.688326, norm: 0.2596, time(ms): 798.76, token/sec:656376.65, hellaswag_acc: 0.2597
Step:  2115, loss: 3.632390, norm: 0.3254, time(ms): 796.99, token/sec:657836.35, hellaswag_acc: 0.2597
Step:  2116, loss: 3.590371, norm: 0.3399, time(ms): 805.37, token/sec:650993.43, hellaswag_acc: 0.2597
Step:  2117, loss: 3.675735, norm: 0.3371, time(ms): 795.01, token/sec:659475.37, hellaswag_acc: 0.2597
Step:  2118, loss: 3.645820, norm: 0.3314, time(ms): 802.89, token/sec:652999.24, hellaswag_acc: 0.2597
Step:  2119, loss: 3.639802, norm: 0.3115, time(ms): 801.58, token/sec:654071.95, hellaswag_acc: 0.2597
Step:  2120, loss: 3.665399, norm: 0.3457, time(ms): 799.28, token/sec:655951.00, hellaswag_acc: 0.2597
Step:  2121, loss: 3.572738, norm: 0.3032, time(ms): 796.25, token/sec:658447.56, hellaswag_acc: 0.2597
Step:  2122, loss: 3.550826, norm: 0.3081, time(ms): 802.29, token/sec:653490.39, hellaswag_acc: 0.2597
Step:  2123, loss: 3.612217, norm: 0.2867, time(ms): 801.58, token/sec:654065.92, hellaswag_acc: 0.2597
Step:  2124, loss: 3.630836, norm: 0.2424, time(ms): 797.53, token/sec:657386.21, hellaswag_acc: 0.2597
Step:  2125, loss: 3.513702, norm: 0.3271, time(ms): 793.14, token/sec:661028.37, hellaswag_acc: 0.2597
Step:  2126, loss: 3.575740, norm: 0.2895, time(ms): 807.27, token/sec:649461.08, hellaswag_acc: 0.2597
Step:  2127, loss: 3.627102, norm: 0.2816, time(ms): 801.88, token/sec:653823.22, hellaswag_acc: 0.2597
Step:  2128, loss: 3.575436, norm: 0.2661, time(ms): 794.56, token/sec:659844.62, hellaswag_acc: 0.2597
Step:  2129, loss: 3.555751, norm: 0.2868, time(ms): 795.74, token/sec:658866.59, hellaswag_acc: 0.2597
Step:  2130, loss: 3.574954, norm: 0.2846, time(ms): 807.30, token/sec:649434.03, hellaswag_acc: 0.2597
Step:  2131, loss: 3.602426, norm: 0.2847, time(ms): 800.19, token/sec:655207.15, hellaswag_acc: 0.2597
Step:  2132, loss: 3.565676, norm: 0.2701, time(ms): 795.78, token/sec:658836.39, hellaswag_acc: 0.2597
Step:  2133, loss: 3.491173, norm: 0.2911, time(ms): 803.39, token/sec:652593.83, hellaswag_acc: 0.2597
Step:  2134, loss: 3.491465, norm: 0.2964, time(ms): 799.38, token/sec:655864.92, hellaswag_acc: 0.2597
Step:  2135, loss: 3.505935, norm: 0.2863, time(ms): 800.61, token/sec:654861.98, hellaswag_acc: 0.2597
Step:  2136, loss: 3.542348, norm: 0.2743, time(ms): 793.82, token/sec:660462.74, hellaswag_acc: 0.2597
Step:  2137, loss: 3.516152, norm: 0.2708, time(ms): 804.31, token/sec:651844.24, hellaswag_acc: 0.2597
Step:  2138, loss: 3.545040, norm: 0.3193, time(ms): 802.80, token/sec:653075.26, hellaswag_acc: 0.2597
Step:  2139, loss: 3.551531, norm: 0.3494, time(ms): 800.19, token/sec:655204.41, hellaswag_acc: 0.2597
Step:  2140, loss: 3.504843, norm: 0.3294, time(ms): 794.16, token/sec:660175.24, hellaswag_acc: 0.2597
Step:  2141, loss: 3.513190, norm: 0.3653, time(ms): 802.53, token/sec:653295.08, hellaswag_acc: 0.2597
Step:  2142, loss: 3.575600, norm: 0.3966, time(ms): 802.07, token/sec:653670.66, hellaswag_acc: 0.2597
Step:  2143, loss: 3.549087, norm: 0.3569, time(ms): 798.47, token/sec:656616.55, hellaswag_acc: 0.2597
Step:  2144, loss: 3.671623, norm: 0.2956, time(ms): 793.73, token/sec:660534.36, hellaswag_acc: 0.2597
Step:  2145, loss: 3.650103, norm: 0.3216, time(ms): 801.12, token/sec:654447.64, hellaswag_acc: 0.2597
Step:  2146, loss: 3.669086, norm: 0.3115, time(ms): 806.28, token/sec:650251.92, hellaswag_acc: 0.2597
Step:  2147, loss: 3.658581, norm: 0.2901, time(ms): 796.42, token/sec:658309.39, hellaswag_acc: 0.2597
Step:  2148, loss: 3.631633, norm: 0.3102, time(ms): 795.13, token/sec:659372.35, hellaswag_acc: 0.2597
Step:  2149, loss: 3.591980, norm: 0.2981, time(ms): 805.95, token/sec:650521.23, hellaswag_acc: 0.2597
Step:  2150, loss: 3.654457, norm: 0.2796, time(ms): 801.39, token/sec:654225.29, hellaswag_acc: 0.2597
Step:  2151, loss: 3.632735, norm: 0.2822, time(ms): 788.55, token/sec:664873.11, hellaswag_acc: 0.2597
Step:  2152, loss: 3.635128, norm: 0.3094, time(ms): 792.35, token/sec:661685.55, hellaswag_acc: 0.2597
Step:  2153, loss: 3.635553, norm: 0.3085, time(ms): 791.41, token/sec:662472.93, hellaswag_acc: 0.2597
Step:  2154, loss: 3.708694, norm: 0.3088, time(ms): 792.45, token/sec:661604.92, hellaswag_acc: 0.2597
Step:  2155, loss: 3.585426, norm: 0.2825, time(ms): 794.32, token/sec:660045.45, hellaswag_acc: 0.2597
Step:  2156, loss: 3.589306, norm: 0.2969, time(ms): 789.80, token/sec:663825.82, hellaswag_acc: 0.2597
Step:  2157, loss: 3.597116, norm: 0.2690, time(ms): 791.00, token/sec:662815.18, hellaswag_acc: 0.2597
Step:  2158, loss: 3.553894, norm: 0.2595, time(ms): 798.72, token/sec:656409.18, hellaswag_acc: 0.2597
Step:  2159, loss: 3.597003, norm: 0.2786, time(ms): 789.98, token/sec:663675.76, hellaswag_acc: 0.2597
Step:  2160, loss: 3.582034, norm: 0.3071, time(ms): 792.33, token/sec:661702.47, hellaswag_acc: 0.2597
Step:  2161, loss: 3.568514, norm: 0.3188, time(ms): 790.13, token/sec:663549.19, hellaswag_acc: 0.2597
Step:  2162, loss: 3.579426, norm: 0.3124, time(ms): 790.53, token/sec:663212.79, hellaswag_acc: 0.2597
Step:  2163, loss: 3.601859, norm: 0.3314, time(ms): 794.99, token/sec:659492.77, hellaswag_acc: 0.2597
Step:  2164, loss: 3.594817, norm: 0.3474, time(ms): 797.24, token/sec:657626.44, hellaswag_acc: 0.2597
Step:  2165, loss: 3.573968, norm: 0.3268, time(ms): 804.21, token/sec:651932.74, hellaswag_acc: 0.2597
Step:  2166, loss: 3.537308, norm: 0.2849, time(ms): 799.72, token/sec:655589.22, hellaswag_acc: 0.2597
Step:  2167, loss: 3.598886, norm: 0.2664, time(ms): 792.27, token/sec:661756.83, hellaswag_acc: 0.2597
Step:  2168, loss: 3.530845, norm: 0.2799, time(ms): 803.98, token/sec:652112.15, hellaswag_acc: 0.2597
Step:  2169, loss: 3.487050, norm: 0.2820, time(ms): 803.87, token/sec:652204.60, hellaswag_acc: 0.2597
Step:  2170, loss: 3.488001, norm: 0.2498, time(ms): 799.46, token/sec:655806.63, hellaswag_acc: 0.2597
Step:  2171, loss: 3.504644, norm: 0.2729, time(ms): 792.13, token/sec:661875.15, hellaswag_acc: 0.2597
Step:  2172, loss: 3.558195, norm: 0.2901, time(ms): 804.07, token/sec:652045.44, hellaswag_acc: 0.2597
Step:  2173, loss: 3.479643, norm: 0.3242, time(ms): 803.37, token/sec:652611.26, hellaswag_acc: 0.2597
Step:  2174, loss: 3.596329, norm: 0.3163, time(ms): 794.92, token/sec:659546.18, hellaswag_acc: 0.2597
Step:  2175, loss: 3.519797, norm: 0.2948, time(ms): 798.83, token/sec:656315.92, hellaswag_acc: 0.2597
Step:  2176, loss: 3.518734, norm: 0.3223, time(ms): 804.72, token/sec:651516.12, hellaswag_acc: 0.2597
Step:  2177, loss: 3.494156, norm: 0.2845, time(ms): 800.22, token/sec:655177.47, hellaswag_acc: 0.2597
Step:  2178, loss: 3.515326, norm: 0.2817, time(ms): 790.38, token/sec:663333.82, hellaswag_acc: 0.2597
Step:  2179, loss: 3.670107, norm: 0.3011, time(ms): 800.79, token/sec:654710.10, hellaswag_acc: 0.2597
Step:  2180, loss: 3.636765, norm: 0.2801, time(ms): 808.01, token/sec:648861.64, hellaswag_acc: 0.2597
Step:  2181, loss: 3.676047, norm: 0.2979, time(ms): 789.56, token/sec:664024.26, hellaswag_acc: 0.2597
Step:  2182, loss: 3.602955, norm: 0.3626, time(ms): 797.48, token/sec:657427.28, hellaswag_acc: 0.2597
Step:  2183, loss: 3.669833, norm: 0.3534, time(ms): 790.46, token/sec:663273.00, hellaswag_acc: 0.2597
Step:  2184, loss: 3.592831, norm: 0.3394, time(ms): 796.74, token/sec:658041.28, hellaswag_acc: 0.2597
Step:  2185, loss: 3.643745, norm: 0.3113, time(ms): 794.90, token/sec:659568.34, hellaswag_acc: 0.2597
Step:  2186, loss: 3.666214, norm: 0.2788, time(ms): 792.52, token/sec:661541.63, hellaswag_acc: 0.2597
Step:  2187, loss: 3.601466, norm: 0.3114, time(ms): 795.87, token/sec:658760.01, hellaswag_acc: 0.2597
Step:  2188, loss: 3.653161, norm: 0.3654, time(ms): 795.71, token/sec:658891.27, hellaswag_acc: 0.2597
Step:  2189, loss: 3.603894, norm: 0.3911, time(ms): 803.23, token/sec:652726.72, hellaswag_acc: 0.2597
Step:  2190, loss: 3.560252, norm: 0.3333, time(ms): 803.00, token/sec:652914.12, hellaswag_acc: 0.2597
Step:  2191, loss: 3.615599, norm: 0.3043, time(ms): 798.49, token/sec:656597.53, hellaswag_acc: 0.2597
Step:  2192, loss: 3.572346, norm: 0.2789, time(ms): 794.75, token/sec:659687.05, hellaswag_acc: 0.2597
Step:  2193, loss: 3.591798, norm: 0.2965, time(ms): 803.55, token/sec:652461.59, hellaswag_acc: 0.2597
Step:  2194, loss: 3.645607, norm: 0.2898, time(ms): 802.04, token/sec:653692.03, hellaswag_acc: 0.2597
Step:  2195, loss: 3.602901, norm: 0.3557, time(ms): 790.93, token/sec:662875.92, hellaswag_acc: 0.2597
Step:  2196, loss: 3.603253, norm: 0.4409, time(ms): 798.93, token/sec:656239.73, hellaswag_acc: 0.2597
Step:  2197, loss: 3.530181, norm: 0.3501, time(ms): 802.63, token/sec:653208.73, hellaswag_acc: 0.2597
Step:  2198, loss: 3.624120, norm: 0.3447, time(ms): 804.52, token/sec:651674.24, hellaswag_acc: 0.2597
Step:  2199, loss: 3.596080, norm: 0.3319, time(ms): 799.21, token/sec:656011.86, hellaswag_acc: 0.2597
Step:  2200, loss: 3.597559, norm: 0.3373, time(ms): 803.22, token/sec:652736.02, hellaswag_acc: 0.2597
Step:  2201, loss: 3.564734, norm: 0.2967, time(ms): 794.75, token/sec:659689.23, hellaswag_acc: 0.2597
Step:  2202, loss: 3.508206, norm: 0.2730, time(ms): 801.92, token/sec:653794.06, hellaswag_acc: 0.2597
Step:  2203, loss: 3.518992, norm: 0.3027, time(ms): 802.24, token/sec:653532.92, hellaswag_acc: 0.2597
Step:  2204, loss: 3.531700, norm: 0.2595, time(ms): 795.41, token/sec:659139.33, hellaswag_acc: 0.2597
Step:  2205, loss: 3.542447, norm: 0.2698, time(ms): 801.33, token/sec:654272.39, hellaswag_acc: 0.2597
Step:  2206, loss: 3.497937, norm: 0.2709, time(ms): 799.79, token/sec:655532.15, hellaswag_acc: 0.2597
Step:  2207, loss: 3.540346, norm: 0.2822, time(ms): 802.19, token/sec:653573.32, hellaswag_acc: 0.2597
Step:  2208, loss: 3.546432, norm: 0.2694, time(ms): 791.67, token/sec:662258.46, hellaswag_acc: 0.2597
Step:  2209, loss: 3.530231, norm: 0.2843, time(ms): 798.87, token/sec:656284.19, hellaswag_acc: 0.2597
Step:  2210, loss: 3.473809, norm: 0.4163, time(ms): 795.41, token/sec:659145.25, hellaswag_acc: 0.2597
Step:  2211, loss: 3.475335, norm: 0.2832, time(ms): 793.19, token/sec:660985.85, hellaswag_acc: 0.2597
Step:  2212, loss: 3.483905, norm: 0.2703, time(ms): 797.00, token/sec:657829.27, hellaswag_acc: 0.2597
Step:  2213, loss: 3.540498, norm: 0.2821, time(ms): 800.92, token/sec:654604.08, hellaswag_acc: 0.2597
Step:  2214, loss: 3.623284, norm: 0.3026, time(ms): 797.87, token/sec:657110.40, hellaswag_acc: 0.2597
Step:  2215, loss: 3.665967, norm: 0.2975, time(ms): 797.11, token/sec:657734.43, hellaswag_acc: 0.2597
Step:  2216, loss: 3.632391, norm: 0.3144, time(ms): 792.11, token/sec:661885.51, hellaswag_acc: 0.2597
Step:  2217, loss: 3.578568, norm: 0.3275, time(ms): 794.05, token/sec:660272.57, hellaswag_acc: 0.2597
Step:  2218, loss: 3.620183, norm: 0.4140, time(ms): 790.10, token/sec:663572.62, hellaswag_acc: 0.2597
Step:  2219, loss: 3.614607, norm: 0.3757, time(ms): 792.80, token/sec:661310.06, hellaswag_acc: 0.2597
Step:  2220, loss: 3.619398, norm: 0.3005, time(ms): 790.18, token/sec:663502.94, hellaswag_acc: 0.2597
Step:  2221, loss: 3.693764, norm: 0.2928, time(ms): 807.51, token/sec:649261.66, hellaswag_acc: 0.2597
Step:  2222, loss: 3.616209, norm: 0.3149, time(ms): 799.74, token/sec:655574.95, hellaswag_acc: 0.2597
Step:  2223, loss: 3.711313, norm: 0.3406, time(ms): 792.19, token/sec:661821.36, hellaswag_acc: 0.2597
Step:  2224, loss: 3.590899, norm: 0.3572, time(ms): 804.42, token/sec:651759.42, hellaswag_acc: 0.2597
Step:  2225, loss: 3.606857, norm: 0.3326, time(ms): 803.30, token/sec:652666.66, hellaswag_acc: 0.2597
Step:  2226, loss: 3.596672, norm: 0.2906, time(ms): 794.68, token/sec:659747.82, hellaswag_acc: 0.2597
Step:  2227, loss: 3.559671, norm: 0.2759, time(ms): 799.42, token/sec:655839.49, hellaswag_acc: 0.2597
Step:  2228, loss: 3.570115, norm: 0.2609, time(ms): 804.22, token/sec:651919.21, hellaswag_acc: 0.2597
Step:  2229, loss: 3.573544, norm: 0.2593, time(ms): 800.85, token/sec:654665.46, hellaswag_acc: 0.2597
Step:  2230, loss: 3.625524, norm: 0.2516, time(ms): 798.50, token/sec:656593.41, hellaswag_acc: 0.2597
Step:  2231, loss: 3.547849, norm: 0.2642, time(ms): 788.89, token/sec:664587.17, hellaswag_acc: 0.2597
Step:  2232, loss: 3.551828, norm: 0.2514, time(ms): 791.86, token/sec:662095.15, hellaswag_acc: 0.2597
Step:  2233, loss: 3.568660, norm: 0.2572, time(ms): 791.73, token/sec:662205.81, hellaswag_acc: 0.2597
Step:  2234, loss: 3.528185, norm: 0.2523, time(ms): 791.99, token/sec:661990.91, hellaswag_acc: 0.2597
Step:  2235, loss: 3.598754, norm: 0.2686, time(ms): 791.07, token/sec:662759.25, hellaswag_acc: 0.2597
Step:  2236, loss: 3.661933, norm: 0.3266, time(ms): 797.85, token/sec:657124.15, hellaswag_acc: 0.2597
Step:  2237, loss: 3.524322, norm: 0.3033, time(ms): 805.94, token/sec:650527.77, hellaswag_acc: 0.2597
Step:  2238, loss: 3.530803, norm: 0.2883, time(ms): 800.18, token/sec:655211.44, hellaswag_acc: 0.2597
Step:  2239, loss: 3.532521, norm: 0.3026, time(ms): 790.44, token/sec:663288.20, hellaswag_acc: 0.2597
Step:  2240, loss: 3.518022, norm: 0.3088, time(ms): 799.91, token/sec:655430.75, hellaswag_acc: 0.2597
Step:  2241, loss: 3.569998, norm: 0.3289, time(ms): 796.45, token/sec:658283.96, hellaswag_acc: 0.2597
Step:  2242, loss: 3.561465, norm: 0.3544, time(ms): 793.95, token/sec:660355.25, hellaswag_acc: 0.2597
Step:  2243, loss: 3.513947, norm: 0.2931, time(ms): 785.89, token/sec:667127.77, hellaswag_acc: 0.2597
Step:  2244, loss: 3.521668, norm: 0.2526, time(ms): 793.49, token/sec:660739.58, hellaswag_acc: 0.2597
Step:  2245, loss: 3.512472, norm: 0.2840, time(ms): 791.91, token/sec:662051.90, hellaswag_acc: 0.2597
Step:  2246, loss: 3.543614, norm: 0.2727, time(ms): 796.77, token/sec:658013.32, hellaswag_acc: 0.2597
Step:  2247, loss: 3.554078, norm: 0.2930, time(ms): 791.03, token/sec:662787.81, hellaswag_acc: 0.2597
Step:  2248, loss: 3.468306, norm: 0.3451, time(ms): 797.04, token/sec:657789.91, hellaswag_acc: 0.2597
Step:  2249, loss: 3.606329, norm: 0.3950, time(ms): 798.30, token/sec:656757.15, hellaswag_acc: 0.2597
rank 0 sample 0: Hello, I'm a language model, I'm still a computer program and I'm now a computer program which I think I can run a lot more easily with
rank 0 sample 1: Hello, I'm a language model, and they're really good at this!"
I went ahead to a list of some interesting features of Linux that I've
rank 0 sample 2: Hello, I'm a language model, and I wanted to look through the top of which I'm a native speaker. I wanted to look through the bottom,
rank 0 sample 3: Hello, I'm a language model, I need to write a lot more stuff in Lisp. I'm really going to want to build my output.
How
rank 1 sample 0: Hello, I'm a language model, what do you mean? I'm kind to understand how my sentences are defined and how it works to me. I'm
rank 1 sample 1: Hello, I'm a language model, you're going to use the Python API for the data structures. Python is used for text elements that can be used to
rank 1 sample 2: Hello, I'm a language model, but after the end of the book, I'm thinking I wanted to be a language model in order to make that connection
rank 1 sample 3: Hello, I'm a language model, I'm a program that doesn't really change the parameters if it's going off. At the point, I'm a
Step:  2250, loss: 3.621224, norm: 0.3685, time(ms): 3792.14, token/sec:138256.34, val_loss: 3.6207, hellaswag_acc: 0.2597
Step:  2251, loss: 3.674597, norm: 0.3476, time(ms): 791.61, token/sec:662309.72, hellaswag_acc: 0.2597
Step:  2252, loss: 3.696346, norm: 0.3834, time(ms): 787.58, token/sec:665694.70, hellaswag_acc: 0.2597
Step:  2253, loss: 3.592638, norm: 0.3993, time(ms): 791.17, token/sec:662672.57, hellaswag_acc: 0.2597
Step:  2254, loss: 3.663016, norm: 0.3706, time(ms): 799.56, token/sec:655717.26, hellaswag_acc: 0.2597
Step:  2255, loss: 3.585518, norm: 0.3121, time(ms): 790.07, token/sec:663600.05, hellaswag_acc: 0.2597
Step:  2256, loss: 3.683386, norm: 0.3235, time(ms): 796.82, token/sec:657975.51, hellaswag_acc: 0.2597
Step:  2257, loss: 3.605415, norm: 0.3302, time(ms): 793.77, token/sec:660504.80, hellaswag_acc: 0.2597
Step:  2258, loss: 3.601034, norm: 0.3056, time(ms): 791.00, token/sec:662815.58, hellaswag_acc: 0.2597
Step:  2259, loss: 3.633842, norm: 0.3286, time(ms): 793.49, token/sec:660737.20, hellaswag_acc: 0.2597
Step:  2260, loss: 3.602786, norm: 0.3248, time(ms): 789.43, token/sec:664132.96, hellaswag_acc: 0.2597
Step:  2261, loss: 3.574386, norm: 0.2904, time(ms): 794.25, token/sec:660104.10, hellaswag_acc: 0.2597
Step:  2262, loss: 3.604569, norm: 0.3128, time(ms): 792.93, token/sec:661201.09, hellaswag_acc: 0.2597
Step:  2263, loss: 3.585020, norm: 0.3115, time(ms): 794.27, token/sec:660091.02, hellaswag_acc: 0.2597
Step:  2264, loss: 3.624925, norm: 0.2655, time(ms): 800.60, token/sec:654870.76, hellaswag_acc: 0.2597
Step:  2265, loss: 3.550978, norm: 0.2552, time(ms): 800.38, token/sec:655047.69, hellaswag_acc: 0.2597
Step:  2266, loss: 3.609084, norm: 0.2672, time(ms): 800.24, token/sec:655162.05, hellaswag_acc: 0.2597
Step:  2267, loss: 3.575572, norm: 0.2681, time(ms): 801.09, token/sec:654471.21, hellaswag_acc: 0.2597
Step:  2268, loss: 3.526055, norm: 0.2603, time(ms): 798.43, token/sec:656648.31, hellaswag_acc: 0.2597
Step:  2269, loss: 3.580882, norm: 0.2628, time(ms): 793.19, token/sec:660984.66, hellaswag_acc: 0.2597
Step:  2270, loss: 3.591524, norm: 0.2697, time(ms): 806.92, token/sec:649742.21, hellaswag_acc: 0.2597
Step:  2271, loss: 3.585056, norm: 0.2681, time(ms): 800.58, token/sec:654886.94, hellaswag_acc: 0.2597
Step:  2272, loss: 3.559855, norm: 0.2600, time(ms): 800.01, token/sec:655355.16, hellaswag_acc: 0.2597
Step:  2273, loss: 3.503571, norm: 0.2684, time(ms): 792.93, token/sec:661206.86, hellaswag_acc: 0.2597
Step:  2274, loss: 3.505652, norm: 0.2846, time(ms): 800.13, token/sec:655249.71, hellaswag_acc: 0.2597
Step:  2275, loss: 3.500583, norm: 0.2793, time(ms): 807.08, token/sec:649610.34, hellaswag_acc: 0.2597
Step:  2276, loss: 3.465541, norm: 0.2572, time(ms): 797.42, token/sec:657480.75, hellaswag_acc: 0.2597
Step:  2277, loss: 3.435535, norm: 0.2639, time(ms): 791.17, token/sec:662672.37, hellaswag_acc: 0.2597
Step:  2278, loss: 3.468528, norm: 0.3050, time(ms): 803.91, token/sec:652170.37, hellaswag_acc: 0.2597
Step:  2279, loss: 3.494752, norm: 0.3111, time(ms): 806.65, token/sec:649954.79, hellaswag_acc: 0.2597
Step:  2280, loss: 3.489853, norm: 0.2832, time(ms): 799.46, token/sec:655801.94, hellaswag_acc: 0.2597
Step:  2281, loss: 3.496983, norm: 0.2432, time(ms): 789.65, token/sec:663945.87, hellaswag_acc: 0.2597
Step:  2282, loss: 3.526054, norm: 0.2747, time(ms): 807.45, token/sec:649315.91, hellaswag_acc: 0.2597
Step:  2283, loss: 3.510083, norm: 0.2744, time(ms): 802.06, token/sec:653679.98, hellaswag_acc: 0.2597
Step:  2284, loss: 3.616147, norm: 0.2941, time(ms): 795.67, token/sec:658926.02, hellaswag_acc: 0.2597
Step:  2285, loss: 3.654473, norm: 0.3507, time(ms): 1276.91, token/sec:410591.48, hellaswag_acc: 0.2597
Step:  2286, loss: 3.617178, norm: 0.3757, time(ms): 769.94, token/sec:680944.97, hellaswag_acc: 0.2597
Step:  2287, loss: 3.697263, norm: 0.3637, time(ms): 786.94, token/sec:666234.61, hellaswag_acc: 0.2597
Step:  2288, loss: 3.646616, norm: 0.3338, time(ms): 796.77, token/sec:658014.50, hellaswag_acc: 0.2597
Step:  2289, loss: 3.631609, norm: 0.3532, time(ms): 789.91, token/sec:663733.45, hellaswag_acc: 0.2597
Step:  2290, loss: 3.617209, norm: 0.3591, time(ms): 785.21, token/sec:667706.30, hellaswag_acc: 0.2597
Step:  2291, loss: 3.600707, norm: 0.3534, time(ms): 787.85, token/sec:665463.23, hellaswag_acc: 0.2597
Step:  2292, loss: 3.673907, norm: 0.3374, time(ms): 809.56, token/sec:647622.41, hellaswag_acc: 0.2597
Step:  2293, loss: 3.615498, norm: 0.3232, time(ms): 797.56, token/sec:657363.80, hellaswag_acc: 0.2597
Step:  2294, loss: 3.643132, norm: 0.3394, time(ms): 791.83, token/sec:662125.85, hellaswag_acc: 0.2597
Step:  2295, loss: 3.576152, norm: 0.3299, time(ms): 804.04, token/sec:652068.84, hellaswag_acc: 0.2597
Step:  2296, loss: 3.613569, norm: 0.2727, time(ms): 805.81, token/sec:650635.94, hellaswag_acc: 0.2597
Step:  2297, loss: 3.581405, norm: 0.2758, time(ms): 795.36, token/sec:659183.39, hellaswag_acc: 0.2597
Step:  2298, loss: 3.603408, norm: 0.2590, time(ms): 797.10, token/sec:657747.81, hellaswag_acc: 0.2597
Step:  2299, loss: 3.606662, norm: 0.2662, time(ms): 804.29, token/sec:651862.98, hellaswag_acc: 0.2597
Step:  2300, loss: 3.562861, norm: 0.2530, time(ms): 803.14, token/sec:652793.95, hellaswag_acc: 0.2597
Step:  2301, loss: 3.534336, norm: 0.2729, time(ms): 795.18, token/sec:659330.83, hellaswag_acc: 0.2597
Step:  2302, loss: 3.544395, norm: 0.2522, time(ms): 795.76, token/sec:658852.38, hellaswag_acc: 0.2597
Step:  2303, loss: 3.536093, norm: 0.2620, time(ms): 806.64, token/sec:649964.40, hellaswag_acc: 0.2597
Step:  2304, loss: 3.530371, norm: 0.2530, time(ms): 801.37, token/sec:654243.00, hellaswag_acc: 0.2597
Step:  2305, loss: 3.577909, norm: 0.2567, time(ms): 784.98, token/sec:667902.00, hellaswag_acc: 0.2597
Step:  2306, loss: 3.526387, norm: 0.2680, time(ms): 789.84, token/sec:663792.15, hellaswag_acc: 0.2597
Step:  2307, loss: 3.647700, norm: 0.2790, time(ms): 792.83, token/sec:661290.57, hellaswag_acc: 0.2597
Step:  2308, loss: 3.568697, norm: 0.2998, time(ms): 793.74, token/sec:660526.62, hellaswag_acc: 0.2597
Step:  2309, loss: 3.566577, norm: 0.2819, time(ms): 788.66, token/sec:664784.47, hellaswag_acc: 0.2597
Step:  2310, loss: 3.578686, norm: 0.3154, time(ms): 798.97, token/sec:656206.25, hellaswag_acc: 0.2597
Step:  2311, loss: 3.393609, norm: 0.3504, time(ms): 799.99, token/sec:655367.27, hellaswag_acc: 0.2597
Step:  2312, loss: 3.406017, norm: 0.3768, time(ms): 794.04, token/sec:660282.48, hellaswag_acc: 0.2597
Step:  2313, loss: 3.449717, norm: 0.3299, time(ms): 794.60, token/sec:659809.78, hellaswag_acc: 0.2597
Step:  2314, loss: 3.422933, norm: 0.2829, time(ms): 790.19, token/sec:663495.94, hellaswag_acc: 0.2597
Step:  2315, loss: 3.418565, norm: 0.2919, time(ms): 793.35, token/sec:660854.15, hellaswag_acc: 0.2597
Step:  2316, loss: 3.391841, norm: 0.3037, time(ms): 790.64, token/sec:663116.99, hellaswag_acc: 0.2597
Step:  2317, loss: 3.409824, norm: 0.3206, time(ms): 790.24, token/sec:663458.10, hellaswag_acc: 0.2597
Step:  2318, loss: 3.404621, norm: 0.3188, time(ms): 788.87, token/sec:664609.47, hellaswag_acc: 0.2597
Step:  2319, loss: 3.464834, norm: 0.3192, time(ms): 806.04, token/sec:650452.15, hellaswag_acc: 0.2597
Step:  2320, loss: 3.417762, norm: 0.3085, time(ms): 799.94, token/sec:655407.31, hellaswag_acc: 0.2597
Step:  2321, loss: 3.401484, norm: 0.2948, time(ms): 795.01, token/sec:659472.20, hellaswag_acc: 0.2597
Step:  2322, loss: 3.466060, norm: 0.3202, time(ms): 798.97, token/sec:656204.68, hellaswag_acc: 0.2597
Step:  2323, loss: 3.612163, norm: 0.3057, time(ms): 805.50, token/sec:650882.06, hellaswag_acc: 0.2597
Step:  2324, loss: 3.623127, norm: 0.2859, time(ms): 798.97, token/sec:656201.74, hellaswag_acc: 0.2597
Step:  2325, loss: 3.667542, norm: 0.3061, time(ms): 802.20, token/sec:653565.55, hellaswag_acc: 0.2597
Step:  2326, loss: 3.643831, norm: 0.3081, time(ms): 792.44, token/sec:661611.09, hellaswag_acc: 0.2597
Step:  2327, loss: 3.615992, norm: 0.3126, time(ms): 803.07, token/sec:652852.09, hellaswag_acc: 0.2597
Step:  2328, loss: 3.644670, norm: 0.3121, time(ms): 803.91, token/sec:652170.95, hellaswag_acc: 0.2597
Step:  2329, loss: 3.617743, norm: 0.2992, time(ms): 796.41, token/sec:658313.13, hellaswag_acc: 0.2597
Step:  2330, loss: 3.681334, norm: 0.2748, time(ms): 790.08, token/sec:663588.64, hellaswag_acc: 0.2597
Step:  2331, loss: 3.797178, norm: 0.3252, time(ms): 790.10, token/sec:663569.01, hellaswag_acc: 0.2597
Step:  2332, loss: 3.650861, norm: 0.3375, time(ms): 792.60, token/sec:661478.15, hellaswag_acc: 0.2597
Step:  2333, loss: 3.658468, norm: 0.3388, time(ms): 789.92, token/sec:663724.03, hellaswag_acc: 0.2597
Step:  2334, loss: 3.608263, norm: 0.2866, time(ms): 790.30, token/sec:663407.66, hellaswag_acc: 0.2597
Step:  2335, loss: 3.552299, norm: 0.2861, time(ms): 797.91, token/sec:657074.47, hellaswag_acc: 0.2597
Step:  2336, loss: 3.601383, norm: 0.3125, time(ms): 790.76, token/sec:663017.02, hellaswag_acc: 0.2597
Step:  2337, loss: 3.681581, norm: 0.3034, time(ms): 789.44, token/sec:664125.74, hellaswag_acc: 0.2597
Step:  2338, loss: 3.628776, norm: 0.3027, time(ms): 789.41, token/sec:664150.21, hellaswag_acc: 0.2597
Step:  2339, loss: 3.591098, norm: 0.2944, time(ms): 790.09, token/sec:663581.83, hellaswag_acc: 0.2597
Step:  2340, loss: 3.592774, norm: 0.2915, time(ms): 790.25, token/sec:663448.09, hellaswag_acc: 0.2597
Step:  2341, loss: 3.591150, norm: 0.3017, time(ms): 800.11, token/sec:655268.45, hellaswag_acc: 0.2597
Step:  2342, loss: 3.569839, norm: 0.2890, time(ms): 796.39, token/sec:658332.05, hellaswag_acc: 0.2597
Step:  2343, loss: 3.622617, norm: 0.2722, time(ms): 800.65, token/sec:654825.71, hellaswag_acc: 0.2597
Step:  2344, loss: 3.591975, norm: 0.2632, time(ms): 801.09, token/sec:654465.95, hellaswag_acc: 0.2597
Step:  2345, loss: 3.515433, norm: 0.2543, time(ms): 800.89, token/sec:654629.99, hellaswag_acc: 0.2597
Step:  2346, loss: 3.552378, norm: 0.2622, time(ms): 795.69, token/sec:658912.39, hellaswag_acc: 0.2597
Step:  2347, loss: 3.585072, norm: 0.2660, time(ms): 801.69, token/sec:653978.58, hellaswag_acc: 0.2597
Step:  2348, loss: 3.570787, norm: 0.2862, time(ms): 803.46, token/sec:652541.74, hellaswag_acc: 0.2597
Step:  2349, loss: 3.569659, norm: 0.3303, time(ms): 792.39, token/sec:661654.09, hellaswag_acc: 0.2597
Step:  2350, loss: 3.527288, norm: 0.2841, time(ms): 803.15, token/sec:652787.17, hellaswag_acc: 0.2597
Step:  2351, loss: 3.526381, norm: 0.2570, time(ms): 802.10, token/sec:653645.20, hellaswag_acc: 0.2597
Step:  2352, loss: 3.505620, norm: 0.2820, time(ms): 799.77, token/sec:655546.42, hellaswag_acc: 0.2597
Step:  2353, loss: 3.543974, norm: 0.2699, time(ms): 790.54, token/sec:663205.39, hellaswag_acc: 0.2597
Step:  2354, loss: 3.536625, norm: 0.2916, time(ms): 798.70, token/sec:656429.95, hellaswag_acc: 0.2597
Step:  2355, loss: 3.579244, norm: 0.2775, time(ms): 791.32, token/sec:662551.97, hellaswag_acc: 0.2597
Step:  2356, loss: 3.447331, norm: 0.2735, time(ms): 789.97, token/sec:663678.76, hellaswag_acc: 0.2597
Step:  2357, loss: 3.393916, norm: 0.2957, time(ms): 789.93, token/sec:663711.01, hellaswag_acc: 0.2597
Step:  2358, loss: 3.393795, norm: 0.3091, time(ms): 792.39, token/sec:661651.70, hellaswag_acc: 0.2597
Step:  2359, loss: 3.331772, norm: 0.3568, time(ms): 800.62, token/sec:654855.74, hellaswag_acc: 0.2597
Step:  2360, loss: 3.372617, norm: 0.4057, time(ms): 802.56, token/sec:653269.85, hellaswag_acc: 0.2597
Step:  2361, loss: 3.415342, norm: 0.4188, time(ms): 804.71, token/sec:651523.26, hellaswag_acc: 0.2597
Step:  2362, loss: 3.414315, norm: 0.3218, time(ms): 794.87, token/sec:659585.55, hellaswag_acc: 0.2597
Step:  2363, loss: 3.394655, norm: 0.3031, time(ms): 799.93, token/sec:655419.61, hellaswag_acc: 0.2597
Step:  2364, loss: 3.372436, norm: 0.2989, time(ms): 800.18, token/sec:655215.34, hellaswag_acc: 0.2597
Step:  2365, loss: 3.391730, norm: 0.2869, time(ms): 797.53, token/sec:657389.15, hellaswag_acc: 0.2597
Step:  2366, loss: 3.418597, norm: 0.2825, time(ms): 801.68, token/sec:653987.53, hellaswag_acc: 0.2597
Step:  2367, loss: 3.456879, norm: 0.2830, time(ms): 801.41, token/sec:654204.07, hellaswag_acc: 0.2597
Step:  2368, loss: 3.578459, norm: 0.2926, time(ms): 798.24, token/sec:656804.43, hellaswag_acc: 0.2597
Step:  2369, loss: 3.689130, norm: 0.3227, time(ms): 801.52, token/sec:654119.81, hellaswag_acc: 0.2597
Step:  2370, loss: 3.644550, norm: 0.2962, time(ms): 800.09, token/sec:655287.39, hellaswag_acc: 0.2597
Step:  2371, loss: 3.673075, norm: 0.2957, time(ms): 798.27, token/sec:656777.75, hellaswag_acc: 0.2597
Step:  2372, loss: 3.630151, norm: 0.3235, time(ms): 796.19, token/sec:658494.89, hellaswag_acc: 0.2597
Step:  2373, loss: 3.595395, norm: 0.3247, time(ms): 806.45, token/sec:650120.24, hellaswag_acc: 0.2597
Step:  2374, loss: 3.639720, norm: 0.3282, time(ms): 799.83, token/sec:655499.33, hellaswag_acc: 0.2597
Step:  2375, loss: 3.602787, norm: 0.2891, time(ms): 791.34, token/sec:662534.21, hellaswag_acc: 0.2597
Step:  2376, loss: 3.588725, norm: 0.2509, time(ms): 803.40, token/sec:652589.38, hellaswag_acc: 0.2597
Step:  2377, loss: 3.729144, norm: 0.3174, time(ms): 804.38, token/sec:651793.42, hellaswag_acc: 0.2597
Step:  2378, loss: 3.636963, norm: 0.3894, time(ms): 793.31, token/sec:660884.94, hellaswag_acc: 0.2597
Step:  2379, loss: 3.579547, norm: 0.3060, time(ms): 798.06, token/sec:656951.00, hellaswag_acc: 0.2597
Step:  2380, loss: 3.535860, norm: 0.3063, time(ms): 805.72, token/sec:650709.68, hellaswag_acc: 0.2597
Step:  2381, loss: 3.580161, norm: 0.2913, time(ms): 803.38, token/sec:652605.07, hellaswag_acc: 0.2597
Step:  2382, loss: 3.630783, norm: 0.2991, time(ms): 791.33, token/sec:662541.40, hellaswag_acc: 0.2597
Step:  2383, loss: 3.592038, norm: 0.2668, time(ms): 800.49, token/sec:654957.55, hellaswag_acc: 0.2597
Step:  2384, loss: 3.672091, norm: 0.2667, time(ms): 807.86, token/sec:648980.18, hellaswag_acc: 0.2597
Step:  2385, loss: 3.603311, norm: 0.2692, time(ms): 790.67, token/sec:663090.60, hellaswag_acc: 0.2597
Step:  2386, loss: 3.545152, norm: 0.2658, time(ms): 797.76, token/sec:657199.17, hellaswag_acc: 0.2597
Step:  2387, loss: 3.582623, norm: 0.2596, time(ms): 791.31, token/sec:662559.76, hellaswag_acc: 0.2597
Step:  2388, loss: 3.603559, norm: 0.2740, time(ms): 788.01, token/sec:665329.95, hellaswag_acc: 0.2597
Step:  2389, loss: 3.594018, norm: 0.2777, time(ms): 791.50, token/sec:662399.30, hellaswag_acc: 0.2597
Step:  2390, loss: 3.522185, norm: 0.2714, time(ms): 791.37, token/sec:662509.86, hellaswag_acc: 0.2597
Step:  2391, loss: 3.592664, norm: 0.2927, time(ms): 797.33, token/sec:657558.01, hellaswag_acc: 0.2597
Step:  2392, loss: 3.568793, norm: 0.2803, time(ms): 791.82, token/sec:662128.65, hellaswag_acc: 0.2597
Step:  2393, loss: 3.583059, norm: 0.2846, time(ms): 795.57, token/sec:659009.35, hellaswag_acc: 0.2597
Step:  2394, loss: 3.500563, norm: 0.2944, time(ms): 799.17, token/sec:656038.48, hellaswag_acc: 0.2597
Step:  2395, loss: 3.524363, norm: 0.2990, time(ms): 801.08, token/sec:654479.39, hellaswag_acc: 0.2597
Step:  2396, loss: 3.551871, norm: 0.2698, time(ms): 802.13, token/sec:653618.78, hellaswag_acc: 0.2597
Step:  2397, loss: 3.475596, norm: 0.2563, time(ms): 791.87, token/sec:662084.59, hellaswag_acc: 0.2597
Step:  2398, loss: 3.485917, norm: 0.2465, time(ms): 806.54, token/sec:650042.79, hellaswag_acc: 0.2597
Step:  2399, loss: 3.533320, norm: 0.2839, time(ms): 800.48, token/sec:654969.45, hellaswag_acc: 0.2597
Step:  2400, loss: 3.571444, norm: 0.3088, time(ms): 800.51, token/sec:654940.39, hellaswag_acc: 0.2597
Step:  2401, loss: 3.513020, norm: 0.2891, time(ms): 790.40, token/sec:663323.82, hellaswag_acc: 0.2597
Step:  2402, loss: 3.339973, norm: 0.2714, time(ms): 806.19, token/sec:650328.84, hellaswag_acc: 0.2597
Step:  2403, loss: 3.332957, norm: 0.3051, time(ms): 802.50, token/sec:653317.98, hellaswag_acc: 0.2597
Step:  2404, loss: 3.444623, norm: 0.2803, time(ms): 799.68, token/sec:655619.71, hellaswag_acc: 0.2597
Step:  2405, loss: 3.365373, norm: 0.3010, time(ms): 792.68, token/sec:661410.11, hellaswag_acc: 0.2597
Step:  2406, loss: 3.291555, norm: 0.3152, time(ms): 805.14, token/sec:651176.95, hellaswag_acc: 0.2597
Step:  2407, loss: 3.352879, norm: 0.3419, time(ms): 801.66, token/sec:654001.14, hellaswag_acc: 0.2597
Step:  2408, loss: 3.351192, norm: 0.3293, time(ms): 800.07, token/sec:655305.36, hellaswag_acc: 0.2597
Step:  2409, loss: 3.395944, norm: 0.3183, time(ms): 792.54, token/sec:661532.08, hellaswag_acc: 0.2597
Step:  2410, loss: 3.371028, norm: 0.2719, time(ms): 801.64, token/sec:654020.79, hellaswag_acc: 0.2597
Step:  2411, loss: 3.388313, norm: 0.3037, time(ms): 805.35, token/sec:651004.22, hellaswag_acc: 0.2597
Step:  2412, loss: 3.426281, norm: 0.3009, time(ms): 800.14, token/sec:655241.31, hellaswag_acc: 0.2597
Step:  2413, loss: 3.462119, norm: 0.3079, time(ms): 792.76, token/sec:661346.65, hellaswag_acc: 0.2597
Step:  2414, loss: 3.577787, norm: 0.2781, time(ms): 803.48, token/sec:652523.54, hellaswag_acc: 0.2597
Step:  2415, loss: 3.626930, norm: 0.2797, time(ms): 804.16, token/sec:651966.96, hellaswag_acc: 0.2597
Step:  2416, loss: 3.547598, norm: 0.2795, time(ms): 793.63, token/sec:660620.68, hellaswag_acc: 0.2597
Step:  2417, loss: 3.584489, norm: 0.3462, time(ms): 803.32, token/sec:652655.23, hellaswag_acc: 0.2597
Step:  2418, loss: 3.564372, norm: 0.3583, time(ms): 798.30, token/sec:656757.94, hellaswag_acc: 0.2597
Step:  2419, loss: 3.560990, norm: 0.3522, time(ms): 803.68, token/sec:652356.48, hellaswag_acc: 0.2597
Step:  2420, loss: 3.526786, norm: 0.3228, time(ms): 794.40, token/sec:659976.31, hellaswag_acc: 0.2597
Step:  2421, loss: 3.605958, norm: 0.3165, time(ms): 800.87, token/sec:654648.31, hellaswag_acc: 0.2597
Step:  2422, loss: 3.560104, norm: 0.3132, time(ms): 801.50, token/sec:654136.35, hellaswag_acc: 0.2597
Step:  2423, loss: 3.602964, norm: 0.2890, time(ms): 802.42, token/sec:653385.93, hellaswag_acc: 0.2597
Step:  2424, loss: 3.575780, norm: 0.2800, time(ms): 790.00, token/sec:663655.73, hellaswag_acc: 0.2597
Step:  2425, loss: 3.582983, norm: 0.3047, time(ms): 800.84, token/sec:654675.79, hellaswag_acc: 0.2597
Step:  2426, loss: 3.638040, norm: 0.3218, time(ms): 805.32, token/sec:651026.77, hellaswag_acc: 0.2597
Step:  2427, loss: 3.575730, norm: 0.3031, time(ms): 803.40, token/sec:652586.86, hellaswag_acc: 0.2597
Step:  2428, loss: 3.584951, norm: 0.3182, time(ms): 793.08, token/sec:661081.23, hellaswag_acc: 0.2597
Step:  2429, loss: 3.587391, norm: 0.3218, time(ms): 798.23, token/sec:656815.22, hellaswag_acc: 0.2597
Step:  2430, loss: 3.611808, norm: 0.2738, time(ms): 806.73, token/sec:649893.33, hellaswag_acc: 0.2597
Step:  2431, loss: 3.593924, norm: 0.3091, time(ms): 800.63, token/sec:654844.23, hellaswag_acc: 0.2597
Step:  2432, loss: 3.582725, norm: 0.2824, time(ms): 788.99, token/sec:664508.85, hellaswag_acc: 0.2597
Step:  2433, loss: 3.615315, norm: 0.3747, time(ms): 805.21, token/sec:651122.96, hellaswag_acc: 0.2597
Step:  2434, loss: 3.666633, norm: 0.4245, time(ms): 805.93, token/sec:650540.86, hellaswag_acc: 0.2597
Step:  2435, loss: 3.611765, norm: 0.3930, time(ms): 793.61, token/sec:660637.95, hellaswag_acc: 0.2597
Step:  2436, loss: 3.596578, norm: 0.3388, time(ms): 799.75, token/sec:655564.99, hellaswag_acc: 0.2597
Step:  2437, loss: 3.567861, norm: 0.2874, time(ms): 803.61, token/sec:652418.42, hellaswag_acc: 0.2597
Step:  2438, loss: 3.581372, norm: 0.3211, time(ms): 801.66, token/sec:654002.51, hellaswag_acc: 0.2597
Step:  2439, loss: 3.545352, norm: 0.2761, time(ms): 799.12, token/sec:656078.40, hellaswag_acc: 0.2597
Step:  2440, loss: 3.517344, norm: 0.2891, time(ms): 796.15, token/sec:658531.96, hellaswag_acc: 0.2597
Step:  2441, loss: 3.534704, norm: 0.2890, time(ms): 797.01, token/sec:657821.59, hellaswag_acc: 0.2597
Step:  2442, loss: 3.506136, norm: 0.2658, time(ms): 805.41, token/sec:650955.85, hellaswag_acc: 0.2597
Step:  2443, loss: 3.525593, norm: 0.2449, time(ms): 802.63, token/sec:653210.08, hellaswag_acc: 0.2597
Step:  2444, loss: 3.568836, norm: 0.2703, time(ms): 791.99, token/sec:661986.93, hellaswag_acc: 0.2597
Step:  2445, loss: 3.570432, norm: 0.2781, time(ms): 805.05, token/sec:651250.81, hellaswag_acc: 0.2597
Step:  2446, loss: 3.536212, norm: 0.2703, time(ms): 800.95, token/sec:654585.56, hellaswag_acc: 0.2597
Step:  2447, loss: 3.586292, norm: 0.2733, time(ms): 800.73, token/sec:654759.81, hellaswag_acc: 0.2597
Step:  2448, loss: 3.477322, norm: 0.2948, time(ms): 791.11, token/sec:662721.50, hellaswag_acc: 0.2597
Step:  2449, loss: 3.455861, norm: 0.3151, time(ms): 805.47, token/sec:650910.38, hellaswag_acc: 0.2597
Step:  2450, loss: 3.407704, norm: 0.3030, time(ms): 803.20, token/sec:652747.45, hellaswag_acc: 0.2597
Step:  2451, loss: 3.355799, norm: 0.2865, time(ms): 794.46, token/sec:659931.95, hellaswag_acc: 0.2597
Step:  2452, loss: 3.378261, norm: 0.2746, time(ms): 799.40, token/sec:655850.44, hellaswag_acc: 0.2597
Step:  2453, loss: 3.403172, norm: 0.2983, time(ms): 803.64, token/sec:652388.61, hellaswag_acc: 0.2597
Step:  2454, loss: 3.450460, norm: 0.3126, time(ms): 801.18, token/sec:654392.72, hellaswag_acc: 0.2597
Step:  2455, loss: 3.327428, norm: 0.3070, time(ms): 797.46, token/sec:657449.69, hellaswag_acc: 0.2597
Step:  2456, loss: 3.395663, norm: 0.2968, time(ms): 793.39, token/sec:660820.19, hellaswag_acc: 0.2597
Step:  2457, loss: 3.335613, norm: 0.2933, time(ms): 807.51, token/sec:649265.87, hellaswag_acc: 0.2597
Step:  2458, loss: 3.360775, norm: 0.3092, time(ms): 801.28, token/sec:654311.13, hellaswag_acc: 0.2597
Step:  2459, loss: 3.428254, norm: 0.3234, time(ms): 794.32, token/sec:660044.26, hellaswag_acc: 0.2597
Step:  2460, loss: 3.340281, norm: 0.2810, time(ms): 797.87, token/sec:657112.37, hellaswag_acc: 0.2597
Step:  2461, loss: 3.470858, norm: 0.2854, time(ms): 806.81, token/sec:649831.49, hellaswag_acc: 0.2597
Step:  2462, loss: 3.583373, norm: 0.2869, time(ms): 796.22, token/sec:658474.38, hellaswag_acc: 0.2597
Step:  2463, loss: 3.561023, norm: 0.2932, time(ms): 801.97, token/sec:653753.44, hellaswag_acc: 0.2597
Step:  2464, loss: 3.561081, norm: 0.3068, time(ms): 798.38, token/sec:656692.04, hellaswag_acc: 0.2597
Step:  2465, loss: 3.634433, norm: 0.3281, time(ms): 802.38, token/sec:653413.11, hellaswag_acc: 0.2597
Step:  2466, loss: 3.539953, norm: 0.3212, time(ms): 798.33, token/sec:656732.24, hellaswag_acc: 0.2597
Step:  2467, loss: 3.589619, norm: 0.3627, time(ms): 799.12, token/sec:656079.38, hellaswag_acc: 0.2597
Step:  2468, loss: 3.596557, norm: 0.3287, time(ms): 803.09, token/sec:652834.46, hellaswag_acc: 0.2597
Step:  2469, loss: 3.572662, norm: 0.3255, time(ms): 799.00, token/sec:656177.07, hellaswag_acc: 0.2597
Step:  2470, loss: 3.536576, norm: 0.2902, time(ms): 794.21, token/sec:660133.82, hellaswag_acc: 0.2597
Step:  2471, loss: 3.571229, norm: 0.2889, time(ms): 803.67, token/sec:652367.90, hellaswag_acc: 0.2597
Step:  2472, loss: 3.574963, norm: 0.3129, time(ms): 798.54, token/sec:656555.58, hellaswag_acc: 0.2597
Step:  2473, loss: 3.570843, norm: 0.2713, time(ms): 803.22, token/sec:652730.20, hellaswag_acc: 0.2597
Step:  2474, loss: 3.574575, norm: 0.2835, time(ms): 799.43, token/sec:655826.00, hellaswag_acc: 0.2597
Step:  2475, loss: 3.588253, norm: 0.2787, time(ms): 794.88, token/sec:659578.62, hellaswag_acc: 0.2597
Step:  2476, loss: 3.618804, norm: 0.2917, time(ms): 1333.17, token/sec:393265.32, hellaswag_acc: 0.2597
Step:  2477, loss: 3.639236, norm: 0.3139, time(ms): 796.57, token/sec:658181.51, hellaswag_acc: 0.2597
Step:  2478, loss: 3.638415, norm: 0.2907, time(ms): 783.43, token/sec:669217.90, hellaswag_acc: 0.2597
Step:  2479, loss: 3.603975, norm: 0.2920, time(ms): 786.38, token/sec:666707.88, hellaswag_acc: 0.2597
Step:  2480, loss: 3.600387, norm: 0.2907, time(ms): 803.09, token/sec:652839.69, hellaswag_acc: 0.2597
Step:  2481, loss: 3.595260, norm: 0.2578, time(ms): 801.76, token/sec:653918.49, hellaswag_acc: 0.2597
Step:  2482, loss: 3.631880, norm: 0.2742, time(ms): 788.19, token/sec:665175.79, hellaswag_acc: 0.2597
Step:  2483, loss: 3.582864, norm: 0.2670, time(ms): 791.01, token/sec:662809.19, hellaswag_acc: 0.2597
Step:  2484, loss: 3.589248, norm: 0.2577, time(ms): 793.98, token/sec:660325.50, hellaswag_acc: 0.2597
Step:  2485, loss: 3.704914, norm: 0.2881, time(ms): 792.53, token/sec:661536.46, hellaswag_acc: 0.2597
Step:  2486, loss: 3.553057, norm: 0.3040, time(ms): 792.89, token/sec:661234.49, hellaswag_acc: 0.2597
Step:  2487, loss: 3.516269, norm: 0.3525, time(ms): 792.23, token/sec:661789.50, hellaswag_acc: 0.2597
Step:  2488, loss: 3.521011, norm: 0.3047, time(ms): 804.40, token/sec:651771.59, hellaswag_acc: 0.2597
Step:  2489, loss: 3.522074, norm: 0.2771, time(ms): 803.83, token/sec:652234.97, hellaswag_acc: 0.2597
Step:  2490, loss: 3.500874, norm: 0.3276, time(ms): 796.29, token/sec:658416.22, hellaswag_acc: 0.2597
Step:  2491, loss: 3.513784, norm: 0.2819, time(ms): 799.72, token/sec:655586.48, hellaswag_acc: 0.2597
Step:  2492, loss: 3.553078, norm: 0.2872, time(ms): 800.13, token/sec:655255.76, hellaswag_acc: 0.2597
Step:  2493, loss: 3.501286, norm: 0.3083, time(ms): 798.67, token/sec:656450.13, hellaswag_acc: 0.2597
Step:  2494, loss: 3.507062, norm: 0.2659, time(ms): 800.82, token/sec:654690.61, hellaswag_acc: 0.2597
Step:  2495, loss: 3.516942, norm: 0.2987, time(ms): 794.20, token/sec:660149.08, hellaswag_acc: 0.2597
Step:  2496, loss: 3.533848, norm: 0.2828, time(ms): 805.18, token/sec:651147.26, hellaswag_acc: 0.2597
Step:  2497, loss: 3.482456, norm: 0.2912, time(ms): 800.80, token/sec:654708.73, hellaswag_acc: 0.2597
Step:  2498, loss: 3.569836, norm: 0.2958, time(ms): 793.23, token/sec:660956.65, hellaswag_acc: 0.2597
Step:  2499, loss: 3.534908, norm: 0.3020, time(ms): 793.27, token/sec:660918.11, hellaswag_acc: 0.2597
rank 0 sample 0: Hello, I'm a language model, and I'd like you to know where everything from the rest of the globe gets. And why not do I have any
rank 0 sample 1: Hello, I'm a language model, but here's a link to it.
I see here that there's something I want to do this:
Note
rank 0 sample 2: Hello, I'm a language model, but I're an adult learning-worker. What's the reason, I'm a language model, and I've gotten
rank 0 sample 3: Hello, I'm a language model, and, perhaps, I'm a language teacher
- I'm a language learner; language learner.
When
rank 1 sample 0: Hello, I'm a language model, and we have a "type" method to specify which we can use to "see." This can be done by using
rank 1 sample 1: Hello, I'm a language model, which I can learn from.
What type of language(s) are they-symbols, and how do
rank 1 sample 2: Hello, I'm a language model, I didn't even know what I'm talking about. So how does this have to do with all this information being applied
rank 1 sample 3: Hello, I'm a language model, and I'm very excited to learn what.
For information, email firstname.lastname@example.org.
Step:  2500, loss: 3.603123, norm: 0.3096, time(ms): 3785.39, token/sec:138503.13, val_loss: 3.5697, hellaswag_acc: 0.2597
Step:  2501, loss: 3.531710, norm: 0.2797, time(ms): 787.90, token/sec:665423.56, hellaswag_acc: 0.2597
Step:  2502, loss: 3.570455, norm: 0.2698, time(ms): 790.74, token/sec:663034.21, hellaswag_acc: 0.2597
Step:  2503, loss: 3.573540, norm: 0.2978, time(ms): 791.10, token/sec:662734.88, hellaswag_acc: 0.2597
Step:  2504, loss: 3.533409, norm: 0.3143, time(ms): 799.04, token/sec:656149.47, hellaswag_acc: 0.2597
Step:  2505, loss: 3.581480, norm: 0.2911, time(ms): 792.51, token/sec:661550.19, hellaswag_acc: 0.2597
Step:  2506, loss: 3.588022, norm: 0.2706, time(ms): 801.84, token/sec:653853.94, hellaswag_acc: 0.2597
Step:  2507, loss: 3.581981, norm: 0.3166, time(ms): 806.47, token/sec:650104.09, hellaswag_acc: 0.2597
Step:  2508, loss: 3.558468, norm: 0.2954, time(ms): 789.03, token/sec:664467.69, hellaswag_acc: 0.2597
Step:  2509, loss: 3.607855, norm: 0.2973, time(ms): 792.55, token/sec:661520.14, hellaswag_acc: 0.2597
Step:  2510, loss: 3.598693, norm: 0.2964, time(ms): 789.49, token/sec:664087.03, hellaswag_acc: 0.2597
Step:  2511, loss: 3.632063, norm: 0.2703, time(ms): 793.09, token/sec:661068.91, hellaswag_acc: 0.2597
Step:  2512, loss: 3.574754, norm: 0.2775, time(ms): 791.46, token/sec:662429.43, hellaswag_acc: 0.2597
Step:  2513, loss: 3.579583, norm: 0.2872, time(ms): 793.22, token/sec:660965.59, hellaswag_acc: 0.2597
Step:  2514, loss: 3.542861, norm: 0.2767, time(ms): 801.73, token/sec:653945.71, hellaswag_acc: 0.2597
Step:  2515, loss: 3.597191, norm: 0.2722, time(ms): 798.92, token/sec:656248.35, hellaswag_acc: 0.2597
Step:  2516, loss: 3.633957, norm: 0.3076, time(ms): 791.82, token/sec:662127.45, hellaswag_acc: 0.2597
Step:  2517, loss: 3.575405, norm: 0.3331, time(ms): 792.44, token/sec:661612.49, hellaswag_acc: 0.2597
Step:  2518, loss: 3.579705, norm: 0.3054, time(ms): 800.01, token/sec:655351.84, hellaswag_acc: 0.2597
Step:  2519, loss: 3.608358, norm: 0.2630, time(ms): 799.80, token/sec:655520.63, hellaswag_acc: 0.2597
Step:  2520, loss: 3.549100, norm: 0.3023, time(ms): 798.75, token/sec:656385.47, hellaswag_acc: 0.2597
Step:  2521, loss: 3.491519, norm: 0.3074, time(ms): 793.35, token/sec:660852.76, hellaswag_acc: 0.2597
Step:  2522, loss: 3.514943, norm: 0.3228, time(ms): 789.97, token/sec:663680.16, hellaswag_acc: 0.2597
Step:  2523, loss: 3.535528, norm: 0.3398, time(ms): 791.40, token/sec:662485.51, hellaswag_acc: 0.2597
Step:  2524, loss: 3.486624, norm: 0.3926, time(ms): 792.25, token/sec:661771.97, hellaswag_acc: 0.2597
Step:  2525, loss: 3.508478, norm: 0.3669, time(ms): 788.09, token/sec:665263.32, hellaswag_acc: 0.2597
Step:  2526, loss: 3.523078, norm: 0.3501, time(ms): 800.74, token/sec:654753.37, hellaswag_acc: 0.2597
Step:  2527, loss: 3.514446, norm: 0.3284, time(ms): 806.60, token/sec:649997.64, hellaswag_acc: 0.2597
Step:  2528, loss: 3.524029, norm: 0.3200, time(ms): 801.95, token/sec:653763.35, hellaswag_acc: 0.2597
Step:  2529, loss: 3.540595, norm: 0.2678, time(ms): 784.29, token/sec:668485.33, hellaswag_acc: 0.2597
Step:  2530, loss: 3.519768, norm: 0.2663, time(ms): 789.95, token/sec:663694.99, hellaswag_acc: 0.2597
Step:  2531, loss: 3.510410, norm: 0.2636, time(ms): 795.99, token/sec:658662.93, hellaswag_acc: 0.2597
Step:  2532, loss: 3.528607, norm: 0.2800, time(ms): 790.81, token/sec:662973.05, hellaswag_acc: 0.2597
Step:  2533, loss: 3.548870, norm: 0.2799, time(ms): 790.16, token/sec:663523.76, hellaswag_acc: 0.2597
Step:  2534, loss: 3.598217, norm: 0.3133, time(ms): 799.64, token/sec:655655.09, hellaswag_acc: 0.2597
Step:  2535, loss: 3.565916, norm: 0.3519, time(ms): 805.10, token/sec:651205.87, hellaswag_acc: 0.2597
Step:  2536, loss: 3.644851, norm: 0.3496, time(ms): 803.57, token/sec:652451.91, hellaswag_acc: 0.2597
Step:  2537, loss: 3.683831, norm: 0.2652, time(ms): 784.26, token/sec:668514.59, hellaswag_acc: 0.2597
Step:  2538, loss: 3.560383, norm: 0.2896, time(ms): 788.76, token/sec:664696.05, hellaswag_acc: 0.2597
Step:  2539, loss: 3.649717, norm: 0.2949, time(ms): 803.35, token/sec:652623.66, hellaswag_acc: 0.2597
Step:  2540, loss: 3.587050, norm: 0.2671, time(ms): 800.56, token/sec:654903.13, hellaswag_acc: 0.2597
Step:  2541, loss: 3.566247, norm: 0.2769, time(ms): 789.68, token/sec:663922.62, hellaswag_acc: 0.2597
Step:  2542, loss: 3.681489, norm: 0.3262, time(ms): 786.95, token/sec:666225.33, hellaswag_acc: 0.2597
Step:  2543, loss: 3.563298, norm: 0.3587, time(ms): 793.83, token/sec:660451.64, hellaswag_acc: 0.2597
Step:  2544, loss: 3.606617, norm: 0.3527, time(ms): 792.62, token/sec:661458.45, hellaswag_acc: 0.2597
Step:  2545, loss: 3.601557, norm: 0.3045, time(ms): 792.42, token/sec:661626.42, hellaswag_acc: 0.2597
Step:  2546, loss: 3.570152, norm: 0.2800, time(ms): 792.00, token/sec:661981.74, hellaswag_acc: 0.2597
Step:  2547, loss: 3.596808, norm: 0.3059, time(ms): 792.63, token/sec:661452.28, hellaswag_acc: 0.2597
Step:  2548, loss: 3.646262, norm: 0.3231, time(ms): 790.24, token/sec:663455.50, hellaswag_acc: 0.2597
Step:  2549, loss: 3.621590, norm: 0.3145, time(ms): 791.82, token/sec:662126.85, hellaswag_acc: 0.2597
Step:  2550, loss: 3.585996, norm: 0.2730, time(ms): 790.66, token/sec:663099.79, hellaswag_acc: 0.2597
Step:  2551, loss: 3.524965, norm: 0.2747, time(ms): 802.82, token/sec:653056.64, hellaswag_acc: 0.2597
Step:  2552, loss: 3.578541, norm: 0.2801, time(ms): 799.36, token/sec:655884.48, hellaswag_acc: 0.2597
Step:  2553, loss: 3.642550, norm: 0.3833, time(ms): 804.90, token/sec:651374.08, hellaswag_acc: 0.2597
Step:  2554, loss: 3.612312, norm: 0.3783, time(ms): 789.45, token/sec:664116.11, hellaswag_acc: 0.2597
Step:  2555, loss: 3.594526, norm: 0.3481, time(ms): 798.80, token/sec:656344.92, hellaswag_acc: 0.2597
Step:  2556, loss: 3.556691, norm: 0.3694, time(ms): 791.77, token/sec:662167.92, hellaswag_acc: 0.2597
Step:  2557, loss: 3.651846, norm: 0.3132, time(ms): 790.69, token/sec:663076.20, hellaswag_acc: 0.2597
Step:  2558, loss: 3.473271, norm: 0.3007, time(ms): 791.13, token/sec:662704.72, hellaswag_acc: 0.2597
Step:  2559, loss: 3.502905, norm: 0.2518, time(ms): 784.87, token/sec:667992.49, hellaswag_acc: 0.2597
Step:  2560, loss: 3.477586, norm: 0.2543, time(ms): 797.10, token/sec:657740.92, hellaswag_acc: 0.2597
Step:  2561, loss: 3.431835, norm: 0.3434, time(ms): 793.87, token/sec:660417.52, hellaswag_acc: 0.2597
Step:  2562, loss: 3.528293, norm: 0.2740, time(ms): 790.54, token/sec:663205.19, hellaswag_acc: 0.2597
Step:  2563, loss: 3.503227, norm: 0.2708, time(ms): 806.06, token/sec:650433.87, hellaswag_acc: 0.2597
Step:  2564, loss: 3.520653, norm: 0.2595, time(ms): 803.59, token/sec:652434.29, hellaswag_acc: 0.2597
Step:  2565, loss: 3.541690, norm: 0.2701, time(ms): 799.41, token/sec:655847.32, hellaswag_acc: 0.2597
Step:  2566, loss: 3.475729, norm: 0.2512, time(ms): 789.75, token/sec:663866.50, hellaswag_acc: 0.2597
Step:  2567, loss: 3.465401, norm: 0.2765, time(ms): 807.02, token/sec:649659.28, hellaswag_acc: 0.2597
Step:  2568, loss: 3.532709, norm: 0.2552, time(ms): 802.97, token/sec:652934.29, hellaswag_acc: 0.2597
Step:  2569, loss: 3.572428, norm: 0.3049, time(ms): 800.77, token/sec:654727.25, hellaswag_acc: 0.2597
Step:  2570, loss: 3.622999, norm: 0.2935, time(ms): 781.55, token/sec:670833.97, hellaswag_acc: 0.2597
Step:  2571, loss: 3.583846, norm: 0.3115, time(ms): 790.78, token/sec:662999.83, hellaswag_acc: 0.2597
Step:  2572, loss: 3.570424, norm: 0.2959, time(ms): 799.51, token/sec:655762.04, hellaswag_acc: 0.2597
Step:  2573, loss: 3.529464, norm: 0.2810, time(ms): 790.24, token/sec:663454.10, hellaswag_acc: 0.2597
Step:  2574, loss: 3.610171, norm: 0.2969, time(ms): 789.82, token/sec:663809.18, hellaswag_acc: 0.2597
Step:  2575, loss: 3.544391, norm: 0.3105, time(ms): 797.69, token/sec:657261.24, hellaswag_acc: 0.2597
Step:  2576, loss: 3.591563, norm: 0.3105, time(ms): 807.46, token/sec:649307.67, hellaswag_acc: 0.2597
Step:  2577, loss: 3.585193, norm: 0.3257, time(ms): 801.96, token/sec:653760.83, hellaswag_acc: 0.2597
Step:  2578, loss: 3.545944, norm: 0.3018, time(ms): 788.91, token/sec:664573.52, hellaswag_acc: 0.2597
Step:  2579, loss: 3.510190, norm: 0.2978, time(ms): 799.47, token/sec:655791.18, hellaswag_acc: 0.2597
Step:  2580, loss: 3.570469, norm: 0.3151, time(ms): 792.65, token/sec:661439.15, hellaswag_acc: 0.2597
Step:  2581, loss: 3.575661, norm: 0.3029, time(ms): 798.55, token/sec:656546.75, hellaswag_acc: 0.2597
Step:  2582, loss: 3.623219, norm: 0.3139, time(ms): 783.34, token/sec:669299.99, hellaswag_acc: 0.2597
Step:  2583, loss: 3.546272, norm: 0.2866, time(ms): 793.34, token/sec:660858.13, hellaswag_acc: 0.2597
Step:  2584, loss: 3.591488, norm: 0.2568, time(ms): 795.38, token/sec:659168.96, hellaswag_acc: 0.2597
Step:  2585, loss: 3.577110, norm: 0.2753, time(ms): 795.03, token/sec:659459.15, hellaswag_acc: 0.2597
Step:  2586, loss: 3.588127, norm: 0.3041, time(ms): 790.38, token/sec:663334.42, hellaswag_acc: 0.2597
Step:  2587, loss: 3.578887, norm: 0.2926, time(ms): 799.95, token/sec:655399.49, hellaswag_acc: 0.2597
Step:  2588, loss: 3.586475, norm: 0.2690, time(ms): 783.65, token/sec:669034.45, hellaswag_acc: 0.2597
Step:  2589, loss: 3.610248, norm: 0.2769, time(ms): 792.53, token/sec:661540.24, hellaswag_acc: 0.2597
Step:  2590, loss: 3.579710, norm: 0.2936, time(ms): 794.43, token/sec:659958.68, hellaswag_acc: 0.2597
Step:  2591, loss: 3.583720, norm: 0.2875, time(ms): 792.51, token/sec:661550.19, hellaswag_acc: 0.2597
Step:  2592, loss: 3.480036, norm: 0.2818, time(ms): 795.55, token/sec:659023.77, hellaswag_acc: 0.2597
Step:  2593, loss: 3.454463, norm: 0.2981, time(ms): 793.76, token/sec:660508.17, hellaswag_acc: 0.2597
Step:  2594, loss: 3.484996, norm: 0.3092, time(ms): 801.52, token/sec:654116.31, hellaswag_acc: 0.2597
Step:  2595, loss: 3.480130, norm: 0.2650, time(ms): 804.58, token/sec:651631.76, hellaswag_acc: 0.2597
Step:  2596, loss: 3.486055, norm: 0.2661, time(ms): 791.68, token/sec:662248.49, hellaswag_acc: 0.2597
Step:  2597, loss: 3.474238, norm: 0.2634, time(ms): 800.39, token/sec:655044.18, hellaswag_acc: 0.2597
Step:  2598, loss: 3.544304, norm: 0.2615, time(ms): 805.88, token/sec:650580.31, hellaswag_acc: 0.2597
Step:  2599, loss: 3.480149, norm: 0.2666, time(ms): 796.77, token/sec:658016.07, hellaswag_acc: 0.2597
Step:  2600, loss: 3.481912, norm: 0.2744, time(ms): 795.02, token/sec:659468.25, hellaswag_acc: 0.2597
Step:  2601, loss: 3.518963, norm: 0.2717, time(ms): 805.72, token/sec:650710.83, hellaswag_acc: 0.2597
Step:  2602, loss: 3.551878, norm: 0.2555, time(ms): 801.74, token/sec:653940.85, hellaswag_acc: 0.2597
Step:  2603, loss: 3.576800, norm: 0.2960, time(ms): 794.88, token/sec:659583.96, hellaswag_acc: 0.2597
Step:  2604, loss: 3.541764, norm: 0.3133, time(ms): 803.17, token/sec:652772.64, hellaswag_acc: 0.2597
Step:  2605, loss: 3.608042, norm: 0.3200, time(ms): 803.16, token/sec:652782.33, hellaswag_acc: 0.2597
Step:  2606, loss: 3.639732, norm: 0.3018, time(ms): 791.91, token/sec:662055.29, hellaswag_acc: 0.2597
Step:  2607, loss: 3.527093, norm: 0.2982, time(ms): 805.03, token/sec:651269.13, hellaswag_acc: 0.2597
Step:  2608, loss: 3.560182, norm: 0.2972, time(ms): 802.80, token/sec:653075.65, hellaswag_acc: 0.2597
Step:  2609, loss: 3.534776, norm: 0.3032, time(ms): 797.59, token/sec:657339.63, hellaswag_acc: 0.2597
Step:  2610, loss: 3.521525, norm: 0.2892, time(ms): 792.38, token/sec:661666.24, hellaswag_acc: 0.2597
Step:  2611, loss: 3.580158, norm: 0.2878, time(ms): 806.63, token/sec:649976.12, hellaswag_acc: 0.2597
Step:  2612, loss: 3.558711, norm: 0.2761, time(ms): 802.00, token/sec:653724.09, hellaswag_acc: 0.2597
Step:  2613, loss: 3.580172, norm: 0.2662, time(ms): 790.47, token/sec:663260.99, hellaswag_acc: 0.2597
Step:  2614, loss: 3.609133, norm: 0.3104, time(ms): 800.04, token/sec:655330.94, hellaswag_acc: 0.2597
Step:  2615, loss: 3.613381, norm: 0.3027, time(ms): 797.00, token/sec:657825.14, hellaswag_acc: 0.2597
Step:  2616, loss: 3.550968, norm: 0.3001, time(ms): 794.18, token/sec:660164.34, hellaswag_acc: 0.2597
Step:  2617, loss: 3.617121, norm: 0.2952, time(ms): 795.03, token/sec:659454.21, hellaswag_acc: 0.2597
Step:  2618, loss: 3.502146, norm: 0.2730, time(ms): 791.95, token/sec:662023.40, hellaswag_acc: 0.2597
Step:  2619, loss: 3.582736, norm: 0.2993, time(ms): 790.29, token/sec:663409.26, hellaswag_acc: 0.2597
Step:  2620, loss: 3.592879, norm: 0.3171, time(ms): 790.87, token/sec:662921.88, hellaswag_acc: 0.2597
Step:  2621, loss: 3.548785, norm: 0.2934, time(ms): 795.88, token/sec:658752.12, hellaswag_acc: 0.2597
Step:  2622, loss: 3.572905, norm: 0.2828, time(ms): 792.23, token/sec:661790.09, hellaswag_acc: 0.2597
Step:  2623, loss: 3.596797, norm: 0.3051, time(ms): 793.14, token/sec:661027.18, hellaswag_acc: 0.2597
Step:  2624, loss: 3.627793, norm: 0.2782, time(ms): 805.53, token/sec:650859.33, hellaswag_acc: 0.2597
Step:  2625, loss: 3.600042, norm: 0.2830, time(ms): 802.05, token/sec:653681.15, hellaswag_acc: 0.2597
Step:  2626, loss: 3.446334, norm: 0.2925, time(ms): 795.99, token/sec:658660.96, hellaswag_acc: 0.2597
Step:  2627, loss: 3.498235, norm: 0.2923, time(ms): 799.63, token/sec:655662.13, hellaswag_acc: 0.2597
Step:  2628, loss: 3.548818, norm: 0.3016, time(ms): 801.77, token/sec:653910.32, hellaswag_acc: 0.2597
Step:  2629, loss: 3.557273, norm: 0.3000, time(ms): 801.91, token/sec:653798.73, hellaswag_acc: 0.2597
Step:  2630, loss: 3.510824, norm: 0.2656, time(ms): 797.30, token/sec:657582.39, hellaswag_acc: 0.2597
Step:  2631, loss: 3.604722, norm: 0.2925, time(ms): 797.68, token/sec:657266.15, hellaswag_acc: 0.2597
Step:  2632, loss: 3.436856, norm: 0.2663, time(ms): 804.79, token/sec:651458.98, hellaswag_acc: 0.2597
Step:  2633, loss: 3.524984, norm: 0.2545, time(ms): 799.57, token/sec:655710.23, hellaswag_acc: 0.2597
Step:  2634, loss: 3.529107, norm: 0.2674, time(ms): 790.97, token/sec:662842.35, hellaswag_acc: 0.2597
Step:  2635, loss: 3.473327, norm: 0.2641, time(ms): 802.96, token/sec:652946.11, hellaswag_acc: 0.2597
Step:  2636, loss: 3.491495, norm: 0.2749, time(ms): 804.63, token/sec:651590.05, hellaswag_acc: 0.2597
Step:  2637, loss: 3.549803, norm: 0.2898, time(ms): 798.17, token/sec:656866.23, hellaswag_acc: 0.2597
Step:  2638, loss: 3.550946, norm: 0.3361, time(ms): 798.39, token/sec:656682.62, hellaswag_acc: 0.2597
Step:  2639, loss: 3.559265, norm: 0.3719, time(ms): 803.67, token/sec:652370.61, hellaswag_acc: 0.2597
Step:  2640, loss: 3.549016, norm: 0.4008, time(ms): 794.34, token/sec:660029.60, hellaswag_acc: 0.2597
Step:  2641, loss: 3.569069, norm: 0.3780, time(ms): 805.22, token/sec:651114.09, hellaswag_acc: 0.2597
Step:  2642, loss: 3.623110, norm: 0.2920, time(ms): 798.69, token/sec:656434.85, hellaswag_acc: 0.2597
Step:  2643, loss: 3.576479, norm: 0.3391, time(ms): 801.41, token/sec:654203.68, hellaswag_acc: 0.2597
Step:  2644, loss: 3.546356, norm: 0.2977, time(ms): 791.38, token/sec:662494.49, hellaswag_acc: 0.2597
Step:  2645, loss: 3.532036, norm: 0.3107, time(ms): 806.94, token/sec:649726.85, hellaswag_acc: 0.2597
Step:  2646, loss: 3.545196, norm: 0.2573, time(ms): 792.15, token/sec:661851.24, hellaswag_acc: 0.2597
Step:  2647, loss: 3.534895, norm: 0.3030, time(ms): 807.12, token/sec:649578.30, hellaswag_acc: 0.2597
Step:  2648, loss: 3.555973, norm: 0.3032, time(ms): 801.56, token/sec:654083.62, hellaswag_acc: 0.2597
Step:  2649, loss: 3.615472, norm: 0.2888, time(ms): 793.26, token/sec:660927.45, hellaswag_acc: 0.2597
Step:  2650, loss: 3.562623, norm: 0.2851, time(ms): 797.75, token/sec:657208.40, hellaswag_acc: 0.2597
Step:  2651, loss: 3.538473, norm: 0.2819, time(ms): 807.52, token/sec:649254.56, hellaswag_acc: 0.2597
Step:  2652, loss: 3.556487, norm: 0.2945, time(ms): 802.09, token/sec:653656.08, hellaswag_acc: 0.2597
Step:  2653, loss: 3.597035, norm: 0.2867, time(ms): 790.05, token/sec:663614.27, hellaswag_acc: 0.2597
Step:  2654, loss: 3.513068, norm: 0.2896, time(ms): 805.70, token/sec:650723.74, hellaswag_acc: 0.2597
Step:  2655, loss: 3.551897, norm: 0.2649, time(ms): 802.36, token/sec:653433.49, hellaswag_acc: 0.2597
Step:  2656, loss: 3.484898, norm: 0.2608, time(ms): 800.44, token/sec:655001.06, hellaswag_acc: 0.2597
Step:  2657, loss: 3.578855, norm: 0.2786, time(ms): 792.48, token/sec:661580.64, hellaswag_acc: 0.2597
Step:  2658, loss: 3.529766, norm: 0.2557, time(ms): 804.39, token/sec:651786.47, hellaswag_acc: 0.2597
Step:  2659, loss: 3.534935, norm: 0.2585, time(ms): 801.95, token/sec:653765.10, hellaswag_acc: 0.2597
Step:  2660, loss: 3.551724, norm: 0.2518, time(ms): 800.09, token/sec:655288.17, hellaswag_acc: 0.2597
Step:  2661, loss: 3.521951, norm: 0.2474, time(ms): 789.32, token/sec:664224.63, hellaswag_acc: 0.2597
Step:  2662, loss: 3.467695, norm: 0.2687, time(ms): 804.49, token/sec:651701.86, hellaswag_acc: 0.2597
Step:  2663, loss: 3.525526, norm: 0.2853, time(ms): 805.54, token/sec:650852.78, hellaswag_acc: 0.2597
Step:  2664, loss: 3.523928, norm: 0.2716, time(ms): 801.50, token/sec:654131.88, hellaswag_acc: 0.2597
Step:  2665, loss: 3.502857, norm: 0.2824, time(ms): 787.99, token/sec:665345.45, hellaswag_acc: 0.2597
Step:  2666, loss: 3.513986, norm: 0.2867, time(ms): 1301.98, token/sec:402685.14, hellaswag_acc: 0.2597
Step:  2667, loss: 3.569495, norm: 0.2878, time(ms): 767.30, token/sec:683293.16, hellaswag_acc: 0.2597
Step:  2668, loss: 3.500957, norm: 0.2917, time(ms): 793.75, token/sec:660518.49, hellaswag_acc: 0.2597
Step:  2669, loss: 3.513642, norm: 0.2994, time(ms): 804.46, token/sec:651729.48, hellaswag_acc: 0.2597
Step:  2670, loss: 3.522598, norm: 0.3015, time(ms): 789.59, token/sec:664003.41, hellaswag_acc: 0.2597
Step:  2671, loss: 3.443784, norm: 0.2621, time(ms): 788.12, token/sec:665242.19, hellaswag_acc: 0.2597
Step:  2672, loss: 3.461329, norm: 0.2939, time(ms): 792.98, token/sec:661164.71, hellaswag_acc: 0.2597
Step:  2673, loss: 3.449987, norm: 0.2912, time(ms): 793.96, token/sec:660341.76, hellaswag_acc: 0.2597
Step:  2674, loss: 3.451817, norm: 0.2723, time(ms): 792.06, token/sec:661931.93, hellaswag_acc: 0.2597
Step:  2675, loss: 3.452451, norm: 0.2847, time(ms): 789.01, token/sec:664484.96, hellaswag_acc: 0.2597
Step:  2676, loss: 3.434959, norm: 0.2895, time(ms): 791.89, token/sec:662075.62, hellaswag_acc: 0.2597
Step:  2677, loss: 3.439764, norm: 0.2810, time(ms): 801.06, token/sec:654489.13, hellaswag_acc: 0.2597
Step:  2678, loss: 3.394842, norm: 0.2831, time(ms): 801.31, token/sec:654288.75, hellaswag_acc: 0.2597
Step:  2679, loss: 3.416181, norm: 0.3261, time(ms): 798.01, token/sec:656994.77, hellaswag_acc: 0.2597
Step:  2680, loss: 3.388569, norm: 0.2661, time(ms): 793.36, token/sec:660842.83, hellaswag_acc: 0.2597
Step:  2681, loss: 3.431349, norm: 0.2787, time(ms): 806.32, token/sec:650223.66, hellaswag_acc: 0.2597
Step:  2682, loss: 3.446670, norm: 0.2867, time(ms): 803.12, token/sec:652810.62, hellaswag_acc: 0.2597
Step:  2683, loss: 3.596495, norm: 0.2870, time(ms): 794.99, token/sec:659486.25, hellaswag_acc: 0.2597
Step:  2684, loss: 3.534820, norm: 0.2932, time(ms): 799.11, token/sec:656088.00, hellaswag_acc: 0.2597
Step:  2685, loss: 3.589408, norm: 0.3028, time(ms): 802.21, token/sec:653551.57, hellaswag_acc: 0.2597
Step:  2686, loss: 3.596953, norm: 0.2917, time(ms): 803.08, token/sec:652849.77, hellaswag_acc: 0.2597
Step:  2687, loss: 3.590456, norm: 0.2939, time(ms): 795.44, token/sec:659115.03, hellaswag_acc: 0.2597
Step:  2688, loss: 3.612315, norm: 0.2677, time(ms): 797.22, token/sec:657643.95, hellaswag_acc: 0.2597
Step:  2689, loss: 3.561845, norm: 0.2657, time(ms): 805.79, token/sec:650649.42, hellaswag_acc: 0.2597
Step:  2690, loss: 3.550332, norm: 0.2544, time(ms): 798.76, token/sec:656376.07, hellaswag_acc: 0.2597
Step:  2691, loss: 3.548010, norm: 0.2698, time(ms): 792.23, token/sec:661784.52, hellaswag_acc: 0.2597
Step:  2692, loss: 3.591424, norm: 0.2749, time(ms): 806.62, token/sec:649985.34, hellaswag_acc: 0.2597
Step:  2693, loss: 3.504876, norm: 0.2969, time(ms): 801.06, token/sec:654492.05, hellaswag_acc: 0.2597
Step:  2694, loss: 3.500237, norm: 0.2627, time(ms): 799.51, token/sec:655765.17, hellaswag_acc: 0.2597
Step:  2695, loss: 3.487695, norm: 0.2607, time(ms): 799.72, token/sec:655589.61, hellaswag_acc: 0.2597
Step:  2696, loss: 3.505272, norm: 0.2576, time(ms): 795.41, token/sec:659143.08, hellaswag_acc: 0.2597
Step:  2697, loss: 3.520669, norm: 0.2828, time(ms): 802.83, token/sec:653046.55, hellaswag_acc: 0.2597
Step:  2698, loss: 3.497344, norm: 0.2716, time(ms): 803.22, token/sec:652731.56, hellaswag_acc: 0.2597
Step:  2699, loss: 3.508676, norm: 0.2523, time(ms): 791.98, token/sec:661999.48, hellaswag_acc: 0.2597
Step:  2700, loss: 3.503057, norm: 0.2551, time(ms): 804.59, token/sec:651624.81, hellaswag_acc: 0.2597
Step:  2701, loss: 3.497860, norm: 0.2694, time(ms): 802.59, token/sec:653242.68, hellaswag_acc: 0.2597
Step:  2702, loss: 3.462473, norm: 0.2739, time(ms): 798.66, token/sec:656458.17, hellaswag_acc: 0.2597
Step:  2703, loss: 3.490607, norm: 0.2882, time(ms): 792.38, token/sec:661658.67, hellaswag_acc: 0.2597
Step:  2704, loss: 3.438734, norm: 0.3050, time(ms): 805.67, token/sec:650750.31, hellaswag_acc: 0.2597
Step:  2705, loss: 3.428004, norm: 0.3150, time(ms): 803.13, token/sec:652802.87, hellaswag_acc: 0.2597
Step:  2706, loss: 3.442467, norm: 0.3164, time(ms): 789.03, token/sec:664472.71, hellaswag_acc: 0.2597
Step:  2707, loss: 3.410564, norm: 0.2789, time(ms): 805.65, token/sec:650760.71, hellaswag_acc: 0.2597
Step:  2708, loss: 3.468613, norm: 0.2416, time(ms): 804.52, token/sec:651674.82, hellaswag_acc: 0.2597
Step:  2709, loss: 3.424435, norm: 0.2804, time(ms): 798.02, token/sec:656984.37, hellaswag_acc: 0.2597
Step:  2710, loss: 3.402405, norm: 0.2689, time(ms): 795.19, token/sec:659325.89, hellaswag_acc: 0.2597
Step:  2711, loss: 3.436733, norm: 0.2895, time(ms): 800.49, token/sec:654960.87, hellaswag_acc: 0.2597
Step:  2712, loss: 3.399199, norm: 0.3221, time(ms): 804.81, token/sec:651443.35, hellaswag_acc: 0.2597
Step:  2713, loss: 3.424153, norm: 0.3326, time(ms): 798.93, token/sec:656233.86, hellaswag_acc: 0.2597
Step:  2714, loss: 3.372390, norm: 0.2990, time(ms): 797.51, token/sec:657407.63, hellaswag_acc: 0.2597
Step:  2715, loss: 3.445731, norm: 0.2928, time(ms): 801.86, token/sec:653836.05, hellaswag_acc: 0.2597
Step:  2716, loss: 3.430541, norm: 0.2847, time(ms): 802.17, token/sec:653589.64, hellaswag_acc: 0.2597
Step:  2717, loss: 3.469735, norm: 0.2943, time(ms): 790.08, token/sec:663586.84, hellaswag_acc: 0.2597
Step:  2718, loss: 3.570511, norm: 0.2763, time(ms): 806.72, token/sec:649899.28, hellaswag_acc: 0.2597
Step:  2719, loss: 3.537608, norm: 0.3058, time(ms): 802.19, token/sec:653571.96, hellaswag_acc: 0.2597
Step:  2720, loss: 3.609135, norm: 0.3263, time(ms): 795.51, token/sec:659061.49, hellaswag_acc: 0.2597
Step:  2721, loss: 3.596459, norm: 0.3341, time(ms): 803.99, token/sec:652108.67, hellaswag_acc: 0.2597
Step:  2722, loss: 3.597924, norm: 0.3583, time(ms): 799.41, token/sec:655842.43, hellaswag_acc: 0.2597
Step:  2723, loss: 3.601485, norm: 0.3274, time(ms): 797.29, token/sec:657590.65, hellaswag_acc: 0.2597
Step:  2724, loss: 3.494418, norm: 0.3258, time(ms): 802.39, token/sec:653405.73, hellaswag_acc: 0.2597
Step:  2725, loss: 3.533761, norm: 0.3027, time(ms): 798.83, token/sec:656316.51, hellaswag_acc: 0.2597
Step:  2726, loss: 3.628459, norm: 0.3259, time(ms): 796.81, token/sec:657982.80, hellaswag_acc: 0.2597
Step:  2727, loss: 3.619803, norm: 0.3107, time(ms): 802.07, token/sec:653669.88, hellaswag_acc: 0.2597
Step:  2728, loss: 3.531226, norm: 0.3065, time(ms): 801.67, token/sec:653994.73, hellaswag_acc: 0.2597
Step:  2729, loss: 3.573199, norm: 0.3334, time(ms): 796.96, token/sec:657861.94, hellaswag_acc: 0.2597
Step:  2730, loss: 3.495145, norm: 0.3703, time(ms): 801.14, token/sec:654429.92, hellaswag_acc: 0.2597
Step:  2731, loss: 3.525052, norm: 0.3393, time(ms): 802.33, token/sec:653456.79, hellaswag_acc: 0.2597
Step:  2732, loss: 3.489105, norm: 0.3269, time(ms): 799.75, token/sec:655562.84, hellaswag_acc: 0.2597
Step:  2733, loss: 3.509505, norm: 0.2856, time(ms): 794.69, token/sec:659741.48, hellaswag_acc: 0.2597
Step:  2734, loss: 3.456349, norm: 0.2830, time(ms): 800.81, token/sec:654696.45, hellaswag_acc: 0.2597
Step:  2735, loss: 3.449685, norm: 0.2604, time(ms): 804.18, token/sec:651951.49, hellaswag_acc: 0.2597
Step:  2736, loss: 3.489920, norm: 0.2693, time(ms): 792.31, token/sec:661723.38, hellaswag_acc: 0.2597
Step:  2737, loss: 3.517346, norm: 0.2903, time(ms): 805.14, token/sec:651176.95, hellaswag_acc: 0.2597
Step:  2738, loss: 3.511940, norm: 0.2769, time(ms): 800.30, token/sec:655115.79, hellaswag_acc: 0.2597
Step:  2739, loss: 3.503945, norm: 0.2765, time(ms): 799.87, token/sec:655468.85, hellaswag_acc: 0.2597
Step:  2740, loss: 3.477252, norm: 0.2688, time(ms): 799.48, token/sec:655786.29, hellaswag_acc: 0.2597
Step:  2741, loss: 3.402716, norm: 0.2471, time(ms): 800.07, token/sec:655306.53, hellaswag_acc: 0.2597
Step:  2742, loss: 3.415660, norm: 0.2538, time(ms): 800.97, token/sec:654564.52, hellaswag_acc: 0.2597
Step:  2743, loss: 3.371086, norm: 0.2711, time(ms): 797.45, token/sec:657456.18, hellaswag_acc: 0.2597
Step:  2744, loss: 3.415415, norm: 0.2748, time(ms): 801.08, token/sec:654479.39, hellaswag_acc: 0.2597
Step:  2745, loss: 3.385373, norm: 0.2485, time(ms): 799.46, token/sec:655806.24, hellaswag_acc: 0.2597
Step:  2746, loss: 3.388708, norm: 0.2506, time(ms): 799.21, token/sec:656008.53, hellaswag_acc: 0.2597
Step:  2747, loss: 3.434458, norm: 0.2477, time(ms): 792.11, token/sec:661890.49, hellaswag_acc: 0.2597
Step:  2748, loss: 3.394148, norm: 0.2322, time(ms): 792.43, token/sec:661623.24, hellaswag_acc: 0.2597
Step:  2749, loss: 3.397462, norm: 0.2465, time(ms): 791.69, token/sec:662236.52, hellaswag_acc: 0.2597
rank 0 sample 0: Hello, I'm a language model, and I think it is something to consider - just because you have that you don't need to think like I'm going
rank 0 sample 1: Hello, I'm a language model, I was also a programming language, which is what students at my school all of us have in our own school. So
rank 0 sample 2: Hello, I'm a language model, I'm teaching an adult that loves English. When I teach it on a computer, it's a math problem, but
rank 0 sample 3: Hello, I'm a language model, which, I can't, is something like learning a language. This is what learning a language model (rather than taking
rank 1 sample 0: Hello, I'm a language model,
What's the difference between a student-centred design is that a student-centred design is a design that
rank 1 sample 1: Hello, I'm a language model, but you have to have a very large learning curve. What are you waiting for? Maybe you can just get some ideas
rank 1 sample 2: Hello, I'm a language model, you got it and it's a lot of fun. You are not a language model, but the way to use the
rank 1 sample 3: Hello, I'm a language model, but I'm sure I just had something handy.
Do you work with many languages/like, or do you have
Step:  2750, loss: 3.450622, norm: 0.2331, time(ms): 3807.07, token/sec:137714.15, val_loss: 3.5347, hellaswag_acc: 0.2597
Step:  2751, loss: 3.454953, norm: 0.2971, time(ms): 783.80, token/sec:668902.78, hellaswag_acc: 0.2597
Step:  2752, loss: 3.384958, norm: 0.3170, time(ms): 787.55, token/sec:665717.07, hellaswag_acc: 0.2597
Step:  2753, loss: 3.661634, norm: 0.3630, time(ms): 803.40, token/sec:652585.12, hellaswag_acc: 0.2597
Step:  2754, loss: 3.551382, norm: 0.3284, time(ms): 803.43, token/sec:652560.14, hellaswag_acc: 0.2597
Step:  2755, loss: 3.539623, norm: 0.4024, time(ms): 786.20, token/sec:666862.55, hellaswag_acc: 0.2597
Step:  2756, loss: 3.632262, norm: 0.3896, time(ms): 788.80, token/sec:664666.52, hellaswag_acc: 0.2597
Step:  2757, loss: 3.611646, norm: 0.3573, time(ms): 796.60, token/sec:658159.64, hellaswag_acc: 0.2597
Step:  2758, loss: 3.564439, norm: 0.3088, time(ms): 797.54, token/sec:657381.88, hellaswag_acc: 0.2597
Step:  2759, loss: 3.570399, norm: 0.2996, time(ms): 798.25, token/sec:656792.66, hellaswag_acc: 0.2597
Step:  2760, loss: 3.541172, norm: 0.3044, time(ms): 790.91, token/sec:662892.11, hellaswag_acc: 0.2597
Step:  2761, loss: 3.618346, norm: 0.2799, time(ms): 792.01, token/sec:661968.79, hellaswag_acc: 0.2597
Step:  2762, loss: 3.591550, norm: 0.2611, time(ms): 796.40, token/sec:658321.41, hellaswag_acc: 0.2597
Step:  2763, loss: 3.557901, norm: 0.2797, time(ms): 793.36, token/sec:660847.80, hellaswag_acc: 0.2597
Step:  2764, loss: 3.483613, norm: 0.2720, time(ms): 786.91, token/sec:666260.65, hellaswag_acc: 0.2597
Step:  2765, loss: 3.628798, norm: 0.3904, time(ms): 796.78, token/sec:658009.38, hellaswag_acc: 0.2597
Step:  2766, loss: 3.502936, norm: 0.4493, time(ms): 790.85, token/sec:662944.87, hellaswag_acc: 0.2597
Step:  2767, loss: 3.460187, norm: 0.3739, time(ms): 792.41, token/sec:661634.38, hellaswag_acc: 0.2597
Step:  2768, loss: 3.507082, norm: 0.3705, time(ms): 792.98, token/sec:661160.34, hellaswag_acc: 0.2597
Step:  2769, loss: 3.469383, norm: 0.3267, time(ms): 788.24, token/sec:665137.96, hellaswag_acc: 0.2597
Step:  2770, loss: 3.500519, norm: 0.3177, time(ms): 798.39, token/sec:656681.84, hellaswag_acc: 0.2597
Step:  2771, loss: 3.474376, norm: 0.2764, time(ms): 792.82, token/sec:661292.16, hellaswag_acc: 0.2597
Step:  2772, loss: 3.493664, norm: 0.2711, time(ms): 799.00, token/sec:656182.75, hellaswag_acc: 0.2597
Step:  2773, loss: 3.473271, norm: 0.2535, time(ms): 786.41, token/sec:666685.04, hellaswag_acc: 0.2597
Step:  2774, loss: 3.442594, norm: 0.2576, time(ms): 793.03, token/sec:661121.38, hellaswag_acc: 0.2597
Step:  2775, loss: 3.462632, norm: 0.2971, time(ms): 791.97, token/sec:662009.05, hellaswag_acc: 0.2597
Step:  2776, loss: 3.439887, norm: 0.3135, time(ms): 792.51, token/sec:661555.56, hellaswag_acc: 0.2597
Step:  2777, loss: 3.430977, norm: 0.2975, time(ms): 790.37, token/sec:663341.62, hellaswag_acc: 0.2597
Step:  2778, loss: 3.493730, norm: 0.2694, time(ms): 802.89, token/sec:653003.89, hellaswag_acc: 0.2597
Step:  2779, loss: 3.431356, norm: 0.2691, time(ms): 794.67, token/sec:659752.96, hellaswag_acc: 0.2597
Step:  2780, loss: 3.433270, norm: 0.2574, time(ms): 799.75, token/sec:655564.01, hellaswag_acc: 0.2597
Step:  2781, loss: 3.441254, norm: 0.2606, time(ms): 803.49, token/sec:652510.76, hellaswag_acc: 0.2597
Step:  2782, loss: 3.402040, norm: 0.2869, time(ms): 800.55, token/sec:654911.71, hellaswag_acc: 0.2597
Step:  2783, loss: 3.467730, norm: 0.2854, time(ms): 798.79, token/sec:656349.23, hellaswag_acc: 0.2597
Step:  2784, loss: 3.387954, norm: 0.2447, time(ms): 793.56, token/sec:660675.46, hellaswag_acc: 0.2597
Step:  2785, loss: 3.375507, norm: 0.2493, time(ms): 804.92, token/sec:651356.71, hellaswag_acc: 0.2597
Step:  2786, loss: 3.404975, norm: 0.2861, time(ms): 802.62, token/sec:653219.79, hellaswag_acc: 0.2597
Step:  2787, loss: 3.422325, norm: 0.3235, time(ms): 796.20, token/sec:658491.53, hellaswag_acc: 0.2597
Step:  2788, loss: 3.515308, norm: 0.3047, time(ms): 800.02, token/sec:655347.15, hellaswag_acc: 0.2597
Step:  2789, loss: 3.523520, norm: 0.2613, time(ms): 801.95, token/sec:653763.74, hellaswag_acc: 0.2597
Step:  2790, loss: 3.564991, norm: 0.2746, time(ms): 802.29, token/sec:653490.78, hellaswag_acc: 0.2597
Step:  2791, loss: 3.574924, norm: 0.2888, time(ms): 791.51, token/sec:662393.51, hellaswag_acc: 0.2597
Step:  2792, loss: 3.585969, norm: 0.3207, time(ms): 801.73, token/sec:653943.77, hellaswag_acc: 0.2597
Step:  2793, loss: 3.565148, norm: 0.2936, time(ms): 805.00, token/sec:651293.05, hellaswag_acc: 0.2597
Step:  2794, loss: 3.528445, norm: 0.2565, time(ms): 800.30, token/sec:655113.45, hellaswag_acc: 0.2597
Step:  2795, loss: 3.550104, norm: 0.2945, time(ms): 792.93, token/sec:661202.88, hellaswag_acc: 0.2597
Step:  2796, loss: 3.634277, norm: 0.3452, time(ms): 804.00, token/sec:652100.16, hellaswag_acc: 0.2597
Step:  2797, loss: 3.503677, norm: 0.3456, time(ms): 803.03, token/sec:652884.08, hellaswag_acc: 0.2597
Step:  2798, loss: 3.564187, norm: 0.3169, time(ms): 794.97, token/sec:659505.43, hellaswag_acc: 0.2597
Step:  2799, loss: 3.482491, norm: 0.2978, time(ms): 795.98, token/sec:658666.28, hellaswag_acc: 0.2597
Step:  2800, loss: 3.459363, norm: 0.2793, time(ms): 805.23, token/sec:651104.07, hellaswag_acc: 0.2597
Step:  2801, loss: 3.492176, norm: 0.2636, time(ms): 803.96, token/sec:652133.62, hellaswag_acc: 0.2597
Step:  2802, loss: 3.478510, norm: 0.2757, time(ms): 787.76, token/sec:665545.81, hellaswag_acc: 0.2597
Step:  2803, loss: 3.472621, norm: 0.2738, time(ms): 795.64, token/sec:658949.12, hellaswag_acc: 0.2597
Step:  2804, loss: 3.533902, norm: 0.2637, time(ms): 791.61, token/sec:662304.14, hellaswag_acc: 0.2597
Step:  2805, loss: 3.529059, norm: 0.2741, time(ms): 792.90, token/sec:661225.35, hellaswag_acc: 0.2597
Step:  2806, loss: 3.485487, norm: 0.2384, time(ms): 791.72, token/sec:662215.58, hellaswag_acc: 0.2597
Step:  2807, loss: 3.437446, norm: 0.2577, time(ms): 788.00, token/sec:665343.43, hellaswag_acc: 0.2597
Step:  2808, loss: 3.490306, norm: 0.2701, time(ms): 793.58, token/sec:660663.95, hellaswag_acc: 0.2597
Step:  2809, loss: 3.475671, norm: 0.2508, time(ms): 794.69, token/sec:659739.30, hellaswag_acc: 0.2597
Step:  2810, loss: 3.484658, norm: 0.2584, time(ms): 800.24, token/sec:655166.74, hellaswag_acc: 0.2597
Step:  2811, loss: 3.408018, norm: 0.2536, time(ms): 791.93, token/sec:662040.34, hellaswag_acc: 0.2597
Step:  2812, loss: 3.405739, norm: 0.2384, time(ms): 798.57, token/sec:656534.99, hellaswag_acc: 0.2597
Step:  2813, loss: 3.381578, norm: 0.2562, time(ms): 797.93, token/sec:657058.37, hellaswag_acc: 0.2597
Step:  2814, loss: 3.392829, norm: 0.2437, time(ms): 789.90, token/sec:663741.46, hellaswag_acc: 0.2597
Step:  2815, loss: 3.391703, norm: 0.2382, time(ms): 788.88, token/sec:664594.40, hellaswag_acc: 0.2597
Step:  2816, loss: 3.383671, norm: 0.2464, time(ms): 794.35, token/sec:660018.90, hellaswag_acc: 0.2597
Step:  2817, loss: 3.492127, norm: 0.2700, time(ms): 796.65, token/sec:658113.95, hellaswag_acc: 0.2597
Step:  2818, loss: 3.456795, norm: 0.2914, time(ms): 794.37, token/sec:660007.02, hellaswag_acc: 0.2597
Step:  2819, loss: 3.422084, norm: 0.2924, time(ms): 804.56, token/sec:651645.86, hellaswag_acc: 0.2597
Step:  2820, loss: 3.370042, norm: 0.3044, time(ms): 801.75, token/sec:653932.49, hellaswag_acc: 0.2597
Step:  2821, loss: 3.435918, norm: 0.3306, time(ms): 795.06, token/sec:659433.05, hellaswag_acc: 0.2597
Step:  2822, loss: 3.379473, norm: 0.3117, time(ms): 799.02, token/sec:656166.30, hellaswag_acc: 0.2597
Step:  2823, loss: 3.440115, norm: 0.3076, time(ms): 802.83, token/sec:653047.52, hellaswag_acc: 0.2597
Step:  2824, loss: 3.516345, norm: 0.2887, time(ms): 803.56, token/sec:652455.59, hellaswag_acc: 0.2597
Step:  2825, loss: 3.566999, norm: 0.3124, time(ms): 799.31, token/sec:655925.37, hellaswag_acc: 0.2597
Step:  2826, loss: 3.555651, norm: 0.3593, time(ms): 790.93, token/sec:662877.52, hellaswag_acc: 0.2597
Step:  2827, loss: 3.539074, norm: 0.3926, time(ms): 808.00, token/sec:648870.83, hellaswag_acc: 0.2597
Step:  2828, loss: 3.497910, norm: 0.3521, time(ms): 791.03, token/sec:662791.01, hellaswag_acc: 0.2597
Step:  2829, loss: 3.498835, norm: 0.3538, time(ms): 798.95, token/sec:656217.21, hellaswag_acc: 0.2597
Step:  2830, loss: 3.528942, norm: 0.2826, time(ms): 796.77, token/sec:658015.88, hellaswag_acc: 0.2597
Step:  2831, loss: 3.488684, norm: 0.2833, time(ms): 792.05, token/sec:661937.11, hellaswag_acc: 0.2597
Step:  2832, loss: 3.527920, norm: 0.2926, time(ms): 786.76, token/sec:666385.02, hellaswag_acc: 0.2597
Step:  2833, loss: 3.558378, norm: 0.2620, time(ms): 793.81, token/sec:660469.09, hellaswag_acc: 0.2597
Step:  2834, loss: 3.463363, norm: 0.2684, time(ms): 796.28, token/sec:658421.93, hellaswag_acc: 0.2597
Step:  2835, loss: 3.511674, norm: 0.2513, time(ms): 801.87, token/sec:653832.75, hellaswag_acc: 0.2597
Step:  2836, loss: 3.453383, norm: 0.2619, time(ms): 797.72, token/sec:657232.56, hellaswag_acc: 0.2597
Step:  2837, loss: 3.483447, norm: 0.2791, time(ms): 801.75, token/sec:653928.41, hellaswag_acc: 0.2597
Step:  2838, loss: 3.479918, norm: 0.2826, time(ms): 801.85, token/sec:653847.33, hellaswag_acc: 0.2597
Step:  2839, loss: 3.490237, norm: 0.2751, time(ms): 796.55, token/sec:658200.82, hellaswag_acc: 0.2597
Step:  2840, loss: 3.451345, norm: 0.2588, time(ms): 797.22, token/sec:657646.11, hellaswag_acc: 0.2597
Step:  2841, loss: 3.457992, norm: 0.2559, time(ms): 801.34, token/sec:654266.94, hellaswag_acc: 0.2597
Step:  2842, loss: 3.516356, norm: 0.2677, time(ms): 800.68, token/sec:654803.68, hellaswag_acc: 0.2597
Step:  2843, loss: 3.498778, norm: 0.2588, time(ms): 801.67, token/sec:653997.06, hellaswag_acc: 0.2597
Step:  2844, loss: 3.479050, norm: 0.2789, time(ms): 798.40, token/sec:656674.19, hellaswag_acc: 0.2597
Step:  2845, loss: 3.541136, norm: 0.2831, time(ms): 799.45, token/sec:655808.39, hellaswag_acc: 0.2597
Step:  2846, loss: 3.481356, norm: 0.2995, time(ms): 799.17, token/sec:656042.00, hellaswag_acc: 0.2597
Step:  2847, loss: 3.428710, norm: 0.2908, time(ms): 803.68, token/sec:652357.26, hellaswag_acc: 0.2597
Step:  2848, loss: 3.452103, norm: 0.2943, time(ms): 799.32, token/sec:655919.50, hellaswag_acc: 0.2597
Step:  2849, loss: 3.457138, norm: 0.2747, time(ms): 791.24, token/sec:662613.46, hellaswag_acc: 0.2597
Step:  2850, loss: 3.374408, norm: 0.2641, time(ms): 803.23, token/sec:652721.10, hellaswag_acc: 0.2597
Step:  2851, loss: 3.434164, norm: 0.2812, time(ms): 805.54, token/sec:650851.43, hellaswag_acc: 0.2597
Step:  2852, loss: 3.411335, norm: 0.3267, time(ms): 799.95, token/sec:655397.93, hellaswag_acc: 0.2597
Step:  2853, loss: 3.399854, norm: 0.3083, time(ms): 790.90, token/sec:662902.50, hellaswag_acc: 0.2597
Step:  2854, loss: 3.399440, norm: 0.2527, time(ms): 802.44, token/sec:653366.12, hellaswag_acc: 0.2597
Step:  2855, loss: 3.347109, norm: 0.2598, time(ms): 803.95, token/sec:652138.26, hellaswag_acc: 0.2597
Step:  2856, loss: 3.431689, norm: 0.2623, time(ms): 797.61, token/sec:657320.57, hellaswag_acc: 0.2597
Step:  2857, loss: 3.449207, norm: 0.2804, time(ms): 1284.57, token/sec:408143.26, hellaswag_acc: 0.2597
Step:  2858, loss: 3.445450, norm: 0.2891, time(ms): 797.69, token/sec:657256.13, hellaswag_acc: 0.2597
Step:  2859, loss: 3.468468, norm: 0.2774, time(ms): 787.22, token/sec:666001.36, hellaswag_acc: 0.2597
Step:  2860, loss: 3.429069, norm: 0.2714, time(ms): 789.02, token/sec:664478.93, hellaswag_acc: 0.2597
Step:  2861, loss: 3.509127, norm: 0.2700, time(ms): 793.35, token/sec:660849.98, hellaswag_acc: 0.2597
Step:  2862, loss: 3.488147, norm: 0.2488, time(ms): 803.61, token/sec:652417.84, hellaswag_acc: 0.2597
Step:  2863, loss: 3.384713, norm: 0.2835, time(ms): 789.76, token/sec:663857.28, hellaswag_acc: 0.2597
Step:  2864, loss: 3.551118, norm: 0.3557, time(ms): 780.65, token/sec:671602.88, hellaswag_acc: 0.2597
Step:  2865, loss: 3.436970, norm: 0.4048, time(ms): 784.13, token/sec:668621.71, hellaswag_acc: 0.2597
Step:  2866, loss: 3.445740, norm: 0.3240, time(ms): 799.08, token/sec:656111.88, hellaswag_acc: 0.2597
Step:  2867, loss: 3.314222, norm: 0.3493, time(ms): 794.88, token/sec:659583.96, hellaswag_acc: 0.2597
Step:  2868, loss: 3.248880, norm: 0.3107, time(ms): 785.08, token/sec:667811.74, hellaswag_acc: 0.2597
Step:  2869, loss: 3.274222, norm: 0.3014, time(ms): 790.68, token/sec:663083.20, hellaswag_acc: 0.2597
Step:  2870, loss: 3.305207, norm: 0.2965, time(ms): 801.56, token/sec:654084.21, hellaswag_acc: 0.2597
Step:  2871, loss: 3.289521, norm: 0.2940, time(ms): 793.34, token/sec:660862.30, hellaswag_acc: 0.2597
Step:  2872, loss: 3.300481, norm: 0.2916, time(ms): 801.73, token/sec:653943.38, hellaswag_acc: 0.2597
Step:  2873, loss: 3.242491, norm: 0.2584, time(ms): 794.43, token/sec:659955.71, hellaswag_acc: 0.2597
Step:  2874, loss: 3.271503, norm: 0.2608, time(ms): 792.57, token/sec:661503.62, hellaswag_acc: 0.2597
Step:  2875, loss: 3.279379, norm: 0.2668, time(ms): 791.61, token/sec:662308.92, hellaswag_acc: 0.2597
Step:  2876, loss: 3.350720, norm: 0.2759, time(ms): 789.40, token/sec:664160.24, hellaswag_acc: 0.2597
Step:  2877, loss: 3.324138, norm: 0.2568, time(ms): 789.67, token/sec:663934.85, hellaswag_acc: 0.2597
Step:  2878, loss: 3.498999, norm: 0.2962, time(ms): 804.78, token/sec:651467.28, hellaswag_acc: 0.2597
Step:  2879, loss: 3.460924, norm: 0.4110, time(ms): 801.18, token/sec:654395.83, hellaswag_acc: 0.2597
Step:  2880, loss: 3.541072, norm: 0.2921, time(ms): 796.11, token/sec:658561.54, hellaswag_acc: 0.2597
Step:  2881, loss: 3.571592, norm: 0.2951, time(ms): 803.29, token/sec:652679.25, hellaswag_acc: 0.2597
Step:  2882, loss: 3.486529, norm: 0.2892, time(ms): 800.11, token/sec:655272.16, hellaswag_acc: 0.2597
Step:  2883, loss: 3.462733, norm: 0.2645, time(ms): 795.84, token/sec:658787.84, hellaswag_acc: 0.2597
Step:  2884, loss: 3.482173, norm: 0.2734, time(ms): 799.94, token/sec:655409.65, hellaswag_acc: 0.2597
Step:  2885, loss: 3.525922, norm: 0.2640, time(ms): 804.69, token/sec:651539.28, hellaswag_acc: 0.2597
Step:  2886, loss: 3.525926, norm: 0.2748, time(ms): 800.39, token/sec:655036.96, hellaswag_acc: 0.2597
Step:  2887, loss: 3.550867, norm: 0.2737, time(ms): 791.80, token/sec:662144.60, hellaswag_acc: 0.2597
Step:  2888, loss: 3.548274, norm: 0.2631, time(ms): 805.41, token/sec:650959.51, hellaswag_acc: 0.2597
Step:  2889, loss: 3.536992, norm: 0.2658, time(ms): 802.10, token/sec:653647.92, hellaswag_acc: 0.2597
Step:  2890, loss: 3.526310, norm: 0.2625, time(ms): 796.35, token/sec:658367.13, hellaswag_acc: 0.2597
Step:  2891, loss: 3.517323, norm: 0.2716, time(ms): 802.28, token/sec:653501.26, hellaswag_acc: 0.2597
Step:  2892, loss: 3.505992, norm: 0.2616, time(ms): 797.64, token/sec:657302.89, hellaswag_acc: 0.2597
Step:  2893, loss: 3.509516, norm: 0.2536, time(ms): 799.37, token/sec:655875.87, hellaswag_acc: 0.2597
Step:  2894, loss: 3.586270, norm: 0.2781, time(ms): 803.73, token/sec:652322.23, hellaswag_acc: 0.2597
Step:  2895, loss: 3.501824, norm: 0.2965, time(ms): 798.04, token/sec:656972.00, hellaswag_acc: 0.2597
Step:  2896, loss: 3.524920, norm: 0.2773, time(ms): 796.78, token/sec:658012.33, hellaswag_acc: 0.2597
Step:  2897, loss: 3.509329, norm: 0.2831, time(ms): 802.91, token/sec:652985.47, hellaswag_acc: 0.2597
Step:  2898, loss: 3.492681, norm: 0.2975, time(ms): 796.68, token/sec:658094.25, hellaswag_acc: 0.2597
Step:  2899, loss: 3.532480, norm: 0.2502, time(ms): 804.34, token/sec:651822.60, hellaswag_acc: 0.2597
Step:  2900, loss: 3.478020, norm: 0.2541, time(ms): 799.57, token/sec:655711.99, hellaswag_acc: 0.2597
Step:  2901, loss: 3.494912, norm: 0.2576, time(ms): 794.88, token/sec:659585.35, hellaswag_acc: 0.2597
Step:  2902, loss: 3.463946, norm: 0.2555, time(ms): 799.56, token/sec:655722.94, hellaswag_acc: 0.2597
Step:  2903, loss: 3.467220, norm: 0.2567, time(ms): 805.02, token/sec:651270.48, hellaswag_acc: 0.2597
Step:  2904, loss: 3.464551, norm: 0.3093, time(ms): 794.06, token/sec:660261.07, hellaswag_acc: 0.2597
Step:  2905, loss: 3.451930, norm: 0.3306, time(ms): 804.20, token/sec:651935.06, hellaswag_acc: 0.2597
Step:  2906, loss: 3.528198, norm: 0.3322, time(ms): 799.20, token/sec:656015.38, hellaswag_acc: 0.2597
Step:  2907, loss: 3.472170, norm: 0.3091, time(ms): 802.29, token/sec:653488.64, hellaswag_acc: 0.2597
Step:  2908, loss: 3.442277, norm: 0.2974, time(ms): 798.58, token/sec:656521.86, hellaswag_acc: 0.2597
Step:  2909, loss: 3.496332, norm: 0.2863, time(ms): 794.97, token/sec:659503.06, hellaswag_acc: 0.2597
Step:  2910, loss: 3.471355, norm: 0.2908, time(ms): 802.93, token/sec:652967.05, hellaswag_acc: 0.2597
Step:  2911, loss: 3.476566, norm: 0.2943, time(ms): 801.93, token/sec:653780.65, hellaswag_acc: 0.2597
Step:  2912, loss: 3.484852, norm: 0.2737, time(ms): 799.64, token/sec:655655.68, hellaswag_acc: 0.2597
Step:  2913, loss: 3.266940, norm: 0.3050, time(ms): 793.83, token/sec:660455.60, hellaswag_acc: 0.2597
Step:  2914, loss: 3.288769, norm: 0.3228, time(ms): 804.12, token/sec:652004.07, hellaswag_acc: 0.2597
Step:  2915, loss: 3.243627, norm: 0.3198, time(ms): 801.73, token/sec:653943.77, hellaswag_acc: 0.2597
Step:  2916, loss: 3.322042, norm: 0.3595, time(ms): 791.92, token/sec:662043.53, hellaswag_acc: 0.2597
Step:  2917, loss: 3.285797, norm: 0.3433, time(ms): 803.73, token/sec:652315.65, hellaswag_acc: 0.2597
Step:  2918, loss: 3.368698, norm: 0.3471, time(ms): 804.26, token/sec:651887.52, hellaswag_acc: 0.2597
Step:  2919, loss: 3.276286, norm: 0.3639, time(ms): 801.02, token/sec:654523.80, hellaswag_acc: 0.2597
Step:  2920, loss: 3.305956, norm: 0.3464, time(ms): 792.92, token/sec:661215.41, hellaswag_acc: 0.2597
Step:  2921, loss: 3.286205, norm: 0.2896, time(ms): 805.55, token/sec:650843.72, hellaswag_acc: 0.2597
Step:  2922, loss: 3.315085, norm: 0.2603, time(ms): 799.93, token/sec:655415.71, hellaswag_acc: 0.2597
Step:  2923, loss: 3.320496, norm: 0.2997, time(ms): 800.60, token/sec:654867.83, hellaswag_acc: 0.2597
Step:  2924, loss: 3.435340, norm: 0.2687, time(ms): 793.58, token/sec:660663.15, hellaswag_acc: 0.2597
Step:  2925, loss: 3.606136, norm: 0.2646, time(ms): 802.01, token/sec:653717.49, hellaswag_acc: 0.2597
Step:  2926, loss: 3.504969, norm: 0.2721, time(ms): 803.58, token/sec:652442.62, hellaswag_acc: 0.2597
Step:  2927, loss: 3.609994, norm: 0.3042, time(ms): 798.73, token/sec:656400.56, hellaswag_acc: 0.2597
Step:  2928, loss: 3.502534, norm: 0.3017, time(ms): 799.46, token/sec:655806.63, hellaswag_acc: 0.2597
Step:  2929, loss: 3.526016, norm: 0.3008, time(ms): 796.68, token/sec:658094.25, hellaswag_acc: 0.2597
Step:  2930, loss: 3.481306, norm: 0.2592, time(ms): 801.93, token/sec:653784.15, hellaswag_acc: 0.2597
Step:  2931, loss: 3.610727, norm: 0.3257, time(ms): 802.52, token/sec:653304.40, hellaswag_acc: 0.2597
Step:  2932, loss: 3.493639, norm: 0.3686, time(ms): 794.23, token/sec:660123.91, hellaswag_acc: 0.2597
Step:  2933, loss: 3.512187, norm: 0.2833, time(ms): 802.88, token/sec:653007.77, hellaswag_acc: 0.2597
Step:  2934, loss: 3.542103, norm: 0.2908, time(ms): 799.17, token/sec:656042.78, hellaswag_acc: 0.2597
Step:  2935, loss: 3.592371, norm: 0.2903, time(ms): 803.13, token/sec:652807.33, hellaswag_acc: 0.2597
Step:  2936, loss: 3.466192, norm: 0.2636, time(ms): 793.36, token/sec:660847.00, hellaswag_acc: 0.2597
Step:  2937, loss: 3.502888, norm: 0.2798, time(ms): 803.23, token/sec:652728.27, hellaswag_acc: 0.2597
Step:  2938, loss: 3.459309, norm: 0.2548, time(ms): 801.89, token/sec:653819.33, hellaswag_acc: 0.2597
Step:  2939, loss: 3.489834, norm: 0.2615, time(ms): 796.77, token/sec:658014.50, hellaswag_acc: 0.2597
Step:  2940, loss: 3.572557, norm: 0.2684, time(ms): 798.16, token/sec:656867.60, hellaswag_acc: 0.2597
Step:  2941, loss: 3.514527, norm: 0.2521, time(ms): 802.46, token/sec:653354.67, hellaswag_acc: 0.2597
Step:  2942, loss: 3.490800, norm: 0.2599, time(ms): 803.49, token/sec:652516.38, hellaswag_acc: 0.2597
Step:  2943, loss: 3.441653, norm: 0.2857, time(ms): 793.25, token/sec:660936.19, hellaswag_acc: 0.2597
Step:  2944, loss: 3.486984, norm: 0.2768, time(ms): 804.80, token/sec:651451.65, hellaswag_acc: 0.2597
Step:  2945, loss: 3.417629, norm: 0.2627, time(ms): 801.26, token/sec:654326.71, hellaswag_acc: 0.2597
Step:  2946, loss: 3.479080, norm: 0.2668, time(ms): 799.40, token/sec:655852.99, hellaswag_acc: 0.2597
Step:  2947, loss: 3.528378, norm: 0.2600, time(ms): 794.39, token/sec:659989.78, hellaswag_acc: 0.2597
Step:  2948, loss: 3.450582, norm: 0.2717, time(ms): 803.33, token/sec:652643.61, hellaswag_acc: 0.2597
Step:  2949, loss: 3.479356, norm: 0.2771, time(ms): 802.20, token/sec:653561.08, hellaswag_acc: 0.2597
Step:  2950, loss: 3.438708, norm: 0.2621, time(ms): 793.35, token/sec:660855.15, hellaswag_acc: 0.2597
Step:  2951, loss: 3.457702, norm: 0.2614, time(ms): 804.19, token/sec:651946.27, hellaswag_acc: 0.2597
Step:  2952, loss: 3.378439, norm: 0.2554, time(ms): 800.68, token/sec:654799.39, hellaswag_acc: 0.2597
Step:  2953, loss: 3.419251, norm: 0.2545, time(ms): 797.39, token/sec:657506.89, hellaswag_acc: 0.2597
Step:  2954, loss: 3.394300, norm: 0.2370, time(ms): 801.85, token/sec:653847.52, hellaswag_acc: 0.2597
Step:  2955, loss: 3.399662, norm: 0.2562, time(ms): 800.63, token/sec:654842.28, hellaswag_acc: 0.2597
Step:  2956, loss: 3.454350, norm: 0.2902, time(ms): 799.91, token/sec:655435.83, hellaswag_acc: 0.2597
Step:  2957, loss: 3.535676, norm: 0.2911, time(ms): 799.33, token/sec:655908.74, hellaswag_acc: 0.2597
Step:  2958, loss: 3.447785, norm: 0.2844, time(ms): 797.49, token/sec:657422.96, hellaswag_acc: 0.2597
Step:  2959, loss: 3.448515, norm: 0.2574, time(ms): 800.53, token/sec:654925.76, hellaswag_acc: 0.2597
Step:  2960, loss: 3.348005, norm: 0.3136, time(ms): 802.82, token/sec:653059.55, hellaswag_acc: 0.2597
Step:  2961, loss: 3.335838, norm: 0.2812, time(ms): 796.80, token/sec:657992.05, hellaswag_acc: 0.2597
Step:  2962, loss: 3.316139, norm: 0.3029, time(ms): 794.37, token/sec:660006.03, hellaswag_acc: 0.2597
Step:  2963, loss: 3.276625, norm: 0.3155, time(ms): 804.66, token/sec:651568.24, hellaswag_acc: 0.2597
Step:  2964, loss: 3.306032, norm: 0.3053, time(ms): 802.87, token/sec:653021.34, hellaswag_acc: 0.2597
Step:  2965, loss: 3.309587, norm: 0.3401, time(ms): 800.81, token/sec:654695.48, hellaswag_acc: 0.2597
Step:  2966, loss: 3.259981, norm: 0.3277, time(ms): 781.64, token/sec:670757.85, hellaswag_acc: 0.2597
Step:  2967, loss: 3.322308, norm: 0.3163, time(ms): 790.11, token/sec:663562.61, hellaswag_acc: 0.2597
Step:  2968, loss: 3.286039, norm: 0.2734, time(ms): 800.85, token/sec:654660.79, hellaswag_acc: 0.2597
Step:  2969, loss: 3.306582, norm: 0.2873, time(ms): 790.35, token/sec:663365.24, hellaswag_acc: 0.2597
Step:  2970, loss: 3.341325, norm: 0.2966, time(ms): 794.94, token/sec:659531.54, hellaswag_acc: 0.2597
Step:  2971, loss: 3.315455, norm: 0.3051, time(ms): 794.83, token/sec:659624.72, hellaswag_acc: 0.2597
Step:  2972, loss: 3.510187, norm: 0.3116, time(ms): 802.26, token/sec:653516.80, hellaswag_acc: 0.2597
Step:  2973, loss: 3.461928, norm: 0.3112, time(ms): 804.18, token/sec:651955.55, hellaswag_acc: 0.2597
Step:  2974, loss: 3.508662, norm: 0.3116, time(ms): 791.29, token/sec:662572.94, hellaswag_acc: 0.2597
Step:  2975, loss: 3.490335, norm: 0.2613, time(ms): 797.26, token/sec:657612.28, hellaswag_acc: 0.2597
Step:  2976, loss: 3.543736, norm: 0.2663, time(ms): 803.06, token/sec:652865.86, hellaswag_acc: 0.2597
Step:  2977, loss: 3.700882, norm: 0.2985, time(ms): 792.44, token/sec:661609.30, hellaswag_acc: 0.2597
Step:  2978, loss: 3.515046, norm: 0.3105, time(ms): 794.65, token/sec:659774.54, hellaswag_acc: 0.2597
Step:  2979, loss: 3.505643, norm: 0.3048, time(ms): 792.49, token/sec:661568.30, hellaswag_acc: 0.2597
Step:  2980, loss: 3.482921, norm: 0.3291, time(ms): 800.92, token/sec:654603.88, hellaswag_acc: 0.2597
Step:  2981, loss: 3.487658, norm: 0.3402, time(ms): 795.38, token/sec:659170.74, hellaswag_acc: 0.2597
Step:  2982, loss: 3.544528, norm: 0.2973, time(ms): 797.29, token/sec:657591.24, hellaswag_acc: 0.2597
Step:  2983, loss: 3.553334, norm: 0.3025, time(ms): 795.92, token/sec:658719.75, hellaswag_acc: 0.2597
Step:  2984, loss: 3.502902, norm: 0.2831, time(ms): 791.61, token/sec:662305.33, hellaswag_acc: 0.2597
Step:  2985, loss: 3.519241, norm: 0.2763, time(ms): 788.70, token/sec:664745.88, hellaswag_acc: 0.2597
Step:  2986, loss: 3.576669, norm: 0.3079, time(ms): 792.72, token/sec:661378.88, hellaswag_acc: 0.2597
Step:  2987, loss: 3.476616, norm: 0.2864, time(ms): 800.56, token/sec:654904.69, hellaswag_acc: 0.2597
Step:  2988, loss: 3.517391, norm: 0.2695, time(ms): 802.50, token/sec:653319.54, hellaswag_acc: 0.2597
Step:  2989, loss: 3.541175, norm: 0.3931, time(ms): 793.56, token/sec:660675.66, hellaswag_acc: 0.2597
Step:  2990, loss: 3.480452, norm: 0.3177, time(ms): 803.84, token/sec:652227.82, hellaswag_acc: 0.2597
Step:  2991, loss: 3.532452, norm: 0.2985, time(ms): 801.90, token/sec:653804.56, hellaswag_acc: 0.2597
Step:  2992, loss: 3.535316, norm: 0.3196, time(ms): 798.23, token/sec:656811.49, hellaswag_acc: 0.2597
Step:  2993, loss: 3.531650, norm: 0.3180, time(ms): 799.62, token/sec:655673.27, hellaswag_acc: 0.2597
Step:  2994, loss: 3.482089, norm: 0.2953, time(ms): 797.01, token/sec:657819.82, hellaswag_acc: 0.2597
Step:  2995, loss: 3.407418, norm: 0.2588, time(ms): 803.96, token/sec:652135.94, hellaswag_acc: 0.2597
Step:  2996, loss: 3.439996, norm: 0.2756, time(ms): 800.05, token/sec:655316.88, hellaswag_acc: 0.2597
Step:  2997, loss: 3.435927, norm: 0.2592, time(ms): 794.55, token/sec:659858.88, hellaswag_acc: 0.2597
Step:  2998, loss: 3.418496, norm: 0.2376, time(ms): 796.46, token/sec:658269.38, hellaswag_acc: 0.2597
Step:  2999, loss: 3.419732, norm: 0.2575, time(ms): 809.27, token/sec:647852.89, hellaswag_acc: 0.2597
rank 0 sample 0: Hello, I'm a language model, and I don't have my understanding of their world. I've created a list of different, fun ways to use these
rank 0 sample 1: Hello, I'm a language model, I use the following:
(9) The rules will differ in language model, and for each. For example,
rank 0 sample 2: Hello, I'm a language model, but I would prefer to include the idea of learning "I know how to read," but I'm not sure if it
rank 0 sample 3: Hello, I'm a language model, and, thanks to the following question. (please explain that last point)<|endoftext|>1. Which of the following statements might
rank 1 sample 0: Hello, I'm a language model, just to be honest. I'm simply trying to be good of the way my students and I're trying to be good
rank 1 sample 1: Hello, I'm a language model, you have a new language, so we go through the entire process.
What are Dicaktas?

rank 1 sample 2: Hello, I'm a language model, I teach my students to use the language of the rainbow in one sentence and then ask them to describe their feelings or thoughts
rank 1 sample 3: Hello, I'm a language model, and I'm just trying to see whether i'm doing quite as nice as he's:
If i'm going to
Step:  3000, loss: 3.483342, norm: 0.2724, time(ms): 364271.50, token/sec:1439.28, val_loss: 3.5105, hellaswag_acc: 0.2665
Step:  3001, loss: 3.474546, norm: 0.2585, time(ms): 792.66, token/sec:661428.21, hellaswag_acc: 0.2665
Step:  3002, loss: 3.428422, norm: 0.2669, time(ms): 796.42, token/sec:658306.23, hellaswag_acc: 0.2665
Step:  3003, loss: 3.403288, norm: 0.2747, time(ms): 794.20, token/sec:660144.32, hellaswag_acc: 0.2665
Step:  3004, loss: 3.450618, norm: 0.2614, time(ms): 801.81, token/sec:653877.85, hellaswag_acc: 0.2665
Step:  3005, loss: 3.524625, norm: 0.2732, time(ms): 806.33, token/sec:650215.78, hellaswag_acc: 0.2665
Step:  3006, loss: 3.368775, norm: 0.2462, time(ms): 792.95, token/sec:661190.56, hellaswag_acc: 0.2665
Step:  3007, loss: 3.341783, norm: 0.2695, time(ms): 795.98, token/sec:658667.27, hellaswag_acc: 0.2665
Step:  3008, loss: 3.301912, norm: 0.2840, time(ms): 802.03, token/sec:653698.05, hellaswag_acc: 0.2665
Step:  3009, loss: 3.316981, norm: 0.2614, time(ms): 807.65, token/sec:649154.90, hellaswag_acc: 0.2665
Step:  3010, loss: 3.322605, norm: 0.2766, time(ms): 797.79, token/sec:657173.64, hellaswag_acc: 0.2665
Step:  3011, loss: 3.306582, norm: 0.2996, time(ms): 800.20, token/sec:655199.53, hellaswag_acc: 0.2665
Step:  3012, loss: 3.364776, norm: 0.2857, time(ms): 798.66, token/sec:656459.73, hellaswag_acc: 0.2665
Step:  3013, loss: 3.258730, norm: 0.2695, time(ms): 802.54, token/sec:653282.47, hellaswag_acc: 0.2665
Step:  3014, loss: 3.328929, norm: 0.2937, time(ms): 798.58, token/sec:656522.84, hellaswag_acc: 0.2665
Step:  3015, loss: 3.323995, norm: 0.2946, time(ms): 799.14, token/sec:656064.51, hellaswag_acc: 0.2665
Step:  3016, loss: 3.330415, norm: 0.2874, time(ms): 798.42, token/sec:656659.49, hellaswag_acc: 0.2665
Step:  3017, loss: 3.299255, norm: 0.2992, time(ms): 803.25, token/sec:652708.70, hellaswag_acc: 0.2665
Step:  3018, loss: 3.392076, norm: 0.3024, time(ms): 800.26, token/sec:655149.75, hellaswag_acc: 0.2665
Step:  3019, loss: 3.516159, norm: 0.3029, time(ms): 793.79, token/sec:660488.93, hellaswag_acc: 0.2665
Step:  3020, loss: 3.517035, norm: 0.3130, time(ms): 801.32, token/sec:654277.46, hellaswag_acc: 0.2665
Step:  3021, loss: 3.592035, norm: 0.3051, time(ms): 802.67, token/sec:653181.76, hellaswag_acc: 0.2665
Step:  3022, loss: 3.544665, norm: 0.3340, time(ms): 792.89, token/sec:661238.47, hellaswag_acc: 0.2665
Step:  3023, loss: 3.473367, norm: 0.3036, time(ms): 798.00, token/sec:657002.82, hellaswag_acc: 0.2665
Step:  3024, loss: 3.556143, norm: 0.2850, time(ms): 792.72, token/sec:661381.86, hellaswag_acc: 0.2665
Step:  3025, loss: 3.517212, norm: 0.2790, time(ms): 793.27, token/sec:660918.51, hellaswag_acc: 0.2665
Step:  3026, loss: 3.508669, norm: 0.2706, time(ms): 796.96, token/sec:657862.13, hellaswag_acc: 0.2665
Step:  3027, loss: 3.604617, norm: 0.2780, time(ms): 803.88, token/sec:652193.77, hellaswag_acc: 0.2665
Step:  3028, loss: 3.505023, norm: 0.2915, time(ms): 798.92, token/sec:656242.28, hellaswag_acc: 0.2665
Step:  3029, loss: 3.536954, norm: 0.3062, time(ms): 802.02, token/sec:653706.22, hellaswag_acc: 0.2665
Step:  3030, loss: 3.505886, norm: 0.3119, time(ms): 797.39, token/sec:657501.98, hellaswag_acc: 0.2665
Step:  3031, loss: 3.557535, norm: 0.3073, time(ms): 801.02, token/sec:654526.92, hellaswag_acc: 0.2665
Step:  3032, loss: 3.489408, norm: 0.2998, time(ms): 801.23, token/sec:654351.83, hellaswag_acc: 0.2665
Step:  3033, loss: 3.467418, norm: 0.2896, time(ms): 797.10, token/sec:657745.05, hellaswag_acc: 0.2665
Step:  3034, loss: 3.486132, norm: 0.2673, time(ms): 797.84, token/sec:657138.09, hellaswag_acc: 0.2665
Step:  3035, loss: 3.514829, norm: 0.2918, time(ms): 795.29, token/sec:659241.29, hellaswag_acc: 0.2665
Step:  3036, loss: 3.490261, norm: 0.2791, time(ms): 800.47, token/sec:654974.13, hellaswag_acc: 0.2665
Step:  3037, loss: 3.530066, norm: 0.2572, time(ms): 789.89, token/sec:663746.27, hellaswag_acc: 0.2665
Step:  3038, loss: 3.518765, norm: 0.2615, time(ms): 784.49, token/sec:668313.04, hellaswag_acc: 0.2665
Step:  3039, loss: 3.500518, norm: 0.2664, time(ms): 792.03, token/sec:661955.24, hellaswag_acc: 0.2665
Step:  3040, loss: 3.483619, norm: 0.3068, time(ms): 803.35, token/sec:652626.57, hellaswag_acc: 0.2665
Step:  3041, loss: 3.445688, norm: 0.2902, time(ms): 799.70, token/sec:655607.20, hellaswag_acc: 0.2665
Step:  3042, loss: 3.476316, norm: 0.2817, time(ms): 789.32, token/sec:664224.83, hellaswag_acc: 0.2665
Step:  3043, loss: 3.433850, norm: 0.2918, time(ms): 804.23, token/sec:651908.97, hellaswag_acc: 0.2665
Step:  3044, loss: 3.580027, norm: 0.2945, time(ms): 805.55, token/sec:650842.76, hellaswag_acc: 0.2665
Step:  3045, loss: 3.425683, norm: 0.2881, time(ms): 801.16, token/sec:654408.10, hellaswag_acc: 0.2665
Step:  3046, loss: 3.468131, norm: 0.2841, time(ms): 789.56, token/sec:664023.26, hellaswag_acc: 0.2665
Step:  3047, loss: 3.451543, norm: 0.2631, time(ms): 1343.10, token/sec:390357.93, hellaswag_acc: 0.2665
Step:  3048, loss: 3.563579, norm: 0.3063, time(ms): 769.03, token/sec:681750.77, hellaswag_acc: 0.2665
Step:  3049, loss: 3.507266, norm: 0.2855, time(ms): 793.35, token/sec:660854.75, hellaswag_acc: 0.2665
Step:  3050, loss: 3.454240, norm: 0.2741, time(ms): 800.27, token/sec:655135.90, hellaswag_acc: 0.2665
Step:  3051, loss: 3.532616, norm: 0.2704, time(ms): 786.77, token/sec:666380.58, hellaswag_acc: 0.2665
Step:  3052, loss: 3.484291, norm: 0.2883, time(ms): 784.61, token/sec:668217.39, hellaswag_acc: 0.2665
Step:  3053, loss: 3.532817, norm: 0.2747, time(ms): 788.81, token/sec:664656.67, hellaswag_acc: 0.2665
Step:  3054, loss: 3.510049, norm: 0.2900, time(ms): 799.38, token/sec:655871.77, hellaswag_acc: 0.2665
Step:  3055, loss: 3.489338, norm: 0.2676, time(ms): 800.95, token/sec:654581.08, hellaswag_acc: 0.2665
Step:  3056, loss: 3.498496, norm: 0.2606, time(ms): 795.34, token/sec:659198.41, hellaswag_acc: 0.2665
Step:  3057, loss: 3.481218, norm: 0.2731, time(ms): 802.35, token/sec:653438.54, hellaswag_acc: 0.2665
Step:  3058, loss: 3.529260, norm: 0.2568, time(ms): 799.65, token/sec:655647.67, hellaswag_acc: 0.2665
Step:  3059, loss: 3.489372, norm: 0.2720, time(ms): 803.79, token/sec:652266.31, hellaswag_acc: 0.2665
Step:  3060, loss: 3.467624, norm: 0.2591, time(ms): 792.46, token/sec:661591.39, hellaswag_acc: 0.2665
Step:  3061, loss: 3.474285, norm: 0.2479, time(ms): 795.36, token/sec:659185.36, hellaswag_acc: 0.2665
Step:  3062, loss: 3.439446, norm: 0.2584, time(ms): 790.43, token/sec:663297.81, hellaswag_acc: 0.2665
Step:  3063, loss: 3.473226, norm: 0.2944, time(ms): 797.70, token/sec:657246.71, hellaswag_acc: 0.2665
Step:  3064, loss: 3.461937, norm: 0.2727, time(ms): 792.74, token/sec:661362.17, hellaswag_acc: 0.2665
Step:  3065, loss: 3.473200, norm: 0.2844, time(ms): 794.57, token/sec:659840.86, hellaswag_acc: 0.2665
Step:  3066, loss: 3.543127, norm: 0.2843, time(ms): 791.69, token/sec:662239.51, hellaswag_acc: 0.2665
Step:  3067, loss: 3.461368, norm: 0.2684, time(ms): 790.88, token/sec:662915.29, hellaswag_acc: 0.2665
Step:  3068, loss: 3.369834, norm: 0.2500, time(ms): 788.50, token/sec:664917.94, hellaswag_acc: 0.2665
Step:  3069, loss: 3.438235, norm: 0.2726, time(ms): 802.96, token/sec:652945.92, hellaswag_acc: 0.2665
Step:  3070, loss: 3.426661, norm: 0.2787, time(ms): 800.06, token/sec:655308.29, hellaswag_acc: 0.2665
Step:  3071, loss: 3.439154, norm: 0.2808, time(ms): 795.71, token/sec:658896.60, hellaswag_acc: 0.2665
Step:  3072, loss: 3.442953, norm: 0.2540, time(ms): 802.62, token/sec:653220.37, hellaswag_acc: 0.2665
Step:  3073, loss: 3.395810, norm: 0.2588, time(ms): 800.67, token/sec:654809.33, hellaswag_acc: 0.2665
Step:  3074, loss: 3.429645, norm: 0.2583, time(ms): 798.03, token/sec:656974.36, hellaswag_acc: 0.2665
Step:  3075, loss: 3.408994, norm: 0.2820, time(ms): 802.60, token/sec:653236.47, hellaswag_acc: 0.2665
Step:  3076, loss: 3.398219, norm: 0.2566, time(ms): 796.00, token/sec:658650.50, hellaswag_acc: 0.2665
Step:  3077, loss: 3.399235, norm: 0.2316, time(ms): 802.30, token/sec:653479.32, hellaswag_acc: 0.2665
Step:  3078, loss: 3.383404, norm: 0.2384, time(ms): 801.24, token/sec:654347.74, hellaswag_acc: 0.2665
Step:  3079, loss: 3.422657, norm: 0.2451, time(ms): 789.50, token/sec:664075.40, hellaswag_acc: 0.2665
Step:  3080, loss: 3.513855, norm: 0.2759, time(ms): 794.48, token/sec:659912.54, hellaswag_acc: 0.2665
Step:  3081, loss: 3.520058, norm: 0.3381, time(ms): 790.25, token/sec:663446.29, hellaswag_acc: 0.2665
Step:  3082, loss: 3.529780, norm: 0.3082, time(ms): 794.19, token/sec:660153.04, hellaswag_acc: 0.2665
Step:  3083, loss: 3.452438, norm: 0.2874, time(ms): 791.76, token/sec:662178.49, hellaswag_acc: 0.2665
Step:  3084, loss: 3.385873, norm: 0.4218, time(ms): 793.54, token/sec:660698.09, hellaswag_acc: 0.2665
Step:  3085, loss: 3.459092, norm: 0.3288, time(ms): 800.63, token/sec:654847.55, hellaswag_acc: 0.2665
Step:  3086, loss: 3.523234, norm: 0.3906, time(ms): 801.13, token/sec:654434.40, hellaswag_acc: 0.2665
Step:  3087, loss: 3.486203, norm: 0.3517, time(ms): 801.70, token/sec:653969.25, hellaswag_acc: 0.2665
Step:  3088, loss: 3.416403, norm: 0.3130, time(ms): 800.57, token/sec:654893.18, hellaswag_acc: 0.2665
Step:  3089, loss: 3.599471, norm: 0.3123, time(ms): 794.95, token/sec:659522.05, hellaswag_acc: 0.2665
Step:  3090, loss: 3.492018, norm: 0.3075, time(ms): 802.72, token/sec:653138.11, hellaswag_acc: 0.2665
Step:  3091, loss: 3.503324, norm: 0.3408, time(ms): 801.66, token/sec:654001.34, hellaswag_acc: 0.2665
Step:  3092, loss: 3.480991, norm: 0.3106, time(ms): 796.79, token/sec:658003.87, hellaswag_acc: 0.2665
Step:  3093, loss: 3.461702, norm: 0.3364, time(ms): 797.55, token/sec:657376.58, hellaswag_acc: 0.2665
Step:  3094, loss: 3.441267, norm: 0.2929, time(ms): 803.30, token/sec:652669.57, hellaswag_acc: 0.2665
Step:  3095, loss: 3.426533, norm: 0.2566, time(ms): 802.49, token/sec:653324.00, hellaswag_acc: 0.2665
Step:  3096, loss: 3.476135, norm: 0.2773, time(ms): 791.45, token/sec:662436.81, hellaswag_acc: 0.2665
Step:  3097, loss: 3.461078, norm: 0.2705, time(ms): 801.63, token/sec:654030.71, hellaswag_acc: 0.2665
Step:  3098, loss: 3.446497, norm: 0.2882, time(ms): 806.72, token/sec:649903.32, hellaswag_acc: 0.2665
Step:  3099, loss: 3.513242, norm: 0.2743, time(ms): 796.67, token/sec:658101.14, hellaswag_acc: 0.2665
Step:  3100, loss: 3.441437, norm: 0.2674, time(ms): 787.95, token/sec:665385.91, hellaswag_acc: 0.2665
Step:  3101, loss: 3.461104, norm: 0.2483, time(ms): 792.02, token/sec:661963.21, hellaswag_acc: 0.2665
Step:  3102, loss: 3.475102, norm: 0.2774, time(ms): 798.95, token/sec:656225.24, hellaswag_acc: 0.2665
Step:  3103, loss: 3.488033, norm: 0.2759, time(ms): 794.37, token/sec:660001.07, hellaswag_acc: 0.2665
Step:  3104, loss: 3.419335, norm: 0.2722, time(ms): 793.13, token/sec:661040.29, hellaswag_acc: 0.2665
Step:  3105, loss: 3.450369, norm: 0.2699, time(ms): 790.18, token/sec:663508.55, hellaswag_acc: 0.2665
Step:  3106, loss: 3.405871, norm: 0.2862, time(ms): 798.06, token/sec:656949.04, hellaswag_acc: 0.2665
Step:  3107, loss: 3.423099, norm: 0.2625, time(ms): 791.41, token/sec:662470.14, hellaswag_acc: 0.2665
Step:  3108, loss: 3.431011, norm: 0.2415, time(ms): 791.15, token/sec:662690.54, hellaswag_acc: 0.2665
Step:  3109, loss: 3.445443, norm: 0.2382, time(ms): 801.95, token/sec:653768.79, hellaswag_acc: 0.2665
Step:  3110, loss: 3.407117, norm: 0.2661, time(ms): 801.43, token/sec:654186.75, hellaswag_acc: 0.2665
Step:  3111, loss: 3.393252, norm: 0.2658, time(ms): 798.44, token/sec:656636.94, hellaswag_acc: 0.2665
Step:  3112, loss: 3.423152, norm: 0.2787, time(ms): 792.11, token/sec:661890.49, hellaswag_acc: 0.2665
Step:  3113, loss: 3.399729, norm: 0.2780, time(ms): 803.67, token/sec:652367.32, hellaswag_acc: 0.2665
Step:  3114, loss: 3.430343, norm: 0.2840, time(ms): 805.72, token/sec:650704.67, hellaswag_acc: 0.2665
Step:  3115, loss: 3.457674, norm: 0.3191, time(ms): 786.68, token/sec:666458.74, hellaswag_acc: 0.2665
Step:  3116, loss: 3.520078, norm: 0.3095, time(ms): 789.19, token/sec:664338.41, hellaswag_acc: 0.2665
Step:  3117, loss: 3.483523, norm: 0.3062, time(ms): 792.52, token/sec:661549.59, hellaswag_acc: 0.2665
Step:  3118, loss: 3.481272, norm: 0.3074, time(ms): 801.11, token/sec:654449.59, hellaswag_acc: 0.2665
Step:  3119, loss: 3.484280, norm: 0.2776, time(ms): 802.13, token/sec:653617.22, hellaswag_acc: 0.2665
Step:  3120, loss: 3.517381, norm: 0.2859, time(ms): 790.05, token/sec:663613.07, hellaswag_acc: 0.2665
Step:  3121, loss: 3.470601, norm: 0.2975, time(ms): 786.40, token/sec:666692.72, hellaswag_acc: 0.2665
Step:  3122, loss: 3.461268, norm: 0.2723, time(ms): 802.99, token/sec:652917.23, hellaswag_acc: 0.2665
Step:  3123, loss: 3.422580, norm: 0.2529, time(ms): 807.44, token/sec:649319.55, hellaswag_acc: 0.2665
Step:  3124, loss: 3.390135, norm: 0.2712, time(ms): 791.69, token/sec:662237.32, hellaswag_acc: 0.2665
Step:  3125, loss: 3.478948, norm: 0.2528, time(ms): 796.49, token/sec:658245.15, hellaswag_acc: 0.2665
Step:  3126, loss: 3.515935, norm: 0.2501, time(ms): 791.45, token/sec:662443.60, hellaswag_acc: 0.2665
Step:  3127, loss: 3.463940, norm: 0.3114, time(ms): 798.98, token/sec:656196.85, hellaswag_acc: 0.2665
Step:  3128, loss: 3.420975, norm: 0.3082, time(ms): 791.68, token/sec:662248.69, hellaswag_acc: 0.2665
Step:  3129, loss: 3.456072, norm: 0.3179, time(ms): 793.14, token/sec:661030.36, hellaswag_acc: 0.2665
Step:  3130, loss: 3.434513, norm: 0.3058, time(ms): 790.10, token/sec:663574.22, hellaswag_acc: 0.2665
Step:  3131, loss: 3.423370, norm: 0.2622, time(ms): 796.76, token/sec:658027.69, hellaswag_acc: 0.2665
Step:  3132, loss: 3.474009, norm: 0.2900, time(ms): 793.58, token/sec:660664.94, hellaswag_acc: 0.2665
Step:  3133, loss: 3.484781, norm: 0.2535, time(ms): 790.31, token/sec:663395.66, hellaswag_acc: 0.2665
Step:  3134, loss: 3.460761, norm: 0.2666, time(ms): 796.77, token/sec:658020.60, hellaswag_acc: 0.2665
Step:  3135, loss: 3.461816, norm: 0.2770, time(ms): 804.74, token/sec:651501.45, hellaswag_acc: 0.2665
Step:  3136, loss: 3.401131, norm: 0.2843, time(ms): 802.67, token/sec:653182.92, hellaswag_acc: 0.2665
Step:  3137, loss: 3.429404, norm: 0.2600, time(ms): 788.10, token/sec:665253.86, hellaswag_acc: 0.2665
Step:  3138, loss: 3.455484, norm: 0.2849, time(ms): 790.07, token/sec:663592.84, hellaswag_acc: 0.2665
Step:  3139, loss: 3.419100, norm: 0.3010, time(ms): 791.91, token/sec:662059.07, hellaswag_acc: 0.2665
Step:  3140, loss: 3.410908, norm: 0.2489, time(ms): 792.98, token/sec:661163.32, hellaswag_acc: 0.2665
Step:  3141, loss: 3.381875, norm: 0.2607, time(ms): 795.24, token/sec:659281.81, hellaswag_acc: 0.2665
Step:  3142, loss: 3.417281, norm: 0.2704, time(ms): 794.43, token/sec:659957.30, hellaswag_acc: 0.2665
Step:  3143, loss: 3.419531, norm: 0.2877, time(ms): 801.37, token/sec:654237.55, hellaswag_acc: 0.2665
Step:  3144, loss: 3.372123, norm: 0.2743, time(ms): 804.71, token/sec:651524.22, hellaswag_acc: 0.2665
Step:  3145, loss: 3.394018, norm: 0.2743, time(ms): 799.65, token/sec:655650.79, hellaswag_acc: 0.2665
Step:  3146, loss: 3.381149, norm: 0.2701, time(ms): 792.72, token/sec:661379.67, hellaswag_acc: 0.2665
Step:  3147, loss: 3.451284, norm: 0.2824, time(ms): 799.13, token/sec:656076.84, hellaswag_acc: 0.2665
Step:  3148, loss: 3.426285, norm: 0.2922, time(ms): 807.19, token/sec:649524.57, hellaswag_acc: 0.2665
Step:  3149, loss: 3.412307, norm: 0.2644, time(ms): 791.55, token/sec:662352.81, hellaswag_acc: 0.2665
Step:  3150, loss: 3.495446, norm: 0.2637, time(ms): 798.69, token/sec:656434.45, hellaswag_acc: 0.2665
Step:  3151, loss: 3.442310, norm: 0.2978, time(ms): 803.29, token/sec:652676.93, hellaswag_acc: 0.2665
Step:  3152, loss: 3.468838, norm: 0.3389, time(ms): 805.32, token/sec:651030.05, hellaswag_acc: 0.2665
Step:  3153, loss: 3.503179, norm: 0.3320, time(ms): 797.53, token/sec:657391.32, hellaswag_acc: 0.2665
Step:  3154, loss: 3.518996, norm: 0.2886, time(ms): 794.51, token/sec:659889.17, hellaswag_acc: 0.2665
Step:  3155, loss: 3.455503, norm: 0.3013, time(ms): 803.29, token/sec:652674.22, hellaswag_acc: 0.2665
Step:  3156, loss: 3.466225, norm: 0.3046, time(ms): 804.06, token/sec:652051.63, hellaswag_acc: 0.2665
Step:  3157, loss: 3.472602, norm: 0.2758, time(ms): 797.73, token/sec:657227.45, hellaswag_acc: 0.2665
Step:  3158, loss: 3.488614, norm: 0.2651, time(ms): 793.84, token/sec:660442.11, hellaswag_acc: 0.2665
Step:  3159, loss: 3.512482, norm: 0.2854, time(ms): 803.16, token/sec:652779.42, hellaswag_acc: 0.2665
Step:  3160, loss: 3.503611, norm: 0.2841, time(ms): 804.63, token/sec:651589.86, hellaswag_acc: 0.2665
Step:  3161, loss: 3.458928, norm: 0.2697, time(ms): 794.86, token/sec:659593.86, hellaswag_acc: 0.2665
Step:  3162, loss: 3.429500, norm: 0.2473, time(ms): 796.77, token/sec:658017.45, hellaswag_acc: 0.2665
Step:  3163, loss: 3.439708, norm: 0.2598, time(ms): 804.69, token/sec:651536.77, hellaswag_acc: 0.2665
Step:  3164, loss: 3.440219, norm: 0.2713, time(ms): 801.97, token/sec:653753.63, hellaswag_acc: 0.2665
Step:  3165, loss: 3.435957, norm: 0.2761, time(ms): 798.24, token/sec:656808.35, hellaswag_acc: 0.2665
Step:  3166, loss: 3.457767, norm: 0.2837, time(ms): 798.84, token/sec:656312.20, hellaswag_acc: 0.2665
Step:  3167, loss: 3.460776, norm: 0.2803, time(ms): 800.29, token/sec:655118.53, hellaswag_acc: 0.2665
Step:  3168, loss: 3.508461, norm: 0.2523, time(ms): 804.53, token/sec:651666.91, hellaswag_acc: 0.2665
Step:  3169, loss: 3.405896, norm: 0.2865, time(ms): 796.18, token/sec:658502.77, hellaswag_acc: 0.2665
Step:  3170, loss: 3.459009, norm: 0.3241, time(ms): 792.85, token/sec:661270.88, hellaswag_acc: 0.2665
Step:  3171, loss: 3.482475, norm: 0.3357, time(ms): 792.19, token/sec:661821.96, hellaswag_acc: 0.2665
Step:  3172, loss: 3.500678, norm: 0.3101, time(ms): 797.25, token/sec:657622.90, hellaswag_acc: 0.2665
Step:  3173, loss: 3.416821, norm: 0.3252, time(ms): 791.07, token/sec:662760.45, hellaswag_acc: 0.2665
Step:  3174, loss: 3.385327, norm: 0.3146, time(ms): 797.42, token/sec:657480.55, hellaswag_acc: 0.2665
Step:  3175, loss: 3.405754, norm: 0.2814, time(ms): 793.35, token/sec:660851.17, hellaswag_acc: 0.2665
Step:  3176, loss: 3.427178, norm: 0.3229, time(ms): 793.35, token/sec:660854.95, hellaswag_acc: 0.2665
Step:  3177, loss: 3.377119, norm: 0.3251, time(ms): 790.20, token/sec:663486.33, hellaswag_acc: 0.2665
Step:  3178, loss: 3.416006, norm: 0.3249, time(ms): 791.04, token/sec:662779.42, hellaswag_acc: 0.2665
Step:  3179, loss: 3.371515, norm: 0.3025, time(ms): 801.92, token/sec:653789.40, hellaswag_acc: 0.2665
Step:  3180, loss: 3.376666, norm: 0.2672, time(ms): 790.79, token/sec:662996.23, hellaswag_acc: 0.2665
Step:  3181, loss: 3.416553, norm: 0.2830, time(ms): 805.53, token/sec:650864.72, hellaswag_acc: 0.2665
Step:  3182, loss: 3.434638, norm: 0.2890, time(ms): 802.89, token/sec:653003.12, hellaswag_acc: 0.2665
Step:  3183, loss: 3.395318, norm: 0.2661, time(ms): 801.35, token/sec:654252.34, hellaswag_acc: 0.2665
Step:  3184, loss: 3.471232, norm: 0.2653, time(ms): 787.97, token/sec:665367.39, hellaswag_acc: 0.2665
Step:  3185, loss: 3.567298, norm: 0.2787, time(ms): 792.56, token/sec:661512.38, hellaswag_acc: 0.2665
Step:  3186, loss: 3.465467, norm: 0.3063, time(ms): 793.10, token/sec:661060.37, hellaswag_acc: 0.2665
Step:  3187, loss: 3.482927, norm: 0.2945, time(ms): 790.13, token/sec:663548.59, hellaswag_acc: 0.2665
Step:  3188, loss: 3.524726, norm: 0.2741, time(ms): 794.38, token/sec:659999.49, hellaswag_acc: 0.2665
Step:  3189, loss: 3.565521, norm: 0.3299, time(ms): 794.65, token/sec:659773.94, hellaswag_acc: 0.2665
Step:  3190, loss: 3.461444, norm: 0.2887, time(ms): 800.73, token/sec:654758.83, hellaswag_acc: 0.2665
Step:  3191, loss: 3.498142, norm: 0.2924, time(ms): 804.59, token/sec:651620.17, hellaswag_acc: 0.2665
Step:  3192, loss: 3.526241, norm: 0.3869, time(ms): 797.52, token/sec:657394.46, hellaswag_acc: 0.2665
Step:  3193, loss: 3.486225, norm: 0.3136, time(ms): 794.54, token/sec:659866.60, hellaswag_acc: 0.2665
Step:  3194, loss: 3.390019, norm: 0.2995, time(ms): 800.98, token/sec:654554.97, hellaswag_acc: 0.2665
Step:  3195, loss: 3.466241, norm: 0.2702, time(ms): 805.28, token/sec:651063.97, hellaswag_acc: 0.2665
Step:  3196, loss: 3.472860, norm: 0.2858, time(ms): 792.42, token/sec:661630.60, hellaswag_acc: 0.2665
Step:  3197, loss: 3.390622, norm: 0.2584, time(ms): 797.45, token/sec:657454.01, hellaswag_acc: 0.2665
Step:  3198, loss: 3.449854, norm: 0.2846, time(ms): 795.54, token/sec:659034.83, hellaswag_acc: 0.2665
Step:  3199, loss: 3.469906, norm: 0.2822, time(ms): 793.59, token/sec:660655.02, hellaswag_acc: 0.2665
Step:  3200, loss: 3.548204, norm: 0.3196, time(ms): 793.38, token/sec:660830.72, hellaswag_acc: 0.2665
Step:  3201, loss: 3.516454, norm: 0.3196, time(ms): 791.09, token/sec:662740.87, hellaswag_acc: 0.2665
Step:  3202, loss: 3.452449, norm: 0.3042, time(ms): 790.74, token/sec:663033.02, hellaswag_acc: 0.2665
Step:  3203, loss: 3.490999, norm: 0.2988, time(ms): 797.57, token/sec:657354.96, hellaswag_acc: 0.2665
Step:  3204, loss: 3.407114, norm: 0.2785, time(ms): 793.51, token/sec:660722.11, hellaswag_acc: 0.2665
Step:  3205, loss: 3.485481, norm: 0.2627, time(ms): 793.36, token/sec:660845.81, hellaswag_acc: 0.2665
Step:  3206, loss: 3.488353, norm: 0.2575, time(ms): 786.86, token/sec:666300.02, hellaswag_acc: 0.2665
Step:  3207, loss: 3.457312, norm: 0.2601, time(ms): 790.31, token/sec:663392.05, hellaswag_acc: 0.2665
Step:  3208, loss: 3.465578, norm: 0.3055, time(ms): 794.50, token/sec:659900.06, hellaswag_acc: 0.2665
Step:  3209, loss: 3.391856, norm: 0.2886, time(ms): 791.58, token/sec:662330.07, hellaswag_acc: 0.2665
Step:  3210, loss: 3.448688, norm: 0.2836, time(ms): 789.10, token/sec:664412.28, hellaswag_acc: 0.2665
Step:  3211, loss: 3.397244, norm: 0.3085, time(ms): 798.01, token/sec:656997.91, hellaswag_acc: 0.2665
Step:  3212, loss: 3.398250, norm: 0.2568, time(ms): 804.26, token/sec:651890.81, hellaswag_acc: 0.2665
Step:  3213, loss: 3.392984, norm: 0.2869, time(ms): 803.87, token/sec:652201.51, hellaswag_acc: 0.2665
Step:  3214, loss: 3.389898, norm: 0.2781, time(ms): 791.64, token/sec:662280.80, hellaswag_acc: 0.2665
Step:  3215, loss: 3.385648, norm: 0.2605, time(ms): 797.74, token/sec:657216.06, hellaswag_acc: 0.2665
Step:  3216, loss: 3.398842, norm: 0.2453, time(ms): 794.47, token/sec:659922.64, hellaswag_acc: 0.2665
Step:  3217, loss: 3.416301, norm: 0.2631, time(ms): 791.77, token/sec:662172.51, hellaswag_acc: 0.2665
Step:  3218, loss: 3.383885, norm: 0.2758, time(ms): 793.02, token/sec:661126.15, hellaswag_acc: 0.2665
Step:  3219, loss: 3.408057, norm: 0.2703, time(ms): 795.64, token/sec:658950.30, hellaswag_acc: 0.2665
Step:  3220, loss: 3.440532, norm: 0.2648, time(ms): 792.42, token/sec:661626.62, hellaswag_acc: 0.2665
Step:  3221, loss: 3.450068, norm: 0.2846, time(ms): 796.71, token/sec:658063.92, hellaswag_acc: 0.2665
Step:  3222, loss: 3.506380, norm: 0.2830, time(ms): 795.50, token/sec:659064.65, hellaswag_acc: 0.2665
Step:  3223, loss: 3.462033, norm: 0.2639, time(ms): 795.17, token/sec:659339.33, hellaswag_acc: 0.2665
Step:  3224, loss: 3.469060, norm: 0.2778, time(ms): 791.54, token/sec:662360.79, hellaswag_acc: 0.2665
Step:  3225, loss: 3.456576, norm: 0.2968, time(ms): 800.24, token/sec:655165.18, hellaswag_acc: 0.2665
Step:  3226, loss: 3.407344, norm: 0.3067, time(ms): 803.49, token/sec:652514.63, hellaswag_acc: 0.2665
Step:  3227, loss: 3.477945, norm: 0.3031, time(ms): 789.18, token/sec:664344.23, hellaswag_acc: 0.2665
Step:  3228, loss: 3.478535, norm: 0.2985, time(ms): 798.70, token/sec:656423.48, hellaswag_acc: 0.2665
Step:  3229, loss: 3.438793, norm: 0.3032, time(ms): 792.08, token/sec:661916.19, hellaswag_acc: 0.2665
Step:  3230, loss: 3.445874, norm: 0.2601, time(ms): 784.54, token/sec:668272.22, hellaswag_acc: 0.2665
Step:  3231, loss: 3.500028, norm: 0.3009, time(ms): 791.69, token/sec:662238.52, hellaswag_acc: 0.2665
Step:  3232, loss: 3.436232, norm: 0.2959, time(ms): 796.90, token/sec:657913.31, hellaswag_acc: 0.2665
Step:  3233, loss: 3.516623, norm: 0.3146, time(ms): 801.32, token/sec:654279.79, hellaswag_acc: 0.2665
Step:  3234, loss: 3.450844, norm: 0.3110, time(ms): 801.90, token/sec:653805.92, hellaswag_acc: 0.2665
Step:  3235, loss: 3.462435, norm: 0.3062, time(ms): 792.70, token/sec:661393.40, hellaswag_acc: 0.2665
Step:  3236, loss: 3.462817, norm: 0.3135, time(ms): 799.42, token/sec:655836.17, hellaswag_acc: 0.2665
Step:  3237, loss: 3.436458, norm: 0.2694, time(ms): 805.13, token/sec:651186.21, hellaswag_acc: 0.2665
Step:  3238, loss: 3.460954, norm: 0.2882, time(ms): 1290.06, token/sec:406404.76, hellaswag_acc: 0.2665
Step:  3239, loss: 3.475704, norm: 0.2653, time(ms): 799.80, token/sec:655523.36, hellaswag_acc: 0.2665
Step:  3240, loss: 3.474100, norm: 0.2661, time(ms): 781.89, token/sec:670538.79, hellaswag_acc: 0.2665
Step:  3241, loss: 3.448446, norm: 0.2728, time(ms): 790.60, token/sec:663147.99, hellaswag_acc: 0.2665
Step:  3242, loss: 3.415458, norm: 0.2682, time(ms): 787.79, token/sec:665521.24, hellaswag_acc: 0.2665
Step:  3243, loss: 3.398699, norm: 0.2525, time(ms): 793.36, token/sec:660846.01, hellaswag_acc: 0.2665
Step:  3244, loss: 3.451062, norm: 0.2819, time(ms): 783.85, token/sec:668860.26, hellaswag_acc: 0.2665
Step:  3245, loss: 3.507483, norm: 0.3184, time(ms): 782.39, token/sec:670110.92, hellaswag_acc: 0.2665
Step:  3246, loss: 3.390974, norm: 0.3755, time(ms): 790.13, token/sec:663548.59, hellaswag_acc: 0.2665
Step:  3247, loss: 3.344863, norm: 0.3726, time(ms): 800.61, token/sec:654864.13, hellaswag_acc: 0.2665
Step:  3248, loss: 3.341387, norm: 0.3667, time(ms): 799.97, token/sec:655384.45, hellaswag_acc: 0.2665
Step:  3249, loss: 3.322289, norm: 0.3988, time(ms): 797.42, token/sec:657478.19, hellaswag_acc: 0.2665
rank 0 sample 0: Hello, I'm a language model, and I don't have to go too far from the programming. This gives an idea of how much of the code will
rank 0 sample 1: Hello, I'm a language model, just sort of like that. So maybe you have other problems that can help you solve that problem, please do help and
rank 0 sample 2: Hello, I'm a language model, so I got this class here. But I also got this. It's a big, long, and simple way of
rank 0 sample 3: Hello, I'm a language model, a Java programming language, and an OpenGL environment.
This is a great introduction to a basic Java programming language and why
rank 1 sample 0: Hello, I'm a language model, one that integrates the knowledge and skills relevant in my language.<|endoftext|>The United States is an autonomous and autonomous region of the
rank 1 sample 1: Hello, I'm a language model, which means, it's a simple syntax for the class names. Now, when I give the I, I'm a
rank 1 sample 2: Hello, I'm a language model, a few things about the language, and a few things about some other aspects of the language that is used. And all
rank 1 sample 3: Hello, I'm a language model, and I'm using it now. You try to work them out the concept:
2.2.3 - A
Step:  3250, loss: 3.391765, norm: 0.3531, time(ms): 3808.48, token/sec:137663.35, val_loss: 3.4918, hellaswag_acc: 0.2665
Step:  3251, loss: 3.327701, norm: 0.3173, time(ms): 784.23, token/sec:668538.98, hellaswag_acc: 0.2665
Step:  3252, loss: 3.327818, norm: 0.3079, time(ms): 787.85, token/sec:665469.07, hellaswag_acc: 0.2665
Step:  3253, loss: 3.350151, norm: 0.3125, time(ms): 796.51, token/sec:658235.10, hellaswag_acc: 0.2665
Step:  3254, loss: 3.376661, norm: 0.3019, time(ms): 798.70, token/sec:656424.26, hellaswag_acc: 0.2665
Step:  3255, loss: 3.355834, norm: 0.2673, time(ms): 788.05, token/sec:665300.16, hellaswag_acc: 0.2665
Step:  3256, loss: 3.401939, norm: 0.2791, time(ms): 785.90, token/sec:667114.62, hellaswag_acc: 0.2665
Step:  3257, loss: 3.360246, norm: 0.2663, time(ms): 790.62, token/sec:663133.99, hellaswag_acc: 0.2665
Step:  3258, loss: 3.484879, norm: 0.2633, time(ms): 801.97, token/sec:653748.58, hellaswag_acc: 0.2665
Step:  3259, loss: 3.493309, norm: 0.2672, time(ms): 799.97, token/sec:655385.24, hellaswag_acc: 0.2665
Step:  3260, loss: 3.462191, norm: 0.2495, time(ms): 791.63, token/sec:662285.79, hellaswag_acc: 0.2665
Step:  3261, loss: 3.554436, norm: 0.2966, time(ms): 800.14, token/sec:655244.63, hellaswag_acc: 0.2665
Step:  3262, loss: 3.518198, norm: 0.3494, time(ms): 807.77, token/sec:649058.33, hellaswag_acc: 0.2665
Step:  3263, loss: 3.542646, norm: 0.3200, time(ms): 791.01, token/sec:662806.39, hellaswag_acc: 0.2665
Step:  3264, loss: 3.535425, norm: 0.2941, time(ms): 795.93, token/sec:658708.90, hellaswag_acc: 0.2665
Step:  3265, loss: 3.517313, norm: 0.2595, time(ms): 790.24, token/sec:663457.90, hellaswag_acc: 0.2665
Step:  3266, loss: 3.507345, norm: 0.2780, time(ms): 793.91, token/sec:660385.59, hellaswag_acc: 0.2665
Step:  3267, loss: 3.458556, norm: 0.2540, time(ms): 791.86, token/sec:662095.75, hellaswag_acc: 0.2665
Step:  3268, loss: 3.508922, norm: 0.2544, time(ms): 789.16, token/sec:664360.09, hellaswag_acc: 0.2665
Step:  3269, loss: 3.506939, norm: 0.2560, time(ms): 799.07, token/sec:656118.73, hellaswag_acc: 0.2665
Step:  3270, loss: 3.454520, norm: 0.2618, time(ms): 799.67, token/sec:655628.70, hellaswag_acc: 0.2665
Step:  3271, loss: 3.498068, norm: 0.2824, time(ms): 794.05, token/sec:660273.16, hellaswag_acc: 0.2665
Step:  3272, loss: 3.491251, norm: 0.2631, time(ms): 787.61, token/sec:665669.11, hellaswag_acc: 0.2665
Step:  3273, loss: 3.478981, norm: 0.2529, time(ms): 794.82, token/sec:659633.63, hellaswag_acc: 0.2665
Step:  3274, loss: 3.491212, norm: 0.2580, time(ms): 796.39, token/sec:658330.47, hellaswag_acc: 0.2665
Step:  3275, loss: 3.456728, norm: 0.2795, time(ms): 791.09, token/sec:662737.48, hellaswag_acc: 0.2665
Step:  3276, loss: 3.533236, norm: 0.2716, time(ms): 789.84, token/sec:663791.35, hellaswag_acc: 0.2665
Step:  3277, loss: 3.470851, norm: 0.2802, time(ms): 788.26, token/sec:665122.47, hellaswag_acc: 0.2665
Step:  3278, loss: 3.481738, norm: 0.2776, time(ms): 804.64, token/sec:651579.24, hellaswag_acc: 0.2665
Step:  3279, loss: 3.412601, norm: 0.2485, time(ms): 801.20, token/sec:654374.61, hellaswag_acc: 0.2665
Step:  3280, loss: 3.496823, norm: 0.2531, time(ms): 790.07, token/sec:663595.85, hellaswag_acc: 0.2665
Step:  3281, loss: 3.421277, norm: 0.2614, time(ms): 801.93, token/sec:653779.48, hellaswag_acc: 0.2665
Step:  3282, loss: 3.460207, norm: 0.2384, time(ms): 806.83, token/sec:649811.32, hellaswag_acc: 0.2665
Step:  3283, loss: 3.460779, norm: 0.2598, time(ms): 799.34, token/sec:655897.98, hellaswag_acc: 0.2665
Step:  3284, loss: 3.430317, norm: 0.2623, time(ms): 791.05, token/sec:662774.83, hellaswag_acc: 0.2665
Step:  3285, loss: 3.406210, norm: 0.2645, time(ms): 805.86, token/sec:650593.78, hellaswag_acc: 0.2665
Step:  3286, loss: 3.497576, norm: 0.2804, time(ms): 801.87, token/sec:653835.47, hellaswag_acc: 0.2665
Step:  3287, loss: 3.411502, norm: 0.2705, time(ms): 801.79, token/sec:653894.38, hellaswag_acc: 0.2665
Step:  3288, loss: 3.529384, norm: 0.2913, time(ms): 789.80, token/sec:663819.60, hellaswag_acc: 0.2665
Step:  3289, loss: 3.486892, norm: 0.3032, time(ms): 805.78, token/sec:650660.97, hellaswag_acc: 0.2665
Step:  3290, loss: 3.448519, norm: 0.3147, time(ms): 802.29, token/sec:653490.58, hellaswag_acc: 0.2665
Step:  3291, loss: 3.413306, norm: 0.2618, time(ms): 799.91, token/sec:655431.34, hellaswag_acc: 0.2665
Step:  3292, loss: 3.358353, norm: 0.2565, time(ms): 786.92, token/sec:666250.15, hellaswag_acc: 0.2665
Step:  3293, loss: 3.347945, norm: 0.2545, time(ms): 790.08, token/sec:663588.44, hellaswag_acc: 0.2665
Step:  3294, loss: 3.312650, norm: 0.2535, time(ms): 793.99, token/sec:660317.37, hellaswag_acc: 0.2665
Step:  3295, loss: 3.363765, norm: 0.2699, time(ms): 792.97, token/sec:661165.91, hellaswag_acc: 0.2665
Step:  3296, loss: 3.380546, norm: 0.2740, time(ms): 789.22, token/sec:664311.12, hellaswag_acc: 0.2665
Step:  3297, loss: 3.312805, norm: 0.2642, time(ms): 799.85, token/sec:655482.72, hellaswag_acc: 0.2665
Step:  3298, loss: 3.395333, norm: 0.2713, time(ms): 804.40, token/sec:651777.77, hellaswag_acc: 0.2665
Step:  3299, loss: 3.333006, norm: 0.2656, time(ms): 797.46, token/sec:657451.06, hellaswag_acc: 0.2665
Step:  3300, loss: 3.326149, norm: 0.2656, time(ms): 796.13, token/sec:658542.21, hellaswag_acc: 0.2665
Step:  3301, loss: 3.313682, norm: 0.3273, time(ms): 803.67, token/sec:652364.23, hellaswag_acc: 0.2665
Step:  3302, loss: 3.374004, norm: 0.3345, time(ms): 802.01, token/sec:653714.18, hellaswag_acc: 0.2665
Step:  3303, loss: 3.378520, norm: 0.3227, time(ms): 797.49, token/sec:657420.80, hellaswag_acc: 0.2665
Step:  3304, loss: 3.525192, norm: 0.3193, time(ms): 799.65, token/sec:655643.36, hellaswag_acc: 0.2665
Step:  3305, loss: 3.538145, norm: 0.2991, time(ms): 797.53, token/sec:657385.62, hellaswag_acc: 0.2665
Step:  3306, loss: 3.474826, norm: 0.3037, time(ms): 805.12, token/sec:651189.87, hellaswag_acc: 0.2665
Step:  3307, loss: 3.511871, norm: 0.3047, time(ms): 793.09, token/sec:661073.28, hellaswag_acc: 0.2665
Step:  3308, loss: 3.539660, norm: 0.2876, time(ms): 797.62, token/sec:657319.20, hellaswag_acc: 0.2665
Step:  3309, loss: 3.488324, norm: 0.2544, time(ms): 793.47, token/sec:660755.07, hellaswag_acc: 0.2665
Step:  3310, loss: 3.544967, norm: 0.2971, time(ms): 796.37, token/sec:658349.99, hellaswag_acc: 0.2665
Step:  3311, loss: 3.491587, norm: 0.2634, time(ms): 783.63, token/sec:669052.57, hellaswag_acc: 0.2665
Step:  3312, loss: 3.523934, norm: 0.2797, time(ms): 789.05, token/sec:664458.05, hellaswag_acc: 0.2665
Step:  3313, loss: 3.506742, norm: 0.2879, time(ms): 798.68, token/sec:656439.55, hellaswag_acc: 0.2665
Step:  3314, loss: 3.527454, norm: 0.2692, time(ms): 789.64, token/sec:663961.31, hellaswag_acc: 0.2665
Step:  3315, loss: 3.497155, norm: 0.2473, time(ms): 791.65, token/sec:662274.81, hellaswag_acc: 0.2665
Step:  3316, loss: 3.460824, norm: 0.2562, time(ms): 801.83, token/sec:653864.05, hellaswag_acc: 0.2665
Step:  3317, loss: 3.501436, norm: 0.2576, time(ms): 804.57, token/sec:651637.36, hellaswag_acc: 0.2665
Step:  3318, loss: 3.530621, norm: 0.2497, time(ms): 800.80, token/sec:654708.93, hellaswag_acc: 0.2665
Step:  3319, loss: 3.566838, norm: 0.2687, time(ms): 789.39, token/sec:664164.65, hellaswag_acc: 0.2665
Step:  3320, loss: 3.491120, norm: 0.2434, time(ms): 802.61, token/sec:653225.99, hellaswag_acc: 0.2665
Step:  3321, loss: 3.498511, norm: 0.2703, time(ms): 806.44, token/sec:650122.93, hellaswag_acc: 0.2665
Step:  3322, loss: 3.487194, norm: 0.2813, time(ms): 800.85, token/sec:654661.57, hellaswag_acc: 0.2665
Step:  3323, loss: 3.481038, norm: 0.2996, time(ms): 792.53, token/sec:661533.47, hellaswag_acc: 0.2665
Step:  3324, loss: 3.474936, norm: 0.2877, time(ms): 799.57, token/sec:655713.55, hellaswag_acc: 0.2665
Step:  3325, loss: 3.431972, norm: 0.2807, time(ms): 805.89, token/sec:650570.11, hellaswag_acc: 0.2665
Step:  3326, loss: 3.528312, norm: 0.3046, time(ms): 801.15, token/sec:654420.57, hellaswag_acc: 0.2665
Step:  3327, loss: 3.463918, norm: 0.2839, time(ms): 792.01, token/sec:661973.57, hellaswag_acc: 0.2665
Step:  3328, loss: 3.416515, norm: 0.2743, time(ms): 798.27, token/sec:656781.08, hellaswag_acc: 0.2665
Step:  3329, loss: 3.438193, norm: 0.2735, time(ms): 803.32, token/sec:652654.65, hellaswag_acc: 0.2665
Step:  3330, loss: 3.430974, norm: 0.3121, time(ms): 801.61, token/sec:654040.05, hellaswag_acc: 0.2665
Step:  3331, loss: 3.474607, norm: 0.3212, time(ms): 799.44, token/sec:655820.13, hellaswag_acc: 0.2665
Step:  3332, loss: 3.386785, norm: 0.2736, time(ms): 792.95, token/sec:661187.38, hellaswag_acc: 0.2665
Step:  3333, loss: 3.406924, norm: 0.2653, time(ms): 792.59, token/sec:661488.50, hellaswag_acc: 0.2665
Step:  3334, loss: 3.459482, norm: 0.2795, time(ms): 789.52, token/sec:664059.56, hellaswag_acc: 0.2665
Step:  3335, loss: 3.439735, norm: 0.3095, time(ms): 793.11, token/sec:661055.40, hellaswag_acc: 0.2665
Step:  3336, loss: 3.441022, norm: 0.2332, time(ms): 791.11, token/sec:662725.09, hellaswag_acc: 0.2665
Step:  3337, loss: 3.450809, norm: 0.2452, time(ms): 799.89, token/sec:655450.48, hellaswag_acc: 0.2665
Step:  3338, loss: 3.317939, norm: 0.2496, time(ms): 804.52, token/sec:651677.91, hellaswag_acc: 0.2665
Step:  3339, loss: 3.331052, norm: 0.2844, time(ms): 789.50, token/sec:664073.99, hellaswag_acc: 0.2665
Step:  3340, loss: 3.376853, norm: 0.4255, time(ms): 799.47, token/sec:655790.40, hellaswag_acc: 0.2665
Step:  3341, loss: 3.376678, norm: 0.2953, time(ms): 792.43, token/sec:661621.64, hellaswag_acc: 0.2665
Step:  3342, loss: 3.401746, norm: 0.3171, time(ms): 794.76, token/sec:659684.48, hellaswag_acc: 0.2665
Step:  3343, loss: 3.341305, norm: 0.3108, time(ms): 791.34, token/sec:662533.21, hellaswag_acc: 0.2665
Step:  3344, loss: 3.382150, norm: 0.3459, time(ms): 791.85, token/sec:662108.91, hellaswag_acc: 0.2665
Step:  3345, loss: 3.369402, norm: 0.2757, time(ms): 793.74, token/sec:660524.84, hellaswag_acc: 0.2665
Step:  3346, loss: 3.416552, norm: 0.3000, time(ms): 788.80, token/sec:664668.53, hellaswag_acc: 0.2665
Step:  3347, loss: 3.351240, norm: 0.3113, time(ms): 789.26, token/sec:664279.61, hellaswag_acc: 0.2665
Step:  3348, loss: 3.302969, norm: 0.3169, time(ms): 806.11, token/sec:650390.20, hellaswag_acc: 0.2665
Step:  3349, loss: 3.360462, norm: 0.2840, time(ms): 799.02, token/sec:656164.54, hellaswag_acc: 0.2665
Step:  3350, loss: 3.583116, norm: 0.3574, time(ms): 794.07, token/sec:660252.35, hellaswag_acc: 0.2665
Step:  3351, loss: 3.558404, norm: 0.4095, time(ms): 799.17, token/sec:656038.48, hellaswag_acc: 0.2665
Step:  3352, loss: 3.588109, norm: 0.3764, time(ms): 806.27, token/sec:650266.34, hellaswag_acc: 0.2665
Step:  3353, loss: 3.498833, norm: 0.3188, time(ms): 802.08, token/sec:653659.19, hellaswag_acc: 0.2665
Step:  3354, loss: 3.495662, norm: 0.3151, time(ms): 788.64, token/sec:664798.94, hellaswag_acc: 0.2665
Step:  3355, loss: 3.529495, norm: 0.3456, time(ms): 803.25, token/sec:652706.37, hellaswag_acc: 0.2665
Step:  3356, loss: 3.472976, norm: 0.3351, time(ms): 805.92, token/sec:650545.67, hellaswag_acc: 0.2665
Step:  3357, loss: 3.507759, norm: 0.3188, time(ms): 801.10, token/sec:654458.94, hellaswag_acc: 0.2665
Step:  3358, loss: 3.553336, norm: 0.2991, time(ms): 788.16, token/sec:665204.16, hellaswag_acc: 0.2665
Step:  3359, loss: 3.519555, norm: 0.2989, time(ms): 801.03, token/sec:654513.87, hellaswag_acc: 0.2665
Step:  3360, loss: 3.444603, norm: 0.2671, time(ms): 809.16, token/sec:647941.84, hellaswag_acc: 0.2665
Step:  3361, loss: 3.478749, norm: 0.2620, time(ms): 798.74, token/sec:656392.13, hellaswag_acc: 0.2665
Step:  3362, loss: 3.491649, norm: 0.2762, time(ms): 785.73, token/sec:667265.22, hellaswag_acc: 0.2665
Step:  3363, loss: 3.508769, norm: 0.2837, time(ms): 789.75, token/sec:663867.70, hellaswag_acc: 0.2665
Step:  3364, loss: 3.527061, norm: 0.2920, time(ms): 798.09, token/sec:656924.31, hellaswag_acc: 0.2665
Step:  3365, loss: 3.479398, norm: 0.2594, time(ms): 792.65, token/sec:661435.57, hellaswag_acc: 0.2665
Step:  3366, loss: 3.527668, norm: 0.2720, time(ms): 793.86, token/sec:660430.61, hellaswag_acc: 0.2665
Step:  3367, loss: 3.479540, norm: 0.2655, time(ms): 793.08, token/sec:661079.84, hellaswag_acc: 0.2665
Step:  3368, loss: 3.480814, norm: 0.2722, time(ms): 803.89, token/sec:652188.93, hellaswag_acc: 0.2665
Step:  3369, loss: 3.443388, norm: 0.2524, time(ms): 803.53, token/sec:652480.37, hellaswag_acc: 0.2665
Step:  3370, loss: 3.518382, norm: 0.2695, time(ms): 795.78, token/sec:658838.36, hellaswag_acc: 0.2665
Step:  3371, loss: 3.463909, norm: 0.2920, time(ms): 797.43, token/sec:657474.06, hellaswag_acc: 0.2665
Step:  3372, loss: 3.559850, norm: 0.2661, time(ms): 801.47, token/sec:654161.45, hellaswag_acc: 0.2665
Step:  3373, loss: 3.466503, norm: 0.2683, time(ms): 803.93, token/sec:652157.41, hellaswag_acc: 0.2665
Step:  3374, loss: 3.503629, norm: 0.3142, time(ms): 793.78, token/sec:660495.08, hellaswag_acc: 0.2665
Step:  3375, loss: 3.529260, norm: 0.3040, time(ms): 802.60, token/sec:653240.35, hellaswag_acc: 0.2665
Step:  3376, loss: 3.444801, norm: 0.2789, time(ms): 799.86, token/sec:655478.62, hellaswag_acc: 0.2665
Step:  3377, loss: 3.405280, norm: 0.2506, time(ms): 800.20, token/sec:655192.50, hellaswag_acc: 0.2665
Step:  3378, loss: 3.485915, norm: 0.2574, time(ms): 799.73, token/sec:655582.38, hellaswag_acc: 0.2665
Step:  3379, loss: 3.431830, norm: 0.2596, time(ms): 795.80, token/sec:658817.24, hellaswag_acc: 0.2665
Step:  3380, loss: 3.471606, norm: 0.2506, time(ms): 805.50, token/sec:650883.21, hellaswag_acc: 0.2665
Step:  3381, loss: 3.481835, norm: 0.2394, time(ms): 800.48, token/sec:654967.50, hellaswag_acc: 0.2665
Step:  3382, loss: 3.426304, norm: 0.2360, time(ms): 792.37, token/sec:661667.83, hellaswag_acc: 0.2665
Step:  3383, loss: 3.429994, norm: 0.2474, time(ms): 798.69, token/sec:656433.08, hellaswag_acc: 0.2665
Step:  3384, loss: 3.292771, norm: 0.2708, time(ms): 794.61, token/sec:659806.61, hellaswag_acc: 0.2665
Step:  3385, loss: 3.339710, norm: 0.2766, time(ms): 795.39, token/sec:659155.53, hellaswag_acc: 0.2665
Step:  3386, loss: 3.338970, norm: 0.2833, time(ms): 788.49, token/sec:664924.37, hellaswag_acc: 0.2665
Step:  3387, loss: 3.291554, norm: 0.2716, time(ms): 789.86, token/sec:663771.31, hellaswag_acc: 0.2665
Step:  3388, loss: 3.297030, norm: 0.2910, time(ms): 790.16, token/sec:663522.36, hellaswag_acc: 0.2665
Step:  3389, loss: 3.273624, norm: 0.2741, time(ms): 796.16, token/sec:658518.75, hellaswag_acc: 0.2665
Step:  3390, loss: 3.304418, norm: 0.2704, time(ms): 789.08, token/sec:664430.55, hellaswag_acc: 0.2665
Step:  3391, loss: 3.421650, norm: 0.4324, time(ms): 794.72, token/sec:659714.37, hellaswag_acc: 0.2665
Step:  3392, loss: 3.479655, norm: 0.3393, time(ms): 792.22, token/sec:661796.27, hellaswag_acc: 0.2665
Step:  3393, loss: 3.294362, norm: 0.3457, time(ms): 791.32, token/sec:662549.18, hellaswag_acc: 0.2665
Step:  3394, loss: 3.337883, norm: 0.3056, time(ms): 790.33, token/sec:663377.04, hellaswag_acc: 0.2665
Step:  3395, loss: 3.369691, norm: 0.3037, time(ms): 790.83, token/sec:662955.86, hellaswag_acc: 0.2665
Step:  3396, loss: 3.434321, norm: 0.3377, time(ms): 800.11, token/sec:655271.38, hellaswag_acc: 0.2665
Step:  3397, loss: 3.476858, norm: 0.3304, time(ms): 803.65, token/sec:652384.16, hellaswag_acc: 0.2665
Step:  3398, loss: 3.456200, norm: 0.3330, time(ms): 796.90, token/sec:657910.95, hellaswag_acc: 0.2665
Step:  3399, loss: 3.443480, norm: 0.2916, time(ms): 793.77, token/sec:660506.39, hellaswag_acc: 0.2665
Step:  3400, loss: 3.480184, norm: 0.3091, time(ms): 798.89, token/sec:656266.96, hellaswag_acc: 0.2665
Step:  3401, loss: 3.433183, norm: 0.2971, time(ms): 792.54, token/sec:661526.70, hellaswag_acc: 0.2665
Step:  3402, loss: 3.422432, norm: 0.3044, time(ms): 788.39, token/sec:665007.62, hellaswag_acc: 0.2665
Step:  3403, loss: 3.402941, norm: 0.3585, time(ms): 794.30, token/sec:660065.66, hellaswag_acc: 0.2665
Step:  3404, loss: 3.408063, norm: 0.3348, time(ms): 790.75, token/sec:663029.42, hellaswag_acc: 0.2665
Step:  3405, loss: 3.480507, norm: 0.3201, time(ms): 796.90, token/sec:657910.36, hellaswag_acc: 0.2665
Step:  3406, loss: 3.461299, norm: 0.3198, time(ms): 790.00, token/sec:663651.52, hellaswag_acc: 0.2665
Step:  3407, loss: 3.521709, norm: 0.2992, time(ms): 790.53, token/sec:663206.59, hellaswag_acc: 0.2665
Step:  3408, loss: 3.490426, norm: 0.2789, time(ms): 802.92, token/sec:652975.19, hellaswag_acc: 0.2665
Step:  3409, loss: 3.507376, norm: 0.2760, time(ms): 800.42, token/sec:655016.86, hellaswag_acc: 0.2665
Step:  3410, loss: 3.449646, norm: 0.2987, time(ms): 801.62, token/sec:654033.43, hellaswag_acc: 0.2665
Step:  3411, loss: 3.482961, norm: 0.2756, time(ms): 792.81, token/sec:661299.72, hellaswag_acc: 0.2665
Step:  3412, loss: 3.468490, norm: 0.2603, time(ms): 804.98, token/sec:651305.40, hellaswag_acc: 0.2665
Step:  3413, loss: 3.438451, norm: 0.2352, time(ms): 802.26, token/sec:653516.41, hellaswag_acc: 0.2665
Step:  3414, loss: 3.483324, norm: 0.2509, time(ms): 795.62, token/sec:658970.84, hellaswag_acc: 0.2665
Step:  3415, loss: 3.514797, norm: 0.2818, time(ms): 796.24, token/sec:658455.65, hellaswag_acc: 0.2665
Step:  3416, loss: 3.449878, norm: 0.2857, time(ms): 805.57, token/sec:650832.55, hellaswag_acc: 0.2665
Step:  3417, loss: 3.483249, norm: 0.2923, time(ms): 797.92, token/sec:657065.05, hellaswag_acc: 0.2665
Step:  3418, loss: 3.511885, norm: 0.3175, time(ms): 798.72, token/sec:656412.31, hellaswag_acc: 0.2665
Step:  3419, loss: 3.474760, norm: 0.3193, time(ms): 802.21, token/sec:653556.23, hellaswag_acc: 0.2665
Step:  3420, loss: 3.416011, norm: 0.2827, time(ms): 802.22, token/sec:653547.29, hellaswag_acc: 0.2665
Step:  3421, loss: 3.455593, norm: 0.2583, time(ms): 797.73, token/sec:657224.31, hellaswag_acc: 0.2665
Step:  3422, loss: 3.460916, norm: 0.2775, time(ms): 798.74, token/sec:656391.54, hellaswag_acc: 0.2665
Step:  3423, loss: 3.514258, norm: 0.2696, time(ms): 801.33, token/sec:654273.17, hellaswag_acc: 0.2665
Step:  3424, loss: 3.420123, norm: 0.2919, time(ms): 800.63, token/sec:654848.13, hellaswag_acc: 0.2665
Step:  3425, loss: 3.534495, norm: 0.2568, time(ms): 797.52, token/sec:657396.62, hellaswag_acc: 0.2665
Step:  3426, loss: 3.452935, norm: 0.2642, time(ms): 796.96, token/sec:657863.12, hellaswag_acc: 0.2665
Step:  3427, loss: 3.479468, norm: 0.2871, time(ms): 802.49, token/sec:653329.24, hellaswag_acc: 0.2665
Step:  3428, loss: 3.443555, norm: 0.2628, time(ms): 1323.81, token/sec:396045.93, hellaswag_acc: 0.2665
Step:  3429, loss: 3.421961, norm: 0.2633, time(ms): 769.63, token/sec:681223.21, hellaswag_acc: 0.2665
Step:  3430, loss: 3.426806, norm: 0.2699, time(ms): 787.19, token/sec:666021.53, hellaswag_acc: 0.2665
Step:  3431, loss: 3.383329, norm: 0.2595, time(ms): 799.86, token/sec:655473.93, hellaswag_acc: 0.2665
Step:  3432, loss: 3.392433, norm: 0.2726, time(ms): 787.29, token/sec:665943.47, hellaswag_acc: 0.2665
Step:  3433, loss: 3.429750, norm: 0.3171, time(ms): 784.32, token/sec:668461.14, hellaswag_acc: 0.2665
Step:  3434, loss: 3.410822, norm: 0.2991, time(ms): 785.58, token/sec:667387.54, hellaswag_acc: 0.2665
Step:  3435, loss: 3.497753, norm: 0.2831, time(ms): 800.32, token/sec:655101.55, hellaswag_acc: 0.2665
Step:  3436, loss: 3.414472, norm: 0.2740, time(ms): 793.31, token/sec:660888.12, hellaswag_acc: 0.2665
Step:  3437, loss: 3.440548, norm: 0.2839, time(ms): 789.71, token/sec:663899.57, hellaswag_acc: 0.2665
Step:  3438, loss: 3.416169, norm: 0.2707, time(ms): 787.00, token/sec:666182.13, hellaswag_acc: 0.2665
Step:  3439, loss: 3.391998, norm: 0.2802, time(ms): 786.30, token/sec:666780.45, hellaswag_acc: 0.2665
Step:  3440, loss: 3.390023, norm: 0.2766, time(ms): 806.02, token/sec:650466.19, hellaswag_acc: 0.2665
Step:  3441, loss: 3.436263, norm: 0.2680, time(ms): 801.58, token/sec:654071.37, hellaswag_acc: 0.2665
Step:  3442, loss: 3.359608, norm: 0.2432, time(ms): 789.36, token/sec:664193.74, hellaswag_acc: 0.2665
Step:  3443, loss: 3.367448, norm: 0.2373, time(ms): 800.59, token/sec:654877.00, hellaswag_acc: 0.2665
Step:  3444, loss: 3.318438, norm: 0.2477, time(ms): 806.51, token/sec:650072.19, hellaswag_acc: 0.2665
Step:  3445, loss: 3.395986, norm: 0.2427, time(ms): 797.94, token/sec:657052.68, hellaswag_acc: 0.2665
Step:  3446, loss: 3.336069, norm: 0.2686, time(ms): 796.13, token/sec:658543.59, hellaswag_acc: 0.2665
Step:  3447, loss: 3.375696, norm: 0.2383, time(ms): 806.29, token/sec:650249.62, hellaswag_acc: 0.2665
Step:  3448, loss: 3.348337, norm: 0.2446, time(ms): 801.00, token/sec:654541.92, hellaswag_acc: 0.2665
Step:  3449, loss: 3.405394, norm: 0.2431, time(ms): 797.33, token/sec:657557.62, hellaswag_acc: 0.2665
Step:  3450, loss: 3.320334, norm: 0.2534, time(ms): 801.36, token/sec:654250.79, hellaswag_acc: 0.2665
Step:  3451, loss: 3.411637, norm: 0.2466, time(ms): 799.21, token/sec:656005.79, hellaswag_acc: 0.2665
Step:  3452, loss: 3.388733, norm: 0.2664, time(ms): 801.64, token/sec:654018.26, hellaswag_acc: 0.2665
Step:  3453, loss: 3.418190, norm: 0.2623, time(ms): 795.29, token/sec:659242.67, hellaswag_acc: 0.2665
Step:  3454, loss: 3.428813, norm: 0.2606, time(ms): 796.16, token/sec:658520.13, hellaswag_acc: 0.2665
Step:  3455, loss: 3.439156, norm: 0.2872, time(ms): 805.15, token/sec:651166.73, hellaswag_acc: 0.2665
Step:  3456, loss: 3.409719, norm: 0.2992, time(ms): 803.24, token/sec:652715.29, hellaswag_acc: 0.2665
Step:  3457, loss: 3.429960, norm: 0.2587, time(ms): 795.56, token/sec:659014.68, hellaswag_acc: 0.2665
Step:  3458, loss: 3.402433, norm: 0.2487, time(ms): 793.62, token/sec:660628.02, hellaswag_acc: 0.2665
Step:  3459, loss: 3.429989, norm: 0.2506, time(ms): 789.65, token/sec:663949.08, hellaswag_acc: 0.2665
Step:  3460, loss: 3.401226, norm: 0.2846, time(ms): 790.32, token/sec:663385.65, hellaswag_acc: 0.2665
Step:  3461, loss: 3.384782, norm: 0.2761, time(ms): 791.25, token/sec:662610.47, hellaswag_acc: 0.2665
Step:  3462, loss: 3.462299, norm: 0.2927, time(ms): 795.87, token/sec:658760.60, hellaswag_acc: 0.2665
Step:  3463, loss: 3.431179, norm: 0.3023, time(ms): 795.96, token/sec:658688.18, hellaswag_acc: 0.2665
Step:  3464, loss: 3.425054, norm: 0.2999, time(ms): 802.37, token/sec:653424.17, hellaswag_acc: 0.2665
Step:  3465, loss: 3.409188, norm: 0.3048, time(ms): 798.13, token/sec:656893.11, hellaswag_acc: 0.2665
Step:  3466, loss: 3.436262, norm: 0.2899, time(ms): 797.60, token/sec:657328.83, hellaswag_acc: 0.2665
Step:  3467, loss: 3.405626, norm: 0.2822, time(ms): 800.37, token/sec:655058.62, hellaswag_acc: 0.2665
Step:  3468, loss: 3.414550, norm: 0.2684, time(ms): 800.07, token/sec:655303.99, hellaswag_acc: 0.2665
Step:  3469, loss: 3.416132, norm: 0.2517, time(ms): 792.92, token/sec:661211.23, hellaswag_acc: 0.2665
Step:  3470, loss: 3.392936, norm: 0.2642, time(ms): 793.88, token/sec:660415.73, hellaswag_acc: 0.2665
Step:  3471, loss: 3.446543, norm: 0.2543, time(ms): 788.72, token/sec:664734.83, hellaswag_acc: 0.2665
Step:  3472, loss: 3.426280, norm: 0.2719, time(ms): 789.10, token/sec:664410.27, hellaswag_acc: 0.2665
Step:  3473, loss: 3.430802, norm: 0.2694, time(ms): 789.28, token/sec:664258.54, hellaswag_acc: 0.2665
Step:  3474, loss: 3.397639, norm: 0.2810, time(ms): 791.24, token/sec:662617.86, hellaswag_acc: 0.2665
Step:  3475, loss: 3.343583, norm: 0.3112, time(ms): 796.09, token/sec:658576.53, hellaswag_acc: 0.2665
Step:  3476, loss: 3.387689, norm: 0.2950, time(ms): 799.46, token/sec:655800.96, hellaswag_acc: 0.2665
Step:  3477, loss: 3.344912, norm: 0.3043, time(ms): 804.52, token/sec:651677.91, hellaswag_acc: 0.2665
Step:  3478, loss: 3.343846, norm: 0.3042, time(ms): 799.29, token/sec:655940.83, hellaswag_acc: 0.2665
Step:  3479, loss: 3.346714, norm: 0.2964, time(ms): 795.19, token/sec:659322.92, hellaswag_acc: 0.2665
Step:  3480, loss: 3.454224, norm: 0.2926, time(ms): 799.83, token/sec:655499.13, hellaswag_acc: 0.2665
Step:  3481, loss: 3.368494, norm: 0.2819, time(ms): 805.62, token/sec:650790.37, hellaswag_acc: 0.2665
Step:  3482, loss: 3.396892, norm: 0.2761, time(ms): 786.82, token/sec:666335.75, hellaswag_acc: 0.2665
Step:  3483, loss: 3.390565, norm: 0.2920, time(ms): 787.09, token/sec:666106.86, hellaswag_acc: 0.2665
Step:  3484, loss: 3.414042, norm: 0.2760, time(ms): 799.07, token/sec:656126.17, hellaswag_acc: 0.2665
Step:  3485, loss: 3.351693, norm: 0.2575, time(ms): 797.00, token/sec:657829.66, hellaswag_acc: 0.2665
Step:  3486, loss: 3.410225, norm: 0.2455, time(ms): 790.32, token/sec:663388.85, hellaswag_acc: 0.2665
Step:  3487, loss: 3.412676, norm: 0.2723, time(ms): 792.35, token/sec:661689.33, hellaswag_acc: 0.2665
Step:  3488, loss: 3.461316, norm: 0.2734, time(ms): 802.92, token/sec:652976.94, hellaswag_acc: 0.2665
Step:  3489, loss: 3.484180, norm: 0.3290, time(ms): 802.75, token/sec:653115.02, hellaswag_acc: 0.2665
Step:  3490, loss: 3.507244, norm: 0.3570, time(ms): 792.37, token/sec:661669.42, hellaswag_acc: 0.2665
Step:  3491, loss: 3.425043, norm: 0.3523, time(ms): 796.58, token/sec:658171.46, hellaswag_acc: 0.2665
Step:  3492, loss: 3.413684, norm: 0.3290, time(ms): 791.82, token/sec:662133.03, hellaswag_acc: 0.2665
Step:  3493, loss: 3.429871, norm: 0.2979, time(ms): 792.81, token/sec:661307.27, hellaswag_acc: 0.2665
Step:  3494, loss: 3.374065, norm: 0.2724, time(ms): 792.92, token/sec:661215.21, hellaswag_acc: 0.2665
Step:  3495, loss: 3.431469, norm: 0.2974, time(ms): 791.19, token/sec:662654.20, hellaswag_acc: 0.2665
Step:  3496, loss: 3.421648, norm: 0.2934, time(ms): 790.05, token/sec:663611.87, hellaswag_acc: 0.2665
Step:  3497, loss: 3.420104, norm: 0.2870, time(ms): 790.72, token/sec:663055.01, hellaswag_acc: 0.2665
Step:  3498, loss: 3.419141, norm: 0.3174, time(ms): 801.30, token/sec:654300.82, hellaswag_acc: 0.2665
Step:  3499, loss: 3.431050, norm: 0.2910, time(ms): 782.21, token/sec:670266.35, hellaswag_acc: 0.2665
rank 0 sample 0: Hello, I'm a language model, and I'd like you to know where people start?
- Why have they been working on it, in the language
rank 0 sample 1: Hello, I'm a language model, I just want to make sure you try to make what happens in class; and then, how can I help you make
rank 0 sample 2: Hello, I'm a language model, I'm gonna look at different elements to see exactly what I would want to do. I'm gonna look at different entities
rank 0 sample 3: Hello, I'm a language model, not very good.
This article has a review of the way some aspects of modern-day language design are linked up
rank 1 sample 0: Hello, I'm a language model, as if it were a movie. On this project I decided to make a 3D scene that looks like it's a
rank 1 sample 1: Hello, I'm a language model, a model for languages, and a model for languages. All of the parts were part of the presentation, and I'm
rank 1 sample 2: Hello, I'm a language model, so today, I'm going to say, "Hi, let's go down to the floor. So I think that
rank 1 sample 3: Hello, I'm a language model, and I'm interested to help you learn (and think appropriate, just, really) (including what I'm looking at
Step:  3500, loss: 3.400585, norm: 0.2747, time(ms): 3825.15, token/sec:137063.49, val_loss: 3.4544, hellaswag_acc: 0.2665
Step:  3501, loss: 3.445271, norm: 0.2580, time(ms): 788.91, token/sec:664574.52, hellaswag_acc: 0.2665
Step:  3502, loss: 3.424515, norm: 0.2887, time(ms): 791.44, token/sec:662452.38, hellaswag_acc: 0.2665
Step:  3503, loss: 3.400636, norm: 0.2537, time(ms): 790.39, token/sec:663332.02, hellaswag_acc: 0.2665
Step:  3504, loss: 3.409600, norm: 0.2497, time(ms): 791.38, token/sec:662499.68, hellaswag_acc: 0.2665
Step:  3505, loss: 3.432000, norm: 0.2540, time(ms): 792.64, token/sec:661442.34, hellaswag_acc: 0.2665
Step:  3506, loss: 3.407167, norm: 0.2519, time(ms): 784.36, token/sec:668427.82, hellaswag_acc: 0.2665
Step:  3507, loss: 3.453781, norm: 0.2425, time(ms): 791.93, token/sec:662040.34, hellaswag_acc: 0.2665
Step:  3508, loss: 3.439446, norm: 0.2526, time(ms): 797.45, token/sec:657458.73, hellaswag_acc: 0.2665
Step:  3509, loss: 3.383040, norm: 0.2700, time(ms): 797.20, token/sec:657658.11, hellaswag_acc: 0.2665
Step:  3510, loss: 3.377436, norm: 0.2523, time(ms): 799.98, token/sec:655378.79, hellaswag_acc: 0.2665
Step:  3511, loss: 3.352243, norm: 0.2892, time(ms): 797.46, token/sec:657447.13, hellaswag_acc: 0.2665
Step:  3512, loss: 3.372610, norm: 0.2671, time(ms): 798.99, token/sec:656184.90, hellaswag_acc: 0.2665
Step:  3513, loss: 3.368894, norm: 0.2663, time(ms): 796.36, token/sec:658356.49, hellaswag_acc: 0.2665
Step:  3514, loss: 3.366657, norm: 0.2912, time(ms): 790.71, token/sec:663057.81, hellaswag_acc: 0.2665
Step:  3515, loss: 3.426724, norm: 0.2786, time(ms): 784.06, token/sec:668680.06, hellaswag_acc: 0.2665
Step:  3516, loss: 3.365788, norm: 0.2668, time(ms): 787.58, token/sec:665694.50, hellaswag_acc: 0.2665
Step:  3517, loss: 3.349031, norm: 0.2387, time(ms): 807.79, token/sec:649039.56, hellaswag_acc: 0.2665
Step:  3518, loss: 3.404729, norm: 0.2504, time(ms): 783.97, token/sec:668762.22, hellaswag_acc: 0.2665
Step:  3519, loss: 3.381181, norm: 0.2712, time(ms): 787.91, token/sec:665419.54, hellaswag_acc: 0.2665
Step:  3520, loss: 3.347495, norm: 0.2477, time(ms): 793.23, token/sec:660951.68, hellaswag_acc: 0.2665
Step:  3521, loss: 3.440006, norm: 0.3023, time(ms): 793.72, token/sec:660546.47, hellaswag_acc: 0.2665
Step:  3522, loss: 3.429604, norm: 0.2905, time(ms): 791.50, token/sec:662402.09, hellaswag_acc: 0.2665
Step:  3523, loss: 3.439254, norm: 0.2646, time(ms): 798.23, token/sec:656813.84, hellaswag_acc: 0.2665
Step:  3524, loss: 3.508201, norm: 0.2976, time(ms): 790.15, token/sec:663529.97, hellaswag_acc: 0.2665
Step:  3525, loss: 3.322665, norm: 0.3019, time(ms): 789.90, token/sec:663737.86, hellaswag_acc: 0.2665
Step:  3526, loss: 3.453307, norm: 0.3033, time(ms): 789.01, token/sec:664490.18, hellaswag_acc: 0.2665
Step:  3527, loss: 3.417363, norm: 0.3407, time(ms): 790.07, token/sec:663594.25, hellaswag_acc: 0.2665
Step:  3528, loss: 3.469934, norm: 0.3219, time(ms): 791.67, token/sec:662259.86, hellaswag_acc: 0.2665
Step:  3529, loss: 3.451733, norm: 0.3421, time(ms): 793.39, token/sec:660818.41, hellaswag_acc: 0.2665
Step:  3530, loss: 3.424165, norm: 0.3027, time(ms): 803.71, token/sec:652335.78, hellaswag_acc: 0.2665
Step:  3531, loss: 3.434113, norm: 0.2889, time(ms): 797.75, token/sec:657210.96, hellaswag_acc: 0.2665
Step:  3532, loss: 3.435814, norm: 0.3023, time(ms): 803.51, token/sec:652501.08, hellaswag_acc: 0.2665
Step:  3533, loss: 3.394964, norm: 0.2789, time(ms): 798.81, token/sec:656332.77, hellaswag_acc: 0.2665
Step:  3534, loss: 3.441586, norm: 0.2853, time(ms): 793.73, token/sec:660537.54, hellaswag_acc: 0.2665
Step:  3535, loss: 3.448763, norm: 0.2600, time(ms): 805.20, token/sec:651128.94, hellaswag_acc: 0.2665
Step:  3536, loss: 3.445147, norm: 0.2513, time(ms): 800.19, token/sec:655200.51, hellaswag_acc: 0.2665
Step:  3537, loss: 3.368951, norm: 0.2431, time(ms): 798.38, token/sec:656692.43, hellaswag_acc: 0.2665
Step:  3538, loss: 3.390775, norm: 0.2424, time(ms): 802.39, token/sec:653404.56, hellaswag_acc: 0.2665
Step:  3539, loss: 3.432659, norm: 0.2675, time(ms): 798.65, token/sec:656470.12, hellaswag_acc: 0.2665
Step:  3540, loss: 3.418160, norm: 0.2919, time(ms): 798.05, token/sec:656960.23, hellaswag_acc: 0.2665
Step:  3541, loss: 3.379704, norm: 0.2890, time(ms): 796.57, token/sec:658179.93, hellaswag_acc: 0.2665
Step:  3542, loss: 3.369152, norm: 0.2739, time(ms): 804.40, token/sec:651771.21, hellaswag_acc: 0.2665
Step:  3543, loss: 3.403806, norm: 0.2834, time(ms): 802.31, token/sec:653474.08, hellaswag_acc: 0.2665
Step:  3544, loss: 3.395848, norm: 0.3081, time(ms): 794.98, token/sec:659502.27, hellaswag_acc: 0.2665
Step:  3545, loss: 3.385352, norm: 0.3032, time(ms): 800.61, token/sec:654862.96, hellaswag_acc: 0.2665
Step:  3546, loss: 3.380055, norm: 0.2563, time(ms): 801.89, token/sec:653818.75, hellaswag_acc: 0.2665
Step:  3547, loss: 3.364090, norm: 0.2710, time(ms): 799.79, token/sec:655534.89, hellaswag_acc: 0.2665
Step:  3548, loss: 3.303170, norm: 0.2663, time(ms): 793.75, token/sec:660522.06, hellaswag_acc: 0.2665
Step:  3549, loss: 3.404286, norm: 0.2850, time(ms): 802.29, token/sec:653485.34, hellaswag_acc: 0.2665
Step:  3550, loss: 3.357249, norm: 0.2508, time(ms): 805.07, token/sec:651230.37, hellaswag_acc: 0.2665
Step:  3551, loss: 3.379841, norm: 0.2482, time(ms): 796.41, token/sec:658315.69, hellaswag_acc: 0.2665
Step:  3552, loss: 3.357981, norm: 0.2401, time(ms): 795.47, token/sec:659094.28, hellaswag_acc: 0.2665
Step:  3553, loss: 3.392682, norm: 0.2490, time(ms): 805.98, token/sec:650497.17, hellaswag_acc: 0.2665
Step:  3554, loss: 3.373407, norm: 0.2731, time(ms): 802.34, token/sec:653451.55, hellaswag_acc: 0.2665
Step:  3555, loss: 3.407448, norm: 0.2769, time(ms): 792.91, token/sec:661220.78, hellaswag_acc: 0.2665
Step:  3556, loss: 3.476362, norm: 0.2969, time(ms): 797.65, token/sec:657293.26, hellaswag_acc: 0.2665
Step:  3557, loss: 3.446293, norm: 0.3083, time(ms): 805.02, token/sec:651271.26, hellaswag_acc: 0.2665
Step:  3558, loss: 3.391387, norm: 0.3514, time(ms): 801.92, token/sec:653791.73, hellaswag_acc: 0.2665
Step:  3559, loss: 3.338251, norm: 0.3475, time(ms): 790.10, token/sec:663573.42, hellaswag_acc: 0.2665
Step:  3560, loss: 3.406792, norm: 0.2898, time(ms): 791.56, token/sec:662345.03, hellaswag_acc: 0.2665
Step:  3561, loss: 3.534600, norm: 0.3384, time(ms): 784.86, token/sec:668005.07, hellaswag_acc: 0.2665
Step:  3562, loss: 3.480235, norm: 0.3051, time(ms): 789.88, token/sec:663758.29, hellaswag_acc: 0.2665
Step:  3563, loss: 3.414462, norm: 0.2808, time(ms): 798.22, token/sec:656822.87, hellaswag_acc: 0.2665
Step:  3564, loss: 3.379027, norm: 0.3156, time(ms): 801.71, token/sec:653961.47, hellaswag_acc: 0.2665
Step:  3565, loss: 3.430975, norm: 0.2656, time(ms): 802.78, token/sec:653086.51, hellaswag_acc: 0.2665
Step:  3566, loss: 3.432832, norm: 0.2745, time(ms): 792.56, token/sec:661508.40, hellaswag_acc: 0.2665
Step:  3567, loss: 3.438369, norm: 0.2549, time(ms): 804.16, token/sec:651969.27, hellaswag_acc: 0.2665
Step:  3568, loss: 3.365823, norm: 0.2513, time(ms): 797.24, token/sec:657632.74, hellaswag_acc: 0.2665
Step:  3569, loss: 3.431933, norm: 0.2545, time(ms): 802.85, token/sec:653031.23, hellaswag_acc: 0.2665
Step:  3570, loss: 3.345304, norm: 0.2581, time(ms): 797.33, token/sec:657550.54, hellaswag_acc: 0.2665
Step:  3571, loss: 3.480145, norm: 0.2683, time(ms): 804.87, token/sec:651393.37, hellaswag_acc: 0.2665
Step:  3572, loss: 3.387054, norm: 0.2709, time(ms): 797.32, token/sec:657565.09, hellaswag_acc: 0.2665
Step:  3573, loss: 3.410607, norm: 0.2754, time(ms): 800.51, token/sec:654945.46, hellaswag_acc: 0.2665
Step:  3574, loss: 3.367001, norm: 0.2348, time(ms): 799.04, token/sec:656143.59, hellaswag_acc: 0.2665
Step:  3575, loss: 3.421023, norm: 0.2480, time(ms): 801.56, token/sec:654081.87, hellaswag_acc: 0.2665
Step:  3576, loss: 3.408098, norm: 0.2525, time(ms): 800.28, token/sec:655130.63, hellaswag_acc: 0.2665
Step:  3577, loss: 3.391449, norm: 0.2547, time(ms): 794.92, token/sec:659544.00, hellaswag_acc: 0.2665
Step:  3578, loss: 3.411739, norm: 0.2419, time(ms): 799.56, token/sec:655721.37, hellaswag_acc: 0.2665
Step:  3579, loss: 3.365078, norm: 0.2583, time(ms): 796.75, token/sec:658031.23, hellaswag_acc: 0.2665
Step:  3580, loss: 3.376817, norm: 0.2517, time(ms): 794.99, token/sec:659492.97, hellaswag_acc: 0.2665
Step:  3581, loss: 3.351238, norm: 0.2581, time(ms): 793.35, token/sec:660849.98, hellaswag_acc: 0.2665
Step:  3582, loss: 3.340872, norm: 0.2589, time(ms): 800.10, token/sec:655281.34, hellaswag_acc: 0.2665
Step:  3583, loss: 3.362589, norm: 0.2484, time(ms): 796.30, token/sec:658403.40, hellaswag_acc: 0.2665
Step:  3584, loss: 3.390699, norm: 0.2526, time(ms): 800.28, token/sec:655133.75, hellaswag_acc: 0.2665
Step:  3585, loss: 3.328874, norm: 0.2591, time(ms): 797.72, token/sec:657229.42, hellaswag_acc: 0.2665
Step:  3586, loss: 3.330311, norm: 0.2593, time(ms): 798.20, token/sec:656840.92, hellaswag_acc: 0.2665
Step:  3587, loss: 3.332219, norm: 0.2664, time(ms): 793.83, token/sec:660453.62, hellaswag_acc: 0.2665
Step:  3588, loss: 3.355587, norm: 0.2516, time(ms): 790.58, token/sec:663171.18, hellaswag_acc: 0.2665
Step:  3589, loss: 3.370588, norm: 0.2480, time(ms): 789.56, token/sec:664026.67, hellaswag_acc: 0.2665
Step:  3590, loss: 3.388745, norm: 0.2770, time(ms): 792.03, token/sec:661958.83, hellaswag_acc: 0.2665
Step:  3591, loss: 3.375750, norm: 0.2785, time(ms): 801.24, token/sec:654347.93, hellaswag_acc: 0.2665
Step:  3592, loss: 3.465508, norm: 0.2610, time(ms): 790.52, token/sec:663219.39, hellaswag_acc: 0.2665
Step:  3593, loss: 3.369842, norm: 0.2592, time(ms): 806.55, token/sec:650036.07, hellaswag_acc: 0.2665
Step:  3594, loss: 3.487364, norm: 0.3303, time(ms): 800.78, token/sec:654721.60, hellaswag_acc: 0.2665
Step:  3595, loss: 3.512314, norm: 0.4109, time(ms): 800.82, token/sec:654692.17, hellaswag_acc: 0.2665
Step:  3596, loss: 3.402966, norm: 0.3310, time(ms): 790.20, token/sec:663484.33, hellaswag_acc: 0.2665
Step:  3597, loss: 3.442712, norm: 0.3018, time(ms): 805.34, token/sec:651014.24, hellaswag_acc: 0.2665
Step:  3598, loss: 3.455568, norm: 0.2685, time(ms): 804.11, token/sec:652011.61, hellaswag_acc: 0.2665
Step:  3599, loss: 3.425210, norm: 0.3133, time(ms): 797.50, token/sec:657416.87, hellaswag_acc: 0.2665
Step:  3600, loss: 3.369296, norm: 0.2791, time(ms): 790.38, token/sec:663334.02, hellaswag_acc: 0.2665
Step:  3601, loss: 3.470439, norm: 0.2864, time(ms): 789.59, token/sec:664002.21, hellaswag_acc: 0.2665
Step:  3602, loss: 3.490231, norm: 0.3213, time(ms): 795.95, token/sec:658694.10, hellaswag_acc: 0.2665
Step:  3603, loss: 3.429406, norm: 0.3216, time(ms): 791.64, token/sec:662282.99, hellaswag_acc: 0.2665
Step:  3604, loss: 3.413316, norm: 0.3250, time(ms): 791.43, token/sec:662454.37, hellaswag_acc: 0.2665
Step:  3605, loss: 3.389123, norm: 0.2908, time(ms): 794.84, token/sec:659614.63, hellaswag_acc: 0.2665
Step:  3606, loss: 3.426404, norm: 0.2723, time(ms): 802.41, token/sec:653392.33, hellaswag_acc: 0.2665
Step:  3607, loss: 3.379467, norm: 0.2689, time(ms): 805.66, token/sec:650759.55, hellaswag_acc: 0.2665
Step:  3608, loss: 3.450396, norm: 0.2977, time(ms): 788.37, token/sec:665031.75, hellaswag_acc: 0.2665
Step:  3609, loss: 3.386004, norm: 0.2896, time(ms): 790.65, token/sec:663108.79, hellaswag_acc: 0.2665
Step:  3610, loss: 3.450361, norm: 0.2559, time(ms): 788.61, token/sec:664825.47, hellaswag_acc: 0.2665
Step:  3611, loss: 3.413467, norm: 0.2425, time(ms): 788.86, token/sec:664612.08, hellaswag_acc: 0.2665
Step:  3612, loss: 3.438261, norm: 0.2483, time(ms): 791.42, token/sec:662464.75, hellaswag_acc: 0.2665
Step:  3613, loss: 3.457620, norm: 0.2885, time(ms): 791.53, token/sec:662373.36, hellaswag_acc: 0.2665
Step:  3614, loss: 3.452564, norm: 0.2831, time(ms): 789.46, token/sec:664107.29, hellaswag_acc: 0.2665
Step:  3615, loss: 3.420408, norm: 0.2826, time(ms): 805.10, token/sec:651209.73, hellaswag_acc: 0.2665
Step:  3616, loss: 3.416953, norm: 0.2725, time(ms): 802.54, token/sec:653284.21, hellaswag_acc: 0.2665
Step:  3617, loss: 3.357125, norm: 0.2545, time(ms): 801.52, token/sec:654119.62, hellaswag_acc: 0.2665
Step:  3618, loss: 3.354996, norm: 0.2669, time(ms): 791.97, token/sec:662008.25, hellaswag_acc: 0.2665
Step:  3619, loss: 3.353241, norm: 0.2605, time(ms): 1296.07, token/sec:404522.07, hellaswag_acc: 0.2665
Step:  3620, loss: 3.315259, norm: 0.2738, time(ms): 794.17, token/sec:660170.68, hellaswag_acc: 0.2665
Step:  3621, loss: 3.312788, norm: 0.2589, time(ms): 784.95, token/sec:667928.58, hellaswag_acc: 0.2665
Step:  3622, loss: 3.411465, norm: 0.2807, time(ms): 782.63, token/sec:669906.98, hellaswag_acc: 0.2665
Step:  3623, loss: 3.432607, norm: 0.2932, time(ms): 798.30, token/sec:656758.33, hellaswag_acc: 0.2665
Step:  3624, loss: 3.465627, norm: 0.3051, time(ms): 792.62, token/sec:661463.63, hellaswag_acc: 0.2665
Step:  3625, loss: 3.426872, norm: 0.2610, time(ms): 783.90, token/sec:668820.19, hellaswag_acc: 0.2665
Step:  3626, loss: 3.421022, norm: 0.2486, time(ms): 779.49, token/sec:672604.92, hellaswag_acc: 0.2665
Step:  3627, loss: 3.523636, norm: 0.2696, time(ms): 791.91, token/sec:662052.89, hellaswag_acc: 0.2665
Step:  3628, loss: 3.439707, norm: 0.2746, time(ms): 799.66, token/sec:655640.04, hellaswag_acc: 0.2665
Step:  3629, loss: 3.436853, norm: 0.2633, time(ms): 801.53, token/sec:654106.78, hellaswag_acc: 0.2665
Step:  3630, loss: 3.487606, norm: 0.2789, time(ms): 796.66, token/sec:658105.48, hellaswag_acc: 0.2665
Step:  3631, loss: 3.448694, norm: 0.3021, time(ms): 794.97, token/sec:659504.44, hellaswag_acc: 0.2665
Step:  3632, loss: 3.493677, norm: 0.3018, time(ms): 806.20, token/sec:650318.65, hellaswag_acc: 0.2665
Step:  3633, loss: 3.402380, norm: 0.3145, time(ms): 802.65, token/sec:653195.92, hellaswag_acc: 0.2665
Step:  3634, loss: 3.429754, norm: 0.2936, time(ms): 788.48, token/sec:664935.63, hellaswag_acc: 0.2665
Step:  3635, loss: 3.404188, norm: 0.2661, time(ms): 791.79, token/sec:662152.77, hellaswag_acc: 0.2665
Step:  3636, loss: 3.385553, norm: 0.2965, time(ms): 792.29, token/sec:661740.11, hellaswag_acc: 0.2665
Step:  3637, loss: 3.351550, norm: 0.2853, time(ms): 791.80, token/sec:662147.99, hellaswag_acc: 0.2665
Step:  3638, loss: 3.379951, norm: 0.2752, time(ms): 793.36, token/sec:660848.20, hellaswag_acc: 0.2665
Step:  3639, loss: 3.389976, norm: 0.2705, time(ms): 794.67, token/sec:659757.32, hellaswag_acc: 0.2665
Step:  3640, loss: 3.362418, norm: 0.2804, time(ms): 801.67, token/sec:653995.50, hellaswag_acc: 0.2665
Step:  3641, loss: 3.384448, norm: 0.2873, time(ms): 802.48, token/sec:653337.59, hellaswag_acc: 0.2665
Step:  3642, loss: 3.405643, norm: 0.2872, time(ms): 798.50, token/sec:656591.06, hellaswag_acc: 0.2665
Step:  3643, loss: 3.407896, norm: 0.2772, time(ms): 798.42, token/sec:656656.74, hellaswag_acc: 0.2665
Step:  3644, loss: 3.350640, norm: 0.2688, time(ms): 799.80, token/sec:655520.23, hellaswag_acc: 0.2665
Step:  3645, loss: 3.345325, norm: 0.2789, time(ms): 799.00, token/sec:656178.44, hellaswag_acc: 0.2665
Step:  3646, loss: 3.360048, norm: 0.2586, time(ms): 798.84, token/sec:656310.05, hellaswag_acc: 0.2665
Step:  3647, loss: 3.306185, norm: 0.2481, time(ms): 798.11, token/sec:656912.54, hellaswag_acc: 0.2665
Step:  3648, loss: 3.355784, norm: 0.2853, time(ms): 798.03, token/sec:656977.89, hellaswag_acc: 0.2665
Step:  3649, loss: 3.370539, norm: 0.2973, time(ms): 792.24, token/sec:661779.94, hellaswag_acc: 0.2665
Step:  3650, loss: 3.408072, norm: 0.2675, time(ms): 787.40, token/sec:665845.67, hellaswag_acc: 0.2665
Step:  3651, loss: 3.395899, norm: 0.3084, time(ms): 792.02, token/sec:661961.42, hellaswag_acc: 0.2665
Step:  3652, loss: 3.320379, norm: 0.3100, time(ms): 792.52, token/sec:661548.00, hellaswag_acc: 0.2665
Step:  3653, loss: 3.318418, norm: 0.2958, time(ms): 794.13, token/sec:660205.76, hellaswag_acc: 0.2665
Step:  3654, loss: 3.354010, norm: 0.2833, time(ms): 791.28, token/sec:662585.11, hellaswag_acc: 0.2665
Step:  3655, loss: 3.378076, norm: 0.3093, time(ms): 797.55, token/sec:657373.63, hellaswag_acc: 0.2665
Step:  3656, loss: 3.360688, norm: 0.2821, time(ms): 793.29, token/sec:660902.62, hellaswag_acc: 0.2665
Step:  3657, loss: 3.447860, norm: 0.2731, time(ms): 804.90, token/sec:651373.31, hellaswag_acc: 0.2665
Step:  3658, loss: 3.444907, norm: 0.2660, time(ms): 802.88, token/sec:653008.35, hellaswag_acc: 0.2665
Step:  3659, loss: 3.467154, norm: 0.2613, time(ms): 793.31, token/sec:660887.12, hellaswag_acc: 0.2665
Step:  3660, loss: 3.496441, norm: 0.2693, time(ms): 800.90, token/sec:654625.32, hellaswag_acc: 0.2665
Step:  3661, loss: 3.458839, norm: 0.2625, time(ms): 801.57, token/sec:654078.95, hellaswag_acc: 0.2665
Step:  3662, loss: 3.430968, norm: 0.2534, time(ms): 803.18, token/sec:652764.89, hellaswag_acc: 0.2665
Step:  3663, loss: 3.393600, norm: 0.2509, time(ms): 793.68, token/sec:660582.58, hellaswag_acc: 0.2665
Step:  3664, loss: 3.446981, norm: 0.2464, time(ms): 797.96, token/sec:657039.53, hellaswag_acc: 0.2665
Step:  3665, loss: 3.396999, norm: 0.2600, time(ms): 805.92, token/sec:650548.17, hellaswag_acc: 0.2665
Step:  3666, loss: 3.453272, norm: 0.2585, time(ms): 801.36, token/sec:654249.81, hellaswag_acc: 0.2665
Step:  3667, loss: 3.439089, norm: 0.2496, time(ms): 792.62, token/sec:661461.24, hellaswag_acc: 0.2665
Step:  3668, loss: 3.381051, norm: 0.2688, time(ms): 803.74, token/sec:652310.82, hellaswag_acc: 0.2665
Step:  3669, loss: 3.353519, norm: 0.2450, time(ms): 803.13, token/sec:652809.26, hellaswag_acc: 0.2665
Step:  3670, loss: 3.350823, norm: 0.2484, time(ms): 800.15, token/sec:655239.36, hellaswag_acc: 0.2665
Step:  3671, loss: 3.338745, norm: 0.2698, time(ms): 786.82, token/sec:666338.38, hellaswag_acc: 0.2665
Step:  3672, loss: 3.351624, norm: 0.2689, time(ms): 790.14, token/sec:663534.78, hellaswag_acc: 0.2665
Step:  3673, loss: 3.397357, norm: 0.2727, time(ms): 795.66, token/sec:658935.49, hellaswag_acc: 0.2665
Step:  3674, loss: 3.412323, norm: 0.2605, time(ms): 794.88, token/sec:659581.99, hellaswag_acc: 0.2665
Step:  3675, loss: 3.466037, norm: 0.2507, time(ms): 792.92, token/sec:661214.41, hellaswag_acc: 0.2665
Step:  3676, loss: 3.355079, norm: 0.2696, time(ms): 789.41, token/sec:664150.61, hellaswag_acc: 0.2665
Step:  3677, loss: 3.488133, norm: 0.2793, time(ms): 802.36, token/sec:653433.49, hellaswag_acc: 0.2665
Step:  3678, loss: 3.387500, norm: 0.2666, time(ms): 801.49, token/sec:654143.55, hellaswag_acc: 0.2665
Step:  3679, loss: 3.475220, norm: 0.2834, time(ms): 797.05, token/sec:657789.13, hellaswag_acc: 0.2665
Step:  3680, loss: 3.356093, norm: 0.3464, time(ms): 799.06, token/sec:656128.71, hellaswag_acc: 0.2665
Step:  3681, loss: 3.377588, norm: 0.2932, time(ms): 802.64, token/sec:653203.68, hellaswag_acc: 0.2665
Step:  3682, loss: 3.335891, norm: 0.2688, time(ms): 802.34, token/sec:653451.55, hellaswag_acc: 0.2665
Step:  3683, loss: 3.340536, norm: 0.2729, time(ms): 796.03, token/sec:658627.03, hellaswag_acc: 0.2665
Step:  3684, loss: 3.354575, norm: 0.2519, time(ms): 799.94, token/sec:655411.61, hellaswag_acc: 0.2665
Step:  3685, loss: 3.348366, norm: 0.2555, time(ms): 803.15, token/sec:652790.47, hellaswag_acc: 0.2665
Step:  3686, loss: 3.352607, norm: 0.2702, time(ms): 799.94, token/sec:655407.70, hellaswag_acc: 0.2665
Step:  3687, loss: 3.325879, norm: 0.2801, time(ms): 798.93, token/sec:656233.66, hellaswag_acc: 0.2665
Step:  3688, loss: 3.343779, norm: 0.2903, time(ms): 800.22, token/sec:655180.99, hellaswag_acc: 0.2665
Step:  3689, loss: 3.260127, norm: 0.2953, time(ms): 803.65, token/sec:652384.35, hellaswag_acc: 0.2665
Step:  3690, loss: 3.297947, norm: 0.2848, time(ms): 798.29, token/sec:656761.27, hellaswag_acc: 0.2665
Step:  3691, loss: 3.356621, norm: 0.2551, time(ms): 791.19, token/sec:662661.19, hellaswag_acc: 0.2665
Step:  3692, loss: 3.447906, norm: 0.2668, time(ms): 791.10, token/sec:662735.08, hellaswag_acc: 0.2665
Step:  3693, loss: 3.507950, norm: 0.3104, time(ms): 796.46, token/sec:658271.35, hellaswag_acc: 0.2665
Step:  3694, loss: 3.453620, norm: 0.3264, time(ms): 799.43, token/sec:655829.32, hellaswag_acc: 0.2665
Step:  3695, loss: 3.435584, norm: 0.3072, time(ms): 798.52, token/sec:656578.51, hellaswag_acc: 0.2665
Step:  3696, loss: 3.410007, norm: 0.2935, time(ms): 796.14, token/sec:658534.52, hellaswag_acc: 0.2665
Step:  3697, loss: 3.368194, norm: 0.2625, time(ms): 797.06, token/sec:657776.93, hellaswag_acc: 0.2665
Step:  3698, loss: 3.349331, norm: 0.2959, time(ms): 790.46, token/sec:663268.80, hellaswag_acc: 0.2665
Step:  3699, loss: 3.438421, norm: 0.2697, time(ms): 788.53, token/sec:664889.99, hellaswag_acc: 0.2665
Step:  3700, loss: 3.414127, norm: 0.2717, time(ms): 792.47, token/sec:661587.21, hellaswag_acc: 0.2665
Step:  3701, loss: 3.416960, norm: 0.2694, time(ms): 798.56, token/sec:656537.93, hellaswag_acc: 0.2665
Step:  3702, loss: 3.453708, norm: 0.2811, time(ms): 791.59, token/sec:662318.50, hellaswag_acc: 0.2665
Step:  3703, loss: 3.404095, norm: 0.3069, time(ms): 806.58, token/sec:650017.04, hellaswag_acc: 0.2665
Step:  3704, loss: 3.406584, norm: 0.3031, time(ms): 799.83, token/sec:655499.52, hellaswag_acc: 0.2665
Step:  3705, loss: 3.351207, norm: 0.2821, time(ms): 795.42, token/sec:659135.57, hellaswag_acc: 0.2665
Step:  3706, loss: 3.388302, norm: 0.2611, time(ms): 804.14, token/sec:651982.42, hellaswag_acc: 0.2665
Step:  3707, loss: 3.392576, norm: 0.2722, time(ms): 801.05, token/sec:654498.09, hellaswag_acc: 0.2665
Step:  3708, loss: 3.397542, norm: 0.2639, time(ms): 797.01, token/sec:657820.22, hellaswag_acc: 0.2665
Step:  3709, loss: 3.411398, norm: 0.2591, time(ms): 796.87, token/sec:657936.54, hellaswag_acc: 0.2665
Step:  3710, loss: 3.363425, norm: 0.2703, time(ms): 805.66, token/sec:650753.97, hellaswag_acc: 0.2665
Step:  3711, loss: 3.365910, norm: 0.2558, time(ms): 800.04, token/sec:655324.30, hellaswag_acc: 0.2665
Step:  3712, loss: 3.442984, norm: 0.2607, time(ms): 799.44, token/sec:655817.39, hellaswag_acc: 0.2665
Step:  3713, loss: 3.384641, norm: 0.2674, time(ms): 795.25, token/sec:659272.52, hellaswag_acc: 0.2665
Step:  3714, loss: 3.387806, norm: 0.2561, time(ms): 803.81, token/sec:652257.03, hellaswag_acc: 0.2665
Step:  3715, loss: 3.328192, norm: 0.2464, time(ms): 801.42, token/sec:654196.48, hellaswag_acc: 0.2665
Step:  3716, loss: 3.315325, norm: 0.2323, time(ms): 792.80, token/sec:661309.66, hellaswag_acc: 0.2665
Step:  3717, loss: 3.317042, norm: 0.2471, time(ms): 802.23, token/sec:653541.47, hellaswag_acc: 0.2665
Step:  3718, loss: 3.324921, norm: 0.2680, time(ms): 804.40, token/sec:651775.07, hellaswag_acc: 0.2665
Step:  3719, loss: 3.375066, norm: 0.2830, time(ms): 794.83, token/sec:659620.37, hellaswag_acc: 0.2665
Step:  3720, loss: 3.343420, norm: 0.2881, time(ms): 795.98, token/sec:658666.88, hellaswag_acc: 0.2665
Step:  3721, loss: 3.369889, norm: 0.2812, time(ms): 806.78, token/sec:649853.19, hellaswag_acc: 0.2665
Step:  3722, loss: 3.253525, norm: 0.2829, time(ms): 800.88, token/sec:654642.08, hellaswag_acc: 0.2665
Step:  3723, loss: 3.293901, norm: 0.2795, time(ms): 790.83, token/sec:662958.86, hellaswag_acc: 0.2665
Step:  3724, loss: 3.315353, norm: 0.2970, time(ms): 800.42, token/sec:655019.20, hellaswag_acc: 0.2665
Step:  3725, loss: 3.368621, norm: 0.2638, time(ms): 808.65, token/sec:648347.79, hellaswag_acc: 0.2665
Step:  3726, loss: 3.329417, norm: 0.2557, time(ms): 795.38, token/sec:659164.22, hellaswag_acc: 0.2665
Step:  3727, loss: 3.430846, norm: 0.2507, time(ms): 800.01, token/sec:655352.03, hellaswag_acc: 0.2665
Step:  3728, loss: 3.395242, norm: 0.2872, time(ms): 804.44, token/sec:651741.26, hellaswag_acc: 0.2665
Step:  3729, loss: 3.347951, norm: 0.2955, time(ms): 799.57, token/sec:655708.47, hellaswag_acc: 0.2665
Step:  3730, loss: 3.447906, norm: 0.3122, time(ms): 794.26, token/sec:660094.39, hellaswag_acc: 0.2665
Step:  3731, loss: 3.368063, norm: 0.2703, time(ms): 798.14, token/sec:656884.48, hellaswag_acc: 0.2665
Step:  3732, loss: 3.491200, norm: 0.2714, time(ms): 805.11, token/sec:651199.32, hellaswag_acc: 0.2665
Step:  3733, loss: 3.441533, norm: 0.2955, time(ms): 803.17, token/sec:652771.48, hellaswag_acc: 0.2665
Step:  3734, loss: 3.435827, norm: 0.2802, time(ms): 793.51, token/sec:660721.32, hellaswag_acc: 0.2665
Step:  3735, loss: 3.405841, norm: 0.2749, time(ms): 800.35, token/sec:655069.93, hellaswag_acc: 0.2665
Step:  3736, loss: 3.452902, norm: 0.2739, time(ms): 804.36, token/sec:651805.21, hellaswag_acc: 0.2665
Step:  3737, loss: 3.443268, norm: 0.2784, time(ms): 801.31, token/sec:654292.06, hellaswag_acc: 0.2665
Step:  3738, loss: 3.461120, norm: 0.2960, time(ms): 792.10, token/sec:661895.47, hellaswag_acc: 0.2665
Step:  3739, loss: 3.410144, norm: 0.2896, time(ms): 800.59, token/sec:654876.02, hellaswag_acc: 0.2665
Step:  3740, loss: 3.393046, norm: 0.3308, time(ms): 805.58, token/sec:650822.53, hellaswag_acc: 0.2665
Step:  3741, loss: 3.357774, norm: 0.3192, time(ms): 800.26, token/sec:655145.07, hellaswag_acc: 0.2665
Step:  3742, loss: 3.373382, norm: 0.2472, time(ms): 789.60, token/sec:663994.39, hellaswag_acc: 0.2665
Step:  3743, loss: 3.412889, norm: 0.3060, time(ms): 800.55, token/sec:654908.01, hellaswag_acc: 0.2665
Step:  3744, loss: 3.380975, norm: 0.2733, time(ms): 808.17, token/sec:648731.10, hellaswag_acc: 0.2665
Step:  3745, loss: 3.388449, norm: 0.2601, time(ms): 799.57, token/sec:655710.42, hellaswag_acc: 0.2665
Step:  3746, loss: 3.388335, norm: 0.2687, time(ms): 791.26, token/sec:662597.89, hellaswag_acc: 0.2665
Step:  3747, loss: 3.396789, norm: 0.2590, time(ms): 806.78, token/sec:649850.69, hellaswag_acc: 0.2665
Step:  3748, loss: 3.423877, norm: 0.2447, time(ms): 802.96, token/sec:652945.92, hellaswag_acc: 0.2665
Step:  3749, loss: 3.368320, norm: 0.2608, time(ms): 789.86, token/sec:663774.12, hellaswag_acc: 0.2665
rank 0 sample 0: Hello, I'm a language model, and I like to use it, too. Now, I've come up with a language model to make some interesting comparisons
rank 0 sample 1: Hello, I'm a language model, so now I'm gonna teach the Spanish. So he does that by that name, but you're doing a lot of
rank 0 sample 2: Hello, I'm a language model, but I had the fun stuff while on the bus.
Now we are going to take a look at the basics.
rank 0 sample 3: Hello, I'm a language model, so i'm interested in the topic, and hence i'm interested in the language?
Here is a short explanation :
rank 1 sample 0: Hello, I'm a language model, with my "pantel" side, it was "one of the key words." The second part of the sentence
rank 1 sample 1: Hello, I'm a language model, which I think may be a better solution, but I hope this gives you a valuable, comprehensive language that you can use
rank 1 sample 2: Hello, I'm a language model, so be a first.
I'm a language model, it was my first language model. My first language model is
rank 1 sample 3: Hello, I'm a language model, and I'm in a team of engineers out there. Sometimes when I've spent a ton of time at the gym,
Step:  3750, loss: 3.338365, norm: 0.2774, time(ms): 3816.86, token/sec:137361.04, val_loss: 3.4345, hellaswag_acc: 0.2665
Step:  3751, loss: 3.330579, norm: 0.2582, time(ms): 786.14, token/sec:666917.76, hellaswag_acc: 0.2665
Step:  3752, loss: 3.294729, norm: 0.2972, time(ms): 798.82, token/sec:656329.24, hellaswag_acc: 0.2665
Step:  3753, loss: 3.301076, norm: 0.2784, time(ms): 803.75, token/sec:652299.59, hellaswag_acc: 0.2665
Step:  3754, loss: 3.371593, norm: 0.2848, time(ms): 794.28, token/sec:660081.71, hellaswag_acc: 0.2665
Step:  3755, loss: 3.339462, norm: 0.2731, time(ms): 793.31, token/sec:660888.12, hellaswag_acc: 0.2665
Step:  3756, loss: 3.360114, norm: 0.2468, time(ms): 786.22, token/sec:666846.77, hellaswag_acc: 0.2665
Step:  3757, loss: 3.331323, norm: 0.2469, time(ms): 791.52, token/sec:662383.14, hellaswag_acc: 0.2665
Step:  3758, loss: 3.348519, norm: 0.2775, time(ms): 791.33, token/sec:662541.99, hellaswag_acc: 0.2665
Step:  3759, loss: 3.295084, norm: 0.2833, time(ms): 795.12, token/sec:659380.25, hellaswag_acc: 0.2665
Step:  3760, loss: 3.357938, norm: 0.2785, time(ms): 791.39, token/sec:662492.09, hellaswag_acc: 0.2665
Step:  3761, loss: 3.378798, norm: 0.2931, time(ms): 795.07, token/sec:659420.00, hellaswag_acc: 0.2665
Step:  3762, loss: 3.463222, norm: 0.3151, time(ms): 789.45, token/sec:664116.51, hellaswag_acc: 0.2665
Step:  3763, loss: 3.428035, norm: 0.2516, time(ms): 787.49, token/sec:665772.09, hellaswag_acc: 0.2665
Step:  3764, loss: 3.452774, norm: 0.2836, time(ms): 789.69, token/sec:663916.41, hellaswag_acc: 0.2665
Step:  3765, loss: 3.492892, norm: 0.3229, time(ms): 795.34, token/sec:659198.80, hellaswag_acc: 0.2665
Step:  3766, loss: 3.419137, norm: 0.3021, time(ms): 797.26, token/sec:657609.53, hellaswag_acc: 0.2665
Step:  3767, loss: 3.434289, norm: 0.2866, time(ms): 801.30, token/sec:654294.39, hellaswag_acc: 0.2665
Step:  3768, loss: 3.466125, norm: 0.2756, time(ms): 801.68, token/sec:653986.75, hellaswag_acc: 0.2665
Step:  3769, loss: 3.493931, norm: 0.3192, time(ms): 796.41, token/sec:658315.50, hellaswag_acc: 0.2665
Step:  3770, loss: 3.488545, norm: 0.3828, time(ms): 801.31, token/sec:654285.63, hellaswag_acc: 0.2665
Step:  3771, loss: 3.429980, norm: 0.3628, time(ms): 799.72, token/sec:655592.15, hellaswag_acc: 0.2665
Step:  3772, loss: 3.520408, norm: 0.3422, time(ms): 803.37, token/sec:652613.20, hellaswag_acc: 0.2665
Step:  3773, loss: 3.410454, norm: 0.3538, time(ms): 789.75, token/sec:663869.50, hellaswag_acc: 0.2665
Step:  3774, loss: 3.374485, norm: 0.3269, time(ms): 805.88, token/sec:650578.39, hellaswag_acc: 0.2665
Step:  3775, loss: 3.395558, norm: 0.2853, time(ms): 802.67, token/sec:653176.32, hellaswag_acc: 0.2665
Step:  3776, loss: 3.421792, norm: 0.3071, time(ms): 797.78, token/sec:657185.03, hellaswag_acc: 0.2665
Step:  3777, loss: 3.370967, norm: 0.2797, time(ms): 800.75, token/sec:654745.38, hellaswag_acc: 0.2665
Step:  3778, loss: 3.409525, norm: 0.2880, time(ms): 796.84, token/sec:657962.52, hellaswag_acc: 0.2665
Step:  3779, loss: 3.426737, norm: 0.2762, time(ms): 800.80, token/sec:654702.89, hellaswag_acc: 0.2665
Step:  3780, loss: 3.399437, norm: 0.2613, time(ms): 803.17, token/sec:652777.29, hellaswag_acc: 0.2665
Step:  3781, loss: 3.412213, norm: 0.2848, time(ms): 791.34, token/sec:662532.41, hellaswag_acc: 0.2665
Step:  3782, loss: 3.425662, norm: 0.2909, time(ms): 807.08, token/sec:649611.69, hellaswag_acc: 0.2665
Step:  3783, loss: 3.409644, norm: 0.2739, time(ms): 801.65, token/sec:654010.09, hellaswag_acc: 0.2665
Step:  3784, loss: 3.378118, norm: 0.2741, time(ms): 794.09, token/sec:660238.47, hellaswag_acc: 0.2665
Step:  3785, loss: 3.318764, norm: 0.2756, time(ms): 796.67, token/sec:658097.01, hellaswag_acc: 0.2665
Step:  3786, loss: 3.337374, norm: 0.3093, time(ms): 806.66, token/sec:649949.99, hellaswag_acc: 0.2665
Step:  3787, loss: 3.345638, norm: 0.3222, time(ms): 801.87, token/sec:653828.08, hellaswag_acc: 0.2665
Step:  3788, loss: 3.337521, norm: 0.2866, time(ms): 792.98, token/sec:661157.56, hellaswag_acc: 0.2665
Step:  3789, loss: 3.292149, norm: 0.2498, time(ms): 800.02, token/sec:655342.46, hellaswag_acc: 0.2665
Step:  3790, loss: 3.367348, norm: 0.2556, time(ms): 805.94, token/sec:650531.23, hellaswag_acc: 0.2665
Step:  3791, loss: 3.334219, norm: 0.2902, time(ms): 796.55, token/sec:658196.28, hellaswag_acc: 0.2665
Step:  3792, loss: 3.379207, norm: 0.2885, time(ms): 797.31, token/sec:657574.92, hellaswag_acc: 0.2665
Step:  3793, loss: 3.362508, norm: 0.2635, time(ms): 803.78, token/sec:652280.44, hellaswag_acc: 0.2665
Step:  3794, loss: 3.339000, norm: 0.2675, time(ms): 802.08, token/sec:653660.94, hellaswag_acc: 0.2665
Step:  3795, loss: 3.387652, norm: 0.2636, time(ms): 793.65, token/sec:660604.01, hellaswag_acc: 0.2665
Step:  3796, loss: 3.375774, norm: 0.2428, time(ms): 798.83, token/sec:656316.90, hellaswag_acc: 0.2665
Step:  3797, loss: 3.336300, norm: 0.2573, time(ms): 804.05, token/sec:652060.14, hellaswag_acc: 0.2665
Step:  3798, loss: 3.458361, norm: 0.2746, time(ms): 802.57, token/sec:653265.19, hellaswag_acc: 0.2665
Step:  3799, loss: 3.472704, norm: 0.2805, time(ms): 793.91, token/sec:660389.36, hellaswag_acc: 0.2665
Step:  3800, loss: 3.480999, norm: 0.2939, time(ms): 801.50, token/sec:654134.21, hellaswag_acc: 0.2665
Step:  3801, loss: 3.475185, norm: 0.2801, time(ms): 801.45, token/sec:654171.38, hellaswag_acc: 0.2665
Step:  3802, loss: 3.450037, norm: 0.2773, time(ms): 803.15, token/sec:652792.21, hellaswag_acc: 0.2665
Step:  3803, loss: 3.434804, norm: 0.3014, time(ms): 789.05, token/sec:664451.43, hellaswag_acc: 0.2665
Step:  3804, loss: 3.423520, norm: 0.2828, time(ms): 792.55, token/sec:661524.52, hellaswag_acc: 0.2665
Step:  3805, loss: 3.448774, norm: 0.2815, time(ms): 793.07, token/sec:661082.62, hellaswag_acc: 0.2665
Step:  3806, loss: 3.455917, norm: 0.2595, time(ms): 789.80, token/sec:663826.62, hellaswag_acc: 0.2665
Step:  3807, loss: 3.435061, norm: 0.2513, time(ms): 792.96, token/sec:661179.42, hellaswag_acc: 0.2665
Step:  3808, loss: 3.407632, norm: 0.2644, time(ms): 794.51, token/sec:659891.35, hellaswag_acc: 0.2665
Step:  3809, loss: 3.412471, norm: 0.2581, time(ms): 1287.07, token/sec:407351.00, hellaswag_acc: 0.2665
Step:  3810, loss: 3.416160, norm: 0.2587, time(ms): 767.67, token/sec:682959.56, hellaswag_acc: 0.2665
Step:  3811, loss: 3.412521, norm: 0.2639, time(ms): 790.66, token/sec:663102.99, hellaswag_acc: 0.2665
Step:  3812, loss: 3.449024, norm: 0.2737, time(ms): 799.35, token/sec:655895.05, hellaswag_acc: 0.2665
Step:  3813, loss: 3.413388, norm: 0.2967, time(ms): 785.66, token/sec:667324.55, hellaswag_acc: 0.2665
Step:  3814, loss: 3.461401, norm: 0.2594, time(ms): 780.98, token/sec:671318.91, hellaswag_acc: 0.2665
Step:  3815, loss: 3.394852, norm: 0.2674, time(ms): 783.71, token/sec:668983.37, hellaswag_acc: 0.2665
Step:  3816, loss: 3.452747, norm: 0.3112, time(ms): 791.39, token/sec:662487.50, hellaswag_acc: 0.2665
Step:  3817, loss: 3.410650, norm: 0.3237, time(ms): 795.75, token/sec:658862.25, hellaswag_acc: 0.2665
Step:  3818, loss: 3.364658, norm: 0.2835, time(ms): 787.06, token/sec:666137.74, hellaswag_acc: 0.2665
Step:  3819, loss: 3.391426, norm: 0.3116, time(ms): 784.84, token/sec:668017.24, hellaswag_acc: 0.2665
Step:  3820, loss: 3.386549, norm: 0.2689, time(ms): 791.42, token/sec:662467.94, hellaswag_acc: 0.2665
Step:  3821, loss: 3.406931, norm: 0.2692, time(ms): 799.80, token/sec:655525.90, hellaswag_acc: 0.2665
Step:  3822, loss: 3.399122, norm: 0.2766, time(ms): 789.14, token/sec:664378.76, hellaswag_acc: 0.2665
Step:  3823, loss: 3.363085, norm: 0.2873, time(ms): 793.75, token/sec:660522.26, hellaswag_acc: 0.2665
Step:  3824, loss: 3.362873, norm: 0.2637, time(ms): 790.05, token/sec:663609.87, hellaswag_acc: 0.2665
Step:  3825, loss: 3.370828, norm: 0.2641, time(ms): 794.57, token/sec:659838.28, hellaswag_acc: 0.2665
Step:  3826, loss: 3.462518, norm: 0.2877, time(ms): 786.94, token/sec:666232.19, hellaswag_acc: 0.2665
Step:  3827, loss: 3.399383, norm: 0.2935, time(ms): 793.28, token/sec:660908.38, hellaswag_acc: 0.2665
Step:  3828, loss: 3.391670, norm: 0.2801, time(ms): 791.59, token/sec:662319.89, hellaswag_acc: 0.2665
Step:  3829, loss: 3.342910, norm: 0.2655, time(ms): 790.70, token/sec:663066.80, hellaswag_acc: 0.2665
Step:  3830, loss: 3.235185, norm: 0.2944, time(ms): 791.12, token/sec:662717.30, hellaswag_acc: 0.2665
Step:  3831, loss: 3.199790, norm: 0.3574, time(ms): 789.38, token/sec:664177.89, hellaswag_acc: 0.2665
Step:  3832, loss: 3.298326, norm: 0.3054, time(ms): 793.66, token/sec:660596.67, hellaswag_acc: 0.2665
Step:  3833, loss: 3.225745, norm: 0.2740, time(ms): 788.47, token/sec:664947.70, hellaswag_acc: 0.2665
Step:  3834, loss: 3.277108, norm: 0.2805, time(ms): 802.07, token/sec:653667.55, hellaswag_acc: 0.2665
Step:  3835, loss: 3.279070, norm: 0.3156, time(ms): 800.69, token/sec:654792.95, hellaswag_acc: 0.2665
Step:  3836, loss: 3.257200, norm: 0.3286, time(ms): 800.27, token/sec:655141.75, hellaswag_acc: 0.2665
Step:  3837, loss: 3.360886, norm: 0.3838, time(ms): 793.48, token/sec:660749.11, hellaswag_acc: 0.2665
Step:  3838, loss: 3.151037, norm: 0.3463, time(ms): 801.60, token/sec:654050.55, hellaswag_acc: 0.2665
Step:  3839, loss: 3.230471, norm: 0.3038, time(ms): 803.82, token/sec:652242.90, hellaswag_acc: 0.2665
Step:  3840, loss: 3.281282, norm: 0.2892, time(ms): 799.93, token/sec:655419.61, hellaswag_acc: 0.2665
Step:  3841, loss: 3.277765, norm: 0.2835, time(ms): 794.51, token/sec:659888.58, hellaswag_acc: 0.2665
Step:  3842, loss: 3.452555, norm: 0.2695, time(ms): 804.09, token/sec:652024.76, hellaswag_acc: 0.2665
Step:  3843, loss: 3.417890, norm: 0.2778, time(ms): 800.15, token/sec:655235.06, hellaswag_acc: 0.2665
Step:  3844, loss: 3.470309, norm: 0.2856, time(ms): 798.96, token/sec:656212.32, hellaswag_acc: 0.2665
Step:  3845, loss: 3.425169, norm: 0.2869, time(ms): 798.66, token/sec:656455.62, hellaswag_acc: 0.2665
Step:  3846, loss: 3.400668, norm: 0.2759, time(ms): 801.75, token/sec:653929.57, hellaswag_acc: 0.2665
Step:  3847, loss: 3.427060, norm: 0.2671, time(ms): 802.12, token/sec:653624.02, hellaswag_acc: 0.2665
Step:  3848, loss: 3.397983, norm: 0.2551, time(ms): 789.73, token/sec:663881.73, hellaswag_acc: 0.2665
Step:  3849, loss: 3.382108, norm: 0.2685, time(ms): 802.85, token/sec:653033.95, hellaswag_acc: 0.2665
Step:  3850, loss: 3.484872, norm: 0.2482, time(ms): 805.74, token/sec:650693.70, hellaswag_acc: 0.2665
Step:  3851, loss: 3.458576, norm: 0.2819, time(ms): 799.60, token/sec:655684.81, hellaswag_acc: 0.2665
Step:  3852, loss: 3.408766, norm: 0.2713, time(ms): 791.57, token/sec:662335.65, hellaswag_acc: 0.2665
Step:  3853, loss: 3.398218, norm: 0.2758, time(ms): 794.04, token/sec:660281.29, hellaswag_acc: 0.2665
Step:  3854, loss: 3.397020, norm: 0.2619, time(ms): 789.98, token/sec:663674.96, hellaswag_acc: 0.2665
Step:  3855, loss: 3.442275, norm: 0.2981, time(ms): 793.02, token/sec:661125.95, hellaswag_acc: 0.2665
Step:  3856, loss: 3.455163, norm: 0.2987, time(ms): 788.44, token/sec:664966.60, hellaswag_acc: 0.2665
Step:  3857, loss: 3.353326, norm: 0.2684, time(ms): 797.92, token/sec:657071.92, hellaswag_acc: 0.2665
Step:  3858, loss: 3.470092, norm: 0.2586, time(ms): 802.26, token/sec:653516.22, hellaswag_acc: 0.2665
Step:  3859, loss: 3.550463, norm: 0.3291, time(ms): 801.40, token/sec:654213.81, hellaswag_acc: 0.2665
Step:  3860, loss: 3.416032, norm: 0.2826, time(ms): 793.54, token/sec:660695.31, hellaswag_acc: 0.2665
Step:  3861, loss: 3.405465, norm: 0.3127, time(ms): 798.10, token/sec:656917.64, hellaswag_acc: 0.2665
Step:  3862, loss: 3.440821, norm: 0.3166, time(ms): 792.44, token/sec:661612.88, hellaswag_acc: 0.2665
Step:  3863, loss: 3.444178, norm: 0.3214, time(ms): 787.89, token/sec:665434.84, hellaswag_acc: 0.2665
Step:  3864, loss: 3.426096, norm: 0.2762, time(ms): 793.00, token/sec:661141.46, hellaswag_acc: 0.2665
Step:  3865, loss: 3.384040, norm: 0.2877, time(ms): 792.63, token/sec:661450.30, hellaswag_acc: 0.2665
Step:  3866, loss: 3.370112, norm: 0.3018, time(ms): 792.78, token/sec:661324.38, hellaswag_acc: 0.2665
Step:  3867, loss: 3.392078, norm: 0.2690, time(ms): 790.07, token/sec:663598.45, hellaswag_acc: 0.2665
Step:  3868, loss: 3.345910, norm: 0.2490, time(ms): 793.90, token/sec:660397.88, hellaswag_acc: 0.2665
Step:  3869, loss: 3.329922, norm: 0.2733, time(ms): 799.78, token/sec:655543.49, hellaswag_acc: 0.2665
Step:  3870, loss: 3.357491, norm: 0.2496, time(ms): 804.93, token/sec:651342.82, hellaswag_acc: 0.2665
Step:  3871, loss: 3.373426, norm: 0.2502, time(ms): 800.75, token/sec:654747.92, hellaswag_acc: 0.2665
Step:  3872, loss: 3.417614, norm: 0.2426, time(ms): 799.62, token/sec:655671.52, hellaswag_acc: 0.2665
Step:  3873, loss: 3.370568, norm: 0.2433, time(ms): 790.24, token/sec:663451.70, hellaswag_acc: 0.2665
Step:  3874, loss: 3.334348, norm: 0.2263, time(ms): 801.08, token/sec:654474.71, hellaswag_acc: 0.2665
Step:  3875, loss: 3.371934, norm: 0.2487, time(ms): 796.73, token/sec:658050.73, hellaswag_acc: 0.2665
Step:  3876, loss: 3.194190, norm: 0.2566, time(ms): 790.82, token/sec:662969.25, hellaswag_acc: 0.2665
Step:  3877, loss: 3.189613, norm: 0.3094, time(ms): 787.75, token/sec:665555.28, hellaswag_acc: 0.2665
Step:  3878, loss: 3.243481, norm: 0.3098, time(ms): 790.43, token/sec:663294.40, hellaswag_acc: 0.2665
Step:  3879, loss: 3.202619, norm: 0.2760, time(ms): 796.92, token/sec:657891.07, hellaswag_acc: 0.2665
Step:  3880, loss: 3.256010, norm: 0.2841, time(ms): 798.49, token/sec:656599.10, hellaswag_acc: 0.2665
Step:  3881, loss: 3.227493, norm: 0.2647, time(ms): 798.25, token/sec:656797.56, hellaswag_acc: 0.2665
Step:  3882, loss: 3.247222, norm: 0.2859, time(ms): 798.36, token/sec:656704.39, hellaswag_acc: 0.2665
Step:  3883, loss: 3.212527, norm: 0.2932, time(ms): 793.31, token/sec:660883.15, hellaswag_acc: 0.2665
Step:  3884, loss: 3.279673, norm: 0.2928, time(ms): 793.48, token/sec:660744.35, hellaswag_acc: 0.2665
Step:  3885, loss: 3.249519, norm: 0.3008, time(ms): 794.40, token/sec:659981.66, hellaswag_acc: 0.2665
Step:  3886, loss: 3.187418, norm: 0.2930, time(ms): 796.83, token/sec:657963.31, hellaswag_acc: 0.2665
Step:  3887, loss: 3.234039, norm: 0.2843, time(ms): 790.74, token/sec:663034.21, hellaswag_acc: 0.2665
Step:  3888, loss: 3.471939, norm: 0.2985, time(ms): 789.49, token/sec:664081.21, hellaswag_acc: 0.2665
Step:  3889, loss: 3.440472, norm: 0.2893, time(ms): 791.66, token/sec:662264.24, hellaswag_acc: 0.2665
Step:  3890, loss: 3.478720, norm: 0.2966, time(ms): 789.20, token/sec:664332.59, hellaswag_acc: 0.2665
Step:  3891, loss: 3.474742, norm: 0.2923, time(ms): 806.45, token/sec:650117.93, hellaswag_acc: 0.2665
Step:  3892, loss: 3.479527, norm: 0.3281, time(ms): 800.96, token/sec:654574.46, hellaswag_acc: 0.2665
Step:  3893, loss: 3.509573, norm: 0.3201, time(ms): 791.06, token/sec:662767.04, hellaswag_acc: 0.2665
Step:  3894, loss: 3.379551, norm: 0.2873, time(ms): 796.92, token/sec:657889.88, hellaswag_acc: 0.2665
Step:  3895, loss: 3.416595, norm: 0.3045, time(ms): 790.46, token/sec:663268.20, hellaswag_acc: 0.2665
Step:  3896, loss: 3.415756, norm: 0.2614, time(ms): 795.05, token/sec:659442.74, hellaswag_acc: 0.2665
Step:  3897, loss: 3.476265, norm: 0.2687, time(ms): 791.03, token/sec:662792.81, hellaswag_acc: 0.2665
Step:  3898, loss: 3.454461, norm: 0.2732, time(ms): 790.34, token/sec:663367.04, hellaswag_acc: 0.2665
Step:  3899, loss: 3.479804, norm: 0.2977, time(ms): 797.86, token/sec:657121.01, hellaswag_acc: 0.2665
Step:  3900, loss: 3.404781, norm: 0.2715, time(ms): 805.49, token/sec:650890.73, hellaswag_acc: 0.2665
Step:  3901, loss: 3.431431, norm: 0.2794, time(ms): 798.71, token/sec:656422.11, hellaswag_acc: 0.2665
Step:  3902, loss: 3.427095, norm: 0.3144, time(ms): 790.77, token/sec:663011.23, hellaswag_acc: 0.2665
Step:  3903, loss: 3.419271, norm: 0.2826, time(ms): 791.13, token/sec:662707.52, hellaswag_acc: 0.2665
Step:  3904, loss: 3.436914, norm: 0.2647, time(ms): 798.93, token/sec:656235.62, hellaswag_acc: 0.2665
Step:  3905, loss: 3.403250, norm: 0.2889, time(ms): 788.45, token/sec:664956.74, hellaswag_acc: 0.2665
Step:  3906, loss: 3.437408, norm: 0.2796, time(ms): 791.69, token/sec:662238.91, hellaswag_acc: 0.2665
Step:  3907, loss: 3.447288, norm: 0.2889, time(ms): 789.53, token/sec:664052.34, hellaswag_acc: 0.2665
Step:  3908, loss: 3.464692, norm: 0.2773, time(ms): 790.84, token/sec:662948.66, hellaswag_acc: 0.2665
Step:  3909, loss: 3.362325, norm: 0.2760, time(ms): 800.40, token/sec:655029.74, hellaswag_acc: 0.2665
Step:  3910, loss: 3.431337, norm: 0.2629, time(ms): 795.71, token/sec:658896.01, hellaswag_acc: 0.2665
Step:  3911, loss: 3.363890, norm: 0.3208, time(ms): 801.75, token/sec:653931.32, hellaswag_acc: 0.2665
Step:  3912, loss: 3.397879, norm: 0.3227, time(ms): 801.22, token/sec:654362.73, hellaswag_acc: 0.2665
Step:  3913, loss: 3.390741, norm: 0.2834, time(ms): 799.38, token/sec:655870.01, hellaswag_acc: 0.2665
Step:  3914, loss: 3.350078, norm: 0.2927, time(ms): 794.70, token/sec:659733.17, hellaswag_acc: 0.2665
Step:  3915, loss: 3.347109, norm: 0.2727, time(ms): 798.26, token/sec:656787.95, hellaswag_acc: 0.2665
Step:  3916, loss: 3.350293, norm: 0.2541, time(ms): 806.35, token/sec:650198.86, hellaswag_acc: 0.2665
Step:  3917, loss: 3.349448, norm: 0.2681, time(ms): 801.21, token/sec:654371.10, hellaswag_acc: 0.2665
Step:  3918, loss: 3.361620, norm: 0.2686, time(ms): 791.89, token/sec:662074.02, hellaswag_acc: 0.2665
Step:  3919, loss: 3.361878, norm: 0.3122, time(ms): 805.65, token/sec:650763.98, hellaswag_acc: 0.2665
Step:  3920, loss: 3.344540, norm: 0.2857, time(ms): 801.87, token/sec:653834.11, hellaswag_acc: 0.2665
Step:  3921, loss: 3.393231, norm: 0.3043, time(ms): 793.24, token/sec:660946.32, hellaswag_acc: 0.2665
Step:  3922, loss: 3.362813, norm: 0.2677, time(ms): 801.78, token/sec:653900.99, hellaswag_acc: 0.2665
Step:  3923, loss: 3.235445, norm: 0.2903, time(ms): 803.55, token/sec:652461.59, hellaswag_acc: 0.2665
Step:  3924, loss: 3.244226, norm: 0.2963, time(ms): 791.15, token/sec:662691.94, hellaswag_acc: 0.2665
Step:  3925, loss: 3.233187, norm: 0.2710, time(ms): 792.15, token/sec:661854.43, hellaswag_acc: 0.2665
Step:  3926, loss: 3.415792, norm: 0.2626, time(ms): 790.34, token/sec:663370.04, hellaswag_acc: 0.2665
Step:  3927, loss: 3.208652, norm: 0.2789, time(ms): 792.40, token/sec:661647.72, hellaswag_acc: 0.2665
Step:  3928, loss: 3.163270, norm: 0.2854, time(ms): 793.32, token/sec:660874.81, hellaswag_acc: 0.2665
Step:  3929, loss: 3.188766, norm: 0.3005, time(ms): 792.60, token/sec:661481.93, hellaswag_acc: 0.2665
Step:  3930, loss: 3.205870, norm: 0.2712, time(ms): 803.62, token/sec:652405.26, hellaswag_acc: 0.2665
Step:  3931, loss: 3.217042, norm: 0.2895, time(ms): 800.84, token/sec:654671.70, hellaswag_acc: 0.2665
Step:  3932, loss: 3.187550, norm: 0.2998, time(ms): 801.29, token/sec:654304.32, hellaswag_acc: 0.2665
Step:  3933, loss: 3.231319, norm: 0.2898, time(ms): 796.15, token/sec:658527.03, hellaswag_acc: 0.2665
Step:  3934, loss: 3.243702, norm: 0.2715, time(ms): 796.50, token/sec:658238.64, hellaswag_acc: 0.2665
Step:  3935, loss: 3.439312, norm: 0.2553, time(ms): 792.47, token/sec:661590.59, hellaswag_acc: 0.2665
Step:  3936, loss: 3.388089, norm: 0.2466, time(ms): 795.70, token/sec:658897.78, hellaswag_acc: 0.2665
Step:  3937, loss: 3.389083, norm: 0.2616, time(ms): 793.37, token/sec:660833.30, hellaswag_acc: 0.2665
Step:  3938, loss: 3.549419, norm: 0.2818, time(ms): 802.75, token/sec:653113.47, hellaswag_acc: 0.2665
Step:  3939, loss: 3.441219, norm: 0.2780, time(ms): 801.35, token/sec:654253.90, hellaswag_acc: 0.2665
Step:  3940, loss: 3.517493, norm: 0.3062, time(ms): 791.06, token/sec:662767.84, hellaswag_acc: 0.2665
Step:  3941, loss: 3.452024, norm: 0.2838, time(ms): 789.11, token/sec:664407.26, hellaswag_acc: 0.2665
Step:  3942, loss: 3.392828, norm: 0.2669, time(ms): 794.75, token/sec:659688.64, hellaswag_acc: 0.2665
Step:  3943, loss: 3.463975, norm: 0.3291, time(ms): 796.11, token/sec:658559.96, hellaswag_acc: 0.2665
Step:  3944, loss: 3.437993, norm: 0.3679, time(ms): 792.20, token/sec:661812.80, hellaswag_acc: 0.2665
Step:  3945, loss: 3.382689, norm: 0.3017, time(ms): 787.99, token/sec:665350.28, hellaswag_acc: 0.2665
Step:  3946, loss: 3.471293, norm: 0.3031, time(ms): 799.84, token/sec:655492.88, hellaswag_acc: 0.2665
Step:  3947, loss: 3.470378, norm: 0.2877, time(ms): 793.10, token/sec:661057.58, hellaswag_acc: 0.2665
Step:  3948, loss: 3.487288, norm: 0.2781, time(ms): 788.19, token/sec:665183.63, hellaswag_acc: 0.2665
Step:  3949, loss: 3.471592, norm: 0.2669, time(ms): 793.26, token/sec:660928.64, hellaswag_acc: 0.2665
Step:  3950, loss: 3.374941, norm: 0.2493, time(ms): 790.35, token/sec:663364.84, hellaswag_acc: 0.2665
Step:  3951, loss: 3.395189, norm: 0.2681, time(ms): 800.28, token/sec:655133.36, hellaswag_acc: 0.2665
Step:  3952, loss: 3.455006, norm: 0.2740, time(ms): 799.18, token/sec:656030.06, hellaswag_acc: 0.2665
Step:  3953, loss: 3.444969, norm: 0.2876, time(ms): 804.55, token/sec:651655.32, hellaswag_acc: 0.2665
Step:  3954, loss: 3.508290, norm: 0.3028, time(ms): 794.26, token/sec:660099.74, hellaswag_acc: 0.2665
Step:  3955, loss: 3.438082, norm: 0.3188, time(ms): 800.79, token/sec:654710.88, hellaswag_acc: 0.2665
Step:  3956, loss: 3.455700, norm: 0.2755, time(ms): 801.16, token/sec:654413.56, hellaswag_acc: 0.2665
Step:  3957, loss: 3.443846, norm: 0.2898, time(ms): 803.58, token/sec:652437.00, hellaswag_acc: 0.2665
Step:  3958, loss: 3.410056, norm: 0.2702, time(ms): 794.85, token/sec:659606.52, hellaswag_acc: 0.2665
Step:  3959, loss: 3.355788, norm: 0.2564, time(ms): 797.21, token/sec:657653.19, hellaswag_acc: 0.2665
Step:  3960, loss: 3.399642, norm: 0.2708, time(ms): 802.83, token/sec:653048.49, hellaswag_acc: 0.2665
Step:  3961, loss: 3.377590, norm: 0.2440, time(ms): 798.58, token/sec:656523.82, hellaswag_acc: 0.2665
Step:  3962, loss: 3.345618, norm: 0.2851, time(ms): 798.50, token/sec:656588.12, hellaswag_acc: 0.2665
Step:  3963, loss: 3.401128, norm: 0.2666, time(ms): 800.46, token/sec:654984.67, hellaswag_acc: 0.2665
Step:  3964, loss: 3.391628, norm: 0.2825, time(ms): 804.58, token/sec:651626.74, hellaswag_acc: 0.2665
Step:  3965, loss: 3.361410, norm: 0.3068, time(ms): 797.63, token/sec:657304.27, hellaswag_acc: 0.2665
Step:  3966, loss: 3.373153, norm: 0.2660, time(ms): 799.76, token/sec:655556.39, hellaswag_acc: 0.2665
Step:  3967, loss: 3.430651, norm: 0.3035, time(ms): 801.09, token/sec:654467.51, hellaswag_acc: 0.2665
Step:  3968, loss: 3.401023, norm: 0.2779, time(ms): 800.99, token/sec:654546.99, hellaswag_acc: 0.2665
Step:  3969, loss: 3.411918, norm: 0.2745, time(ms): 793.85, token/sec:660436.16, hellaswag_acc: 0.2665
Step:  3970, loss: 3.333860, norm: 0.2918, time(ms): 801.04, token/sec:654512.11, hellaswag_acc: 0.2665
Step:  3971, loss: 3.261974, norm: 0.3013, time(ms): 805.39, token/sec:650977.43, hellaswag_acc: 0.2665
Step:  3972, loss: 3.172978, norm: 0.3618, time(ms): 799.66, token/sec:655640.82, hellaswag_acc: 0.2665
Step:  3973, loss: 3.302112, norm: 0.4367, time(ms): 796.08, token/sec:658587.18, hellaswag_acc: 0.2665
Step:  3974, loss: 3.244008, norm: 0.3973, time(ms): 801.11, token/sec:654449.39, hellaswag_acc: 0.2665
Step:  3975, loss: 3.225749, norm: 0.3303, time(ms): 802.11, token/sec:653639.37, hellaswag_acc: 0.2665
Step:  3976, loss: 3.254617, norm: 0.3243, time(ms): 797.53, token/sec:657389.35, hellaswag_acc: 0.2665
Step:  3977, loss: 3.193466, norm: 0.2918, time(ms): 797.64, token/sec:657296.41, hellaswag_acc: 0.2665
Step:  3978, loss: 3.203773, norm: 0.2732, time(ms): 802.66, token/sec:653189.32, hellaswag_acc: 0.2665
Step:  3979, loss: 3.195471, norm: 0.2925, time(ms): 802.12, token/sec:653631.21, hellaswag_acc: 0.2665
Step:  3980, loss: 3.186616, norm: 0.2626, time(ms): 795.85, token/sec:658781.52, hellaswag_acc: 0.2665
Step:  3981, loss: 3.298112, norm: 0.2561, time(ms): 799.98, token/sec:655372.73, hellaswag_acc: 0.2665
Step:  3982, loss: 3.266293, norm: 0.2717, time(ms): 803.09, token/sec:652835.81, hellaswag_acc: 0.2665
Step:  3983, loss: 3.338287, norm: 0.2781, time(ms): 800.57, token/sec:654895.91, hellaswag_acc: 0.2665
Step:  3984, loss: 3.421713, norm: 0.2896, time(ms): 790.32, token/sec:663383.25, hellaswag_acc: 0.2665
Step:  3985, loss: 3.430950, norm: 0.2678, time(ms): 793.36, token/sec:660843.83, hellaswag_acc: 0.2665
Step:  3986, loss: 3.421977, norm: 0.2829, time(ms): 794.07, token/sec:660257.50, hellaswag_acc: 0.2665
Step:  3987, loss: 3.467765, norm: 0.2901, time(ms): 794.25, token/sec:660101.32, hellaswag_acc: 0.2665
Step:  3988, loss: 3.423288, norm: 0.2888, time(ms): 796.39, token/sec:658332.64, hellaswag_acc: 0.2665
Step:  3989, loss: 3.424117, norm: 0.2790, time(ms): 790.48, token/sec:663254.99, hellaswag_acc: 0.2665
Step:  3990, loss: 3.422284, norm: 0.2775, time(ms): 786.93, token/sec:666242.48, hellaswag_acc: 0.2665
Step:  3991, loss: 3.371984, norm: 0.2747, time(ms): 787.84, token/sec:665475.32, hellaswag_acc: 0.2665
Step:  3992, loss: 3.477858, norm: 0.2808, time(ms): 804.28, token/sec:651868.58, hellaswag_acc: 0.2665
Step:  3993, loss: 3.431555, norm: 0.2819, time(ms): 798.22, token/sec:656820.91, hellaswag_acc: 0.2665
Step:  3994, loss: 3.454136, norm: 0.2842, time(ms): 796.35, token/sec:658360.43, hellaswag_acc: 0.2665
Step:  3995, loss: 3.362887, norm: 0.3255, time(ms): 802.99, token/sec:652922.27, hellaswag_acc: 0.2665
Step:  3996, loss: 3.436145, norm: 0.3411, time(ms): 802.86, token/sec:653024.45, hellaswag_acc: 0.2665
Step:  3997, loss: 3.398897, norm: 0.3446, time(ms): 795.11, token/sec:659392.71, hellaswag_acc: 0.2665
Step:  3998, loss: 3.438430, norm: 0.2995, time(ms): 800.97, token/sec:654565.11, hellaswag_acc: 0.2665
Step:  3999, loss: 3.420244, norm: 0.2814, time(ms): 800.44, token/sec:654995.98, hellaswag_acc: 0.2665
rank 0 sample 0: Hello, I'm a language model, and I know that's where my new data from the US and EU archives came from, a data source of the data
rank 0 sample 1: Hello, I'm a language model, so a lot of things are not part of my personal, and you still don't need to be fluent with it.
rank 0 sample 2: Hello, I'm a language model, so I thought about language for sure, but we do have it. It's about language and how to use it,
rank 0 sample 3: Hello, I'm a language model, and, we're going to do some research-based research on this language model
(we'll post about this below
rank 1 sample 0: Hello, I'm a language model, this means you can model a wide series of topics and use data to describe their ideas in a single language.
I
rank 1 sample 1: Hello, I'm a language model, which means it's a language model is part of the framework that will be used in its very soon to be released.
rank 1 sample 2: Hello, I'm a language model, I’m a language model, I’m actually trying to think about what's important in terms of how
rank 1 sample 3: Hello, I'm a language model, and I'm very interested in how this framework can be embedded into and/or used today. And I'm interested in
Step:  4000, loss: 3.365217, norm: 0.2831, time(ms): 364510.84, token/sec:1438.33, val_loss: 3.4179, hellaswag_acc: 0.2708
Step:  4001, loss: 3.416286, norm: 0.2782, time(ms): 800.03, token/sec:655335.63, hellaswag_acc: 0.2708
Step:  4002, loss: 3.451803, norm: 0.2752, time(ms): 782.84, token/sec:669726.21, hellaswag_acc: 0.2708
Step:  4003, loss: 3.464520, norm: 0.2653, time(ms): 790.51, token/sec:663227.39, hellaswag_acc: 0.2708
Step:  4004, loss: 3.465561, norm: 0.2644, time(ms): 792.06, token/sec:661933.72, hellaswag_acc: 0.2708
Step:  4005, loss: 3.397678, norm: 0.2593, time(ms): 791.81, token/sec:662138.81, hellaswag_acc: 0.2708
Step:  4006, loss: 3.475268, norm: 0.2526, time(ms): 784.25, token/sec:668519.47, hellaswag_acc: 0.2708
Step:  4007, loss: 3.426808, norm: 0.2671, time(ms): 780.06, token/sec:672115.64, hellaswag_acc: 0.2708
Step:  4008, loss: 3.472115, norm: 0.2435, time(ms): 786.59, token/sec:666529.64, hellaswag_acc: 0.2708
Step:  4009, loss: 3.449724, norm: 0.2527, time(ms): 796.56, token/sec:658188.40, hellaswag_acc: 0.2708
Step:  4010, loss: 3.503191, norm: 0.2955, time(ms): 790.04, token/sec:663624.08, hellaswag_acc: 0.2708
Step:  4011, loss: 3.448364, norm: 0.2737, time(ms): 786.50, token/sec:666606.62, hellaswag_acc: 0.2708
Step:  4012, loss: 3.421775, norm: 0.2620, time(ms): 790.64, token/sec:663119.39, hellaswag_acc: 0.2708
Step:  4013, loss: 3.467589, norm: 0.2721, time(ms): 794.60, token/sec:659813.93, hellaswag_acc: 0.2708
Step:  4014, loss: 3.508479, norm: 0.2864, time(ms): 792.43, token/sec:661621.05, hellaswag_acc: 0.2708
Step:  4015, loss: 3.457843, norm: 0.2632, time(ms): 793.78, token/sec:660495.28, hellaswag_acc: 0.2708
Step:  4016, loss: 3.449757, norm: 0.2507, time(ms): 796.03, token/sec:658626.83, hellaswag_acc: 0.2708
Step:  4017, loss: 3.463058, norm: 0.2583, time(ms): 797.26, token/sec:657609.33, hellaswag_acc: 0.2708
Step:  4018, loss: 3.414441, norm: 0.2593, time(ms): 806.68, token/sec:649932.70, hellaswag_acc: 0.2708
Step:  4019, loss: 3.406294, norm: 0.2517, time(ms): 791.46, token/sec:662431.62, hellaswag_acc: 0.2708
Step:  4020, loss: 3.303534, norm: 0.2790, time(ms): 793.13, token/sec:661037.31, hellaswag_acc: 0.2708
Step:  4021, loss: 3.455941, norm: 0.2823, time(ms): 792.84, token/sec:661280.03, hellaswag_acc: 0.2708
Step:  4022, loss: 3.375740, norm: 0.3274, time(ms): 793.73, token/sec:660540.91, hellaswag_acc: 0.2708
Step:  4023, loss: 3.400080, norm: 0.2973, time(ms): 791.20, token/sec:662651.40, hellaswag_acc: 0.2708
Step:  4024, loss: 3.482425, norm: 0.3193, time(ms): 789.68, token/sec:663920.82, hellaswag_acc: 0.2708
Step:  4025, loss: 3.396543, norm: 0.2814, time(ms): 791.92, token/sec:662044.92, hellaswag_acc: 0.2708
Step:  4026, loss: 3.349937, norm: 0.2858, time(ms): 789.82, token/sec:663810.59, hellaswag_acc: 0.2708
Step:  4027, loss: 3.356784, norm: 0.2630, time(ms): 804.61, token/sec:651606.85, hellaswag_acc: 0.2708
Step:  4028, loss: 3.332799, norm: 0.2418, time(ms): 795.69, token/sec:658909.24, hellaswag_acc: 0.2708
Step:  4029, loss: 3.338540, norm: 0.2687, time(ms): 797.18, token/sec:657677.78, hellaswag_acc: 0.2708
Step:  4030, loss: 3.412303, norm: 0.2473, time(ms): 805.19, token/sec:651137.81, hellaswag_acc: 0.2708
Step:  4031, loss: 3.451512, norm: 0.2594, time(ms): 801.88, token/sec:653825.55, hellaswag_acc: 0.2708
Step:  4032, loss: 3.443196, norm: 0.2585, time(ms): 795.81, token/sec:658810.93, hellaswag_acc: 0.2708
Step:  4033, loss: 3.307889, norm: 0.2971, time(ms): 799.71, token/sec:655600.17, hellaswag_acc: 0.2708
Step:  4034, loss: 3.511555, norm: 0.2973, time(ms): 801.27, token/sec:654321.84, hellaswag_acc: 0.2708
Step:  4035, loss: 3.415441, norm: 0.3397, time(ms): 799.69, token/sec:655617.56, hellaswag_acc: 0.2708
Step:  4036, loss: 3.362378, norm: 0.3220, time(ms): 802.42, token/sec:653381.27, hellaswag_acc: 0.2708
Step:  4037, loss: 3.455203, norm: 0.2664, time(ms): 793.57, token/sec:660674.27, hellaswag_acc: 0.2708
Step:  4038, loss: 3.447814, norm: 0.3153, time(ms): 803.47, token/sec:652528.58, hellaswag_acc: 0.2708
Step:  4039, loss: 3.484054, norm: 0.3362, time(ms): 800.87, token/sec:654645.19, hellaswag_acc: 0.2708
Step:  4040, loss: 3.435391, norm: 0.3421, time(ms): 802.06, token/sec:653679.59, hellaswag_acc: 0.2708
Step:  4041, loss: 3.448394, norm: 0.3658, time(ms): 793.06, token/sec:661095.14, hellaswag_acc: 0.2708
Step:  4042, loss: 3.393725, norm: 0.3279, time(ms): 803.32, token/sec:652652.33, hellaswag_acc: 0.2708
Step:  4043, loss: 3.430428, norm: 0.3437, time(ms): 802.16, token/sec:653596.44, hellaswag_acc: 0.2708
Step:  4044, loss: 3.494454, norm: 0.3328, time(ms): 799.79, token/sec:655531.37, hellaswag_acc: 0.2708
Step:  4045, loss: 3.466233, norm: 0.2753, time(ms): 794.86, token/sec:659600.19, hellaswag_acc: 0.2708
Step:  4046, loss: 3.481128, norm: 0.2872, time(ms): 803.59, token/sec:652433.71, hellaswag_acc: 0.2708
Step:  4047, loss: 3.439441, norm: 0.2797, time(ms): 800.88, token/sec:654638.96, hellaswag_acc: 0.2708
Step:  4048, loss: 3.483067, norm: 0.2618, time(ms): 791.62, token/sec:662297.55, hellaswag_acc: 0.2708
Step:  4049, loss: 3.424288, norm: 0.2610, time(ms): 804.39, token/sec:651782.41, hellaswag_acc: 0.2708
Step:  4050, loss: 3.382108, norm: 0.2661, time(ms): 804.35, token/sec:651814.29, hellaswag_acc: 0.2708
Step:  4051, loss: 3.428229, norm: 0.2849, time(ms): 799.62, token/sec:655670.15, hellaswag_acc: 0.2708
Step:  4052, loss: 3.425910, norm: 0.2692, time(ms): 798.54, token/sec:656555.58, hellaswag_acc: 0.2708
Step:  4053, loss: 3.436978, norm: 0.2668, time(ms): 798.88, token/sec:656281.25, hellaswag_acc: 0.2708
Step:  4054, loss: 3.385378, norm: 0.2731, time(ms): 800.40, token/sec:655033.25, hellaswag_acc: 0.2708
Step:  4055, loss: 3.414653, norm: 0.2545, time(ms): 800.68, token/sec:654805.24, hellaswag_acc: 0.2708
Step:  4056, loss: 3.379191, norm: 0.2456, time(ms): 794.84, token/sec:659613.25, hellaswag_acc: 0.2708
Step:  4057, loss: 3.376735, norm: 0.2381, time(ms): 800.22, token/sec:655177.28, hellaswag_acc: 0.2708
Step:  4058, loss: 3.393881, norm: 0.2397, time(ms): 804.73, token/sec:651506.27, hellaswag_acc: 0.2708
Step:  4059, loss: 3.329191, norm: 0.2387, time(ms): 800.76, token/sec:654734.85, hellaswag_acc: 0.2708
Step:  4060, loss: 3.360765, norm: 0.2514, time(ms): 788.31, token/sec:665077.01, hellaswag_acc: 0.2708
Step:  4061, loss: 3.346707, norm: 0.2418, time(ms): 805.32, token/sec:651031.98, hellaswag_acc: 0.2708
Step:  4062, loss: 3.376616, norm: 0.2359, time(ms): 806.29, token/sec:650249.81, hellaswag_acc: 0.2708
Step:  4063, loss: 3.353641, norm: 0.2860, time(ms): 792.61, token/sec:661470.59, hellaswag_acc: 0.2708
Step:  4064, loss: 3.372941, norm: 0.2517, time(ms): 798.02, token/sec:656983.58, hellaswag_acc: 0.2708
Step:  4065, loss: 3.438435, norm: 0.2635, time(ms): 807.78, token/sec:649052.01, hellaswag_acc: 0.2708
Step:  4066, loss: 3.400546, norm: 0.2590, time(ms): 800.06, token/sec:655311.02, hellaswag_acc: 0.2708
Step:  4067, loss: 3.423599, norm: 0.2568, time(ms): 783.68, token/sec:669010.03, hellaswag_acc: 0.2708
Step:  4068, loss: 3.396940, norm: 0.2601, time(ms): 790.22, token/sec:663472.51, hellaswag_acc: 0.2708
Step:  4069, loss: 3.415540, norm: 0.2741, time(ms): 797.01, token/sec:657817.07, hellaswag_acc: 0.2708
Step:  4070, loss: 3.370671, norm: 0.3273, time(ms): 792.06, token/sec:661929.14, hellaswag_acc: 0.2708
Step:  4071, loss: 3.390018, norm: 0.2973, time(ms): 788.97, token/sec:664522.51, hellaswag_acc: 0.2708
Step:  4072, loss: 3.390197, norm: 0.2882, time(ms): 800.03, token/sec:655338.95, hellaswag_acc: 0.2708
Step:  4073, loss: 3.382108, norm: 0.2696, time(ms): 803.61, token/sec:652412.42, hellaswag_acc: 0.2708
Step:  4074, loss: 3.438915, norm: 0.2470, time(ms): 803.45, token/sec:652545.03, hellaswag_acc: 0.2708
Step:  4075, loss: 3.444009, norm: 0.2714, time(ms): 790.19, token/sec:663492.53, hellaswag_acc: 0.2708
Step:  4076, loss: 3.410252, norm: 0.2924, time(ms): 799.01, token/sec:656174.14, hellaswag_acc: 0.2708
Step:  4077, loss: 3.420762, norm: 0.2811, time(ms): 806.42, token/sec:650143.11, hellaswag_acc: 0.2708
Step:  4078, loss: 3.496662, norm: 0.2980, time(ms): 803.64, token/sec:652392.29, hellaswag_acc: 0.2708
Step:  4079, loss: 3.484000, norm: 0.3106, time(ms): 793.84, token/sec:660444.50, hellaswag_acc: 0.2708
Step:  4080, loss: 3.410228, norm: 0.2918, time(ms): 801.56, token/sec:654087.13, hellaswag_acc: 0.2708
Step:  4081, loss: 3.415714, norm: 0.2796, time(ms): 801.82, token/sec:653869.30, hellaswag_acc: 0.2708
Step:  4082, loss: 3.475372, norm: 0.3190, time(ms): 799.19, token/sec:656026.34, hellaswag_acc: 0.2708
Step:  4083, loss: 3.485139, norm: 0.3019, time(ms): 793.37, token/sec:660834.10, hellaswag_acc: 0.2708
Step:  4084, loss: 3.398505, norm: 0.2792, time(ms): 806.17, token/sec:650341.92, hellaswag_acc: 0.2708
Step:  4085, loss: 3.422857, norm: 0.3012, time(ms): 803.03, token/sec:652890.47, hellaswag_acc: 0.2708
Step:  4086, loss: 3.454514, norm: 0.2694, time(ms): 792.55, token/sec:661522.92, hellaswag_acc: 0.2708
Step:  4087, loss: 3.383554, norm: 0.2734, time(ms): 800.48, token/sec:654965.16, hellaswag_acc: 0.2708
Step:  4088, loss: 3.386904, norm: 0.2489, time(ms): 802.50, token/sec:653317.98, hellaswag_acc: 0.2708
Step:  4089, loss: 3.326447, norm: 0.2660, time(ms): 802.92, token/sec:652980.62, hellaswag_acc: 0.2708
Step:  4090, loss: 3.343680, norm: 0.2578, time(ms): 791.98, token/sec:661999.88, hellaswag_acc: 0.2708
Step:  4091, loss: 3.403783, norm: 0.2500, time(ms): 804.06, token/sec:652047.57, hellaswag_acc: 0.2708
Step:  4092, loss: 3.361038, norm: 0.2625, time(ms): 803.92, token/sec:652163.79, hellaswag_acc: 0.2708
Step:  4093, loss: 3.356074, norm: 0.2570, time(ms): 790.60, token/sec:663151.98, hellaswag_acc: 0.2708
Step:  4094, loss: 3.409420, norm: 0.2788, time(ms): 802.36, token/sec:653429.80, hellaswag_acc: 0.2708
Step:  4095, loss: 3.405380, norm: 0.2888, time(ms): 805.35, token/sec:651004.22, hellaswag_acc: 0.2708
Step:  4096, loss: 3.340501, norm: 0.2552, time(ms): 801.41, token/sec:654209.33, hellaswag_acc: 0.2708
Step:  4097, loss: 3.316811, norm: 0.2578, time(ms): 792.53, token/sec:661539.84, hellaswag_acc: 0.2708
Step:  4098, loss: 3.390040, norm: 0.2829, time(ms): 800.29, token/sec:655119.11, hellaswag_acc: 0.2708
Step:  4099, loss: 3.431502, norm: 0.2633, time(ms): 805.15, token/sec:651171.36, hellaswag_acc: 0.2708
Step:  4100, loss: 3.400086, norm: 0.2967, time(ms): 801.41, token/sec:654210.30, hellaswag_acc: 0.2708
Step:  4101, loss: 3.413698, norm: 0.3212, time(ms): 789.53, token/sec:664052.94, hellaswag_acc: 0.2708
Step:  4102, loss: 3.448653, norm: 0.3280, time(ms): 792.88, token/sec:661245.83, hellaswag_acc: 0.2708
Step:  4103, loss: 3.457751, norm: 0.3178, time(ms): 795.36, token/sec:659180.62, hellaswag_acc: 0.2708
Step:  4104, loss: 3.442031, norm: 0.2886, time(ms): 795.11, token/sec:659387.77, hellaswag_acc: 0.2708
Step:  4105, loss: 3.449675, norm: 0.3118, time(ms): 801.24, token/sec:654341.70, hellaswag_acc: 0.2708
Step:  4106, loss: 3.491479, norm: 0.3652, time(ms): 795.19, token/sec:659322.92, hellaswag_acc: 0.2708
Step:  4107, loss: 3.404159, norm: 0.3357, time(ms): 789.75, token/sec:663862.89, hellaswag_acc: 0.2708
Step:  4108, loss: 3.506612, norm: 0.3289, time(ms): 792.24, token/sec:661781.13, hellaswag_acc: 0.2708
Step:  4109, loss: 3.496083, norm: 0.3302, time(ms): 797.01, token/sec:657819.82, hellaswag_acc: 0.2708
Step:  4110, loss: 3.454467, norm: 0.3483, time(ms): 788.56, token/sec:664870.09, hellaswag_acc: 0.2708
Step:  4111, loss: 3.389197, norm: 0.3196, time(ms): 790.89, token/sec:662906.49, hellaswag_acc: 0.2708
Step:  4112, loss: 3.445528, norm: 0.2833, time(ms): 804.61, token/sec:651607.62, hellaswag_acc: 0.2708
Step:  4113, loss: 3.478226, norm: 0.3158, time(ms): 804.44, token/sec:651738.95, hellaswag_acc: 0.2708
Step:  4114, loss: 3.430522, norm: 0.2775, time(ms): 798.64, token/sec:656478.74, hellaswag_acc: 0.2708
Step:  4115, loss: 3.465288, norm: 0.2820, time(ms): 789.58, token/sec:664009.63, hellaswag_acc: 0.2708
Step:  4116, loss: 3.419952, norm: 0.2700, time(ms): 791.43, token/sec:662454.37, hellaswag_acc: 0.2708
Step:  4117, loss: 3.425733, norm: 0.2632, time(ms): 788.54, token/sec:664880.75, hellaswag_acc: 0.2708
Step:  4118, loss: 3.417351, norm: 0.2436, time(ms): 790.95, token/sec:662857.54, hellaswag_acc: 0.2708
Step:  4119, loss: 3.409654, norm: 0.2740, time(ms): 797.53, token/sec:657386.80, hellaswag_acc: 0.2708
Step:  4120, loss: 3.431043, norm: 0.2749, time(ms): 800.11, token/sec:655267.08, hellaswag_acc: 0.2708
Step:  4121, loss: 3.436458, norm: 0.2877, time(ms): 798.55, token/sec:656552.24, hellaswag_acc: 0.2708
Step:  4122, loss: 3.327157, norm: 0.2623, time(ms): 800.38, token/sec:655046.32, hellaswag_acc: 0.2708
Step:  4123, loss: 3.392857, norm: 0.2493, time(ms): 800.83, token/sec:654678.52, hellaswag_acc: 0.2708
Step:  4124, loss: 3.407798, norm: 0.2665, time(ms): 800.42, token/sec:655015.69, hellaswag_acc: 0.2708
Step:  4125, loss: 3.391572, norm: 0.2551, time(ms): 798.10, token/sec:656920.78, hellaswag_acc: 0.2708
Step:  4126, loss: 3.364947, norm: 0.2767, time(ms): 800.79, token/sec:654713.61, hellaswag_acc: 0.2708
Step:  4127, loss: 3.389789, norm: 0.2502, time(ms): 798.92, token/sec:656245.41, hellaswag_acc: 0.2708
Step:  4128, loss: 3.406686, norm: 0.2630, time(ms): 800.54, token/sec:654919.52, hellaswag_acc: 0.2708
Step:  4129, loss: 3.361867, norm: 0.2720, time(ms): 799.59, token/sec:655697.52, hellaswag_acc: 0.2708
Step:  4130, loss: 3.395503, norm: 0.2836, time(ms): 799.63, token/sec:655661.74, hellaswag_acc: 0.2708
Step:  4131, loss: 3.364142, norm: 0.2643, time(ms): 797.63, token/sec:657306.23, hellaswag_acc: 0.2708
Step:  4132, loss: 3.380986, norm: 0.2257, time(ms): 805.38, token/sec:650985.53, hellaswag_acc: 0.2708
Step:  4133, loss: 3.343900, norm: 0.2604, time(ms): 793.17, token/sec:661002.74, hellaswag_acc: 0.2708
Step:  4134, loss: 3.463191, norm: 0.2423, time(ms): 796.32, token/sec:658388.42, hellaswag_acc: 0.2708
Step:  4135, loss: 3.429214, norm: 0.2752, time(ms): 793.49, token/sec:660736.21, hellaswag_acc: 0.2708
Step:  4136, loss: 3.443008, norm: 0.2818, time(ms): 797.46, token/sec:657444.58, hellaswag_acc: 0.2708
Step:  4137, loss: 3.423340, norm: 0.3306, time(ms): 786.84, token/sec:666320.41, hellaswag_acc: 0.2708
Step:  4138, loss: 3.464200, norm: 0.3373, time(ms): 789.10, token/sec:664409.27, hellaswag_acc: 0.2708
Step:  4139, loss: 3.466742, norm: 0.3161, time(ms): 796.62, token/sec:658136.79, hellaswag_acc: 0.2708
Step:  4140, loss: 3.396710, norm: 0.3332, time(ms): 793.64, token/sec:660614.53, hellaswag_acc: 0.2708
Step:  4141, loss: 3.426567, norm: 0.3099, time(ms): 792.77, token/sec:661339.10, hellaswag_acc: 0.2708
Step:  4142, loss: 3.379393, norm: 0.3107, time(ms): 790.42, token/sec:663304.21, hellaswag_acc: 0.2708
Step:  4143, loss: 3.445765, norm: 0.2692, time(ms): 802.07, token/sec:653667.55, hellaswag_acc: 0.2708
Step:  4144, loss: 3.453583, norm: 0.2716, time(ms): 805.40, token/sec:650964.91, hellaswag_acc: 0.2708
Step:  4145, loss: 3.446505, norm: 0.3149, time(ms): 800.16, token/sec:655232.13, hellaswag_acc: 0.2708
Step:  4146, loss: 3.412015, norm: 0.5166, time(ms): 793.55, token/sec:660684.39, hellaswag_acc: 0.2708
Step:  4147, loss: 3.402501, norm: 0.2643, time(ms): 802.74, token/sec:653125.11, hellaswag_acc: 0.2708
Step:  4148, loss: 3.461167, norm: 0.2852, time(ms): 803.95, token/sec:652142.90, hellaswag_acc: 0.2708
Step:  4149, loss: 3.451921, norm: 0.2551, time(ms): 796.19, token/sec:658494.49, hellaswag_acc: 0.2708
Step:  4150, loss: 3.452457, norm: 0.3147, time(ms): 794.75, token/sec:659689.43, hellaswag_acc: 0.2708
Step:  4151, loss: 3.415709, norm: 0.3036, time(ms): 806.52, token/sec:650064.50, hellaswag_acc: 0.2708
Step:  4152, loss: 3.481087, norm: 0.2587, time(ms): 801.94, token/sec:653775.79, hellaswag_acc: 0.2708
Step:  4153, loss: 3.411084, norm: 0.2973, time(ms): 790.74, token/sec:663034.41, hellaswag_acc: 0.2708
Step:  4154, loss: 3.401710, norm: 0.2512, time(ms): 807.44, token/sec:649318.21, hellaswag_acc: 0.2708
Step:  4155, loss: 3.467277, norm: 0.2873, time(ms): 801.31, token/sec:654285.44, hellaswag_acc: 0.2708
Step:  4156, loss: 3.401290, norm: 0.2990, time(ms): 796.49, token/sec:658251.45, hellaswag_acc: 0.2708
Step:  4157, loss: 3.396119, norm: 0.3473, time(ms): 797.56, token/sec:657362.62, hellaswag_acc: 0.2708
Step:  4158, loss: 3.341494, norm: 0.3030, time(ms): 799.31, token/sec:655921.65, hellaswag_acc: 0.2708
Step:  4159, loss: 3.408010, norm: 0.2727, time(ms): 805.78, token/sec:650658.08, hellaswag_acc: 0.2708
Step:  4160, loss: 3.346216, norm: 0.2764, time(ms): 795.12, token/sec:659380.06, hellaswag_acc: 0.2708
Step:  4161, loss: 3.350025, norm: 0.2579, time(ms): 801.42, token/sec:654202.13, hellaswag_acc: 0.2708
Step:  4162, loss: 3.342106, norm: 0.2652, time(ms): 800.53, token/sec:654926.93, hellaswag_acc: 0.2708
Step:  4163, loss: 3.343832, norm: 0.2831, time(ms): 801.98, token/sec:653738.67, hellaswag_acc: 0.2708
Step:  4164, loss: 3.409665, norm: 0.2707, time(ms): 798.61, token/sec:656503.24, hellaswag_acc: 0.2708
Step:  4165, loss: 3.363507, norm: 0.2494, time(ms): 791.86, token/sec:662098.54, hellaswag_acc: 0.2708
Step:  4166, loss: 3.403020, norm: 0.2788, time(ms): 807.84, token/sec:649002.78, hellaswag_acc: 0.2708
Step:  4167, loss: 3.366515, norm: 0.2433, time(ms): 796.56, token/sec:658193.33, hellaswag_acc: 0.2708
Step:  4168, loss: 3.417219, norm: 0.2463, time(ms): 802.52, token/sec:653302.65, hellaswag_acc: 0.2708
Step:  4169, loss: 3.406145, norm: 0.2737, time(ms): 799.59, token/sec:655693.41, hellaswag_acc: 0.2708
Step:  4170, loss: 3.438567, norm: 0.2438, time(ms): 796.55, token/sec:658198.85, hellaswag_acc: 0.2708
Step:  4171, loss: 3.403368, norm: 0.2527, time(ms): 804.44, token/sec:651740.49, hellaswag_acc: 0.2708
Step:  4172, loss: 3.476866, norm: 0.2638, time(ms): 798.28, token/sec:656769.71, hellaswag_acc: 0.2708
Step:  4173, loss: 3.425716, norm: 0.2771, time(ms): 800.42, token/sec:655019.79, hellaswag_acc: 0.2708
Step:  4174, loss: 3.434149, norm: 0.2729, time(ms): 795.76, token/sec:658849.22, hellaswag_acc: 0.2708
Step:  4175, loss: 3.379665, norm: 0.2564, time(ms): 803.19, token/sec:652758.88, hellaswag_acc: 0.2708
Step:  4176, loss: 3.352420, norm: 0.2584, time(ms): 798.89, token/sec:656269.11, hellaswag_acc: 0.2708
Step:  4177, loss: 3.245633, norm: 0.6500, time(ms): 802.06, token/sec:653673.38, hellaswag_acc: 0.2708
Step:  4178, loss: 3.419783, norm: 0.4475, time(ms): 796.53, token/sec:658211.26, hellaswag_acc: 0.2708
Step:  4179, loss: 3.468271, norm: 0.3679, time(ms): 804.15, token/sec:651979.13, hellaswag_acc: 0.2708
Step:  4180, loss: 3.411660, norm: 0.3393, time(ms): 798.58, token/sec:656528.13, hellaswag_acc: 0.2708
Step:  4181, loss: 3.456247, norm: 0.3384, time(ms): 793.71, token/sec:660551.82, hellaswag_acc: 0.2708
Step:  4182, loss: 3.405426, norm: 0.2858, time(ms): 807.13, token/sec:649568.13, hellaswag_acc: 0.2708
Step:  4183, loss: 3.471029, norm: 0.2959, time(ms): 797.46, token/sec:657443.79, hellaswag_acc: 0.2708
Step:  4184, loss: 3.447917, norm: 0.2946, time(ms): 796.71, token/sec:658068.65, hellaswag_acc: 0.2708
Step:  4185, loss: 3.525536, norm: 0.3257, time(ms): 804.47, token/sec:651718.28, hellaswag_acc: 0.2708
Step:  4186, loss: 3.411589, norm: 0.3325, time(ms): 801.63, token/sec:654031.10, hellaswag_acc: 0.2708
Step:  4187, loss: 3.456576, norm: 0.2940, time(ms): 790.35, token/sec:663363.44, hellaswag_acc: 0.2708
Step:  4188, loss: 3.433111, norm: 0.2558, time(ms): 807.21, token/sec:649509.42, hellaswag_acc: 0.2708
Step:  4189, loss: 3.485035, norm: 0.2644, time(ms): 799.45, token/sec:655811.72, hellaswag_acc: 0.2708
Step:  4190, loss: 3.503650, norm: 0.2705, time(ms): 1340.55, token/sec:391098.91, hellaswag_acc: 0.2708
Step:  4191, loss: 3.382019, norm: 0.3012, time(ms): 767.91, token/sec:682744.13, hellaswag_acc: 0.2708
Step:  4192, loss: 3.381811, norm: 0.2469, time(ms): 790.52, token/sec:663217.59, hellaswag_acc: 0.2708
Step:  4193, loss: 3.416792, norm: 0.2617, time(ms): 800.74, token/sec:654756.69, hellaswag_acc: 0.2708
Step:  4194, loss: 3.414659, norm: 0.2762, time(ms): 786.44, token/sec:666663.41, hellaswag_acc: 0.2708
Step:  4195, loss: 3.385263, norm: 0.2431, time(ms): 781.86, token/sec:670565.37, hellaswag_acc: 0.2708
Step:  4196, loss: 3.411086, norm: 0.2612, time(ms): 790.86, token/sec:662931.88, hellaswag_acc: 0.2708
Step:  4197, loss: 3.416608, norm: 0.2463, time(ms): 795.74, token/sec:658866.20, hellaswag_acc: 0.2708
Step:  4198, loss: 3.398515, norm: 0.2541, time(ms): 806.34, token/sec:650204.24, hellaswag_acc: 0.2708
Step:  4199, loss: 3.392186, norm: 0.2401, time(ms): 784.60, token/sec:668225.92, hellaswag_acc: 0.2708
Step:  4200, loss: 3.485884, norm: 0.2932, time(ms): 791.68, token/sec:662250.08, hellaswag_acc: 0.2708
Step:  4201, loss: 3.372531, norm: 0.3127, time(ms): 796.07, token/sec:658599.02, hellaswag_acc: 0.2708
Step:  4202, loss: 3.422879, norm: 0.3047, time(ms): 799.86, token/sec:655477.64, hellaswag_acc: 0.2708
Step:  4203, loss: 3.368185, norm: 0.2693, time(ms): 790.11, token/sec:663565.01, hellaswag_acc: 0.2708
Step:  4204, loss: 3.385552, norm: 0.2632, time(ms): 782.43, token/sec:670076.41, hellaswag_acc: 0.2708
Step:  4205, loss: 3.414798, norm: 0.2711, time(ms): 784.38, token/sec:668412.99, hellaswag_acc: 0.2708
Step:  4206, loss: 3.413903, norm: 0.2488, time(ms): 805.93, token/sec:650537.39, hellaswag_acc: 0.2708
Step:  4207, loss: 3.366387, norm: 0.2442, time(ms): 803.18, token/sec:652762.17, hellaswag_acc: 0.2708
Step:  4208, loss: 3.322438, norm: 0.2655, time(ms): 788.09, token/sec:665262.52, hellaswag_acc: 0.2708
Step:  4209, loss: 3.398037, norm: 0.2509, time(ms): 790.16, token/sec:663518.36, hellaswag_acc: 0.2708
Step:  4210, loss: 3.402845, norm: 0.2716, time(ms): 791.16, token/sec:662682.15, hellaswag_acc: 0.2708
Step:  4211, loss: 3.396052, norm: 0.2973, time(ms): 790.87, token/sec:662929.28, hellaswag_acc: 0.2708
Step:  4212, loss: 3.351324, norm: 0.2772, time(ms): 797.43, token/sec:657475.64, hellaswag_acc: 0.2708
Step:  4213, loss: 3.320015, norm: 0.2735, time(ms): 791.83, token/sec:662120.27, hellaswag_acc: 0.2708
Step:  4214, loss: 3.430814, norm: 0.2684, time(ms): 802.89, token/sec:652998.07, hellaswag_acc: 0.2708
Step:  4215, loss: 3.362247, norm: 0.2460, time(ms): 806.88, token/sec:649774.46, hellaswag_acc: 0.2708
Step:  4216, loss: 3.345824, norm: 0.2537, time(ms): 792.33, token/sec:661705.26, hellaswag_acc: 0.2708
Step:  4217, loss: 3.524186, norm: 0.3045, time(ms): 796.88, token/sec:657921.97, hellaswag_acc: 0.2708
Step:  4218, loss: 3.422766, norm: 0.3465, time(ms): 795.25, token/sec:659276.86, hellaswag_acc: 0.2708
Step:  4219, loss: 3.441303, norm: 0.3079, time(ms): 795.22, token/sec:659297.03, hellaswag_acc: 0.2708
Step:  4220, loss: 3.334657, norm: 0.2437, time(ms): 789.54, token/sec:664038.50, hellaswag_acc: 0.2708
Step:  4221, loss: 3.435344, norm: 0.2741, time(ms): 791.59, token/sec:662325.08, hellaswag_acc: 0.2708
Step:  4222, loss: 3.425043, norm: 0.2892, time(ms): 786.65, token/sec:666481.97, hellaswag_acc: 0.2708
Step:  4223, loss: 3.409046, norm: 0.2928, time(ms): 791.21, token/sec:662644.21, hellaswag_acc: 0.2708
Step:  4224, loss: 3.376387, norm: 0.2979, time(ms): 789.73, token/sec:663885.94, hellaswag_acc: 0.2708
Step:  4225, loss: 3.367264, norm: 0.2666, time(ms): 800.64, token/sec:654837.41, hellaswag_acc: 0.2708
Step:  4226, loss: 3.480244, norm: 0.2731, time(ms): 806.77, token/sec:649858.37, hellaswag_acc: 0.2708
Step:  4227, loss: 3.402871, norm: 0.2982, time(ms): 802.49, token/sec:653329.82, hellaswag_acc: 0.2708
Step:  4228, loss: 3.441041, norm: 0.2843, time(ms): 790.22, token/sec:663472.51, hellaswag_acc: 0.2708
Step:  4229, loss: 3.409801, norm: 0.2624, time(ms): 805.33, token/sec:651020.80, hellaswag_acc: 0.2708
Step:  4230, loss: 3.368093, norm: 0.2464, time(ms): 803.27, token/sec:652688.55, hellaswag_acc: 0.2708
Step:  4231, loss: 3.365251, norm: 0.2514, time(ms): 794.84, token/sec:659616.02, hellaswag_acc: 0.2708
Step:  4232, loss: 3.435552, norm: 0.2638, time(ms): 796.64, token/sec:658121.23, hellaswag_acc: 0.2708
Step:  4233, loss: 3.369348, norm: 0.2676, time(ms): 806.72, token/sec:649904.28, hellaswag_acc: 0.2708
Step:  4234, loss: 3.423831, norm: 0.2822, time(ms): 799.66, token/sec:655638.67, hellaswag_acc: 0.2708
Step:  4235, loss: 3.383214, norm: 0.2782, time(ms): 801.11, token/sec:654451.53, hellaswag_acc: 0.2708
Step:  4236, loss: 3.389439, norm: 0.2671, time(ms): 793.18, token/sec:660997.38, hellaswag_acc: 0.2708
Step:  4237, loss: 3.476327, norm: 0.2615, time(ms): 804.86, token/sec:651399.55, hellaswag_acc: 0.2708
Step:  4238, loss: 3.413594, norm: 0.2846, time(ms): 799.72, token/sec:655587.66, hellaswag_acc: 0.2708
Step:  4239, loss: 3.406627, norm: 0.3208, time(ms): 799.18, token/sec:656036.13, hellaswag_acc: 0.2708
Step:  4240, loss: 3.360806, norm: 0.2809, time(ms): 796.72, token/sec:658057.62, hellaswag_acc: 0.2708
Step:  4241, loss: 3.411224, norm: 0.2946, time(ms): 805.11, token/sec:651198.16, hellaswag_acc: 0.2708
Step:  4242, loss: 3.377809, norm: 0.2754, time(ms): 799.12, token/sec:656083.69, hellaswag_acc: 0.2708
Step:  4243, loss: 3.317644, norm: 0.2835, time(ms): 792.17, token/sec:661836.50, hellaswag_acc: 0.2708
Step:  4244, loss: 3.399386, norm: 0.2566, time(ms): 806.16, token/sec:650350.96, hellaswag_acc: 0.2708
Step:  4245, loss: 3.375164, norm: 0.2600, time(ms): 801.80, token/sec:653890.88, hellaswag_acc: 0.2708
Step:  4246, loss: 3.429032, norm: 0.2878, time(ms): 789.06, token/sec:664450.42, hellaswag_acc: 0.2708
Step:  4247, loss: 3.365452, norm: 0.2891, time(ms): 791.45, token/sec:662443.00, hellaswag_acc: 0.2708
Step:  4248, loss: 3.358173, norm: 0.2740, time(ms): 789.09, token/sec:664418.30, hellaswag_acc: 0.2708
Step:  4249, loss: 3.369033, norm: 0.2765, time(ms): 791.28, token/sec:662579.72, hellaswag_acc: 0.2708
rank 0 sample 0: Hello, I'm a language model, and I need to be clear what a machine was when it came about. And I have to start by understanding what that
rank 0 sample 1: Hello, I'm a language model, so a language model is a model.
- As your child reads into her books and tells her which books she likes
rank 0 sample 2: Hello, I'm a language model, but I understand what I don't really know of.
"It's a bit like the language model, and I
rank 0 sample 3: Hello, I'm a language model, which in the world is a language. So much of the language models, I could imagine, would be models.<|endoftext|>
rank 1 sample 0: Hello, I'm a language model, and it is a pretty simple language". The same way your grammar is a way of describing a whole language and the way
rank 1 sample 1: Hello, I'm a language model, not an actual language model. And if you're in search of English, that means more than we can't get to
rank 1 sample 2: Hello, I'm a language model, so yes it's a language model.
The grammar and reading skills that are essential to language skills, such as knowing
rank 1 sample 3: Hello, I'm a language model, and I'm also going to want to design a lot more of our design methods. These concepts are very important as they
Step:  4250, loss: 3.400394, norm: 0.2490, time(ms): 4205.25, token/sec:124674.55, val_loss: 3.3981, hellaswag_acc: 0.2708
Step:  4251, loss: 3.431722, norm: 0.2441, time(ms): 794.57, token/sec:659839.67, hellaswag_acc: 0.2708
Step:  4252, loss: 3.472023, norm: 0.2727, time(ms): 791.62, token/sec:662300.94, hellaswag_acc: 0.2708
Step:  4253, loss: 3.355863, norm: 0.2940, time(ms): 799.64, token/sec:655654.51, hellaswag_acc: 0.2708
Step:  4254, loss: 3.396449, norm: 0.2848, time(ms): 806.06, token/sec:650436.95, hellaswag_acc: 0.2708
Step:  4255, loss: 3.465130, norm: 0.2924, time(ms): 786.98, token/sec:666200.50, hellaswag_acc: 0.2708
Step:  4256, loss: 3.400581, norm: 0.2646, time(ms): 789.37, token/sec:664181.90, hellaswag_acc: 0.2708
Step:  4257, loss: 3.386827, norm: 0.2854, time(ms): 796.11, token/sec:658560.95, hellaswag_acc: 0.2708
Step:  4258, loss: 3.383998, norm: 0.2923, time(ms): 791.53, token/sec:662376.35, hellaswag_acc: 0.2708
Step:  4259, loss: 3.472429, norm: 0.2881, time(ms): 785.35, token/sec:667585.89, hellaswag_acc: 0.2708
Step:  4260, loss: 3.376099, norm: 0.2690, time(ms): 788.34, token/sec:665051.87, hellaswag_acc: 0.2708
Step:  4261, loss: 3.423960, norm: 0.2908, time(ms): 798.70, token/sec:656423.87, hellaswag_acc: 0.2708
Step:  4262, loss: 3.420760, norm: 0.2794, time(ms): 799.72, token/sec:655593.33, hellaswag_acc: 0.2708
Step:  4263, loss: 3.359687, norm: 0.2599, time(ms): 794.56, token/sec:659850.56, hellaswag_acc: 0.2708
Step:  4264, loss: 3.406456, norm: 0.2628, time(ms): 800.17, token/sec:655223.15, hellaswag_acc: 0.2708
Step:  4265, loss: 3.394626, norm: 0.2977, time(ms): 802.49, token/sec:653327.88, hellaswag_acc: 0.2708
Step:  4266, loss: 3.458905, norm: 0.2620, time(ms): 803.99, token/sec:652111.19, hellaswag_acc: 0.2708
Step:  4267, loss: 3.368609, norm: 0.2674, time(ms): 794.76, token/sec:659683.69, hellaswag_acc: 0.2708
Step:  4268, loss: 3.382890, norm: 0.2813, time(ms): 803.78, token/sec:652281.79, hellaswag_acc: 0.2708
Step:  4269, loss: 3.427706, norm: 0.2801, time(ms): 800.73, token/sec:654760.39, hellaswag_acc: 0.2708
Step:  4270, loss: 3.387368, norm: 0.2434, time(ms): 799.35, token/sec:655894.46, hellaswag_acc: 0.2708
Step:  4271, loss: 3.373048, norm: 0.3022, time(ms): 796.08, token/sec:658583.83, hellaswag_acc: 0.2708
Step:  4272, loss: 3.342626, norm: 0.3291, time(ms): 801.01, token/sec:654530.23, hellaswag_acc: 0.2708
Step:  4273, loss: 3.311301, norm: 0.3350, time(ms): 803.67, token/sec:652364.81, hellaswag_acc: 0.2708
Step:  4274, loss: 3.307252, norm: 0.3043, time(ms): 797.78, token/sec:657181.69, hellaswag_acc: 0.2708
Step:  4275, loss: 3.403972, norm: 0.3019, time(ms): 795.31, token/sec:659226.47, hellaswag_acc: 0.2708
Step:  4276, loss: 3.380010, norm: 0.2844, time(ms): 802.47, token/sec:653345.55, hellaswag_acc: 0.2708
Step:  4277, loss: 3.289188, norm: 0.2751, time(ms): 803.05, token/sec:652871.28, hellaswag_acc: 0.2708
Step:  4278, loss: 3.343326, norm: 0.2819, time(ms): 802.48, token/sec:653336.81, hellaswag_acc: 0.2708
Step:  4279, loss: 3.343470, norm: 0.2770, time(ms): 788.81, token/sec:664657.68, hellaswag_acc: 0.2708
Step:  4280, loss: 3.310029, norm: 0.2628, time(ms): 804.46, token/sec:651727.36, hellaswag_acc: 0.2708
Step:  4281, loss: 3.414430, norm: 0.2779, time(ms): 804.97, token/sec:651316.97, hellaswag_acc: 0.2708
Step:  4282, loss: 3.326645, norm: 0.2721, time(ms): 799.58, token/sec:655701.23, hellaswag_acc: 0.2708
Step:  4283, loss: 3.374714, norm: 0.2885, time(ms): 791.48, token/sec:662412.67, hellaswag_acc: 0.2708
Step:  4284, loss: 3.345423, norm: 0.2551, time(ms): 805.35, token/sec:651009.62, hellaswag_acc: 0.2708
Step:  4285, loss: 3.353375, norm: 0.2993, time(ms): 802.22, token/sec:653548.65, hellaswag_acc: 0.2708
Step:  4286, loss: 3.402671, norm: 0.2885, time(ms): 800.79, token/sec:654710.10, hellaswag_acc: 0.2708
Step:  4287, loss: 3.381736, norm: 0.2613, time(ms): 789.56, token/sec:664026.07, hellaswag_acc: 0.2708
Step:  4288, loss: 3.414688, norm: 0.2687, time(ms): 802.98, token/sec:652923.82, hellaswag_acc: 0.2708
Step:  4289, loss: 3.404786, norm: 0.2600, time(ms): 806.27, token/sec:650263.65, hellaswag_acc: 0.2708
Step:  4290, loss: 3.495750, norm: 0.3169, time(ms): 793.76, token/sec:660511.55, hellaswag_acc: 0.2708
Step:  4291, loss: 3.357640, norm: 0.3369, time(ms): 798.38, token/sec:656691.25, hellaswag_acc: 0.2708
Step:  4292, loss: 3.400836, norm: 0.3012, time(ms): 806.25, token/sec:650282.69, hellaswag_acc: 0.2708
Step:  4293, loss: 3.353457, norm: 0.2860, time(ms): 801.69, token/sec:653975.47, hellaswag_acc: 0.2708
Step:  4294, loss: 3.366024, norm: 0.2564, time(ms): 788.69, token/sec:664757.54, hellaswag_acc: 0.2708
Step:  4295, loss: 3.440175, norm: 0.2935, time(ms): 791.14, token/sec:662702.72, hellaswag_acc: 0.2708
Step:  4296, loss: 3.414749, norm: 0.2751, time(ms): 794.06, token/sec:660259.28, hellaswag_acc: 0.2708
Step:  4297, loss: 3.431152, norm: 0.2918, time(ms): 789.66, token/sec:663940.86, hellaswag_acc: 0.2708
Step:  4298, loss: 3.419003, norm: 0.2635, time(ms): 792.07, token/sec:661921.37, hellaswag_acc: 0.2708
Step:  4299, loss: 3.381912, norm: 0.2943, time(ms): 792.98, token/sec:661157.76, hellaswag_acc: 0.2708
Step:  4300, loss: 3.361254, norm: 0.2488, time(ms): 792.61, token/sec:661474.17, hellaswag_acc: 0.2708
Step:  4301, loss: 3.386629, norm: 0.2533, time(ms): 797.05, token/sec:657787.75, hellaswag_acc: 0.2708
Step:  4302, loss: 3.394662, norm: 0.2591, time(ms): 792.66, token/sec:661429.21, hellaswag_acc: 0.2708
Step:  4303, loss: 3.357178, norm: 0.2491, time(ms): 791.90, token/sec:662060.27, hellaswag_acc: 0.2708
Step:  4304, loss: 3.389059, norm: 0.2648, time(ms): 785.63, token/sec:667346.63, hellaswag_acc: 0.2708
Step:  4305, loss: 3.421244, norm: 0.2716, time(ms): 786.67, token/sec:666466.41, hellaswag_acc: 0.2708
Step:  4306, loss: 3.326361, norm: 0.3291, time(ms): 801.77, token/sec:653911.49, hellaswag_acc: 0.2708
Step:  4307, loss: 3.370916, norm: 0.3580, time(ms): 798.82, token/sec:656326.11, hellaswag_acc: 0.2708
Step:  4308, loss: 3.356971, norm: 0.3393, time(ms): 795.31, token/sec:659221.33, hellaswag_acc: 0.2708
Step:  4309, loss: 3.311199, norm: 0.2818, time(ms): 805.04, token/sec:651257.75, hellaswag_acc: 0.2708
Step:  4310, loss: 3.399317, norm: 0.3203, time(ms): 799.73, token/sec:655582.77, hellaswag_acc: 0.2708
Step:  4311, loss: 3.354443, norm: 0.2628, time(ms): 799.72, token/sec:655591.57, hellaswag_acc: 0.2708
Step:  4312, loss: 3.290884, norm: 0.2746, time(ms): 794.23, token/sec:660118.16, hellaswag_acc: 0.2708
Step:  4313, loss: 3.388195, norm: 0.2616, time(ms): 804.70, token/sec:651534.45, hellaswag_acc: 0.2708
Step:  4314, loss: 3.351600, norm: 0.2711, time(ms): 801.75, token/sec:653930.16, hellaswag_acc: 0.2708
Step:  4315, loss: 3.284629, norm: 0.3031, time(ms): 793.80, token/sec:660475.04, hellaswag_acc: 0.2708
Step:  4316, loss: 3.334466, norm: 0.2842, time(ms): 800.57, token/sec:654891.04, hellaswag_acc: 0.2708
Step:  4317, loss: 3.338427, norm: 0.2767, time(ms): 803.14, token/sec:652794.54, hellaswag_acc: 0.2708
Step:  4318, loss: 3.369117, norm: 0.2494, time(ms): 802.32, token/sec:653462.42, hellaswag_acc: 0.2708
Step:  4319, loss: 3.395124, norm: 0.2808, time(ms): 791.26, token/sec:662598.29, hellaswag_acc: 0.2708
Step:  4320, loss: 3.423422, norm: 0.2986, time(ms): 801.18, token/sec:654394.08, hellaswag_acc: 0.2708
Step:  4321, loss: 3.408529, norm: 0.2781, time(ms): 803.42, token/sec:652571.18, hellaswag_acc: 0.2708
Step:  4322, loss: 3.377827, norm: 0.2944, time(ms): 799.65, token/sec:655645.71, hellaswag_acc: 0.2708
Step:  4323, loss: 3.391259, norm: 0.3428, time(ms): 802.51, token/sec:653310.03, hellaswag_acc: 0.2708
Step:  4324, loss: 3.420250, norm: 0.3330, time(ms): 798.11, token/sec:656911.95, hellaswag_acc: 0.2708
Step:  4325, loss: 3.393411, norm: 0.2874, time(ms): 800.28, token/sec:655130.63, hellaswag_acc: 0.2708
Step:  4326, loss: 3.368432, norm: 0.3051, time(ms): 801.53, token/sec:654106.39, hellaswag_acc: 0.2708
Step:  4327, loss: 3.396132, norm: 0.2772, time(ms): 797.90, token/sec:657088.81, hellaswag_acc: 0.2708
Step:  4328, loss: 3.396529, norm: 0.2755, time(ms): 798.06, token/sec:656955.12, hellaswag_acc: 0.2708
Step:  4329, loss: 3.429744, norm: 0.2880, time(ms): 803.79, token/sec:652267.47, hellaswag_acc: 0.2708
Step:  4330, loss: 3.362693, norm: 0.2914, time(ms): 799.98, token/sec:655375.47, hellaswag_acc: 0.2708
Step:  4331, loss: 3.417985, norm: 0.2697, time(ms): 795.11, token/sec:659393.90, hellaswag_acc: 0.2708
Step:  4332, loss: 3.360250, norm: 0.2760, time(ms): 803.41, token/sec:652578.15, hellaswag_acc: 0.2708
Step:  4333, loss: 3.354488, norm: 0.2610, time(ms): 801.00, token/sec:654545.43, hellaswag_acc: 0.2708
Step:  4334, loss: 3.392532, norm: 0.2998, time(ms): 793.24, token/sec:660947.91, hellaswag_acc: 0.2708
Step:  4335, loss: 3.362197, norm: 0.2826, time(ms): 803.08, token/sec:652844.15, hellaswag_acc: 0.2708
Step:  4336, loss: 3.362128, norm: 0.2949, time(ms): 801.37, token/sec:654243.20, hellaswag_acc: 0.2708
Step:  4337, loss: 3.406220, norm: 0.2985, time(ms): 800.48, token/sec:654970.23, hellaswag_acc: 0.2708
Step:  4338, loss: 3.365488, norm: 0.2761, time(ms): 794.12, token/sec:660212.50, hellaswag_acc: 0.2708
Step:  4339, loss: 3.438326, norm: 0.2399, time(ms): 802.96, token/sec:652941.65, hellaswag_acc: 0.2708
Step:  4340, loss: 3.454313, norm: 0.2573, time(ms): 804.04, token/sec:652067.48, hellaswag_acc: 0.2708
Step:  4341, loss: 3.377607, norm: 0.2766, time(ms): 796.75, token/sec:658036.55, hellaswag_acc: 0.2708
Step:  4342, loss: 3.383110, norm: 0.2787, time(ms): 792.48, token/sec:661581.24, hellaswag_acc: 0.2708
Step:  4343, loss: 3.353266, norm: 0.3015, time(ms): 801.71, token/sec:653959.72, hellaswag_acc: 0.2708
Step:  4344, loss: 3.294116, norm: 0.2764, time(ms): 799.84, token/sec:655494.25, hellaswag_acc: 0.2708
Step:  4345, loss: 3.340399, norm: 0.2684, time(ms): 792.31, token/sec:661718.00, hellaswag_acc: 0.2708
Step:  4346, loss: 3.365897, norm: 0.2457, time(ms): 788.03, token/sec:665311.43, hellaswag_acc: 0.2708
Step:  4347, loss: 3.360637, norm: 0.2533, time(ms): 792.40, token/sec:661642.15, hellaswag_acc: 0.2708
Step:  4348, loss: 3.347163, norm: 0.2725, time(ms): 794.61, token/sec:659804.03, hellaswag_acc: 0.2708
Step:  4349, loss: 3.362136, norm: 0.2913, time(ms): 791.07, token/sec:662760.25, hellaswag_acc: 0.2708
Step:  4350, loss: 3.351639, norm: 0.2772, time(ms): 792.48, token/sec:661577.65, hellaswag_acc: 0.2708
Step:  4351, loss: 3.269860, norm: 0.2505, time(ms): 794.86, token/sec:659601.57, hellaswag_acc: 0.2708
Step:  4352, loss: 3.336814, norm: 0.2549, time(ms): 791.89, token/sec:662075.82, hellaswag_acc: 0.2708
Step:  4353, loss: 3.337117, norm: 0.2363, time(ms): 790.62, token/sec:663132.79, hellaswag_acc: 0.2708
Step:  4354, loss: 3.435771, norm: 0.2597, time(ms): 787.85, token/sec:665465.85, hellaswag_acc: 0.2708
Step:  4355, loss: 3.370796, norm: 0.2628, time(ms): 791.53, token/sec:662375.36, hellaswag_acc: 0.2708
Step:  4356, loss: 3.372724, norm: 0.2534, time(ms): 788.17, token/sec:665197.92, hellaswag_acc: 0.2708
Step:  4357, loss: 3.447191, norm: 0.2412, time(ms): 794.23, token/sec:660119.55, hellaswag_acc: 0.2708
Step:  4358, loss: 3.382919, norm: 0.2634, time(ms): 791.22, token/sec:662634.23, hellaswag_acc: 0.2708
Step:  4359, loss: 3.444682, norm: 0.2824, time(ms): 795.91, token/sec:658724.09, hellaswag_acc: 0.2708
Step:  4360, loss: 3.357256, norm: 0.2800, time(ms): 792.48, token/sec:661581.44, hellaswag_acc: 0.2708
Step:  4361, loss: 3.442483, norm: 0.2643, time(ms): 794.61, token/sec:659801.46, hellaswag_acc: 0.2708
Step:  4362, loss: 3.394216, norm: 0.2644, time(ms): 795.23, token/sec:659287.54, hellaswag_acc: 0.2708
Step:  4363, loss: 3.353400, norm: 0.2565, time(ms): 798.82, token/sec:656324.93, hellaswag_acc: 0.2708
Step:  4364, loss: 3.387700, norm: 0.2700, time(ms): 803.27, token/sec:652691.46, hellaswag_acc: 0.2708
Step:  4365, loss: 3.422596, norm: 0.3042, time(ms): 796.33, token/sec:658377.97, hellaswag_acc: 0.2708
Step:  4366, loss: 3.384434, norm: 0.2983, time(ms): 797.75, token/sec:657211.35, hellaswag_acc: 0.2708
Step:  4367, loss: 3.383836, norm: 0.2736, time(ms): 798.90, token/sec:656264.41, hellaswag_acc: 0.2708
Step:  4368, loss: 3.383665, norm: 0.2774, time(ms): 792.67, token/sec:661422.04, hellaswag_acc: 0.2708
Step:  4369, loss: 3.391483, norm: 0.2474, time(ms): 794.78, token/sec:659661.72, hellaswag_acc: 0.2708
Step:  4370, loss: 3.369583, norm: 0.2714, time(ms): 794.80, token/sec:659651.24, hellaswag_acc: 0.2708
Step:  4371, loss: 3.445734, norm: 0.2899, time(ms): 801.98, token/sec:653743.92, hellaswag_acc: 0.2708
Step:  4372, loss: 3.403212, norm: 0.2902, time(ms): 803.93, token/sec:652156.63, hellaswag_acc: 0.2708
Step:  4373, loss: 3.392488, norm: 0.2791, time(ms): 792.05, token/sec:661939.70, hellaswag_acc: 0.2708
Step:  4374, loss: 3.418302, norm: 0.2905, time(ms): 797.89, token/sec:657092.54, hellaswag_acc: 0.2708
Step:  4375, loss: 3.376952, norm: 0.2849, time(ms): 789.65, token/sec:663953.49, hellaswag_acc: 0.2708
Step:  4376, loss: 3.365719, norm: 0.2671, time(ms): 796.77, token/sec:658020.60, hellaswag_acc: 0.2708
Step:  4377, loss: 3.327195, norm: 0.3018, time(ms): 789.59, token/sec:664000.00, hellaswag_acc: 0.2708
Step:  4378, loss: 3.337476, norm: 0.2665, time(ms): 789.00, token/sec:664501.02, hellaswag_acc: 0.2708
Step:  4379, loss: 3.320920, norm: 0.2651, time(ms): 802.28, token/sec:653498.74, hellaswag_acc: 0.2708
Step:  4380, loss: 3.351923, norm: 0.2561, time(ms): 802.58, token/sec:653251.42, hellaswag_acc: 0.2708
Step:  4381, loss: 3.305813, norm: 0.2527, time(ms): 1297.05, token/sec:404216.24, hellaswag_acc: 0.2708
Step:  4382, loss: 3.333273, norm: 0.2528, time(ms): 788.08, token/sec:665270.17, hellaswag_acc: 0.2708
Step:  4383, loss: 3.339288, norm: 0.2616, time(ms): 782.28, token/sec:670206.91, hellaswag_acc: 0.2708
Step:  4384, loss: 3.371983, norm: 0.2588, time(ms): 782.08, token/sec:670373.63, hellaswag_acc: 0.2708
Step:  4385, loss: 3.320322, norm: 0.2444, time(ms): 802.20, token/sec:653563.42, hellaswag_acc: 0.2708
Step:  4386, loss: 3.309110, norm: 0.2891, time(ms): 795.30, token/sec:659232.79, hellaswag_acc: 0.2708
Step:  4387, loss: 3.340566, norm: 0.2986, time(ms): 793.91, token/sec:660390.35, hellaswag_acc: 0.2708
Step:  4388, loss: 3.343147, norm: 0.2605, time(ms): 782.83, token/sec:669731.31, hellaswag_acc: 0.2708
Step:  4389, loss: 3.366825, norm: 0.2356, time(ms): 791.14, token/sec:662701.73, hellaswag_acc: 0.2708
Step:  4390, loss: 3.287570, norm: 0.2671, time(ms): 804.32, token/sec:651840.37, hellaswag_acc: 0.2708
Step:  4391, loss: 3.441938, norm: 0.2538, time(ms): 791.77, token/sec:662167.92, hellaswag_acc: 0.2708
Step:  4392, loss: 3.351858, norm: 0.2767, time(ms): 788.28, token/sec:665101.55, hellaswag_acc: 0.2708
Step:  4393, loss: 3.409112, norm: 0.3136, time(ms): 791.22, token/sec:662629.04, hellaswag_acc: 0.2708
Step:  4394, loss: 3.394323, norm: 0.3180, time(ms): 798.25, token/sec:656796.78, hellaswag_acc: 0.2708
Step:  4395, loss: 3.405986, norm: 0.2803, time(ms): 802.19, token/sec:653572.16, hellaswag_acc: 0.2708
Step:  4396, loss: 3.326345, norm: 0.2799, time(ms): 792.41, token/sec:661641.15, hellaswag_acc: 0.2708
Step:  4397, loss: 3.407629, norm: 0.2987, time(ms): 786.00, token/sec:667029.22, hellaswag_acc: 0.2708
Step:  4398, loss: 3.440706, norm: 0.2849, time(ms): 791.43, token/sec:662458.96, hellaswag_acc: 0.2708
Step:  4399, loss: 3.398306, norm: 0.3154, time(ms): 794.51, token/sec:659887.19, hellaswag_acc: 0.2708
Step:  4400, loss: 3.439961, norm: 0.2958, time(ms): 795.62, token/sec:658969.85, hellaswag_acc: 0.2708
Step:  4401, loss: 3.369724, norm: 0.2941, time(ms): 800.61, token/sec:654862.57, hellaswag_acc: 0.2708
Step:  4402, loss: 3.391125, norm: 0.2519, time(ms): 805.17, token/sec:651150.53, hellaswag_acc: 0.2708
Step:  4403, loss: 3.378413, norm: 0.2806, time(ms): 790.99, token/sec:662823.17, hellaswag_acc: 0.2708
Step:  4404, loss: 3.352816, norm: 0.3305, time(ms): 792.14, token/sec:661860.21, hellaswag_acc: 0.2708
Step:  4405, loss: 3.379555, norm: 0.3137, time(ms): 795.21, token/sec:659310.27, hellaswag_acc: 0.2708
Step:  4406, loss: 3.375646, norm: 0.2541, time(ms): 796.55, token/sec:658202.19, hellaswag_acc: 0.2708
Step:  4407, loss: 3.353504, norm: 0.2979, time(ms): 794.82, token/sec:659629.07, hellaswag_acc: 0.2708
Step:  4408, loss: 3.373937, norm: 0.2886, time(ms): 792.57, token/sec:661507.00, hellaswag_acc: 0.2708
Step:  4409, loss: 3.346878, norm: 0.3118, time(ms): 788.93, token/sec:664556.44, hellaswag_acc: 0.2708
Step:  4410, loss: 3.399333, norm: 0.3226, time(ms): 791.07, token/sec:662758.65, hellaswag_acc: 0.2708
Step:  4411, loss: 3.382960, norm: 0.2717, time(ms): 788.57, token/sec:664858.23, hellaswag_acc: 0.2708
Step:  4412, loss: 3.376930, norm: 0.2713, time(ms): 802.53, token/sec:653294.50, hellaswag_acc: 0.2708
Step:  4413, loss: 3.468340, norm: 0.2962, time(ms): 803.13, token/sec:652802.29, hellaswag_acc: 0.2708
Step:  4414, loss: 3.382325, norm: 0.2864, time(ms): 800.55, token/sec:654909.18, hellaswag_acc: 0.2708
Step:  4415, loss: 3.347772, norm: 0.2801, time(ms): 794.68, token/sec:659747.82, hellaswag_acc: 0.2708
Step:  4416, loss: 3.376059, norm: 0.3029, time(ms): 803.10, token/sec:652830.78, hellaswag_acc: 0.2708
Step:  4417, loss: 3.329080, norm: 0.2741, time(ms): 801.66, token/sec:654002.89, hellaswag_acc: 0.2708
Step:  4418, loss: 3.322599, norm: 0.2612, time(ms): 795.74, token/sec:658868.96, hellaswag_acc: 0.2708
Step:  4419, loss: 3.398764, norm: 0.2551, time(ms): 794.94, token/sec:659530.75, hellaswag_acc: 0.2708
Step:  4420, loss: 3.298935, norm: 0.2609, time(ms): 807.86, token/sec:648984.39, hellaswag_acc: 0.2708
Step:  4421, loss: 3.298385, norm: 0.2728, time(ms): 802.08, token/sec:653656.86, hellaswag_acc: 0.2708
Step:  4422, loss: 3.349348, norm: 0.2662, time(ms): 790.04, token/sec:663621.48, hellaswag_acc: 0.2708
Step:  4423, loss: 3.349475, norm: 0.2580, time(ms): 807.00, token/sec:649677.71, hellaswag_acc: 0.2708
Step:  4424, loss: 3.354634, norm: 0.2904, time(ms): 800.66, token/sec:654820.64, hellaswag_acc: 0.2708
Step:  4425, loss: 3.384093, norm: 0.3104, time(ms): 800.83, token/sec:654681.06, hellaswag_acc: 0.2708
Step:  4426, loss: 3.279225, norm: 0.2840, time(ms): 797.18, token/sec:657678.17, hellaswag_acc: 0.2708
Step:  4427, loss: 3.356436, norm: 0.2686, time(ms): 799.47, token/sec:655795.88, hellaswag_acc: 0.2708
Step:  4428, loss: 3.401866, norm: 0.2885, time(ms): 801.50, token/sec:654136.55, hellaswag_acc: 0.2708
Step:  4429, loss: 3.431428, norm: 0.2680, time(ms): 800.74, token/sec:654755.91, hellaswag_acc: 0.2708
Step:  4430, loss: 3.357686, norm: 0.2749, time(ms): 796.50, token/sec:658236.67, hellaswag_acc: 0.2708
Step:  4431, loss: 3.427909, norm: 0.2953, time(ms): 791.94, token/sec:662028.78, hellaswag_acc: 0.2708
Step:  4432, loss: 3.436846, norm: 0.2706, time(ms): 792.49, token/sec:661567.50, hellaswag_acc: 0.2708
Step:  4433, loss: 3.355886, norm: 0.2856, time(ms): 796.24, token/sec:658453.48, hellaswag_acc: 0.2708
Step:  4434, loss: 3.397872, norm: 0.2630, time(ms): 793.34, token/sec:660861.30, hellaswag_acc: 0.2708
Step:  4435, loss: 3.378833, norm: 0.2809, time(ms): 789.46, token/sec:664107.89, hellaswag_acc: 0.2708
Step:  4436, loss: 3.414951, norm: 0.2632, time(ms): 794.30, token/sec:660063.48, hellaswag_acc: 0.2708
Step:  4437, loss: 3.449165, norm: 0.2804, time(ms): 805.19, token/sec:651133.18, hellaswag_acc: 0.2708
Step:  4438, loss: 3.371447, norm: 0.2616, time(ms): 798.78, token/sec:656359.41, hellaswag_acc: 0.2708
Step:  4439, loss: 3.320394, norm: 0.2974, time(ms): 795.24, token/sec:659281.02, hellaswag_acc: 0.2708
Step:  4440, loss: 3.373956, norm: 0.2727, time(ms): 800.21, token/sec:655186.65, hellaswag_acc: 0.2708
Step:  4441, loss: 3.356338, norm: 0.2458, time(ms): 803.11, token/sec:652822.25, hellaswag_acc: 0.2708
Step:  4442, loss: 3.342859, norm: 0.2519, time(ms): 801.14, token/sec:654429.92, hellaswag_acc: 0.2708
Step:  4443, loss: 3.349252, norm: 0.2456, time(ms): 795.30, token/sec:659233.98, hellaswag_acc: 0.2708
Step:  4444, loss: 3.416100, norm: 0.2631, time(ms): 799.82, token/sec:655510.86, hellaswag_acc: 0.2708
Step:  4445, loss: 3.383260, norm: 0.2523, time(ms): 798.67, token/sec:656449.54, hellaswag_acc: 0.2708
Step:  4446, loss: 3.348984, norm: 0.2595, time(ms): 805.98, token/sec:650501.02, hellaswag_acc: 0.2708
Step:  4447, loss: 3.408759, norm: 0.2682, time(ms): 794.39, token/sec:659987.01, hellaswag_acc: 0.2708
Step:  4448, loss: 3.403332, norm: 0.2675, time(ms): 800.23, token/sec:655175.72, hellaswag_acc: 0.2708
Step:  4449, loss: 3.381099, norm: 0.2910, time(ms): 799.71, token/sec:655597.23, hellaswag_acc: 0.2708
Step:  4450, loss: 3.407925, norm: 0.3267, time(ms): 805.21, token/sec:651122.96, hellaswag_acc: 0.2708
Step:  4451, loss: 3.364095, norm: 0.2926, time(ms): 791.09, token/sec:662738.47, hellaswag_acc: 0.2708
Step:  4452, loss: 3.317224, norm: 0.2737, time(ms): 798.18, token/sec:656854.85, hellaswag_acc: 0.2708
Step:  4453, loss: 3.291931, norm: 0.2950, time(ms): 805.52, token/sec:650866.45, hellaswag_acc: 0.2708
Step:  4454, loss: 3.360281, norm: 0.2855, time(ms): 804.33, token/sec:651834.77, hellaswag_acc: 0.2708
Step:  4455, loss: 3.296162, norm: 0.2647, time(ms): 789.61, token/sec:663984.97, hellaswag_acc: 0.2708
Step:  4456, loss: 3.329946, norm: 0.2724, time(ms): 800.04, token/sec:655325.47, hellaswag_acc: 0.2708
Step:  4457, loss: 3.370997, norm: 0.2455, time(ms): 803.00, token/sec:652913.54, hellaswag_acc: 0.2708
Step:  4458, loss: 3.332857, norm: 0.2943, time(ms): 803.49, token/sec:652513.28, hellaswag_acc: 0.2708
Step:  4459, loss: 3.330231, norm: 0.3039, time(ms): 799.47, token/sec:655797.44, hellaswag_acc: 0.2708
Step:  4460, loss: 3.296906, norm: 0.2865, time(ms): 797.31, token/sec:657569.81, hellaswag_acc: 0.2708
Step:  4461, loss: 3.331140, norm: 0.2901, time(ms): 804.59, token/sec:651617.28, hellaswag_acc: 0.2708
Step:  4462, loss: 3.338032, norm: 0.2771, time(ms): 797.93, token/sec:657058.57, hellaswag_acc: 0.2708
Step:  4463, loss: 3.379981, norm: 0.3163, time(ms): 792.60, token/sec:661477.95, hellaswag_acc: 0.2708
Step:  4464, loss: 3.455680, norm: 0.3341, time(ms): 792.18, token/sec:661828.93, hellaswag_acc: 0.2708
Step:  4465, loss: 3.409725, norm: 0.3224, time(ms): 794.44, token/sec:659948.98, hellaswag_acc: 0.2708
Step:  4466, loss: 3.382882, norm: 0.2718, time(ms): 798.41, token/sec:656662.82, hellaswag_acc: 0.2708
Step:  4467, loss: 3.430917, norm: 0.2819, time(ms): 799.92, token/sec:655423.52, hellaswag_acc: 0.2708
Step:  4468, loss: 3.378515, norm: 0.2915, time(ms): 802.22, token/sec:653545.74, hellaswag_acc: 0.2708
Step:  4469, loss: 3.391117, norm: 0.2842, time(ms): 794.03, token/sec:660286.25, hellaswag_acc: 0.2708
Step:  4470, loss: 3.361449, norm: 0.3067, time(ms): 797.02, token/sec:657806.64, hellaswag_acc: 0.2708
Step:  4471, loss: 3.427684, norm: 0.3071, time(ms): 788.73, token/sec:664728.00, hellaswag_acc: 0.2708
Step:  4472, loss: 3.405843, norm: 0.3467, time(ms): 790.67, token/sec:663090.20, hellaswag_acc: 0.2708
Step:  4473, loss: 3.483997, norm: 0.3343, time(ms): 785.74, token/sec:667254.49, hellaswag_acc: 0.2708
Step:  4474, loss: 3.390249, norm: 0.3178, time(ms): 799.86, token/sec:655472.17, hellaswag_acc: 0.2708
Step:  4475, loss: 3.363306, norm: 0.3725, time(ms): 805.18, token/sec:651143.40, hellaswag_acc: 0.2708
Step:  4476, loss: 3.373963, norm: 0.3080, time(ms): 798.10, token/sec:656920.58, hellaswag_acc: 0.2708
Step:  4477, loss: 3.328727, norm: 0.3221, time(ms): 785.82, token/sec:667187.28, hellaswag_acc: 0.2708
Step:  4478, loss: 3.355043, norm: 0.3081, time(ms): 788.03, token/sec:665316.86, hellaswag_acc: 0.2708
Step:  4479, loss: 3.369431, norm: 0.2776, time(ms): 790.91, token/sec:662893.31, hellaswag_acc: 0.2708
Step:  4480, loss: 3.355829, norm: 0.2903, time(ms): 796.54, token/sec:658210.47, hellaswag_acc: 0.2708
Step:  4481, loss: 3.364635, norm: 0.2851, time(ms): 794.76, token/sec:659681.91, hellaswag_acc: 0.2708
Step:  4482, loss: 3.327724, norm: 0.2588, time(ms): 800.51, token/sec:654942.92, hellaswag_acc: 0.2708
Step:  4483, loss: 3.334915, norm: 0.2717, time(ms): 802.87, token/sec:653014.56, hellaswag_acc: 0.2708
Step:  4484, loss: 3.392565, norm: 0.2652, time(ms): 797.95, token/sec:657043.65, hellaswag_acc: 0.2708
Step:  4485, loss: 3.358759, norm: 0.2566, time(ms): 795.91, token/sec:658725.28, hellaswag_acc: 0.2708
Step:  4486, loss: 3.362432, norm: 0.2801, time(ms): 799.92, token/sec:655423.91, hellaswag_acc: 0.2708
Step:  4487, loss: 3.339547, norm: 0.2583, time(ms): 801.51, token/sec:654126.23, hellaswag_acc: 0.2708
Step:  4488, loss: 3.334346, norm: 0.2426, time(ms): 803.93, token/sec:652160.11, hellaswag_acc: 0.2708
Step:  4489, loss: 3.274767, norm: 0.2395, time(ms): 790.86, token/sec:662938.07, hellaswag_acc: 0.2708
Step:  4490, loss: 3.288874, norm: 0.2518, time(ms): 807.80, token/sec:649031.70, hellaswag_acc: 0.2708
Step:  4491, loss: 3.276700, norm: 0.2440, time(ms): 800.27, token/sec:655141.75, hellaswag_acc: 0.2708
Step:  4492, loss: 3.330277, norm: 0.2773, time(ms): 797.54, token/sec:657383.26, hellaswag_acc: 0.2708
Step:  4493, loss: 3.309974, norm: 0.2797, time(ms): 799.05, token/sec:656142.22, hellaswag_acc: 0.2708
Step:  4494, loss: 3.303785, norm: 0.2681, time(ms): 801.25, token/sec:654337.42, hellaswag_acc: 0.2708
Step:  4495, loss: 3.267971, norm: 0.2881, time(ms): 801.57, token/sec:654078.76, hellaswag_acc: 0.2708
Step:  4496, loss: 3.312948, norm: 0.2603, time(ms): 796.89, token/sec:657920.79, hellaswag_acc: 0.2708
Step:  4497, loss: 3.358944, norm: 0.2550, time(ms): 800.55, token/sec:654912.88, hellaswag_acc: 0.2708
Step:  4498, loss: 3.307219, norm: 0.2709, time(ms): 798.81, token/sec:656338.25, hellaswag_acc: 0.2708
Step:  4499, loss: 3.342370, norm: 0.2909, time(ms): 800.58, token/sec:654888.70, hellaswag_acc: 0.2708
rank 0 sample 0: Hello, I'm a language model, and I don't want to talk anything back to you.
We live in a culture of globalization. We know
rank 0 sample 1: Hello, I'm a language model, I love to read, and the kind of fun these kinds of conversations look good, too. I always have to think
rank 0 sample 2: Hello, I'm a language model, I'm still writing (it's great, this is a nice thing)
But how can I do that? Is
rank 0 sample 3: Hello, I'm a language model, and not a programmer. I've also noticed more in the above list. It contains two subprogrammers. One consists
rank 1 sample 0: Hello, I'm a language model, as if you're a computer programmer is not doing the homework (or learning anything). And you'll get back to the
rank 1 sample 1: Hello, I'm a language model, a teacher who works in a school language course. I’m a math curriculum leader. Because of my experience,
rank 1 sample 2: Hello, I'm a language model, so today, I'm going to explain how to use this structure to make a simple sentence sound out of the box of
rank 1 sample 3: Hello, I'm a language model, and I'm really a designer. You already know who would actually think they saw the machine made in the first place.
Step:  4500, loss: 3.374473, norm: 0.2677, time(ms): 3856.26, token/sec:135957.56, val_loss: 3.3822, hellaswag_acc: 0.2708
Step:  4501, loss: 3.336337, norm: 0.2777, time(ms): 790.07, token/sec:663592.84, hellaswag_acc: 0.2708
Step:  4502, loss: 3.422889, norm: 0.2868, time(ms): 786.20, token/sec:666866.99, hellaswag_acc: 0.2708
Step:  4503, loss: 3.378547, norm: 0.2538, time(ms): 807.02, token/sec:649659.28, hellaswag_acc: 0.2708
Step:  4504, loss: 3.355892, norm: 0.3013, time(ms): 802.53, token/sec:653297.80, hellaswag_acc: 0.2708
Step:  4505, loss: 3.353970, norm: 0.3192, time(ms): 800.34, token/sec:655082.03, hellaswag_acc: 0.2708
Step:  4506, loss: 3.341050, norm: 0.2914, time(ms): 794.32, token/sec:660044.26, hellaswag_acc: 0.2708
Step:  4507, loss: 3.430924, norm: 0.2883, time(ms): 797.71, token/sec:657240.22, hellaswag_acc: 0.2708
Step:  4508, loss: 3.404454, norm: 0.2749, time(ms): 806.21, token/sec:650312.50, hellaswag_acc: 0.2708
Step:  4509, loss: 3.461406, norm: 0.2761, time(ms): 796.46, token/sec:658275.10, hellaswag_acc: 0.2708
Step:  4510, loss: 3.380186, norm: 0.2926, time(ms): 794.29, token/sec:660067.84, hellaswag_acc: 0.2708
Step:  4511, loss: 3.430993, norm: 0.2684, time(ms): 796.70, token/sec:658078.30, hellaswag_acc: 0.2708
Step:  4512, loss: 3.428423, norm: 0.3494, time(ms): 790.54, token/sec:663199.78, hellaswag_acc: 0.2708
Step:  4513, loss: 3.382445, norm: 0.3152, time(ms): 799.88, token/sec:655461.81, hellaswag_acc: 0.2708
Step:  4514, loss: 3.364746, norm: 0.2865, time(ms): 790.34, token/sec:663368.44, hellaswag_acc: 0.2708
Step:  4515, loss: 3.469963, norm: 0.2718, time(ms): 786.09, token/sec:666953.16, hellaswag_acc: 0.2708
Step:  4516, loss: 3.356040, norm: 0.3117, time(ms): 801.88, token/sec:653821.47, hellaswag_acc: 0.2708
Step:  4517, loss: 3.323127, norm: 0.2846, time(ms): 803.73, token/sec:652316.81, hellaswag_acc: 0.2708
Step:  4518, loss: 3.352364, norm: 0.2699, time(ms): 792.09, token/sec:661908.62, hellaswag_acc: 0.2708
Step:  4519, loss: 3.416002, norm: 0.2747, time(ms): 793.64, token/sec:660614.93, hellaswag_acc: 0.2708
Step:  4520, loss: 3.399969, norm: 0.2666, time(ms): 791.83, token/sec:662117.88, hellaswag_acc: 0.2708
Step:  4521, loss: 3.364520, norm: 0.2495, time(ms): 797.22, token/sec:657645.13, hellaswag_acc: 0.2708
Step:  4522, loss: 3.298846, norm: 0.2514, time(ms): 793.36, token/sec:660842.83, hellaswag_acc: 0.2708
Step:  4523, loss: 3.365722, norm: 0.2583, time(ms): 789.85, token/sec:663784.94, hellaswag_acc: 0.2708
Step:  4524, loss: 3.332610, norm: 0.2785, time(ms): 788.78, token/sec:664680.58, hellaswag_acc: 0.2708
Step:  4525, loss: 3.251967, norm: 0.2346, time(ms): 787.90, token/sec:665422.15, hellaswag_acc: 0.2708
Step:  4526, loss: 3.297544, norm: 0.2410, time(ms): 797.98, token/sec:657020.88, hellaswag_acc: 0.2708
Step:  4527, loss: 3.308093, norm: 0.2453, time(ms): 804.82, token/sec:651435.63, hellaswag_acc: 0.2708
Step:  4528, loss: 3.365582, norm: 0.2645, time(ms): 800.88, token/sec:654639.15, hellaswag_acc: 0.2708
Step:  4529, loss: 3.321612, norm: 0.2686, time(ms): 795.00, token/sec:659485.46, hellaswag_acc: 0.2708
Step:  4530, loss: 3.325472, norm: 0.2518, time(ms): 799.08, token/sec:656118.53, hellaswag_acc: 0.2708
Step:  4531, loss: 3.336855, norm: 0.2492, time(ms): 803.16, token/sec:652779.42, hellaswag_acc: 0.2708
Step:  4532, loss: 3.358104, norm: 0.2351, time(ms): 801.36, token/sec:654246.31, hellaswag_acc: 0.2708
Step:  4533, loss: 3.345152, norm: 0.2523, time(ms): 796.08, token/sec:658587.18, hellaswag_acc: 0.2708
Step:  4534, loss: 3.368984, norm: 0.2549, time(ms): 799.73, token/sec:655578.47, hellaswag_acc: 0.2708
Step:  4535, loss: 3.317321, norm: 0.2793, time(ms): 802.02, token/sec:653711.07, hellaswag_acc: 0.2708
Step:  4536, loss: 3.391661, norm: 0.2646, time(ms): 800.52, token/sec:654937.07, hellaswag_acc: 0.2708
Step:  4537, loss: 3.351422, norm: 0.2604, time(ms): 800.90, token/sec:654622.39, hellaswag_acc: 0.2708
Step:  4538, loss: 3.402745, norm: 0.2598, time(ms): 790.21, token/sec:663481.32, hellaswag_acc: 0.2708
Step:  4539, loss: 3.374565, norm: 0.2962, time(ms): 798.80, token/sec:656346.68, hellaswag_acc: 0.2708
Step:  4540, loss: 3.428413, norm: 0.2824, time(ms): 790.54, token/sec:663205.39, hellaswag_acc: 0.2708
Step:  4541, loss: 3.388757, norm: 0.2890, time(ms): 793.55, token/sec:660686.38, hellaswag_acc: 0.2708
Step:  4542, loss: 3.357027, norm: 0.2553, time(ms): 793.63, token/sec:660619.69, hellaswag_acc: 0.2708
Step:  4543, loss: 3.381408, norm: 0.2842, time(ms): 788.26, token/sec:665123.07, hellaswag_acc: 0.2708
Step:  4544, loss: 3.408438, norm: 0.2903, time(ms): 799.65, token/sec:655646.49, hellaswag_acc: 0.2708
Step:  4545, loss: 3.416499, norm: 0.2932, time(ms): 804.24, token/sec:651905.11, hellaswag_acc: 0.2708
Step:  4546, loss: 3.366455, norm: 0.2783, time(ms): 791.67, token/sec:662256.86, hellaswag_acc: 0.2708
Step:  4547, loss: 3.383091, norm: 0.3073, time(ms): 796.91, token/sec:657904.65, hellaswag_acc: 0.2708
Step:  4548, loss: 3.331604, norm: 0.3340, time(ms): 790.34, token/sec:663372.84, hellaswag_acc: 0.2708
Step:  4549, loss: 3.390607, norm: 0.2803, time(ms): 795.28, token/sec:659249.59, hellaswag_acc: 0.2708
Step:  4550, loss: 3.348864, norm: 0.2754, time(ms): 796.73, token/sec:658052.70, hellaswag_acc: 0.2708
Step:  4551, loss: 3.363814, norm: 0.2915, time(ms): 791.99, token/sec:661991.31, hellaswag_acc: 0.2708
Step:  4552, loss: 3.373636, norm: 0.3006, time(ms): 784.48, token/sec:668328.68, hellaswag_acc: 0.2708
Step:  4553, loss: 3.453909, norm: 0.2626, time(ms): 785.17, token/sec:667735.70, hellaswag_acc: 0.2708
Step:  4554, loss: 3.370330, norm: 0.2791, time(ms): 804.66, token/sec:651561.67, hellaswag_acc: 0.2708
Step:  4555, loss: 3.367791, norm: 0.2616, time(ms): 801.15, token/sec:654419.40, hellaswag_acc: 0.2708
Step:  4556, loss: 3.337255, norm: 0.2870, time(ms): 799.00, token/sec:656180.99, hellaswag_acc: 0.2708
Step:  4557, loss: 3.325257, norm: 0.2919, time(ms): 792.97, token/sec:661165.91, hellaswag_acc: 0.2708
Step:  4558, loss: 3.404889, norm: 0.3719, time(ms): 806.00, token/sec:650478.89, hellaswag_acc: 0.2708
Step:  4559, loss: 3.330862, norm: 0.4001, time(ms): 802.22, token/sec:653542.83, hellaswag_acc: 0.2708
Step:  4560, loss: 3.299783, norm: 0.3282, time(ms): 790.69, token/sec:663078.40, hellaswag_acc: 0.2708
Step:  4561, loss: 3.300965, norm: 0.2791, time(ms): 807.08, token/sec:649608.81, hellaswag_acc: 0.2708
Step:  4562, loss: 3.263011, norm: 0.2965, time(ms): 799.47, token/sec:655794.51, hellaswag_acc: 0.2708
Step:  4563, loss: 3.328864, norm: 0.2511, time(ms): 799.98, token/sec:655376.45, hellaswag_acc: 0.2708
Step:  4564, loss: 3.312515, norm: 0.2907, time(ms): 794.48, token/sec:659909.37, hellaswag_acc: 0.2708
Step:  4565, loss: 3.306055, norm: 0.2621, time(ms): 803.67, token/sec:652368.87, hellaswag_acc: 0.2708
Step:  4566, loss: 3.299534, norm: 0.2799, time(ms): 802.92, token/sec:652980.24, hellaswag_acc: 0.2708
Step:  4567, loss: 3.276368, norm: 0.2653, time(ms): 800.06, token/sec:655308.48, hellaswag_acc: 0.2708
Step:  4568, loss: 3.333748, norm: 0.2713, time(ms): 787.03, token/sec:666158.72, hellaswag_acc: 0.2708
Step:  4569, loss: 3.334645, norm: 0.3066, time(ms): 789.34, token/sec:664214.40, hellaswag_acc: 0.2708
Step:  4570, loss: 3.447213, norm: 0.3021, time(ms): 798.71, token/sec:656415.06, hellaswag_acc: 0.2708
Step:  4571, loss: 3.347108, norm: 0.2817, time(ms): 1317.51, token/sec:397939.79, hellaswag_acc: 0.2708
Step:  4572, loss: 3.253849, norm: 0.2512, time(ms): 764.87, token/sec:685457.35, hellaswag_acc: 0.2708
Step:  4573, loss: 3.287074, norm: 0.2887, time(ms): 787.77, token/sec:665530.90, hellaswag_acc: 0.2708
Step:  4574, loss: 3.256047, norm: 0.2786, time(ms): 793.37, token/sec:660836.08, hellaswag_acc: 0.2708
Step:  4575, loss: 3.242705, norm: 0.2576, time(ms): 786.66, token/sec:666475.70, hellaswag_acc: 0.2708
Step:  4576, loss: 3.227425, norm: 0.2469, time(ms): 782.36, token/sec:670138.69, hellaswag_acc: 0.2708
Step:  4577, loss: 3.278892, norm: 0.2590, time(ms): 785.96, token/sec:667069.08, hellaswag_acc: 0.2708
Step:  4578, loss: 3.253471, norm: 0.2418, time(ms): 802.81, token/sec:653066.34, hellaswag_acc: 0.2708
Step:  4579, loss: 3.229620, norm: 0.2943, time(ms): 802.08, token/sec:653659.58, hellaswag_acc: 0.2708
Step:  4580, loss: 3.312449, norm: 0.2975, time(ms): 792.44, token/sec:661611.89, hellaswag_acc: 0.2708
Step:  4581, loss: 3.434421, norm: 0.3298, time(ms): 805.65, token/sec:650767.06, hellaswag_acc: 0.2708
Step:  4582, loss: 3.395031, norm: 0.2986, time(ms): 800.64, token/sec:654838.97, hellaswag_acc: 0.2708
Step:  4583, loss: 3.413296, norm: 0.2682, time(ms): 797.17, token/sec:657687.81, hellaswag_acc: 0.2708
Step:  4584, loss: 3.397653, norm: 0.3042, time(ms): 793.79, token/sec:660486.75, hellaswag_acc: 0.2708
Step:  4585, loss: 3.357185, norm: 0.2760, time(ms): 807.73, token/sec:649089.37, hellaswag_acc: 0.2708
Step:  4586, loss: 3.329108, norm: 0.2667, time(ms): 800.81, token/sec:654699.38, hellaswag_acc: 0.2708
Step:  4587, loss: 3.447753, norm: 0.2704, time(ms): 794.14, token/sec:660197.24, hellaswag_acc: 0.2708
Step:  4588, loss: 3.375562, norm: 0.2947, time(ms): 794.94, token/sec:659532.13, hellaswag_acc: 0.2708
Step:  4589, loss: 3.372744, norm: 0.2626, time(ms): 792.49, token/sec:661570.09, hellaswag_acc: 0.2708
Step:  4590, loss: 3.350814, norm: 0.2728, time(ms): 788.69, token/sec:664757.74, hellaswag_acc: 0.2708
Step:  4591, loss: 3.438889, norm: 0.2517, time(ms): 789.46, token/sec:664109.69, hellaswag_acc: 0.2708
Step:  4592, loss: 3.445649, norm: 0.2526, time(ms): 795.34, token/sec:659200.78, hellaswag_acc: 0.2708
Step:  4593, loss: 3.432262, norm: 0.2810, time(ms): 800.86, token/sec:654655.33, hellaswag_acc: 0.2708
Step:  4594, loss: 3.426373, norm: 0.2688, time(ms): 802.95, token/sec:652949.99, hellaswag_acc: 0.2708
Step:  4595, loss: 3.370082, norm: 0.2769, time(ms): 793.03, token/sec:661120.19, hellaswag_acc: 0.2708
Step:  4596, loss: 3.376138, norm: 0.2476, time(ms): 796.99, token/sec:657835.57, hellaswag_acc: 0.2708
Step:  4597, loss: 3.389350, norm: 0.2571, time(ms): 792.19, token/sec:661820.97, hellaswag_acc: 0.2708
Step:  4598, loss: 3.374258, norm: 0.2827, time(ms): 794.92, token/sec:659548.55, hellaswag_acc: 0.2708
Step:  4599, loss: 3.362427, norm: 0.2778, time(ms): 798.23, token/sec:656816.00, hellaswag_acc: 0.2708
Step:  4600, loss: 3.336095, norm: 0.2803, time(ms): 800.17, token/sec:655223.74, hellaswag_acc: 0.2708
Step:  4601, loss: 3.412952, norm: 0.2542, time(ms): 799.36, token/sec:655888.59, hellaswag_acc: 0.2708
Step:  4602, loss: 3.379389, norm: 0.3066, time(ms): 801.47, token/sec:654161.26, hellaswag_acc: 0.2708
Step:  4603, loss: 3.341311, norm: 0.2893, time(ms): 796.52, token/sec:658221.31, hellaswag_acc: 0.2708
Step:  4604, loss: 3.359637, norm: 0.2741, time(ms): 796.21, token/sec:658476.94, hellaswag_acc: 0.2708
Step:  4605, loss: 3.384016, norm: 0.3304, time(ms): 789.88, token/sec:663753.28, hellaswag_acc: 0.2708
Step:  4606, loss: 3.363473, norm: 0.3283, time(ms): 793.64, token/sec:660610.76, hellaswag_acc: 0.2708
Step:  4607, loss: 3.349590, norm: 0.2920, time(ms): 791.89, token/sec:662072.43, hellaswag_acc: 0.2708
Step:  4608, loss: 3.308902, norm: 0.3168, time(ms): 789.47, token/sec:664104.88, hellaswag_acc: 0.2708
Step:  4609, loss: 3.382763, norm: 0.2749, time(ms): 798.10, token/sec:656918.62, hellaswag_acc: 0.2708
Step:  4610, loss: 3.348275, norm: 0.3060, time(ms): 805.62, token/sec:650787.86, hellaswag_acc: 0.2708
Step:  4611, loss: 3.350833, norm: 0.2753, time(ms): 799.75, token/sec:655567.92, hellaswag_acc: 0.2708
Step:  4612, loss: 3.271285, norm: 0.2860, time(ms): 787.45, token/sec:665800.72, hellaswag_acc: 0.2708
Step:  4613, loss: 3.306694, norm: 0.2732, time(ms): 791.05, token/sec:662773.43, hellaswag_acc: 0.2708
Step:  4614, loss: 3.316650, norm: 0.2441, time(ms): 794.38, token/sec:659998.10, hellaswag_acc: 0.2708
Step:  4615, loss: 3.282566, norm: 0.2507, time(ms): 791.91, token/sec:662054.29, hellaswag_acc: 0.2708
Step:  4616, loss: 3.210978, norm: 0.2518, time(ms): 791.04, token/sec:662783.62, hellaswag_acc: 0.2708
Step:  4617, loss: 3.230258, norm: 0.2713, time(ms): 800.54, token/sec:654918.54, hellaswag_acc: 0.2708
Step:  4618, loss: 3.287544, norm: 0.2507, time(ms): 800.40, token/sec:655032.66, hellaswag_acc: 0.2708
Step:  4619, loss: 3.280886, norm: 0.2903, time(ms): 799.78, token/sec:655543.68, hellaswag_acc: 0.2708
Step:  4620, loss: 3.258419, norm: 0.3194, time(ms): 800.01, token/sec:655354.96, hellaswag_acc: 0.2708
Step:  4621, loss: 3.216854, norm: 0.2939, time(ms): 795.46, token/sec:659103.57, hellaswag_acc: 0.2708
Step:  4622, loss: 3.264896, norm: 0.2827, time(ms): 805.44, token/sec:650935.04, hellaswag_acc: 0.2708
Step:  4623, loss: 3.291615, norm: 0.2982, time(ms): 799.64, token/sec:655654.12, hellaswag_acc: 0.2708
Step:  4624, loss: 3.239078, norm: 0.2771, time(ms): 793.19, token/sec:660984.26, hellaswag_acc: 0.2708
Step:  4625, loss: 3.245469, norm: 0.2774, time(ms): 803.49, token/sec:652515.21, hellaswag_acc: 0.2708
Step:  4626, loss: 3.227441, norm: 0.3102, time(ms): 803.07, token/sec:652851.90, hellaswag_acc: 0.2708
Step:  4627, loss: 3.282519, norm: 0.2681, time(ms): 799.12, token/sec:656082.51, hellaswag_acc: 0.2708
Step:  4628, loss: 3.400725, norm: 0.2850, time(ms): 790.50, token/sec:663233.39, hellaswag_acc: 0.2708
Step:  4629, loss: 3.389419, norm: 0.3084, time(ms): 789.82, token/sec:663803.17, hellaswag_acc: 0.2708
Step:  4630, loss: 3.335984, norm: 0.3071, time(ms): 798.72, token/sec:656409.57, hellaswag_acc: 0.2708
Step:  4631, loss: 3.446853, norm: 0.3082, time(ms): 789.64, token/sec:663957.10, hellaswag_acc: 0.2708
Step:  4632, loss: 3.421965, norm: 0.3054, time(ms): 790.03, token/sec:663631.89, hellaswag_acc: 0.2708
Step:  4633, loss: 3.408363, norm: 0.2862, time(ms): 794.04, token/sec:660278.51, hellaswag_acc: 0.2708
Step:  4634, loss: 3.367115, norm: 0.2793, time(ms): 791.07, token/sec:662759.05, hellaswag_acc: 0.2708
Step:  4635, loss: 3.385031, norm: 0.2707, time(ms): 791.98, token/sec:661997.09, hellaswag_acc: 0.2708
Step:  4636, loss: 3.370833, norm: 0.2787, time(ms): 796.92, token/sec:657895.20, hellaswag_acc: 0.2708
Step:  4637, loss: 3.402660, norm: 0.2972, time(ms): 807.25, token/sec:649473.55, hellaswag_acc: 0.2708
Step:  4638, loss: 3.309652, norm: 0.2885, time(ms): 800.29, token/sec:655123.21, hellaswag_acc: 0.2708
Step:  4639, loss: 3.430445, norm: 0.2562, time(ms): 793.90, token/sec:660397.29, hellaswag_acc: 0.2708
Step:  4640, loss: 3.349016, norm: 0.2719, time(ms): 803.06, token/sec:652865.47, hellaswag_acc: 0.2708
Step:  4641, loss: 3.371485, norm: 0.2772, time(ms): 803.12, token/sec:652814.50, hellaswag_acc: 0.2708
Step:  4642, loss: 3.401319, norm: 0.2734, time(ms): 792.80, token/sec:661309.06, hellaswag_acc: 0.2708
Step:  4643, loss: 3.377902, norm: 0.3109, time(ms): 804.37, token/sec:651800.96, hellaswag_acc: 0.2708
Step:  4644, loss: 3.363640, norm: 0.3090, time(ms): 797.90, token/sec:657086.65, hellaswag_acc: 0.2708
Step:  4645, loss: 3.369727, norm: 0.2634, time(ms): 802.77, token/sec:653094.65, hellaswag_acc: 0.2708
Step:  4646, loss: 3.407493, norm: 0.3015, time(ms): 794.77, token/sec:659671.02, hellaswag_acc: 0.2708
Step:  4647, loss: 3.422715, norm: 0.2809, time(ms): 801.61, token/sec:654043.16, hellaswag_acc: 0.2708
Step:  4648, loss: 3.351041, norm: 0.2851, time(ms): 803.88, token/sec:652196.48, hellaswag_acc: 0.2708
Step:  4649, loss: 3.376058, norm: 0.2490, time(ms): 794.63, token/sec:659789.98, hellaswag_acc: 0.2708
Step:  4650, loss: 3.361012, norm: 0.2664, time(ms): 794.63, token/sec:659789.38, hellaswag_acc: 0.2708
Step:  4651, loss: 3.362990, norm: 0.2688, time(ms): 790.62, token/sec:663135.19, hellaswag_acc: 0.2708
Step:  4652, loss: 3.379454, norm: 0.2726, time(ms): 789.63, token/sec:663966.32, hellaswag_acc: 0.2708
Step:  4653, loss: 3.294461, norm: 0.2700, time(ms): 790.75, token/sec:663024.42, hellaswag_acc: 0.2708
Step:  4654, loss: 3.369444, norm: 0.2448, time(ms): 794.99, token/sec:659489.02, hellaswag_acc: 0.2708
Step:  4655, loss: 3.316990, norm: 0.2885, time(ms): 800.03, token/sec:655338.75, hellaswag_acc: 0.2708
Step:  4656, loss: 3.344300, norm: 0.2501, time(ms): 802.07, token/sec:653664.83, hellaswag_acc: 0.2708
Step:  4657, loss: 3.418662, norm: 0.2705, time(ms): 800.99, token/sec:654548.93, hellaswag_acc: 0.2708
Step:  4658, loss: 3.323637, norm: 0.2855, time(ms): 795.67, token/sec:658923.45, hellaswag_acc: 0.2708
Step:  4659, loss: 3.336053, norm: 0.2601, time(ms): 794.52, token/sec:659876.70, hellaswag_acc: 0.2708
Step:  4660, loss: 3.292915, norm: 0.2388, time(ms): 796.15, token/sec:658525.84, hellaswag_acc: 0.2708
Step:  4661, loss: 3.349480, norm: 0.2505, time(ms): 794.90, token/sec:659561.61, hellaswag_acc: 0.2708
Step:  4662, loss: 3.235616, norm: 0.2665, time(ms): 792.47, token/sec:661590.99, hellaswag_acc: 0.2708
Step:  4663, loss: 3.256770, norm: 0.2590, time(ms): 801.98, token/sec:653743.53, hellaswag_acc: 0.2708
Step:  4664, loss: 3.241942, norm: 0.2390, time(ms): 802.74, token/sec:653121.62, hellaswag_acc: 0.2708
Step:  4665, loss: 3.241030, norm: 0.2710, time(ms): 793.11, token/sec:661050.03, hellaswag_acc: 0.2708
Step:  4666, loss: 3.284663, norm: 0.2986, time(ms): 794.91, token/sec:659560.03, hellaswag_acc: 0.2708
Step:  4667, loss: 3.243916, norm: 0.2833, time(ms): 787.26, token/sec:665962.83, hellaswag_acc: 0.2708
Step:  4668, loss: 3.224770, norm: 0.2794, time(ms): 796.43, token/sec:658294.41, hellaswag_acc: 0.2708
Step:  4669, loss: 3.236098, norm: 0.2864, time(ms): 790.38, token/sec:663332.62, hellaswag_acc: 0.2708
Step:  4670, loss: 3.226983, norm: 0.2536, time(ms): 784.59, token/sec:668231.61, hellaswag_acc: 0.2708
Step:  4671, loss: 3.280204, norm: 0.2841, time(ms): 790.27, token/sec:663432.08, hellaswag_acc: 0.2708
Step:  4672, loss: 3.176507, norm: 0.2655, time(ms): 795.76, token/sec:658853.76, hellaswag_acc: 0.2708
Step:  4673, loss: 3.306666, norm: 0.2684, time(ms): 791.22, token/sec:662632.63, hellaswag_acc: 0.2708
Step:  4674, loss: 3.460867, norm: 0.2934, time(ms): 792.11, token/sec:661888.30, hellaswag_acc: 0.2708
Step:  4675, loss: 3.382792, norm: 0.2967, time(ms): 797.93, token/sec:657058.57, hellaswag_acc: 0.2708
Step:  4676, loss: 3.399946, norm: 0.3223, time(ms): 801.41, token/sec:654207.19, hellaswag_acc: 0.2708
Step:  4677, loss: 3.500411, norm: 0.3219, time(ms): 804.39, token/sec:651783.57, hellaswag_acc: 0.2708
Step:  4678, loss: 3.386883, norm: 0.3252, time(ms): 786.60, token/sec:666524.39, hellaswag_acc: 0.2708
Step:  4679, loss: 3.414694, norm: 0.3046, time(ms): 792.08, token/sec:661912.80, hellaswag_acc: 0.2708
Step:  4680, loss: 3.388440, norm: 0.2826, time(ms): 794.28, token/sec:660076.36, hellaswag_acc: 0.2708
Step:  4681, loss: 3.410212, norm: 0.3403, time(ms): 799.90, token/sec:655444.62, hellaswag_acc: 0.2708
Step:  4682, loss: 3.362943, norm: 0.2948, time(ms): 793.68, token/sec:660578.01, hellaswag_acc: 0.2708
Step:  4683, loss: 3.363747, norm: 0.2857, time(ms): 788.23, token/sec:665149.63, hellaswag_acc: 0.2708
Step:  4684, loss: 3.458903, norm: 0.2932, time(ms): 790.56, token/sec:663183.98, hellaswag_acc: 0.2708
Step:  4685, loss: 3.350449, norm: 0.2787, time(ms): 792.24, token/sec:661779.14, hellaswag_acc: 0.2708
Step:  4686, loss: 3.314619, norm: 0.2537, time(ms): 796.61, token/sec:658148.02, hellaswag_acc: 0.2708
Step:  4687, loss: 3.326963, norm: 0.2669, time(ms): 797.60, token/sec:657329.42, hellaswag_acc: 0.2708
Step:  4688, loss: 3.362078, norm: 0.2627, time(ms): 802.02, token/sec:653711.66, hellaswag_acc: 0.2708
Step:  4689, loss: 3.360908, norm: 0.2476, time(ms): 802.78, token/sec:653091.55, hellaswag_acc: 0.2708
Step:  4690, loss: 3.375997, norm: 0.2707, time(ms): 795.34, token/sec:659196.43, hellaswag_acc: 0.2708
Step:  4691, loss: 3.362009, norm: 0.2391, time(ms): 802.49, token/sec:653328.47, hellaswag_acc: 0.2708
Step:  4692, loss: 3.326869, norm: 0.2419, time(ms): 800.15, token/sec:655240.92, hellaswag_acc: 0.2708
Step:  4693, loss: 3.360557, norm: 0.2444, time(ms): 800.78, token/sec:654719.84, hellaswag_acc: 0.2708
Step:  4694, loss: 3.291062, norm: 0.2826, time(ms): 794.24, token/sec:660111.63, hellaswag_acc: 0.2708
Step:  4695, loss: 3.356592, norm: 0.2664, time(ms): 805.91, token/sec:650554.33, hellaswag_acc: 0.2708
Step:  4696, loss: 3.369863, norm: 0.2683, time(ms): 799.54, token/sec:655738.38, hellaswag_acc: 0.2708
Step:  4697, loss: 3.352784, norm: 0.2651, time(ms): 792.43, token/sec:661621.64, hellaswag_acc: 0.2708
Step:  4698, loss: 3.293578, norm: 0.2624, time(ms): 803.26, token/sec:652701.34, hellaswag_acc: 0.2708
Step:  4699, loss: 3.358893, norm: 0.2880, time(ms): 800.32, token/sec:655097.84, hellaswag_acc: 0.2708
Step:  4700, loss: 3.329549, norm: 0.3070, time(ms): 804.92, token/sec:651355.75, hellaswag_acc: 0.2708
Step:  4701, loss: 3.322532, norm: 0.2954, time(ms): 790.72, token/sec:663048.01, hellaswag_acc: 0.2708
Step:  4702, loss: 3.339724, norm: 0.2588, time(ms): 801.08, token/sec:654474.13, hellaswag_acc: 0.2708
Step:  4703, loss: 3.287303, norm: 0.2645, time(ms): 805.82, token/sec:650623.24, hellaswag_acc: 0.2708
Step:  4704, loss: 3.302616, norm: 0.3060, time(ms): 800.04, token/sec:655325.47, hellaswag_acc: 0.2708
Step:  4705, loss: 3.302987, norm: 0.2621, time(ms): 798.00, token/sec:656998.50, hellaswag_acc: 0.2708
Step:  4706, loss: 3.354365, norm: 0.2933, time(ms): 790.41, token/sec:663307.41, hellaswag_acc: 0.2708
Step:  4707, loss: 3.295449, norm: 0.2694, time(ms): 790.80, token/sec:662986.84, hellaswag_acc: 0.2708
Step:  4708, loss: 3.224972, norm: 0.3318, time(ms): 794.01, token/sec:660307.26, hellaswag_acc: 0.2708
Step:  4709, loss: 3.304853, norm: 0.3544, time(ms): 789.51, token/sec:664064.77, hellaswag_acc: 0.2708
Step:  4710, loss: 3.297751, norm: 0.3105, time(ms): 787.11, token/sec:666089.92, hellaswag_acc: 0.2708
Step:  4711, loss: 3.232572, norm: 0.3259, time(ms): 801.51, token/sec:654127.21, hellaswag_acc: 0.2708
Step:  4712, loss: 3.252676, norm: 0.3384, time(ms): 791.45, token/sec:662439.81, hellaswag_acc: 0.2708
Step:  4713, loss: 3.292267, norm: 0.3377, time(ms): 797.78, token/sec:657184.24, hellaswag_acc: 0.2708
Step:  4714, loss: 3.272243, norm: 0.3329, time(ms): 794.22, token/sec:660130.25, hellaswag_acc: 0.2708
Step:  4715, loss: 3.329724, norm: 0.3445, time(ms): 796.03, token/sec:658625.45, hellaswag_acc: 0.2708
Step:  4716, loss: 3.270617, norm: 0.2971, time(ms): 798.74, token/sec:656390.17, hellaswag_acc: 0.2708
Step:  4717, loss: 3.234911, norm: 0.3090, time(ms): 788.96, token/sec:664529.73, hellaswag_acc: 0.2708
Step:  4718, loss: 3.301963, norm: 0.2699, time(ms): 788.49, token/sec:664925.98, hellaswag_acc: 0.2708
Step:  4719, loss: 3.235810, norm: 0.2837, time(ms): 791.09, token/sec:662743.47, hellaswag_acc: 0.2708
Step:  4720, loss: 3.215297, norm: 0.3006, time(ms): 790.21, token/sec:663476.12, hellaswag_acc: 0.2708
Step:  4721, loss: 3.344598, norm: 0.3385, time(ms): 799.41, token/sec:655846.53, hellaswag_acc: 0.2708
Step:  4722, loss: 3.400091, norm: 0.3119, time(ms): 790.72, token/sec:663051.61, hellaswag_acc: 0.2708
Step:  4723, loss: 3.385634, norm: 0.2623, time(ms): 787.48, token/sec:665783.18, hellaswag_acc: 0.2708
Step:  4724, loss: 3.395810, norm: 0.2819, time(ms): 790.69, token/sec:663073.80, hellaswag_acc: 0.2708
Step:  4725, loss: 3.409314, norm: 0.3001, time(ms): 796.73, token/sec:658052.50, hellaswag_acc: 0.2708
Step:  4726, loss: 3.392214, norm: 0.2747, time(ms): 799.58, token/sec:655703.77, hellaswag_acc: 0.2708
Step:  4727, loss: 3.403018, norm: 0.2530, time(ms): 802.35, token/sec:653438.54, hellaswag_acc: 0.2708
Step:  4728, loss: 3.397315, norm: 0.2728, time(ms): 797.27, token/sec:657600.49, hellaswag_acc: 0.2708
Step:  4729, loss: 3.380500, norm: 0.2573, time(ms): 800.71, token/sec:654779.11, hellaswag_acc: 0.2708
Step:  4730, loss: 3.351860, norm: 0.2466, time(ms): 799.05, token/sec:656142.03, hellaswag_acc: 0.2708
Step:  4731, loss: 3.330805, norm: 0.2565, time(ms): 803.65, token/sec:652386.68, hellaswag_acc: 0.2708
Step:  4732, loss: 3.355110, norm: 0.2327, time(ms): 796.01, token/sec:658644.78, hellaswag_acc: 0.2708
Step:  4733, loss: 3.409178, norm: 0.2497, time(ms): 794.93, token/sec:659543.01, hellaswag_acc: 0.2708
Step:  4734, loss: 3.421572, norm: 0.2981, time(ms): 802.77, token/sec:653096.79, hellaswag_acc: 0.2708
Step:  4735, loss: 3.364230, norm: 0.3429, time(ms): 804.22, token/sec:651920.95, hellaswag_acc: 0.2708
Step:  4736, loss: 3.380388, norm: 0.2932, time(ms): 792.39, token/sec:661655.68, hellaswag_acc: 0.2708
Step:  4737, loss: 3.417178, norm: 0.3271, time(ms): 797.21, token/sec:657651.22, hellaswag_acc: 0.2708
Step:  4738, loss: 3.394558, norm: 0.3476, time(ms): 792.30, token/sec:661728.76, hellaswag_acc: 0.2708
Step:  4739, loss: 3.412586, norm: 0.3309, time(ms): 795.36, token/sec:659179.83, hellaswag_acc: 0.2708
Step:  4740, loss: 3.400398, norm: 0.2738, time(ms): 797.94, token/sec:657055.63, hellaswag_acc: 0.2708
Step:  4741, loss: 3.377237, norm: 0.3021, time(ms): 801.01, token/sec:654531.60, hellaswag_acc: 0.2708
Step:  4742, loss: 3.361818, norm: 0.2827, time(ms): 798.61, token/sec:656503.63, hellaswag_acc: 0.2708
Step:  4743, loss: 3.358466, norm: 0.2817, time(ms): 795.85, token/sec:658776.98, hellaswag_acc: 0.2708
Step:  4744, loss: 3.377031, norm: 0.2893, time(ms): 788.80, token/sec:664663.30, hellaswag_acc: 0.2708
Step:  4745, loss: 3.356619, norm: 0.3027, time(ms): 794.00, token/sec:660314.20, hellaswag_acc: 0.2708
Step:  4746, loss: 3.292398, norm: 0.2728, time(ms): 787.19, token/sec:666026.77, hellaswag_acc: 0.2708
Step:  4747, loss: 3.318884, norm: 0.2582, time(ms): 790.06, token/sec:663606.06, hellaswag_acc: 0.2708
Step:  4748, loss: 3.356555, norm: 0.2628, time(ms): 807.01, token/sec:649666.00, hellaswag_acc: 0.2708
Step:  4749, loss: 3.304167, norm: 0.2873, time(ms): 791.95, token/sec:662019.81, hellaswag_acc: 0.2708
rank 0 sample 0: Hello, I'm a language model, and I don't understand, because we really only talk about language; let's talk, why should you do that?
rank 0 sample 1: Hello, I'm a language model, so why not? I'm just making a new batch variable, so that we can get an object at runtime. That
rank 0 sample 2: Hello, I'm a language model, I'm familiar with other languages, which are quite different from your English.
You're familiar with the English word form
rank 0 sample 3: Hello, I'm a language model, not what I'm talking about, I've spent a lot of time with people when I do things I'm talking —
rank 1 sample 0: Hello, I'm a language model, "what is the most common language first" [http://web.uu.edu/en/courses/
rank 1 sample 1: Hello, I'm a language model, you know how to write a language like your own. To write a language, you follow a command.
If you
rank 1 sample 2: Hello, I'm a language model, so are there any other languages that I can use? Well...I have a language model. The one I like best
rank 1 sample 3: Hello, I'm a language model, and I'm using it so I am asking you to choose my answer or comment. Now, let's say you're
Step:  4750, loss: 3.367949, norm: 0.2639, time(ms): 3857.12, token/sec:135927.42, val_loss: 3.3674, hellaswag_acc: 0.2708
Step:  4751, loss: 3.296351, norm: 0.2586, time(ms): 785.51, token/sec:667449.93, hellaswag_acc: 0.2708
Step:  4752, loss: 3.334406, norm: 0.2484, time(ms): 793.37, token/sec:660839.06, hellaswag_acc: 0.2708
Step:  4753, loss: 3.278476, norm: 0.2595, time(ms): 792.09, token/sec:661904.43, hellaswag_acc: 0.2708
Step:  4754, loss: 3.318430, norm: 0.2576, time(ms): 792.51, token/sec:661557.75, hellaswag_acc: 0.2708
Step:  4755, loss: 3.359688, norm: 0.2707, time(ms): 787.47, token/sec:665791.04, hellaswag_acc: 0.2708
Step:  4756, loss: 3.309968, norm: 0.2893, time(ms): 790.37, token/sec:663349.03, hellaswag_acc: 0.2708
Step:  4757, loss: 3.259754, norm: 0.2906, time(ms): 808.08, token/sec:648806.32, hellaswag_acc: 0.2708
Step:  4758, loss: 3.213041, norm: 0.2744, time(ms): 791.99, token/sec:661986.13, hellaswag_acc: 0.2708
Step:  4759, loss: 3.216681, norm: 0.2971, time(ms): 792.15, token/sec:661852.24, hellaswag_acc: 0.2708
Step:  4760, loss: 3.226091, norm: 0.2737, time(ms): 787.37, token/sec:665874.71, hellaswag_acc: 0.2708
Step:  4761, loss: 3.204066, norm: 0.2773, time(ms): 790.86, token/sec:662936.67, hellaswag_acc: 0.2708
Step:  4762, loss: 3.367041, norm: 0.2683, time(ms): 1281.50, token/sec:409119.16, hellaswag_acc: 0.2708
Step:  4763, loss: 3.306002, norm: 0.2710, time(ms): 798.56, token/sec:656544.21, hellaswag_acc: 0.2708
Step:  4764, loss: 3.288313, norm: 0.2786, time(ms): 789.34, token/sec:664207.18, hellaswag_acc: 0.2708
Step:  4765, loss: 3.414124, norm: 0.2644, time(ms): 778.86, token/sec:673151.15, hellaswag_acc: 0.2708
Step:  4766, loss: 3.306402, norm: 0.2544, time(ms): 796.16, token/sec:658524.66, hellaswag_acc: 0.2708
Step:  4767, loss: 3.282251, norm: 0.2398, time(ms): 794.06, token/sec:660259.48, hellaswag_acc: 0.2708
Step:  4768, loss: 3.300117, norm: 0.2680, time(ms): 795.27, token/sec:659255.32, hellaswag_acc: 0.2708
Step:  4769, loss: 3.322099, norm: 0.2910, time(ms): 791.72, token/sec:662209.80, hellaswag_acc: 0.2708
Step:  4770, loss: 3.341198, norm: 0.2621, time(ms): 789.34, token/sec:664209.39, hellaswag_acc: 0.2708
Step:  4771, loss: 3.333852, norm: 0.2581, time(ms): 793.63, token/sec:660620.88, hellaswag_acc: 0.2708
Step:  4772, loss: 3.299306, norm: 0.2773, time(ms): 792.57, token/sec:661502.82, hellaswag_acc: 0.2708
Step:  4773, loss: 3.347449, norm: 0.2598, time(ms): 794.90, token/sec:659566.36, hellaswag_acc: 0.2708
Step:  4774, loss: 3.336881, norm: 0.2767, time(ms): 790.97, token/sec:662843.55, hellaswag_acc: 0.2708
Step:  4775, loss: 3.436811, norm: 0.2855, time(ms): 790.73, token/sec:663042.81, hellaswag_acc: 0.2708
Step:  4776, loss: 3.382602, norm: 0.3047, time(ms): 796.14, token/sec:658538.86, hellaswag_acc: 0.2708
Step:  4777, loss: 3.364543, norm: 0.3139, time(ms): 794.83, token/sec:659623.93, hellaswag_acc: 0.2708
Step:  4778, loss: 3.339085, norm: 0.3242, time(ms): 796.71, token/sec:658067.66, hellaswag_acc: 0.2708
Step:  4779, loss: 3.457818, norm: 0.3627, time(ms): 789.58, token/sec:664008.22, hellaswag_acc: 0.2708
Step:  4780, loss: 3.413093, norm: 0.2747, time(ms): 793.12, token/sec:661046.26, hellaswag_acc: 0.2708
Step:  4781, loss: 3.399916, norm: 0.2763, time(ms): 791.46, token/sec:662430.63, hellaswag_acc: 0.2708
Step:  4782, loss: 3.427973, norm: 0.2816, time(ms): 791.32, token/sec:662546.39, hellaswag_acc: 0.2708
Step:  4783, loss: 3.439530, norm: 0.2901, time(ms): 801.75, token/sec:653926.46, hellaswag_acc: 0.2708
Step:  4784, loss: 3.386854, norm: 0.3027, time(ms): 803.02, token/sec:652898.23, hellaswag_acc: 0.2708
Step:  4785, loss: 3.429620, norm: 0.2936, time(ms): 796.53, token/sec:658218.55, hellaswag_acc: 0.2708
Step:  4786, loss: 3.400098, norm: 0.3015, time(ms): 798.55, token/sec:656549.30, hellaswag_acc: 0.2708
Step:  4787, loss: 3.396727, norm: 0.2769, time(ms): 802.85, token/sec:653035.89, hellaswag_acc: 0.2708
Step:  4788, loss: 3.452096, norm: 0.2869, time(ms): 798.79, token/sec:656351.18, hellaswag_acc: 0.2708
Step:  4789, loss: 3.416774, norm: 0.3074, time(ms): 793.80, token/sec:660479.01, hellaswag_acc: 0.2708
Step:  4790, loss: 3.381435, norm: 0.2812, time(ms): 800.20, token/sec:655194.07, hellaswag_acc: 0.2708
Step:  4791, loss: 3.367379, norm: 0.2989, time(ms): 807.34, token/sec:649397.79, hellaswag_acc: 0.2708
Step:  4792, loss: 3.435022, norm: 0.2728, time(ms): 797.52, token/sec:657397.41, hellaswag_acc: 0.2708
Step:  4793, loss: 3.437884, norm: 0.3119, time(ms): 785.93, token/sec:667090.94, hellaswag_acc: 0.2708
Step:  4794, loss: 3.483732, norm: 0.2654, time(ms): 793.41, token/sec:660802.72, hellaswag_acc: 0.2708
Step:  4795, loss: 3.377132, norm: 0.2904, time(ms): 792.76, token/sec:661341.88, hellaswag_acc: 0.2708
Step:  4796, loss: 3.413921, norm: 0.3022, time(ms): 791.45, token/sec:662437.41, hellaswag_acc: 0.2708
Step:  4797, loss: 3.336247, norm: 0.2851, time(ms): 793.59, token/sec:660651.25, hellaswag_acc: 0.2708
Step:  4798, loss: 3.361829, norm: 0.2702, time(ms): 795.50, token/sec:659067.42, hellaswag_acc: 0.2708
Step:  4799, loss: 3.396041, norm: 0.2514, time(ms): 802.83, token/sec:653052.95, hellaswag_acc: 0.2708
Step:  4800, loss: 3.373246, norm: 0.2652, time(ms): 797.39, token/sec:657507.09, hellaswag_acc: 0.2708
Step:  4801, loss: 3.327775, norm: 0.2570, time(ms): 794.76, token/sec:659683.69, hellaswag_acc: 0.2708
Step:  4802, loss: 3.380542, norm: 0.2571, time(ms): 793.52, token/sec:660713.57, hellaswag_acc: 0.2708
Step:  4803, loss: 3.381955, norm: 0.2659, time(ms): 793.88, token/sec:660408.99, hellaswag_acc: 0.2708
Step:  4804, loss: 3.345541, norm: 0.2656, time(ms): 799.15, token/sec:656057.46, hellaswag_acc: 0.2708
Step:  4805, loss: 3.328886, norm: 0.2544, time(ms): 801.37, token/sec:654237.94, hellaswag_acc: 0.2708
Step:  4806, loss: 3.302012, norm: 0.2495, time(ms): 794.83, token/sec:659622.54, hellaswag_acc: 0.2708
Step:  4807, loss: 3.361264, norm: 0.2542, time(ms): 790.47, token/sec:663265.20, hellaswag_acc: 0.2708
Step:  4808, loss: 3.382108, norm: 0.2536, time(ms): 789.62, token/sec:663971.13, hellaswag_acc: 0.2708
Step:  4809, loss: 3.309060, norm: 0.2760, time(ms): 789.21, token/sec:664321.75, hellaswag_acc: 0.2708
Step:  4810, loss: 3.341389, norm: 0.3038, time(ms): 796.14, token/sec:658534.72, hellaswag_acc: 0.2708
Step:  4811, loss: 3.317672, norm: 0.2878, time(ms): 800.58, token/sec:654886.16, hellaswag_acc: 0.2708
Step:  4812, loss: 3.374618, norm: 0.2799, time(ms): 803.06, token/sec:652861.79, hellaswag_acc: 0.2708
Step:  4813, loss: 3.358980, norm: 0.2852, time(ms): 799.81, token/sec:655518.67, hellaswag_acc: 0.2708
Step:  4814, loss: 3.320908, norm: 0.2648, time(ms): 797.30, token/sec:657580.62, hellaswag_acc: 0.2708
Step:  4815, loss: 3.339673, norm: 0.2659, time(ms): 801.67, token/sec:653994.34, hellaswag_acc: 0.2708
Step:  4816, loss: 3.364394, norm: 0.3022, time(ms): 798.74, token/sec:656397.22, hellaswag_acc: 0.2708
Step:  4817, loss: 3.343634, norm: 0.3045, time(ms): 793.67, token/sec:660590.91, hellaswag_acc: 0.2708
Step:  4818, loss: 3.285470, norm: 0.3265, time(ms): 806.63, token/sec:649977.27, hellaswag_acc: 0.2708
Step:  4819, loss: 3.336189, norm: 0.3083, time(ms): 800.46, token/sec:654981.94, hellaswag_acc: 0.2708
Step:  4820, loss: 3.332701, norm: 0.2788, time(ms): 798.49, token/sec:656600.86, hellaswag_acc: 0.2708
Step:  4821, loss: 3.422408, norm: 0.3225, time(ms): 794.97, token/sec:659503.45, hellaswag_acc: 0.2708
Step:  4822, loss: 3.417202, norm: 0.2860, time(ms): 806.52, token/sec:650059.51, hellaswag_acc: 0.2708
Step:  4823, loss: 3.411740, norm: 0.2734, time(ms): 797.13, token/sec:657718.89, hellaswag_acc: 0.2708
Step:  4824, loss: 3.425133, norm: 0.2799, time(ms): 803.30, token/sec:652671.31, hellaswag_acc: 0.2708
Step:  4825, loss: 3.383203, norm: 0.2728, time(ms): 791.57, token/sec:662337.85, hellaswag_acc: 0.2708
Step:  4826, loss: 3.464972, norm: 0.2887, time(ms): 806.08, token/sec:650418.10, hellaswag_acc: 0.2708
Step:  4827, loss: 3.365343, norm: 0.3183, time(ms): 801.77, token/sec:653911.30, hellaswag_acc: 0.2708
Step:  4828, loss: 3.359133, norm: 0.2799, time(ms): 793.47, token/sec:660750.30, hellaswag_acc: 0.2708
Step:  4829, loss: 3.400466, norm: 0.2854, time(ms): 803.98, token/sec:652118.92, hellaswag_acc: 0.2708
Step:  4830, loss: 3.361014, norm: 0.2585, time(ms): 800.68, token/sec:654801.14, hellaswag_acc: 0.2708
Step:  4831, loss: 3.395806, norm: 0.2456, time(ms): 792.59, token/sec:661486.71, hellaswag_acc: 0.2708
Step:  4832, loss: 3.376924, norm: 0.2992, time(ms): 803.94, token/sec:652144.45, hellaswag_acc: 0.2708
Step:  4833, loss: 3.321515, norm: 0.3444, time(ms): 803.44, token/sec:652557.81, hellaswag_acc: 0.2708
Step:  4834, loss: 3.358879, norm: 0.3170, time(ms): 794.27, token/sec:660092.01, hellaswag_acc: 0.2708
Step:  4835, loss: 3.323674, norm: 0.2738, time(ms): 800.83, token/sec:654680.67, hellaswag_acc: 0.2708
Step:  4836, loss: 3.319400, norm: 0.3115, time(ms): 804.63, token/sec:651585.81, hellaswag_acc: 0.2708
Step:  4837, loss: 3.333362, norm: 0.2755, time(ms): 800.65, token/sec:654828.05, hellaswag_acc: 0.2708
Step:  4838, loss: 3.325790, norm: 0.2984, time(ms): 796.73, token/sec:658046.79, hellaswag_acc: 0.2708
Step:  4839, loss: 3.311555, norm: 0.3117, time(ms): 797.91, token/sec:657077.42, hellaswag_acc: 0.2708
Step:  4840, loss: 3.338256, norm: 0.2558, time(ms): 804.21, token/sec:651929.26, hellaswag_acc: 0.2708
Step:  4841, loss: 3.334891, norm: 0.2654, time(ms): 797.92, token/sec:657067.99, hellaswag_acc: 0.2708
Step:  4842, loss: 3.355427, norm: 0.2762, time(ms): 796.86, token/sec:657940.87, hellaswag_acc: 0.2708
Step:  4843, loss: 3.298371, norm: 0.2685, time(ms): 799.89, token/sec:655448.14, hellaswag_acc: 0.2708
Step:  4844, loss: 3.352015, norm: 0.2582, time(ms): 805.53, token/sec:650858.17, hellaswag_acc: 0.2708
Step:  4845, loss: 3.357878, norm: 0.2556, time(ms): 797.21, token/sec:657656.34, hellaswag_acc: 0.2708
Step:  4846, loss: 3.300749, norm: 0.2849, time(ms): 794.59, token/sec:659820.07, hellaswag_acc: 0.2708
Step:  4847, loss: 3.322492, norm: 0.2808, time(ms): 805.49, token/sec:650893.04, hellaswag_acc: 0.2708
Step:  4848, loss: 3.386214, norm: 0.2725, time(ms): 794.23, token/sec:660121.33, hellaswag_acc: 0.2708
Step:  4849, loss: 3.336611, norm: 0.2548, time(ms): 801.60, token/sec:654049.38, hellaswag_acc: 0.2708
Step:  4850, loss: 3.330665, norm: 0.2548, time(ms): 802.60, token/sec:653235.12, hellaswag_acc: 0.2708
Step:  4851, loss: 3.332493, norm: 0.2486, time(ms): 802.78, token/sec:653092.91, hellaswag_acc: 0.2708
Step:  4852, loss: 3.305807, norm: 0.2455, time(ms): 786.71, token/sec:666431.87, hellaswag_acc: 0.2708
Step:  4853, loss: 3.377915, norm: 0.2660, time(ms): 790.48, token/sec:663255.59, hellaswag_acc: 0.2708
Step:  4854, loss: 3.353994, norm: 0.2629, time(ms): 794.20, token/sec:660142.54, hellaswag_acc: 0.2708
Step:  4855, loss: 3.345831, norm: 0.2537, time(ms): 792.18, token/sec:661827.74, hellaswag_acc: 0.2708
Step:  4856, loss: 3.404068, norm: 0.2629, time(ms): 793.30, token/sec:660897.65, hellaswag_acc: 0.2708
Step:  4857, loss: 3.378776, norm: 0.2638, time(ms): 797.61, token/sec:657326.08, hellaswag_acc: 0.2708
Step:  4858, loss: 3.422986, norm: 0.3073, time(ms): 800.22, token/sec:655179.82, hellaswag_acc: 0.2708
Step:  4859, loss: 3.446815, norm: 0.2863, time(ms): 802.54, token/sec:653283.05, hellaswag_acc: 0.2708
Step:  4860, loss: 3.375213, norm: 0.2551, time(ms): 796.68, token/sec:658093.46, hellaswag_acc: 0.2708
Step:  4861, loss: 3.364736, norm: 0.2712, time(ms): 800.59, token/sec:654876.02, hellaswag_acc: 0.2708
Step:  4862, loss: 3.389277, norm: 0.2773, time(ms): 795.75, token/sec:658856.72, hellaswag_acc: 0.2708
Step:  4863, loss: 3.348799, norm: 0.2690, time(ms): 803.40, token/sec:652583.57, hellaswag_acc: 0.2708
Step:  4864, loss: 3.373144, norm: 0.2651, time(ms): 803.32, token/sec:652652.13, hellaswag_acc: 0.2708
Step:  4865, loss: 3.360680, norm: 0.2590, time(ms): 796.70, token/sec:658074.36, hellaswag_acc: 0.2708
Step:  4866, loss: 3.475146, norm: 0.2571, time(ms): 800.83, token/sec:654678.72, hellaswag_acc: 0.2708
Step:  4867, loss: 3.356943, norm: 0.2680, time(ms): 798.05, token/sec:656962.78, hellaswag_acc: 0.2708
Step:  4868, loss: 3.413304, norm: 0.2801, time(ms): 804.08, token/sec:652038.29, hellaswag_acc: 0.2708
Step:  4869, loss: 3.337043, norm: 0.2863, time(ms): 795.92, token/sec:658721.92, hellaswag_acc: 0.2708
Step:  4870, loss: 3.377229, norm: 0.2591, time(ms): 800.67, token/sec:654813.04, hellaswag_acc: 0.2708
Step:  4871, loss: 3.414628, norm: 0.2494, time(ms): 795.29, token/sec:659239.91, hellaswag_acc: 0.2708
Step:  4872, loss: 3.329099, norm: 0.2535, time(ms): 802.64, token/sec:653203.29, hellaswag_acc: 0.2708
Step:  4873, loss: 3.323067, norm: 0.2622, time(ms): 799.91, token/sec:655430.95, hellaswag_acc: 0.2708
Step:  4874, loss: 3.307205, norm: 0.2605, time(ms): 795.91, token/sec:658729.22, hellaswag_acc: 0.2708
Step:  4875, loss: 3.330877, norm: 0.2779, time(ms): 798.70, token/sec:656430.53, hellaswag_acc: 0.2708
Step:  4876, loss: 3.236247, norm: 0.2774, time(ms): 792.13, token/sec:661871.56, hellaswag_acc: 0.2708
Step:  4877, loss: 3.334316, norm: 0.2734, time(ms): 794.53, token/sec:659868.38, hellaswag_acc: 0.2708
Step:  4878, loss: 3.340702, norm: 0.2854, time(ms): 790.61, token/sec:663142.99, hellaswag_acc: 0.2708
Step:  4879, loss: 3.354282, norm: 0.2985, time(ms): 787.41, token/sec:665834.59, hellaswag_acc: 0.2708
Step:  4880, loss: 3.371395, norm: 0.2865, time(ms): 795.41, token/sec:659143.08, hellaswag_acc: 0.2708
Step:  4881, loss: 3.346995, norm: 0.2656, time(ms): 793.22, token/sec:660957.64, hellaswag_acc: 0.2708
Step:  4882, loss: 3.297007, norm: 0.2783, time(ms): 789.38, token/sec:664181.10, hellaswag_acc: 0.2708
Step:  4883, loss: 3.379571, norm: 0.2610, time(ms): 803.17, token/sec:652773.41, hellaswag_acc: 0.2708
Step:  4884, loss: 3.421820, norm: 0.2732, time(ms): 802.93, token/sec:652971.90, hellaswag_acc: 0.2708
Step:  4885, loss: 3.375392, norm: 0.2801, time(ms): 795.50, token/sec:659063.66, hellaswag_acc: 0.2708
Step:  4886, loss: 3.362850, norm: 0.3011, time(ms): 797.12, token/sec:657730.30, hellaswag_acc: 0.2708
Step:  4887, loss: 3.325625, norm: 0.2681, time(ms): 805.38, token/sec:650980.52, hellaswag_acc: 0.2708
Step:  4888, loss: 3.364230, norm: 0.2684, time(ms): 798.82, token/sec:656327.48, hellaswag_acc: 0.2708
Step:  4889, loss: 3.336381, norm: 0.2755, time(ms): 802.06, token/sec:653672.99, hellaswag_acc: 0.2708
Step:  4890, loss: 3.338822, norm: 0.2993, time(ms): 798.18, token/sec:656858.18, hellaswag_acc: 0.2708
Step:  4891, loss: 3.416182, norm: 0.2878, time(ms): 796.12, token/sec:658557.20, hellaswag_acc: 0.2708
Step:  4892, loss: 3.475252, norm: 0.3219, time(ms): 802.95, token/sec:652953.67, hellaswag_acc: 0.2708
Step:  4893, loss: 3.394259, norm: 0.3301, time(ms): 802.66, token/sec:653186.22, hellaswag_acc: 0.2708
Step:  4894, loss: 3.401959, norm: 0.2869, time(ms): 790.89, token/sec:662909.69, hellaswag_acc: 0.2708
Step:  4895, loss: 3.387250, norm: 0.2687, time(ms): 798.35, token/sec:656714.39, hellaswag_acc: 0.2708
Step:  4896, loss: 3.434393, norm: 0.2617, time(ms): 807.68, token/sec:649125.77, hellaswag_acc: 0.2708
Step:  4897, loss: 3.365614, norm: 0.2701, time(ms): 799.67, token/sec:655629.29, hellaswag_acc: 0.2708
Step:  4898, loss: 3.397521, norm: 0.2458, time(ms): 786.41, token/sec:666682.81, hellaswag_acc: 0.2708
Step:  4899, loss: 3.448234, norm: 0.2557, time(ms): 790.58, token/sec:663169.58, hellaswag_acc: 0.2708
Step:  4900, loss: 3.352969, norm: 0.2870, time(ms): 794.61, token/sec:659809.18, hellaswag_acc: 0.2708
Step:  4901, loss: 3.419881, norm: 0.2676, time(ms): 791.99, token/sec:661991.91, hellaswag_acc: 0.2708
Step:  4902, loss: 3.344001, norm: 0.2911, time(ms): 787.07, token/sec:666130.27, hellaswag_acc: 0.2708
Step:  4903, loss: 3.273989, norm: 0.3072, time(ms): 794.06, token/sec:660264.44, hellaswag_acc: 0.2708
Step:  4904, loss: 3.369089, norm: 0.2999, time(ms): 796.09, token/sec:658580.08, hellaswag_acc: 0.2708
Step:  4905, loss: 3.322490, norm: 0.2759, time(ms): 788.56, token/sec:664864.06, hellaswag_acc: 0.2708
Step:  4906, loss: 3.319608, norm: 0.2793, time(ms): 789.70, token/sec:663906.18, hellaswag_acc: 0.2708
Step:  4907, loss: 3.321784, norm: 0.2870, time(ms): 792.07, token/sec:661919.18, hellaswag_acc: 0.2708
Step:  4908, loss: 3.281726, norm: 0.2777, time(ms): 785.95, token/sec:667074.35, hellaswag_acc: 0.2708
Step:  4909, loss: 3.311688, norm: 0.2805, time(ms): 794.86, token/sec:659601.77, hellaswag_acc: 0.2708
Step:  4910, loss: 3.334998, norm: 0.2698, time(ms): 808.03, token/sec:648846.33, hellaswag_acc: 0.2708
Step:  4911, loss: 3.399421, norm: 0.2491, time(ms): 800.09, token/sec:655287.98, hellaswag_acc: 0.2708
Step:  4912, loss: 3.342422, norm: 0.2533, time(ms): 783.97, token/sec:668757.54, hellaswag_acc: 0.2708
Step:  4913, loss: 3.303953, norm: 0.2569, time(ms): 788.90, token/sec:664581.15, hellaswag_acc: 0.2708
Step:  4914, loss: 3.393131, norm: 0.2554, time(ms): 790.41, token/sec:663308.81, hellaswag_acc: 0.2708
Step:  4915, loss: 3.354048, norm: 0.2595, time(ms): 795.53, token/sec:659039.37, hellaswag_acc: 0.2708
Step:  4916, loss: 3.392105, norm: 0.2599, time(ms): 790.58, token/sec:663166.38, hellaswag_acc: 0.2708
Step:  4917, loss: 3.420422, norm: 0.3762, time(ms): 797.58, token/sec:657347.89, hellaswag_acc: 0.2708
Step:  4918, loss: 3.373731, norm: 0.3840, time(ms): 793.17, token/sec:661002.94, hellaswag_acc: 0.2708
Step:  4919, loss: 3.391251, norm: 0.3524, time(ms): 790.86, token/sec:662937.87, hellaswag_acc: 0.2708
Step:  4920, loss: 3.326754, norm: 0.3347, time(ms): 795.61, token/sec:658977.36, hellaswag_acc: 0.2708
Step:  4921, loss: 3.469860, norm: 0.3202, time(ms): 787.85, token/sec:665469.88, hellaswag_acc: 0.2708
Step:  4922, loss: 3.409025, norm: 0.2805, time(ms): 792.69, token/sec:661400.56, hellaswag_acc: 0.2708
Step:  4923, loss: 3.353510, norm: 0.3010, time(ms): 791.89, token/sec:662072.43, hellaswag_acc: 0.2708
Step:  4924, loss: 3.398515, norm: 0.2769, time(ms): 785.81, token/sec:667195.38, hellaswag_acc: 0.2708
Step:  4925, loss: 3.337827, norm: 0.2909, time(ms): 787.77, token/sec:665530.90, hellaswag_acc: 0.2708
Step:  4926, loss: 3.390829, norm: 0.3168, time(ms): 795.37, token/sec:659177.46, hellaswag_acc: 0.2708
Step:  4927, loss: 3.416924, norm: 0.3321, time(ms): 791.32, token/sec:662545.39, hellaswag_acc: 0.2708
Step:  4928, loss: 3.395380, norm: 0.2727, time(ms): 789.79, token/sec:663831.63, hellaswag_acc: 0.2708
Step:  4929, loss: 3.409446, norm: 0.2921, time(ms): 802.36, token/sec:653431.55, hellaswag_acc: 0.2708
Step:  4930, loss: 3.402836, norm: 0.2995, time(ms): 804.09, token/sec:652026.30, hellaswag_acc: 0.2708
Step:  4931, loss: 3.426898, norm: 0.2709, time(ms): 798.58, token/sec:656528.33, hellaswag_acc: 0.2708
Step:  4932, loss: 3.371748, norm: 0.3195, time(ms): 793.07, token/sec:661087.59, hellaswag_acc: 0.2708
Step:  4933, loss: 3.468312, norm: 0.3016, time(ms): 799.72, token/sec:655586.48, hellaswag_acc: 0.2708
Step:  4934, loss: 3.392893, norm: 0.2706, time(ms): 800.29, token/sec:655124.97, hellaswag_acc: 0.2708
Step:  4935, loss: 3.395459, norm: 0.2943, time(ms): 794.52, token/sec:659876.10, hellaswag_acc: 0.2708
Step:  4936, loss: 3.367198, norm: 0.2990, time(ms): 794.09, token/sec:660234.90, hellaswag_acc: 0.2708
Step:  4937, loss: 3.439982, norm: 0.2862, time(ms): 791.68, token/sec:662244.50, hellaswag_acc: 0.2708
Step:  4938, loss: 3.396430, norm: 0.2772, time(ms): 795.80, token/sec:658814.68, hellaswag_acc: 0.2708
Step:  4939, loss: 3.353017, norm: 0.2719, time(ms): 790.73, token/sec:663045.81, hellaswag_acc: 0.2708
Step:  4940, loss: 3.395807, norm: 0.2562, time(ms): 791.76, token/sec:662181.88, hellaswag_acc: 0.2708
Step:  4941, loss: 3.269070, norm: 0.2586, time(ms): 789.69, token/sec:663919.61, hellaswag_acc: 0.2708
Step:  4942, loss: 3.355594, norm: 0.2592, time(ms): 790.50, token/sec:663236.59, hellaswag_acc: 0.2708
Step:  4943, loss: 3.311317, norm: 0.2689, time(ms): 808.03, token/sec:648846.71, hellaswag_acc: 0.2708
Step:  4944, loss: 3.398881, norm: 0.2499, time(ms): 790.76, token/sec:663014.82, hellaswag_acc: 0.2708
Step:  4945, loss: 3.353590, norm: 0.2768, time(ms): 791.92, token/sec:662049.91, hellaswag_acc: 0.2708
Step:  4946, loss: 3.310836, norm: 0.2614, time(ms): 786.20, token/sec:666861.53, hellaswag_acc: 0.2708
Step:  4947, loss: 3.290182, norm: 0.2944, time(ms): 789.58, token/sec:664011.03, hellaswag_acc: 0.2708
Step:  4948, loss: 3.310012, norm: 0.2724, time(ms): 800.00, token/sec:655359.65, hellaswag_acc: 0.2708
Step:  4949, loss: 3.279197, norm: 0.2773, time(ms): 795.16, token/sec:659346.25, hellaswag_acc: 0.2708
Step:  4950, loss: 3.293030, norm: 0.2929, time(ms): 800.85, token/sec:654661.37, hellaswag_acc: 0.2708
Step:  4951, loss: 3.367095, norm: 0.2462, time(ms): 804.44, token/sec:651744.74, hellaswag_acc: 0.2708
Step:  4952, loss: 3.338676, norm: 0.2715, time(ms): 1298.52, token/sec:403756.61, hellaswag_acc: 0.2708
Step:  4953, loss: 3.395705, norm: 0.2799, time(ms): 771.95, token/sec:679172.89, hellaswag_acc: 0.2708
Step:  4954, loss: 3.360000, norm: 0.2896, time(ms): 795.20, token/sec:659318.97, hellaswag_acc: 0.2708
Step:  4955, loss: 3.339870, norm: 0.2871, time(ms): 795.36, token/sec:659181.21, hellaswag_acc: 0.2708
Step:  4956, loss: 3.346374, norm: 0.3025, time(ms): 788.48, token/sec:664938.65, hellaswag_acc: 0.2708
Step:  4957, loss: 3.397903, norm: 0.2664, time(ms): 780.99, token/sec:671311.33, hellaswag_acc: 0.2708
Step:  4958, loss: 3.305041, norm: 0.2783, time(ms): 790.23, token/sec:663462.51, hellaswag_acc: 0.2708
Step:  4959, loss: 3.295380, norm: 0.2784, time(ms): 793.01, token/sec:661135.29, hellaswag_acc: 0.2708
Step:  4960, loss: 3.277046, norm: 0.2532, time(ms): 790.25, token/sec:663448.29, hellaswag_acc: 0.2708
Step:  4961, loss: 3.318639, norm: 0.2488, time(ms): 788.36, token/sec:665035.17, hellaswag_acc: 0.2708
Step:  4962, loss: 3.285905, norm: 0.2650, time(ms): 795.74, token/sec:658865.01, hellaswag_acc: 0.2708
Step:  4963, loss: 3.311753, norm: 0.2532, time(ms): 791.83, token/sec:662124.06, hellaswag_acc: 0.2708
Step:  4964, loss: 3.281535, norm: 0.2693, time(ms): 797.21, token/sec:657657.32, hellaswag_acc: 0.2708
Step:  4965, loss: 3.286928, norm: 0.2544, time(ms): 794.28, token/sec:660078.34, hellaswag_acc: 0.2708
Step:  4966, loss: 3.297578, norm: 0.2661, time(ms): 790.71, token/sec:663057.21, hellaswag_acc: 0.2708
Step:  4967, loss: 3.358629, norm: 0.3304, time(ms): 785.71, token/sec:667280.81, hellaswag_acc: 0.2708
Step:  4968, loss: 3.346995, norm: 0.3184, time(ms): 786.50, token/sec:666607.03, hellaswag_acc: 0.2708
Step:  4969, loss: 3.281031, norm: 0.2669, time(ms): 800.46, token/sec:654981.35, hellaswag_acc: 0.2708
Step:  4970, loss: 3.343985, norm: 0.3101, time(ms): 803.00, token/sec:652915.09, hellaswag_acc: 0.2708
Step:  4971, loss: 3.347354, norm: 0.3381, time(ms): 794.21, token/sec:660139.37, hellaswag_acc: 0.2708
Step:  4972, loss: 3.352435, norm: 0.3115, time(ms): 800.29, token/sec:655122.82, hellaswag_acc: 0.2708
Step:  4973, loss: 3.375189, norm: 0.3758, time(ms): 804.75, token/sec:651490.83, hellaswag_acc: 0.2708
Step:  4974, loss: 3.329496, norm: 0.3083, time(ms): 798.53, token/sec:656567.73, hellaswag_acc: 0.2708
Step:  4975, loss: 3.320886, norm: 0.2849, time(ms): 790.46, token/sec:663272.60, hellaswag_acc: 0.2708
Step:  4976, loss: 3.343240, norm: 0.2913, time(ms): 792.22, token/sec:661797.46, hellaswag_acc: 0.2708
Step:  4977, loss: 3.370330, norm: 0.2687, time(ms): 792.29, token/sec:661739.51, hellaswag_acc: 0.2708
Step:  4978, loss: 3.329367, norm: 0.2722, time(ms): 789.29, token/sec:664249.51, hellaswag_acc: 0.2708
Step:  4979, loss: 3.336735, norm: 0.2726, time(ms): 792.68, token/sec:661411.50, hellaswag_acc: 0.2708
Step:  4980, loss: 3.405508, norm: 0.2818, time(ms): 795.40, token/sec:659153.95, hellaswag_acc: 0.2708
Step:  4981, loss: 3.339218, norm: 0.2855, time(ms): 806.57, token/sec:650018.77, hellaswag_acc: 0.2708
Step:  4982, loss: 3.399460, norm: 0.2591, time(ms): 793.84, token/sec:660446.08, hellaswag_acc: 0.2708
Step:  4983, loss: 3.326412, norm: 0.2558, time(ms): 797.83, token/sec:657145.55, hellaswag_acc: 0.2708
Step:  4984, loss: 3.335234, norm: 0.2693, time(ms): 802.16, token/sec:653599.35, hellaswag_acc: 0.2708
Step:  4985, loss: 3.327210, norm: 0.2753, time(ms): 796.17, token/sec:658514.60, hellaswag_acc: 0.2708
Step:  4986, loss: 3.384261, norm: 0.2597, time(ms): 791.39, token/sec:662490.30, hellaswag_acc: 0.2708
Step:  4987, loss: 3.328794, norm: 0.2482, time(ms): 792.80, token/sec:661308.47, hellaswag_acc: 0.2708
Step:  4988, loss: 3.344673, norm: 0.2672, time(ms): 793.44, token/sec:660774.52, hellaswag_acc: 0.2708
Step:  4989, loss: 3.327058, norm: 0.2478, time(ms): 789.25, token/sec:664285.63, hellaswag_acc: 0.2708
Step:  4990, loss: 3.373294, norm: 0.2573, time(ms): 791.57, token/sec:662338.45, hellaswag_acc: 0.2708
Step:  4991, loss: 3.314391, norm: 0.2664, time(ms): 788.97, token/sec:664520.50, hellaswag_acc: 0.2708
Step:  4992, loss: 3.363385, norm: 0.2629, time(ms): 792.64, token/sec:661442.54, hellaswag_acc: 0.2708
Step:  4993, loss: 3.338781, norm: 0.2543, time(ms): 797.91, token/sec:657075.26, hellaswag_acc: 0.2708
Step:  4994, loss: 3.269672, norm: 0.2562, time(ms): 790.93, token/sec:662874.32, hellaswag_acc: 0.2708
Step:  4995, loss: 3.305992, norm: 0.2675, time(ms): 789.50, token/sec:664078.41, hellaswag_acc: 0.2708
Step:  4996, loss: 3.243116, norm: 0.2897, time(ms): 789.96, token/sec:663686.97, hellaswag_acc: 0.2708
Step:  4997, loss: 3.223950, norm: 0.2670, time(ms): 794.48, token/sec:659910.56, hellaswag_acc: 0.2708
Step:  4998, loss: 3.326798, norm: 0.3138, time(ms): 804.46, token/sec:651729.10, hellaswag_acc: 0.2708
Step:  4999, loss: 3.307356, norm: 0.2739, time(ms): 800.45, token/sec:654991.11, hellaswag_acc: 0.2708
rank 0 sample 0: Hello, I'm a language model, and I was reading this chapter on what an awesome thing about this word has to do in today's lesson, and what
rank 0 sample 1: Hello, I'm a language model, so don't worry, I'll probably be wrong? - It's something we've done over and over.
In
rank 0 sample 2: Hello, I'm a language model, so I did that while there's some problems here, and now you've got a whole lot of practice, so you
rank 0 sample 3: Hello, I'm a language model, a software program that is an object of type D.
Is "Taken "D": "Do not take that
rank 1 sample 0: Hello, I'm a language model, who was living in the city of Yere and the region now known as Southern Sudan. The book is an ancient history
rank 1 sample 1: Hello, I'm a language model, you're not gonna be able to make some sense of yourself. How's that going been done? Well, I'm
rank 1 sample 2: Hello, I'm a language model, I must know this.
I'm a language model, no. It's a language model, but I'll change
rank 1 sample 3: Hello, I'm a language model, and I'm very proud of the result there.
2. Now when you're told these things, you will be
Step:  5000, loss: 3.261734, norm: 0.2639, time(ms): 363994.02, token/sec:1440.38, val_loss: 3.3552, hellaswag_acc: 0.2768
Step:  5001, loss: 3.333830, norm: 0.2977, time(ms): 794.88, token/sec:659578.23, hellaswag_acc: 0.2768
Step:  5002, loss: 3.348510, norm: 0.2874, time(ms): 795.35, token/sec:659195.64, hellaswag_acc: 0.2768
Step:  5003, loss: 3.267401, norm: 0.2676, time(ms): 799.56, token/sec:655720.00, hellaswag_acc: 0.2768
Step:  5004, loss: 3.403799, norm: 0.4030, time(ms): 794.54, token/sec:659860.26, hellaswag_acc: 0.2768
Step:  5005, loss: 3.308208, norm: 0.3702, time(ms): 804.12, token/sec:651999.82, hellaswag_acc: 0.2768
Step:  5006, loss: 3.403657, norm: 0.3961, time(ms): 799.88, token/sec:655454.58, hellaswag_acc: 0.2768
Step:  5007, loss: 3.373723, norm: 0.3471, time(ms): 790.80, token/sec:662985.84, hellaswag_acc: 0.2768
Step:  5008, loss: 3.356421, norm: 0.2862, time(ms): 792.88, token/sec:661246.23, hellaswag_acc: 0.2768
Step:  5009, loss: 3.348319, norm: 0.3172, time(ms): 794.20, token/sec:660143.73, hellaswag_acc: 0.2768
Step:  5010, loss: 3.403365, norm: 0.3020, time(ms): 789.50, token/sec:664077.40, hellaswag_acc: 0.2768
Step:  5011, loss: 3.345416, norm: 0.2933, time(ms): 789.33, token/sec:664220.42, hellaswag_acc: 0.2768
Step:  5012, loss: 3.400780, norm: 0.2810, time(ms): 803.73, token/sec:652317.98, hellaswag_acc: 0.2768
Step:  5013, loss: 3.368455, norm: 0.3059, time(ms): 794.11, token/sec:660218.25, hellaswag_acc: 0.2768
Step:  5014, loss: 3.346560, norm: 0.2801, time(ms): 799.13, token/sec:656074.49, hellaswag_acc: 0.2768
Step:  5015, loss: 3.281942, norm: 0.2657, time(ms): 804.35, token/sec:651815.25, hellaswag_acc: 0.2768
Step:  5016, loss: 3.313338, norm: 0.2844, time(ms): 801.73, token/sec:653945.33, hellaswag_acc: 0.2768
Step:  5017, loss: 3.333850, norm: 0.2575, time(ms): 799.54, token/sec:655733.30, hellaswag_acc: 0.2768
Step:  5018, loss: 3.313126, norm: 0.2626, time(ms): 787.00, token/sec:666187.18, hellaswag_acc: 0.2768
Step:  5019, loss: 3.325360, norm: 0.3013, time(ms): 791.26, token/sec:662597.09, hellaswag_acc: 0.2768
Step:  5020, loss: 3.382143, norm: 0.2857, time(ms): 799.06, token/sec:656127.73, hellaswag_acc: 0.2768
Step:  5021, loss: 3.394427, norm: 0.3008, time(ms): 788.80, token/sec:664665.11, hellaswag_acc: 0.2768
Step:  5022, loss: 3.339541, norm: 0.3076, time(ms): 790.67, token/sec:663091.00, hellaswag_acc: 0.2768
Step:  5023, loss: 3.330319, norm: 0.2645, time(ms): 800.64, token/sec:654833.90, hellaswag_acc: 0.2768
Step:  5024, loss: 3.435790, norm: 0.3167, time(ms): 798.95, token/sec:656219.17, hellaswag_acc: 0.2768
Step:  5025, loss: 3.340008, norm: 0.2640, time(ms): 799.57, token/sec:655714.72, hellaswag_acc: 0.2768
Step:  5026, loss: 3.343431, norm: 0.2820, time(ms): 798.46, token/sec:656625.96, hellaswag_acc: 0.2768
Step:  5027, loss: 3.342498, norm: 0.2814, time(ms): 803.00, token/sec:652915.09, hellaswag_acc: 0.2768
Step:  5028, loss: 3.349183, norm: 0.2428, time(ms): 800.03, token/sec:655336.21, hellaswag_acc: 0.2768
Step:  5029, loss: 3.325817, norm: 0.2756, time(ms): 792.29, token/sec:661739.11, hellaswag_acc: 0.2768
Step:  5030, loss: 3.264559, norm: 0.2885, time(ms): 805.82, token/sec:650629.59, hellaswag_acc: 0.2768
Step:  5031, loss: 3.276126, norm: 0.2678, time(ms): 802.53, token/sec:653293.53, hellaswag_acc: 0.2768
Step:  5032, loss: 3.323040, norm: 0.2804, time(ms): 792.76, token/sec:661341.88, hellaswag_acc: 0.2768
Step:  5033, loss: 3.370046, norm: 0.3190, time(ms): 799.31, token/sec:655927.91, hellaswag_acc: 0.2768
Step:  5034, loss: 3.308129, norm: 0.3177, time(ms): 805.90, token/sec:650560.29, hellaswag_acc: 0.2768
Step:  5035, loss: 3.320450, norm: 0.2855, time(ms): 798.18, token/sec:656857.01, hellaswag_acc: 0.2768
Step:  5036, loss: 3.251036, norm: 0.2710, time(ms): 792.40, token/sec:661643.74, hellaswag_acc: 0.2768
Step:  5037, loss: 3.304198, norm: 0.2588, time(ms): 799.29, token/sec:655940.63, hellaswag_acc: 0.2768
Step:  5038, loss: 3.334912, norm: 0.2669, time(ms): 794.07, token/sec:660255.91, hellaswag_acc: 0.2768
Step:  5039, loss: 3.297263, norm: 0.2595, time(ms): 792.80, token/sec:661314.43, hellaswag_acc: 0.2768
Step:  5040, loss: 3.262633, norm: 0.2629, time(ms): 802.55, token/sec:653276.45, hellaswag_acc: 0.2768
Step:  5041, loss: 3.338680, norm: 0.2773, time(ms): 796.74, token/sec:658038.52, hellaswag_acc: 0.2768
Step:  5042, loss: 3.348564, norm: 0.2423, time(ms): 801.32, token/sec:654279.60, hellaswag_acc: 0.2768
Step:  5043, loss: 3.297189, norm: 0.2494, time(ms): 798.85, token/sec:656305.74, hellaswag_acc: 0.2768
Step:  5044, loss: 3.402062, norm: 0.2849, time(ms): 798.80, token/sec:656347.66, hellaswag_acc: 0.2768
Step:  5045, loss: 3.329396, norm: 0.2941, time(ms): 801.81, token/sec:653876.88, hellaswag_acc: 0.2768
Step:  5046, loss: 3.357949, norm: 0.2838, time(ms): 801.12, token/sec:654445.50, hellaswag_acc: 0.2768
Step:  5047, loss: 3.393850, norm: 0.2561, time(ms): 798.09, token/sec:656926.67, hellaswag_acc: 0.2768
Step:  5048, loss: 3.319650, norm: 0.2741, time(ms): 797.03, token/sec:657800.15, hellaswag_acc: 0.2768
Step:  5049, loss: 3.302829, norm: 0.2627, time(ms): 804.57, token/sec:651639.29, hellaswag_acc: 0.2768
Step:  5050, loss: 3.350195, norm: 0.2606, time(ms): 799.82, token/sec:655505.38, hellaswag_acc: 0.2768
Step:  5051, loss: 3.361721, norm: 0.2463, time(ms): 796.99, token/sec:657833.60, hellaswag_acc: 0.2768
Step:  5052, loss: 3.348901, norm: 0.2511, time(ms): 800.48, token/sec:654969.65, hellaswag_acc: 0.2768
Step:  5053, loss: 3.332388, norm: 0.2618, time(ms): 794.80, token/sec:659645.10, hellaswag_acc: 0.2768
Step:  5054, loss: 3.347967, norm: 0.2554, time(ms): 799.42, token/sec:655835.97, hellaswag_acc: 0.2768
Step:  5055, loss: 3.432299, norm: 0.2599, time(ms): 792.84, token/sec:661275.85, hellaswag_acc: 0.2768
Step:  5056, loss: 3.357741, norm: 0.2821, time(ms): 787.40, token/sec:665843.66, hellaswag_acc: 0.2768
Step:  5057, loss: 3.325942, norm: 0.2635, time(ms): 791.33, token/sec:662541.20, hellaswag_acc: 0.2768
Step:  5058, loss: 3.304385, norm: 0.2560, time(ms): 792.68, token/sec:661413.09, hellaswag_acc: 0.2768
Step:  5059, loss: 3.347707, norm: 0.2662, time(ms): 800.93, token/sec:654601.54, hellaswag_acc: 0.2768
Step:  5060, loss: 3.325983, norm: 0.2503, time(ms): 801.92, token/sec:653794.06, hellaswag_acc: 0.2768
Step:  5061, loss: 3.345594, norm: 0.2528, time(ms): 799.18, token/sec:656031.23, hellaswag_acc: 0.2768
Step:  5062, loss: 3.300440, norm: 0.2516, time(ms): 800.32, token/sec:655096.08, hellaswag_acc: 0.2768
Step:  5063, loss: 3.355174, norm: 0.2357, time(ms): 799.34, token/sec:655905.02, hellaswag_acc: 0.2768
Step:  5064, loss: 3.246665, norm: 0.2902, time(ms): 800.80, token/sec:654702.30, hellaswag_acc: 0.2768
Step:  5065, loss: 3.277889, norm: 0.3043, time(ms): 797.65, token/sec:657289.73, hellaswag_acc: 0.2768
Step:  5066, loss: 3.320012, norm: 0.2794, time(ms): 801.63, token/sec:654026.43, hellaswag_acc: 0.2768
Step:  5067, loss: 3.324984, norm: 0.2862, time(ms): 800.20, token/sec:655196.60, hellaswag_acc: 0.2768
Step:  5068, loss: 3.250082, norm: 0.2607, time(ms): 790.89, token/sec:662908.49, hellaswag_acc: 0.2768
Step:  5069, loss: 3.245558, norm: 0.2712, time(ms): 807.60, token/sec:649190.74, hellaswag_acc: 0.2768
Step:  5070, loss: 3.319277, norm: 0.2727, time(ms): 802.10, token/sec:653640.73, hellaswag_acc: 0.2768
Step:  5071, loss: 3.267032, norm: 0.2604, time(ms): 790.81, token/sec:662973.45, hellaswag_acc: 0.2768
Step:  5072, loss: 3.238666, norm: 0.2471, time(ms): 800.69, token/sec:654794.51, hellaswag_acc: 0.2768
Step:  5073, loss: 3.293427, norm: 0.2711, time(ms): 808.02, token/sec:648856.86, hellaswag_acc: 0.2768
Step:  5074, loss: 3.237194, norm: 0.2433, time(ms): 796.86, token/sec:657943.23, hellaswag_acc: 0.2768
Step:  5075, loss: 3.336374, norm: 0.2664, time(ms): 793.67, token/sec:660587.74, hellaswag_acc: 0.2768
Step:  5076, loss: 3.361599, norm: 0.2763, time(ms): 806.28, token/sec:650252.88, hellaswag_acc: 0.2768
Step:  5077, loss: 3.304314, norm: 0.3040, time(ms): 801.75, token/sec:653932.88, hellaswag_acc: 0.2768
Step:  5078, loss: 3.364631, norm: 0.2766, time(ms): 799.94, token/sec:655410.04, hellaswag_acc: 0.2768
Step:  5079, loss: 3.343886, norm: 0.2920, time(ms): 794.89, token/sec:659570.51, hellaswag_acc: 0.2768
Step:  5080, loss: 3.335791, norm: 0.2873, time(ms): 803.96, token/sec:652132.84, hellaswag_acc: 0.2768
Step:  5081, loss: 3.330490, norm: 0.2644, time(ms): 799.69, token/sec:655617.95, hellaswag_acc: 0.2768
Step:  5082, loss: 3.374112, norm: 0.2649, time(ms): 795.07, token/sec:659421.97, hellaswag_acc: 0.2768
Step:  5083, loss: 3.321813, norm: 0.2662, time(ms): 800.46, token/sec:654984.08, hellaswag_acc: 0.2768
Step:  5084, loss: 3.309159, norm: 0.2532, time(ms): 804.81, token/sec:651446.05, hellaswag_acc: 0.2768
Step:  5085, loss: 3.288655, norm: 0.2332, time(ms): 798.09, token/sec:656930.20, hellaswag_acc: 0.2768
Step:  5086, loss: 3.312440, norm: 0.2616, time(ms): 794.72, token/sec:659715.55, hellaswag_acc: 0.2768
Step:  5087, loss: 3.322364, norm: 0.2849, time(ms): 804.89, token/sec:651375.24, hellaswag_acc: 0.2768
Step:  5088, loss: 3.299082, norm: 0.2967, time(ms): 801.65, token/sec:654011.26, hellaswag_acc: 0.2768
Step:  5089, loss: 3.281654, norm: 0.2869, time(ms): 788.46, token/sec:664950.71, hellaswag_acc: 0.2768
Step:  5090, loss: 3.344776, norm: 0.2748, time(ms): 791.38, token/sec:662502.47, hellaswag_acc: 0.2768
Step:  5091, loss: 3.356034, norm: 0.2804, time(ms): 789.90, token/sec:663740.46, hellaswag_acc: 0.2768
Step:  5092, loss: 3.339940, norm: 0.2569, time(ms): 790.70, token/sec:663070.60, hellaswag_acc: 0.2768
Step:  5093, loss: 3.329374, norm: 0.3096, time(ms): 796.33, token/sec:658379.95, hellaswag_acc: 0.2768
Step:  5094, loss: 3.313591, norm: 0.2613, time(ms): 795.95, token/sec:658692.72, hellaswag_acc: 0.2768
Step:  5095, loss: 3.355418, norm: 0.2796, time(ms): 804.44, token/sec:651744.55, hellaswag_acc: 0.2768
Step:  5096, loss: 3.298385, norm: 0.2895, time(ms): 801.45, token/sec:654175.27, hellaswag_acc: 0.2768
Step:  5097, loss: 3.297835, norm: 0.2400, time(ms): 797.23, token/sec:657635.69, hellaswag_acc: 0.2768
Step:  5098, loss: 3.363120, norm: 0.3163, time(ms): 792.57, token/sec:661500.64, hellaswag_acc: 0.2768
Step:  5099, loss: 3.311910, norm: 0.2907, time(ms): 793.61, token/sec:660636.16, hellaswag_acc: 0.2768
Step:  5100, loss: 3.337035, norm: 0.2994, time(ms): 796.67, token/sec:658102.52, hellaswag_acc: 0.2768
Step:  5101, loss: 3.324882, norm: 0.2495, time(ms): 795.82, token/sec:658798.49, hellaswag_acc: 0.2768
Step:  5102, loss: 3.305013, norm: 0.2742, time(ms): 795.21, token/sec:659303.94, hellaswag_acc: 0.2768
Step:  5103, loss: 3.243829, norm: 0.2493, time(ms): 796.87, token/sec:657932.20, hellaswag_acc: 0.2768
Step:  5104, loss: 3.243906, norm: 0.2633, time(ms): 789.60, token/sec:663995.59, hellaswag_acc: 0.2768
Step:  5105, loss: 3.229312, norm: 0.2501, time(ms): 788.47, token/sec:664940.46, hellaswag_acc: 0.2768
Step:  5106, loss: 3.290251, norm: 0.2845, time(ms): 787.43, token/sec:665823.30, hellaswag_acc: 0.2768
Step:  5107, loss: 3.238994, norm: 0.2794, time(ms): 803.47, token/sec:652527.61, hellaswag_acc: 0.2768
Step:  5108, loss: 3.300320, norm: 0.2722, time(ms): 798.47, token/sec:656614.78, hellaswag_acc: 0.2768
Step:  5109, loss: 3.208491, norm: 0.2551, time(ms): 802.71, token/sec:653150.13, hellaswag_acc: 0.2768
Step:  5110, loss: 3.313954, norm: 0.2797, time(ms): 792.60, token/sec:661475.17, hellaswag_acc: 0.2768
Step:  5111, loss: 3.417532, norm: 0.2712, time(ms): 806.84, token/sec:649806.14, hellaswag_acc: 0.2768
Step:  5112, loss: 3.320083, norm: 0.2843, time(ms): 800.06, token/sec:655307.11, hellaswag_acc: 0.2768
Step:  5113, loss: 3.350482, norm: 0.2728, time(ms): 791.15, token/sec:662688.15, hellaswag_acc: 0.2768
Step:  5114, loss: 3.330463, norm: 0.2863, time(ms): 807.11, token/sec:649585.78, hellaswag_acc: 0.2768
Step:  5115, loss: 3.383561, norm: 0.2602, time(ms): 801.35, token/sec:654259.94, hellaswag_acc: 0.2768
Step:  5116, loss: 3.315751, norm: 0.3059, time(ms): 796.47, token/sec:658267.41, hellaswag_acc: 0.2768
Step:  5117, loss: 3.310102, norm: 0.2696, time(ms): 797.55, token/sec:657372.45, hellaswag_acc: 0.2768
Step:  5118, loss: 3.292065, norm: 0.2800, time(ms): 805.10, token/sec:651207.61, hellaswag_acc: 0.2768
Step:  5119, loss: 3.346438, norm: 0.2585, time(ms): 799.69, token/sec:655612.48, hellaswag_acc: 0.2768
Step:  5120, loss: 3.353133, norm: 0.2754, time(ms): 795.01, token/sec:659473.00, hellaswag_acc: 0.2768
Step:  5121, loss: 3.410379, norm: 0.2911, time(ms): 801.23, token/sec:654351.05, hellaswag_acc: 0.2768
Step:  5122, loss: 3.362731, norm: 0.2899, time(ms): 803.47, token/sec:652532.25, hellaswag_acc: 0.2768
Step:  5123, loss: 3.315508, norm: 0.2692, time(ms): 800.46, token/sec:654982.91, hellaswag_acc: 0.2768
Step:  5124, loss: 3.327362, norm: 0.2657, time(ms): 790.05, token/sec:663615.87, hellaswag_acc: 0.2768
Step:  5125, loss: 3.351966, norm: 0.2527, time(ms): 808.31, token/sec:648618.77, hellaswag_acc: 0.2768
Step:  5126, loss: 3.357131, norm: 0.2914, time(ms): 798.99, token/sec:656186.67, hellaswag_acc: 0.2768
Step:  5127, loss: 3.351645, norm: 0.2837, time(ms): 801.28, token/sec:654310.55, hellaswag_acc: 0.2768
Step:  5128, loss: 3.303149, norm: 0.2829, time(ms): 791.25, token/sec:662608.67, hellaswag_acc: 0.2768
Step:  5129, loss: 3.370226, norm: 0.2802, time(ms): 806.87, token/sec:649779.84, hellaswag_acc: 0.2768
Step:  5130, loss: 3.302713, norm: 0.2433, time(ms): 802.28, token/sec:653494.47, hellaswag_acc: 0.2768
Step:  5131, loss: 3.352892, norm: 0.3060, time(ms): 785.49, token/sec:667469.38, hellaswag_acc: 0.2768
Step:  5132, loss: 3.312157, norm: 0.2784, time(ms): 787.59, token/sec:665682.81, hellaswag_acc: 0.2768
Step:  5133, loss: 3.325007, norm: 0.2598, time(ms): 796.20, token/sec:658486.41, hellaswag_acc: 0.2768
Step:  5134, loss: 3.282902, norm: 0.3040, time(ms): 791.38, token/sec:662497.88, hellaswag_acc: 0.2768
Step:  5135, loss: 3.276433, norm: 0.2612, time(ms): 796.35, token/sec:658363.98, hellaswag_acc: 0.2768
Step:  5136, loss: 3.284661, norm: 0.2783, time(ms): 791.60, token/sec:662316.90, hellaswag_acc: 0.2768
Step:  5137, loss: 3.277875, norm: 0.2932, time(ms): 801.43, token/sec:654187.73, hellaswag_acc: 0.2768
Step:  5138, loss: 3.297342, norm: 0.2390, time(ms): 794.52, token/sec:659883.43, hellaswag_acc: 0.2768
Step:  5139, loss: 3.292933, norm: 0.2903, time(ms): 793.72, token/sec:660547.85, hellaswag_acc: 0.2768
Step:  5140, loss: 3.296229, norm: 0.2833, time(ms): 791.70, token/sec:662229.54, hellaswag_acc: 0.2768
Step:  5141, loss: 3.278976, norm: 0.2573, time(ms): 792.92, token/sec:661213.82, hellaswag_acc: 0.2768
Step:  5142, loss: 3.279577, norm: 0.2960, time(ms): 789.55, token/sec:664033.89, hellaswag_acc: 0.2768
Step:  5143, loss: 3.284145, norm: 0.2764, time(ms): 1266.31, token/sec:414028.79, hellaswag_acc: 0.2768
Step:  5144, loss: 3.277905, norm: 0.2635, time(ms): 785.19, token/sec:667723.33, hellaswag_acc: 0.2768
Step:  5145, loss: 3.304932, norm: 0.2704, time(ms): 786.54, token/sec:666576.11, hellaswag_acc: 0.2768
Step:  5146, loss: 3.321887, norm: 0.2767, time(ms): 789.49, token/sec:664087.63, hellaswag_acc: 0.2768
Step:  5147, loss: 3.318500, norm: 0.2590, time(ms): 790.10, token/sec:663575.42, hellaswag_acc: 0.2768
Step:  5148, loss: 3.328371, norm: 0.2521, time(ms): 795.78, token/sec:658838.96, hellaswag_acc: 0.2768
Step:  5149, loss: 3.324160, norm: 0.2692, time(ms): 790.81, token/sec:662980.04, hellaswag_acc: 0.2768
Step:  5150, loss: 3.370346, norm: 0.2875, time(ms): 788.04, token/sec:665307.40, hellaswag_acc: 0.2768
Step:  5151, loss: 3.334895, norm: 0.2619, time(ms): 785.84, token/sec:667170.07, hellaswag_acc: 0.2768
Step:  5152, loss: 3.339015, norm: 0.2490, time(ms): 802.57, token/sec:653261.70, hellaswag_acc: 0.2768
Step:  5153, loss: 3.332931, norm: 0.2543, time(ms): 796.92, token/sec:657890.87, hellaswag_acc: 0.2768
Step:  5154, loss: 3.428419, norm: 0.2557, time(ms): 798.66, token/sec:656459.73, hellaswag_acc: 0.2768
Step:  5155, loss: 3.311658, norm: 0.2930, time(ms): 799.39, token/sec:655858.46, hellaswag_acc: 0.2768
Step:  5156, loss: 3.353565, norm: 0.2873, time(ms): 806.92, token/sec:649739.33, hellaswag_acc: 0.2768
Step:  5157, loss: 3.366537, norm: 0.2768, time(ms): 798.83, token/sec:656317.49, hellaswag_acc: 0.2768
Step:  5158, loss: 3.411819, norm: 0.2557, time(ms): 800.11, token/sec:655266.11, hellaswag_acc: 0.2768
Step:  5159, loss: 3.380751, norm: 0.2941, time(ms): 796.94, token/sec:657873.94, hellaswag_acc: 0.2768
Step:  5160, loss: 3.371246, norm: 0.2844, time(ms): 802.12, token/sec:653625.97, hellaswag_acc: 0.2768
Step:  5161, loss: 3.363123, norm: 0.2927, time(ms): 800.75, token/sec:654746.36, hellaswag_acc: 0.2768
Step:  5162, loss: 3.398255, norm: 0.2660, time(ms): 794.55, token/sec:659857.09, hellaswag_acc: 0.2768
Step:  5163, loss: 3.357896, norm: 0.2539, time(ms): 797.18, token/sec:657681.32, hellaswag_acc: 0.2768
Step:  5164, loss: 3.371859, norm: 0.2792, time(ms): 808.09, token/sec:648795.60, hellaswag_acc: 0.2768
Step:  5165, loss: 3.363348, norm: 0.3277, time(ms): 799.84, token/sec:655495.03, hellaswag_acc: 0.2768
Step:  5166, loss: 3.320238, norm: 0.3120, time(ms): 789.87, token/sec:663767.11, hellaswag_acc: 0.2768
Step:  5167, loss: 3.422967, norm: 0.2831, time(ms): 802.72, token/sec:653139.46, hellaswag_acc: 0.2768
Step:  5168, loss: 3.352988, norm: 0.2936, time(ms): 807.42, token/sec:649338.34, hellaswag_acc: 0.2768
Step:  5169, loss: 3.346534, norm: 0.2981, time(ms): 792.54, token/sec:661527.70, hellaswag_acc: 0.2768
Step:  5170, loss: 3.375948, norm: 0.3180, time(ms): 800.66, token/sec:654815.76, hellaswag_acc: 0.2768
Step:  5171, loss: 3.355600, norm: 0.2587, time(ms): 804.97, token/sec:651311.18, hellaswag_acc: 0.2768
Step:  5172, loss: 3.241222, norm: 0.2905, time(ms): 798.97, token/sec:656207.42, hellaswag_acc: 0.2768
Step:  5173, loss: 3.267741, norm: 0.2700, time(ms): 795.74, token/sec:658870.54, hellaswag_acc: 0.2768
Step:  5174, loss: 3.324565, norm: 0.2675, time(ms): 804.13, token/sec:651993.63, hellaswag_acc: 0.2768
Step:  5175, loss: 3.311721, norm: 0.2634, time(ms): 800.77, token/sec:654728.42, hellaswag_acc: 0.2768
Step:  5176, loss: 3.256279, norm: 0.2701, time(ms): 797.21, token/sec:657650.63, hellaswag_acc: 0.2768
Step:  5177, loss: 3.258980, norm: 0.2701, time(ms): 799.59, token/sec:655694.00, hellaswag_acc: 0.2768
Step:  5178, loss: 3.316725, norm: 0.2666, time(ms): 798.60, token/sec:656511.08, hellaswag_acc: 0.2768
Step:  5179, loss: 3.293873, norm: 0.2598, time(ms): 803.09, token/sec:652836.20, hellaswag_acc: 0.2768
Step:  5180, loss: 3.288354, norm: 0.2532, time(ms): 797.60, token/sec:657331.97, hellaswag_acc: 0.2768
Step:  5181, loss: 3.358512, norm: 0.2756, time(ms): 800.39, token/sec:655039.69, hellaswag_acc: 0.2768
Step:  5182, loss: 3.305509, norm: 0.2555, time(ms): 801.92, token/sec:653786.87, hellaswag_acc: 0.2768
Step:  5183, loss: 3.292040, norm: 0.2776, time(ms): 800.50, token/sec:654952.48, hellaswag_acc: 0.2768
Step:  5184, loss: 3.367785, norm: 0.2859, time(ms): 790.01, token/sec:663644.11, hellaswag_acc: 0.2768
Step:  5185, loss: 3.398086, norm: 0.2610, time(ms): 792.36, token/sec:661678.38, hellaswag_acc: 0.2768
Step:  5186, loss: 3.361883, norm: 0.2759, time(ms): 788.11, token/sec:665244.61, hellaswag_acc: 0.2768
Step:  5187, loss: 3.369988, norm: 0.2903, time(ms): 792.72, token/sec:661378.08, hellaswag_acc: 0.2768
Step:  5188, loss: 3.340033, norm: 0.2795, time(ms): 791.85, token/sec:662105.92, hellaswag_acc: 0.2768
Step:  5189, loss: 3.318064, norm: 0.2829, time(ms): 794.49, token/sec:659907.19, hellaswag_acc: 0.2768
Step:  5190, loss: 3.377531, norm: 0.2535, time(ms): 794.09, token/sec:660236.88, hellaswag_acc: 0.2768
Step:  5191, loss: 3.349261, norm: 0.2726, time(ms): 797.42, token/sec:657482.71, hellaswag_acc: 0.2768
Step:  5192, loss: 3.344104, norm: 0.2525, time(ms): 793.49, token/sec:660738.98, hellaswag_acc: 0.2768
Step:  5193, loss: 3.340227, norm: 0.2553, time(ms): 795.36, token/sec:659182.40, hellaswag_acc: 0.2768
Step:  5194, loss: 3.364874, norm: 0.2666, time(ms): 790.84, token/sec:662950.86, hellaswag_acc: 0.2768
Step:  5195, loss: 3.350469, norm: 0.2456, time(ms): 788.43, token/sec:664973.84, hellaswag_acc: 0.2768
Step:  5196, loss: 3.299067, norm: 0.2639, time(ms): 784.48, token/sec:668322.39, hellaswag_acc: 0.2768
Step:  5197, loss: 3.403498, norm: 0.2527, time(ms): 800.61, token/sec:654857.69, hellaswag_acc: 0.2768
Step:  5198, loss: 3.344127, norm: 0.3066, time(ms): 802.66, token/sec:653189.52, hellaswag_acc: 0.2768
Step:  5199, loss: 3.354476, norm: 0.2867, time(ms): 798.48, token/sec:656611.64, hellaswag_acc: 0.2768
Step:  5200, loss: 3.382929, norm: 0.2733, time(ms): 797.65, token/sec:657294.05, hellaswag_acc: 0.2768
Step:  5201, loss: 3.374321, norm: 0.3128, time(ms): 800.11, token/sec:655265.91, hellaswag_acc: 0.2768
Step:  5202, loss: 3.407778, norm: 0.3318, time(ms): 803.29, token/sec:652678.28, hellaswag_acc: 0.2768
Step:  5203, loss: 3.446233, norm: 0.3373, time(ms): 799.66, token/sec:655635.15, hellaswag_acc: 0.2768
Step:  5204, loss: 3.294649, norm: 0.3130, time(ms): 797.53, token/sec:657386.60, hellaswag_acc: 0.2768
Step:  5205, loss: 3.377542, norm: 0.4119, time(ms): 799.41, token/sec:655846.73, hellaswag_acc: 0.2768
Step:  5206, loss: 3.270096, norm: 0.3308, time(ms): 798.73, token/sec:656404.08, hellaswag_acc: 0.2768
Step:  5207, loss: 3.270785, norm: 0.2816, time(ms): 801.90, token/sec:653808.84, hellaswag_acc: 0.2768
Step:  5208, loss: 3.281067, norm: 0.2826, time(ms): 803.45, token/sec:652542.52, hellaswag_acc: 0.2768
Step:  5209, loss: 3.277318, norm: 0.3039, time(ms): 787.81, token/sec:665500.29, hellaswag_acc: 0.2768
Step:  5210, loss: 3.266572, norm: 0.2685, time(ms): 790.46, token/sec:663271.00, hellaswag_acc: 0.2768
Step:  5211, loss: 3.296292, norm: 0.2626, time(ms): 795.73, token/sec:658874.09, hellaswag_acc: 0.2768
Step:  5212, loss: 3.314755, norm: 0.2623, time(ms): 789.54, token/sec:664041.71, hellaswag_acc: 0.2768
Step:  5213, loss: 3.331937, norm: 0.2547, time(ms): 790.91, token/sec:662890.31, hellaswag_acc: 0.2768
Step:  5214, loss: 3.257155, norm: 0.2631, time(ms): 796.73, token/sec:658048.56, hellaswag_acc: 0.2768
Step:  5215, loss: 3.278102, norm: 0.2663, time(ms): 805.96, token/sec:650517.38, hellaswag_acc: 0.2768
Step:  5216, loss: 3.265079, norm: 0.2533, time(ms): 792.90, token/sec:661227.93, hellaswag_acc: 0.2768
Step:  5217, loss: 3.322571, norm: 0.2448, time(ms): 798.34, token/sec:656725.97, hellaswag_acc: 0.2768
Step:  5218, loss: 3.325781, norm: 0.2772, time(ms): 793.51, token/sec:660720.92, hellaswag_acc: 0.2768
Step:  5219, loss: 3.323948, norm: 0.2577, time(ms): 794.81, token/sec:659642.73, hellaswag_acc: 0.2768
Step:  5220, loss: 3.390901, norm: 0.2618, time(ms): 798.43, token/sec:656648.11, hellaswag_acc: 0.2768
Step:  5221, loss: 3.358724, norm: 0.2739, time(ms): 792.61, token/sec:661471.98, hellaswag_acc: 0.2768
Step:  5222, loss: 3.380857, norm: 0.2637, time(ms): 789.59, token/sec:663996.99, hellaswag_acc: 0.2768
Step:  5223, loss: 3.356860, norm: 0.2604, time(ms): 789.08, token/sec:664428.14, hellaswag_acc: 0.2768
Step:  5224, loss: 3.366683, norm: 0.2986, time(ms): 785.92, token/sec:667099.03, hellaswag_acc: 0.2768
Step:  5225, loss: 3.282102, norm: 0.3409, time(ms): 797.68, token/sec:657270.08, hellaswag_acc: 0.2768
Step:  5226, loss: 3.330005, norm: 0.3758, time(ms): 805.09, token/sec:651217.06, hellaswag_acc: 0.2768
Step:  5227, loss: 3.371855, norm: 0.3604, time(ms): 791.76, token/sec:662184.47, hellaswag_acc: 0.2768
Step:  5228, loss: 3.371363, norm: 0.2983, time(ms): 793.15, token/sec:661018.24, hellaswag_acc: 0.2768
Step:  5229, loss: 3.389686, norm: 0.3241, time(ms): 787.13, token/sec:666077.41, hellaswag_acc: 0.2768
Step:  5230, loss: 3.331867, norm: 0.2753, time(ms): 790.92, token/sec:662882.52, hellaswag_acc: 0.2768
Step:  5231, loss: 3.368093, norm: 0.2780, time(ms): 794.75, token/sec:659692.99, hellaswag_acc: 0.2768
Step:  5232, loss: 3.357756, norm: 0.2680, time(ms): 791.69, token/sec:662239.11, hellaswag_acc: 0.2768
Step:  5233, loss: 3.356569, norm: 0.2555, time(ms): 790.15, token/sec:663526.97, hellaswag_acc: 0.2768
Step:  5234, loss: 3.287432, norm: 0.2516, time(ms): 794.21, token/sec:660134.81, hellaswag_acc: 0.2768
Step:  5235, loss: 3.334339, norm: 0.2490, time(ms): 797.10, token/sec:657743.68, hellaswag_acc: 0.2768
Step:  5236, loss: 3.344242, norm: 0.2519, time(ms): 790.89, token/sec:662912.89, hellaswag_acc: 0.2768
Step:  5237, loss: 3.377632, norm: 0.2506, time(ms): 789.24, token/sec:664293.46, hellaswag_acc: 0.2768
Step:  5238, loss: 3.419613, norm: 0.2801, time(ms): 789.17, token/sec:664354.47, hellaswag_acc: 0.2768
Step:  5239, loss: 3.362416, norm: 0.2892, time(ms): 792.14, token/sec:661862.00, hellaswag_acc: 0.2768
Step:  5240, loss: 3.295237, norm: 0.2829, time(ms): 799.99, token/sec:655364.92, hellaswag_acc: 0.2768
Step:  5241, loss: 3.283395, norm: 0.2758, time(ms): 806.38, token/sec:650170.98, hellaswag_acc: 0.2768
Step:  5242, loss: 3.276567, norm: 0.2803, time(ms): 799.87, token/sec:655467.67, hellaswag_acc: 0.2768
Step:  5243, loss: 3.315176, norm: 0.2509, time(ms): 792.57, token/sec:661503.62, hellaswag_acc: 0.2768
Step:  5244, loss: 3.304304, norm: 0.2559, time(ms): 804.61, token/sec:651601.45, hellaswag_acc: 0.2768
Step:  5245, loss: 3.321639, norm: 0.2540, time(ms): 803.85, token/sec:652218.72, hellaswag_acc: 0.2768
Step:  5246, loss: 3.281338, norm: 0.2651, time(ms): 796.00, token/sec:658649.91, hellaswag_acc: 0.2768
Step:  5247, loss: 3.253459, norm: 0.2364, time(ms): 800.30, token/sec:655111.70, hellaswag_acc: 0.2768
Step:  5248, loss: 3.258180, norm: 0.3018, time(ms): 798.80, token/sec:656341.98, hellaswag_acc: 0.2768
Step:  5249, loss: 3.311051, norm: 0.2791, time(ms): 803.12, token/sec:652815.66, hellaswag_acc: 0.2768
rank 0 sample 0: Hello, I'm a language model, and I need to know something else for him when I'm not speaking German!
"All you can do is say
rank 0 sample 1: Hello, I'm a language model, so here's the code. The computer is the repository of all information, the source, and all it has to do
rank 0 sample 2: Hello, I'm a language model, I'm actually making a very specialization of some of the ideas, so I'm working on a much more general one
rank 0 sample 3: Hello, I'm a language model, a model of a language, and some things as you would expect.
The purpose of this article is to explain something
rank 1 sample 0: Hello, I'm a language model, what does that mean? I'm no different, it's how I do it. It's all about my language.
rank 1 sample 1: Hello, I'm a language model, not an interpreter.
I was told (and I said) that I don't remember what it is.
I
rank 1 sample 2: Hello, I'm a language model, so many languages do.
I'm a language model, so many languages do.
I want a model. I
rank 1 sample 3: Hello, I'm a language model, and I'm using a machine learning tool — a set of language skills you do in Microsoft Word — that's how I
Step:  5250, loss: 3.278667, norm: 0.2773, time(ms): 3781.90, token/sec:138630.72, val_loss: 3.3402, hellaswag_acc: 0.2768
Step:  5251, loss: 3.274119, norm: 0.2609, time(ms): 786.15, token/sec:666904.41, hellaswag_acc: 0.2768
Step:  5252, loss: 3.353687, norm: 0.2995, time(ms): 782.16, token/sec:670309.46, hellaswag_acc: 0.2768
Step:  5253, loss: 3.317971, norm: 0.2714, time(ms): 800.18, token/sec:655210.46, hellaswag_acc: 0.2768
Step:  5254, loss: 3.372679, norm: 0.2574, time(ms): 795.24, token/sec:659284.57, hellaswag_acc: 0.2768
Step:  5255, loss: 3.337743, norm: 0.2764, time(ms): 795.79, token/sec:658828.89, hellaswag_acc: 0.2768
Step:  5256, loss: 3.371207, norm: 0.2560, time(ms): 787.96, token/sec:665377.86, hellaswag_acc: 0.2768
Step:  5257, loss: 3.322825, norm: 0.2627, time(ms): 786.38, token/sec:666713.54, hellaswag_acc: 0.2768
Step:  5258, loss: 3.362958, norm: 0.2638, time(ms): 793.85, token/sec:660439.93, hellaswag_acc: 0.2768
Step:  5259, loss: 3.282402, norm: 0.2538, time(ms): 793.34, token/sec:660863.09, hellaswag_acc: 0.2768
Step:  5260, loss: 3.405464, norm: 0.2708, time(ms): 795.86, token/sec:658772.05, hellaswag_acc: 0.2768
Step:  5261, loss: 3.358902, norm: 0.2742, time(ms): 788.67, token/sec:664775.22, hellaswag_acc: 0.2768
Step:  5262, loss: 3.363100, norm: 0.2729, time(ms): 798.54, token/sec:656561.06, hellaswag_acc: 0.2768
Step:  5263, loss: 3.348536, norm: 0.2677, time(ms): 791.31, token/sec:662554.37, hellaswag_acc: 0.2768
Step:  5264, loss: 3.330197, norm: 0.2928, time(ms): 788.41, token/sec:664989.92, hellaswag_acc: 0.2768
Step:  5265, loss: 3.315776, norm: 0.2792, time(ms): 787.10, token/sec:666100.41, hellaswag_acc: 0.2768
Step:  5266, loss: 3.346793, norm: 0.2480, time(ms): 801.66, token/sec:654000.95, hellaswag_acc: 0.2768
Step:  5267, loss: 3.347678, norm: 0.2646, time(ms): 801.98, token/sec:653741.58, hellaswag_acc: 0.2768
Step:  5268, loss: 3.330484, norm: 0.2651, time(ms): 797.29, token/sec:657589.47, hellaswag_acc: 0.2768
Step:  5269, loss: 3.329885, norm: 0.2503, time(ms): 798.68, token/sec:656439.35, hellaswag_acc: 0.2768
Step:  5270, loss: 3.332054, norm: 0.2729, time(ms): 803.95, token/sec:652138.07, hellaswag_acc: 0.2768
Step:  5271, loss: 3.326859, norm: 0.2631, time(ms): 799.08, token/sec:656112.27, hellaswag_acc: 0.2768
Step:  5272, loss: 3.353343, norm: 0.2552, time(ms): 791.60, token/sec:662316.30, hellaswag_acc: 0.2768
Step:  5273, loss: 3.310217, norm: 0.2736, time(ms): 801.59, token/sec:654060.28, hellaswag_acc: 0.2768
Step:  5274, loss: 3.309247, norm: 0.2510, time(ms): 799.79, token/sec:655535.67, hellaswag_acc: 0.2768
Step:  5275, loss: 3.313110, norm: 0.2516, time(ms): 797.62, token/sec:657312.72, hellaswag_acc: 0.2768
Step:  5276, loss: 3.249225, norm: 0.2563, time(ms): 795.72, token/sec:658888.51, hellaswag_acc: 0.2768
Step:  5277, loss: 3.333602, norm: 0.2426, time(ms): 794.22, token/sec:660130.45, hellaswag_acc: 0.2768
Step:  5278, loss: 3.325747, norm: 0.2995, time(ms): 796.07, token/sec:658597.04, hellaswag_acc: 0.2768
Step:  5279, loss: 3.314041, norm: 0.2942, time(ms): 795.48, token/sec:659085.59, hellaswag_acc: 0.2768
Step:  5280, loss: 3.294945, norm: 0.2945, time(ms): 796.71, token/sec:658062.35, hellaswag_acc: 0.2768
Step:  5281, loss: 3.377224, norm: 0.3065, time(ms): 786.75, token/sec:666396.33, hellaswag_acc: 0.2768
Step:  5282, loss: 3.265089, norm: 0.2961, time(ms): 794.67, token/sec:659757.91, hellaswag_acc: 0.2768
Step:  5283, loss: 3.279789, norm: 0.2895, time(ms): 792.52, token/sec:661544.42, hellaswag_acc: 0.2768
Step:  5284, loss: 3.381166, norm: 0.3008, time(ms): 790.73, token/sec:663046.01, hellaswag_acc: 0.2768
Step:  5285, loss: 3.290559, norm: 0.3030, time(ms): 804.60, token/sec:651610.52, hellaswag_acc: 0.2768
Step:  5286, loss: 3.302334, norm: 0.3118, time(ms): 794.94, token/sec:659527.59, hellaswag_acc: 0.2768
Step:  5287, loss: 3.323386, norm: 0.2844, time(ms): 801.58, token/sec:654065.92, hellaswag_acc: 0.2768
Step:  5288, loss: 3.363296, norm: 0.2888, time(ms): 803.19, token/sec:652756.17, hellaswag_acc: 0.2768
Step:  5289, loss: 3.381237, norm: 0.2955, time(ms): 799.42, token/sec:655835.97, hellaswag_acc: 0.2768
Step:  5290, loss: 3.279568, norm: 0.2982, time(ms): 793.04, token/sec:661110.85, hellaswag_acc: 0.2768
Step:  5291, loss: 3.429096, norm: 0.3227, time(ms): 806.09, token/sec:650405.21, hellaswag_acc: 0.2768
Step:  5292, loss: 3.342486, norm: 0.3228, time(ms): 801.77, token/sec:653916.16, hellaswag_acc: 0.2768
Step:  5293, loss: 3.344978, norm: 0.3102, time(ms): 794.25, token/sec:660102.11, hellaswag_acc: 0.2768
Step:  5294, loss: 3.316808, norm: 0.2471, time(ms): 798.67, token/sec:656452.48, hellaswag_acc: 0.2768
Step:  5295, loss: 3.357923, norm: 0.3057, time(ms): 803.94, token/sec:652146.38, hellaswag_acc: 0.2768
Step:  5296, loss: 3.336599, norm: 0.3026, time(ms): 801.71, token/sec:653964.77, hellaswag_acc: 0.2768
Step:  5297, loss: 3.359011, norm: 0.2600, time(ms): 793.73, token/sec:660539.72, hellaswag_acc: 0.2768
Step:  5298, loss: 3.374616, norm: 0.3231, time(ms): 804.41, token/sec:651768.89, hellaswag_acc: 0.2768
Step:  5299, loss: 3.357712, norm: 0.3060, time(ms): 801.41, token/sec:654208.16, hellaswag_acc: 0.2768
Step:  5300, loss: 3.372783, norm: 0.2885, time(ms): 791.47, token/sec:662422.64, hellaswag_acc: 0.2768
Step:  5301, loss: 3.344329, norm: 0.2947, time(ms): 806.90, token/sec:649757.37, hellaswag_acc: 0.2768
Step:  5302, loss: 3.311819, norm: 0.2793, time(ms): 801.03, token/sec:654514.26, hellaswag_acc: 0.2768
Step:  5303, loss: 3.317488, norm: 0.2780, time(ms): 794.70, token/sec:659729.61, hellaswag_acc: 0.2768
Step:  5304, loss: 3.343171, norm: 0.2773, time(ms): 804.32, token/sec:651841.72, hellaswag_acc: 0.2768
Step:  5305, loss: 3.349842, norm: 0.2764, time(ms): 798.06, token/sec:656951.59, hellaswag_acc: 0.2768
Step:  5306, loss: 3.342361, norm: 0.2571, time(ms): 795.86, token/sec:658772.84, hellaswag_acc: 0.2768
Step:  5307, loss: 3.340135, norm: 0.2654, time(ms): 803.72, token/sec:652329.97, hellaswag_acc: 0.2768
Step:  5308, loss: 3.343073, norm: 0.2506, time(ms): 801.78, token/sec:653906.82, hellaswag_acc: 0.2768
Step:  5309, loss: 3.218560, norm: 0.2480, time(ms): 798.46, token/sec:656621.45, hellaswag_acc: 0.2768
Step:  5310, loss: 3.243947, norm: 0.2673, time(ms): 789.56, token/sec:664028.47, hellaswag_acc: 0.2768
Step:  5311, loss: 3.289971, norm: 0.2482, time(ms): 789.53, token/sec:664050.33, hellaswag_acc: 0.2768
Step:  5312, loss: 3.292446, norm: 0.2306, time(ms): 792.68, token/sec:661414.29, hellaswag_acc: 0.2768
Step:  5313, loss: 3.270811, norm: 0.2471, time(ms): 792.03, token/sec:661956.04, hellaswag_acc: 0.2768
Step:  5314, loss: 3.232155, norm: 0.2553, time(ms): 787.77, token/sec:665537.95, hellaswag_acc: 0.2768
Step:  5315, loss: 3.262976, norm: 0.2531, time(ms): 793.97, token/sec:660336.41, hellaswag_acc: 0.2768
Step:  5316, loss: 3.262055, norm: 0.2504, time(ms): 793.58, token/sec:660658.59, hellaswag_acc: 0.2768
Step:  5317, loss: 3.289239, norm: 0.2521, time(ms): 796.83, token/sec:657970.59, hellaswag_acc: 0.2768
Step:  5318, loss: 3.195448, norm: 0.2548, time(ms): 800.16, token/sec:655226.28, hellaswag_acc: 0.2768
Step:  5319, loss: 3.338284, norm: 0.2877, time(ms): 803.46, token/sec:652534.00, hellaswag_acc: 0.2768
Step:  5320, loss: 3.360078, norm: 0.3005, time(ms): 792.81, token/sec:661300.91, hellaswag_acc: 0.2768
Step:  5321, loss: 3.433001, norm: 0.2926, time(ms): 801.74, token/sec:653940.08, hellaswag_acc: 0.2768
Step:  5322, loss: 3.364251, norm: 0.3154, time(ms): 799.87, token/sec:655463.38, hellaswag_acc: 0.2768
Step:  5323, loss: 3.384877, norm: 0.3420, time(ms): 797.22, token/sec:657642.77, hellaswag_acc: 0.2768
Step:  5324, loss: 3.350511, norm: 0.2976, time(ms): 791.98, token/sec:661999.88, hellaswag_acc: 0.2768
Step:  5325, loss: 3.341168, norm: 0.3018, time(ms): 791.80, token/sec:662148.18, hellaswag_acc: 0.2768
Step:  5326, loss: 3.375719, norm: 0.2787, time(ms): 787.47, token/sec:665788.22, hellaswag_acc: 0.2768
Step:  5327, loss: 3.389593, norm: 0.2714, time(ms): 787.49, token/sec:665767.66, hellaswag_acc: 0.2768
Step:  5328, loss: 3.337811, norm: 0.2876, time(ms): 798.59, token/sec:656516.96, hellaswag_acc: 0.2768
Step:  5329, loss: 3.373223, norm: 0.2670, time(ms): 791.15, token/sec:662689.54, hellaswag_acc: 0.2768
Step:  5330, loss: 3.349792, norm: 0.2674, time(ms): 788.55, token/sec:664874.51, hellaswag_acc: 0.2768
Step:  5331, loss: 3.342584, norm: 0.2570, time(ms): 791.74, token/sec:662193.65, hellaswag_acc: 0.2768
Step:  5332, loss: 3.348114, norm: 0.2664, time(ms): 793.04, token/sec:661110.45, hellaswag_acc: 0.2768
Step:  5333, loss: 3.379310, norm: 0.2716, time(ms): 1323.82, token/sec:396042.37, hellaswag_acc: 0.2768
Step:  5334, loss: 3.272585, norm: 0.2787, time(ms): 766.50, token/sec:684000.27, hellaswag_acc: 0.2768
Step:  5335, loss: 3.211063, norm: 0.2557, time(ms): 792.83, token/sec:661289.57, hellaswag_acc: 0.2768
Step:  5336, loss: 3.278450, norm: 0.2948, time(ms): 802.29, token/sec:653488.64, hellaswag_acc: 0.2768
Step:  5337, loss: 3.189042, norm: 0.3086, time(ms): 788.26, token/sec:665121.26, hellaswag_acc: 0.2768
Step:  5338, loss: 3.285443, norm: 0.3089, time(ms): 781.68, token/sec:670717.54, hellaswag_acc: 0.2768
Step:  5339, loss: 3.281575, norm: 0.2556, time(ms): 788.04, token/sec:665303.17, hellaswag_acc: 0.2768
Step:  5340, loss: 3.191110, norm: 0.2808, time(ms): 793.38, token/sec:660824.56, hellaswag_acc: 0.2768
Step:  5341, loss: 3.220385, norm: 0.2619, time(ms): 806.99, token/sec:649682.89, hellaswag_acc: 0.2768
Step:  5342, loss: 3.211323, norm: 0.3012, time(ms): 788.57, token/sec:664861.85, hellaswag_acc: 0.2768
Step:  5343, loss: 3.209207, norm: 0.2932, time(ms): 790.60, token/sec:663152.58, hellaswag_acc: 0.2768
Step:  5344, loss: 3.197642, norm: 0.2697, time(ms): 788.08, token/sec:665272.98, hellaswag_acc: 0.2768
Step:  5345, loss: 3.213871, norm: 0.2821, time(ms): 791.33, token/sec:662541.59, hellaswag_acc: 0.2768
Step:  5346, loss: 3.344771, norm: 0.2804, time(ms): 790.86, token/sec:662934.67, hellaswag_acc: 0.2768
Step:  5347, loss: 3.330468, norm: 0.3148, time(ms): 791.89, token/sec:662069.84, hellaswag_acc: 0.2768
Step:  5348, loss: 3.379923, norm: 0.3326, time(ms): 793.15, token/sec:661021.82, hellaswag_acc: 0.2768
Step:  5349, loss: 3.358950, norm: 0.2732, time(ms): 797.70, token/sec:657251.42, hellaswag_acc: 0.2768
Step:  5350, loss: 3.336833, norm: 0.2493, time(ms): 802.85, token/sec:653032.40, hellaswag_acc: 0.2768
Step:  5351, loss: 3.337906, norm: 0.2585, time(ms): 802.78, token/sec:653086.70, hellaswag_acc: 0.2768
Step:  5352, loss: 3.267170, norm: 0.2545, time(ms): 790.54, token/sec:663201.58, hellaswag_acc: 0.2768
Step:  5353, loss: 3.359805, norm: 0.2897, time(ms): 790.03, token/sec:663628.89, hellaswag_acc: 0.2768
Step:  5354, loss: 3.378411, norm: 0.3151, time(ms): 794.80, token/sec:659650.25, hellaswag_acc: 0.2768
Step:  5355, loss: 3.282414, norm: 0.2706, time(ms): 789.64, token/sec:663959.10, hellaswag_acc: 0.2768
Step:  5356, loss: 3.343796, norm: 0.3168, time(ms): 788.62, token/sec:664814.21, hellaswag_acc: 0.2768
Step:  5357, loss: 3.330315, norm: 0.3144, time(ms): 804.04, token/sec:652067.87, hellaswag_acc: 0.2768
Step:  5358, loss: 3.315048, norm: 0.2833, time(ms): 802.00, token/sec:653723.90, hellaswag_acc: 0.2768
Step:  5359, loss: 3.416922, norm: 0.2832, time(ms): 794.52, token/sec:659880.86, hellaswag_acc: 0.2768
Step:  5360, loss: 3.376892, norm: 0.2952, time(ms): 801.49, token/sec:654138.49, hellaswag_acc: 0.2768
Step:  5361, loss: 3.299121, norm: 0.2845, time(ms): 802.74, token/sec:653126.27, hellaswag_acc: 0.2768
Step:  5362, loss: 3.407872, norm: 0.2872, time(ms): 800.86, token/sec:654658.45, hellaswag_acc: 0.2768
Step:  5363, loss: 3.343112, norm: 0.3141, time(ms): 788.53, token/sec:664895.02, hellaswag_acc: 0.2768
Step:  5364, loss: 3.392516, norm: 0.3035, time(ms): 792.85, token/sec:661266.91, hellaswag_acc: 0.2768
Step:  5365, loss: 3.352509, norm: 0.3186, time(ms): 790.34, token/sec:663370.24, hellaswag_acc: 0.2768
Step:  5366, loss: 3.332575, norm: 0.2744, time(ms): 789.91, token/sec:663729.64, hellaswag_acc: 0.2768
Step:  5367, loss: 3.337908, norm: 0.2871, time(ms): 789.29, token/sec:664255.33, hellaswag_acc: 0.2768
Step:  5368, loss: 3.312872, norm: 0.3019, time(ms): 800.57, token/sec:654896.89, hellaswag_acc: 0.2768
Step:  5369, loss: 3.308331, norm: 0.2842, time(ms): 803.75, token/sec:652300.37, hellaswag_acc: 0.2768
Step:  5370, loss: 3.295997, norm: 0.2866, time(ms): 799.55, token/sec:655726.26, hellaswag_acc: 0.2768
Step:  5371, loss: 3.350980, norm: 0.2587, time(ms): 793.94, token/sec:660362.58, hellaswag_acc: 0.2768
Step:  5372, loss: 3.291060, norm: 0.2920, time(ms): 803.06, token/sec:652863.14, hellaswag_acc: 0.2768
Step:  5373, loss: 3.285862, norm: 0.2525, time(ms): 805.36, token/sec:651000.95, hellaswag_acc: 0.2768
Step:  5374, loss: 3.287127, norm: 0.2679, time(ms): 798.02, token/sec:656982.21, hellaswag_acc: 0.2768
Step:  5375, loss: 3.297838, norm: 0.2567, time(ms): 793.08, token/sec:661076.46, hellaswag_acc: 0.2768
Step:  5376, loss: 3.309973, norm: 0.2838, time(ms): 801.41, token/sec:654205.44, hellaswag_acc: 0.2768
Step:  5377, loss: 3.292434, norm: 0.2442, time(ms): 803.71, token/sec:652337.71, hellaswag_acc: 0.2768
Step:  5378, loss: 3.276053, norm: 0.2754, time(ms): 794.69, token/sec:659742.47, hellaswag_acc: 0.2768
Step:  5379, loss: 3.338658, norm: 0.2762, time(ms): 792.50, token/sec:661565.11, hellaswag_acc: 0.2768
Step:  5380, loss: 3.318871, norm: 0.2516, time(ms): 792.31, token/sec:661722.19, hellaswag_acc: 0.2768
Step:  5381, loss: 3.257622, norm: 0.2800, time(ms): 796.85, token/sec:657948.35, hellaswag_acc: 0.2768
Step:  5382, loss: 3.232320, norm: 0.2686, time(ms): 797.34, token/sec:657543.46, hellaswag_acc: 0.2768
Step:  5383, loss: 3.286674, norm: 0.2664, time(ms): 790.92, token/sec:662887.11, hellaswag_acc: 0.2768
Step:  5384, loss: 3.199512, norm: 0.2635, time(ms): 787.54, token/sec:665724.53, hellaswag_acc: 0.2768
Step:  5385, loss: 3.300212, norm: 0.2585, time(ms): 787.80, token/sec:665511.17, hellaswag_acc: 0.2768
Step:  5386, loss: 3.226709, norm: 0.2560, time(ms): 799.17, token/sec:656039.85, hellaswag_acc: 0.2768
Step:  5387, loss: 3.217860, norm: 0.2728, time(ms): 801.55, token/sec:654090.24, hellaswag_acc: 0.2768
Step:  5388, loss: 3.225366, norm: 0.2570, time(ms): 801.86, token/sec:653842.27, hellaswag_acc: 0.2768
Step:  5389, loss: 3.189682, norm: 0.2499, time(ms): 794.09, token/sec:660238.87, hellaswag_acc: 0.2768
Step:  5390, loss: 3.224563, norm: 0.2605, time(ms): 797.34, token/sec:657542.28, hellaswag_acc: 0.2768
Step:  5391, loss: 3.226418, norm: 0.2656, time(ms): 805.29, token/sec:651058.38, hellaswag_acc: 0.2768
Step:  5392, loss: 3.229431, norm: 0.2811, time(ms): 802.31, token/sec:653469.03, hellaswag_acc: 0.2768
Step:  5393, loss: 3.215864, norm: 0.2775, time(ms): 789.68, token/sec:663920.82, hellaswag_acc: 0.2768
Step:  5394, loss: 3.420115, norm: 0.2868, time(ms): 805.33, token/sec:651026.19, hellaswag_acc: 0.2768
Step:  5395, loss: 3.267327, norm: 0.3398, time(ms): 804.53, token/sec:651666.91, hellaswag_acc: 0.2768
Step:  5396, loss: 3.344081, norm: 0.3306, time(ms): 799.53, token/sec:655746.40, hellaswag_acc: 0.2768
Step:  5397, loss: 3.329993, norm: 0.3277, time(ms): 794.05, token/sec:660272.76, hellaswag_acc: 0.2768
Step:  5398, loss: 3.388742, norm: 0.2853, time(ms): 803.50, token/sec:652506.11, hellaswag_acc: 0.2768
Step:  5399, loss: 3.418036, norm: 0.2982, time(ms): 801.90, token/sec:653804.37, hellaswag_acc: 0.2768
Step:  5400, loss: 3.365756, norm: 0.3193, time(ms): 787.86, token/sec:665455.98, hellaswag_acc: 0.2768
Step:  5401, loss: 3.345071, norm: 0.3013, time(ms): 789.34, token/sec:664209.59, hellaswag_acc: 0.2768
Step:  5402, loss: 3.274550, norm: 0.3064, time(ms): 792.55, token/sec:661521.73, hellaswag_acc: 0.2768
Step:  5403, loss: 3.283184, norm: 0.3016, time(ms): 790.79, token/sec:662995.83, hellaswag_acc: 0.2768
Step:  5404, loss: 3.292784, norm: 0.2824, time(ms): 788.36, token/sec:665032.96, hellaswag_acc: 0.2768
Step:  5405, loss: 3.347946, norm: 0.2724, time(ms): 791.02, token/sec:662798.60, hellaswag_acc: 0.2768
Step:  5406, loss: 3.377276, norm: 0.3005, time(ms): 795.41, token/sec:659145.06, hellaswag_acc: 0.2768
Step:  5407, loss: 3.297599, norm: 0.2862, time(ms): 793.32, token/sec:660876.99, hellaswag_acc: 0.2768
Step:  5408, loss: 3.335386, norm: 0.2783, time(ms): 790.15, token/sec:663531.37, hellaswag_acc: 0.2768
Step:  5409, loss: 3.367797, norm: 0.3057, time(ms): 789.16, token/sec:664361.29, hellaswag_acc: 0.2768
Step:  5410, loss: 3.304020, norm: 0.2908, time(ms): 790.76, token/sec:663018.22, hellaswag_acc: 0.2768
Step:  5411, loss: 3.299700, norm: 0.2751, time(ms): 795.98, token/sec:658670.43, hellaswag_acc: 0.2768
Step:  5412, loss: 3.331929, norm: 0.3071, time(ms): 802.66, token/sec:653191.46, hellaswag_acc: 0.2768
Step:  5413, loss: 3.293957, norm: 0.2816, time(ms): 792.57, token/sec:661503.22, hellaswag_acc: 0.2768
Step:  5414, loss: 3.367903, norm: 0.2507, time(ms): 806.18, token/sec:650334.04, hellaswag_acc: 0.2768
Step:  5415, loss: 3.325922, norm: 0.2909, time(ms): 802.13, token/sec:653622.47, hellaswag_acc: 0.2768
Step:  5416, loss: 3.359161, norm: 0.2449, time(ms): 788.96, token/sec:664527.53, hellaswag_acc: 0.2768
Step:  5417, loss: 3.291894, norm: 0.2452, time(ms): 797.90, token/sec:657082.92, hellaswag_acc: 0.2768
Step:  5418, loss: 3.264059, norm: 0.2801, time(ms): 791.15, token/sec:662692.54, hellaswag_acc: 0.2768
Step:  5419, loss: 3.264636, norm: 0.2433, time(ms): 791.01, token/sec:662809.39, hellaswag_acc: 0.2768
Step:  5420, loss: 3.270984, norm: 0.2863, time(ms): 790.62, token/sec:663134.79, hellaswag_acc: 0.2768
Step:  5421, loss: 3.246345, norm: 0.2738, time(ms): 794.07, token/sec:660257.70, hellaswag_acc: 0.2768
Step:  5422, loss: 3.270314, norm: 0.2747, time(ms): 798.16, token/sec:656868.78, hellaswag_acc: 0.2768
Step:  5423, loss: 3.316665, norm: 0.3124, time(ms): 803.03, token/sec:652884.46, hellaswag_acc: 0.2768
Step:  5424, loss: 3.269346, norm: 0.2586, time(ms): 795.35, token/sec:659195.24, hellaswag_acc: 0.2768
Step:  5425, loss: 3.295112, norm: 0.2732, time(ms): 801.65, token/sec:654007.37, hellaswag_acc: 0.2768
Step:  5426, loss: 3.267625, norm: 0.2667, time(ms): 803.11, token/sec:652818.37, hellaswag_acc: 0.2768
Step:  5427, loss: 3.289846, norm: 0.2546, time(ms): 792.94, token/sec:661193.14, hellaswag_acc: 0.2768
Step:  5428, loss: 3.239484, norm: 0.2742, time(ms): 792.80, token/sec:661315.23, hellaswag_acc: 0.2768
Step:  5429, loss: 3.227722, norm: 0.3041, time(ms): 793.80, token/sec:660479.21, hellaswag_acc: 0.2768
Step:  5430, loss: 3.282177, norm: 0.2854, time(ms): 796.17, token/sec:658513.82, hellaswag_acc: 0.2768
Step:  5431, loss: 3.222560, norm: 0.2900, time(ms): 802.74, token/sec:653125.88, hellaswag_acc: 0.2768
Step:  5432, loss: 3.206153, norm: 0.2898, time(ms): 796.49, token/sec:658245.54, hellaswag_acc: 0.2768
Step:  5433, loss: 3.231687, norm: 0.2679, time(ms): 796.76, token/sec:658022.57, hellaswag_acc: 0.2768
Step:  5434, loss: 3.209451, norm: 0.3137, time(ms): 788.81, token/sec:664656.67, hellaswag_acc: 0.2768
Step:  5435, loss: 3.190073, norm: 0.2807, time(ms): 791.27, token/sec:662593.70, hellaswag_acc: 0.2768
Step:  5436, loss: 3.268009, norm: 0.3096, time(ms): 793.06, token/sec:661097.73, hellaswag_acc: 0.2768
Step:  5437, loss: 3.197717, norm: 0.3144, time(ms): 788.94, token/sec:664550.82, hellaswag_acc: 0.2768
Step:  5438, loss: 3.191023, norm: 0.3058, time(ms): 807.13, token/sec:649573.69, hellaswag_acc: 0.2768
Step:  5439, loss: 3.155636, norm: 0.2739, time(ms): 798.54, token/sec:656559.69, hellaswag_acc: 0.2768
Step:  5440, loss: 3.350116, norm: 0.2869, time(ms): 794.72, token/sec:659714.17, hellaswag_acc: 0.2768
Step:  5441, loss: 3.397237, norm: 0.3078, time(ms): 800.96, token/sec:654574.85, hellaswag_acc: 0.2768
Step:  5442, loss: 3.328546, norm: 0.2913, time(ms): 805.17, token/sec:651152.85, hellaswag_acc: 0.2768
Step:  5443, loss: 3.333359, norm: 0.2820, time(ms): 792.47, token/sec:661585.81, hellaswag_acc: 0.2768
Step:  5444, loss: 3.298671, norm: 0.2723, time(ms): 801.71, token/sec:653965.55, hellaswag_acc: 0.2768
Step:  5445, loss: 3.331753, norm: 0.3022, time(ms): 803.86, token/sec:652211.37, hellaswag_acc: 0.2768
Step:  5446, loss: 3.347635, norm: 0.2947, time(ms): 801.58, token/sec:654067.67, hellaswag_acc: 0.2768
Step:  5447, loss: 3.337062, norm: 0.2882, time(ms): 796.28, token/sec:658424.30, hellaswag_acc: 0.2768
Step:  5448, loss: 3.307183, norm: 0.2546, time(ms): 797.30, token/sec:657580.62, hellaswag_acc: 0.2768
Step:  5449, loss: 3.377445, norm: 0.2578, time(ms): 804.14, token/sec:651987.64, hellaswag_acc: 0.2768
Step:  5450, loss: 3.328149, norm: 0.2785, time(ms): 801.18, token/sec:654398.76, hellaswag_acc: 0.2768
Step:  5451, loss: 3.351355, norm: 0.2682, time(ms): 795.46, token/sec:659101.99, hellaswag_acc: 0.2768
Step:  5452, loss: 3.324524, norm: 0.2622, time(ms): 801.68, token/sec:653985.00, hellaswag_acc: 0.2768
Step:  5453, loss: 3.353225, norm: 0.2633, time(ms): 799.76, token/sec:655559.51, hellaswag_acc: 0.2768
Step:  5454, loss: 3.332421, norm: 0.2659, time(ms): 800.42, token/sec:655018.03, hellaswag_acc: 0.2768
Step:  5455, loss: 3.323973, norm: 0.2539, time(ms): 801.63, token/sec:654031.49, hellaswag_acc: 0.2768
Step:  5456, loss: 3.355017, norm: 0.2595, time(ms): 797.03, token/sec:657802.70, hellaswag_acc: 0.2768
Step:  5457, loss: 3.327797, norm: 0.2369, time(ms): 801.27, token/sec:654318.73, hellaswag_acc: 0.2768
Step:  5458, loss: 3.316481, norm: 0.2529, time(ms): 798.70, token/sec:656424.26, hellaswag_acc: 0.2768
Step:  5459, loss: 3.360755, norm: 0.2786, time(ms): 801.53, token/sec:654107.94, hellaswag_acc: 0.2768
Step:  5460, loss: 3.293806, norm: 0.2831, time(ms): 800.17, token/sec:655221.79, hellaswag_acc: 0.2768
Step:  5461, loss: 3.351771, norm: 0.2743, time(ms): 793.23, token/sec:660956.05, hellaswag_acc: 0.2768
Step:  5462, loss: 3.377100, norm: 0.2787, time(ms): 806.54, token/sec:650047.02, hellaswag_acc: 0.2768
Step:  5463, loss: 3.345656, norm: 0.3155, time(ms): 800.38, token/sec:655048.86, hellaswag_acc: 0.2768
Step:  5464, loss: 3.300467, norm: 0.3048, time(ms): 794.66, token/sec:659761.87, hellaswag_acc: 0.2768
Step:  5465, loss: 3.299018, norm: 0.2748, time(ms): 797.46, token/sec:657449.30, hellaswag_acc: 0.2768
Step:  5466, loss: 3.287852, norm: 0.2710, time(ms): 805.13, token/sec:651180.81, hellaswag_acc: 0.2768
Step:  5467, loss: 3.274126, norm: 0.2417, time(ms): 802.80, token/sec:653077.20, hellaswag_acc: 0.2768
Step:  5468, loss: 3.361297, norm: 0.2720, time(ms): 789.27, token/sec:664266.57, hellaswag_acc: 0.2768
Step:  5469, loss: 3.307774, norm: 0.2928, time(ms): 797.50, token/sec:657410.38, hellaswag_acc: 0.2768
Step:  5470, loss: 3.317638, norm: 0.2497, time(ms): 789.55, token/sec:664035.09, hellaswag_acc: 0.2768
Step:  5471, loss: 3.304799, norm: 0.2631, time(ms): 788.77, token/sec:664693.84, hellaswag_acc: 0.2768
Step:  5472, loss: 3.313232, norm: 0.2642, time(ms): 790.08, token/sec:663588.44, hellaswag_acc: 0.2768
Step:  5473, loss: 3.273603, norm: 0.2843, time(ms): 796.98, token/sec:657847.37, hellaswag_acc: 0.2768
Step:  5474, loss: 3.294726, norm: 0.2413, time(ms): 805.87, token/sec:650587.82, hellaswag_acc: 0.2768
Step:  5475, loss: 3.213618, norm: 0.2685, time(ms): 799.17, token/sec:656040.04, hellaswag_acc: 0.2768
Step:  5476, loss: 3.279610, norm: 0.2756, time(ms): 787.59, token/sec:665685.23, hellaswag_acc: 0.2768
Step:  5477, loss: 3.229188, norm: 0.2474, time(ms): 787.01, token/sec:666173.66, hellaswag_acc: 0.2768
Step:  5478, loss: 3.223845, norm: 0.2677, time(ms): 801.46, token/sec:654166.32, hellaswag_acc: 0.2768
Step:  5479, loss: 3.196814, norm: 0.2389, time(ms): 794.60, token/sec:659813.73, hellaswag_acc: 0.2768
Step:  5480, loss: 3.291801, norm: 0.2807, time(ms): 789.29, token/sec:664255.13, hellaswag_acc: 0.2768
Step:  5481, loss: 3.200627, norm: 0.2934, time(ms): 788.01, token/sec:665329.74, hellaswag_acc: 0.2768
Step:  5482, loss: 3.218874, norm: 0.2474, time(ms): 791.07, token/sec:662761.05, hellaswag_acc: 0.2768
Step:  5483, loss: 3.178644, norm: 0.2622, time(ms): 797.18, token/sec:657678.37, hellaswag_acc: 0.2768
Step:  5484, loss: 3.206707, norm: 0.2428, time(ms): 794.54, token/sec:659862.84, hellaswag_acc: 0.2768
Step:  5485, loss: 3.187947, norm: 0.2576, time(ms): 795.22, token/sec:659295.44, hellaswag_acc: 0.2768
Step:  5486, loss: 3.264213, norm: 0.2497, time(ms): 791.46, token/sec:662429.63, hellaswag_acc: 0.2768
Step:  5487, loss: 3.375561, norm: 0.2874, time(ms): 787.48, token/sec:665778.95, hellaswag_acc: 0.2768
Step:  5488, loss: 3.336433, norm: 0.2766, time(ms): 792.63, token/sec:661449.90, hellaswag_acc: 0.2768
Step:  5489, loss: 3.338656, norm: 0.2639, time(ms): 795.33, token/sec:659205.91, hellaswag_acc: 0.2768
Step:  5490, loss: 3.346053, norm: 0.2933, time(ms): 803.95, token/sec:652142.90, hellaswag_acc: 0.2768
Step:  5491, loss: 3.279677, norm: 0.2679, time(ms): 798.17, token/sec:656858.77, hellaswag_acc: 0.2768
Step:  5492, loss: 3.408141, norm: 0.3163, time(ms): 797.87, token/sec:657107.85, hellaswag_acc: 0.2768
Step:  5493, loss: 3.337209, norm: 0.2958, time(ms): 801.66, token/sec:654006.01, hellaswag_acc: 0.2768
Step:  5494, loss: 3.346151, norm: 0.3097, time(ms): 802.67, token/sec:653182.92, hellaswag_acc: 0.2768
Step:  5495, loss: 3.335277, norm: 0.3142, time(ms): 791.41, token/sec:662475.73, hellaswag_acc: 0.2768
Step:  5496, loss: 3.278979, norm: 0.2830, time(ms): 794.23, token/sec:660125.10, hellaswag_acc: 0.2768
Step:  5497, loss: 3.338557, norm: 0.2856, time(ms): 790.65, token/sec:663112.19, hellaswag_acc: 0.2768
Step:  5498, loss: 3.377906, norm: 0.2858, time(ms): 793.83, token/sec:660452.63, hellaswag_acc: 0.2768
Step:  5499, loss: 3.370022, norm: 0.2921, time(ms): 790.90, token/sec:662904.30, hellaswag_acc: 0.2768
rank 0 sample 0: Hello, I'm a language model, and I think it is an amazing piece of programming.
It helps when a user needs to be in the language to
rank 0 sample 1: Hello, I'm a language model, but now I'm just having fun as a student when I talk about other languages, I have a fun word hunt with
rank 0 sample 2: Hello, I'm a language model, I'm part of the business world. I just live in California where I'm not part of the business world, I
rank 0 sample 3: Hello, I'm a language model, but how do I get it right? I like to talk about using an online encyclopedia like a dictionary on a wiki of
rank 1 sample 0: Hello, I'm a language model, in which you have to look at objects. This makes it kind of easy to understand by going on a different page.
rank 1 sample 1: Hello, I'm a language model, you know that, it's pretty common in the US or in our daily commute, maybe about 80,000 miles away
rank 1 sample 2: Hello, I'm a language model, but maybe not in the general sense.
I'm just thinking that it's a good thing and a good example.
rank 1 sample 3: Hello, I'm a language model, and I'm the one here. In computer science, data scientist, linguists, the science-fiction writer, and
Step:  5500, loss: 3.360411, norm: 0.2594, time(ms): 4305.44, token/sec:121773.50, val_loss: 3.3252, hellaswag_acc: 0.2768
Step:  5501, loss: 3.380068, norm: 0.2612, time(ms): 782.20, token/sec:670271.05, hellaswag_acc: 0.2768
Step:  5502, loss: 3.335623, norm: 0.2633, time(ms): 790.43, token/sec:663297.01, hellaswag_acc: 0.2768
Step:  5503, loss: 3.301224, norm: 0.2830, time(ms): 791.77, token/sec:662170.72, hellaswag_acc: 0.2768
Step:  5504, loss: 3.315236, norm: 0.3004, time(ms): 807.33, token/sec:649409.87, hellaswag_acc: 0.2768
Step:  5505, loss: 3.316196, norm: 0.3029, time(ms): 785.37, token/sec:667567.25, hellaswag_acc: 0.2768
Step:  5506, loss: 3.343359, norm: 0.2743, time(ms): 786.70, token/sec:666436.32, hellaswag_acc: 0.2768
Step:  5507, loss: 3.331430, norm: 0.2859, time(ms): 794.29, token/sec:660069.62, hellaswag_acc: 0.2768
Step:  5508, loss: 3.294736, norm: 0.2786, time(ms): 792.50, token/sec:661564.12, hellaswag_acc: 0.2768
Step:  5509, loss: 3.314940, norm: 0.2868, time(ms): 791.56, token/sec:662344.83, hellaswag_acc: 0.2768
Step:  5510, loss: 3.319180, norm: 0.2952, time(ms): 793.83, token/sec:660457.59, hellaswag_acc: 0.2768
Step:  5511, loss: 3.297742, norm: 0.2789, time(ms): 786.88, token/sec:666288.31, hellaswag_acc: 0.2768
Step:  5512, loss: 3.304953, norm: 0.2697, time(ms): 797.60, token/sec:657330.01, hellaswag_acc: 0.2768
Step:  5513, loss: 3.308148, norm: 0.2684, time(ms): 789.41, token/sec:664150.41, hellaswag_acc: 0.2768
Step:  5514, loss: 3.276473, norm: 0.2812, time(ms): 787.56, token/sec:665709.41, hellaswag_acc: 0.2768
Step:  5515, loss: 3.280168, norm: 0.2755, time(ms): 787.37, token/sec:665870.68, hellaswag_acc: 0.2768
Step:  5516, loss: 3.289089, norm: 0.2547, time(ms): 797.72, token/sec:657235.51, hellaswag_acc: 0.2768
Step:  5517, loss: 3.304659, norm: 0.2925, time(ms): 807.58, token/sec:649210.09, hellaswag_acc: 0.2768
Step:  5518, loss: 3.241076, norm: 0.2330, time(ms): 791.51, token/sec:662386.53, hellaswag_acc: 0.2768
Step:  5519, loss: 3.302403, norm: 0.2646, time(ms): 797.45, token/sec:657453.82, hellaswag_acc: 0.2768
Step:  5520, loss: 3.249683, norm: 0.2553, time(ms): 788.36, token/sec:665032.56, hellaswag_acc: 0.2768
Step:  5521, loss: 3.336955, norm: 0.2548, time(ms): 793.07, token/sec:661086.80, hellaswag_acc: 0.2768
Step:  5522, loss: 3.222625, norm: 0.2592, time(ms): 792.92, token/sec:661209.44, hellaswag_acc: 0.2768
Step:  5523, loss: 3.195899, norm: 0.2641, time(ms): 787.41, token/sec:665838.21, hellaswag_acc: 0.2768
Step:  5524, loss: 3.303058, norm: 0.2844, time(ms): 16611.54, token/sec:31561.67, hellaswag_acc: 0.2768
Step:  5525, loss: 3.310817, norm: 0.2937, time(ms): 789.98, token/sec:663675.96, hellaswag_acc: 0.2768
Step:  5526, loss: 3.419424, norm: 0.2448, time(ms): 780.65, token/sec:671600.42, hellaswag_acc: 0.2768
Step:  5527, loss: 3.404320, norm: 0.2944, time(ms): 788.19, token/sec:665181.02, hellaswag_acc: 0.2768
Step:  5528, loss: 3.376286, norm: 0.2922, time(ms): 787.21, token/sec:666007.21, hellaswag_acc: 0.2768
Step:  5529, loss: 3.349505, norm: 0.2765, time(ms): 786.91, token/sec:666259.64, hellaswag_acc: 0.2768
Step:  5530, loss: 3.467162, norm: 0.3221, time(ms): 788.91, token/sec:664572.11, hellaswag_acc: 0.2768
Step:  5531, loss: 3.352225, norm: 0.2823, time(ms): 783.99, token/sec:668739.85, hellaswag_acc: 0.2768
Step:  5532, loss: 3.384659, norm: 0.2791, time(ms): 780.66, token/sec:671592.21, hellaswag_acc: 0.2768
Step:  5533, loss: 3.379036, norm: 0.2700, time(ms): 785.48, token/sec:667472.21, hellaswag_acc: 0.2768
Step:  5534, loss: 3.382823, norm: 0.2793, time(ms): 787.19, token/sec:666024.96, hellaswag_acc: 0.2768
Step:  5535, loss: 3.328452, norm: 0.2846, time(ms): 787.55, token/sec:665717.27, hellaswag_acc: 0.2768
Step:  5536, loss: 3.357866, norm: 0.2757, time(ms): 780.93, token/sec:671365.64, hellaswag_acc: 0.2768
Step:  5537, loss: 3.289917, norm: 0.2748, time(ms): 788.76, token/sec:664700.47, hellaswag_acc: 0.2768
Step:  5538, loss: 3.350343, norm: 0.2630, time(ms): 792.22, token/sec:661794.28, hellaswag_acc: 0.2768
Step:  5539, loss: 3.312037, norm: 0.2705, time(ms): 790.90, token/sec:662902.10, hellaswag_acc: 0.2768
Step:  5540, loss: 3.410990, norm: 0.3286, time(ms): 785.00, token/sec:667884.76, hellaswag_acc: 0.2768
Step:  5541, loss: 3.351764, norm: 0.3752, time(ms): 784.27, token/sec:668506.05, hellaswag_acc: 0.2768
Step:  5542, loss: 3.347115, norm: 0.3213, time(ms): 792.05, token/sec:661935.91, hellaswag_acc: 0.2768
Step:  5543, loss: 3.294986, norm: 0.4496, time(ms): 788.06, token/sec:665288.88, hellaswag_acc: 0.2768
Step:  5544, loss: 3.308255, norm: 0.4795, time(ms): 788.09, token/sec:665264.33, hellaswag_acc: 0.2768
Step:  5545, loss: 3.304129, norm: 0.3016, time(ms): 785.17, token/sec:667737.52, hellaswag_acc: 0.2768
Step:  5546, loss: 3.358953, norm: 0.3108, time(ms): 790.29, token/sec:663416.27, hellaswag_acc: 0.2768
Step:  5547, loss: 3.333721, norm: 0.2849, time(ms): 784.92, token/sec:667951.70, hellaswag_acc: 0.2768
Step:  5548, loss: 3.246813, norm: 0.3409, time(ms): 779.80, token/sec:672332.23, hellaswag_acc: 0.2768
Step:  5549, loss: 3.350549, norm: 0.3025, time(ms): 783.75, token/sec:668949.38, hellaswag_acc: 0.2768
Step:  5550, loss: 3.263650, norm: 0.2880, time(ms): 787.75, token/sec:665553.46, hellaswag_acc: 0.2768
Step:  5551, loss: 3.269069, norm: 0.2967, time(ms): 786.55, token/sec:666568.63, hellaswag_acc: 0.2768
Step:  5552, loss: 3.304278, norm: 0.2678, time(ms): 783.68, token/sec:669004.94, hellaswag_acc: 0.2768
Step:  5553, loss: 3.268467, norm: 0.2471, time(ms): 781.96, token/sec:670475.82, hellaswag_acc: 0.2768
Step:  5554, loss: 3.275777, norm: 0.2707, time(ms): 788.20, token/sec:665172.16, hellaswag_acc: 0.2768
Step:  5555, loss: 3.283638, norm: 0.2734, time(ms): 785.35, token/sec:667582.04, hellaswag_acc: 0.2768
Step:  5556, loss: 3.296199, norm: 0.4241, time(ms): 785.73, token/sec:667262.79, hellaswag_acc: 0.2768
Step:  5557, loss: 3.390057, norm: 0.2750, time(ms): 781.79, token/sec:670621.82, hellaswag_acc: 0.2768
Step:  5558, loss: 3.280073, norm: 0.2746, time(ms): 790.45, token/sec:663280.80, hellaswag_acc: 0.2768
Step:  5559, loss: 3.231372, norm: 0.2710, time(ms): 787.73, token/sec:665567.16, hellaswag_acc: 0.2768
Step:  5560, loss: 3.212817, norm: 0.2399, time(ms): 786.97, token/sec:666212.41, hellaswag_acc: 0.2768
Step:  5561, loss: 3.241007, norm: 0.2854, time(ms): 787.91, token/sec:665419.54, hellaswag_acc: 0.2768
Step:  5562, loss: 3.158136, norm: 0.2695, time(ms): 786.23, token/sec:666842.12, hellaswag_acc: 0.2768
Step:  5563, loss: 3.267827, norm: 0.2791, time(ms): 792.32, token/sec:661714.22, hellaswag_acc: 0.2768
Step:  5564, loss: 3.217300, norm: 0.2515, time(ms): 786.05, token/sec:666989.97, hellaswag_acc: 0.2768
Step:  5565, loss: 3.229550, norm: 0.2567, time(ms): 788.37, token/sec:665031.15, hellaswag_acc: 0.2768
Step:  5566, loss: 3.267601, norm: 0.2828, time(ms): 791.14, token/sec:662699.93, hellaswag_acc: 0.2768
Step:  5567, loss: 3.228829, norm: 0.2373, time(ms): 789.69, token/sec:663918.81, hellaswag_acc: 0.2768
Step:  5568, loss: 3.216675, norm: 0.3037, time(ms): 794.41, token/sec:659972.55, hellaswag_acc: 0.2768
Step:  5569, loss: 3.185965, norm: 0.2733, time(ms): 796.55, token/sec:658202.59, hellaswag_acc: 0.2768
Step:  5570, loss: 3.233856, norm: 0.2550, time(ms): 788.89, token/sec:664591.79, hellaswag_acc: 0.2768
Step:  5571, loss: 3.330702, norm: 0.2661, time(ms): 786.07, token/sec:666973.59, hellaswag_acc: 0.2768
Step:  5572, loss: 3.369903, norm: 0.2981, time(ms): 788.08, token/sec:665274.19, hellaswag_acc: 0.2768
Step:  5573, loss: 3.398707, norm: 0.2600, time(ms): 797.53, token/sec:657392.69, hellaswag_acc: 0.2768
Step:  5574, loss: 3.313275, norm: 0.2782, time(ms): 792.48, token/sec:661580.24, hellaswag_acc: 0.2768
Step:  5575, loss: 3.352254, norm: 0.2798, time(ms): 795.10, token/sec:659397.46, hellaswag_acc: 0.2768
Step:  5576, loss: 3.424932, norm: 0.2574, time(ms): 787.98, token/sec:665356.92, hellaswag_acc: 0.2768
Step:  5577, loss: 3.374389, norm: 0.3132, time(ms): 788.66, token/sec:664784.87, hellaswag_acc: 0.2768
Step:  5578, loss: 3.327031, norm: 0.2994, time(ms): 799.91, token/sec:655429.97, hellaswag_acc: 0.2768
Step:  5579, loss: 3.321643, norm: 0.2984, time(ms): 792.20, token/sec:661812.00, hellaswag_acc: 0.2768
Step:  5580, loss: 3.322167, norm: 0.2797, time(ms): 788.55, token/sec:664877.13, hellaswag_acc: 0.2768
Step:  5581, loss: 3.358938, norm: 0.2572, time(ms): 799.49, token/sec:655779.25, hellaswag_acc: 0.2768
Step:  5582, loss: 3.306517, norm: 0.2713, time(ms): 798.27, token/sec:656780.49, hellaswag_acc: 0.2768
Step:  5583, loss: 3.306136, norm: 0.2960, time(ms): 800.03, token/sec:655335.63, hellaswag_acc: 0.2768
Step:  5584, loss: 3.322396, norm: 0.2757, time(ms): 801.26, token/sec:654328.85, hellaswag_acc: 0.2768
Step:  5585, loss: 3.259123, norm: 0.2561, time(ms): 802.47, token/sec:653346.52, hellaswag_acc: 0.2768
Step:  5586, loss: 3.278248, norm: 0.2534, time(ms): 797.02, token/sec:657813.92, hellaswag_acc: 0.2768
Step:  5587, loss: 3.358562, norm: 0.2760, time(ms): 794.25, token/sec:660100.53, hellaswag_acc: 0.2768
Step:  5588, loss: 3.312436, norm: 0.2502, time(ms): 804.63, token/sec:651589.28, hellaswag_acc: 0.2768
Step:  5589, loss: 3.305485, norm: 0.2425, time(ms): 803.52, token/sec:652489.46, hellaswag_acc: 0.2768
Step:  5590, loss: 3.401958, norm: 0.2459, time(ms): 791.38, token/sec:662498.48, hellaswag_acc: 0.2768
Step:  5591, loss: 3.341577, norm: 0.2511, time(ms): 800.06, token/sec:655311.21, hellaswag_acc: 0.2768
Step:  5592, loss: 3.385104, norm: 0.2651, time(ms): 806.97, token/sec:649699.78, hellaswag_acc: 0.2768
Step:  5593, loss: 3.308581, norm: 0.2471, time(ms): 799.59, token/sec:655694.39, hellaswag_acc: 0.2768
Step:  5594, loss: 3.304955, norm: 0.2712, time(ms): 795.20, token/sec:659315.41, hellaswag_acc: 0.2768
Step:  5595, loss: 3.321998, norm: 0.2619, time(ms): 804.12, token/sec:651999.24, hellaswag_acc: 0.2768
Step:  5596, loss: 3.256731, norm: 0.2692, time(ms): 801.20, token/sec:654378.31, hellaswag_acc: 0.2768
Step:  5597, loss: 3.317348, norm: 0.2573, time(ms): 793.53, token/sec:660707.02, hellaswag_acc: 0.2768
Step:  5598, loss: 3.323480, norm: 0.2827, time(ms): 804.19, token/sec:651946.27, hellaswag_acc: 0.2768
Step:  5599, loss: 3.314926, norm: 0.2708, time(ms): 802.16, token/sec:653593.14, hellaswag_acc: 0.2768
Step:  5600, loss: 3.264303, norm: 0.2701, time(ms): 794.62, token/sec:659797.10, hellaswag_acc: 0.2768
Step:  5601, loss: 3.284593, norm: 0.2875, time(ms): 801.75, token/sec:653926.66, hellaswag_acc: 0.2768
Step:  5602, loss: 3.314179, norm: 0.2651, time(ms): 801.31, token/sec:654285.63, hellaswag_acc: 0.2768
Step:  5603, loss: 3.293860, norm: 0.2518, time(ms): 801.13, token/sec:654433.81, hellaswag_acc: 0.2768
Step:  5604, loss: 3.274448, norm: 0.2354, time(ms): 798.32, token/sec:656737.54, hellaswag_acc: 0.2768
Step:  5605, loss: 3.208035, norm: 0.2471, time(ms): 800.07, token/sec:655302.23, hellaswag_acc: 0.2768
Step:  5606, loss: 3.302502, norm: 0.2571, time(ms): 802.35, token/sec:653439.51, hellaswag_acc: 0.2768
Step:  5607, loss: 3.247338, norm: 0.2447, time(ms): 797.45, token/sec:657452.44, hellaswag_acc: 0.2768
Step:  5608, loss: 3.202441, norm: 0.2697, time(ms): 799.84, token/sec:655494.64, hellaswag_acc: 0.2768
Step:  5609, loss: 3.179081, norm: 0.2409, time(ms): 801.02, token/sec:654526.92, hellaswag_acc: 0.2768
Step:  5610, loss: 3.176921, norm: 0.2387, time(ms): 799.74, token/sec:655576.13, hellaswag_acc: 0.2768
Step:  5611, loss: 3.251134, norm: 0.2639, time(ms): 798.65, token/sec:656470.32, hellaswag_acc: 0.2768
Step:  5612, loss: 3.206564, norm: 0.2626, time(ms): 799.41, token/sec:655839.88, hellaswag_acc: 0.2768
Step:  5613, loss: 3.214419, norm: 0.2769, time(ms): 800.47, token/sec:654976.28, hellaswag_acc: 0.2768
Step:  5614, loss: 3.186138, norm: 0.2712, time(ms): 802.20, token/sec:653564.97, hellaswag_acc: 0.2768
Step:  5615, loss: 3.204685, norm: 0.3038, time(ms): 798.25, token/sec:656794.23, hellaswag_acc: 0.2768
Step:  5616, loss: 3.256474, norm: 0.3076, time(ms): 798.93, token/sec:656238.95, hellaswag_acc: 0.2768
Step:  5617, loss: 3.305884, norm: 0.3314, time(ms): 801.46, token/sec:654168.46, hellaswag_acc: 0.2768
Step:  5618, loss: 3.371801, norm: 0.3353, time(ms): 799.76, token/sec:655559.51, hellaswag_acc: 0.2768
Step:  5619, loss: 3.378555, norm: 0.3505, time(ms): 800.77, token/sec:654731.15, hellaswag_acc: 0.2768
Step:  5620, loss: 3.348677, norm: 0.3483, time(ms): 798.22, token/sec:656818.55, hellaswag_acc: 0.2768
Step:  5621, loss: 3.369199, norm: 0.2833, time(ms): 798.57, token/sec:656534.21, hellaswag_acc: 0.2768
Step:  5622, loss: 3.336972, norm: 0.3018, time(ms): 802.46, token/sec:653351.76, hellaswag_acc: 0.2768
Step:  5623, loss: 3.302704, norm: 0.2721, time(ms): 799.48, token/sec:655787.66, hellaswag_acc: 0.2768
Step:  5624, loss: 3.358448, norm: 0.2835, time(ms): 799.71, token/sec:655597.43, hellaswag_acc: 0.2768
Step:  5625, loss: 3.381395, norm: 0.2788, time(ms): 800.44, token/sec:655000.86, hellaswag_acc: 0.2768
Step:  5626, loss: 3.339920, norm: 0.2622, time(ms): 798.59, token/sec:656514.22, hellaswag_acc: 0.2768
Step:  5627, loss: 3.388579, norm: 0.3087, time(ms): 799.03, token/sec:656156.71, hellaswag_acc: 0.2768
Step:  5628, loss: 3.334674, norm: 0.2882, time(ms): 801.78, token/sec:653903.32, hellaswag_acc: 0.2768
Step:  5629, loss: 3.347448, norm: 0.3095, time(ms): 797.60, token/sec:657328.04, hellaswag_acc: 0.2768
Step:  5630, loss: 3.354311, norm: 0.3036, time(ms): 801.82, token/sec:653870.46, hellaswag_acc: 0.2768
Step:  5631, loss: 3.280999, norm: 0.2738, time(ms): 799.50, token/sec:655771.82, hellaswag_acc: 0.2768
Step:  5632, loss: 3.356904, norm: 0.2844, time(ms): 799.60, token/sec:655690.09, hellaswag_acc: 0.2768
Step:  5633, loss: 3.261947, norm: 0.2987, time(ms): 799.67, token/sec:655634.18, hellaswag_acc: 0.2768
Step:  5634, loss: 3.290290, norm: 0.2511, time(ms): 800.69, token/sec:654794.51, hellaswag_acc: 0.2768
Step:  5635, loss: 3.307051, norm: 0.2682, time(ms): 798.60, token/sec:656512.06, hellaswag_acc: 0.2768
Step:  5636, loss: 3.295974, norm: 0.2611, time(ms): 799.84, token/sec:655487.02, hellaswag_acc: 0.2768
Step:  5637, loss: 3.250885, norm: 0.2540, time(ms): 801.29, token/sec:654307.24, hellaswag_acc: 0.2768
Step:  5638, loss: 3.318205, norm: 0.2688, time(ms): 798.03, token/sec:656977.69, hellaswag_acc: 0.2768
Step:  5639, loss: 3.303454, norm: 0.2719, time(ms): 799.64, token/sec:655658.61, hellaswag_acc: 0.2768
Step:  5640, loss: 3.320791, norm: 0.2608, time(ms): 802.07, token/sec:653665.02, hellaswag_acc: 0.2768
Step:  5641, loss: 3.278447, norm: 0.2903, time(ms): 799.05, token/sec:656140.66, hellaswag_acc: 0.2768
Step:  5642, loss: 3.318496, norm: 0.2809, time(ms): 800.05, token/sec:655318.44, hellaswag_acc: 0.2768
Step:  5643, loss: 3.299643, norm: 0.2359, time(ms): 798.21, token/sec:656826.99, hellaswag_acc: 0.2768
Step:  5644, loss: 3.278775, norm: 0.2638, time(ms): 801.57, token/sec:654077.79, hellaswag_acc: 0.2768
Step:  5645, loss: 3.304501, norm: 0.2882, time(ms): 799.82, token/sec:655503.63, hellaswag_acc: 0.2768
Step:  5646, loss: 3.273109, norm: 0.2864, time(ms): 800.71, token/sec:654778.91, hellaswag_acc: 0.2768
Step:  5647, loss: 3.323100, norm: 0.2697, time(ms): 797.57, token/sec:657360.46, hellaswag_acc: 0.2768
Step:  5648, loss: 3.294240, norm: 0.2455, time(ms): 800.81, token/sec:654700.55, hellaswag_acc: 0.2768
Step:  5649, loss: 3.282825, norm: 0.2527, time(ms): 800.35, token/sec:655075.59, hellaswag_acc: 0.2768
Step:  5650, loss: 3.252579, norm: 0.2571, time(ms): 801.22, token/sec:654365.85, hellaswag_acc: 0.2768
Step:  5651, loss: 3.279073, norm: 0.2441, time(ms): 796.63, token/sec:658134.23, hellaswag_acc: 0.2768
Step:  5652, loss: 3.273690, norm: 0.2468, time(ms): 802.13, token/sec:653617.61, hellaswag_acc: 0.2768
Step:  5653, loss: 3.206944, norm: 0.2486, time(ms): 800.37, token/sec:655054.91, hellaswag_acc: 0.2768
Step:  5654, loss: 3.209507, norm: 0.2564, time(ms): 798.76, token/sec:656374.89, hellaswag_acc: 0.2768
Step:  5655, loss: 3.174526, norm: 0.2715, time(ms): 799.69, token/sec:655616.39, hellaswag_acc: 0.2768
Step:  5656, loss: 3.199914, norm: 0.2620, time(ms): 799.66, token/sec:655637.89, hellaswag_acc: 0.2768
Step:  5657, loss: 3.262640, norm: 0.2833, time(ms): 799.90, token/sec:655441.89, hellaswag_acc: 0.2768
Step:  5658, loss: 3.240474, norm: 0.2880, time(ms): 800.23, token/sec:655172.59, hellaswag_acc: 0.2768
Step:  5659, loss: 3.302023, norm: 0.2677, time(ms): 799.29, token/sec:655938.28, hellaswag_acc: 0.2768
Step:  5660, loss: 3.249161, norm: 0.3319, time(ms): 800.37, token/sec:655059.40, hellaswag_acc: 0.2768
Step:  5661, loss: 3.157524, norm: 0.3279, time(ms): 800.10, token/sec:655280.56, hellaswag_acc: 0.2768
Step:  5662, loss: 3.279666, norm: 0.2607, time(ms): 797.75, token/sec:657211.94, hellaswag_acc: 0.2768
Step:  5663, loss: 3.240922, norm: 0.2805, time(ms): 799.99, token/sec:655365.12, hellaswag_acc: 0.2768
Step:  5664, loss: 3.364146, norm: 0.3143, time(ms): 801.99, token/sec:653735.37, hellaswag_acc: 0.2768
Step:  5665, loss: 3.412657, norm: 0.3105, time(ms): 800.14, token/sec:655246.19, hellaswag_acc: 0.2768
Step:  5666, loss: 3.383883, norm: 0.3325, time(ms): 797.54, token/sec:657377.56, hellaswag_acc: 0.2768
Step:  5667, loss: 3.335390, norm: 0.2810, time(ms): 799.44, token/sec:655822.87, hellaswag_acc: 0.2768
Step:  5668, loss: 3.356444, norm: 0.3012, time(ms): 799.62, token/sec:655670.15, hellaswag_acc: 0.2768
Step:  5669, loss: 3.310956, norm: 0.2925, time(ms): 802.37, token/sec:653422.43, hellaswag_acc: 0.2768
Step:  5670, loss: 3.292073, norm: 0.2705, time(ms): 799.30, token/sec:655931.04, hellaswag_acc: 0.2768
Step:  5671, loss: 3.360018, norm: 0.2813, time(ms): 798.21, token/sec:656829.54, hellaswag_acc: 0.2768
Step:  5672, loss: 3.382107, norm: 0.2925, time(ms): 801.06, token/sec:654492.63, hellaswag_acc: 0.2768
Step:  5673, loss: 3.427919, norm: 0.2713, time(ms): 800.90, token/sec:654624.34, hellaswag_acc: 0.2768
Step:  5674, loss: 3.322263, norm: 0.3100, time(ms): 799.72, token/sec:655589.22, hellaswag_acc: 0.2768
Step:  5675, loss: 3.295994, norm: 0.2680, time(ms): 799.22, token/sec:655996.79, hellaswag_acc: 0.2768
Step:  5676, loss: 3.306677, norm: 0.2791, time(ms): 799.40, token/sec:655848.10, hellaswag_acc: 0.2768
Step:  5677, loss: 3.310042, norm: 0.2563, time(ms): 800.59, token/sec:654874.46, hellaswag_acc: 0.2768
Step:  5678, loss: 3.314055, norm: 0.3012, time(ms): 799.63, token/sec:655662.91, hellaswag_acc: 0.2768
Step:  5679, loss: 3.321342, norm: 0.2807, time(ms): 800.20, token/sec:655199.92, hellaswag_acc: 0.2768
Step:  5680, loss: 3.282477, norm: 0.2796, time(ms): 798.87, token/sec:656285.17, hellaswag_acc: 0.2768
Step:  5681, loss: 3.364509, norm: 0.2620, time(ms): 799.90, token/sec:655445.01, hellaswag_acc: 0.2768
Step:  5682, loss: 3.382236, norm: 0.3146, time(ms): 800.67, token/sec:654815.37, hellaswag_acc: 0.2768
Step:  5683, loss: 3.358740, norm: 0.2734, time(ms): 800.24, token/sec:655165.76, hellaswag_acc: 0.2768
Step:  5684, loss: 3.267623, norm: 0.2520, time(ms): 798.26, token/sec:656786.58, hellaswag_acc: 0.2768
Step:  5685, loss: 3.334723, norm: 0.2913, time(ms): 798.19, token/sec:656844.84, hellaswag_acc: 0.2768
Step:  5686, loss: 3.370792, norm: 0.2610, time(ms): 802.36, token/sec:653432.52, hellaswag_acc: 0.2768
Step:  5687, loss: 3.298100, norm: 0.2660, time(ms): 800.26, token/sec:655149.36, hellaswag_acc: 0.2768
Step:  5688, loss: 3.228335, norm: 0.2741, time(ms): 798.13, token/sec:656898.60, hellaswag_acc: 0.2768
Step:  5689, loss: 3.272727, norm: 0.2810, time(ms): 800.28, token/sec:655134.73, hellaswag_acc: 0.2768
Step:  5690, loss: 3.305239, norm: 0.2706, time(ms): 801.06, token/sec:654491.08, hellaswag_acc: 0.2768
Step:  5691, loss: 3.299925, norm: 0.2842, time(ms): 799.99, token/sec:655369.22, hellaswag_acc: 0.2768
Step:  5692, loss: 3.333487, norm: 0.3329, time(ms): 797.92, token/sec:657067.99, hellaswag_acc: 0.2768
Step:  5693, loss: 3.284188, norm: 0.3042, time(ms): 800.79, token/sec:654709.90, hellaswag_acc: 0.2768
Step:  5694, loss: 3.252445, norm: 0.2848, time(ms): 800.94, token/sec:654590.44, hellaswag_acc: 0.2768
Step:  5695, loss: 3.244430, norm: 0.2637, time(ms): 799.13, token/sec:656069.79, hellaswag_acc: 0.2768
Step:  5696, loss: 3.249945, norm: 0.2731, time(ms): 798.56, token/sec:656542.64, hellaswag_acc: 0.2768
Step:  5697, loss: 3.286882, norm: 0.2631, time(ms): 799.46, token/sec:655804.09, hellaswag_acc: 0.2768
Step:  5698, loss: 3.182033, norm: 0.2593, time(ms): 801.49, token/sec:654139.08, hellaswag_acc: 0.2768
Step:  5699, loss: 3.245659, norm: 0.2935, time(ms): 800.90, token/sec:654626.49, hellaswag_acc: 0.2768
Step:  5700, loss: 3.205765, norm: 0.2604, time(ms): 800.03, token/sec:655332.50, hellaswag_acc: 0.2768
Step:  5701, loss: 3.217749, norm: 0.2560, time(ms): 796.42, token/sec:658305.44, hellaswag_acc: 0.2768
Step:  5702, loss: 3.275253, norm: 0.2478, time(ms): 801.75, token/sec:653932.69, hellaswag_acc: 0.2768
Step:  5703, loss: 3.188144, norm: 0.2842, time(ms): 801.55, token/sec:654095.30, hellaswag_acc: 0.2768
Step:  5704, loss: 3.139926, norm: 0.2716, time(ms): 799.11, token/sec:656087.21, hellaswag_acc: 0.2768
Step:  5705, loss: 3.177446, norm: 0.2610, time(ms): 797.05, token/sec:657784.99, hellaswag_acc: 0.2768
Step:  5706, loss: 3.218976, norm: 0.2382, time(ms): 801.60, token/sec:654052.11, hellaswag_acc: 0.2768
Step:  5707, loss: 3.212528, norm: 0.2705, time(ms): 801.71, token/sec:653961.27, hellaswag_acc: 0.2768
Step:  5708, loss: 3.231842, norm: 0.2439, time(ms): 798.63, token/sec:656485.21, hellaswag_acc: 0.2768
Step:  5709, loss: 3.237335, norm: 0.2469, time(ms): 799.03, token/sec:656155.14, hellaswag_acc: 0.2768
Step:  5710, loss: 3.282668, norm: 0.2540, time(ms): 801.40, token/sec:654211.86, hellaswag_acc: 0.2768
Step:  5711, loss: 3.322732, norm: 0.2559, time(ms): 800.09, token/sec:655290.32, hellaswag_acc: 0.2768
Step:  5712, loss: 3.331519, norm: 0.2577, time(ms): 799.09, token/sec:656107.96, hellaswag_acc: 0.2768
Step:  5713, loss: 3.343763, norm: 0.2547, time(ms): 798.90, token/sec:656262.65, hellaswag_acc: 0.2768
Step:  5714, loss: 3.367103, norm: 0.2688, time(ms): 1281.79, token/sec:409026.70, hellaswag_acc: 0.2768
Step:  5715, loss: 3.255167, norm: 0.3066, time(ms): 771.84, token/sec:679271.70, hellaswag_acc: 0.2768
Step:  5716, loss: 3.276848, norm: 0.3524, time(ms): 788.69, token/sec:664761.56, hellaswag_acc: 0.2768
Step:  5717, loss: 3.235124, norm: 0.3135, time(ms): 803.08, token/sec:652844.54, hellaswag_acc: 0.2768
Step:  5718, loss: 3.313954, norm: 0.3224, time(ms): 790.91, token/sec:662893.11, hellaswag_acc: 0.2768
Step:  5719, loss: 3.309546, norm: 0.2855, time(ms): 790.52, token/sec:663219.19, hellaswag_acc: 0.2768
Step:  5720, loss: 3.379165, norm: 0.2860, time(ms): 788.79, token/sec:664675.76, hellaswag_acc: 0.2768
Step:  5721, loss: 3.365772, norm: 0.2999, time(ms): 800.65, token/sec:654830.58, hellaswag_acc: 0.2768
Step:  5722, loss: 3.315473, norm: 0.2761, time(ms): 803.20, token/sec:652750.36, hellaswag_acc: 0.2768
Step:  5723, loss: 3.304049, norm: 0.2671, time(ms): 792.30, token/sec:661725.57, hellaswag_acc: 0.2768
Step:  5724, loss: 3.297608, norm: 0.2669, time(ms): 797.30, token/sec:657581.61, hellaswag_acc: 0.2768
Step:  5725, loss: 3.321789, norm: 0.2584, time(ms): 805.23, token/sec:651107.35, hellaswag_acc: 0.2768
Step:  5726, loss: 3.309742, norm: 0.2783, time(ms): 801.78, token/sec:653901.57, hellaswag_acc: 0.2768
Step:  5727, loss: 3.356678, norm: 0.2442, time(ms): 800.75, token/sec:654747.72, hellaswag_acc: 0.2768
Step:  5728, loss: 3.291258, norm: 0.2654, time(ms): 799.48, token/sec:655788.44, hellaswag_acc: 0.2768
Step:  5729, loss: 3.298712, norm: 0.2714, time(ms): 798.25, token/sec:656796.19, hellaswag_acc: 0.2768
Step:  5730, loss: 3.390239, norm: 0.2635, time(ms): 799.43, token/sec:655826.58, hellaswag_acc: 0.2768
Step:  5731, loss: 3.409791, norm: 0.3529, time(ms): 803.75, token/sec:652302.11, hellaswag_acc: 0.2768
Step:  5732, loss: 3.300357, norm: 0.3189, time(ms): 797.29, token/sec:657590.65, hellaswag_acc: 0.2768
Step:  5733, loss: 3.308330, norm: 0.2669, time(ms): 799.72, token/sec:655590.20, hellaswag_acc: 0.2768
Step:  5734, loss: 3.328103, norm: 0.2850, time(ms): 802.16, token/sec:653593.52, hellaswag_acc: 0.2768
Step:  5735, loss: 3.358335, norm: 0.2949, time(ms): 794.86, token/sec:659601.57, hellaswag_acc: 0.2768
Step:  5736, loss: 3.295539, norm: 0.2761, time(ms): 801.61, token/sec:654043.94, hellaswag_acc: 0.2768
Step:  5737, loss: 3.301553, norm: 0.2879, time(ms): 801.66, token/sec:654001.73, hellaswag_acc: 0.2768
Step:  5738, loss: 3.342872, norm: 0.2886, time(ms): 800.35, token/sec:655070.13, hellaswag_acc: 0.2768
Step:  5739, loss: 3.334369, norm: 0.2640, time(ms): 797.53, token/sec:657391.32, hellaswag_acc: 0.2768
Step:  5740, loss: 3.327949, norm: 0.2783, time(ms): 800.17, token/sec:655223.54, hellaswag_acc: 0.2768
Step:  5741, loss: 3.313398, norm: 0.2438, time(ms): 801.05, token/sec:654502.18, hellaswag_acc: 0.2768
Step:  5742, loss: 3.273791, norm: 0.2538, time(ms): 799.41, token/sec:655844.77, hellaswag_acc: 0.2768
Step:  5743, loss: 3.269098, norm: 0.2639, time(ms): 797.89, token/sec:657089.98, hellaswag_acc: 0.2768
Step:  5744, loss: 3.290850, norm: 0.2364, time(ms): 800.45, token/sec:654992.08, hellaswag_acc: 0.2768
Step:  5745, loss: 3.238708, norm: 0.2580, time(ms): 803.57, token/sec:652445.91, hellaswag_acc: 0.2768
Step:  5746, loss: 3.253661, norm: 0.2757, time(ms): 800.11, token/sec:655268.06, hellaswag_acc: 0.2768
Step:  5747, loss: 3.271604, norm: 0.2636, time(ms): 791.33, token/sec:662542.19, hellaswag_acc: 0.2768
Step:  5748, loss: 3.355832, norm: 0.3161, time(ms): 802.19, token/sec:653572.74, hellaswag_acc: 0.2768
Step:  5749, loss: 3.265658, norm: 0.3713, time(ms): 804.75, token/sec:651487.74, hellaswag_acc: 0.2768
rank 0 sample 0: Hello, I'm a language model, and I was going through what we saw above. Now I'm really aware that I am reading in this chapter, because
rank 0 sample 1: Hello, I'm a language model, I do not know the language but see the way some cultures have different needs to live. And so here, I think
rank 0 sample 2: Hello, I'm a language model, so I wanted to work as a student in any language. In English, I am teaching my students to speak the German
rank 0 sample 3: Hello, I'm a language model, I say, the language is the language that talks about the grammar of the English language. For me, it's easy
rank 1 sample 0: Hello, I'm a language model, just a big deal.
We put it down into your context.
OK, now let's go over the basics
rank 1 sample 1: Hello, I'm a language model, which I think I have learned, that makes it much closer to human comprehension than how someone "could understand" a word
rank 1 sample 2: Hello, I'm a language model, I write in an imperative language, I'm a language model! And so I'm going to teach a lot! I
rank 1 sample 3: Hello, I'm a language model, and I'm using a "nuclease" as the second one that allows me to "fill in" (which
Step:  5750, loss: 3.246322, norm: 0.3178, time(ms): 3825.35, token/sec:137056.22, val_loss: 3.3124, hellaswag_acc: 0.2768
Step:  5751, loss: 3.306506, norm: 0.2807, time(ms): 794.69, token/sec:659740.89, hellaswag_acc: 0.2768
Step:  5752, loss: 3.292822, norm: 0.3136, time(ms): 791.23, token/sec:662625.44, hellaswag_acc: 0.2768
Step:  5753, loss: 3.306834, norm: 0.3027, time(ms): 805.71, token/sec:650715.26, hellaswag_acc: 0.2768
Step:  5754, loss: 3.349116, norm: 0.2969, time(ms): 804.50, token/sec:651696.07, hellaswag_acc: 0.2768
Step:  5755, loss: 3.292457, norm: 0.3474, time(ms): 790.72, token/sec:663050.01, hellaswag_acc: 0.2768
Step:  5756, loss: 3.338535, norm: 0.3290, time(ms): 803.54, token/sec:652468.75, hellaswag_acc: 0.2768
Step:  5757, loss: 3.327233, norm: 0.2679, time(ms): 800.50, token/sec:654947.21, hellaswag_acc: 0.2768
Step:  5758, loss: 3.394029, norm: 0.3388, time(ms): 802.95, token/sec:652948.24, hellaswag_acc: 0.2768
Step:  5759, loss: 3.354323, norm: 0.3181, time(ms): 798.71, token/sec:656418.19, hellaswag_acc: 0.2768
Step:  5760, loss: 3.307858, norm: 0.2783, time(ms): 800.68, token/sec:654805.04, hellaswag_acc: 0.2768
Step:  5761, loss: 3.324158, norm: 0.2968, time(ms): 799.18, token/sec:656035.74, hellaswag_acc: 0.2768
Step:  5762, loss: 3.325541, norm: 0.2729, time(ms): 801.79, token/sec:653900.60, hellaswag_acc: 0.2768
Step:  5763, loss: 3.296519, norm: 0.2729, time(ms): 796.65, token/sec:658114.73, hellaswag_acc: 0.2768
Step:  5764, loss: 3.342467, norm: 0.3098, time(ms): 802.17, token/sec:653583.23, hellaswag_acc: 0.2768
Step:  5765, loss: 3.388441, norm: 0.3103, time(ms): 800.37, token/sec:655057.44, hellaswag_acc: 0.2768
Step:  5766, loss: 3.379084, norm: 0.2846, time(ms): 798.65, token/sec:656469.92, hellaswag_acc: 0.2768
Step:  5767, loss: 3.256722, norm: 0.2884, time(ms): 800.34, token/sec:655083.79, hellaswag_acc: 0.2768
Step:  5768, loss: 3.360633, norm: 0.2695, time(ms): 797.25, token/sec:657617.79, hellaswag_acc: 0.2768
Step:  5769, loss: 3.323702, norm: 0.2621, time(ms): 802.90, token/sec:652991.48, hellaswag_acc: 0.2768
Step:  5770, loss: 3.317691, norm: 0.2955, time(ms): 799.15, token/sec:656054.33, hellaswag_acc: 0.2768
Step:  5771, loss: 3.326481, norm: 0.2738, time(ms): 795.95, token/sec:658693.51, hellaswag_acc: 0.2768
Step:  5772, loss: 3.339847, norm: 0.2619, time(ms): 801.98, token/sec:653740.81, hellaswag_acc: 0.2768
Step:  5773, loss: 3.347841, norm: 0.2457, time(ms): 801.73, token/sec:653945.71, hellaswag_acc: 0.2768
Step:  5774, loss: 3.279932, norm: 0.2646, time(ms): 799.38, token/sec:655867.07, hellaswag_acc: 0.2768
Step:  5775, loss: 3.281464, norm: 0.2656, time(ms): 798.29, token/sec:656759.90, hellaswag_acc: 0.2768
Step:  5776, loss: 3.276853, norm: 0.2592, time(ms): 799.62, token/sec:655674.45, hellaswag_acc: 0.2768
Step:  5777, loss: 3.234310, norm: 0.2529, time(ms): 802.32, token/sec:653463.40, hellaswag_acc: 0.2768
Step:  5778, loss: 3.264489, norm: 0.2583, time(ms): 799.19, token/sec:656025.36, hellaswag_acc: 0.2768
Step:  5779, loss: 3.298080, norm: 0.2560, time(ms): 799.20, token/sec:656014.60, hellaswag_acc: 0.2768
Step:  5780, loss: 3.326842, norm: 0.3027, time(ms): 800.52, token/sec:654936.09, hellaswag_acc: 0.2768
Step:  5781, loss: 3.233771, norm: 0.2327, time(ms): 800.22, token/sec:655178.25, hellaswag_acc: 0.2768
Step:  5782, loss: 3.288568, norm: 0.2662, time(ms): 797.26, token/sec:657614.64, hellaswag_acc: 0.2768
Step:  5783, loss: 3.298240, norm: 0.2590, time(ms): 802.90, token/sec:652994.39, hellaswag_acc: 0.2768
Step:  5784, loss: 3.334238, norm: 0.2663, time(ms): 799.27, token/sec:655960.00, hellaswag_acc: 0.2768
Step:  5785, loss: 3.268119, norm: 0.2501, time(ms): 796.60, token/sec:658159.64, hellaswag_acc: 0.2768
Step:  5786, loss: 3.303153, norm: 0.2503, time(ms): 803.35, token/sec:652627.53, hellaswag_acc: 0.2768
Step:  5787, loss: 3.283609, norm: 0.2587, time(ms): 797.70, token/sec:657246.90, hellaswag_acc: 0.2768
Step:  5788, loss: 3.326974, norm: 0.2661, time(ms): 801.53, token/sec:654107.94, hellaswag_acc: 0.2768
Step:  5789, loss: 3.330327, norm: 0.2779, time(ms): 800.30, token/sec:655112.67, hellaswag_acc: 0.2768
Step:  5790, loss: 3.321675, norm: 0.2611, time(ms): 798.99, token/sec:656192.54, hellaswag_acc: 0.2768
Step:  5791, loss: 3.304231, norm: 0.2807, time(ms): 800.42, token/sec:655019.01, hellaswag_acc: 0.2768
Step:  5792, loss: 3.328260, norm: 0.2655, time(ms): 799.59, token/sec:655695.76, hellaswag_acc: 0.2768
Step:  5793, loss: 3.332353, norm: 0.2737, time(ms): 799.14, token/sec:656067.44, hellaswag_acc: 0.2768
Step:  5794, loss: 3.316935, norm: 0.3288, time(ms): 800.06, token/sec:655310.43, hellaswag_acc: 0.2768
Step:  5795, loss: 3.346200, norm: 0.2878, time(ms): 800.99, token/sec:654546.99, hellaswag_acc: 0.2768
Step:  5796, loss: 3.325465, norm: 0.2983, time(ms): 797.87, token/sec:657110.99, hellaswag_acc: 0.2768
Step:  5797, loss: 3.344389, norm: 0.3095, time(ms): 800.86, token/sec:654655.33, hellaswag_acc: 0.2768
Step:  5798, loss: 3.316699, norm: 0.2959, time(ms): 798.74, token/sec:656394.68, hellaswag_acc: 0.2768
Step:  5799, loss: 3.294181, norm: 0.2846, time(ms): 801.37, token/sec:654239.11, hellaswag_acc: 0.2768
Step:  5800, loss: 3.363254, norm: 0.2639, time(ms): 800.75, token/sec:654746.94, hellaswag_acc: 0.2768
Step:  5801, loss: 3.310187, norm: 0.2728, time(ms): 797.21, token/sec:657654.17, hellaswag_acc: 0.2768
Step:  5802, loss: 3.311154, norm: 0.2741, time(ms): 797.39, token/sec:657508.27, hellaswag_acc: 0.2768
Step:  5803, loss: 3.322732, norm: 0.2649, time(ms): 801.98, token/sec:653739.84, hellaswag_acc: 0.2768
Step:  5804, loss: 3.345180, norm: 0.2573, time(ms): 802.14, token/sec:653613.15, hellaswag_acc: 0.2768
Step:  5805, loss: 3.310362, norm: 0.2588, time(ms): 799.28, token/sec:655947.28, hellaswag_acc: 0.2768
Step:  5806, loss: 3.336091, norm: 0.2885, time(ms): 798.34, token/sec:656722.83, hellaswag_acc: 0.2768
Step:  5807, loss: 3.360764, norm: 0.2328, time(ms): 801.82, token/sec:653871.24, hellaswag_acc: 0.2768
Step:  5808, loss: 3.345376, norm: 0.2844, time(ms): 799.29, token/sec:655946.11, hellaswag_acc: 0.2768
Step:  5809, loss: 3.349085, norm: 0.2543, time(ms): 798.36, token/sec:656710.08, hellaswag_acc: 0.2768
Step:  5810, loss: 3.269995, norm: 0.2574, time(ms): 801.24, token/sec:654347.74, hellaswag_acc: 0.2768
Step:  5811, loss: 3.302794, norm: 0.2657, time(ms): 796.57, token/sec:658180.52, hellaswag_acc: 0.2768
Step:  5812, loss: 3.331613, norm: 0.2732, time(ms): 804.34, token/sec:651824.72, hellaswag_acc: 0.2768
Step:  5813, loss: 3.304998, norm: 0.2966, time(ms): 797.52, token/sec:657401.93, hellaswag_acc: 0.2768
Step:  5814, loss: 3.271666, norm: 0.2482, time(ms): 800.75, token/sec:654748.70, hellaswag_acc: 0.2768
Step:  5815, loss: 3.260180, norm: 0.2636, time(ms): 799.34, token/sec:655900.52, hellaswag_acc: 0.2768
Step:  5816, loss: 3.304874, norm: 0.2563, time(ms): 800.71, token/sec:654775.60, hellaswag_acc: 0.2768
Step:  5817, loss: 3.268178, norm: 0.2845, time(ms): 799.52, token/sec:655752.85, hellaswag_acc: 0.2768
Step:  5818, loss: 3.290569, norm: 0.2704, time(ms): 800.34, token/sec:655081.84, hellaswag_acc: 0.2768
Step:  5819, loss: 3.246339, norm: 0.2735, time(ms): 798.01, token/sec:656993.99, hellaswag_acc: 0.2768
Step:  5820, loss: 3.264170, norm: 0.2559, time(ms): 800.21, token/sec:655190.16, hellaswag_acc: 0.2768
Step:  5821, loss: 3.275396, norm: 0.2510, time(ms): 802.11, token/sec:653632.96, hellaswag_acc: 0.2768
Step:  5822, loss: 3.272851, norm: 0.2775, time(ms): 798.63, token/sec:656486.78, hellaswag_acc: 0.2768
Step:  5823, loss: 3.284894, norm: 0.3432, time(ms): 799.46, token/sec:655805.07, hellaswag_acc: 0.2768
Step:  5824, loss: 3.288784, norm: 0.2797, time(ms): 799.64, token/sec:655658.81, hellaswag_acc: 0.2768
Step:  5825, loss: 3.300867, norm: 0.3117, time(ms): 801.09, token/sec:654465.56, hellaswag_acc: 0.2768
Step:  5826, loss: 3.286211, norm: 0.3375, time(ms): 800.56, token/sec:654905.47, hellaswag_acc: 0.2768
Step:  5827, loss: 3.311291, norm: 0.2771, time(ms): 797.15, token/sec:657700.20, hellaswag_acc: 0.2768
Step:  5828, loss: 3.293895, norm: 0.3008, time(ms): 801.10, token/sec:654458.74, hellaswag_acc: 0.2768
Step:  5829, loss: 3.382058, norm: 0.2591, time(ms): 800.51, token/sec:654939.41, hellaswag_acc: 0.2768
Step:  5830, loss: 3.299155, norm: 0.2905, time(ms): 799.01, token/sec:656170.22, hellaswag_acc: 0.2768
Step:  5831, loss: 3.348249, norm: 0.2929, time(ms): 800.24, token/sec:655164.39, hellaswag_acc: 0.2768
Step:  5832, loss: 3.340697, norm: 0.2853, time(ms): 800.48, token/sec:654970.62, hellaswag_acc: 0.2768
Step:  5833, loss: 3.300131, norm: 0.2958, time(ms): 796.02, token/sec:658639.85, hellaswag_acc: 0.2768
Step:  5834, loss: 3.351165, norm: 0.3011, time(ms): 803.18, token/sec:652765.66, hellaswag_acc: 0.2768
Step:  5835, loss: 3.296657, norm: 0.2695, time(ms): 799.79, token/sec:655528.83, hellaswag_acc: 0.2768
Step:  5836, loss: 3.285244, norm: 0.3176, time(ms): 791.82, token/sec:662130.64, hellaswag_acc: 0.2768
Step:  5837, loss: 3.396111, norm: 0.2784, time(ms): 794.50, token/sec:659893.53, hellaswag_acc: 0.2768
Step:  5838, loss: 3.335680, norm: 0.2741, time(ms): 793.48, token/sec:660742.16, hellaswag_acc: 0.2768
Step:  5839, loss: 3.381891, norm: 0.3202, time(ms): 794.89, token/sec:659570.12, hellaswag_acc: 0.2768
Step:  5840, loss: 3.320860, norm: 0.3151, time(ms): 792.42, token/sec:661624.83, hellaswag_acc: 0.2768
Step:  5841, loss: 3.269603, norm: 0.3031, time(ms): 791.76, token/sec:662181.28, hellaswag_acc: 0.2768
Step:  5842, loss: 3.271957, norm: 0.2653, time(ms): 801.20, token/sec:654375.00, hellaswag_acc: 0.2768
Step:  5843, loss: 3.348898, norm: 0.2410, time(ms): 793.27, token/sec:660921.49, hellaswag_acc: 0.2768
Step:  5844, loss: 3.281536, norm: 0.2476, time(ms): 794.32, token/sec:660043.66, hellaswag_acc: 0.2768
Step:  5845, loss: 3.328041, norm: 0.2678, time(ms): 789.46, token/sec:664106.68, hellaswag_acc: 0.2768
Step:  5846, loss: 3.262376, norm: 0.2686, time(ms): 792.08, token/sec:661908.82, hellaswag_acc: 0.2768
Step:  5847, loss: 3.236025, norm: 0.2561, time(ms): 790.18, token/sec:663501.14, hellaswag_acc: 0.2768
Step:  5848, loss: 3.291962, norm: 0.2305, time(ms): 789.20, token/sec:664332.39, hellaswag_acc: 0.2768
Step:  5849, loss: 3.311267, norm: 0.2536, time(ms): 791.11, token/sec:662724.69, hellaswag_acc: 0.2768
Step:  5850, loss: 3.263350, norm: 0.2583, time(ms): 796.02, token/sec:658637.68, hellaswag_acc: 0.2768
Step:  5851, loss: 3.262984, norm: 0.2799, time(ms): 792.52, token/sec:661546.21, hellaswag_acc: 0.2768
Step:  5852, loss: 3.272128, norm: 0.2763, time(ms): 789.53, token/sec:664054.94, hellaswag_acc: 0.2768
Step:  5853, loss: 3.272332, norm: 0.2658, time(ms): 790.14, token/sec:663537.98, hellaswag_acc: 0.2768
Step:  5854, loss: 3.252644, norm: 0.2591, time(ms): 792.82, token/sec:661292.96, hellaswag_acc: 0.2768
Step:  5855, loss: 3.274134, norm: 0.2688, time(ms): 793.68, token/sec:660581.98, hellaswag_acc: 0.2768
Step:  5856, loss: 3.239755, norm: 0.2645, time(ms): 797.08, token/sec:657762.96, hellaswag_acc: 0.2768
Step:  5857, loss: 3.335239, norm: 0.2670, time(ms): 802.46, token/sec:653347.68, hellaswag_acc: 0.2768
Step:  5858, loss: 3.281368, norm: 0.2536, time(ms): 802.87, token/sec:653016.50, hellaswag_acc: 0.2768
Step:  5859, loss: 3.305990, norm: 0.2464, time(ms): 790.48, token/sec:663250.59, hellaswag_acc: 0.2768
Step:  5860, loss: 3.377425, norm: 0.2748, time(ms): 803.23, token/sec:652721.29, hellaswag_acc: 0.2768
Step:  5861, loss: 3.366171, norm: 0.2404, time(ms): 804.70, token/sec:651535.42, hellaswag_acc: 0.2768
Step:  5862, loss: 3.344821, norm: 0.2942, time(ms): 795.58, token/sec:659001.05, hellaswag_acc: 0.2768
Step:  5863, loss: 3.345586, norm: 0.3005, time(ms): 804.06, token/sec:652047.18, hellaswag_acc: 0.2768
Step:  5864, loss: 3.317877, norm: 0.2682, time(ms): 795.89, token/sec:658747.58, hellaswag_acc: 0.2768
Step:  5865, loss: 3.269495, norm: 0.3016, time(ms): 802.78, token/sec:653091.16, hellaswag_acc: 0.2768
Step:  5866, loss: 3.340470, norm: 0.2911, time(ms): 791.34, token/sec:662528.82, hellaswag_acc: 0.2768
Step:  5867, loss: 3.311832, norm: 0.2702, time(ms): 790.43, token/sec:663294.80, hellaswag_acc: 0.2768
Step:  5868, loss: 3.353940, norm: 0.2757, time(ms): 789.76, token/sec:663856.28, hellaswag_acc: 0.2768
Step:  5869, loss: 3.342572, norm: 0.2936, time(ms): 790.31, token/sec:663394.86, hellaswag_acc: 0.2768
Step:  5870, loss: 3.336462, norm: 0.2739, time(ms): 796.98, token/sec:657840.49, hellaswag_acc: 0.2768
Step:  5871, loss: 3.325176, norm: 0.2506, time(ms): 793.23, token/sec:660956.85, hellaswag_acc: 0.2768
Step:  5872, loss: 3.353972, norm: 0.2587, time(ms): 795.63, token/sec:658963.53, hellaswag_acc: 0.2768
Step:  5873, loss: 3.380331, norm: 0.2740, time(ms): 793.13, token/sec:661037.12, hellaswag_acc: 0.2768
Step:  5874, loss: 3.296416, norm: 0.3158, time(ms): 793.98, token/sec:660330.26, hellaswag_acc: 0.2768
Step:  5875, loss: 3.337060, norm: 0.3743, time(ms): 794.20, token/sec:660147.29, hellaswag_acc: 0.2768
Step:  5876, loss: 3.309517, norm: 0.3274, time(ms): 789.11, token/sec:664407.86, hellaswag_acc: 0.2768
Step:  5877, loss: 3.326000, norm: 0.2943, time(ms): 788.35, token/sec:665044.22, hellaswag_acc: 0.2768
Step:  5878, loss: 3.289331, norm: 0.3328, time(ms): 791.44, token/sec:662451.78, hellaswag_acc: 0.2768
Step:  5879, loss: 3.294919, norm: 0.2680, time(ms): 799.95, token/sec:655403.99, hellaswag_acc: 0.2768
Step:  5880, loss: 3.282999, norm: 0.2843, time(ms): 798.27, token/sec:656784.22, hellaswag_acc: 0.2768
Step:  5881, loss: 3.265121, norm: 0.2640, time(ms): 803.44, token/sec:652551.62, hellaswag_acc: 0.2768
Step:  5882, loss: 3.275872, norm: 0.2733, time(ms): 799.31, token/sec:655923.41, hellaswag_acc: 0.2768
Step:  5883, loss: 3.310703, norm: 0.3122, time(ms): 795.11, token/sec:659390.34, hellaswag_acc: 0.2768
Step:  5884, loss: 3.234153, norm: 0.2955, time(ms): 802.99, token/sec:652919.75, hellaswag_acc: 0.2768
Step:  5885, loss: 3.286064, norm: 0.2819, time(ms): 796.86, token/sec:657938.70, hellaswag_acc: 0.2768
Step:  5886, loss: 3.283333, norm: 0.2467, time(ms): 803.74, token/sec:652312.75, hellaswag_acc: 0.2768
Step:  5887, loss: 3.277989, norm: 0.2809, time(ms): 799.58, token/sec:655702.41, hellaswag_acc: 0.2768
Step:  5888, loss: 3.293036, norm: 0.2959, time(ms): 799.68, token/sec:655622.06, hellaswag_acc: 0.2768
Step:  5889, loss: 3.289605, norm: 0.2549, time(ms): 799.07, token/sec:656125.39, hellaswag_acc: 0.2768
Step:  5890, loss: 3.308977, norm: 0.2837, time(ms): 796.52, token/sec:658219.34, hellaswag_acc: 0.2768
Step:  5891, loss: 3.350459, norm: 0.2862, time(ms): 800.81, token/sec:654693.72, hellaswag_acc: 0.2768
Step:  5892, loss: 3.308517, norm: 0.2879, time(ms): 803.71, token/sec:652332.68, hellaswag_acc: 0.2768
Step:  5893, loss: 3.356017, norm: 0.2833, time(ms): 799.79, token/sec:655533.33, hellaswag_acc: 0.2768
Step:  5894, loss: 3.304792, norm: 0.3398, time(ms): 791.85, token/sec:662101.53, hellaswag_acc: 0.2768
Step:  5895, loss: 3.385447, norm: 0.7634, time(ms): 807.28, token/sec:649449.57, hellaswag_acc: 0.2768
Step:  5896, loss: 3.289193, norm: 0.4553, time(ms): 798.05, token/sec:656962.78, hellaswag_acc: 0.2768
Step:  5897, loss: 3.381804, norm: 0.3860, time(ms): 793.73, token/sec:660534.56, hellaswag_acc: 0.2768
Step:  5898, loss: 3.340701, norm: 0.4270, time(ms): 797.81, token/sec:657160.87, hellaswag_acc: 0.2768
Step:  5899, loss: 3.437291, norm: 0.3456, time(ms): 788.89, token/sec:664586.57, hellaswag_acc: 0.2768
Step:  5900, loss: 3.335847, norm: 0.3807, time(ms): 791.55, token/sec:662357.20, hellaswag_acc: 0.2768
Step:  5901, loss: 3.365896, norm: 0.2973, time(ms): 791.21, token/sec:662636.83, hellaswag_acc: 0.2768
Step:  5902, loss: 3.339854, norm: 0.3508, time(ms): 796.75, token/sec:658034.38, hellaswag_acc: 0.2768
Step:  5903, loss: 3.366802, norm: 0.2862, time(ms): 798.14, token/sec:656889.97, hellaswag_acc: 0.2768
Step:  5904, loss: 3.309732, norm: 0.3072, time(ms): 797.64, token/sec:657295.43, hellaswag_acc: 0.2768
Step:  5905, loss: 3.314621, norm: 0.2804, time(ms): 1243.74, token/sec:421540.72, hellaswag_acc: 0.2768
Step:  5906, loss: 3.398496, norm: 0.2939, time(ms): 804.44, token/sec:651741.84, hellaswag_acc: 0.2768
Step:  5907, loss: 3.333620, norm: 0.2880, time(ms): 785.06, token/sec:667833.24, hellaswag_acc: 0.2768
Step:  5908, loss: 3.349252, norm: 0.2781, time(ms): 793.91, token/sec:660384.80, hellaswag_acc: 0.2768
Step:  5909, loss: 3.413074, norm: 0.2809, time(ms): 793.19, token/sec:660984.06, hellaswag_acc: 0.2768
Step:  5910, loss: 3.312480, norm: 0.2591, time(ms): 805.75, token/sec:650681.57, hellaswag_acc: 0.2768
Step:  5911, loss: 3.353120, norm: 0.2583, time(ms): 789.27, token/sec:664270.98, hellaswag_acc: 0.2768
Step:  5912, loss: 3.325875, norm: 0.2558, time(ms): 795.36, token/sec:659183.39, hellaswag_acc: 0.2768
Step:  5913, loss: 3.346964, norm: 0.2482, time(ms): 792.16, token/sec:661848.06, hellaswag_acc: 0.2768
Step:  5914, loss: 3.318587, norm: 0.2605, time(ms): 801.06, token/sec:654494.39, hellaswag_acc: 0.2768
Step:  5915, loss: 3.346885, norm: 0.2372, time(ms): 796.04, token/sec:658623.87, hellaswag_acc: 0.2768
Step:  5916, loss: 3.336164, norm: 0.2487, time(ms): 795.09, token/sec:659402.99, hellaswag_acc: 0.2768
Step:  5917, loss: 3.277539, norm: 0.3059, time(ms): 791.27, token/sec:662593.50, hellaswag_acc: 0.2768
Step:  5918, loss: 3.332375, norm: 0.2500, time(ms): 789.71, token/sec:663896.56, hellaswag_acc: 0.2768
Step:  5919, loss: 3.402373, norm: 0.2708, time(ms): 792.79, token/sec:661321.20, hellaswag_acc: 0.2768
Step:  5920, loss: 3.267622, norm: 0.2788, time(ms): 788.77, token/sec:664687.01, hellaswag_acc: 0.2768
Step:  5921, loss: 3.264529, norm: 0.2676, time(ms): 791.33, token/sec:662536.60, hellaswag_acc: 0.2768
Step:  5922, loss: 3.285584, norm: 0.2615, time(ms): 792.11, token/sec:661887.50, hellaswag_acc: 0.2768
Step:  5923, loss: 3.261059, norm: 0.2608, time(ms): 798.44, token/sec:656639.09, hellaswag_acc: 0.2768
Step:  5924, loss: 3.316622, norm: 0.2487, time(ms): 800.19, token/sec:655203.83, hellaswag_acc: 0.2768
Step:  5925, loss: 3.264395, norm: 0.2522, time(ms): 803.47, token/sec:652532.45, hellaswag_acc: 0.2768
Step:  5926, loss: 3.235852, norm: 0.2584, time(ms): 788.95, token/sec:664540.78, hellaswag_acc: 0.2768
Step:  5927, loss: 3.277235, norm: 0.2629, time(ms): 790.02, token/sec:663641.31, hellaswag_acc: 0.2768
Step:  5928, loss: 3.289677, norm: 0.2720, time(ms): 794.05, token/sec:660268.20, hellaswag_acc: 0.2768
Step:  5929, loss: 3.316052, norm: 0.2430, time(ms): 793.07, token/sec:661086.80, hellaswag_acc: 0.2768
Step:  5930, loss: 3.319809, norm: 0.2662, time(ms): 792.96, token/sec:661181.21, hellaswag_acc: 0.2768
Step:  5931, loss: 3.166056, norm: 0.2722, time(ms): 796.72, token/sec:658056.24, hellaswag_acc: 0.2768
Step:  5932, loss: 3.123729, norm: 0.2980, time(ms): 798.77, token/sec:656372.73, hellaswag_acc: 0.2768
Step:  5933, loss: 3.094854, norm: 0.2778, time(ms): 797.93, token/sec:657062.89, hellaswag_acc: 0.2768
Step:  5934, loss: 3.101713, norm: 0.2620, time(ms): 800.60, token/sec:654869.39, hellaswag_acc: 0.2768
Step:  5935, loss: 3.062803, norm: 0.2797, time(ms): 796.78, token/sec:658004.65, hellaswag_acc: 0.2768
Step:  5936, loss: 3.076908, norm: 0.3317, time(ms): 797.48, token/sec:657429.64, hellaswag_acc: 0.2768
Step:  5937, loss: 3.125330, norm: 0.3905, time(ms): 790.71, token/sec:663056.41, hellaswag_acc: 0.2768
Step:  5938, loss: 3.098256, norm: 0.4990, time(ms): 797.96, token/sec:657039.13, hellaswag_acc: 0.2768
Step:  5939, loss: 3.130541, norm: 0.3942, time(ms): 796.76, token/sec:658023.56, hellaswag_acc: 0.2768
Step:  5940, loss: 3.084654, norm: 0.3250, time(ms): 800.88, token/sec:654639.93, hellaswag_acc: 0.2768
Step:  5941, loss: 3.129577, norm: 0.3202, time(ms): 800.36, token/sec:655067.01, hellaswag_acc: 0.2768
Step:  5942, loss: 3.140378, norm: 0.2732, time(ms): 793.73, token/sec:660532.97, hellaswag_acc: 0.2768
Step:  5943, loss: 3.363626, norm: 0.3552, time(ms): 793.11, token/sec:661051.82, hellaswag_acc: 0.2768
Step:  5944, loss: 3.327845, norm: 0.3267, time(ms): 788.08, token/sec:665269.96, hellaswag_acc: 0.2768
Step:  5945, loss: 3.340684, norm: 0.3159, time(ms): 789.04, token/sec:664464.48, hellaswag_acc: 0.2768
Step:  5946, loss: 3.330792, norm: 0.2971, time(ms): 792.43, token/sec:661624.43, hellaswag_acc: 0.2768
Step:  5947, loss: 3.305849, norm: 0.3075, time(ms): 801.75, token/sec:653928.60, hellaswag_acc: 0.2768
Step:  5948, loss: 3.312912, norm: 0.2870, time(ms): 804.19, token/sec:651944.34, hellaswag_acc: 0.2768
Step:  5949, loss: 3.373851, norm: 0.3227, time(ms): 797.35, token/sec:657538.15, hellaswag_acc: 0.2768
Step:  5950, loss: 3.338629, norm: 0.2996, time(ms): 796.92, token/sec:657889.29, hellaswag_acc: 0.2768
Step:  5951, loss: 3.338592, norm: 0.2749, time(ms): 802.02, token/sec:653711.85, hellaswag_acc: 0.2768
Step:  5952, loss: 3.285208, norm: 0.2760, time(ms): 801.04, token/sec:654508.80, hellaswag_acc: 0.2768
Step:  5953, loss: 3.321154, norm: 0.2568, time(ms): 799.61, token/sec:655675.62, hellaswag_acc: 0.2768
Step:  5954, loss: 3.348411, norm: 0.2574, time(ms): 798.78, token/sec:656360.00, hellaswag_acc: 0.2768
Step:  5955, loss: 3.303444, norm: 0.2413, time(ms): 798.96, token/sec:656211.14, hellaswag_acc: 0.2768
Step:  5956, loss: 3.327631, norm: 0.2694, time(ms): 802.72, token/sec:653136.75, hellaswag_acc: 0.2768
Step:  5957, loss: 3.333105, norm: 0.2677, time(ms): 799.40, token/sec:655853.57, hellaswag_acc: 0.2768
Step:  5958, loss: 3.360687, norm: 0.2768, time(ms): 791.62, token/sec:662298.95, hellaswag_acc: 0.2768
Step:  5959, loss: 3.331125, norm: 0.2910, time(ms): 808.46, token/sec:648504.77, hellaswag_acc: 0.2768
Step:  5960, loss: 3.369462, norm: 0.2793, time(ms): 800.27, token/sec:655138.82, hellaswag_acc: 0.2768
Step:  5961, loss: 3.375419, norm: 0.3029, time(ms): 790.46, token/sec:663271.00, hellaswag_acc: 0.2768
Step:  5962, loss: 3.296836, norm: 0.3010, time(ms): 798.57, token/sec:656533.43, hellaswag_acc: 0.2768
Step:  5963, loss: 3.312520, norm: 0.3000, time(ms): 790.86, token/sec:662933.67, hellaswag_acc: 0.2768
Step:  5964, loss: 3.336073, norm: 0.2667, time(ms): 785.96, token/sec:667063.42, hellaswag_acc: 0.2768
Step:  5965, loss: 3.323944, norm: 0.2783, time(ms): 787.20, token/sec:666013.86, hellaswag_acc: 0.2768
Step:  5966, loss: 3.257161, norm: 0.2751, time(ms): 802.70, token/sec:653158.09, hellaswag_acc: 0.2768
Step:  5967, loss: 3.270282, norm: 0.2442, time(ms): 803.70, token/sec:652343.13, hellaswag_acc: 0.2768
Step:  5968, loss: 3.239874, norm: 0.3263, time(ms): 791.52, token/sec:662377.35, hellaswag_acc: 0.2768
Step:  5969, loss: 3.297686, norm: 0.4431, time(ms): 798.09, token/sec:656929.02, hellaswag_acc: 0.2768
Step:  5970, loss: 3.275799, norm: 0.2822, time(ms): 791.74, token/sec:662193.65, hellaswag_acc: 0.2768
Step:  5971, loss: 3.260208, norm: 0.2552, time(ms): 790.65, token/sec:663110.99, hellaswag_acc: 0.2768
Step:  5972, loss: 3.243988, norm: 0.2727, time(ms): 795.96, token/sec:658684.24, hellaswag_acc: 0.2768
Step:  5973, loss: 3.246367, norm: 0.2595, time(ms): 789.03, token/sec:664475.12, hellaswag_acc: 0.2768
Step:  5974, loss: 3.341958, norm: 0.2416, time(ms): 788.06, token/sec:665290.49, hellaswag_acc: 0.2768
Step:  5975, loss: 3.273680, norm: 0.2547, time(ms): 791.92, token/sec:662047.91, hellaswag_acc: 0.2768
Step:  5976, loss: 3.258177, norm: 0.2597, time(ms): 799.29, token/sec:655942.59, hellaswag_acc: 0.2768
Step:  5977, loss: 3.221085, norm: 0.2559, time(ms): 801.56, token/sec:654086.74, hellaswag_acc: 0.2768
Step:  5978, loss: 3.121943, norm: 0.2836, time(ms): 797.81, token/sec:657158.12, hellaswag_acc: 0.2768
Step:  5979, loss: 3.042364, norm: 0.2668, time(ms): 794.40, token/sec:659981.86, hellaswag_acc: 0.2768
Step:  5980, loss: 3.067505, norm: 0.3062, time(ms): 801.25, token/sec:654339.17, hellaswag_acc: 0.2768
Step:  5981, loss: 3.099838, norm: 0.3607, time(ms): 800.96, token/sec:654574.65, hellaswag_acc: 0.2768
Step:  5982, loss: 3.001538, norm: 0.3255, time(ms): 804.26, token/sec:651885.39, hellaswag_acc: 0.2768
Step:  5983, loss: 3.112070, norm: 0.2954, time(ms): 792.55, token/sec:661520.73, hellaswag_acc: 0.2768
Step:  5984, loss: 3.097098, norm: 0.3370, time(ms): 803.27, token/sec:652689.33, hellaswag_acc: 0.2768
Step:  5985, loss: 3.106367, norm: 0.3077, time(ms): 804.69, token/sec:651540.82, hellaswag_acc: 0.2768
Step:  5986, loss: 3.072265, norm: 0.2807, time(ms): 798.42, token/sec:656657.52, hellaswag_acc: 0.2768
Step:  5987, loss: 3.103991, norm: 0.2983, time(ms): 790.73, token/sec:663045.41, hellaswag_acc: 0.2768
Step:  5988, loss: 3.134003, norm: 0.2480, time(ms): 791.92, token/sec:662047.51, hellaswag_acc: 0.2768
Step:  5989, loss: 3.138364, norm: 0.2799, time(ms): 789.32, token/sec:664228.85, hellaswag_acc: 0.2768
Step:  5990, loss: 3.360338, norm: 0.2920, time(ms): 790.60, token/sec:663151.98, hellaswag_acc: 0.2768
Step:  5991, loss: 3.356934, norm: 0.2620, time(ms): 794.92, token/sec:659550.73, hellaswag_acc: 0.2768
Step:  5992, loss: 3.383177, norm: 0.2791, time(ms): 796.72, token/sec:658059.39, hellaswag_acc: 0.2768
Step:  5993, loss: 3.359072, norm: 0.2531, time(ms): 804.66, token/sec:651561.67, hellaswag_acc: 0.2768
Step:  5994, loss: 3.334505, norm: 0.2708, time(ms): 801.55, token/sec:654091.99, hellaswag_acc: 0.2768
Step:  5995, loss: 3.325171, norm: 0.3079, time(ms): 792.22, token/sec:661793.28, hellaswag_acc: 0.2768
Step:  5996, loss: 3.256562, norm: 0.2751, time(ms): 801.48, token/sec:654153.86, hellaswag_acc: 0.2768
Step:  5997, loss: 3.291508, norm: 0.2810, time(ms): 800.78, token/sec:654724.72, hellaswag_acc: 0.2768
Step:  5998, loss: 3.343019, norm: 0.2716, time(ms): 795.89, token/sec:658748.37, hellaswag_acc: 0.2768
Step:  5999, loss: 3.333448, norm: 0.2466, time(ms): 791.73, token/sec:662204.41, hellaswag_acc: 0.2768
rank 0 sample 0: Hello, I'm a language model, and I don't have any background of words for a language, even languages such as German, German and Dutch. My
rank 0 sample 1: Hello, I'm a language model, so i'm a language model, for example I's writing "the sentence "the dog chased the sheep," and "
rank 0 sample 2: Hello, I'm a language model, so I really need to take a bit of some coding and try some new things.
I'm a language model trying
rank 0 sample 3: Hello, I'm a language model, I believe that I can say it to a general audience. I also see it frequently and ask people a lot. For
rank 1 sample 0: Hello, I'm a language model, here is my answer. I'm glad I asked for another comment.
(I can't think of a better way
rank 1 sample 1: Hello, I'm a language model, a linguist, a linguist, a linguist - I see you. I guess, by now, I'm
rank 1 sample 2: Hello, I'm a language model, I wanted to do a little bit of a little bit of thinking, and I'm a very simple and simple thing to
rank 1 sample 3: Hello, I'm a language model, and I'm very excited."
A short video
was broadcast and recorded yesterday. Now when you're listening to the
Step:  6000, loss: 3.250975, norm: 0.2640, time(ms): 364022.94, token/sec:1440.26, val_loss: 3.3004, hellaswag_acc: 0.2836
Step:  6001, loss: 3.358349, norm: 0.2751, time(ms): 795.20, token/sec:659312.05, hellaswag_acc: 0.2836
Step:  6002, loss: 3.306414, norm: 0.2900, time(ms): 794.72, token/sec:659715.95, hellaswag_acc: 0.2836
Step:  6003, loss: 3.333420, norm: 0.2811, time(ms): 805.38, token/sec:650981.29, hellaswag_acc: 0.2836
Step:  6004, loss: 3.326933, norm: 0.2659, time(ms): 798.26, token/sec:656792.07, hellaswag_acc: 0.2836
Step:  6005, loss: 3.284829, norm: 0.2856, time(ms): 794.82, token/sec:659629.47, hellaswag_acc: 0.2836
Step:  6006, loss: 3.298826, norm: 0.2792, time(ms): 802.80, token/sec:653073.51, hellaswag_acc: 0.2836
Step:  6007, loss: 3.384726, norm: 0.2628, time(ms): 802.38, token/sec:653412.52, hellaswag_acc: 0.2836
Step:  6008, loss: 3.331703, norm: 0.3201, time(ms): 799.36, token/sec:655888.59, hellaswag_acc: 0.2836
Step:  6009, loss: 3.351291, norm: 0.2960, time(ms): 801.71, token/sec:653965.75, hellaswag_acc: 0.2836
Step:  6010, loss: 3.274112, norm: 0.2627, time(ms): 799.65, token/sec:655643.17, hellaswag_acc: 0.2836
Step:  6011, loss: 3.345762, norm: 0.2827, time(ms): 792.43, token/sec:661619.45, hellaswag_acc: 0.2836
Step:  6012, loss: 3.315329, norm: 0.2995, time(ms): 794.79, token/sec:659653.21, hellaswag_acc: 0.2836
Step:  6013, loss: 3.211025, norm: 0.2777, time(ms): 793.46, token/sec:660764.00, hellaswag_acc: 0.2836
Step:  6014, loss: 3.236212, norm: 0.2622, time(ms): 792.54, token/sec:661531.68, hellaswag_acc: 0.2836
Step:  6015, loss: 3.281796, norm: 0.2955, time(ms): 792.98, token/sec:661160.14, hellaswag_acc: 0.2836
Step:  6016, loss: 3.306054, norm: 0.2680, time(ms): 788.53, token/sec:664896.63, hellaswag_acc: 0.2836
Step:  6017, loss: 3.264384, norm: 0.2787, time(ms): 794.05, token/sec:660269.20, hellaswag_acc: 0.2836
Step:  6018, loss: 3.268558, norm: 0.2463, time(ms): 792.58, token/sec:661491.28, hellaswag_acc: 0.2836
Step:  6019, loss: 3.270285, norm: 0.2548, time(ms): 788.47, token/sec:664943.47, hellaswag_acc: 0.2836
Step:  6020, loss: 3.333522, norm: 0.2805, time(ms): 793.17, token/sec:661001.55, hellaswag_acc: 0.2836
Step:  6021, loss: 3.238978, norm: 0.3066, time(ms): 796.25, token/sec:658443.82, hellaswag_acc: 0.2836
Step:  6022, loss: 3.250702, norm: 0.2626, time(ms): 791.46, token/sec:662435.22, hellaswag_acc: 0.2836
Step:  6023, loss: 3.272447, norm: 0.2640, time(ms): 792.03, token/sec:661958.63, hellaswag_acc: 0.2836
Step:  6024, loss: 3.139171, norm: 0.2584, time(ms): 793.40, token/sec:660815.63, hellaswag_acc: 0.2836
Step:  6025, loss: 3.009298, norm: 0.3056, time(ms): 802.57, token/sec:653261.51, hellaswag_acc: 0.2836
Step:  6026, loss: 3.072815, norm: 0.3638, time(ms): 797.65, token/sec:657292.09, hellaswag_acc: 0.2836
Step:  6027, loss: 3.045102, norm: 0.3503, time(ms): 796.16, token/sec:658522.89, hellaswag_acc: 0.2836
Step:  6028, loss: 3.112082, norm: 0.3449, time(ms): 804.34, token/sec:651823.95, hellaswag_acc: 0.2836
Step:  6029, loss: 3.039026, norm: 0.3580, time(ms): 801.90, token/sec:653805.73, hellaswag_acc: 0.2836
Step:  6030, loss: 3.097591, norm: 0.3526, time(ms): 791.30, token/sec:662564.75, hellaswag_acc: 0.2836
Step:  6031, loss: 3.037057, norm: 0.3399, time(ms): 801.26, token/sec:654331.97, hellaswag_acc: 0.2836
Step:  6032, loss: 3.098023, norm: 0.2821, time(ms): 802.46, token/sec:653350.01, hellaswag_acc: 0.2836
Step:  6033, loss: 3.118516, norm: 0.3054, time(ms): 801.02, token/sec:654529.26, hellaswag_acc: 0.2836
Step:  6034, loss: 3.108901, norm: 0.3158, time(ms): 799.67, token/sec:655631.44, hellaswag_acc: 0.2836
Step:  6035, loss: 3.146065, norm: 0.2785, time(ms): 799.50, token/sec:655766.93, hellaswag_acc: 0.2836
Step:  6036, loss: 3.344856, norm: 0.2934, time(ms): 803.03, token/sec:652890.47, hellaswag_acc: 0.2836
Step:  6037, loss: 3.315554, norm: 0.2461, time(ms): 798.84, token/sec:656312.59, hellaswag_acc: 0.2836
Step:  6038, loss: 3.346676, norm: 0.2939, time(ms): 797.90, token/sec:657085.66, hellaswag_acc: 0.2836
Step:  6039, loss: 3.317542, norm: 0.2726, time(ms): 799.21, token/sec:656010.68, hellaswag_acc: 0.2836
Step:  6040, loss: 3.350682, norm: 0.2685, time(ms): 803.24, token/sec:652718.00, hellaswag_acc: 0.2836
Step:  6041, loss: 3.330445, norm: 0.2567, time(ms): 796.93, token/sec:657887.72, hellaswag_acc: 0.2836
Step:  6042, loss: 3.310482, norm: 0.2575, time(ms): 796.87, token/sec:657935.75, hellaswag_acc: 0.2836
Step:  6043, loss: 3.343317, norm: 0.2718, time(ms): 804.00, token/sec:652098.23, hellaswag_acc: 0.2836
Step:  6044, loss: 3.278923, norm: 0.2791, time(ms): 802.79, token/sec:653081.66, hellaswag_acc: 0.2836
Step:  6045, loss: 3.312452, norm: 0.2961, time(ms): 796.27, token/sec:658429.82, hellaswag_acc: 0.2836
Step:  6046, loss: 3.392968, norm: 0.2942, time(ms): 797.91, token/sec:657077.42, hellaswag_acc: 0.2836
Step:  6047, loss: 3.330815, norm: 0.2984, time(ms): 802.14, token/sec:653611.59, hellaswag_acc: 0.2836
Step:  6048, loss: 3.379409, norm: 0.2916, time(ms): 799.98, token/sec:655373.71, hellaswag_acc: 0.2836
Step:  6049, loss: 3.326056, norm: 0.2751, time(ms): 799.62, token/sec:655675.23, hellaswag_acc: 0.2836
Step:  6050, loss: 3.290359, norm: 0.2660, time(ms): 798.97, token/sec:656208.40, hellaswag_acc: 0.2836
Step:  6051, loss: 3.364351, norm: 0.2894, time(ms): 800.83, token/sec:654684.17, hellaswag_acc: 0.2836
Step:  6052, loss: 3.344985, norm: 0.2814, time(ms): 802.28, token/sec:653500.10, hellaswag_acc: 0.2836
Step:  6053, loss: 3.323510, norm: 0.3227, time(ms): 792.50, token/sec:661563.72, hellaswag_acc: 0.2836
Step:  6054, loss: 3.327363, norm: 0.3394, time(ms): 803.09, token/sec:652836.59, hellaswag_acc: 0.2836
Step:  6055, loss: 3.345346, norm: 0.2814, time(ms): 799.50, token/sec:655767.71, hellaswag_acc: 0.2836
Step:  6056, loss: 3.419062, norm: 0.2974, time(ms): 801.40, token/sec:654218.87, hellaswag_acc: 0.2836
Step:  6057, loss: 3.326896, norm: 0.3095, time(ms): 795.82, token/sec:658801.45, hellaswag_acc: 0.2836
Step:  6058, loss: 3.324015, norm: 0.2850, time(ms): 802.40, token/sec:653395.83, hellaswag_acc: 0.2836
Step:  6059, loss: 3.294673, norm: 0.2778, time(ms): 803.30, token/sec:652670.15, hellaswag_acc: 0.2836
Step:  6060, loss: 3.310054, norm: 0.2460, time(ms): 795.92, token/sec:658723.50, hellaswag_acc: 0.2836
Step:  6061, loss: 3.302635, norm: 0.2903, time(ms): 802.10, token/sec:653647.14, hellaswag_acc: 0.2836
Step:  6062, loss: 3.296044, norm: 0.2757, time(ms): 802.19, token/sec:653572.74, hellaswag_acc: 0.2836
Step:  6063, loss: 3.255458, norm: 0.2703, time(ms): 795.91, token/sec:658729.42, hellaswag_acc: 0.2836
Step:  6064, loss: 3.277040, norm: 0.2625, time(ms): 800.94, token/sec:654589.66, hellaswag_acc: 0.2836
Step:  6065, loss: 3.287117, norm: 0.2563, time(ms): 799.87, token/sec:655468.85, hellaswag_acc: 0.2836
Step:  6066, loss: 3.250766, norm: 0.2566, time(ms): 804.28, token/sec:651876.51, hellaswag_acc: 0.2836
Step:  6067, loss: 3.251171, norm: 0.2526, time(ms): 796.32, token/sec:658384.68, hellaswag_acc: 0.2836
Step:  6068, loss: 3.294041, norm: 0.2508, time(ms): 794.65, token/sec:659771.57, hellaswag_acc: 0.2836
Step:  6069, loss: 3.261447, norm: 0.2618, time(ms): 802.38, token/sec:653416.60, hellaswag_acc: 0.2836
Step:  6070, loss: 3.223364, norm: 0.2596, time(ms): 805.17, token/sec:651155.93, hellaswag_acc: 0.2836
Step:  6071, loss: 3.139690, norm: 0.2749, time(ms): 793.11, token/sec:661050.83, hellaswag_acc: 0.2836
Step:  6072, loss: 3.197819, norm: 0.3306, time(ms): 802.22, token/sec:653543.21, hellaswag_acc: 0.2836
Step:  6073, loss: 3.066160, norm: 0.3140, time(ms): 801.64, token/sec:654020.40, hellaswag_acc: 0.2836
Step:  6074, loss: 3.063233, norm: 0.2911, time(ms): 800.09, token/sec:655283.68, hellaswag_acc: 0.2836
Step:  6075, loss: 3.047070, norm: 0.3046, time(ms): 795.72, token/sec:658885.94, hellaswag_acc: 0.2836
Step:  6076, loss: 3.073673, norm: 0.3199, time(ms): 799.35, token/sec:655897.00, hellaswag_acc: 0.2836
Step:  6077, loss: 3.046939, norm: 0.3007, time(ms): 806.45, token/sec:650118.32, hellaswag_acc: 0.2836
Step:  6078, loss: 3.066922, norm: 0.3029, time(ms): 798.35, token/sec:656712.83, hellaswag_acc: 0.2836
Step:  6079, loss: 3.063236, norm: 0.2611, time(ms): 790.92, token/sec:662883.91, hellaswag_acc: 0.2836
Step:  6080, loss: 3.074560, norm: 0.2737, time(ms): 792.64, token/sec:661447.51, hellaswag_acc: 0.2836
Step:  6081, loss: 3.101797, norm: 0.2767, time(ms): 793.28, token/sec:660913.14, hellaswag_acc: 0.2836
Step:  6082, loss: 3.127694, norm: 0.2930, time(ms): 799.97, token/sec:655387.97, hellaswag_acc: 0.2836
Step:  6083, loss: 3.314620, norm: 0.2545, time(ms): 803.39, token/sec:652596.74, hellaswag_acc: 0.2836
Step:  6084, loss: 3.382876, norm: 0.2971, time(ms): 795.34, token/sec:659196.63, hellaswag_acc: 0.2836
Step:  6085, loss: 3.329350, norm: 0.3069, time(ms): 800.39, token/sec:655043.40, hellaswag_acc: 0.2836
Step:  6086, loss: 3.272842, norm: 0.2995, time(ms): 799.94, token/sec:655411.80, hellaswag_acc: 0.2836
Step:  6087, loss: 3.310272, norm: 0.2756, time(ms): 798.64, token/sec:656472.28, hellaswag_acc: 0.2836
Step:  6088, loss: 3.314463, norm: 0.3157, time(ms): 801.28, token/sec:654311.13, hellaswag_acc: 0.2836
Step:  6089, loss: 3.318988, norm: 0.2681, time(ms): 793.66, token/sec:660592.90, hellaswag_acc: 0.2836
Step:  6090, loss: 3.321477, norm: 0.2903, time(ms): 790.06, token/sec:663605.46, hellaswag_acc: 0.2836
Step:  6091, loss: 3.344435, norm: 0.2731, time(ms): 788.30, token/sec:665084.05, hellaswag_acc: 0.2836
Step:  6092, loss: 3.313888, norm: 0.3014, time(ms): 787.10, token/sec:666097.58, hellaswag_acc: 0.2836
Step:  6093, loss: 3.295433, norm: 0.2581, time(ms): 802.51, token/sec:653308.28, hellaswag_acc: 0.2836
Step:  6094, loss: 3.299272, norm: 0.2518, time(ms): 800.43, token/sec:655006.52, hellaswag_acc: 0.2836
Step:  6095, loss: 3.366938, norm: 0.2747, time(ms): 1248.65, token/sec:419884.01, hellaswag_acc: 0.2836
Step:  6096, loss: 3.265540, norm: 0.2682, time(ms): 766.10, token/sec:684357.25, hellaswag_acc: 0.2836
Step:  6097, loss: 3.292146, norm: 0.2525, time(ms): 783.42, token/sec:669229.71, hellaswag_acc: 0.2836
Step:  6098, loss: 3.245578, norm: 0.3070, time(ms): 799.78, token/sec:655541.14, hellaswag_acc: 0.2836
Step:  6099, loss: 3.267919, norm: 0.2863, time(ms): 787.01, token/sec:666173.05, hellaswag_acc: 0.2836
Step:  6100, loss: 3.271930, norm: 0.2671, time(ms): 783.09, token/sec:669515.99, hellaswag_acc: 0.2836
Step:  6101, loss: 3.366385, norm: 0.2891, time(ms): 785.53, token/sec:667435.14, hellaswag_acc: 0.2836
Step:  6102, loss: 3.223260, norm: 0.2648, time(ms): 802.40, token/sec:653396.02, hellaswag_acc: 0.2836
Step:  6103, loss: 3.300198, norm: 0.2733, time(ms): 796.90, token/sec:657911.14, hellaswag_acc: 0.2836
Step:  6104, loss: 3.268590, norm: 0.3114, time(ms): 792.65, token/sec:661434.78, hellaswag_acc: 0.2836
Step:  6105, loss: 3.376061, norm: 0.2832, time(ms): 788.57, token/sec:664860.44, hellaswag_acc: 0.2836
Step:  6106, loss: 3.278158, norm: 0.2665, time(ms): 803.10, token/sec:652834.26, hellaswag_acc: 0.2836
Step:  6107, loss: 3.285987, norm: 0.2855, time(ms): 792.03, token/sec:661953.05, hellaswag_acc: 0.2836
Step:  6108, loss: 3.300910, norm: 0.2736, time(ms): 789.32, token/sec:664224.23, hellaswag_acc: 0.2836
Step:  6109, loss: 3.245948, norm: 0.2746, time(ms): 788.52, token/sec:664901.25, hellaswag_acc: 0.2836
Step:  6110, loss: 3.360613, norm: 0.2859, time(ms): 787.48, token/sec:665779.55, hellaswag_acc: 0.2836
Step:  6111, loss: 3.324939, norm: 0.3166, time(ms): 797.15, token/sec:657704.14, hellaswag_acc: 0.2836
Step:  6112, loss: 3.425548, norm: 0.2984, time(ms): 806.15, token/sec:650358.46, hellaswag_acc: 0.2836
Step:  6113, loss: 3.305693, norm: 0.3020, time(ms): 801.24, token/sec:654342.09, hellaswag_acc: 0.2836
Step:  6114, loss: 3.301443, norm: 0.3132, time(ms): 794.67, token/sec:659757.12, hellaswag_acc: 0.2836
Step:  6115, loss: 3.326959, norm: 0.2746, time(ms): 800.68, token/sec:654806.21, hellaswag_acc: 0.2836
Step:  6116, loss: 3.324505, norm: 0.2752, time(ms): 801.50, token/sec:654134.60, hellaswag_acc: 0.2836
Step:  6117, loss: 3.313509, norm: 0.2664, time(ms): 800.92, token/sec:654606.22, hellaswag_acc: 0.2836
Step:  6118, loss: 3.306053, norm: 0.2814, time(ms): 793.60, token/sec:660648.47, hellaswag_acc: 0.2836
Step:  6119, loss: 3.330405, norm: 0.2635, time(ms): 800.02, token/sec:655345.20, hellaswag_acc: 0.2836
Step:  6120, loss: 3.321774, norm: 0.2737, time(ms): 805.75, token/sec:650684.07, hellaswag_acc: 0.2836
Step:  6121, loss: 3.334213, norm: 0.2893, time(ms): 800.46, token/sec:654986.42, hellaswag_acc: 0.2836
Step:  6122, loss: 3.270099, norm: 0.2603, time(ms): 788.68, token/sec:664770.00, hellaswag_acc: 0.2836
Step:  6123, loss: 3.254832, norm: 0.2695, time(ms): 791.03, token/sec:662790.41, hellaswag_acc: 0.2836
Step:  6124, loss: 3.304478, norm: 0.2740, time(ms): 790.19, token/sec:663498.94, hellaswag_acc: 0.2836
Step:  6125, loss: 3.253680, norm: 0.2933, time(ms): 791.43, token/sec:662459.56, hellaswag_acc: 0.2836
Step:  6126, loss: 3.326777, norm: 0.2718, time(ms): 789.29, token/sec:664255.73, hellaswag_acc: 0.2836
Step:  6127, loss: 3.317241, norm: 0.2751, time(ms): 799.15, token/sec:656057.26, hellaswag_acc: 0.2836
Step:  6128, loss: 3.265262, norm: 0.2794, time(ms): 799.51, token/sec:655760.48, hellaswag_acc: 0.2836
Step:  6129, loss: 3.216366, norm: 0.2573, time(ms): 792.35, token/sec:661686.35, hellaswag_acc: 0.2836
Step:  6130, loss: 3.344636, norm: 0.2657, time(ms): 789.38, token/sec:664175.28, hellaswag_acc: 0.2836
Step:  6131, loss: 3.299994, norm: 0.2708, time(ms): 793.93, token/sec:660369.53, hellaswag_acc: 0.2836
Step:  6132, loss: 3.273881, norm: 0.2695, time(ms): 790.20, token/sec:663487.13, hellaswag_acc: 0.2836
Step:  6133, loss: 3.274904, norm: 0.2548, time(ms): 793.06, token/sec:661095.54, hellaswag_acc: 0.2836
Step:  6134, loss: 3.271813, norm: 0.2423, time(ms): 794.29, token/sec:660070.02, hellaswag_acc: 0.2836
Step:  6135, loss: 3.309689, norm: 0.2596, time(ms): 786.86, token/sec:666304.05, hellaswag_acc: 0.2836
Step:  6136, loss: 3.282932, norm: 0.2735, time(ms): 802.48, token/sec:653330.99, hellaswag_acc: 0.2836
Step:  6137, loss: 3.354522, norm: 0.2733, time(ms): 804.16, token/sec:651971.40, hellaswag_acc: 0.2836
Step:  6138, loss: 3.318844, norm: 0.2786, time(ms): 800.46, token/sec:654986.42, hellaswag_acc: 0.2836
Step:  6139, loss: 3.296277, norm: 0.2831, time(ms): 789.65, token/sec:663951.49, hellaswag_acc: 0.2836
Step:  6140, loss: 3.319238, norm: 0.2684, time(ms): 798.38, token/sec:656690.86, hellaswag_acc: 0.2836
Step:  6141, loss: 3.292398, norm: 0.2972, time(ms): 795.34, token/sec:659202.36, hellaswag_acc: 0.2836
Step:  6142, loss: 3.280645, norm: 0.2630, time(ms): 789.24, token/sec:664290.85, hellaswag_acc: 0.2836
Step:  6143, loss: 3.315643, norm: 0.2800, time(ms): 791.85, token/sec:662104.72, hellaswag_acc: 0.2836
Step:  6144, loss: 3.257604, norm: 0.2749, time(ms): 787.37, token/sec:665874.10, hellaswag_acc: 0.2836
Step:  6145, loss: 3.369479, norm: 0.2744, time(ms): 804.94, token/sec:651340.31, hellaswag_acc: 0.2836
Step:  6146, loss: 3.341179, norm: 0.2624, time(ms): 802.88, token/sec:653005.64, hellaswag_acc: 0.2836
Step:  6147, loss: 3.474727, norm: 0.2910, time(ms): 790.28, token/sec:663421.47, hellaswag_acc: 0.2836
Step:  6148, loss: 3.337787, norm: 0.3268, time(ms): 792.37, token/sec:661669.22, hellaswag_acc: 0.2836
Step:  6149, loss: 3.414479, norm: 0.3067, time(ms): 794.87, token/sec:659588.51, hellaswag_acc: 0.2836
Step:  6150, loss: 3.345047, norm: 0.3171, time(ms): 797.93, token/sec:657063.48, hellaswag_acc: 0.2836
Step:  6151, loss: 3.385679, norm: 0.3614, time(ms): 794.08, token/sec:660242.04, hellaswag_acc: 0.2836
Step:  6152, loss: 3.324640, norm: 0.2765, time(ms): 790.01, token/sec:663649.72, hellaswag_acc: 0.2836
Step:  6153, loss: 3.292221, norm: 0.2712, time(ms): 787.74, token/sec:665560.51, hellaswag_acc: 0.2836
Step:  6154, loss: 3.302158, norm: 0.2926, time(ms): 788.88, token/sec:664597.22, hellaswag_acc: 0.2836
Step:  6155, loss: 3.275404, norm: 0.2746, time(ms): 800.38, token/sec:655049.64, hellaswag_acc: 0.2836
Step:  6156, loss: 3.340029, norm: 0.2811, time(ms): 799.96, token/sec:655392.27, hellaswag_acc: 0.2836
Step:  6157, loss: 3.329323, norm: 0.2630, time(ms): 789.66, token/sec:663944.47, hellaswag_acc: 0.2836
Step:  6158, loss: 3.321054, norm: 0.2835, time(ms): 789.49, token/sec:664086.43, hellaswag_acc: 0.2836
Step:  6159, loss: 3.269516, norm: 0.2815, time(ms): 791.44, token/sec:662447.19, hellaswag_acc: 0.2836
Step:  6160, loss: 3.225884, norm: 0.2665, time(ms): 789.72, token/sec:663889.75, hellaswag_acc: 0.2836
Step:  6161, loss: 3.269787, norm: 0.2659, time(ms): 793.52, token/sec:660714.57, hellaswag_acc: 0.2836
Step:  6162, loss: 3.301200, norm: 0.2523, time(ms): 797.56, token/sec:657363.80, hellaswag_acc: 0.2836
Step:  6163, loss: 3.243710, norm: 0.2750, time(ms): 792.22, token/sec:661799.85, hellaswag_acc: 0.2836
Step:  6164, loss: 3.277696, norm: 0.2479, time(ms): 793.41, token/sec:660803.12, hellaswag_acc: 0.2836
Step:  6165, loss: 3.225355, norm: 0.2622, time(ms): 797.13, token/sec:657722.04, hellaswag_acc: 0.2836
Step:  6166, loss: 3.339434, norm: 0.2908, time(ms): 802.45, token/sec:653360.11, hellaswag_acc: 0.2836
Step:  6167, loss: 3.314342, norm: 0.2652, time(ms): 802.13, token/sec:653616.45, hellaswag_acc: 0.2836
Step:  6168, loss: 3.313857, norm: 0.2845, time(ms): 791.63, token/sec:662288.58, hellaswag_acc: 0.2836
Step:  6169, loss: 3.264013, norm: 0.3110, time(ms): 792.36, token/sec:661678.58, hellaswag_acc: 0.2836
Step:  6170, loss: 3.335675, norm: 0.2944, time(ms): 785.66, token/sec:667323.14, hellaswag_acc: 0.2836
Step:  6171, loss: 3.324305, norm: 0.3036, time(ms): 790.79, token/sec:662994.23, hellaswag_acc: 0.2836
Step:  6172, loss: 3.291263, norm: 0.2952, time(ms): 798.86, token/sec:656295.36, hellaswag_acc: 0.2836
Step:  6173, loss: 3.368469, norm: 0.2945, time(ms): 790.53, token/sec:663214.39, hellaswag_acc: 0.2836
Step:  6174, loss: 3.282385, norm: 0.2763, time(ms): 796.04, token/sec:658616.77, hellaswag_acc: 0.2836
Step:  6175, loss: 3.324739, norm: 0.2769, time(ms): 793.93, token/sec:660367.94, hellaswag_acc: 0.2836
Step:  6176, loss: 3.275651, norm: 0.2667, time(ms): 787.02, token/sec:666169.22, hellaswag_acc: 0.2836
Step:  6177, loss: 3.282580, norm: 0.2567, time(ms): 787.39, token/sec:665855.96, hellaswag_acc: 0.2836
Step:  6178, loss: 3.295942, norm: 0.2765, time(ms): 804.00, token/sec:652099.39, hellaswag_acc: 0.2836
Step:  6179, loss: 3.274065, norm: 0.2727, time(ms): 800.17, token/sec:655219.44, hellaswag_acc: 0.2836
Step:  6180, loss: 3.383342, norm: 0.3240, time(ms): 791.78, token/sec:662166.53, hellaswag_acc: 0.2836
Step:  6181, loss: 3.328485, norm: 0.3395, time(ms): 797.86, token/sec:657120.42, hellaswag_acc: 0.2836
Step:  6182, loss: 3.290057, norm: 0.3260, time(ms): 793.78, token/sec:660496.67, hellaswag_acc: 0.2836
Step:  6183, loss: 3.366168, norm: 0.3067, time(ms): 794.57, token/sec:659835.12, hellaswag_acc: 0.2836
Step:  6184, loss: 3.320277, norm: 0.2802, time(ms): 787.80, token/sec:665507.74, hellaswag_acc: 0.2836
Step:  6185, loss: 3.334940, norm: 0.2982, time(ms): 787.41, token/sec:665835.39, hellaswag_acc: 0.2836
Step:  6186, loss: 3.331574, norm: 0.2806, time(ms): 795.45, token/sec:659108.51, hellaswag_acc: 0.2836
Step:  6187, loss: 3.298747, norm: 0.2841, time(ms): 791.46, token/sec:662429.43, hellaswag_acc: 0.2836
Step:  6188, loss: 3.285318, norm: 0.2657, time(ms): 792.97, token/sec:661169.68, hellaswag_acc: 0.2836
Step:  6189, loss: 3.271300, norm: 0.2706, time(ms): 803.18, token/sec:652762.76, hellaswag_acc: 0.2836
Step:  6190, loss: 3.351491, norm: 0.2709, time(ms): 801.71, token/sec:653962.05, hellaswag_acc: 0.2836
Step:  6191, loss: 3.310650, norm: 0.2742, time(ms): 802.17, token/sec:653588.28, hellaswag_acc: 0.2836
Step:  6192, loss: 3.284545, norm: 0.2653, time(ms): 794.21, token/sec:660136.99, hellaswag_acc: 0.2836
Step:  6193, loss: 3.280702, norm: 0.2581, time(ms): 800.16, token/sec:655226.67, hellaswag_acc: 0.2836
Step:  6194, loss: 3.286888, norm: 0.2904, time(ms): 802.29, token/sec:653485.34, hellaswag_acc: 0.2836
Step:  6195, loss: 3.245647, norm: 0.2602, time(ms): 798.67, token/sec:656448.56, hellaswag_acc: 0.2836
Step:  6196, loss: 3.254087, norm: 0.3160, time(ms): 795.95, token/sec:658696.27, hellaswag_acc: 0.2836
Step:  6197, loss: 3.273443, norm: 0.2725, time(ms): 805.31, token/sec:651042.58, hellaswag_acc: 0.2836
Step:  6198, loss: 3.273656, norm: 0.3236, time(ms): 795.60, token/sec:658980.91, hellaswag_acc: 0.2836
Step:  6199, loss: 3.343903, norm: 0.3045, time(ms): 801.77, token/sec:653913.43, hellaswag_acc: 0.2836
Step:  6200, loss: 3.241431, norm: 0.2778, time(ms): 802.23, token/sec:653536.42, hellaswag_acc: 0.2836
Step:  6201, loss: 3.239900, norm: 0.2831, time(ms): 800.01, token/sec:655350.08, hellaswag_acc: 0.2836
Step:  6202, loss: 3.283532, norm: 0.2898, time(ms): 800.96, token/sec:654577.58, hellaswag_acc: 0.2836
Step:  6203, loss: 3.286047, norm: 0.3060, time(ms): 796.72, token/sec:658055.26, hellaswag_acc: 0.2836
Step:  6204, loss: 3.365634, norm: 0.2733, time(ms): 801.81, token/sec:653876.69, hellaswag_acc: 0.2836
Step:  6205, loss: 3.344283, norm: 0.3395, time(ms): 799.05, token/sec:656138.89, hellaswag_acc: 0.2836
Step:  6206, loss: 3.251346, norm: 0.2533, time(ms): 799.93, token/sec:655418.25, hellaswag_acc: 0.2836
Step:  6207, loss: 3.273651, norm: 0.3071, time(ms): 789.72, token/sec:663887.34, hellaswag_acc: 0.2836
Step:  6208, loss: 3.263336, norm: 0.2960, time(ms): 789.71, token/sec:663899.97, hellaswag_acc: 0.2836
Step:  6209, loss: 3.334190, norm: 0.2893, time(ms): 787.58, token/sec:665693.49, hellaswag_acc: 0.2836
Step:  6210, loss: 3.209240, norm: 0.2875, time(ms): 791.43, token/sec:662456.97, hellaswag_acc: 0.2836
Step:  6211, loss: 3.307499, norm: 0.2852, time(ms): 799.64, token/sec:655653.33, hellaswag_acc: 0.2836
Step:  6212, loss: 3.281867, norm: 0.2566, time(ms): 799.85, token/sec:655485.45, hellaswag_acc: 0.2836
Step:  6213, loss: 3.361494, norm: 0.2971, time(ms): 799.12, token/sec:656083.69, hellaswag_acc: 0.2836
Step:  6214, loss: 3.366172, norm: 0.2691, time(ms): 799.90, token/sec:655442.86, hellaswag_acc: 0.2836
Step:  6215, loss: 3.356152, norm: 0.2992, time(ms): 798.22, token/sec:656819.34, hellaswag_acc: 0.2836
Step:  6216, loss: 3.324755, norm: 0.3369, time(ms): 802.46, token/sec:653348.85, hellaswag_acc: 0.2836
Step:  6217, loss: 3.367891, norm: 0.3517, time(ms): 797.21, token/sec:657652.01, hellaswag_acc: 0.2836
Step:  6218, loss: 3.321774, norm: 0.2986, time(ms): 801.12, token/sec:654444.72, hellaswag_acc: 0.2836
Step:  6219, loss: 3.293431, norm: 0.3361, time(ms): 800.58, token/sec:654885.97, hellaswag_acc: 0.2836
Step:  6220, loss: 3.259210, norm: 0.3377, time(ms): 800.78, token/sec:654722.18, hellaswag_acc: 0.2836
Step:  6221, loss: 3.404794, norm: 0.3022, time(ms): 793.78, token/sec:660495.08, hellaswag_acc: 0.2836
Step:  6222, loss: 3.350002, norm: 0.3561, time(ms): 797.98, token/sec:657017.74, hellaswag_acc: 0.2836
Step:  6223, loss: 3.312828, norm: 0.2931, time(ms): 790.50, token/sec:663233.59, hellaswag_acc: 0.2836
Step:  6224, loss: 3.309073, norm: 0.2938, time(ms): 793.36, token/sec:660845.61, hellaswag_acc: 0.2836
Step:  6225, loss: 3.322443, norm: 0.2973, time(ms): 790.27, token/sec:663431.28, hellaswag_acc: 0.2836
Step:  6226, loss: 3.377228, norm: 0.2802, time(ms): 789.79, token/sec:663835.03, hellaswag_acc: 0.2836
Step:  6227, loss: 3.359001, norm: 0.2746, time(ms): 794.47, token/sec:659918.48, hellaswag_acc: 0.2836
Step:  6228, loss: 3.351290, norm: 0.2480, time(ms): 791.10, token/sec:662736.88, hellaswag_acc: 0.2836
Step:  6229, loss: 3.341126, norm: 0.2741, time(ms): 789.44, token/sec:664122.73, hellaswag_acc: 0.2836
Step:  6230, loss: 3.243453, norm: 0.2658, time(ms): 792.08, token/sec:661913.40, hellaswag_acc: 0.2836
Step:  6231, loss: 3.326197, norm: 0.2722, time(ms): 790.39, token/sec:663325.02, hellaswag_acc: 0.2836
Step:  6232, loss: 3.284201, norm: 0.2748, time(ms): 796.21, token/sec:658481.08, hellaswag_acc: 0.2836
Step:  6233, loss: 3.268593, norm: 0.2609, time(ms): 793.30, token/sec:660892.88, hellaswag_acc: 0.2836
Step:  6234, loss: 3.329750, norm: 0.2636, time(ms): 789.83, token/sec:663799.17, hellaswag_acc: 0.2836
Step:  6235, loss: 3.250407, norm: 0.2644, time(ms): 800.19, token/sec:655208.12, hellaswag_acc: 0.2836
Step:  6236, loss: 3.287199, norm: 0.2543, time(ms): 803.15, token/sec:652787.37, hellaswag_acc: 0.2836
Step:  6237, loss: 3.275218, norm: 0.2571, time(ms): 799.44, token/sec:655816.41, hellaswag_acc: 0.2836
Step:  6238, loss: 3.336579, norm: 0.2576, time(ms): 798.53, token/sec:656562.63, hellaswag_acc: 0.2836
Step:  6239, loss: 3.246653, norm: 0.2633, time(ms): 800.23, token/sec:655168.49, hellaswag_acc: 0.2836
Step:  6240, loss: 3.277049, norm: 0.2557, time(ms): 801.42, token/sec:654199.99, hellaswag_acc: 0.2836
Step:  6241, loss: 3.304008, norm: 0.2725, time(ms): 796.48, token/sec:658254.21, hellaswag_acc: 0.2836
Step:  6242, loss: 3.268556, norm: 0.2513, time(ms): 801.51, token/sec:654125.45, hellaswag_acc: 0.2836
Step:  6243, loss: 3.284643, norm: 0.2703, time(ms): 801.44, token/sec:654179.94, hellaswag_acc: 0.2836
Step:  6244, loss: 3.284283, norm: 0.2748, time(ms): 795.46, token/sec:659096.46, hellaswag_acc: 0.2836
Step:  6245, loss: 3.348217, norm: 0.2770, time(ms): 796.06, token/sec:658600.20, hellaswag_acc: 0.2836
Step:  6246, loss: 3.356040, norm: 0.3138, time(ms): 791.48, token/sec:662414.06, hellaswag_acc: 0.2836
Step:  6247, loss: 3.311326, norm: 0.3045, time(ms): 797.55, token/sec:657372.25, hellaswag_acc: 0.2836
Step:  6248, loss: 3.256304, norm: 0.3017, time(ms): 792.95, token/sec:661189.16, hellaswag_acc: 0.2836
Step:  6249, loss: 3.246419, norm: 0.2702, time(ms): 791.62, token/sec:662294.96, hellaswag_acc: 0.2836
rank 0 sample 0: Hello, I'm a language model, and I need to be able to tell about.
However, to some it's more exciting and more important than language
rank 0 sample 1: Hello, I'm a language model, so how do I make it a standard language, i use the English one for the English language? That's a lot
rank 0 sample 2: Hello, I'm a language model, I'm always pretty well into the lingo world, and there you've got to get a little bit more information.
rank 0 sample 3: Hello, I'm a language model, so all I can do is just type "math" into my Google Chrome account here. Thanks, if you have it
rank 1 sample 0: Hello, I'm a language model, just what you're talking about. Don't feel so frustrated just because you're not certain of a language or you're
rank 1 sample 1: Hello, I'm a language model, not an English teacher. I can be pretty sure that any of the ideas or grammar errors you see in the text are
rank 1 sample 2: Hello, I'm a language model, so are the numbers in parentheses.
- I'm an acronym. It's a little confusing for a lot of different
rank 1 sample 3: Hello, I'm a language model, and I'm working with kids in other elementary schools. Their main target is vocabulary. Children tend to start off with vocabulary
Step:  6250, loss: 3.370532, norm: 0.2784, time(ms): 3760.61, token/sec:139415.50, val_loss: 3.2924, hellaswag_acc: 0.2836
Step:  6251, loss: 3.285296, norm: 0.2643, time(ms): 781.75, token/sec:670660.68, hellaswag_acc: 0.2836
Step:  6252, loss: 3.304247, norm: 0.2731, time(ms): 788.96, token/sec:664531.94, hellaswag_acc: 0.2836
Step:  6253, loss: 3.405623, norm: 0.3048, time(ms): 798.49, token/sec:656597.72, hellaswag_acc: 0.2836
Step:  6254, loss: 3.372860, norm: 0.2904, time(ms): 807.26, token/sec:649464.34, hellaswag_acc: 0.2836
Step:  6255, loss: 3.314752, norm: 0.2854, time(ms): 791.12, token/sec:662717.10, hellaswag_acc: 0.2836
Step:  6256, loss: 3.267567, norm: 0.2835, time(ms): 797.79, token/sec:657175.80, hellaswag_acc: 0.2836
Step:  6257, loss: 3.297037, norm: 0.2790, time(ms): 791.82, token/sec:662134.43, hellaswag_acc: 0.2836
Step:  6258, loss: 3.442316, norm: 0.3058, time(ms): 793.48, token/sec:660748.71, hellaswag_acc: 0.2836
Step:  6259, loss: 3.272195, norm: 0.2639, time(ms): 794.37, token/sec:660001.47, hellaswag_acc: 0.2836
Step:  6260, loss: 3.327317, norm: 0.2900, time(ms): 789.86, token/sec:663772.72, hellaswag_acc: 0.2836
Step:  6261, loss: 3.390530, norm: 0.3005, time(ms): 784.75, token/sec:668093.76, hellaswag_acc: 0.2836
Step:  6262, loss: 3.345654, norm: 0.2742, time(ms): 789.80, token/sec:663826.62, hellaswag_acc: 0.2836
Step:  6263, loss: 3.303072, norm: 0.2711, time(ms): 801.02, token/sec:654526.34, hellaswag_acc: 0.2836
Step:  6264, loss: 3.274890, norm: 0.2492, time(ms): 802.22, token/sec:653547.29, hellaswag_acc: 0.2836
Step:  6265, loss: 3.283592, norm: 0.2452, time(ms): 800.11, token/sec:655270.60, hellaswag_acc: 0.2836
Step:  6266, loss: 3.272023, norm: 0.2302, time(ms): 793.99, token/sec:660318.76, hellaswag_acc: 0.2836
Step:  6267, loss: 3.298180, norm: 0.2458, time(ms): 803.35, token/sec:652626.76, hellaswag_acc: 0.2836
Step:  6268, loss: 3.263427, norm: 0.2670, time(ms): 801.09, token/sec:654471.21, hellaswag_acc: 0.2836
Step:  6269, loss: 3.281877, norm: 0.2579, time(ms): 803.15, token/sec:652792.40, hellaswag_acc: 0.2836
Step:  6270, loss: 3.331759, norm: 0.2908, time(ms): 792.10, token/sec:661892.88, hellaswag_acc: 0.2836
Step:  6271, loss: 3.276271, norm: 0.2932, time(ms): 801.16, token/sec:654409.66, hellaswag_acc: 0.2836
Step:  6272, loss: 3.300901, norm: 0.2690, time(ms): 804.97, token/sec:651310.22, hellaswag_acc: 0.2836
Step:  6273, loss: 3.268660, norm: 0.2891, time(ms): 801.30, token/sec:654296.14, hellaswag_acc: 0.2836
Step:  6274, loss: 3.245092, norm: 0.2610, time(ms): 784.32, token/sec:668463.99, hellaswag_acc: 0.2836
Step:  6275, loss: 3.291210, norm: 0.2641, time(ms): 795.14, token/sec:659367.40, hellaswag_acc: 0.2836
Step:  6276, loss: 3.299391, norm: 0.2605, time(ms): 790.62, token/sec:663137.39, hellaswag_acc: 0.2836
Step:  6277, loss: 3.288753, norm: 0.2671, time(ms): 793.36, token/sec:660844.42, hellaswag_acc: 0.2836
Step:  6278, loss: 3.341675, norm: 0.2809, time(ms): 794.17, token/sec:660167.91, hellaswag_acc: 0.2836
Step:  6279, loss: 3.301347, norm: 0.2529, time(ms): 790.51, token/sec:663223.79, hellaswag_acc: 0.2836
Step:  6280, loss: 3.268258, norm: 0.2636, time(ms): 805.17, token/sec:651155.74, hellaswag_acc: 0.2836
Step:  6281, loss: 3.336357, norm: 0.2751, time(ms): 794.79, token/sec:659652.03, hellaswag_acc: 0.2836
Step:  6282, loss: 3.287794, norm: 0.2850, time(ms): 794.96, token/sec:659516.11, hellaswag_acc: 0.2836
Step:  6283, loss: 3.283947, norm: 0.2416, time(ms): 792.59, token/sec:661488.10, hellaswag_acc: 0.2836
Step:  6284, loss: 3.317362, norm: 0.2699, time(ms): 795.33, token/sec:659211.65, hellaswag_acc: 0.2836
Step:  6285, loss: 3.297422, norm: 0.2840, time(ms): 794.94, token/sec:659531.94, hellaswag_acc: 0.2836
Step:  6286, loss: 3.320298, norm: 0.2470, time(ms): 1269.82, token/sec:412884.42, hellaswag_acc: 0.2836
Step:  6287, loss: 3.294341, norm: 0.2674, time(ms): 790.55, token/sec:663190.98, hellaswag_acc: 0.2836
Step:  6288, loss: 3.342237, norm: 0.2675, time(ms): 787.78, token/sec:665528.49, hellaswag_acc: 0.2836
Step:  6289, loss: 3.288120, norm: 0.2554, time(ms): 787.59, token/sec:665683.82, hellaswag_acc: 0.2836
Step:  6290, loss: 3.321095, norm: 0.2584, time(ms): 787.87, token/sec:665449.34, hellaswag_acc: 0.2836
Step:  6291, loss: 3.330147, norm: 0.2677, time(ms): 805.28, token/sec:651064.16, hellaswag_acc: 0.2836
Step:  6292, loss: 3.275957, norm: 0.2684, time(ms): 787.55, token/sec:665723.52, hellaswag_acc: 0.2836
Step:  6293, loss: 3.302132, norm: 0.2571, time(ms): 790.05, token/sec:663616.07, hellaswag_acc: 0.2836
Step:  6294, loss: 3.246011, norm: 0.2772, time(ms): 794.56, token/sec:659847.79, hellaswag_acc: 0.2836
Step:  6295, loss: 3.283419, norm: 0.2573, time(ms): 804.15, token/sec:651975.27, hellaswag_acc: 0.2836
Step:  6296, loss: 3.304540, norm: 0.2640, time(ms): 793.38, token/sec:660830.72, hellaswag_acc: 0.2836
Step:  6297, loss: 3.352481, norm: 0.2471, time(ms): 785.32, token/sec:667606.56, hellaswag_acc: 0.2836
Step:  6298, loss: 3.276038, norm: 0.2601, time(ms): 794.70, token/sec:659730.00, hellaswag_acc: 0.2836
Step:  6299, loss: 3.265965, norm: 0.2600, time(ms): 790.02, token/sec:663638.70, hellaswag_acc: 0.2836
Step:  6300, loss: 3.371731, norm: 0.2489, time(ms): 790.10, token/sec:663573.22, hellaswag_acc: 0.2836
Step:  6301, loss: 3.256559, norm: 0.2744, time(ms): 796.24, token/sec:658457.42, hellaswag_acc: 0.2836
Step:  6302, loss: 3.357023, norm: 0.2662, time(ms): 792.15, token/sec:661855.03, hellaswag_acc: 0.2836
Step:  6303, loss: 3.324172, norm: 0.2608, time(ms): 788.43, token/sec:664979.87, hellaswag_acc: 0.2836
Step:  6304, loss: 3.233499, norm: 0.2601, time(ms): 790.25, token/sec:663444.69, hellaswag_acc: 0.2836
Step:  6305, loss: 3.305098, norm: 0.3296, time(ms): 796.14, token/sec:658536.30, hellaswag_acc: 0.2836
Step:  6306, loss: 3.305797, norm: 0.3130, time(ms): 801.13, token/sec:654437.32, hellaswag_acc: 0.2836
Step:  6307, loss: 3.257348, norm: 0.2739, time(ms): 803.26, token/sec:652700.18, hellaswag_acc: 0.2836
Step:  6308, loss: 3.278819, norm: 0.3040, time(ms): 792.09, token/sec:661904.43, hellaswag_acc: 0.2836
Step:  6309, loss: 3.282541, norm: 0.2974, time(ms): 792.28, token/sec:661745.09, hellaswag_acc: 0.2836
Step:  6310, loss: 3.282053, norm: 0.2839, time(ms): 795.20, token/sec:659314.82, hellaswag_acc: 0.2836
Step:  6311, loss: 3.251845, norm: 0.3012, time(ms): 795.62, token/sec:658968.47, hellaswag_acc: 0.2836
Step:  6312, loss: 3.256960, norm: 0.3160, time(ms): 799.28, token/sec:655952.57, hellaswag_acc: 0.2836
Step:  6313, loss: 3.304954, norm: 0.2454, time(ms): 794.02, token/sec:660299.33, hellaswag_acc: 0.2836
Step:  6314, loss: 3.272468, norm: 0.2953, time(ms): 790.67, token/sec:663093.19, hellaswag_acc: 0.2836
Step:  6315, loss: 3.284412, norm: 0.2857, time(ms): 786.99, token/sec:666197.67, hellaswag_acc: 0.2836
Step:  6316, loss: 3.176187, norm: 0.2715, time(ms): 789.33, token/sec:664217.61, hellaswag_acc: 0.2836
Step:  6317, loss: 3.224124, norm: 0.3078, time(ms): 802.12, token/sec:653624.22, hellaswag_acc: 0.2836
Step:  6318, loss: 3.192581, norm: 0.2735, time(ms): 802.52, token/sec:653303.82, hellaswag_acc: 0.2836
Step:  6319, loss: 3.215974, norm: 0.2917, time(ms): 789.28, token/sec:664264.36, hellaswag_acc: 0.2836
Step:  6320, loss: 3.231733, norm: 0.3134, time(ms): 790.13, token/sec:663544.59, hellaswag_acc: 0.2836
Step:  6321, loss: 3.228253, norm: 0.2703, time(ms): 790.52, token/sec:663218.79, hellaswag_acc: 0.2836
Step:  6322, loss: 3.175973, norm: 0.3061, time(ms): 790.03, token/sec:663627.89, hellaswag_acc: 0.2836
Step:  6323, loss: 3.229372, norm: 0.2961, time(ms): 789.70, token/sec:663908.39, hellaswag_acc: 0.2836
Step:  6324, loss: 3.192516, norm: 0.3317, time(ms): 797.75, token/sec:657211.15, hellaswag_acc: 0.2836
Step:  6325, loss: 3.171660, norm: 0.2889, time(ms): 791.92, token/sec:662047.11, hellaswag_acc: 0.2836
Step:  6326, loss: 3.175047, norm: 0.2516, time(ms): 789.78, token/sec:663836.84, hellaswag_acc: 0.2836
Step:  6327, loss: 3.210671, norm: 0.3000, time(ms): 788.22, token/sec:665153.65, hellaswag_acc: 0.2836
Step:  6328, loss: 3.355279, norm: 0.2796, time(ms): 785.43, token/sec:667513.34, hellaswag_acc: 0.2836
Step:  6329, loss: 3.302017, norm: 0.3066, time(ms): 793.13, token/sec:661038.31, hellaswag_acc: 0.2836
Step:  6330, loss: 3.331732, norm: 0.2931, time(ms): 799.38, token/sec:655866.48, hellaswag_acc: 0.2836
Step:  6331, loss: 3.367183, norm: 0.2964, time(ms): 803.03, token/sec:652886.21, hellaswag_acc: 0.2836
Step:  6332, loss: 3.348289, norm: 0.3013, time(ms): 787.76, token/sec:665542.59, hellaswag_acc: 0.2836
Step:  6333, loss: 3.284688, norm: 0.2739, time(ms): 791.40, token/sec:662477.72, hellaswag_acc: 0.2836
Step:  6334, loss: 3.323950, norm: 0.2795, time(ms): 790.09, token/sec:663580.63, hellaswag_acc: 0.2836
Step:  6335, loss: 3.325585, norm: 0.2844, time(ms): 792.33, token/sec:661708.05, hellaswag_acc: 0.2836
Step:  6336, loss: 3.363053, norm: 0.2482, time(ms): 793.91, token/sec:660388.76, hellaswag_acc: 0.2836
Step:  6337, loss: 3.301485, norm: 0.3089, time(ms): 794.57, token/sec:659841.25, hellaswag_acc: 0.2836
Step:  6338, loss: 3.347916, norm: 0.2813, time(ms): 800.67, token/sec:654811.67, hellaswag_acc: 0.2836
Step:  6339, loss: 3.303419, norm: 0.3024, time(ms): 806.37, token/sec:650182.90, hellaswag_acc: 0.2836
Step:  6340, loss: 3.310379, norm: 0.2618, time(ms): 793.13, token/sec:661037.12, hellaswag_acc: 0.2836
Step:  6341, loss: 3.267873, norm: 0.3002, time(ms): 798.71, token/sec:656421.33, hellaswag_acc: 0.2836
Step:  6342, loss: 3.310991, norm: 0.2712, time(ms): 798.78, token/sec:656363.53, hellaswag_acc: 0.2836
Step:  6343, loss: 3.320429, norm: 0.2784, time(ms): 789.08, token/sec:664425.93, hellaswag_acc: 0.2836
Step:  6344, loss: 3.195533, norm: 0.2792, time(ms): 790.74, token/sec:663031.42, hellaswag_acc: 0.2836
Step:  6345, loss: 3.278210, norm: 0.2879, time(ms): 789.57, token/sec:664013.64, hellaswag_acc: 0.2836
Step:  6346, loss: 3.346046, norm: 0.2438, time(ms): 789.35, token/sec:664203.37, hellaswag_acc: 0.2836
Step:  6347, loss: 3.317255, norm: 0.2680, time(ms): 789.92, token/sec:663721.83, hellaswag_acc: 0.2836
Step:  6348, loss: 3.261407, norm: 0.2577, time(ms): 797.68, token/sec:657270.08, hellaswag_acc: 0.2836
Step:  6349, loss: 3.374678, norm: 0.2768, time(ms): 794.26, token/sec:660096.57, hellaswag_acc: 0.2836
Step:  6350, loss: 3.307479, norm: 0.3120, time(ms): 803.55, token/sec:652466.04, hellaswag_acc: 0.2836
Step:  6351, loss: 3.237963, norm: 0.2830, time(ms): 803.89, token/sec:652186.42, hellaswag_acc: 0.2836
Step:  6352, loss: 3.264973, norm: 0.2563, time(ms): 798.12, token/sec:656906.06, hellaswag_acc: 0.2836
Step:  6353, loss: 3.243342, norm: 0.2643, time(ms): 794.36, token/sec:660009.99, hellaswag_acc: 0.2836
Step:  6354, loss: 3.267786, norm: 0.2771, time(ms): 804.67, token/sec:651557.43, hellaswag_acc: 0.2836
Step:  6355, loss: 3.278282, norm: 0.2490, time(ms): 802.65, token/sec:653193.59, hellaswag_acc: 0.2836
Step:  6356, loss: 3.265282, norm: 0.2874, time(ms): 783.15, token/sec:669459.12, hellaswag_acc: 0.2836
Step:  6357, loss: 3.272803, norm: 0.2910, time(ms): 789.87, token/sec:663763.90, hellaswag_acc: 0.2836
Step:  6358, loss: 3.294885, norm: 0.2726, time(ms): 793.95, token/sec:660352.87, hellaswag_acc: 0.2836
Step:  6359, loss: 3.271115, norm: 0.2880, time(ms): 791.11, token/sec:662724.89, hellaswag_acc: 0.2836
Step:  6360, loss: 3.286686, norm: 0.2639, time(ms): 792.41, token/sec:661636.37, hellaswag_acc: 0.2836
Step:  6361, loss: 3.252127, norm: 0.2671, time(ms): 797.30, token/sec:657577.08, hellaswag_acc: 0.2836
Step:  6362, loss: 3.278062, norm: 0.2750, time(ms): 789.50, token/sec:664073.39, hellaswag_acc: 0.2836
Step:  6363, loss: 3.173771, norm: 0.2790, time(ms): 796.84, token/sec:657957.21, hellaswag_acc: 0.2836
Step:  6364, loss: 3.182622, norm: 0.2536, time(ms): 793.01, token/sec:661132.91, hellaswag_acc: 0.2836
Step:  6365, loss: 3.203801, norm: 0.2754, time(ms): 788.45, token/sec:664963.78, hellaswag_acc: 0.2836
Step:  6366, loss: 3.219367, norm: 0.2618, time(ms): 787.51, token/sec:665751.74, hellaswag_acc: 0.2836
Step:  6367, loss: 3.175949, norm: 0.2696, time(ms): 788.98, token/sec:664509.85, hellaswag_acc: 0.2836
Step:  6368, loss: 3.188461, norm: 0.2684, time(ms): 802.81, token/sec:653066.72, hellaswag_acc: 0.2836
Step:  6369, loss: 3.206899, norm: 0.2870, time(ms): 802.61, token/sec:653232.59, hellaswag_acc: 0.2836
Step:  6370, loss: 3.155995, norm: 0.2510, time(ms): 792.68, token/sec:661415.88, hellaswag_acc: 0.2836
Step:  6371, loss: 3.213904, norm: 0.2715, time(ms): 798.92, token/sec:656244.43, hellaswag_acc: 0.2836
Step:  6372, loss: 3.196240, norm: 0.2687, time(ms): 805.19, token/sec:651136.65, hellaswag_acc: 0.2836
Step:  6373, loss: 3.224533, norm: 0.2516, time(ms): 801.12, token/sec:654440.04, hellaswag_acc: 0.2836
Step:  6374, loss: 3.352483, norm: 0.2767, time(ms): 791.27, token/sec:662587.11, hellaswag_acc: 0.2836
Step:  6375, loss: 3.338111, norm: 0.3121, time(ms): 806.92, token/sec:649739.90, hellaswag_acc: 0.2836
Step:  6376, loss: 3.334296, norm: 0.2913, time(ms): 802.71, token/sec:653147.61, hellaswag_acc: 0.2836
Step:  6377, loss: 3.314716, norm: 0.2603, time(ms): 793.21, token/sec:660972.54, hellaswag_acc: 0.2836
Step:  6378, loss: 3.318952, norm: 0.2948, time(ms): 801.49, token/sec:654140.44, hellaswag_acc: 0.2836
Step:  6379, loss: 3.314624, norm: 0.2720, time(ms): 803.11, token/sec:652824.19, hellaswag_acc: 0.2836
Step:  6380, loss: 3.328816, norm: 0.2748, time(ms): 801.14, token/sec:654427.58, hellaswag_acc: 0.2836
Step:  6381, loss: 3.254622, norm: 0.3096, time(ms): 799.21, token/sec:656008.73, hellaswag_acc: 0.2836
Step:  6382, loss: 3.307679, norm: 0.3363, time(ms): 794.66, token/sec:659760.88, hellaswag_acc: 0.2836
Step:  6383, loss: 3.308838, norm: 0.2803, time(ms): 803.14, token/sec:652795.12, hellaswag_acc: 0.2836
Step:  6384, loss: 3.295087, norm: 0.2990, time(ms): 801.62, token/sec:654032.07, hellaswag_acc: 0.2836
Step:  6385, loss: 3.331042, norm: 0.3115, time(ms): 795.33, token/sec:659207.30, hellaswag_acc: 0.2836
Step:  6386, loss: 3.264402, norm: 0.2729, time(ms): 802.24, token/sec:653529.04, hellaswag_acc: 0.2836
Step:  6387, loss: 3.229764, norm: 0.2884, time(ms): 803.25, token/sec:652707.73, hellaswag_acc: 0.2836
Step:  6388, loss: 3.293866, norm: 0.2766, time(ms): 796.96, token/sec:657856.03, hellaswag_acc: 0.2836
Step:  6389, loss: 3.293219, norm: 0.2754, time(ms): 793.79, token/sec:660486.55, hellaswag_acc: 0.2836
Step:  6390, loss: 3.302294, norm: 0.2773, time(ms): 806.31, token/sec:650232.89, hellaswag_acc: 0.2836
Step:  6391, loss: 3.285004, norm: 0.3142, time(ms): 800.12, token/sec:655260.84, hellaswag_acc: 0.2836
Step:  6392, loss: 3.286719, norm: 0.2829, time(ms): 793.14, token/sec:661025.99, hellaswag_acc: 0.2836
Step:  6393, loss: 3.309227, norm: 0.2841, time(ms): 801.32, token/sec:654277.84, hellaswag_acc: 0.2836
Step:  6394, loss: 3.251184, norm: 0.2632, time(ms): 805.79, token/sec:650648.84, hellaswag_acc: 0.2836
Step:  6395, loss: 3.240702, norm: 0.2724, time(ms): 796.60, token/sec:658155.31, hellaswag_acc: 0.2836
Step:  6396, loss: 3.337365, norm: 0.2875, time(ms): 798.99, token/sec:656186.08, hellaswag_acc: 0.2836
Step:  6397, loss: 3.221105, norm: 0.3015, time(ms): 803.75, token/sec:652301.14, hellaswag_acc: 0.2836
Step:  6398, loss: 3.297959, norm: 0.3180, time(ms): 800.71, token/sec:654779.89, hellaswag_acc: 0.2836
Step:  6399, loss: 3.258265, norm: 0.2535, time(ms): 798.29, token/sec:656762.25, hellaswag_acc: 0.2836
Step:  6400, loss: 3.253865, norm: 0.2843, time(ms): 788.45, token/sec:664956.34, hellaswag_acc: 0.2836
Step:  6401, loss: 3.229557, norm: 0.2674, time(ms): 789.94, token/sec:663702.60, hellaswag_acc: 0.2836
Step:  6402, loss: 3.232278, norm: 0.2679, time(ms): 793.63, token/sec:660620.28, hellaswag_acc: 0.2836
Step:  6403, loss: 3.242475, norm: 0.2663, time(ms): 790.88, token/sec:662918.29, hellaswag_acc: 0.2836
Step:  6404, loss: 3.274151, norm: 0.2382, time(ms): 789.91, token/sec:663733.25, hellaswag_acc: 0.2836
Step:  6405, loss: 3.238084, norm: 0.2393, time(ms): 797.99, token/sec:657013.03, hellaswag_acc: 0.2836
Step:  6406, loss: 3.251637, norm: 0.2696, time(ms): 792.75, token/sec:661357.59, hellaswag_acc: 0.2836
Step:  6407, loss: 3.259309, norm: 0.2618, time(ms): 792.73, token/sec:661370.32, hellaswag_acc: 0.2836
Step:  6408, loss: 3.233799, norm: 0.2607, time(ms): 794.72, token/sec:659711.59, hellaswag_acc: 0.2836
Step:  6409, loss: 3.148245, norm: 0.2906, time(ms): 788.26, token/sec:665119.65, hellaswag_acc: 0.2836
Step:  6410, loss: 3.220271, norm: 0.2539, time(ms): 791.86, token/sec:662099.34, hellaswag_acc: 0.2836
Step:  6411, loss: 3.167499, norm: 0.2598, time(ms): 790.66, token/sec:663102.39, hellaswag_acc: 0.2836
Step:  6412, loss: 3.230094, norm: 0.2520, time(ms): 795.17, token/sec:659344.47, hellaswag_acc: 0.2836
Step:  6413, loss: 3.137572, norm: 0.2695, time(ms): 798.43, token/sec:656648.11, hellaswag_acc: 0.2836
Step:  6414, loss: 3.233250, norm: 0.2728, time(ms): 803.44, token/sec:652553.94, hellaswag_acc: 0.2836
Step:  6415, loss: 3.206153, norm: 0.2673, time(ms): 800.80, token/sec:654705.42, hellaswag_acc: 0.2836
Step:  6416, loss: 3.170104, norm: 0.2637, time(ms): 794.89, token/sec:659574.47, hellaswag_acc: 0.2836
Step:  6417, loss: 3.184784, norm: 0.2680, time(ms): 802.17, token/sec:653587.89, hellaswag_acc: 0.2836
Step:  6418, loss: 3.150941, norm: 0.2474, time(ms): 799.02, token/sec:656164.74, hellaswag_acc: 0.2836
Step:  6419, loss: 3.212924, norm: 0.2661, time(ms): 803.35, token/sec:652629.86, hellaswag_acc: 0.2836
Step:  6420, loss: 3.307585, norm: 0.2911, time(ms): 793.74, token/sec:660526.62, hellaswag_acc: 0.2836
Step:  6421, loss: 3.340125, norm: 0.2691, time(ms): 798.43, token/sec:656649.68, hellaswag_acc: 0.2836
Step:  6422, loss: 3.310919, norm: 0.2654, time(ms): 805.06, token/sec:651240.40, hellaswag_acc: 0.2836
Step:  6423, loss: 3.268888, norm: 0.2750, time(ms): 791.38, token/sec:662500.68, hellaswag_acc: 0.2836
Step:  6424, loss: 3.310158, norm: 0.2812, time(ms): 790.18, token/sec:663507.95, hellaswag_acc: 0.2836
Step:  6425, loss: 3.292325, norm: 0.2709, time(ms): 789.56, token/sec:664028.88, hellaswag_acc: 0.2836
Step:  6426, loss: 3.311939, norm: 0.2642, time(ms): 791.38, token/sec:662498.08, hellaswag_acc: 0.2836
Step:  6427, loss: 3.306686, norm: 0.2998, time(ms): 790.97, token/sec:662842.35, hellaswag_acc: 0.2836
Step:  6428, loss: 3.358893, norm: 0.2778, time(ms): 797.44, token/sec:657463.84, hellaswag_acc: 0.2836
Step:  6429, loss: 3.315970, norm: 0.2767, time(ms): 792.02, token/sec:661967.00, hellaswag_acc: 0.2836
Step:  6430, loss: 3.297011, norm: 0.2940, time(ms): 788.66, token/sec:664781.45, hellaswag_acc: 0.2836
Step:  6431, loss: 3.331463, norm: 0.2547, time(ms): 792.36, token/sec:661675.99, hellaswag_acc: 0.2836
Step:  6432, loss: 3.274804, norm: 0.2627, time(ms): 787.89, token/sec:665436.05, hellaswag_acc: 0.2836
Step:  6433, loss: 3.261269, norm: 0.2918, time(ms): 791.90, token/sec:662065.45, hellaswag_acc: 0.2836
Step:  6434, loss: 3.283246, norm: 0.2794, time(ms): 792.78, token/sec:661325.97, hellaswag_acc: 0.2836
Step:  6435, loss: 3.287861, norm: 0.3231, time(ms): 803.40, token/sec:652584.73, hellaswag_acc: 0.2836
Step:  6436, loss: 3.321690, norm: 0.2750, time(ms): 788.70, token/sec:664752.72, hellaswag_acc: 0.2836
Step:  6437, loss: 3.285623, norm: 0.2687, time(ms): 793.14, token/sec:661025.79, hellaswag_acc: 0.2836
Step:  6438, loss: 3.388082, norm: 0.2763, time(ms): 787.90, token/sec:665427.99, hellaswag_acc: 0.2836
Step:  6439, loss: 3.259933, norm: 0.2925, time(ms): 790.87, token/sec:662923.88, hellaswag_acc: 0.2836
Step:  6440, loss: 3.261392, norm: 0.2638, time(ms): 795.75, token/sec:658858.89, hellaswag_acc: 0.2836
Step:  6441, loss: 3.231115, norm: 0.2632, time(ms): 794.85, token/sec:659607.71, hellaswag_acc: 0.2836
Step:  6442, loss: 3.292160, norm: 0.2704, time(ms): 804.20, token/sec:651938.35, hellaswag_acc: 0.2836
Step:  6443, loss: 3.258632, norm: 0.2799, time(ms): 803.78, token/sec:652280.63, hellaswag_acc: 0.2836
Step:  6444, loss: 3.269124, norm: 0.2675, time(ms): 792.40, token/sec:661645.93, hellaswag_acc: 0.2836
Step:  6445, loss: 3.269131, norm: 0.2774, time(ms): 796.37, token/sec:658345.85, hellaswag_acc: 0.2836
Step:  6446, loss: 3.268220, norm: 0.2798, time(ms): 792.32, token/sec:661711.23, hellaswag_acc: 0.2836
Step:  6447, loss: 3.263936, norm: 0.2929, time(ms): 793.84, token/sec:660445.49, hellaswag_acc: 0.2836
Step:  6448, loss: 3.263294, norm: 0.2622, time(ms): 799.47, token/sec:655791.77, hellaswag_acc: 0.2836
Step:  6449, loss: 3.283049, norm: 0.2852, time(ms): 799.21, token/sec:656007.36, hellaswag_acc: 0.2836
Step:  6450, loss: 3.300954, norm: 0.2709, time(ms): 799.74, token/sec:655574.37, hellaswag_acc: 0.2836
Step:  6451, loss: 3.259126, norm: 0.2676, time(ms): 800.78, token/sec:654718.87, hellaswag_acc: 0.2836
Step:  6452, loss: 3.232410, norm: 0.2634, time(ms): 798.28, token/sec:656775.39, hellaswag_acc: 0.2836
Step:  6453, loss: 3.251710, norm: 0.2627, time(ms): 799.60, token/sec:655686.96, hellaswag_acc: 0.2836
Step:  6454, loss: 3.231178, norm: 0.2768, time(ms): 800.70, token/sec:654787.10, hellaswag_acc: 0.2836
Step:  6455, loss: 3.158144, norm: 0.2704, time(ms): 795.50, token/sec:659067.22, hellaswag_acc: 0.2836
Step:  6456, loss: 3.175760, norm: 0.2525, time(ms): 788.64, token/sec:664802.96, hellaswag_acc: 0.2836
Step:  6457, loss: 3.154101, norm: 0.2695, time(ms): 789.82, token/sec:663807.78, hellaswag_acc: 0.2836
Step:  6458, loss: 3.189207, norm: 0.2733, time(ms): 791.23, token/sec:662625.64, hellaswag_acc: 0.2836
Step:  6459, loss: 3.198398, norm: 0.2861, time(ms): 791.69, token/sec:662237.32, hellaswag_acc: 0.2836
Step:  6460, loss: 3.226274, norm: 0.2641, time(ms): 805.85, token/sec:650601.48, hellaswag_acc: 0.2836
Step:  6461, loss: 3.178605, norm: 0.2766, time(ms): 801.88, token/sec:653821.47, hellaswag_acc: 0.2836
Step:  6462, loss: 3.178061, norm: 0.2815, time(ms): 797.75, token/sec:657208.01, hellaswag_acc: 0.2836
Step:  6463, loss: 3.188804, norm: 0.2493, time(ms): 795.01, token/sec:659470.42, hellaswag_acc: 0.2836
Step:  6464, loss: 3.206145, norm: 0.2596, time(ms): 803.00, token/sec:652908.31, hellaswag_acc: 0.2836
Step:  6465, loss: 3.165944, norm: 0.2599, time(ms): 802.14, token/sec:653608.09, hellaswag_acc: 0.2836
Step:  6466, loss: 3.205573, norm: 0.2614, time(ms): 796.87, token/sec:657932.01, hellaswag_acc: 0.2836
Step:  6467, loss: 3.307770, norm: 0.2750, time(ms): 796.20, token/sec:658488.18, hellaswag_acc: 0.2836
Step:  6468, loss: 3.359105, norm: 0.3234, time(ms): 804.89, token/sec:651379.48, hellaswag_acc: 0.2836
Step:  6469, loss: 3.303861, norm: 0.2982, time(ms): 803.28, token/sec:652682.74, hellaswag_acc: 0.2836
Step:  6470, loss: 3.235460, norm: 0.3029, time(ms): 792.51, token/sec:661557.15, hellaswag_acc: 0.2836
Step:  6471, loss: 3.314279, norm: 0.2883, time(ms): 796.40, token/sec:658322.98, hellaswag_acc: 0.2836
Step:  6472, loss: 3.304375, norm: 0.2955, time(ms): 807.52, token/sec:649259.35, hellaswag_acc: 0.2836
Step:  6473, loss: 3.330072, norm: 0.3017, time(ms): 791.70, token/sec:662230.94, hellaswag_acc: 0.2836
Step:  6474, loss: 3.290909, norm: 0.3045, time(ms): 788.96, token/sec:664530.74, hellaswag_acc: 0.2836
Step:  6475, loss: 3.301054, norm: 0.2846, time(ms): 790.65, token/sec:663105.99, hellaswag_acc: 0.2836
Step:  6476, loss: 3.317546, norm: 0.2735, time(ms): 1292.09, token/sec:405768.47, hellaswag_acc: 0.2836
Step:  6477, loss: 3.279332, norm: 0.3220, time(ms): 772.70, token/sec:678511.93, hellaswag_acc: 0.2836
Step:  6478, loss: 3.263793, norm: 0.2870, time(ms): 783.91, token/sec:668807.98, hellaswag_acc: 0.2836
Step:  6479, loss: 3.317517, norm: 0.2899, time(ms): 795.59, token/sec:658988.81, hellaswag_acc: 0.2836
Step:  6480, loss: 3.288733, norm: 0.2722, time(ms): 789.20, token/sec:664326.17, hellaswag_acc: 0.2836
Step:  6481, loss: 3.210021, norm: 0.3448, time(ms): 780.43, token/sec:671789.58, hellaswag_acc: 0.2836
Step:  6482, loss: 3.224602, norm: 0.2903, time(ms): 788.03, token/sec:665311.83, hellaswag_acc: 0.2836
Step:  6483, loss: 3.323214, norm: 0.3438, time(ms): 790.18, token/sec:663507.15, hellaswag_acc: 0.2836
Step:  6484, loss: 3.292983, norm: 0.3616, time(ms): 794.53, token/sec:659869.57, hellaswag_acc: 0.2836
Step:  6485, loss: 3.239320, norm: 0.3124, time(ms): 792.57, token/sec:661502.43, hellaswag_acc: 0.2836
Step:  6486, loss: 3.263169, norm: 0.2937, time(ms): 795.54, token/sec:659033.05, hellaswag_acc: 0.2836
Step:  6487, loss: 3.243306, norm: 0.2980, time(ms): 793.28, token/sec:660907.98, hellaswag_acc: 0.2836
Step:  6488, loss: 3.204382, norm: 0.3120, time(ms): 797.77, token/sec:657190.72, hellaswag_acc: 0.2836
Step:  6489, loss: 3.256902, norm: 0.2865, time(ms): 796.98, token/sec:657842.45, hellaswag_acc: 0.2836
Step:  6490, loss: 3.301800, norm: 0.2669, time(ms): 798.07, token/sec:656947.47, hellaswag_acc: 0.2836
Step:  6491, loss: 3.259292, norm: 0.2953, time(ms): 799.96, token/sec:655390.12, hellaswag_acc: 0.2836
Step:  6492, loss: 3.272007, norm: 0.2727, time(ms): 797.49, token/sec:657419.81, hellaswag_acc: 0.2836
Step:  6493, loss: 3.255735, norm: 0.2507, time(ms): 789.98, token/sec:663669.55, hellaswag_acc: 0.2836
Step:  6494, loss: 3.271022, norm: 0.2642, time(ms): 788.82, token/sec:664646.23, hellaswag_acc: 0.2836
Step:  6495, loss: 3.258679, norm: 0.2440, time(ms): 793.55, token/sec:660690.35, hellaswag_acc: 0.2836
Step:  6496, loss: 3.228309, norm: 0.2685, time(ms): 791.41, token/sec:662473.73, hellaswag_acc: 0.2836
Step:  6497, loss: 3.271951, norm: 0.2603, time(ms): 802.18, token/sec:653579.73, hellaswag_acc: 0.2836
Step:  6498, loss: 3.298510, norm: 0.2811, time(ms): 801.60, token/sec:654051.91, hellaswag_acc: 0.2836
Step:  6499, loss: 3.237050, norm: 0.2683, time(ms): 793.04, token/sec:661109.85, hellaswag_acc: 0.2836
rank 0 sample 0: Hello, I'm a language model, I'm sure you've come into the discussion a lot. I do expect a lot more vocabulary words to come in this
rank 0 sample 1: Hello, I'm a language model, so here's my question: I thought I was writing with my language friends! I think this was like an extension of
rank 0 sample 2: Hello, I'm a language model, so I wanted to say you wanted to know why we use "words" in the sentence.
I'm a first
rank 0 sample 3: Hello, I'm a language model, and not a language model.
And this wasn't the first time I've played that board. We have been asked
rank 1 sample 0: Hello, I'm a language model, in fact I'm a linguist all over the world.”
How do we use “words”
rank 1 sample 1: Hello, I'm a language model, you can see, it's an interface that's the heart of that language. Most beginners really like the idea of using
rank 1 sample 2: Hello, I'm a language model, and is the best way to learn the language. I've already said the question, "How is a language made up
rank 1 sample 3: Hello, I'm a language model, I'm a big one so I'd write a single story that sounds nice."
On July 22, 2015, the
Step:  6500, loss: 3.232461, norm: 0.2722, time(ms): 3757.45, token/sec:139532.89, val_loss: 3.2855, hellaswag_acc: 0.2836
Step:  6501, loss: 3.185031, norm: 0.2898, time(ms): 791.74, token/sec:662195.64, hellaswag_acc: 0.2836
Step:  6502, loss: 3.200823, norm: 0.2841, time(ms): 786.02, token/sec:667012.83, hellaswag_acc: 0.2836
Step:  6503, loss: 3.251091, norm: 0.2627, time(ms): 794.34, token/sec:660030.19, hellaswag_acc: 0.2836
Step:  6504, loss: 3.282143, norm: 0.2709, time(ms): 787.52, token/sec:665748.91, hellaswag_acc: 0.2836
Step:  6505, loss: 3.316154, norm: 0.2954, time(ms): 785.67, token/sec:667312.81, hellaswag_acc: 0.2836
Step:  6506, loss: 3.300695, norm: 0.2896, time(ms): 796.90, token/sec:657913.31, hellaswag_acc: 0.2836
Step:  6507, loss: 3.300548, norm: 0.2969, time(ms): 805.76, token/sec:650677.91, hellaswag_acc: 0.2836
Step:  6508, loss: 3.292953, norm: 0.2860, time(ms): 785.77, token/sec:667229.39, hellaswag_acc: 0.2836
Step:  6509, loss: 3.291538, norm: 0.2948, time(ms): 794.72, token/sec:659712.19, hellaswag_acc: 0.2836
Step:  6510, loss: 3.296616, norm: 0.2734, time(ms): 789.95, token/sec:663698.39, hellaswag_acc: 0.2836
Step:  6511, loss: 3.281290, norm: 0.2641, time(ms): 790.55, token/sec:663194.38, hellaswag_acc: 0.2836
Step:  6512, loss: 3.277592, norm: 0.2723, time(ms): 790.15, token/sec:663525.57, hellaswag_acc: 0.2836
Step:  6513, loss: 3.298144, norm: 0.2964, time(ms): 797.50, token/sec:657414.11, hellaswag_acc: 0.2836
Step:  6514, loss: 3.266003, norm: 0.2572, time(ms): 791.41, token/sec:662473.53, hellaswag_acc: 0.2836
Step:  6515, loss: 3.318099, norm: 0.2910, time(ms): 796.87, token/sec:657932.01, hellaswag_acc: 0.2836
Step:  6516, loss: 3.260568, norm: 0.2795, time(ms): 791.46, token/sec:662435.62, hellaswag_acc: 0.2836
Step:  6517, loss: 3.253159, norm: 0.2803, time(ms): 788.66, token/sec:664782.46, hellaswag_acc: 0.2836
Step:  6518, loss: 3.274279, norm: 0.2740, time(ms): 792.97, token/sec:661173.86, hellaswag_acc: 0.2836
Step:  6519, loss: 3.252686, norm: 0.2693, time(ms): 790.67, token/sec:663091.99, hellaswag_acc: 0.2836
Step:  6520, loss: 3.232500, norm: 0.2722, time(ms): 797.42, token/sec:657484.29, hellaswag_acc: 0.2836
Step:  6521, loss: 3.244403, norm: 0.2659, time(ms): 791.11, token/sec:662723.10, hellaswag_acc: 0.2836
Step:  6522, loss: 3.230444, norm: 0.2531, time(ms): 805.67, token/sec:650751.27, hellaswag_acc: 0.2836
Step:  6523, loss: 3.231913, norm: 0.2983, time(ms): 794.76, token/sec:659680.33, hellaswag_acc: 0.2836
Step:  6524, loss: 3.266101, norm: 0.2796, time(ms): 792.48, token/sec:661574.67, hellaswag_acc: 0.2836
Step:  6525, loss: 3.298685, norm: 0.2502, time(ms): 789.01, token/sec:664488.57, hellaswag_acc: 0.2836
Step:  6526, loss: 3.280766, norm: 0.2758, time(ms): 793.00, token/sec:661145.23, hellaswag_acc: 0.2836
Step:  6527, loss: 3.245420, norm: 0.2736, time(ms): 793.15, token/sec:661022.01, hellaswag_acc: 0.2836
Step:  6528, loss: 3.225712, norm: 0.3023, time(ms): 790.98, token/sec:662832.96, hellaswag_acc: 0.2836
Step:  6529, loss: 3.291373, norm: 0.2976, time(ms): 799.25, token/sec:655977.61, hellaswag_acc: 0.2836
Step:  6530, loss: 3.265059, norm: 0.2806, time(ms): 800.87, token/sec:654647.34, hellaswag_acc: 0.2836
Step:  6531, loss: 3.273176, norm: 0.2786, time(ms): 791.94, token/sec:662026.78, hellaswag_acc: 0.2836
Step:  6532, loss: 3.268422, norm: 0.2782, time(ms): 793.64, token/sec:660609.57, hellaswag_acc: 0.2836
Step:  6533, loss: 3.255033, norm: 0.2775, time(ms): 795.03, token/sec:659459.35, hellaswag_acc: 0.2836
Step:  6534, loss: 3.250348, norm: 0.2776, time(ms): 799.38, token/sec:655872.16, hellaswag_acc: 0.2836
Step:  6535, loss: 3.226419, norm: 0.2675, time(ms): 791.29, token/sec:662577.13, hellaswag_acc: 0.2836
Step:  6536, loss: 3.238898, norm: 0.2677, time(ms): 787.05, token/sec:666146.41, hellaswag_acc: 0.2836
Step:  6537, loss: 3.227826, norm: 0.2592, time(ms): 786.33, token/sec:666753.36, hellaswag_acc: 0.2836
Step:  6538, loss: 3.278149, norm: 0.2669, time(ms): 798.87, token/sec:656285.17, hellaswag_acc: 0.2836
Step:  6539, loss: 3.279169, norm: 0.2655, time(ms): 804.39, token/sec:651781.06, hellaswag_acc: 0.2836
Step:  6540, loss: 3.290375, norm: 0.2874, time(ms): 795.13, token/sec:659370.96, hellaswag_acc: 0.2836
Step:  6541, loss: 3.323108, norm: 0.2685, time(ms): 800.14, token/sec:655241.51, hellaswag_acc: 0.2836
Step:  6542, loss: 3.402665, norm: 0.3061, time(ms): 801.13, token/sec:654439.65, hellaswag_acc: 0.2836
Step:  6543, loss: 3.314911, norm: 0.4030, time(ms): 801.33, token/sec:654273.17, hellaswag_acc: 0.2836
Step:  6544, loss: 3.319886, norm: 0.4110, time(ms): 795.25, token/sec:659274.89, hellaswag_acc: 0.2836
Step:  6545, loss: 3.338733, norm: 0.3030, time(ms): 805.34, token/sec:651017.33, hellaswag_acc: 0.2836
Step:  6546, loss: 3.290072, norm: 0.3607, time(ms): 800.01, token/sec:655347.73, hellaswag_acc: 0.2836
Step:  6547, loss: 3.240498, norm: 0.2992, time(ms): 794.50, token/sec:659893.53, hellaswag_acc: 0.2836
Step:  6548, loss: 3.372614, norm: 0.3569, time(ms): 800.66, token/sec:654821.61, hellaswag_acc: 0.2836
Step:  6549, loss: 3.285541, norm: 0.3939, time(ms): 804.52, token/sec:651680.42, hellaswag_acc: 0.2836
Step:  6550, loss: 3.247068, norm: 0.3204, time(ms): 799.67, token/sec:655626.75, hellaswag_acc: 0.2836
Step:  6551, loss: 3.270097, norm: 0.3109, time(ms): 791.49, token/sec:662407.68, hellaswag_acc: 0.2836
Step:  6552, loss: 3.238544, norm: 0.3222, time(ms): 801.85, token/sec:653845.77, hellaswag_acc: 0.2836
Step:  6553, loss: 3.260001, norm: 0.3106, time(ms): 805.78, token/sec:650656.54, hellaswag_acc: 0.2836
Step:  6554, loss: 3.264672, norm: 0.2588, time(ms): 786.48, token/sec:666622.18, hellaswag_acc: 0.2836
Step:  6555, loss: 3.245009, norm: 0.2900, time(ms): 787.62, token/sec:665661.45, hellaswag_acc: 0.2836
Step:  6556, loss: 3.283154, norm: 0.2763, time(ms): 790.34, token/sec:663372.64, hellaswag_acc: 0.2836
Step:  6557, loss: 3.302438, norm: 0.2771, time(ms): 794.35, token/sec:660023.85, hellaswag_acc: 0.2836
Step:  6558, loss: 3.241723, norm: 0.2645, time(ms): 790.84, token/sec:662954.06, hellaswag_acc: 0.2836
Step:  6559, loss: 3.237922, norm: 0.2772, time(ms): 792.76, token/sec:661343.87, hellaswag_acc: 0.2836
Step:  6560, loss: 3.341908, norm: 0.3036, time(ms): 795.24, token/sec:659286.75, hellaswag_acc: 0.2836
Step:  6561, loss: 3.239712, norm: 0.3151, time(ms): 796.31, token/sec:658395.91, hellaswag_acc: 0.2836
Step:  6562, loss: 3.248528, norm: 0.3051, time(ms): 797.80, token/sec:657169.71, hellaswag_acc: 0.2836
Step:  6563, loss: 3.297437, norm: 0.2525, time(ms): 795.71, token/sec:658892.26, hellaswag_acc: 0.2836
Step:  6564, loss: 3.212208, norm: 0.2834, time(ms): 789.55, token/sec:664031.88, hellaswag_acc: 0.2836
Step:  6565, loss: 3.221837, norm: 0.2679, time(ms): 792.69, token/sec:661406.33, hellaswag_acc: 0.2836
Step:  6566, loss: 3.229355, norm: 0.2627, time(ms): 791.18, token/sec:662665.18, hellaswag_acc: 0.2836
Step:  6567, loss: 3.241622, norm: 0.2790, time(ms): 795.10, token/sec:659398.64, hellaswag_acc: 0.2836
Step:  6568, loss: 3.258836, norm: 0.2711, time(ms): 796.17, token/sec:658509.67, hellaswag_acc: 0.2836
Step:  6569, loss: 3.229256, norm: 0.2614, time(ms): 803.49, token/sec:652514.44, hellaswag_acc: 0.2836
Step:  6570, loss: 3.235650, norm: 0.2565, time(ms): 800.18, token/sec:655214.95, hellaswag_acc: 0.2836
Step:  6571, loss: 3.184922, norm: 0.2653, time(ms): 794.92, token/sec:659551.32, hellaswag_acc: 0.2836
Step:  6572, loss: 3.249483, norm: 0.2567, time(ms): 797.38, token/sec:657514.95, hellaswag_acc: 0.2836
Step:  6573, loss: 3.292896, norm: 0.2628, time(ms): 807.50, token/sec:649273.35, hellaswag_acc: 0.2836
Step:  6574, loss: 3.307115, norm: 0.2685, time(ms): 790.66, token/sec:663103.99, hellaswag_acc: 0.2836
Step:  6575, loss: 3.256857, norm: 0.2914, time(ms): 791.16, token/sec:662685.15, hellaswag_acc: 0.2836
Step:  6576, loss: 3.288270, norm: 0.2921, time(ms): 794.56, token/sec:659844.82, hellaswag_acc: 0.2836
Step:  6577, loss: 3.261443, norm: 0.2727, time(ms): 792.34, token/sec:661699.88, hellaswag_acc: 0.2836
Step:  6578, loss: 3.235761, norm: 0.2777, time(ms): 792.87, token/sec:661254.58, hellaswag_acc: 0.2836
Step:  6579, loss: 3.276495, norm: 0.2642, time(ms): 791.30, token/sec:662563.35, hellaswag_acc: 0.2836
Step:  6580, loss: 3.302554, norm: 0.2739, time(ms): 796.84, token/sec:657958.39, hellaswag_acc: 0.2836
Step:  6581, loss: 3.333274, norm: 0.2744, time(ms): 792.12, token/sec:661881.32, hellaswag_acc: 0.2836
Step:  6582, loss: 3.273661, norm: 0.2810, time(ms): 790.30, token/sec:663407.26, hellaswag_acc: 0.2836
Step:  6583, loss: 3.249417, norm: 0.2572, time(ms): 796.13, token/sec:658543.79, hellaswag_acc: 0.2836
Step:  6584, loss: 3.266081, norm: 0.2741, time(ms): 789.14, token/sec:664375.14, hellaswag_acc: 0.2836
Step:  6585, loss: 3.231172, norm: 0.2678, time(ms): 791.93, token/sec:662038.74, hellaswag_acc: 0.2836
Step:  6586, loss: 3.291838, norm: 0.2468, time(ms): 792.68, token/sec:661413.09, hellaswag_acc: 0.2836
Step:  6587, loss: 3.254703, norm: 0.2581, time(ms): 794.90, token/sec:659566.75, hellaswag_acc: 0.2836
Step:  6588, loss: 3.226950, norm: 0.2723, time(ms): 795.76, token/sec:658850.01, hellaswag_acc: 0.2836
Step:  6589, loss: 3.267534, norm: 0.2557, time(ms): 802.36, token/sec:653430.58, hellaswag_acc: 0.2836
Step:  6590, loss: 3.246519, norm: 0.2939, time(ms): 793.80, token/sec:660478.02, hellaswag_acc: 0.2836
Step:  6591, loss: 3.224697, norm: 0.3087, time(ms): 800.98, token/sec:654557.90, hellaswag_acc: 0.2836
Step:  6592, loss: 3.301306, norm: 0.2758, time(ms): 802.82, token/sec:653059.74, hellaswag_acc: 0.2836
Step:  6593, loss: 3.263669, norm: 0.2564, time(ms): 799.71, token/sec:655600.95, hellaswag_acc: 0.2836
Step:  6594, loss: 3.241340, norm: 0.2734, time(ms): 804.34, token/sec:651827.23, hellaswag_acc: 0.2836
Step:  6595, loss: 3.260137, norm: 0.2674, time(ms): 800.15, token/sec:655236.62, hellaswag_acc: 0.2836
Step:  6596, loss: 3.252955, norm: 0.2575, time(ms): 798.91, token/sec:656255.60, hellaswag_acc: 0.2836
Step:  6597, loss: 3.309307, norm: 0.7503, time(ms): 799.94, token/sec:655409.07, hellaswag_acc: 0.2836
Step:  6598, loss: 3.228160, norm: 0.3109, time(ms): 800.80, token/sec:654702.30, hellaswag_acc: 0.2836
Step:  6599, loss: 3.285053, norm: 0.2975, time(ms): 794.94, token/sec:659528.38, hellaswag_acc: 0.2836
Step:  6600, loss: 3.348834, norm: 0.2967, time(ms): 803.14, token/sec:652798.02, hellaswag_acc: 0.2836
Step:  6601, loss: 3.243540, norm: 0.3230, time(ms): 798.97, token/sec:656202.53, hellaswag_acc: 0.2836
Step:  6602, loss: 3.245088, norm: 0.2624, time(ms): 800.90, token/sec:654623.17, hellaswag_acc: 0.2836
Step:  6603, loss: 3.225426, norm: 0.3041, time(ms): 798.33, token/sec:656734.60, hellaswag_acc: 0.2836
Step:  6604, loss: 3.185173, norm: 0.2603, time(ms): 802.31, token/sec:653473.10, hellaswag_acc: 0.2836
Step:  6605, loss: 3.213095, norm: 0.2859, time(ms): 798.98, token/sec:656200.37, hellaswag_acc: 0.2836
Step:  6606, loss: 3.275347, norm: 0.2601, time(ms): 797.29, token/sec:657588.29, hellaswag_acc: 0.2836
Step:  6607, loss: 3.266431, norm: 0.2924, time(ms): 803.94, token/sec:652150.64, hellaswag_acc: 0.2836
Step:  6608, loss: 3.324172, norm: 0.3106, time(ms): 794.69, token/sec:659740.29, hellaswag_acc: 0.2836
Step:  6609, loss: 3.250096, norm: 0.3243, time(ms): 798.95, token/sec:656219.56, hellaswag_acc: 0.2836
Step:  6610, loss: 3.337348, norm: 0.2979, time(ms): 805.29, token/sec:651058.00, hellaswag_acc: 0.2836
Step:  6611, loss: 3.357480, norm: 0.2967, time(ms): 801.37, token/sec:654240.08, hellaswag_acc: 0.2836
Step:  6612, loss: 3.299954, norm: 0.2903, time(ms): 788.39, token/sec:665008.42, hellaswag_acc: 0.2836
Step:  6613, loss: 3.324445, norm: 0.2988, time(ms): 791.80, token/sec:662150.78, hellaswag_acc: 0.2836
Step:  6614, loss: 3.266130, norm: 0.2829, time(ms): 790.77, token/sec:663012.82, hellaswag_acc: 0.2836
Step:  6615, loss: 3.344305, norm: 0.2807, time(ms): 793.02, token/sec:661125.95, hellaswag_acc: 0.2836
Step:  6616, loss: 3.271231, norm: 0.2832, time(ms): 789.78, token/sec:663840.25, hellaswag_acc: 0.2836
Step:  6617, loss: 3.309301, norm: 0.2852, time(ms): 796.68, token/sec:658093.46, hellaswag_acc: 0.2836
Step:  6618, loss: 3.311441, norm: 0.2889, time(ms): 806.93, token/sec:649730.88, hellaswag_acc: 0.2836
Step:  6619, loss: 3.283864, norm: 0.3016, time(ms): 796.59, token/sec:658164.76, hellaswag_acc: 0.2836
Step:  6620, loss: 3.277093, norm: 0.2636, time(ms): 791.71, token/sec:662218.97, hellaswag_acc: 0.2836
Step:  6621, loss: 3.309019, norm: 0.2677, time(ms): 792.48, token/sec:661574.67, hellaswag_acc: 0.2836
Step:  6622, loss: 3.255897, norm: 0.2682, time(ms): 794.45, token/sec:659941.85, hellaswag_acc: 0.2836
Step:  6623, loss: 3.266974, norm: 0.2531, time(ms): 793.49, token/sec:660735.61, hellaswag_acc: 0.2836
Step:  6624, loss: 3.282226, norm: 0.2817, time(ms): 788.34, token/sec:665056.29, hellaswag_acc: 0.2836
Step:  6625, loss: 3.280078, norm: 0.2432, time(ms): 791.96, token/sec:662012.24, hellaswag_acc: 0.2836
Step:  6626, loss: 3.290092, norm: 0.2766, time(ms): 791.07, token/sec:662762.04, hellaswag_acc: 0.2836
Step:  6627, loss: 3.266314, norm: 0.2607, time(ms): 793.56, token/sec:660681.02, hellaswag_acc: 0.2836
Step:  6628, loss: 3.245986, norm: 0.2539, time(ms): 802.16, token/sec:653599.16, hellaswag_acc: 0.2836
Step:  6629, loss: 3.250716, norm: 0.2484, time(ms): 803.51, token/sec:652493.92, hellaswag_acc: 0.2836
Step:  6630, loss: 3.270835, norm: 0.2678, time(ms): 795.90, token/sec:658737.91, hellaswag_acc: 0.2836
Step:  6631, loss: 3.211246, norm: 0.2764, time(ms): 797.74, token/sec:657213.31, hellaswag_acc: 0.2836
Step:  6632, loss: 3.218157, norm: 0.3200, time(ms): 803.99, token/sec:652107.90, hellaswag_acc: 0.2836
Step:  6633, loss: 3.219029, norm: 0.2618, time(ms): 800.32, token/sec:655093.94, hellaswag_acc: 0.2836
Step:  6634, loss: 3.234127, norm: 0.2542, time(ms): 790.25, token/sec:663441.69, hellaswag_acc: 0.2836
Step:  6635, loss: 3.276364, norm: 0.2731, time(ms): 791.79, token/sec:662154.56, hellaswag_acc: 0.2836
Step:  6636, loss: 3.295969, norm: 0.2522, time(ms): 787.60, token/sec:665681.00, hellaswag_acc: 0.2836
Step:  6637, loss: 3.219959, norm: 0.2731, time(ms): 792.38, token/sec:661659.47, hellaswag_acc: 0.2836
Step:  6638, loss: 3.267891, norm: 0.2813, time(ms): 795.52, token/sec:659046.88, hellaswag_acc: 0.2836
Step:  6639, loss: 3.247827, norm: 0.2809, time(ms): 795.10, token/sec:659401.61, hellaswag_acc: 0.2836
Step:  6640, loss: 3.259469, norm: 0.2864, time(ms): 802.43, token/sec:653375.25, hellaswag_acc: 0.2836
Step:  6641, loss: 3.278687, norm: 0.2820, time(ms): 804.47, token/sec:651718.86, hellaswag_acc: 0.2836
Step:  6642, loss: 3.300906, norm: 0.2944, time(ms): 790.90, token/sec:662900.50, hellaswag_acc: 0.2836
Step:  6643, loss: 3.333522, norm: 0.3069, time(ms): 792.30, token/sec:661731.15, hellaswag_acc: 0.2836
Step:  6644, loss: 3.308884, norm: 0.2911, time(ms): 792.35, token/sec:661688.54, hellaswag_acc: 0.2836
Step:  6645, loss: 3.275786, norm: 0.2926, time(ms): 803.99, token/sec:652110.99, hellaswag_acc: 0.2836
Step:  6646, loss: 3.294331, norm: 0.3179, time(ms): 796.91, token/sec:657900.71, hellaswag_acc: 0.2836
Step:  6647, loss: 3.234850, norm: 0.3167, time(ms): 793.79, token/sec:660488.33, hellaswag_acc: 0.2836
Step:  6648, loss: 3.284760, norm: 0.2878, time(ms): 792.05, token/sec:661934.12, hellaswag_acc: 0.2836
Step:  6649, loss: 3.243783, norm: 0.2781, time(ms): 787.35, token/sec:665893.06, hellaswag_acc: 0.2836
Step:  6650, loss: 3.330239, norm: 0.2757, time(ms): 786.74, token/sec:666408.45, hellaswag_acc: 0.2836
Step:  6651, loss: 3.240224, norm: 0.2869, time(ms): 795.71, token/sec:658892.06, hellaswag_acc: 0.2836
Step:  6652, loss: 3.251657, norm: 0.2835, time(ms): 807.08, token/sec:649607.85, hellaswag_acc: 0.2836
Step:  6653, loss: 3.242346, norm: 0.2452, time(ms): 800.32, token/sec:655099.01, hellaswag_acc: 0.2836
Step:  6654, loss: 3.205849, norm: 0.2777, time(ms): 784.88, token/sec:667983.97, hellaswag_acc: 0.2836
Step:  6655, loss: 3.257743, norm: 0.2551, time(ms): 797.20, token/sec:657661.85, hellaswag_acc: 0.2836
Step:  6656, loss: 3.243791, norm: 0.2513, time(ms): 788.06, token/sec:665291.30, hellaswag_acc: 0.2836
Step:  6657, loss: 3.276609, norm: 0.2827, time(ms): 793.21, token/sec:660969.36, hellaswag_acc: 0.2836
Step:  6658, loss: 3.291360, norm: 0.2500, time(ms): 793.78, token/sec:660499.25, hellaswag_acc: 0.2836
Step:  6659, loss: 3.281219, norm: 0.2646, time(ms): 798.28, token/sec:656774.41, hellaswag_acc: 0.2836
Step:  6660, loss: 3.282301, norm: 0.2659, time(ms): 800.81, token/sec:654695.28, hellaswag_acc: 0.2836
Step:  6661, loss: 3.333285, norm: 0.2710, time(ms): 797.88, token/sec:657098.23, hellaswag_acc: 0.2836
Step:  6662, loss: 3.274409, norm: 0.2682, time(ms): 798.61, token/sec:656501.28, hellaswag_acc: 0.2836
Step:  6663, loss: 3.259617, norm: 0.2678, time(ms): 805.29, token/sec:651054.91, hellaswag_acc: 0.2836
Step:  6664, loss: 3.315179, norm: 0.2996, time(ms): 795.68, token/sec:658917.92, hellaswag_acc: 0.2836
Step:  6665, loss: 3.247428, norm: 0.3300, time(ms): 792.95, token/sec:661189.56, hellaswag_acc: 0.2836
Step:  6666, loss: 3.220060, norm: 0.2989, time(ms): 792.68, token/sec:661412.89, hellaswag_acc: 0.2836
Step:  6667, loss: 3.259056, norm: 0.2871, time(ms): 1242.07, token/sec:422109.40, hellaswag_acc: 0.2836
Step:  6668, loss: 3.278758, norm: 0.2937, time(ms): 794.84, token/sec:659612.06, hellaswag_acc: 0.2836
Step:  6669, loss: 3.288133, norm: 0.2849, time(ms): 787.75, token/sec:665553.87, hellaswag_acc: 0.2836
Step:  6670, loss: 3.295540, norm: 0.2641, time(ms): 785.71, token/sec:667279.40, hellaswag_acc: 0.2836
Step:  6671, loss: 3.317660, norm: 0.2949, time(ms): 796.11, token/sec:658563.12, hellaswag_acc: 0.2836
Step:  6672, loss: 3.315740, norm: 0.2998, time(ms): 799.42, token/sec:655837.93, hellaswag_acc: 0.2836
Step:  6673, loss: 3.289680, norm: 0.2831, time(ms): 793.82, token/sec:660461.16, hellaswag_acc: 0.2836
Step:  6674, loss: 3.271677, norm: 0.2650, time(ms): 781.62, token/sec:670770.12, hellaswag_acc: 0.2836
Step:  6675, loss: 3.224844, norm: 0.2888, time(ms): 790.58, token/sec:663168.38, hellaswag_acc: 0.2836
Step:  6676, loss: 3.245760, norm: 0.3012, time(ms): 796.55, token/sec:658198.65, hellaswag_acc: 0.2836
Step:  6677, loss: 3.238395, norm: 0.3084, time(ms): 793.66, token/sec:660598.45, hellaswag_acc: 0.2836
Step:  6678, loss: 3.268295, norm: 0.2767, time(ms): 794.44, token/sec:659950.17, hellaswag_acc: 0.2836
Step:  6679, loss: 3.283432, norm: 0.2949, time(ms): 788.48, token/sec:664936.44, hellaswag_acc: 0.2836
Step:  6680, loss: 3.247470, norm: 0.2721, time(ms): 801.73, token/sec:653944.55, hellaswag_acc: 0.2836
Step:  6681, loss: 3.208317, norm: 0.2432, time(ms): 804.36, token/sec:651811.39, hellaswag_acc: 0.2836
Step:  6682, loss: 3.228705, norm: 0.2390, time(ms): 800.96, token/sec:654571.15, hellaswag_acc: 0.2836
Step:  6683, loss: 3.213737, norm: 0.2384, time(ms): 791.85, token/sec:662103.73, hellaswag_acc: 0.2836
Step:  6684, loss: 3.255420, norm: 0.2401, time(ms): 793.35, token/sec:660855.74, hellaswag_acc: 0.2836
Step:  6685, loss: 3.273316, norm: 0.2319, time(ms): 790.34, token/sec:663366.24, hellaswag_acc: 0.2836
Step:  6686, loss: 3.236197, norm: 0.2545, time(ms): 792.04, token/sec:661945.08, hellaswag_acc: 0.2836
Step:  6687, loss: 3.357487, norm: 0.2762, time(ms): 793.84, token/sec:660445.29, hellaswag_acc: 0.2836
Step:  6688, loss: 3.321513, norm: 0.2694, time(ms): 796.03, token/sec:658628.01, hellaswag_acc: 0.2836
Step:  6689, loss: 3.289256, norm: 0.2531, time(ms): 799.91, token/sec:655437.78, hellaswag_acc: 0.2836
Step:  6690, loss: 3.258104, norm: 0.2842, time(ms): 801.17, token/sec:654403.62, hellaswag_acc: 0.2836
Step:  6691, loss: 3.272044, norm: 0.2878, time(ms): 797.02, token/sec:657809.20, hellaswag_acc: 0.2836
Step:  6692, loss: 3.316815, norm: 0.2891, time(ms): 802.42, token/sec:653385.15, hellaswag_acc: 0.2836
Step:  6693, loss: 3.304275, norm: 0.2949, time(ms): 803.21, token/sec:652741.25, hellaswag_acc: 0.2836
Step:  6694, loss: 3.265992, norm: 0.3037, time(ms): 796.25, token/sec:658446.78, hellaswag_acc: 0.2836
Step:  6695, loss: 3.271561, norm: 0.2814, time(ms): 796.84, token/sec:657955.63, hellaswag_acc: 0.2836
Step:  6696, loss: 3.309701, norm: 0.2789, time(ms): 801.74, token/sec:653936.57, hellaswag_acc: 0.2836
Step:  6697, loss: 3.341524, norm: 0.2721, time(ms): 801.50, token/sec:654130.51, hellaswag_acc: 0.2836
Step:  6698, loss: 3.295288, norm: 0.2732, time(ms): 802.28, token/sec:653498.93, hellaswag_acc: 0.2836
Step:  6699, loss: 3.270917, norm: 0.2806, time(ms): 791.72, token/sec:662212.99, hellaswag_acc: 0.2836
Step:  6700, loss: 3.272789, norm: 0.2645, time(ms): 797.81, token/sec:657156.36, hellaswag_acc: 0.2836
Step:  6701, loss: 3.353460, norm: 0.2745, time(ms): 792.04, token/sec:661949.26, hellaswag_acc: 0.2836
Step:  6702, loss: 3.288950, norm: 0.2842, time(ms): 794.21, token/sec:660135.40, hellaswag_acc: 0.2836
Step:  6703, loss: 3.297332, norm: 0.2840, time(ms): 797.08, token/sec:657757.84, hellaswag_acc: 0.2836
Step:  6704, loss: 3.251352, norm: 0.2774, time(ms): 801.33, token/sec:654275.70, hellaswag_acc: 0.2836
Step:  6705, loss: 3.231269, norm: 0.2579, time(ms): 804.52, token/sec:651678.49, hellaswag_acc: 0.2836
Step:  6706, loss: 3.319610, norm: 0.2616, time(ms): 792.15, token/sec:661857.62, hellaswag_acc: 0.2836
Step:  6707, loss: 3.284752, norm: 0.2801, time(ms): 794.08, token/sec:660245.41, hellaswag_acc: 0.2836
Step:  6708, loss: 3.253987, norm: 0.2774, time(ms): 790.59, token/sec:663159.58, hellaswag_acc: 0.2836
Step:  6709, loss: 3.141555, norm: 0.2746, time(ms): 791.54, token/sec:662363.39, hellaswag_acc: 0.2836
Step:  6710, loss: 3.264423, norm: 0.2847, time(ms): 791.37, token/sec:662506.66, hellaswag_acc: 0.2836
Step:  6711, loss: 3.275351, norm: 0.2984, time(ms): 800.32, token/sec:655094.91, hellaswag_acc: 0.2836
Step:  6712, loss: 3.216514, norm: 0.2675, time(ms): 792.65, token/sec:661440.15, hellaswag_acc: 0.2836
Step:  6713, loss: 3.226857, norm: 0.2871, time(ms): 801.68, token/sec:653983.25, hellaswag_acc: 0.2836
Step:  6714, loss: 3.251396, norm: 0.2745, time(ms): 804.71, token/sec:651521.91, hellaswag_acc: 0.2836
Step:  6715, loss: 3.215149, norm: 0.2535, time(ms): 798.03, token/sec:656975.54, hellaswag_acc: 0.2836
Step:  6716, loss: 3.240820, norm: 0.2763, time(ms): 794.12, token/sec:660214.68, hellaswag_acc: 0.2836
Step:  6717, loss: 3.295509, norm: 0.2785, time(ms): 807.54, token/sec:649237.31, hellaswag_acc: 0.2836
Step:  6718, loss: 3.251232, norm: 0.2456, time(ms): 799.83, token/sec:655496.98, hellaswag_acc: 0.2836
Step:  6719, loss: 3.278210, norm: 0.2611, time(ms): 792.76, token/sec:661348.44, hellaswag_acc: 0.2836
Step:  6720, loss: 3.315786, norm: 0.2825, time(ms): 800.81, token/sec:654698.79, hellaswag_acc: 0.2836
Step:  6721, loss: 3.262995, norm: 0.2883, time(ms): 805.62, token/sec:650785.94, hellaswag_acc: 0.2836
Step:  6722, loss: 3.267612, norm: 0.2740, time(ms): 797.15, token/sec:657706.10, hellaswag_acc: 0.2836
Step:  6723, loss: 3.242525, norm: 0.2877, time(ms): 799.12, token/sec:656080.95, hellaswag_acc: 0.2836
Step:  6724, loss: 3.281253, norm: 0.3108, time(ms): 800.86, token/sec:654652.80, hellaswag_acc: 0.2836
Step:  6725, loss: 3.253719, norm: 0.2636, time(ms): 802.13, token/sec:653623.44, hellaswag_acc: 0.2836
Step:  6726, loss: 3.524877, norm: 0.3715, time(ms): 795.42, token/sec:659136.36, hellaswag_acc: 0.2836
Step:  6727, loss: 3.355947, norm: 0.3758, time(ms): 799.02, token/sec:656167.09, hellaswag_acc: 0.2836
Step:  6728, loss: 3.292723, norm: 0.3069, time(ms): 802.45, token/sec:653356.61, hellaswag_acc: 0.2836
Step:  6729, loss: 3.278052, norm: 0.3005, time(ms): 803.06, token/sec:652866.44, hellaswag_acc: 0.2836
Step:  6730, loss: 3.307930, norm: 0.2937, time(ms): 795.80, token/sec:658814.68, hellaswag_acc: 0.2836
Step:  6731, loss: 3.336916, norm: 0.3059, time(ms): 801.27, token/sec:654319.31, hellaswag_acc: 0.2836
Step:  6732, loss: 3.352580, norm: 0.3083, time(ms): 801.06, token/sec:654495.17, hellaswag_acc: 0.2836
Step:  6733, loss: 3.295483, norm: 0.2631, time(ms): 800.29, token/sec:655122.23, hellaswag_acc: 0.2836
Step:  6734, loss: 3.285146, norm: 0.2877, time(ms): 796.48, token/sec:658252.83, hellaswag_acc: 0.2836
Step:  6735, loss: 3.292166, norm: 0.2657, time(ms): 801.72, token/sec:653954.27, hellaswag_acc: 0.2836
Step:  6736, loss: 3.301191, norm: 0.2783, time(ms): 800.96, token/sec:654571.54, hellaswag_acc: 0.2836
Step:  6737, loss: 3.273067, norm: 0.2804, time(ms): 801.11, token/sec:654449.78, hellaswag_acc: 0.2836
Step:  6738, loss: 3.310804, norm: 0.2438, time(ms): 796.56, token/sec:658190.77, hellaswag_acc: 0.2836
Step:  6739, loss: 3.327832, norm: 0.2694, time(ms): 800.66, token/sec:654819.47, hellaswag_acc: 0.2836
Step:  6740, loss: 3.351228, norm: 0.2701, time(ms): 801.03, token/sec:654519.71, hellaswag_acc: 0.2836
Step:  6741, loss: 3.288229, norm: 0.2636, time(ms): 800.87, token/sec:654647.34, hellaswag_acc: 0.2836
Step:  6742, loss: 3.257590, norm: 0.2644, time(ms): 794.64, token/sec:659778.50, hellaswag_acc: 0.2836
Step:  6743, loss: 3.288632, norm: 0.2717, time(ms): 802.66, token/sec:653184.28, hellaswag_acc: 0.2836
Step:  6744, loss: 3.255576, norm: 0.2535, time(ms): 802.21, token/sec:653552.15, hellaswag_acc: 0.2836
Step:  6745, loss: 3.301290, norm: 0.2679, time(ms): 798.78, token/sec:656363.92, hellaswag_acc: 0.2836
Step:  6746, loss: 3.224164, norm: 0.3115, time(ms): 791.61, token/sec:662302.74, hellaswag_acc: 0.2836
Step:  6747, loss: 3.218115, norm: 0.2968, time(ms): 806.17, token/sec:650342.31, hellaswag_acc: 0.2836
Step:  6748, loss: 3.198975, norm: 0.2729, time(ms): 803.53, token/sec:652484.62, hellaswag_acc: 0.2836
Step:  6749, loss: 3.277266, norm: 0.2321, time(ms): 793.10, token/sec:661065.13, hellaswag_acc: 0.2836
rank 0 sample 0: Hello, I'm a language model, and I know that it's easy to describe when you're not native to that language and/or the target language but
rank 0 sample 1: Hello, I'm a language model, so here's a good example to visualize how the verb -
'You can use 'in the name of the person
rank 0 sample 2: Hello, I'm a language model, so I had no idea to give the same explanation to the first time.
What is the difference between a grammarian
rank 0 sample 3: Hello, I'm a language model, but like all languages, it is used in my class.
A native English interpreter and an interpreter have a variety of
rank 1 sample 0: Hello, I'm a language model, like how I learn my own language very easily? How long must it take to learn English? Can you learn English?
rank 1 sample 1: Hello, I'm a language model, not an interpreter.
I think we can use these functions to add a string library object. Because the function is called
rank 1 sample 2: Hello, I'm a language model, but only if you're a language model.
Here, here is an example of a sentence where a word "l
rank 1 sample 3: Hello, I'm a language model, and I'm trying to talk about that subject. My best friend is another who is able to write a language in English
Step:  6750, loss: 3.248131, norm: 0.2640, time(ms): 3773.39, token/sec:138943.47, val_loss: 3.2759, hellaswag_acc: 0.2836
Step:  6751, loss: 3.233928, norm: 0.2504, time(ms): 788.59, token/sec:664846.37, hellaswag_acc: 0.2836
Step:  6752, loss: 3.243590, norm: 0.2292, time(ms): 792.84, token/sec:661280.83, hellaswag_acc: 0.2836
Step:  6753, loss: 3.265221, norm: 0.2635, time(ms): 793.53, token/sec:660703.45, hellaswag_acc: 0.2836
Step:  6754, loss: 3.348803, norm: 0.2461, time(ms): 797.51, token/sec:657404.09, hellaswag_acc: 0.2836
Step:  6755, loss: 3.373207, norm: 0.2706, time(ms): 788.75, token/sec:664709.11, hellaswag_acc: 0.2836
Step:  6756, loss: 3.304477, norm: 0.2589, time(ms): 788.34, token/sec:665052.67, hellaswag_acc: 0.2836
Step:  6757, loss: 3.297839, norm: 0.2495, time(ms): 791.72, token/sec:662217.78, hellaswag_acc: 0.2836
Step:  6758, loss: 3.252607, norm: 0.2686, time(ms): 789.74, token/sec:663875.72, hellaswag_acc: 0.2836
Step:  6759, loss: 3.284690, norm: 0.2662, time(ms): 792.72, token/sec:661380.87, hellaswag_acc: 0.2836
Step:  6760, loss: 3.281247, norm: 0.2569, time(ms): 799.91, token/sec:655434.85, hellaswag_acc: 0.2836
Step:  6761, loss: 3.282581, norm: 0.2837, time(ms): 805.36, token/sec:650994.39, hellaswag_acc: 0.2836
Step:  6762, loss: 3.297626, norm: 0.2965, time(ms): 799.40, token/sec:655853.97, hellaswag_acc: 0.2836
Step:  6763, loss: 3.344493, norm: 0.3082, time(ms): 796.95, token/sec:657870.99, hellaswag_acc: 0.2836
Step:  6764, loss: 3.297328, norm: 0.2947, time(ms): 803.13, token/sec:652807.33, hellaswag_acc: 0.2836
Step:  6765, loss: 3.269740, norm: 0.2907, time(ms): 800.51, token/sec:654941.17, hellaswag_acc: 0.2836
Step:  6766, loss: 3.256841, norm: 0.3008, time(ms): 799.62, token/sec:655672.30, hellaswag_acc: 0.2836
Step:  6767, loss: 3.348082, norm: 0.2547, time(ms): 799.58, token/sec:655706.12, hellaswag_acc: 0.2836
Step:  6768, loss: 3.318421, norm: 0.2955, time(ms): 802.05, token/sec:653684.65, hellaswag_acc: 0.2836
Step:  6769, loss: 3.341906, norm: 0.2897, time(ms): 797.39, token/sec:657501.78, hellaswag_acc: 0.2836
Step:  6770, loss: 3.277397, norm: 0.2944, time(ms): 800.50, token/sec:654949.75, hellaswag_acc: 0.2836
Step:  6771, loss: 3.282896, norm: 0.2794, time(ms): 799.90, token/sec:655440.13, hellaswag_acc: 0.2836
Step:  6772, loss: 3.377950, norm: 0.2954, time(ms): 796.46, token/sec:658268.99, hellaswag_acc: 0.2836
Step:  6773, loss: 3.253741, norm: 0.3142, time(ms): 799.83, token/sec:655497.57, hellaswag_acc: 0.2836
Step:  6774, loss: 3.288156, norm: 0.2771, time(ms): 801.16, token/sec:654414.14, hellaswag_acc: 0.2836
Step:  6775, loss: 3.270631, norm: 0.2747, time(ms): 801.87, token/sec:653828.47, hellaswag_acc: 0.2836
Step:  6776, loss: 3.252012, norm: 0.2719, time(ms): 800.51, token/sec:654945.46, hellaswag_acc: 0.2836
Step:  6777, loss: 3.265592, norm: 0.2895, time(ms): 793.67, token/sec:660587.94, hellaswag_acc: 0.2836
Step:  6778, loss: 3.246715, norm: 0.2615, time(ms): 802.83, token/sec:653050.05, hellaswag_acc: 0.2836
Step:  6779, loss: 3.242415, norm: 0.2800, time(ms): 804.46, token/sec:651724.65, hellaswag_acc: 0.2836
Step:  6780, loss: 3.242264, norm: 0.2584, time(ms): 794.56, token/sec:659845.81, hellaswag_acc: 0.2836
Step:  6781, loss: 3.222879, norm: 0.2726, time(ms): 793.50, token/sec:660726.08, hellaswag_acc: 0.2836
Step:  6782, loss: 3.245695, norm: 0.3326, time(ms): 792.88, token/sec:661248.81, hellaswag_acc: 0.2836
Step:  6783, loss: 3.222671, norm: 0.3243, time(ms): 787.39, token/sec:665859.38, hellaswag_acc: 0.2836
Step:  6784, loss: 3.193034, norm: 0.3244, time(ms): 790.53, token/sec:663212.39, hellaswag_acc: 0.2836
Step:  6785, loss: 3.237158, norm: 0.2998, time(ms): 791.94, token/sec:662027.18, hellaswag_acc: 0.2836
Step:  6786, loss: 3.236686, norm: 0.2695, time(ms): 799.15, token/sec:656057.46, hellaswag_acc: 0.2836
Step:  6787, loss: 3.238457, norm: 0.2572, time(ms): 803.62, token/sec:652405.06, hellaswag_acc: 0.2836
Step:  6788, loss: 3.231068, norm: 0.2898, time(ms): 803.87, token/sec:652202.09, hellaswag_acc: 0.2836
Step:  6789, loss: 3.266958, norm: 0.2814, time(ms): 795.50, token/sec:659070.97, hellaswag_acc: 0.2836
Step:  6790, loss: 3.278785, norm: 0.2815, time(ms): 796.91, token/sec:657901.89, hellaswag_acc: 0.2836
Step:  6791, loss: 3.260651, norm: 0.2835, time(ms): 805.54, token/sec:650850.46, hellaswag_acc: 0.2836
Step:  6792, loss: 3.275864, norm: 0.2974, time(ms): 798.75, token/sec:656386.25, hellaswag_acc: 0.2836
Step:  6793, loss: 3.267175, norm: 0.3111, time(ms): 788.87, token/sec:664602.24, hellaswag_acc: 0.2836
Step:  6794, loss: 3.245097, norm: 0.3229, time(ms): 792.21, token/sec:661807.82, hellaswag_acc: 0.2836
Step:  6795, loss: 3.334510, norm: 0.2789, time(ms): 800.57, token/sec:654891.23, hellaswag_acc: 0.2836
Step:  6796, loss: 3.242244, norm: 0.3291, time(ms): 797.55, token/sec:657370.68, hellaswag_acc: 0.2836
Step:  6797, loss: 3.273952, norm: 0.2554, time(ms): 793.15, token/sec:661020.03, hellaswag_acc: 0.2836
Step:  6798, loss: 3.250573, norm: 0.2742, time(ms): 791.15, token/sec:662695.14, hellaswag_acc: 0.2836
Step:  6799, loss: 3.311304, norm: 0.2967, time(ms): 784.46, token/sec:668346.76, hellaswag_acc: 0.2836
Step:  6800, loss: 3.299564, norm: 0.3111, time(ms): 790.35, token/sec:663358.63, hellaswag_acc: 0.2836
Step:  6801, loss: 3.302937, norm: 0.2978, time(ms): 800.63, token/sec:654843.06, hellaswag_acc: 0.2836
Step:  6802, loss: 3.347126, norm: 0.2628, time(ms): 801.53, token/sec:654106.58, hellaswag_acc: 0.2836
Step:  6803, loss: 3.265179, norm: 0.3238, time(ms): 800.52, token/sec:654930.44, hellaswag_acc: 0.2836
Step:  6804, loss: 3.263851, norm: 0.3088, time(ms): 793.42, token/sec:660791.00, hellaswag_acc: 0.2836
Step:  6805, loss: 3.321081, norm: 0.3053, time(ms): 802.49, token/sec:653326.72, hellaswag_acc: 0.2836
Step:  6806, loss: 3.364501, norm: 0.2795, time(ms): 803.30, token/sec:652664.34, hellaswag_acc: 0.2836
Step:  6807, loss: 3.268882, norm: 0.2994, time(ms): 795.97, token/sec:658680.69, hellaswag_acc: 0.2836
Step:  6808, loss: 3.293358, norm: 0.2737, time(ms): 794.97, token/sec:659508.60, hellaswag_acc: 0.2836
Step:  6809, loss: 3.333431, norm: 0.4232, time(ms): 807.62, token/sec:649180.58, hellaswag_acc: 0.2836
Step:  6810, loss: 3.331650, norm: 0.3526, time(ms): 791.39, token/sec:662492.69, hellaswag_acc: 0.2836
Step:  6811, loss: 3.255873, norm: 0.3106, time(ms): 792.99, token/sec:661152.59, hellaswag_acc: 0.2836
Step:  6812, loss: 3.239351, norm: 0.2933, time(ms): 788.73, token/sec:664725.39, hellaswag_acc: 0.2836
Step:  6813, loss: 3.251638, norm: 0.2910, time(ms): 792.44, token/sec:661615.67, hellaswag_acc: 0.2836
Step:  6814, loss: 3.186882, norm: 0.2770, time(ms): 793.57, token/sec:660668.91, hellaswag_acc: 0.2836
Step:  6815, loss: 3.288576, norm: 0.2977, time(ms): 790.55, token/sec:663194.18, hellaswag_acc: 0.2836
Step:  6816, loss: 3.256928, norm: 0.2662, time(ms): 789.77, token/sec:663845.46, hellaswag_acc: 0.2836
Step:  6817, loss: 3.244616, norm: 0.2727, time(ms): 797.98, token/sec:657021.66, hellaswag_acc: 0.2836
Step:  6818, loss: 3.241998, norm: 0.2919, time(ms): 797.24, token/sec:657632.74, hellaswag_acc: 0.2836
Step:  6819, loss: 3.154865, norm: 0.2893, time(ms): 798.54, token/sec:656561.26, hellaswag_acc: 0.2836
Step:  6820, loss: 3.245992, norm: 0.2982, time(ms): 802.98, token/sec:652926.34, hellaswag_acc: 0.2836
Step:  6821, loss: 3.255477, norm: 0.2738, time(ms): 799.79, token/sec:655528.25, hellaswag_acc: 0.2836
Step:  6822, loss: 3.243286, norm: 0.2863, time(ms): 792.89, token/sec:661240.66, hellaswag_acc: 0.2836
Step:  6823, loss: 3.248559, norm: 0.3127, time(ms): 788.91, token/sec:664572.11, hellaswag_acc: 0.2836
Step:  6824, loss: 3.286567, norm: 0.2681, time(ms): 793.51, token/sec:660718.34, hellaswag_acc: 0.2836
Step:  6825, loss: 3.207682, norm: 0.2916, time(ms): 793.31, token/sec:660882.95, hellaswag_acc: 0.2836
Step:  6826, loss: 3.286533, norm: 0.2760, time(ms): 790.98, token/sec:662833.36, hellaswag_acc: 0.2836
Step:  6827, loss: 3.255686, norm: 0.2490, time(ms): 801.26, token/sec:654331.38, hellaswag_acc: 0.2836
Step:  6828, loss: 3.236662, norm: 0.2734, time(ms): 794.89, token/sec:659571.11, hellaswag_acc: 0.2836
Step:  6829, loss: 3.260648, norm: 0.2711, time(ms): 804.92, token/sec:651352.28, hellaswag_acc: 0.2836
Step:  6830, loss: 3.245162, norm: 0.2541, time(ms): 801.75, token/sec:653931.52, hellaswag_acc: 0.2836
Step:  6831, loss: 3.315651, norm: 0.2592, time(ms): 794.45, token/sec:659934.72, hellaswag_acc: 0.2836
Step:  6832, loss: 3.259022, norm: 0.2734, time(ms): 800.40, token/sec:655030.71, hellaswag_acc: 0.2836
Step:  6833, loss: 3.259431, norm: 0.2502, time(ms): 803.78, token/sec:652278.70, hellaswag_acc: 0.2836
Step:  6834, loss: 3.291950, norm: 0.2930, time(ms): 798.14, token/sec:656889.38, hellaswag_acc: 0.2836
Step:  6835, loss: 3.344989, norm: 0.2869, time(ms): 793.10, token/sec:661061.16, hellaswag_acc: 0.2836
Step:  6836, loss: 3.320504, norm: 0.2548, time(ms): 806.37, token/sec:650184.06, hellaswag_acc: 0.2836
Step:  6837, loss: 3.296255, norm: 0.2840, time(ms): 802.13, token/sec:653622.28, hellaswag_acc: 0.2836
Step:  6838, loss: 3.280268, norm: 0.2539, time(ms): 798.76, token/sec:656374.69, hellaswag_acc: 0.2836
Step:  6839, loss: 3.305393, norm: 0.2832, time(ms): 794.04, token/sec:660278.32, hellaswag_acc: 0.2836
Step:  6840, loss: 3.300534, norm: 0.2479, time(ms): 805.82, token/sec:650623.04, hellaswag_acc: 0.2836
Step:  6841, loss: 3.299153, norm: 0.2740, time(ms): 799.59, token/sec:655697.91, hellaswag_acc: 0.2836
Step:  6842, loss: 3.303642, norm: 0.2673, time(ms): 791.23, token/sec:662625.64, hellaswag_acc: 0.2836
Step:  6843, loss: 3.290358, norm: 0.2509, time(ms): 798.05, token/sec:656963.96, hellaswag_acc: 0.2836
Step:  6844, loss: 3.276248, norm: 0.2598, time(ms): 792.23, token/sec:661783.72, hellaswag_acc: 0.2836
Step:  6845, loss: 3.285149, norm: 0.2843, time(ms): 787.78, token/sec:665523.05, hellaswag_acc: 0.2836
Step:  6846, loss: 3.253750, norm: 0.2724, time(ms): 788.38, token/sec:665018.28, hellaswag_acc: 0.2836
Step:  6847, loss: 3.286459, norm: 0.2683, time(ms): 793.86, token/sec:660426.25, hellaswag_acc: 0.2836
Step:  6848, loss: 3.210308, norm: 0.2609, time(ms): 808.12, token/sec:648771.29, hellaswag_acc: 0.2836
Step:  6849, loss: 3.265845, norm: 0.2631, time(ms): 793.94, token/sec:660362.78, hellaswag_acc: 0.2836
Step:  6850, loss: 3.288964, norm: 0.2412, time(ms): 796.71, token/sec:658068.65, hellaswag_acc: 0.2836
Step:  6851, loss: 3.268907, norm: 0.2618, time(ms): 802.44, token/sec:653363.60, hellaswag_acc: 0.2836
Step:  6852, loss: 3.362164, norm: 0.3184, time(ms): 806.67, token/sec:649941.92, hellaswag_acc: 0.2836
Step:  6853, loss: 3.250885, norm: 0.3255, time(ms): 787.27, token/sec:665954.56, hellaswag_acc: 0.2836
Step:  6854, loss: 3.222572, norm: 0.2707, time(ms): 788.49, token/sec:664926.58, hellaswag_acc: 0.2836
Step:  6855, loss: 3.208712, norm: 0.2648, time(ms): 801.86, token/sec:653842.66, hellaswag_acc: 0.2836
Step:  6856, loss: 3.254092, norm: 0.3018, time(ms): 802.65, token/sec:653195.53, hellaswag_acc: 0.2836
Step:  6857, loss: 3.254550, norm: 0.3057, time(ms): 1291.68, token/sec:405896.32, hellaswag_acc: 0.2836
Step:  6858, loss: 3.318939, norm: 0.3605, time(ms): 771.65, token/sec:679433.30, hellaswag_acc: 0.2836
Step:  6859, loss: 3.328961, norm: 0.3138, time(ms): 792.98, token/sec:661165.11, hellaswag_acc: 0.2836
Step:  6860, loss: 3.299227, norm: 0.3442, time(ms): 800.24, token/sec:655161.47, hellaswag_acc: 0.2836
Step:  6861, loss: 3.274608, norm: 0.3299, time(ms): 804.21, token/sec:651927.33, hellaswag_acc: 0.2836
Step:  6862, loss: 3.278382, norm: 0.2991, time(ms): 787.45, token/sec:665806.56, hellaswag_acc: 0.2836
Step:  6863, loss: 3.338219, norm: 0.3668, time(ms): 797.97, token/sec:657026.77, hellaswag_acc: 0.2836
Step:  6864, loss: 3.250107, norm: 0.3006, time(ms): 792.44, token/sec:661610.70, hellaswag_acc: 0.2836
Step:  6865, loss: 3.293792, norm: 0.2944, time(ms): 792.43, token/sec:661622.04, hellaswag_acc: 0.2836
Step:  6866, loss: 3.203702, norm: 0.2666, time(ms): 789.37, token/sec:664189.53, hellaswag_acc: 0.2836
Step:  6867, loss: 3.263930, norm: 0.2717, time(ms): 787.30, token/sec:665929.96, hellaswag_acc: 0.2836
Step:  6868, loss: 3.180649, norm: 0.2556, time(ms): 801.68, token/sec:653990.25, hellaswag_acc: 0.2836
Step:  6869, loss: 3.220994, norm: 0.2754, time(ms): 804.13, token/sec:651991.50, hellaswag_acc: 0.2836
Step:  6870, loss: 3.261837, norm: 0.2523, time(ms): 794.84, token/sec:659616.81, hellaswag_acc: 0.2836
Step:  6871, loss: 3.231157, norm: 0.2696, time(ms): 796.02, token/sec:658635.51, hellaswag_acc: 0.2836
Step:  6872, loss: 3.262405, norm: 0.2610, time(ms): 791.11, token/sec:662727.09, hellaswag_acc: 0.2836
Step:  6873, loss: 3.257125, norm: 0.2613, time(ms): 799.40, token/sec:655852.60, hellaswag_acc: 0.2836
Step:  6874, loss: 3.236905, norm: 0.2517, time(ms): 791.55, token/sec:662354.21, hellaswag_acc: 0.2836
Step:  6875, loss: 3.294614, norm: 0.2977, time(ms): 789.27, token/sec:664268.78, hellaswag_acc: 0.2836
Step:  6876, loss: 3.247856, norm: 0.2883, time(ms): 790.65, token/sec:663112.39, hellaswag_acc: 0.2836
Step:  6877, loss: 3.293699, norm: 0.2924, time(ms): 790.45, token/sec:663277.80, hellaswag_acc: 0.2836
Step:  6878, loss: 3.360370, norm: 0.2798, time(ms): 788.33, token/sec:665063.33, hellaswag_acc: 0.2836
Step:  6879, loss: 3.285536, norm: 0.2799, time(ms): 794.20, token/sec:660149.47, hellaswag_acc: 0.2836
Step:  6880, loss: 3.273284, norm: 0.2797, time(ms): 788.14, token/sec:665219.65, hellaswag_acc: 0.2836
Step:  6881, loss: 3.355726, norm: 0.2910, time(ms): 792.79, token/sec:661321.59, hellaswag_acc: 0.2836
Step:  6882, loss: 3.249420, norm: 0.2916, time(ms): 791.35, token/sec:662520.44, hellaswag_acc: 0.2836
Step:  6883, loss: 3.294542, norm: 0.3033, time(ms): 797.08, token/sec:657764.14, hellaswag_acc: 0.2836
Step:  6884, loss: 3.297203, norm: 0.2889, time(ms): 804.02, token/sec:652086.63, hellaswag_acc: 0.2836
Step:  6885, loss: 3.311399, norm: 0.2756, time(ms): 801.99, token/sec:653737.31, hellaswag_acc: 0.2836
Step:  6886, loss: 3.290060, norm: 0.2757, time(ms): 786.72, token/sec:666425.41, hellaswag_acc: 0.2836
Step:  6887, loss: 3.300621, norm: 0.2588, time(ms): 792.72, token/sec:661374.70, hellaswag_acc: 0.2836
Step:  6888, loss: 3.263655, norm: 0.2566, time(ms): 794.40, token/sec:659982.06, hellaswag_acc: 0.2836
Step:  6889, loss: 3.320602, norm: 0.2742, time(ms): 803.04, token/sec:652875.55, hellaswag_acc: 0.2836
Step:  6890, loss: 3.323587, norm: 0.2818, time(ms): 791.67, token/sec:662257.66, hellaswag_acc: 0.2836
Step:  6891, loss: 3.331645, norm: 0.3486, time(ms): 789.09, token/sec:664419.30, hellaswag_acc: 0.2836
Step:  6892, loss: 3.288430, norm: 0.3090, time(ms): 789.84, token/sec:663790.75, hellaswag_acc: 0.2836
Step:  6893, loss: 3.287940, norm: 0.3019, time(ms): 792.84, token/sec:661277.64, hellaswag_acc: 0.2836
Step:  6894, loss: 3.300210, norm: 0.2850, time(ms): 792.97, token/sec:661167.30, hellaswag_acc: 0.2836
Step:  6895, loss: 3.330511, norm: 0.2982, time(ms): 797.98, token/sec:657016.56, hellaswag_acc: 0.2836
Step:  6896, loss: 3.319725, norm: 0.3004, time(ms): 806.71, token/sec:649912.73, hellaswag_acc: 0.2836
Step:  6897, loss: 3.286353, norm: 0.2792, time(ms): 800.31, token/sec:655107.21, hellaswag_acc: 0.2836
Step:  6898, loss: 3.320942, norm: 0.2827, time(ms): 789.91, token/sec:663731.05, hellaswag_acc: 0.2836
Step:  6899, loss: 3.336738, norm: 0.2850, time(ms): 800.37, token/sec:655059.98, hellaswag_acc: 0.2836
Step:  6900, loss: 3.248863, norm: 0.3118, time(ms): 796.69, token/sec:658085.39, hellaswag_acc: 0.2836
Step:  6901, loss: 3.285116, norm: 0.2501, time(ms): 792.32, token/sec:661710.44, hellaswag_acc: 0.2836
Step:  6902, loss: 3.251592, norm: 0.2953, time(ms): 785.70, token/sec:667290.13, hellaswag_acc: 0.2836
Step:  6903, loss: 3.241521, norm: 0.2816, time(ms): 790.45, token/sec:663276.60, hellaswag_acc: 0.2836
Step:  6904, loss: 3.223792, norm: 0.2719, time(ms): 796.79, token/sec:658004.06, hellaswag_acc: 0.2836
Step:  6905, loss: 3.230769, norm: 0.2894, time(ms): 804.21, token/sec:651927.53, hellaswag_acc: 0.2836
Step:  6906, loss: 3.233199, norm: 0.2628, time(ms): 798.82, token/sec:656324.74, hellaswag_acc: 0.2836
Step:  6907, loss: 3.314570, norm: 0.2805, time(ms): 793.82, token/sec:660464.33, hellaswag_acc: 0.2836
Step:  6908, loss: 3.302043, norm: 0.3092, time(ms): 802.26, token/sec:653516.22, hellaswag_acc: 0.2836
Step:  6909, loss: 3.235099, norm: 0.2818, time(ms): 805.75, token/sec:650681.95, hellaswag_acc: 0.2836
Step:  6910, loss: 3.300299, norm: 0.3314, time(ms): 791.20, token/sec:662651.20, hellaswag_acc: 0.2836
Step:  6911, loss: 3.257648, norm: 0.3437, time(ms): 793.10, token/sec:661064.14, hellaswag_acc: 0.2836
Step:  6912, loss: 3.329959, norm: 0.2675, time(ms): 791.83, token/sec:662125.66, hellaswag_acc: 0.2836
Step:  6913, loss: 3.271619, norm: 0.3113, time(ms): 792.55, token/sec:661524.12, hellaswag_acc: 0.2836
Step:  6914, loss: 3.316296, norm: 0.2900, time(ms): 789.52, token/sec:664058.15, hellaswag_acc: 0.2836
Step:  6915, loss: 3.276511, norm: 0.2989, time(ms): 786.01, token/sec:667023.96, hellaswag_acc: 0.2836
Step:  6916, loss: 3.378764, norm: 0.3106, time(ms): 785.26, token/sec:667665.35, hellaswag_acc: 0.2836
Step:  6917, loss: 3.325154, norm: 0.3382, time(ms): 803.42, token/sec:652567.69, hellaswag_acc: 0.2836
Step:  6918, loss: 3.245358, norm: 0.3537, time(ms): 806.14, token/sec:650365.00, hellaswag_acc: 0.2836
Step:  6919, loss: 3.294425, norm: 0.3118, time(ms): 800.43, token/sec:655004.18, hellaswag_acc: 0.2836
Step:  6920, loss: 3.236798, norm: 0.2781, time(ms): 789.57, token/sec:664019.85, hellaswag_acc: 0.2836
Step:  6921, loss: 3.322359, norm: 0.2976, time(ms): 803.60, token/sec:652425.00, hellaswag_acc: 0.2836
Step:  6922, loss: 3.361262, norm: 0.2738, time(ms): 805.37, token/sec:650988.80, hellaswag_acc: 0.2836
Step:  6923, loss: 3.256079, norm: 0.3385, time(ms): 797.02, token/sec:657808.21, hellaswag_acc: 0.2836
Step:  6924, loss: 3.270516, norm: 0.2497, time(ms): 795.23, token/sec:659287.54, hellaswag_acc: 0.2836
Step:  6925, loss: 3.234725, norm: 0.2870, time(ms): 806.62, token/sec:649984.19, hellaswag_acc: 0.2836
Step:  6926, loss: 3.283774, norm: 0.2431, time(ms): 801.35, token/sec:654252.93, hellaswag_acc: 0.2836
Step:  6927, loss: 3.202731, norm: 0.2547, time(ms): 793.87, token/sec:660416.33, hellaswag_acc: 0.2836
Step:  6928, loss: 3.277840, norm: 0.2478, time(ms): 796.22, token/sec:658474.58, hellaswag_acc: 0.2836
Step:  6929, loss: 3.322990, norm: 0.2740, time(ms): 807.15, token/sec:649554.89, hellaswag_acc: 0.2836
Step:  6930, loss: 3.277787, norm: 0.2752, time(ms): 802.23, token/sec:653535.64, hellaswag_acc: 0.2836
Step:  6931, loss: 3.202839, norm: 0.2674, time(ms): 784.12, token/sec:668636.14, hellaswag_acc: 0.2836
Step:  6932, loss: 3.251920, norm: 0.2588, time(ms): 789.18, token/sec:664343.03, hellaswag_acc: 0.2836
Step:  6933, loss: 3.253174, norm: 0.2474, time(ms): 795.64, token/sec:658951.69, hellaswag_acc: 0.2836
Step:  6934, loss: 3.245368, norm: 0.2424, time(ms): 791.14, token/sec:662703.12, hellaswag_acc: 0.2836
Step:  6935, loss: 3.256532, norm: 0.2489, time(ms): 786.71, token/sec:666434.90, hellaswag_acc: 0.2836
Step:  6936, loss: 3.269335, norm: 0.2599, time(ms): 790.41, token/sec:663312.61, hellaswag_acc: 0.2836
Step:  6937, loss: 3.231931, norm: 0.2709, time(ms): 794.43, token/sec:659953.14, hellaswag_acc: 0.2836
Step:  6938, loss: 3.230889, norm: 0.2541, time(ms): 796.30, token/sec:658406.36, hellaswag_acc: 0.2836
Step:  6939, loss: 3.246936, norm: 0.2616, time(ms): 789.82, token/sec:663805.58, hellaswag_acc: 0.2836
Step:  6940, loss: 3.197655, norm: 0.2714, time(ms): 785.42, token/sec:667526.92, hellaswag_acc: 0.2836
Step:  6941, loss: 3.210045, norm: 0.2482, time(ms): 789.45, token/sec:664118.72, hellaswag_acc: 0.2836
Step:  6942, loss: 3.224257, norm: 0.2822, time(ms): 801.88, token/sec:653820.31, hellaswag_acc: 0.2836
Step:  6943, loss: 3.221310, norm: 0.2918, time(ms): 803.15, token/sec:652786.98, hellaswag_acc: 0.2836
Step:  6944, loss: 3.195480, norm: 0.2530, time(ms): 791.10, token/sec:662735.88, hellaswag_acc: 0.2836
Step:  6945, loss: 3.241319, norm: 0.2632, time(ms): 798.03, token/sec:656975.93, hellaswag_acc: 0.2836
Step:  6946, loss: 3.223744, norm: 0.2666, time(ms): 791.15, token/sec:662694.54, hellaswag_acc: 0.2836
Step:  6947, loss: 3.260399, norm: 0.2559, time(ms): 786.92, token/sec:666249.95, hellaswag_acc: 0.2836
Step:  6948, loss: 3.274954, norm: 0.2729, time(ms): 791.84, token/sec:662112.90, hellaswag_acc: 0.2836
Step:  6949, loss: 3.310528, norm: 0.2468, time(ms): 791.00, token/sec:662818.98, hellaswag_acc: 0.2836
Step:  6950, loss: 3.345125, norm: 0.2888, time(ms): 799.14, token/sec:656067.64, hellaswag_acc: 0.2836
Step:  6951, loss: 3.312397, norm: 0.3190, time(ms): 792.29, token/sec:661738.51, hellaswag_acc: 0.2836
Step:  6952, loss: 3.286528, norm: 0.3238, time(ms): 787.62, token/sec:665665.28, hellaswag_acc: 0.2836
Step:  6953, loss: 3.327567, norm: 0.3266, time(ms): 791.79, token/sec:662158.35, hellaswag_acc: 0.2836
Step:  6954, loss: 3.313332, norm: 0.2909, time(ms): 787.15, token/sec:666059.45, hellaswag_acc: 0.2836
Step:  6955, loss: 3.298939, norm: 0.2848, time(ms): 789.98, token/sec:663670.15, hellaswag_acc: 0.2836
Step:  6956, loss: 3.291880, norm: 0.2824, time(ms): 799.51, token/sec:655760.87, hellaswag_acc: 0.2836
Step:  6957, loss: 3.360258, norm: 0.2997, time(ms): 791.36, token/sec:662511.05, hellaswag_acc: 0.2836
Step:  6958, loss: 3.254018, norm: 0.3427, time(ms): 803.74, token/sec:652307.14, hellaswag_acc: 0.2836
Step:  6959, loss: 3.336465, norm: 0.2971, time(ms): 804.78, token/sec:651470.56, hellaswag_acc: 0.2836
Step:  6960, loss: 3.280260, norm: 0.3034, time(ms): 792.06, token/sec:661929.54, hellaswag_acc: 0.2836
Step:  6961, loss: 3.213391, norm: 0.3302, time(ms): 797.64, token/sec:657300.14, hellaswag_acc: 0.2836
Step:  6962, loss: 3.264542, norm: 0.3013, time(ms): 808.75, token/sec:648269.62, hellaswag_acc: 0.2836
Step:  6963, loss: 3.268218, norm: 0.2766, time(ms): 801.76, token/sec:653918.49, hellaswag_acc: 0.2836
Step:  6964, loss: 3.278239, norm: 0.3265, time(ms): 786.07, token/sec:666976.82, hellaswag_acc: 0.2836
Step:  6965, loss: 3.270980, norm: 0.2951, time(ms): 789.36, token/sec:664196.95, hellaswag_acc: 0.2836
Step:  6966, loss: 3.263883, norm: 0.2781, time(ms): 795.57, token/sec:659010.53, hellaswag_acc: 0.2836
Step:  6967, loss: 3.226030, norm: 0.2766, time(ms): 793.09, token/sec:661068.51, hellaswag_acc: 0.2836
Step:  6968, loss: 3.212595, norm: 0.2660, time(ms): 790.18, token/sec:663506.75, hellaswag_acc: 0.2836
Step:  6969, loss: 3.220984, norm: 0.2539, time(ms): 798.09, token/sec:656925.49, hellaswag_acc: 0.2836
Step:  6970, loss: 3.244431, norm: 0.2585, time(ms): 802.03, token/sec:653701.55, hellaswag_acc: 0.2836
Step:  6971, loss: 3.369967, norm: 0.2709, time(ms): 802.55, token/sec:653281.11, hellaswag_acc: 0.2836
Step:  6972, loss: 3.247094, norm: 0.2913, time(ms): 792.73, token/sec:661367.74, hellaswag_acc: 0.2836
Step:  6973, loss: 3.270705, norm: 0.2466, time(ms): 797.64, token/sec:657300.73, hellaswag_acc: 0.2836
Step:  6974, loss: 3.258991, norm: 0.2755, time(ms): 791.90, token/sec:662066.85, hellaswag_acc: 0.2836
Step:  6975, loss: 3.199829, norm: 0.2473, time(ms): 790.89, token/sec:662912.09, hellaswag_acc: 0.2836
Step:  6976, loss: 3.221351, norm: 0.2646, time(ms): 791.81, token/sec:662137.02, hellaswag_acc: 0.2836
Step:  6977, loss: 3.232473, norm: 0.2515, time(ms): 787.21, token/sec:666004.38, hellaswag_acc: 0.2836
Step:  6978, loss: 3.244849, norm: 0.2584, time(ms): 791.97, token/sec:662007.25, hellaswag_acc: 0.2836
Step:  6979, loss: 3.258321, norm: 0.2596, time(ms): 790.32, token/sec:663386.45, hellaswag_acc: 0.2836
Step:  6980, loss: 3.250375, norm: 0.2509, time(ms): 799.20, token/sec:656019.88, hellaswag_acc: 0.2836
Step:  6981, loss: 3.227676, norm: 0.2468, time(ms): 805.06, token/sec:651237.50, hellaswag_acc: 0.2836
Step:  6982, loss: 3.203466, norm: 0.2514, time(ms): 799.46, token/sec:655800.96, hellaswag_acc: 0.2836
Step:  6983, loss: 3.201967, norm: 0.2530, time(ms): 791.69, token/sec:662239.51, hellaswag_acc: 0.2836
Step:  6984, loss: 3.302055, norm: 0.2617, time(ms): 807.59, token/sec:649198.21, hellaswag_acc: 0.2836
Step:  6985, loss: 3.243901, norm: 0.2669, time(ms): 799.50, token/sec:655767.32, hellaswag_acc: 0.2836
Step:  6986, loss: 3.278849, norm: 0.2630, time(ms): 796.17, token/sec:658511.65, hellaswag_acc: 0.2836
Step:  6987, loss: 3.289156, norm: 0.2523, time(ms): 803.37, token/sec:652610.88, hellaswag_acc: 0.2836
Step:  6988, loss: 3.287893, norm: 0.2635, time(ms): 798.08, token/sec:656933.93, hellaswag_acc: 0.2836
Step:  6989, loss: 3.271946, norm: 0.2453, time(ms): 803.88, token/sec:652199.57, hellaswag_acc: 0.2836
Step:  6990, loss: 3.305092, norm: 0.2525, time(ms): 795.66, token/sec:658934.11, hellaswag_acc: 0.2836
Step:  6991, loss: 3.271412, norm: 0.3019, time(ms): 801.77, token/sec:653916.93, hellaswag_acc: 0.2836
Step:  6992, loss: 3.235261, norm: 0.2644, time(ms): 794.59, token/sec:659820.27, hellaswag_acc: 0.2836
Step:  6993, loss: 3.277378, norm: 0.2803, time(ms): 805.03, token/sec:651261.23, hellaswag_acc: 0.2836
Step:  6994, loss: 3.272985, norm: 0.3270, time(ms): 794.44, token/sec:659943.43, hellaswag_acc: 0.2836
Step:  6995, loss: 3.257521, norm: 0.3026, time(ms): 797.63, token/sec:657307.41, hellaswag_acc: 0.2836
Step:  6996, loss: 3.266885, norm: 0.2714, time(ms): 806.80, token/sec:649832.64, hellaswag_acc: 0.2836
Step:  6997, loss: 3.233610, norm: 0.3394, time(ms): 802.84, token/sec:653042.87, hellaswag_acc: 0.2836
Step:  6998, loss: 3.266544, norm: 0.3189, time(ms): 794.79, token/sec:659655.19, hellaswag_acc: 0.2836
Step:  6999, loss: 3.231598, norm: 0.3019, time(ms): 798.71, token/sec:656418.19, hellaswag_acc: 0.2836
rank 0 sample 0: Hello, I'm a language model, so I want to be able to be of great use of that I didn't know before I read that book. But
rank 0 sample 1: Hello, I'm a language model, and when I was working on this model, my translation took a long time to complete and I didn't get around to
rank 0 sample 2: Hello, I'm a language model, and I mean the person's language, and in all languages of this world, he's the language of the people,
rank 0 sample 3: Hello, I'm a language model, so now I'm going to talk about how Linux is used in Java. So we need to use "compute tree
rank 1 sample 0: Hello, I'm a language model, so there are a lot of things to be had to explain before I can give you some more detail.
The first
rank 1 sample 1: Hello, I'm a language model, not an expert - I'm a software engineer. I teach you an old English dialect while you teach your students. I
rank 1 sample 2: Hello, I'm a language model, I should have written it.
As I said, you cannot have an effective language model to understand what is written.
rank 1 sample 3: Hello, I'm a language model, so I'm really trying to write things very well. Sometimes people forget me since I used to write things in different languages
Step:  7000, loss: 3.586847, norm: 0.5046, time(ms): 364015.54, token/sec:1440.29, val_loss: 3.2687, hellaswag_acc: 0.2821
Step:  7001, loss: 3.255913, norm: 0.4997, time(ms): 794.11, token/sec:660222.41, hellaswag_acc: 0.2821
Step:  7002, loss: 3.246531, norm: 0.3931, time(ms): 799.19, token/sec:656021.64, hellaswag_acc: 0.2821
Step:  7003, loss: 3.347130, norm: 0.3891, time(ms): 791.42, token/sec:662462.36, hellaswag_acc: 0.2821
Step:  7004, loss: 3.261520, norm: 0.4302, time(ms): 805.24, token/sec:651096.36, hellaswag_acc: 0.2821
Step:  7005, loss: 3.250890, norm: 0.3037, time(ms): 803.06, token/sec:652865.08, hellaswag_acc: 0.2821
Step:  7006, loss: 3.286394, norm: 0.3205, time(ms): 796.58, token/sec:658171.46, hellaswag_acc: 0.2821
Step:  7007, loss: 3.292192, norm: 0.3005, time(ms): 793.83, token/sec:660454.41, hellaswag_acc: 0.2821
Step:  7008, loss: 3.265686, norm: 0.2982, time(ms): 805.44, token/sec:650936.78, hellaswag_acc: 0.2821
Step:  7009, loss: 3.271727, norm: 0.2964, time(ms): 803.78, token/sec:652278.12, hellaswag_acc: 0.2821
Step:  7010, loss: 3.265478, norm: 0.3039, time(ms): 790.52, token/sec:663216.39, hellaswag_acc: 0.2821
Step:  7011, loss: 3.262635, norm: 0.2840, time(ms): 803.21, token/sec:652742.02, hellaswag_acc: 0.2821
Step:  7012, loss: 3.267939, norm: 0.2927, time(ms): 802.97, token/sec:652939.52, hellaswag_acc: 0.2821
Step:  7013, loss: 3.215590, norm: 0.2687, time(ms): 801.51, token/sec:654125.26, hellaswag_acc: 0.2821
Step:  7014, loss: 3.251957, norm: 0.2789, time(ms): 798.00, token/sec:656999.09, hellaswag_acc: 0.2821
Step:  7015, loss: 3.281476, norm: 0.2700, time(ms): 800.20, token/sec:655193.28, hellaswag_acc: 0.2821
Step:  7016, loss: 3.241581, norm: 0.2770, time(ms): 800.26, token/sec:655149.95, hellaswag_acc: 0.2821
Step:  7017, loss: 3.224764, norm: 0.2644, time(ms): 801.67, token/sec:653997.84, hellaswag_acc: 0.2821
Step:  7018, loss: 3.217635, norm: 0.2658, time(ms): 798.99, token/sec:656185.10, hellaswag_acc: 0.2821
Step:  7019, loss: 3.214609, norm: 0.2930, time(ms): 798.14, token/sec:656885.85, hellaswag_acc: 0.2821
Step:  7020, loss: 3.333080, norm: 0.3067, time(ms): 800.91, token/sec:654611.87, hellaswag_acc: 0.2821
Step:  7021, loss: 3.280679, norm: 0.3117, time(ms): 799.54, token/sec:655735.25, hellaswag_acc: 0.2821
Step:  7022, loss: 3.232495, norm: 0.2956, time(ms): 801.34, token/sec:654262.08, hellaswag_acc: 0.2821
Step:  7023, loss: 3.306574, norm: 0.2830, time(ms): 799.39, token/sec:655863.75, hellaswag_acc: 0.2821
Step:  7024, loss: 3.262403, norm: 0.3123, time(ms): 796.86, token/sec:657945.39, hellaswag_acc: 0.2821
Step:  7025, loss: 3.229403, norm: 0.2765, time(ms): 803.06, token/sec:652865.47, hellaswag_acc: 0.2821
Step:  7026, loss: 3.242889, norm: 0.2593, time(ms): 794.55, token/sec:659854.32, hellaswag_acc: 0.2821
Step:  7027, loss: 3.270763, norm: 0.3077, time(ms): 803.58, token/sec:652442.62, hellaswag_acc: 0.2821
Step:  7028, loss: 3.243305, norm: 0.2742, time(ms): 800.78, token/sec:654719.84, hellaswag_acc: 0.2821
Step:  7029, loss: 3.211455, norm: 0.2925, time(ms): 800.89, token/sec:654629.80, hellaswag_acc: 0.2821
Step:  7030, loss: 3.240505, norm: 0.2637, time(ms): 797.95, token/sec:657041.29, hellaswag_acc: 0.2821
Step:  7031, loss: 3.316028, norm: 0.2629, time(ms): 796.94, token/sec:657879.26, hellaswag_acc: 0.2821
Step:  7032, loss: 3.192568, norm: 0.2548, time(ms): 803.69, token/sec:652352.61, hellaswag_acc: 0.2821
Step:  7033, loss: 3.242551, norm: 0.2813, time(ms): 800.74, token/sec:654750.84, hellaswag_acc: 0.2821
Step:  7034, loss: 3.222586, norm: 0.2575, time(ms): 796.72, token/sec:658057.82, hellaswag_acc: 0.2821
Step:  7035, loss: 3.295297, norm: 0.2707, time(ms): 798.36, token/sec:656705.18, hellaswag_acc: 0.2821
Step:  7036, loss: 3.301517, norm: 0.2570, time(ms): 803.49, token/sec:652516.57, hellaswag_acc: 0.2821
Step:  7037, loss: 3.290091, norm: 0.2365, time(ms): 799.67, token/sec:655630.27, hellaswag_acc: 0.2821
Step:  7038, loss: 3.278190, norm: 0.2582, time(ms): 795.74, token/sec:658872.12, hellaswag_acc: 0.2821
Step:  7039, loss: 3.291801, norm: 0.2400, time(ms): 797.57, token/sec:657360.66, hellaswag_acc: 0.2821
Step:  7040, loss: 3.257209, norm: 0.2534, time(ms): 806.38, token/sec:650171.75, hellaswag_acc: 0.2821
Step:  7041, loss: 3.281672, norm: 0.2425, time(ms): 801.19, token/sec:654386.88, hellaswag_acc: 0.2821
Step:  7042, loss: 3.210714, norm: 0.2563, time(ms): 787.70, token/sec:665594.36, hellaswag_acc: 0.2821
Step:  7043, loss: 3.196137, norm: 0.2747, time(ms): 792.52, token/sec:661547.60, hellaswag_acc: 0.2821
Step:  7044, loss: 3.211497, norm: 0.2448, time(ms): 793.95, token/sec:660352.67, hellaswag_acc: 0.2821
Step:  7045, loss: 3.202716, norm: 0.2560, time(ms): 795.27, token/sec:659258.29, hellaswag_acc: 0.2821
Step:  7046, loss: 3.190149, norm: 0.2439, time(ms): 792.64, token/sec:661446.91, hellaswag_acc: 0.2821
Step:  7047, loss: 3.247655, norm: 0.2298, time(ms): 793.27, token/sec:660921.68, hellaswag_acc: 0.2821
Step:  7048, loss: 3.234414, norm: 0.2538, time(ms): 1270.83, token/sec:412555.99, hellaswag_acc: 0.2821
Step:  7049, loss: 3.230372, norm: 0.2699, time(ms): 796.92, token/sec:657891.26, hellaswag_acc: 0.2821
Step:  7050, loss: 3.192829, norm: 0.2690, time(ms): 780.47, token/sec:671763.11, hellaswag_acc: 0.2821
Step:  7051, loss: 3.177013, norm: 0.2634, time(ms): 782.69, token/sec:669856.78, hellaswag_acc: 0.2821
Step:  7052, loss: 3.200022, norm: 0.2550, time(ms): 806.61, token/sec:649991.30, hellaswag_acc: 0.2821
Step:  7053, loss: 3.244980, norm: 0.3182, time(ms): 804.21, token/sec:651928.69, hellaswag_acc: 0.2821
Step:  7054, loss: 3.246970, norm: 0.3252, time(ms): 793.11, token/sec:661057.38, hellaswag_acc: 0.2821
Step:  7055, loss: 3.273660, norm: 0.2778, time(ms): 796.46, token/sec:658276.67, hellaswag_acc: 0.2821
Step:  7056, loss: 3.215567, norm: 0.2927, time(ms): 804.21, token/sec:651931.00, hellaswag_acc: 0.2821
Step:  7057, loss: 3.259206, norm: 0.2823, time(ms): 806.46, token/sec:650106.59, hellaswag_acc: 0.2821
Step:  7058, loss: 3.281560, norm: 0.2896, time(ms): 795.00, token/sec:659479.92, hellaswag_acc: 0.2821
Step:  7059, loss: 3.284284, norm: 0.2906, time(ms): 796.55, token/sec:658196.48, hellaswag_acc: 0.2821
Step:  7060, loss: 3.263848, norm: 0.2754, time(ms): 804.07, token/sec:652045.06, hellaswag_acc: 0.2821
Step:  7061, loss: 3.257634, norm: 0.3065, time(ms): 802.08, token/sec:653658.22, hellaswag_acc: 0.2821
Step:  7062, loss: 3.299204, norm: 0.2621, time(ms): 796.75, token/sec:658030.84, hellaswag_acc: 0.2821
Step:  7063, loss: 3.246186, norm: 0.2766, time(ms): 794.68, token/sec:659746.43, hellaswag_acc: 0.2821
Step:  7064, loss: 3.307635, norm: 0.2990, time(ms): 807.28, token/sec:649453.79, hellaswag_acc: 0.2821
Step:  7065, loss: 3.293847, norm: 0.3071, time(ms): 801.15, token/sec:654419.79, hellaswag_acc: 0.2821
Step:  7066, loss: 3.273472, norm: 0.2783, time(ms): 798.69, token/sec:656431.71, hellaswag_acc: 0.2821
Step:  7067, loss: 3.300513, norm: 0.2838, time(ms): 790.11, token/sec:663565.61, hellaswag_acc: 0.2821
Step:  7068, loss: 3.241874, norm: 0.2840, time(ms): 790.32, token/sec:663390.85, hellaswag_acc: 0.2821
Step:  7069, loss: 3.218244, norm: 0.2730, time(ms): 786.20, token/sec:666859.51, hellaswag_acc: 0.2821
Step:  7070, loss: 3.231322, norm: 0.2491, time(ms): 792.57, token/sec:661505.41, hellaswag_acc: 0.2821
Step:  7071, loss: 3.260176, norm: 0.2728, time(ms): 797.22, token/sec:657643.36, hellaswag_acc: 0.2821
Step:  7072, loss: 3.253738, norm: 0.2428, time(ms): 799.23, token/sec:655989.55, hellaswag_acc: 0.2821
Step:  7073, loss: 3.223608, norm: 0.2845, time(ms): 803.88, token/sec:652198.22, hellaswag_acc: 0.2821
Step:  7074, loss: 3.216102, norm: 0.2852, time(ms): 797.90, token/sec:657088.81, hellaswag_acc: 0.2821
Step:  7075, loss: 3.223023, norm: 0.2547, time(ms): 799.21, token/sec:656008.92, hellaswag_acc: 0.2821
Step:  7076, loss: 3.306942, norm: 0.2870, time(ms): 798.09, token/sec:656928.24, hellaswag_acc: 0.2821
Step:  7077, loss: 3.223473, norm: 0.2456, time(ms): 801.01, token/sec:654533.15, hellaswag_acc: 0.2821
Step:  7078, loss: 3.211740, norm: 0.2592, time(ms): 799.24, token/sec:655981.92, hellaswag_acc: 0.2821
Step:  7079, loss: 3.288737, norm: 0.2923, time(ms): 796.00, token/sec:658652.08, hellaswag_acc: 0.2821
Step:  7080, loss: 3.236564, norm: 0.2918, time(ms): 803.53, token/sec:652478.04, hellaswag_acc: 0.2821
Step:  7081, loss: 3.215389, norm: 0.2758, time(ms): 804.21, token/sec:651929.26, hellaswag_acc: 0.2821
Step:  7082, loss: 3.228245, norm: 0.2611, time(ms): 795.63, token/sec:658961.95, hellaswag_acc: 0.2821
Step:  7083, loss: 3.289569, norm: 0.2774, time(ms): 797.74, token/sec:657214.29, hellaswag_acc: 0.2821
Step:  7084, loss: 3.246277, norm: 0.2642, time(ms): 802.94, token/sec:652956.39, hellaswag_acc: 0.2821
Step:  7085, loss: 3.221912, norm: 0.2795, time(ms): 802.13, token/sec:653618.78, hellaswag_acc: 0.2821
Step:  7086, loss: 3.190182, norm: 0.2517, time(ms): 791.09, token/sec:662743.87, hellaswag_acc: 0.2821
Step:  7087, loss: 3.196826, norm: 0.2688, time(ms): 791.33, token/sec:662538.60, hellaswag_acc: 0.2821
Step:  7088, loss: 3.244781, norm: 0.2872, time(ms): 796.04, token/sec:658617.16, hellaswag_acc: 0.2821
Step:  7089, loss: 3.249754, norm: 0.2876, time(ms): 793.72, token/sec:660545.08, hellaswag_acc: 0.2821
Step:  7090, loss: 3.250293, norm: 0.3026, time(ms): 791.63, token/sec:662290.37, hellaswag_acc: 0.2821
Step:  7091, loss: 3.248863, norm: 0.2689, time(ms): 781.67, token/sec:670728.18, hellaswag_acc: 0.2821
Step:  7092, loss: 3.276837, norm: 0.2972, time(ms): 790.54, token/sec:663202.78, hellaswag_acc: 0.2821
Step:  7093, loss: 3.238713, norm: 0.3002, time(ms): 795.63, token/sec:658956.82, hellaswag_acc: 0.2821
Step:  7094, loss: 3.280206, norm: 0.2856, time(ms): 807.57, token/sec:649213.74, hellaswag_acc: 0.2821
Step:  7095, loss: 3.250960, norm: 0.2809, time(ms): 784.24, token/sec:668527.19, hellaswag_acc: 0.2821
Step:  7096, loss: 3.231928, norm: 0.2933, time(ms): 786.47, token/sec:666636.73, hellaswag_acc: 0.2821
Step:  7097, loss: 3.221717, norm: 0.3068, time(ms): 794.35, token/sec:660024.84, hellaswag_acc: 0.2821
Step:  7098, loss: 3.291362, norm: 0.2725, time(ms): 794.30, token/sec:660066.45, hellaswag_acc: 0.2821
Step:  7099, loss: 3.244189, norm: 0.2662, time(ms): 800.84, token/sec:654669.95, hellaswag_acc: 0.2821
Step:  7100, loss: 3.231575, norm: 0.2951, time(ms): 790.55, token/sec:663194.18, hellaswag_acc: 0.2821
Step:  7101, loss: 3.314209, norm: 0.3206, time(ms): 791.52, token/sec:662385.33, hellaswag_acc: 0.2821
Step:  7102, loss: 3.246653, norm: 0.3013, time(ms): 795.75, token/sec:658860.28, hellaswag_acc: 0.2821
Step:  7103, loss: 3.304420, norm: 0.3108, time(ms): 798.95, token/sec:656220.54, hellaswag_acc: 0.2821
Step:  7104, loss: 3.278827, norm: 0.2896, time(ms): 794.77, token/sec:659675.97, hellaswag_acc: 0.2821
Step:  7105, loss: 3.276667, norm: 0.2681, time(ms): 792.73, token/sec:661369.73, hellaswag_acc: 0.2821
Step:  7106, loss: 3.248448, norm: 0.2730, time(ms): 792.12, token/sec:661880.92, hellaswag_acc: 0.2821
Step:  7107, loss: 3.265291, norm: 0.2746, time(ms): 785.73, token/sec:667260.77, hellaswag_acc: 0.2821
Step:  7108, loss: 3.281508, norm: 0.2617, time(ms): 790.92, token/sec:662882.72, hellaswag_acc: 0.2821
Step:  7109, loss: 3.251050, norm: 0.2746, time(ms): 804.31, token/sec:651851.96, hellaswag_acc: 0.2821
Step:  7110, loss: 3.238693, norm: 0.2516, time(ms): 800.82, token/sec:654686.12, hellaswag_acc: 0.2821
Step:  7111, loss: 3.294888, norm: 0.2673, time(ms): 793.36, token/sec:660842.04, hellaswag_acc: 0.2821
Step:  7112, loss: 3.223902, norm: 0.2666, time(ms): 801.54, token/sec:654097.63, hellaswag_acc: 0.2821
Step:  7113, loss: 3.183130, norm: 0.2750, time(ms): 803.25, token/sec:652708.89, hellaswag_acc: 0.2821
Step:  7114, loss: 3.231060, norm: 0.2789, time(ms): 800.61, token/sec:654857.30, hellaswag_acc: 0.2821
Step:  7115, loss: 3.239698, norm: 0.2528, time(ms): 790.03, token/sec:663629.29, hellaswag_acc: 0.2821
Step:  7116, loss: 3.225416, norm: 0.2825, time(ms): 801.76, token/sec:653917.52, hellaswag_acc: 0.2821
Step:  7117, loss: 3.244184, norm: 0.2458, time(ms): 807.39, token/sec:649364.80, hellaswag_acc: 0.2821
Step:  7118, loss: 3.183000, norm: 0.2456, time(ms): 801.87, token/sec:653830.61, hellaswag_acc: 0.2821
Step:  7119, loss: 3.252247, norm: 0.2763, time(ms): 788.11, token/sec:665248.23, hellaswag_acc: 0.2821
Step:  7120, loss: 3.216795, norm: 0.2576, time(ms): 804.28, token/sec:651869.55, hellaswag_acc: 0.2821
Step:  7121, loss: 3.185115, norm: 0.2734, time(ms): 805.75, token/sec:650683.49, hellaswag_acc: 0.2821
Step:  7122, loss: 3.210502, norm: 0.2783, time(ms): 790.50, token/sec:663239.39, hellaswag_acc: 0.2821
Step:  7123, loss: 3.224585, norm: 0.2423, time(ms): 798.39, token/sec:656679.49, hellaswag_acc: 0.2821
Step:  7124, loss: 3.336967, norm: 0.3251, time(ms): 790.43, token/sec:663298.61, hellaswag_acc: 0.2821
Step:  7125, loss: 3.292137, norm: 0.4505, time(ms): 790.01, token/sec:663648.12, hellaswag_acc: 0.2821
Step:  7126, loss: 3.218623, norm: 0.3726, time(ms): 791.91, token/sec:662051.50, hellaswag_acc: 0.2821
Step:  7127, loss: 3.306399, norm: 0.3095, time(ms): 788.13, token/sec:665234.34, hellaswag_acc: 0.2821
Step:  7128, loss: 3.325711, norm: 0.3267, time(ms): 798.69, token/sec:656435.04, hellaswag_acc: 0.2821
Step:  7129, loss: 3.251797, norm: 0.2996, time(ms): 792.98, token/sec:661163.92, hellaswag_acc: 0.2821
Step:  7130, loss: 3.244504, norm: 0.3026, time(ms): 796.12, token/sec:658550.30, hellaswag_acc: 0.2821
Step:  7131, loss: 3.255482, norm: 0.2889, time(ms): 791.50, token/sec:662396.11, hellaswag_acc: 0.2821
Step:  7132, loss: 3.343383, norm: 0.2994, time(ms): 788.32, token/sec:665069.16, hellaswag_acc: 0.2821
Step:  7133, loss: 3.304068, norm: 0.2926, time(ms): 791.53, token/sec:662376.15, hellaswag_acc: 0.2821
Step:  7134, loss: 3.287921, norm: 0.2775, time(ms): 790.45, token/sec:663277.20, hellaswag_acc: 0.2821
Step:  7135, loss: 3.253581, norm: 0.2864, time(ms): 795.81, token/sec:658812.11, hellaswag_acc: 0.2821
Step:  7136, loss: 3.255386, norm: 0.2692, time(ms): 795.98, token/sec:658671.22, hellaswag_acc: 0.2821
Step:  7137, loss: 3.278513, norm: 0.2757, time(ms): 803.08, token/sec:652847.25, hellaswag_acc: 0.2821
Step:  7138, loss: 3.281221, norm: 0.2560, time(ms): 803.36, token/sec:652616.69, hellaswag_acc: 0.2821
Step:  7139, loss: 3.247595, norm: 0.2838, time(ms): 791.56, token/sec:662346.63, hellaswag_acc: 0.2821
Step:  7140, loss: 3.262288, norm: 0.2650, time(ms): 800.90, token/sec:654626.68, hellaswag_acc: 0.2821
Step:  7141, loss: 3.245835, norm: 0.2437, time(ms): 805.94, token/sec:650526.81, hellaswag_acc: 0.2821
Step:  7142, loss: 3.273326, norm: 0.2590, time(ms): 801.67, token/sec:653996.86, hellaswag_acc: 0.2821
Step:  7143, loss: 3.224056, norm: 0.2479, time(ms): 789.99, token/sec:663666.74, hellaswag_acc: 0.2821
Step:  7144, loss: 3.255782, norm: 0.2361, time(ms): 801.56, token/sec:654085.37, hellaswag_acc: 0.2821
Step:  7145, loss: 3.319655, norm: 0.2437, time(ms): 805.45, token/sec:650924.64, hellaswag_acc: 0.2821
Step:  7146, loss: 3.242556, norm: 0.2537, time(ms): 791.25, token/sec:662609.07, hellaswag_acc: 0.2821
Step:  7147, loss: 3.378581, norm: 0.3179, time(ms): 788.65, token/sec:664795.92, hellaswag_acc: 0.2821
Step:  7148, loss: 3.230112, norm: 0.2617, time(ms): 787.12, token/sec:666083.66, hellaswag_acc: 0.2821
Step:  7149, loss: 3.239472, norm: 0.2578, time(ms): 790.45, token/sec:663281.20, hellaswag_acc: 0.2821
Step:  7150, loss: 3.196905, norm: 0.2559, time(ms): 799.35, token/sec:655891.33, hellaswag_acc: 0.2821
Step:  7151, loss: 3.204573, norm: 0.2682, time(ms): 801.18, token/sec:654393.50, hellaswag_acc: 0.2821
Step:  7152, loss: 3.253794, norm: 0.2602, time(ms): 793.43, token/sec:660784.85, hellaswag_acc: 0.2821
Step:  7153, loss: 3.286742, norm: 0.2649, time(ms): 792.75, token/sec:661351.82, hellaswag_acc: 0.2821
Step:  7154, loss: 3.221806, norm: 0.2460, time(ms): 794.14, token/sec:660198.82, hellaswag_acc: 0.2821
Step:  7155, loss: 3.190883, norm: 0.2628, time(ms): 790.78, token/sec:663001.63, hellaswag_acc: 0.2821
Step:  7156, loss: 3.205251, norm: 0.2715, time(ms): 791.40, token/sec:662482.51, hellaswag_acc: 0.2821
Step:  7157, loss: 3.233779, norm: 0.2701, time(ms): 785.35, token/sec:667587.11, hellaswag_acc: 0.2821
Step:  7158, loss: 3.175968, norm: 0.2745, time(ms): 792.64, token/sec:661444.13, hellaswag_acc: 0.2821
Step:  7159, loss: 3.192411, norm: 0.2595, time(ms): 798.14, token/sec:656886.24, hellaswag_acc: 0.2821
Step:  7160, loss: 3.273633, norm: 0.2844, time(ms): 799.24, token/sec:655981.33, hellaswag_acc: 0.2821
Step:  7161, loss: 3.295949, norm: 0.3002, time(ms): 802.58, token/sec:653249.86, hellaswag_acc: 0.2821
Step:  7162, loss: 3.284328, norm: 0.2836, time(ms): 791.49, token/sec:662409.28, hellaswag_acc: 0.2821
Step:  7163, loss: 3.290590, norm: 0.2888, time(ms): 799.53, token/sec:655747.77, hellaswag_acc: 0.2821
Step:  7164, loss: 3.295565, norm: 0.3164, time(ms): 807.34, token/sec:649403.16, hellaswag_acc: 0.2821
Step:  7165, loss: 3.264008, norm: 0.2856, time(ms): 801.96, token/sec:653761.99, hellaswag_acc: 0.2821
Step:  7166, loss: 3.267570, norm: 0.2679, time(ms): 790.17, token/sec:663516.16, hellaswag_acc: 0.2821
Step:  7167, loss: 3.304119, norm: 0.2866, time(ms): 803.35, token/sec:652631.02, hellaswag_acc: 0.2821
Step:  7168, loss: 3.230155, norm: 0.2558, time(ms): 805.55, token/sec:650846.42, hellaswag_acc: 0.2821
Step:  7169, loss: 3.303864, norm: 0.3157, time(ms): 795.25, token/sec:659276.86, hellaswag_acc: 0.2821
Step:  7170, loss: 3.247044, norm: 0.3346, time(ms): 796.86, token/sec:657945.39, hellaswag_acc: 0.2821
Step:  7171, loss: 3.282048, norm: 0.2646, time(ms): 805.03, token/sec:651265.85, hellaswag_acc: 0.2821
Step:  7172, loss: 3.319190, norm: 0.2620, time(ms): 802.56, token/sec:653267.72, hellaswag_acc: 0.2821
Step:  7173, loss: 3.280877, norm: 0.2679, time(ms): 794.34, token/sec:660030.39, hellaswag_acc: 0.2821
Step:  7174, loss: 3.259152, norm: 0.2697, time(ms): 804.01, token/sec:652092.62, hellaswag_acc: 0.2821
Step:  7175, loss: 3.242750, norm: 0.2808, time(ms): 799.57, token/sec:655711.79, hellaswag_acc: 0.2821
Step:  7176, loss: 3.219315, norm: 0.2624, time(ms): 801.00, token/sec:654544.26, hellaswag_acc: 0.2821
Step:  7177, loss: 3.290216, norm: 0.2581, time(ms): 798.03, token/sec:656980.64, hellaswag_acc: 0.2821
Step:  7178, loss: 3.259942, norm: 0.2767, time(ms): 800.90, token/sec:654625.90, hellaswag_acc: 0.2821
Step:  7179, loss: 3.270578, norm: 0.2659, time(ms): 797.33, token/sec:657555.26, hellaswag_acc: 0.2821
Step:  7180, loss: 3.264342, norm: 0.2785, time(ms): 802.50, token/sec:653318.57, hellaswag_acc: 0.2821
Step:  7181, loss: 3.335775, norm: 0.3166, time(ms): 800.82, token/sec:654686.51, hellaswag_acc: 0.2821
Step:  7182, loss: 3.245670, norm: 0.2650, time(ms): 793.28, token/sec:660915.33, hellaswag_acc: 0.2821
Step:  7183, loss: 3.266474, norm: 0.2907, time(ms): 797.60, token/sec:657330.40, hellaswag_acc: 0.2821
Step:  7184, loss: 3.320853, norm: 0.3705, time(ms): 803.15, token/sec:652788.33, hellaswag_acc: 0.2821
Step:  7185, loss: 3.248908, norm: 0.3045, time(ms): 799.96, token/sec:655394.81, hellaswag_acc: 0.2821
Step:  7186, loss: 3.239218, norm: 0.3069, time(ms): 798.50, token/sec:656592.43, hellaswag_acc: 0.2821
Step:  7187, loss: 3.223435, norm: 0.3098, time(ms): 806.88, token/sec:649770.81, hellaswag_acc: 0.2821
Step:  7188, loss: 3.218182, norm: 0.2669, time(ms): 796.08, token/sec:658589.35, hellaswag_acc: 0.2821
Step:  7189, loss: 3.207127, norm: 0.2628, time(ms): 796.43, token/sec:658301.31, hellaswag_acc: 0.2821
Step:  7190, loss: 3.215904, norm: 0.2678, time(ms): 804.47, token/sec:651721.18, hellaswag_acc: 0.2821
Step:  7191, loss: 3.206549, norm: 0.2811, time(ms): 802.06, token/sec:653676.10, hellaswag_acc: 0.2821
Step:  7192, loss: 3.216229, norm: 0.2567, time(ms): 791.53, token/sec:662369.17, hellaswag_acc: 0.2821
Step:  7193, loss: 3.237979, norm: 0.2827, time(ms): 798.95, token/sec:656218.19, hellaswag_acc: 0.2821
Step:  7194, loss: 3.261790, norm: 0.2513, time(ms): 808.73, token/sec:648289.11, hellaswag_acc: 0.2821
Step:  7195, loss: 3.293936, norm: 0.2647, time(ms): 793.32, token/sec:660878.58, hellaswag_acc: 0.2821
Step:  7196, loss: 3.316465, norm: 0.2770, time(ms): 801.29, token/sec:654307.82, hellaswag_acc: 0.2821
Step:  7197, loss: 3.258822, norm: 0.2797, time(ms): 805.03, token/sec:651263.35, hellaswag_acc: 0.2821
Step:  7198, loss: 3.200469, norm: 0.2659, time(ms): 796.00, token/sec:658656.62, hellaswag_acc: 0.2821
Step:  7199, loss: 3.216686, norm: 0.2592, time(ms): 799.22, token/sec:656001.68, hellaswag_acc: 0.2821
Step:  7200, loss: 3.297307, norm: 0.2836, time(ms): 798.24, token/sec:656802.07, hellaswag_acc: 0.2821
Step:  7201, loss: 3.305989, norm: 0.2676, time(ms): 805.81, token/sec:650637.87, hellaswag_acc: 0.2821
Step:  7202, loss: 3.296756, norm: 0.2822, time(ms): 799.81, token/sec:655513.20, hellaswag_acc: 0.2821
Step:  7203, loss: 3.286993, norm: 0.2737, time(ms): 784.99, token/sec:667892.67, hellaswag_acc: 0.2821
Step:  7204, loss: 3.374466, norm: 0.3297, time(ms): 788.54, token/sec:664882.96, hellaswag_acc: 0.2821
Step:  7205, loss: 3.291844, norm: 0.4218, time(ms): 796.00, token/sec:658653.07, hellaswag_acc: 0.2821
Step:  7206, loss: 3.220462, norm: 0.2761, time(ms): 791.83, token/sec:662119.08, hellaswag_acc: 0.2821
Step:  7207, loss: 3.278414, norm: 0.2903, time(ms): 786.84, token/sec:666320.81, hellaswag_acc: 0.2821
Step:  7208, loss: 3.252074, norm: 0.2793, time(ms): 791.73, token/sec:662206.01, hellaswag_acc: 0.2821
Step:  7209, loss: 3.288196, norm: 0.2830, time(ms): 795.11, token/sec:659393.90, hellaswag_acc: 0.2821
Step:  7210, loss: 3.288733, norm: 0.2806, time(ms): 801.13, token/sec:654432.45, hellaswag_acc: 0.2821
Step:  7211, loss: 3.240459, norm: 0.2788, time(ms): 799.55, token/sec:655728.21, hellaswag_acc: 0.2821
Step:  7212, loss: 3.270884, norm: 0.2756, time(ms): 793.72, token/sec:660546.07, hellaswag_acc: 0.2821
Step:  7213, loss: 3.300104, norm: 0.2901, time(ms): 790.30, token/sec:663403.46, hellaswag_acc: 0.2821
Step:  7214, loss: 3.303061, norm: 0.2570, time(ms): 788.46, token/sec:664952.92, hellaswag_acc: 0.2821
Step:  7215, loss: 3.288886, norm: 0.2651, time(ms): 790.53, token/sec:663214.59, hellaswag_acc: 0.2821
Step:  7216, loss: 3.268773, norm: 0.2510, time(ms): 797.55, token/sec:657373.24, hellaswag_acc: 0.2821
Step:  7217, loss: 3.249445, norm: 0.2786, time(ms): 792.35, token/sec:661685.35, hellaswag_acc: 0.2821
Step:  7218, loss: 3.269707, norm: 0.2735, time(ms): 803.84, token/sec:652227.04, hellaswag_acc: 0.2821
Step:  7219, loss: 3.188511, norm: 0.2681, time(ms): 804.31, token/sec:651844.62, hellaswag_acc: 0.2821
Step:  7220, loss: 3.200084, norm: 0.2765, time(ms): 797.17, token/sec:657682.89, hellaswag_acc: 0.2821
Step:  7221, loss: 3.238737, norm: 0.2864, time(ms): 792.78, token/sec:661328.16, hellaswag_acc: 0.2821
Step:  7222, loss: 3.224442, norm: 0.2784, time(ms): 792.18, token/sec:661826.14, hellaswag_acc: 0.2821
Step:  7223, loss: 3.230575, norm: 0.2684, time(ms): 789.29, token/sec:664254.73, hellaswag_acc: 0.2821
Step:  7224, loss: 3.207836, norm: 0.2925, time(ms): 792.24, token/sec:661777.75, hellaswag_acc: 0.2821
Step:  7225, loss: 3.219419, norm: 0.2552, time(ms): 794.73, token/sec:659708.43, hellaswag_acc: 0.2821
Step:  7226, loss: 3.268004, norm: 0.2868, time(ms): 795.98, token/sec:658666.68, hellaswag_acc: 0.2821
Step:  7227, loss: 3.246832, norm: 0.2533, time(ms): 800.47, token/sec:654976.86, hellaswag_acc: 0.2821
Step:  7228, loss: 3.162533, norm: 0.2626, time(ms): 803.32, token/sec:652652.13, hellaswag_acc: 0.2821
Step:  7229, loss: 3.204558, norm: 0.2621, time(ms): 793.18, token/sec:660994.40, hellaswag_acc: 0.2821
Step:  7230, loss: 3.256309, norm: 0.2742, time(ms): 798.32, token/sec:656735.58, hellaswag_acc: 0.2821
Step:  7231, loss: 3.264767, norm: 0.2749, time(ms): 798.97, token/sec:656202.72, hellaswag_acc: 0.2821
Step:  7232, loss: 3.234505, norm: 0.2912, time(ms): 792.40, token/sec:661648.72, hellaswag_acc: 0.2821
Step:  7233, loss: 3.249728, norm: 0.2650, time(ms): 788.98, token/sec:664515.28, hellaswag_acc: 0.2821
Step:  7234, loss: 3.273764, norm: 0.2968, time(ms): 793.15, token/sec:661019.03, hellaswag_acc: 0.2821
Step:  7235, loss: 3.281684, norm: 0.3092, time(ms): 790.50, token/sec:663234.79, hellaswag_acc: 0.2821
Step:  7236, loss: 3.265812, norm: 0.2989, time(ms): 792.85, token/sec:661266.91, hellaswag_acc: 0.2821
Step:  7237, loss: 3.141567, norm: 0.3129, time(ms): 791.36, token/sec:662513.85, hellaswag_acc: 0.2821
Step:  7238, loss: 3.244796, norm: 0.2924, time(ms): 1258.72, token/sec:416526.01, hellaswag_acc: 0.2821
Step:  7239, loss: 3.254952, norm: 0.2987, time(ms): 768.67, token/sec:682070.71, hellaswag_acc: 0.2821
Step:  7240, loss: 3.249831, norm: 0.2795, time(ms): 795.62, token/sec:658971.63, hellaswag_acc: 0.2821
Step:  7241, loss: 3.259273, norm: 0.2777, time(ms): 797.42, token/sec:657478.78, hellaswag_acc: 0.2821
Step:  7242, loss: 3.265683, norm: 0.3077, time(ms): 785.31, token/sec:667615.08, hellaswag_acc: 0.2821
Step:  7243, loss: 3.253171, norm: 0.2690, time(ms): 778.11, token/sec:673794.06, hellaswag_acc: 0.2821
Step:  7244, loss: 3.295055, norm: 0.3121, time(ms): 784.90, token/sec:667965.50, hellaswag_acc: 0.2821
Step:  7245, loss: 3.222820, norm: 0.2954, time(ms): 792.63, token/sec:661452.88, hellaswag_acc: 0.2821
Step:  7246, loss: 3.262408, norm: 0.2541, time(ms): 792.79, token/sec:661318.81, hellaswag_acc: 0.2821
Step:  7247, loss: 3.202454, norm: 0.2959, time(ms): 790.18, token/sec:663501.34, hellaswag_acc: 0.2821
Step:  7248, loss: 3.171825, norm: 0.2706, time(ms): 786.59, token/sec:666530.65, hellaswag_acc: 0.2821
Step:  7249, loss: 3.041332, norm: 0.2779, time(ms): 804.03, token/sec:652075.80, hellaswag_acc: 0.2821
rank 0 sample 0: Hello, I'm a language model, and I'll be the first time I understand an analogy of how English-C is similar to a French/English dialect
rank 0 sample 1: Hello, I'm a language model, I use Ruby on Rails, Ruby on Rails. All code in Ruby on Rails. Ruby on Rails in Ruby on Rails
rank 0 sample 2: Hello, I'm a language model, so I like languages when a friend uses a particular language. That makes it easier to learn, and it makes me stronger
rank 0 sample 3: Hello, I'm a language model, I’m a language modeling and language diagram. I’m an environment model, I’m part
rank 1 sample 0: Hello, I'm a language model, we don't have to use CGL. This means that what we have and what we want it to do is to
rank 1 sample 1: Hello, I'm a language model, not an expert. I'm a native speaker of English too. Thank you for what!"
*The first line of
rank 1 sample 2: Hello, I'm a language model, I haven't heard of any language, I'm a model myself and my father. I was very curious to know how
rank 1 sample 3: Hello, I'm a language model, and I'm doing it through my own perspective. I’m very well-behaved, and I like to
Step:  7250, loss: 3.082994, norm: 0.3473, time(ms): 3789.98, token/sec:138335.43, val_loss: 3.2653, hellaswag_acc: 0.2821
Step:  7251, loss: 3.052397, norm: 0.3845, time(ms): 781.70, token/sec:670699.54, hellaswag_acc: 0.2821
Step:  7252, loss: 3.117170, norm: 0.4287, time(ms): 790.86, token/sec:662936.27, hellaswag_acc: 0.2821
Step:  7253, loss: 3.040629, norm: 0.4023, time(ms): 790.31, token/sec:663399.06, hellaswag_acc: 0.2821
Step:  7254, loss: 3.051585, norm: 0.3491, time(ms): 798.17, token/sec:656862.11, hellaswag_acc: 0.2821
Step:  7255, loss: 3.084831, norm: 0.2807, time(ms): 790.89, token/sec:662907.29, hellaswag_acc: 0.2821
Step:  7256, loss: 3.050450, norm: 0.2774, time(ms): 786.60, token/sec:666521.76, hellaswag_acc: 0.2821
Step:  7257, loss: 2.999125, norm: 0.3046, time(ms): 789.14, token/sec:664382.17, hellaswag_acc: 0.2821
Step:  7258, loss: 3.071801, norm: 0.2599, time(ms): 798.18, token/sec:656856.22, hellaswag_acc: 0.2821
Step:  7259, loss: 3.000893, norm: 0.3292, time(ms): 804.30, token/sec:651852.93, hellaswag_acc: 0.2821
Step:  7260, loss: 3.116555, norm: 0.2795, time(ms): 799.39, token/sec:655857.49, hellaswag_acc: 0.2821
Step:  7261, loss: 3.307096, norm: 0.3527, time(ms): 792.00, token/sec:661975.97, hellaswag_acc: 0.2821
Step:  7262, loss: 3.253388, norm: 0.2757, time(ms): 798.23, token/sec:656810.31, hellaswag_acc: 0.2821
Step:  7263, loss: 3.254751, norm: 0.2944, time(ms): 792.62, token/sec:661465.42, hellaswag_acc: 0.2821
Step:  7264, loss: 3.278702, norm: 0.2973, time(ms): 792.53, token/sec:661537.25, hellaswag_acc: 0.2821
Step:  7265, loss: 3.196866, norm: 0.2738, time(ms): 798.11, token/sec:656913.91, hellaswag_acc: 0.2821
Step:  7266, loss: 3.297042, norm: 0.3117, time(ms): 803.43, token/sec:652565.56, hellaswag_acc: 0.2821
Step:  7267, loss: 3.226866, norm: 0.2815, time(ms): 795.67, token/sec:658929.18, hellaswag_acc: 0.2821
Step:  7268, loss: 3.293964, norm: 0.2706, time(ms): 796.14, token/sec:658538.86, hellaswag_acc: 0.2821
Step:  7269, loss: 3.323185, norm: 0.2925, time(ms): 788.46, token/sec:664955.94, hellaswag_acc: 0.2821
Step:  7270, loss: 3.250191, norm: 0.2511, time(ms): 788.72, token/sec:664732.42, hellaswag_acc: 0.2821
Step:  7271, loss: 3.314297, norm: 0.2603, time(ms): 787.09, token/sec:666109.49, hellaswag_acc: 0.2821
Step:  7272, loss: 3.346000, norm: 0.2708, time(ms): 804.62, token/sec:651596.43, hellaswag_acc: 0.2821
Step:  7273, loss: 3.277874, norm: 0.2482, time(ms): 801.65, token/sec:654011.84, hellaswag_acc: 0.2821
Step:  7274, loss: 3.306777, norm: 0.2685, time(ms): 790.81, token/sec:662979.24, hellaswag_acc: 0.2821
Step:  7275, loss: 3.272563, norm: 0.2576, time(ms): 796.91, token/sec:657902.88, hellaswag_acc: 0.2821
Step:  7276, loss: 3.353867, norm: 0.2568, time(ms): 791.44, token/sec:662452.38, hellaswag_acc: 0.2821
Step:  7277, loss: 3.242271, norm: 0.2950, time(ms): 789.45, token/sec:664118.12, hellaswag_acc: 0.2821
Step:  7278, loss: 3.269547, norm: 0.2518, time(ms): 790.86, token/sec:662932.87, hellaswag_acc: 0.2821
Step:  7279, loss: 3.324946, norm: 0.2805, time(ms): 797.29, token/sec:657587.31, hellaswag_acc: 0.2821
Step:  7280, loss: 3.304642, norm: 0.2822, time(ms): 798.61, token/sec:656497.75, hellaswag_acc: 0.2821
Step:  7281, loss: 3.282566, norm: 0.2554, time(ms): 797.15, token/sec:657704.53, hellaswag_acc: 0.2821
Step:  7282, loss: 3.300746, norm: 0.2897, time(ms): 802.75, token/sec:653111.14, hellaswag_acc: 0.2821
Step:  7283, loss: 3.228683, norm: 0.2828, time(ms): 800.97, token/sec:654564.13, hellaswag_acc: 0.2821
Step:  7284, loss: 3.211682, norm: 0.2714, time(ms): 799.68, token/sec:655622.64, hellaswag_acc: 0.2821
Step:  7285, loss: 3.234370, norm: 0.2599, time(ms): 795.07, token/sec:659427.71, hellaswag_acc: 0.2821
Step:  7286, loss: 3.234532, norm: 0.2896, time(ms): 802.68, token/sec:653169.92, hellaswag_acc: 0.2821
Step:  7287, loss: 3.174288, norm: 0.2585, time(ms): 804.00, token/sec:652098.04, hellaswag_acc: 0.2821
Step:  7288, loss: 3.233868, norm: 0.3055, time(ms): 795.45, token/sec:659108.90, hellaswag_acc: 0.2821
Step:  7289, loss: 3.216611, norm: 0.2763, time(ms): 792.78, token/sec:661330.94, hellaswag_acc: 0.2821
Step:  7290, loss: 3.172045, norm: 0.2624, time(ms): 790.68, token/sec:663083.00, hellaswag_acc: 0.2821
Step:  7291, loss: 3.286731, norm: 0.2930, time(ms): 796.46, token/sec:658276.87, hellaswag_acc: 0.2821
Step:  7292, loss: 3.248669, norm: 0.2833, time(ms): 790.02, token/sec:663642.51, hellaswag_acc: 0.2821
Step:  7293, loss: 3.213090, norm: 0.2733, time(ms): 786.76, token/sec:666390.47, hellaswag_acc: 0.2821
Step:  7294, loss: 3.186500, norm: 0.2610, time(ms): 796.69, token/sec:658085.19, hellaswag_acc: 0.2821
Step:  7295, loss: 3.032246, norm: 0.2820, time(ms): 790.34, token/sec:663373.84, hellaswag_acc: 0.2821
Step:  7296, loss: 3.045396, norm: 0.3069, time(ms): 798.40, token/sec:656672.82, hellaswag_acc: 0.2821
Step:  7297, loss: 3.037303, norm: 0.3162, time(ms): 785.07, token/sec:667827.15, hellaswag_acc: 0.2821
Step:  7298, loss: 3.044127, norm: 0.3114, time(ms): 790.35, token/sec:663361.63, hellaswag_acc: 0.2821
Step:  7299, loss: 3.065423, norm: 0.2678, time(ms): 796.82, token/sec:657971.38, hellaswag_acc: 0.2821
Step:  7300, loss: 3.003200, norm: 0.3171, time(ms): 790.77, token/sec:663009.43, hellaswag_acc: 0.2821
Step:  7301, loss: 3.032724, norm: 0.3081, time(ms): 790.34, token/sec:663373.04, hellaswag_acc: 0.2821
Step:  7302, loss: 3.086384, norm: 0.3220, time(ms): 796.64, token/sec:658122.22, hellaswag_acc: 0.2821
Step:  7303, loss: 2.965984, norm: 0.2957, time(ms): 791.91, token/sec:662058.28, hellaswag_acc: 0.2821
Step:  7304, loss: 3.079286, norm: 0.3238, time(ms): 791.78, token/sec:662161.34, hellaswag_acc: 0.2821
Step:  7305, loss: 3.099616, norm: 0.3511, time(ms): 792.20, token/sec:661809.21, hellaswag_acc: 0.2821
Step:  7306, loss: 3.169002, norm: 0.3034, time(ms): 786.98, token/sec:666205.34, hellaswag_acc: 0.2821
Step:  7307, loss: 3.288251, norm: 0.3056, time(ms): 792.85, token/sec:661273.47, hellaswag_acc: 0.2821
Step:  7308, loss: 3.245146, norm: 0.3387, time(ms): 789.96, token/sec:663686.97, hellaswag_acc: 0.2821
Step:  7309, loss: 3.224371, norm: 0.2650, time(ms): 792.25, token/sec:661772.37, hellaswag_acc: 0.2821
Step:  7310, loss: 3.311079, norm: 0.3108, time(ms): 790.63, token/sec:663129.39, hellaswag_acc: 0.2821
Step:  7311, loss: 3.282066, norm: 0.2863, time(ms): 789.09, token/sec:664420.51, hellaswag_acc: 0.2821
Step:  7312, loss: 3.296916, norm: 0.3313, time(ms): 792.50, token/sec:661565.31, hellaswag_acc: 0.2821
Step:  7313, loss: 3.223393, norm: 0.2971, time(ms): 797.23, token/sec:657638.64, hellaswag_acc: 0.2821
Step:  7314, loss: 3.319736, norm: 0.3013, time(ms): 795.74, token/sec:658870.54, hellaswag_acc: 0.2821
Step:  7315, loss: 3.247541, norm: 0.2706, time(ms): 801.71, token/sec:653964.00, hellaswag_acc: 0.2821
Step:  7316, loss: 3.247920, norm: 0.2692, time(ms): 801.44, token/sec:654178.58, hellaswag_acc: 0.2821
Step:  7317, loss: 3.316785, norm: 0.3194, time(ms): 795.09, token/sec:659407.94, hellaswag_acc: 0.2821
Step:  7318, loss: 3.274276, norm: 0.2770, time(ms): 798.83, token/sec:656318.86, hellaswag_acc: 0.2821
Step:  7319, loss: 3.287128, norm: 0.2600, time(ms): 804.65, token/sec:651571.91, hellaswag_acc: 0.2821
Step:  7320, loss: 3.319550, norm: 0.2684, time(ms): 798.40, token/sec:656671.84, hellaswag_acc: 0.2821
Step:  7321, loss: 3.288926, norm: 0.2552, time(ms): 797.28, token/sec:657598.72, hellaswag_acc: 0.2821
Step:  7322, loss: 3.305057, norm: 0.2709, time(ms): 802.31, token/sec:653476.79, hellaswag_acc: 0.2821
Step:  7323, loss: 3.264740, norm: 0.2542, time(ms): 803.17, token/sec:652774.58, hellaswag_acc: 0.2821
Step:  7324, loss: 3.274189, norm: 0.2779, time(ms): 792.52, token/sec:661547.40, hellaswag_acc: 0.2821
Step:  7325, loss: 3.258357, norm: 0.2587, time(ms): 798.27, token/sec:656776.77, hellaswag_acc: 0.2821
Step:  7326, loss: 3.286736, norm: 0.2705, time(ms): 791.14, token/sec:662700.53, hellaswag_acc: 0.2821
Step:  7327, loss: 3.265358, norm: 0.2891, time(ms): 788.42, token/sec:664984.49, hellaswag_acc: 0.2821
Step:  7328, loss: 3.268012, norm: 0.2815, time(ms): 790.28, token/sec:663417.67, hellaswag_acc: 0.2821
Step:  7329, loss: 3.245811, norm: 0.2692, time(ms): 790.06, token/sec:663603.46, hellaswag_acc: 0.2821
Step:  7330, loss: 3.195158, norm: 0.3083, time(ms): 791.00, token/sec:662816.78, hellaswag_acc: 0.2821
Step:  7331, loss: 3.217671, norm: 0.2602, time(ms): 794.36, token/sec:660013.95, hellaswag_acc: 0.2821
Step:  7332, loss: 3.262451, norm: 0.2780, time(ms): 800.28, token/sec:655131.99, hellaswag_acc: 0.2821
Step:  7333, loss: 3.208482, norm: 0.3010, time(ms): 802.96, token/sec:652947.66, hellaswag_acc: 0.2821
Step:  7334, loss: 3.265025, norm: 0.2578, time(ms): 795.23, token/sec:659294.46, hellaswag_acc: 0.2821
Step:  7335, loss: 3.218379, norm: 0.2704, time(ms): 803.39, token/sec:652598.10, hellaswag_acc: 0.2821
Step:  7336, loss: 3.245011, norm: 0.2395, time(ms): 800.39, token/sec:655043.79, hellaswag_acc: 0.2821
Step:  7337, loss: 3.257478, norm: 0.2577, time(ms): 795.12, token/sec:659384.80, hellaswag_acc: 0.2821
Step:  7338, loss: 3.290041, norm: 0.2617, time(ms): 803.39, token/sec:652592.29, hellaswag_acc: 0.2821
Step:  7339, loss: 3.143340, norm: 0.2990, time(ms): 802.02, token/sec:653711.46, hellaswag_acc: 0.2821
Step:  7340, loss: 2.960342, norm: 0.2988, time(ms): 794.76, token/sec:659677.36, hellaswag_acc: 0.2821
Step:  7341, loss: 2.973434, norm: 0.3878, time(ms): 803.56, token/sec:652453.07, hellaswag_acc: 0.2821
Step:  7342, loss: 3.040472, norm: 0.4072, time(ms): 796.76, token/sec:658021.39, hellaswag_acc: 0.2821
Step:  7343, loss: 3.017069, norm: 0.3332, time(ms): 803.41, token/sec:652580.28, hellaswag_acc: 0.2821
Step:  7344, loss: 3.066200, norm: 0.3119, time(ms): 799.48, token/sec:655786.49, hellaswag_acc: 0.2821
Step:  7345, loss: 3.036559, norm: 0.3425, time(ms): 796.52, token/sec:658225.05, hellaswag_acc: 0.2821
Step:  7346, loss: 3.041753, norm: 0.2988, time(ms): 800.21, token/sec:655185.28, hellaswag_acc: 0.2821
Step:  7347, loss: 3.016569, norm: 0.2835, time(ms): 797.85, token/sec:657123.95, hellaswag_acc: 0.2821
Step:  7348, loss: 3.029030, norm: 0.2644, time(ms): 805.28, token/sec:651059.15, hellaswag_acc: 0.2821
Step:  7349, loss: 3.020162, norm: 0.2787, time(ms): 800.69, token/sec:654792.37, hellaswag_acc: 0.2821
Step:  7350, loss: 3.009064, norm: 0.2765, time(ms): 788.38, token/sec:665016.87, hellaswag_acc: 0.2821
Step:  7351, loss: 3.335069, norm: 0.2888, time(ms): 789.01, token/sec:664487.77, hellaswag_acc: 0.2821
Step:  7352, loss: 3.301083, norm: 0.2969, time(ms): 791.27, token/sec:662590.70, hellaswag_acc: 0.2821
Step:  7353, loss: 3.245162, norm: 0.3700, time(ms): 790.75, token/sec:663028.22, hellaswag_acc: 0.2821
Step:  7354, loss: 3.247944, norm: 0.2689, time(ms): 796.10, token/sec:658571.01, hellaswag_acc: 0.2821
Step:  7355, loss: 3.266270, norm: 0.3019, time(ms): 800.09, token/sec:655286.61, hellaswag_acc: 0.2821
Step:  7356, loss: 3.288685, norm: 0.2936, time(ms): 797.45, token/sec:657459.52, hellaswag_acc: 0.2821
Step:  7357, loss: 3.243826, norm: 0.3002, time(ms): 802.98, token/sec:652925.17, hellaswag_acc: 0.2821
Step:  7358, loss: 3.258582, norm: 0.2972, time(ms): 796.51, token/sec:658233.72, hellaswag_acc: 0.2821
Step:  7359, loss: 3.316315, norm: 0.3014, time(ms): 795.98, token/sec:658669.64, hellaswag_acc: 0.2821
Step:  7360, loss: 3.264812, norm: 0.2898, time(ms): 793.65, token/sec:660606.99, hellaswag_acc: 0.2821
Step:  7361, loss: 3.288657, norm: 0.3059, time(ms): 796.60, token/sec:658158.66, hellaswag_acc: 0.2821
Step:  7362, loss: 3.289589, norm: 0.2806, time(ms): 788.52, token/sec:664898.64, hellaswag_acc: 0.2821
Step:  7363, loss: 3.288260, norm: 0.2752, time(ms): 792.14, token/sec:661862.00, hellaswag_acc: 0.2821
Step:  7364, loss: 3.276132, norm: 0.4183, time(ms): 787.83, token/sec:665485.99, hellaswag_acc: 0.2821
Step:  7365, loss: 3.314269, norm: 0.2731, time(ms): 791.40, token/sec:662485.71, hellaswag_acc: 0.2821
Step:  7366, loss: 3.277784, norm: 0.2778, time(ms): 794.69, token/sec:659742.87, hellaswag_acc: 0.2821
Step:  7367, loss: 3.269746, norm: 0.2691, time(ms): 797.35, token/sec:657536.58, hellaswag_acc: 0.2821
Step:  7368, loss: 3.254848, norm: 0.2552, time(ms): 806.70, token/sec:649914.84, hellaswag_acc: 0.2821
Step:  7369, loss: 3.290061, norm: 0.2723, time(ms): 793.63, token/sec:660617.51, hellaswag_acc: 0.2821
Step:  7370, loss: 3.254028, norm: 0.2426, time(ms): 803.28, token/sec:652681.19, hellaswag_acc: 0.2821
Step:  7371, loss: 3.245623, norm: 0.2781, time(ms): 799.11, token/sec:656089.17, hellaswag_acc: 0.2821
Step:  7372, loss: 3.338130, norm: 0.2711, time(ms): 800.41, token/sec:655024.66, hellaswag_acc: 0.2821
Step:  7373, loss: 3.278761, norm: 0.2983, time(ms): 801.40, token/sec:654217.11, hellaswag_acc: 0.2821
Step:  7374, loss: 3.235801, norm: 0.3106, time(ms): 790.81, token/sec:662976.84, hellaswag_acc: 0.2821
Step:  7375, loss: 3.246413, norm: 0.2949, time(ms): 807.85, token/sec:648991.67, hellaswag_acc: 0.2821
Step:  7376, loss: 3.248379, norm: 0.2859, time(ms): 800.88, token/sec:654640.91, hellaswag_acc: 0.2821
Step:  7377, loss: 3.238139, norm: 0.2599, time(ms): 795.35, token/sec:659192.28, hellaswag_acc: 0.2821
Step:  7378, loss: 3.239012, norm: 0.2679, time(ms): 802.04, token/sec:653689.50, hellaswag_acc: 0.2821
Step:  7379, loss: 3.182334, norm: 0.2715, time(ms): 801.49, token/sec:654143.55, hellaswag_acc: 0.2821
Step:  7380, loss: 3.218049, norm: 0.2578, time(ms): 795.60, token/sec:658987.43, hellaswag_acc: 0.2821
Step:  7381, loss: 3.234801, norm: 0.2739, time(ms): 803.13, token/sec:652805.19, hellaswag_acc: 0.2821
Step:  7382, loss: 3.176647, norm: 0.2765, time(ms): 802.43, token/sec:653377.97, hellaswag_acc: 0.2821
Step:  7383, loss: 3.235708, norm: 0.2999, time(ms): 792.89, token/sec:661236.28, hellaswag_acc: 0.2821
Step:  7384, loss: 3.172006, norm: 0.2949, time(ms): 795.86, token/sec:658770.07, hellaswag_acc: 0.2821
Step:  7385, loss: 3.059380, norm: 0.2764, time(ms): 791.91, token/sec:662054.89, hellaswag_acc: 0.2821
Step:  7386, loss: 3.062263, norm: 0.3440, time(ms): 786.05, token/sec:666987.55, hellaswag_acc: 0.2821
Step:  7387, loss: 3.086953, norm: 0.3615, time(ms): 790.68, token/sec:663084.80, hellaswag_acc: 0.2821
Step:  7388, loss: 3.090519, norm: 0.2858, time(ms): 796.90, token/sec:657907.60, hellaswag_acc: 0.2821
Step:  7389, loss: 3.046111, norm: 0.2952, time(ms): 799.10, token/sec:656095.04, hellaswag_acc: 0.2821
Step:  7390, loss: 3.054443, norm: 0.3393, time(ms): 803.41, token/sec:652578.92, hellaswag_acc: 0.2821
Step:  7391, loss: 3.060579, norm: 0.2961, time(ms): 793.06, token/sec:661093.75, hellaswag_acc: 0.2821
Step:  7392, loss: 2.984665, norm: 0.2873, time(ms): 798.37, token/sec:656700.27, hellaswag_acc: 0.2821
Step:  7393, loss: 3.041886, norm: 0.3250, time(ms): 792.43, token/sec:661621.44, hellaswag_acc: 0.2821
Step:  7394, loss: 3.000544, norm: 0.2847, time(ms): 793.52, token/sec:660713.38, hellaswag_acc: 0.2821
Step:  7395, loss: 2.985765, norm: 0.3007, time(ms): 797.62, token/sec:657311.54, hellaswag_acc: 0.2821
Step:  7396, loss: 3.311474, norm: 0.3134, time(ms): 800.57, token/sec:654894.74, hellaswag_acc: 0.2821
Step:  7397, loss: 3.238571, norm: 0.3222, time(ms): 804.18, token/sec:651954.78, hellaswag_acc: 0.2821
Step:  7398, loss: 3.222324, norm: 0.3001, time(ms): 792.15, token/sec:661851.84, hellaswag_acc: 0.2821
Step:  7399, loss: 3.297803, norm: 0.2894, time(ms): 797.21, token/sec:657654.57, hellaswag_acc: 0.2821
Step:  7400, loss: 3.236899, norm: 0.2813, time(ms): 788.58, token/sec:664849.19, hellaswag_acc: 0.2821
Step:  7401, loss: 3.298973, norm: 0.2630, time(ms): 791.86, token/sec:662096.95, hellaswag_acc: 0.2821
Step:  7402, loss: 3.270113, norm: 0.3073, time(ms): 791.48, token/sec:662411.07, hellaswag_acc: 0.2821
Step:  7403, loss: 3.267252, norm: 0.2811, time(ms): 788.23, token/sec:665142.59, hellaswag_acc: 0.2821
Step:  7404, loss: 3.276907, norm: 0.2834, time(ms): 798.93, token/sec:656240.91, hellaswag_acc: 0.2821
Step:  7405, loss: 3.439789, norm: 0.3987, time(ms): 790.93, token/sec:662871.92, hellaswag_acc: 0.2821
Step:  7406, loss: 3.292663, norm: 0.4331, time(ms): 786.00, token/sec:667033.88, hellaswag_acc: 0.2821
Step:  7407, loss: 3.288356, norm: 0.3527, time(ms): 789.97, token/sec:663679.56, hellaswag_acc: 0.2821
Step:  7408, loss: 3.265390, norm: 0.3444, time(ms): 795.82, token/sec:658805.99, hellaswag_acc: 0.2821
Step:  7409, loss: 3.292628, norm: 0.3241, time(ms): 803.69, token/sec:652352.42, hellaswag_acc: 0.2821
Step:  7410, loss: 3.264307, norm: 0.3004, time(ms): 796.94, token/sec:657876.11, hellaswag_acc: 0.2821
Step:  7411, loss: 3.290803, norm: 0.3066, time(ms): 792.42, token/sec:661627.22, hellaswag_acc: 0.2821
Step:  7412, loss: 3.317689, norm: 0.2604, time(ms): 790.51, token/sec:663225.39, hellaswag_acc: 0.2821
Step:  7413, loss: 3.240708, norm: 0.2925, time(ms): 799.39, token/sec:655858.07, hellaswag_acc: 0.2821
Step:  7414, loss: 3.234042, norm: 0.2682, time(ms): 802.82, token/sec:653061.10, hellaswag_acc: 0.2821
Step:  7415, loss: 3.293571, norm: 0.2871, time(ms): 797.42, token/sec:657482.52, hellaswag_acc: 0.2821
Step:  7416, loss: 3.262982, norm: 0.2664, time(ms): 792.42, token/sec:661628.21, hellaswag_acc: 0.2821
Step:  7417, loss: 3.305872, norm: 0.2878, time(ms): 789.67, token/sec:663932.04, hellaswag_acc: 0.2821
Step:  7418, loss: 3.311193, norm: 0.3137, time(ms): 790.87, token/sec:662925.28, hellaswag_acc: 0.2821
Step:  7419, loss: 3.233460, norm: 0.2637, time(ms): 792.85, token/sec:661273.67, hellaswag_acc: 0.2821
Step:  7420, loss: 3.221263, norm: 0.2893, time(ms): 791.66, token/sec:662266.04, hellaswag_acc: 0.2821
Step:  7421, loss: 3.255295, norm: 0.2590, time(ms): 801.65, token/sec:654009.70, hellaswag_acc: 0.2821
Step:  7422, loss: 3.179401, norm: 0.2739, time(ms): 801.19, token/sec:654388.43, hellaswag_acc: 0.2821
Step:  7423, loss: 3.208977, norm: 0.2522, time(ms): 802.02, token/sec:653713.21, hellaswag_acc: 0.2821
Step:  7424, loss: 3.246456, norm: 0.2653, time(ms): 790.56, token/sec:663184.58, hellaswag_acc: 0.2821
Step:  7425, loss: 3.223503, norm: 0.2405, time(ms): 801.73, token/sec:653948.83, hellaswag_acc: 0.2821
Step:  7426, loss: 3.228197, norm: 0.2595, time(ms): 805.77, token/sec:650664.63, hellaswag_acc: 0.2821
Step:  7427, loss: 3.258898, norm: 0.2457, time(ms): 795.11, token/sec:659392.51, hellaswag_acc: 0.2821
Step:  7428, loss: 3.269788, norm: 0.2426, time(ms): 803.11, token/sec:652823.60, hellaswag_acc: 0.2821
Step:  7429, loss: 3.275920, norm: 0.2696, time(ms): 1296.91, token/sec:404259.93, hellaswag_acc: 0.2821
Step:  7430, loss: 3.275894, norm: 0.2425, time(ms): 790.50, token/sec:663233.99, hellaswag_acc: 0.2821
Step:  7431, loss: 3.287099, norm: 0.2747, time(ms): 782.89, token/sec:669680.73, hellaswag_acc: 0.2821
Step:  7432, loss: 3.287448, norm: 0.2963, time(ms): 783.40, token/sec:669246.42, hellaswag_acc: 0.2821
Step:  7433, loss: 3.341599, norm: 0.2645, time(ms): 803.72, token/sec:652329.78, hellaswag_acc: 0.2821
Step:  7434, loss: 3.293044, norm: 0.2959, time(ms): 804.25, token/sec:651895.64, hellaswag_acc: 0.2821
Step:  7435, loss: 3.247197, norm: 0.2879, time(ms): 785.36, token/sec:667576.77, hellaswag_acc: 0.2821
Step:  7436, loss: 3.204257, norm: 0.2881, time(ms): 781.68, token/sec:670719.38, hellaswag_acc: 0.2821
Step:  7437, loss: 3.264387, norm: 0.2621, time(ms): 786.36, token/sec:666724.45, hellaswag_acc: 0.2821
Step:  7438, loss: 3.264752, norm: 0.2751, time(ms): 794.36, token/sec:660010.98, hellaswag_acc: 0.2821
Step:  7439, loss: 3.258221, norm: 0.2784, time(ms): 792.73, token/sec:661373.31, hellaswag_acc: 0.2821
Step:  7440, loss: 3.261838, norm: 0.2843, time(ms): 781.48, token/sec:670888.00, hellaswag_acc: 0.2821
Step:  7441, loss: 3.296323, norm: 0.2961, time(ms): 789.06, token/sec:664444.20, hellaswag_acc: 0.2821
Step:  7442, loss: 3.241745, norm: 0.2811, time(ms): 796.75, token/sec:658033.40, hellaswag_acc: 0.2821
Step:  7443, loss: 3.325786, norm: 0.2637, time(ms): 790.17, token/sec:663516.76, hellaswag_acc: 0.2821
Step:  7444, loss: 3.321419, norm: 0.3086, time(ms): 798.93, token/sec:656237.97, hellaswag_acc: 0.2821
Step:  7445, loss: 3.298961, norm: 0.2635, time(ms): 791.24, token/sec:662616.86, hellaswag_acc: 0.2821
Step:  7446, loss: 3.276696, norm: 0.2809, time(ms): 791.96, token/sec:662016.82, hellaswag_acc: 0.2821
Step:  7447, loss: 3.296760, norm: 0.2666, time(ms): 792.02, token/sec:661962.22, hellaswag_acc: 0.2821
Step:  7448, loss: 3.259927, norm: 0.2759, time(ms): 796.11, token/sec:658562.33, hellaswag_acc: 0.2821
Step:  7449, loss: 3.296996, norm: 0.2557, time(ms): 788.19, token/sec:665177.19, hellaswag_acc: 0.2821
Step:  7450, loss: 3.291378, norm: 0.2746, time(ms): 790.09, token/sec:663577.42, hellaswag_acc: 0.2821
Step:  7451, loss: 3.262589, norm: 0.2401, time(ms): 787.82, token/sec:665495.46, hellaswag_acc: 0.2821
Step:  7452, loss: 3.224450, norm: 0.2709, time(ms): 800.96, token/sec:654570.56, hellaswag_acc: 0.2821
Step:  7453, loss: 3.217648, norm: 0.2471, time(ms): 794.25, token/sec:660107.66, hellaswag_acc: 0.2821
Step:  7454, loss: 3.215364, norm: 0.2856, time(ms): 802.22, token/sec:653545.93, hellaswag_acc: 0.2821
Step:  7455, loss: 3.222773, norm: 0.2395, time(ms): 802.65, token/sec:653199.41, hellaswag_acc: 0.2821
Step:  7456, loss: 3.286039, norm: 0.2946, time(ms): 800.37, token/sec:655059.98, hellaswag_acc: 0.2821
Step:  7457, loss: 3.237293, norm: 0.2622, time(ms): 790.31, token/sec:663392.65, hellaswag_acc: 0.2821
Step:  7458, loss: 3.243674, norm: 0.3346, time(ms): 789.60, token/sec:663990.78, hellaswag_acc: 0.2821
Step:  7459, loss: 3.288896, norm: 0.2945, time(ms): 790.32, token/sec:663387.45, hellaswag_acc: 0.2821
Step:  7460, loss: 3.224692, norm: 0.2774, time(ms): 793.36, token/sec:660848.20, hellaswag_acc: 0.2821
Step:  7461, loss: 3.357737, norm: 0.3627, time(ms): 787.93, token/sec:665396.58, hellaswag_acc: 0.2821
Step:  7462, loss: 3.309721, norm: 0.3865, time(ms): 799.49, token/sec:655781.01, hellaswag_acc: 0.2821
Step:  7463, loss: 3.304856, norm: 0.3000, time(ms): 791.20, token/sec:662649.41, hellaswag_acc: 0.2821
Step:  7464, loss: 3.307387, norm: 0.3416, time(ms): 789.57, token/sec:664016.24, hellaswag_acc: 0.2821
Step:  7465, loss: 3.265851, norm: 0.2962, time(ms): 792.54, token/sec:661524.71, hellaswag_acc: 0.2821
Step:  7466, loss: 3.234425, norm: 0.3368, time(ms): 789.40, token/sec:664164.05, hellaswag_acc: 0.2821
Step:  7467, loss: 3.294774, norm: 0.2908, time(ms): 795.39, token/sec:659161.26, hellaswag_acc: 0.2821
Step:  7468, loss: 3.345040, norm: 0.3054, time(ms): 790.24, token/sec:663454.70, hellaswag_acc: 0.2821
Step:  7469, loss: 3.254225, norm: 0.3324, time(ms): 791.02, token/sec:662797.00, hellaswag_acc: 0.2821
Step:  7470, loss: 3.261831, norm: 0.2809, time(ms): 799.45, token/sec:655810.74, hellaswag_acc: 0.2821
Step:  7471, loss: 3.245499, norm: 0.3226, time(ms): 790.98, token/sec:662833.16, hellaswag_acc: 0.2821
Step:  7472, loss: 3.219730, norm: 0.2768, time(ms): 791.82, token/sec:662132.04, hellaswag_acc: 0.2821
Step:  7473, loss: 3.263185, norm: 0.2982, time(ms): 791.01, token/sec:662805.19, hellaswag_acc: 0.2821
Step:  7474, loss: 3.273021, norm: 0.2729, time(ms): 790.66, token/sec:663105.79, hellaswag_acc: 0.2821
Step:  7475, loss: 3.334365, norm: 0.2891, time(ms): 798.98, token/sec:656200.57, hellaswag_acc: 0.2821
Step:  7476, loss: 3.312811, norm: 0.2931, time(ms): 801.84, token/sec:653855.69, hellaswag_acc: 0.2821
Step:  7477, loss: 3.276086, norm: 0.2544, time(ms): 799.21, token/sec:656004.23, hellaswag_acc: 0.2821
Step:  7478, loss: 3.271325, norm: 0.2820, time(ms): 799.95, token/sec:655402.62, hellaswag_acc: 0.2821
Step:  7479, loss: 3.247686, norm: 0.2674, time(ms): 800.64, token/sec:654836.04, hellaswag_acc: 0.2821
Step:  7480, loss: 3.292876, norm: 0.2740, time(ms): 798.11, token/sec:656914.30, hellaswag_acc: 0.2821
Step:  7481, loss: 3.253675, norm: 0.2751, time(ms): 795.05, token/sec:659439.97, hellaswag_acc: 0.2821
Step:  7482, loss: 3.307169, norm: 0.2745, time(ms): 792.39, token/sec:661653.89, hellaswag_acc: 0.2821
Step:  7483, loss: 3.321153, norm: 0.3125, time(ms): 793.45, token/sec:660768.57, hellaswag_acc: 0.2821
Step:  7484, loss: 3.247648, norm: 0.2795, time(ms): 796.65, token/sec:658116.31, hellaswag_acc: 0.2821
Step:  7485, loss: 3.258014, norm: 0.2723, time(ms): 800.62, token/sec:654853.98, hellaswag_acc: 0.2821
Step:  7486, loss: 3.207641, norm: 0.2603, time(ms): 799.88, token/sec:655455.17, hellaswag_acc: 0.2821
Step:  7487, loss: 3.281384, norm: 0.2726, time(ms): 799.73, token/sec:655580.03, hellaswag_acc: 0.2821
Step:  7488, loss: 3.259002, norm: 0.2852, time(ms): 796.44, token/sec:658290.66, hellaswag_acc: 0.2821
Step:  7489, loss: 3.233231, norm: 0.2609, time(ms): 789.45, token/sec:664119.12, hellaswag_acc: 0.2821
Step:  7490, loss: 3.254615, norm: 0.2767, time(ms): 788.88, token/sec:664599.22, hellaswag_acc: 0.2821
Step:  7491, loss: 3.221860, norm: 0.2409, time(ms): 791.18, token/sec:662668.18, hellaswag_acc: 0.2821
Step:  7492, loss: 3.177167, norm: 0.2495, time(ms): 791.10, token/sec:662734.48, hellaswag_acc: 0.2821
Step:  7493, loss: 3.274648, norm: 0.2765, time(ms): 800.41, token/sec:655027.79, hellaswag_acc: 0.2821
Step:  7494, loss: 3.255916, norm: 0.2983, time(ms): 803.36, token/sec:652618.43, hellaswag_acc: 0.2821
Step:  7495, loss: 3.241598, norm: 0.2848, time(ms): 803.07, token/sec:652853.45, hellaswag_acc: 0.2821
Step:  7496, loss: 3.222394, norm: 0.2952, time(ms): 798.28, token/sec:656775.79, hellaswag_acc: 0.2821
Step:  7497, loss: 3.250593, norm: 0.2890, time(ms): 795.30, token/sec:659236.94, hellaswag_acc: 0.2821
Step:  7498, loss: 3.269655, norm: 0.3138, time(ms): 805.12, token/sec:651195.27, hellaswag_acc: 0.2821
Step:  7499, loss: 3.231635, norm: 0.2757, time(ms): 792.29, token/sec:661734.93, hellaswag_acc: 0.2821
rank 0 sample 0: Hello, I'm a language model, and I'd like you to have more on these and explain the importance of these words to you to help you understand and
rank 0 sample 1: Hello, I'm a language model, I do not know. I can try to figure out an answer that gives an explanation of my own point of view.
rank 0 sample 2: Hello, I'm a language model, I'm like to help in coding the language you're using today."
The new method of learning the language has revolution
rank 0 sample 3: Hello, I'm a language model, you and me can't tell me whether or not I'm making progress toward my education. This is exactly what happens."
rank 1 sample 0: Hello, I'm a language model, there is a lot of jargon here's an open problem on any language. Here's my dictionary definition:
- A
rank 1 sample 1: Hello, I'm a language model, not an expert in the language modeling profession. I'm sure that every language model has three criteria for its ability to be
rank 1 sample 2: Hello, I'm a language model, but
the more I learn, the more I can
change. And I'm not as a native
to New
rank 1 sample 3: Hello, I'm a language model, and I'm using the old grammar from Spanish. I did that yesterday for several weeks until I realized that I would be
Step:  7500, loss: 3.257930, norm: 0.2916, time(ms): 3778.37, token/sec:138760.39, val_loss: 3.2529, hellaswag_acc: 0.2821
Step:  7501, loss: 3.262619, norm: 0.2861, time(ms): 793.21, token/sec:660972.14, hellaswag_acc: 0.2821
Step:  7502, loss: 3.218610, norm: 0.2840, time(ms): 787.37, token/sec:665868.86, hellaswag_acc: 0.2821
Step:  7503, loss: 3.274384, norm: 0.2847, time(ms): 798.37, token/sec:656697.14, hellaswag_acc: 0.2821
Step:  7504, loss: 3.343612, norm: 0.3604, time(ms): 791.95, token/sec:662018.41, hellaswag_acc: 0.2821
Step:  7505, loss: 3.311394, norm: 0.3796, time(ms): 791.68, token/sec:662243.90, hellaswag_acc: 0.2821
Step:  7506, loss: 3.337463, norm: 0.3131, time(ms): 782.94, token/sec:669638.32, hellaswag_acc: 0.2821
Step:  7507, loss: 3.346580, norm: 0.2815, time(ms): 792.71, token/sec:661387.83, hellaswag_acc: 0.2821
Step:  7508, loss: 3.296547, norm: 0.2992, time(ms): 790.52, token/sec:663216.79, hellaswag_acc: 0.2821
Step:  7509, loss: 3.254668, norm: 0.3180, time(ms): 799.00, token/sec:656178.05, hellaswag_acc: 0.2821
Step:  7510, loss: 3.232062, norm: 0.2943, time(ms): 790.79, token/sec:662996.43, hellaswag_acc: 0.2821
Step:  7511, loss: 3.300098, norm: 0.2640, time(ms): 796.34, token/sec:658372.65, hellaswag_acc: 0.2821
Step:  7512, loss: 3.267710, norm: 0.2885, time(ms): 791.24, token/sec:662613.26, hellaswag_acc: 0.2821
Step:  7513, loss: 3.241437, norm: 0.2758, time(ms): 787.08, token/sec:666121.39, hellaswag_acc: 0.2821
Step:  7514, loss: 3.350778, norm: 0.7851, time(ms): 791.76, token/sec:662178.69, hellaswag_acc: 0.2821
Step:  7515, loss: 3.261463, norm: 0.4485, time(ms): 798.31, token/sec:656751.27, hellaswag_acc: 0.2821
Step:  7516, loss: 3.268436, norm: 0.3445, time(ms): 803.72, token/sec:652329.78, hellaswag_acc: 0.2821
Step:  7517, loss: 3.244930, norm: 0.3117, time(ms): 797.99, token/sec:657013.22, hellaswag_acc: 0.2821
Step:  7518, loss: 3.270349, norm: 0.3008, time(ms): 794.23, token/sec:660123.32, hellaswag_acc: 0.2821
Step:  7519, loss: 3.337241, norm: 0.3167, time(ms): 802.88, token/sec:653010.87, hellaswag_acc: 0.2821
Step:  7520, loss: 3.202133, norm: 0.2975, time(ms): 802.29, token/sec:653489.81, hellaswag_acc: 0.2821
Step:  7521, loss: 3.273580, norm: 0.3088, time(ms): 793.82, token/sec:660463.93, hellaswag_acc: 0.2821
Step:  7522, loss: 3.210638, norm: 0.3464, time(ms): 791.61, token/sec:662308.13, hellaswag_acc: 0.2821
Step:  7523, loss: 3.236170, norm: 0.2820, time(ms): 793.02, token/sec:661130.52, hellaswag_acc: 0.2821
Step:  7524, loss: 3.267069, norm: 0.2967, time(ms): 797.63, token/sec:657307.02, hellaswag_acc: 0.2821
Step:  7525, loss: 3.331375, norm: 0.2879, time(ms): 797.07, token/sec:657766.70, hellaswag_acc: 0.2821
Step:  7526, loss: 3.216234, norm: 0.2958, time(ms): 789.48, token/sec:664089.24, hellaswag_acc: 0.2821
Step:  7527, loss: 3.245024, norm: 0.2868, time(ms): 784.51, token/sec:668303.30, hellaswag_acc: 0.2821
Step:  7528, loss: 3.217639, norm: 0.2659, time(ms): 792.61, token/sec:661471.19, hellaswag_acc: 0.2821
Step:  7529, loss: 3.241109, norm: 0.2754, time(ms): 798.24, token/sec:656805.02, hellaswag_acc: 0.2821
Step:  7530, loss: 3.303828, norm: 0.2565, time(ms): 800.88, token/sec:654641.30, hellaswag_acc: 0.2821
Step:  7531, loss: 3.250885, norm: 0.3074, time(ms): 801.54, token/sec:654098.60, hellaswag_acc: 0.2821
Step:  7532, loss: 3.230522, norm: 0.2564, time(ms): 794.75, token/sec:659689.82, hellaswag_acc: 0.2821
Step:  7533, loss: 3.195727, norm: 0.2880, time(ms): 803.23, token/sec:652723.42, hellaswag_acc: 0.2821
Step:  7534, loss: 3.223463, norm: 0.2660, time(ms): 803.11, token/sec:652821.86, hellaswag_acc: 0.2821
Step:  7535, loss: 3.209751, norm: 0.2603, time(ms): 798.63, token/sec:656484.62, hellaswag_acc: 0.2821
Step:  7536, loss: 3.210713, norm: 0.2724, time(ms): 795.95, token/sec:658694.10, hellaswag_acc: 0.2821
Step:  7537, loss: 3.242461, norm: 0.2642, time(ms): 801.21, token/sec:654373.25, hellaswag_acc: 0.2821
Step:  7538, loss: 3.202061, norm: 0.2698, time(ms): 803.20, token/sec:652749.97, hellaswag_acc: 0.2821
Step:  7539, loss: 3.262839, norm: 0.2736, time(ms): 791.27, token/sec:662586.71, hellaswag_acc: 0.2821
Step:  7540, loss: 3.236039, norm: 0.2531, time(ms): 805.91, token/sec:650555.10, hellaswag_acc: 0.2821
Step:  7541, loss: 3.242240, norm: 0.2638, time(ms): 801.31, token/sec:654285.05, hellaswag_acc: 0.2821
Step:  7542, loss: 3.249808, norm: 0.2857, time(ms): 798.58, token/sec:656524.21, hellaswag_acc: 0.2821
Step:  7543, loss: 3.288502, norm: 0.2826, time(ms): 791.07, token/sec:662756.05, hellaswag_acc: 0.2821
Step:  7544, loss: 3.271150, norm: 0.2842, time(ms): 791.68, token/sec:662251.48, hellaswag_acc: 0.2821
Step:  7545, loss: 3.285497, norm: 0.2743, time(ms): 788.91, token/sec:664573.31, hellaswag_acc: 0.2821
Step:  7546, loss: 3.294372, norm: 0.2783, time(ms): 791.81, token/sec:662135.23, hellaswag_acc: 0.2821
Step:  7547, loss: 3.339099, norm: 0.2873, time(ms): 787.28, token/sec:665945.89, hellaswag_acc: 0.2821
Step:  7548, loss: 3.252328, norm: 0.3190, time(ms): 792.55, token/sec:661518.74, hellaswag_acc: 0.2821
Step:  7549, loss: 3.305754, norm: 0.2776, time(ms): 794.23, token/sec:660124.70, hellaswag_acc: 0.2821
Step:  7550, loss: 3.326250, norm: 0.2932, time(ms): 798.54, token/sec:656556.16, hellaswag_acc: 0.2821
Step:  7551, loss: 3.338784, norm: 0.3213, time(ms): 788.82, token/sec:664646.63, hellaswag_acc: 0.2821
Step:  7552, loss: 3.290619, norm: 0.2707, time(ms): 785.67, token/sec:667313.21, hellaswag_acc: 0.2821
Step:  7553, loss: 3.202586, norm: 0.3102, time(ms): 789.35, token/sec:664198.95, hellaswag_acc: 0.2821
Step:  7554, loss: 3.202914, norm: 0.2537, time(ms): 799.74, token/sec:655569.09, hellaswag_acc: 0.2821
Step:  7555, loss: 3.237745, norm: 0.3048, time(ms): 795.04, token/sec:659450.85, hellaswag_acc: 0.2821
Step:  7556, loss: 3.318670, norm: 0.2637, time(ms): 801.11, token/sec:654452.90, hellaswag_acc: 0.2821
Step:  7557, loss: 3.262751, norm: 0.2908, time(ms): 802.90, token/sec:652994.58, hellaswag_acc: 0.2821
Step:  7558, loss: 3.269956, norm: 0.2785, time(ms): 798.93, token/sec:656236.80, hellaswag_acc: 0.2821
Step:  7559, loss: 3.302514, norm: 0.2999, time(ms): 800.71, token/sec:654774.82, hellaswag_acc: 0.2821
Step:  7560, loss: 3.210228, norm: 0.2661, time(ms): 799.90, token/sec:655442.08, hellaswag_acc: 0.2821
Step:  7561, loss: 3.249386, norm: 0.2717, time(ms): 795.02, token/sec:659461.72, hellaswag_acc: 0.2821
Step:  7562, loss: 3.291286, norm: 0.2964, time(ms): 802.35, token/sec:653440.48, hellaswag_acc: 0.2821
Step:  7563, loss: 3.248416, norm: 0.2528, time(ms): 801.93, token/sec:653781.23, hellaswag_acc: 0.2821
Step:  7564, loss: 3.245506, norm: 0.2861, time(ms): 799.25, token/sec:655974.48, hellaswag_acc: 0.2821
Step:  7565, loss: 3.230171, norm: 0.2853, time(ms): 795.88, token/sec:658752.12, hellaswag_acc: 0.2821
Step:  7566, loss: 3.243001, norm: 0.2891, time(ms): 803.03, token/sec:652884.08, hellaswag_acc: 0.2821
Step:  7567, loss: 3.266504, norm: 0.2848, time(ms): 800.19, token/sec:655205.78, hellaswag_acc: 0.2821
Step:  7568, loss: 3.288351, norm: 0.2955, time(ms): 799.77, token/sec:655551.70, hellaswag_acc: 0.2821
Step:  7569, loss: 3.220555, norm: 0.2895, time(ms): 800.54, token/sec:654913.86, hellaswag_acc: 0.2821
Step:  7570, loss: 3.310612, norm: 0.3204, time(ms): 799.50, token/sec:655770.65, hellaswag_acc: 0.2821
Step:  7571, loss: 3.234637, norm: 0.2964, time(ms): 800.54, token/sec:654915.22, hellaswag_acc: 0.2821
Step:  7572, loss: 3.271148, norm: 0.2843, time(ms): 800.08, token/sec:655298.13, hellaswag_acc: 0.2821
Step:  7573, loss: 3.230303, norm: 0.2949, time(ms): 798.16, token/sec:656874.66, hellaswag_acc: 0.2821
Step:  7574, loss: 3.238591, norm: 0.2588, time(ms): 801.34, token/sec:654266.16, hellaswag_acc: 0.2821
Step:  7575, loss: 3.227602, norm: 0.2858, time(ms): 799.27, token/sec:655955.50, hellaswag_acc: 0.2821
Step:  7576, loss: 3.295405, norm: 0.3154, time(ms): 799.62, token/sec:655671.12, hellaswag_acc: 0.2821
Step:  7577, loss: 3.319930, norm: 0.3346, time(ms): 800.55, token/sec:654909.76, hellaswag_acc: 0.2821
Step:  7578, loss: 3.300085, norm: 0.3088, time(ms): 794.30, token/sec:660060.31, hellaswag_acc: 0.2821
Step:  7579, loss: 3.207878, norm: 0.2968, time(ms): 802.01, token/sec:653718.85, hellaswag_acc: 0.2821
Step:  7580, loss: 3.210349, norm: 0.2900, time(ms): 802.41, token/sec:653390.78, hellaswag_acc: 0.2821
Step:  7581, loss: 3.272323, norm: 0.3160, time(ms): 796.36, token/sec:658357.48, hellaswag_acc: 0.2821
Step:  7582, loss: 3.290514, norm: 0.3004, time(ms): 803.13, token/sec:652803.06, hellaswag_acc: 0.2821
Step:  7583, loss: 3.226697, norm: 0.3106, time(ms): 797.72, token/sec:657229.03, hellaswag_acc: 0.2821
Step:  7584, loss: 3.256687, norm: 0.2649, time(ms): 798.71, token/sec:656420.54, hellaswag_acc: 0.2821
Step:  7585, loss: 3.282207, norm: 0.2867, time(ms): 803.14, token/sec:652795.89, hellaswag_acc: 0.2821
Step:  7586, loss: 3.303887, norm: 0.2753, time(ms): 795.09, token/sec:659403.98, hellaswag_acc: 0.2821
Step:  7587, loss: 3.229202, norm: 0.2872, time(ms): 795.25, token/sec:659271.53, hellaswag_acc: 0.2821
Step:  7588, loss: 3.200526, norm: 0.2899, time(ms): 790.23, token/sec:663465.51, hellaswag_acc: 0.2821
Step:  7589, loss: 3.286817, norm: 0.2771, time(ms): 786.39, token/sec:666705.05, hellaswag_acc: 0.2821
Step:  7590, loss: 3.259149, norm: 0.2812, time(ms): 788.52, token/sec:664900.85, hellaswag_acc: 0.2821
Step:  7591, loss: 3.249048, norm: 0.2547, time(ms): 802.50, token/sec:653320.12, hellaswag_acc: 0.2821
Step:  7592, loss: 3.228675, norm: 0.2535, time(ms): 801.55, token/sec:654095.88, hellaswag_acc: 0.2821
Step:  7593, loss: 3.224223, norm: 0.2493, time(ms): 791.14, token/sec:662701.13, hellaswag_acc: 0.2821
Step:  7594, loss: 3.243750, norm: 0.2560, time(ms): 792.18, token/sec:661831.72, hellaswag_acc: 0.2821
Step:  7595, loss: 3.244493, norm: 0.2782, time(ms): 792.92, token/sec:661210.44, hellaswag_acc: 0.2821
Step:  7596, loss: 3.243537, norm: 0.2330, time(ms): 799.70, token/sec:655601.93, hellaswag_acc: 0.2821
Step:  7597, loss: 3.233272, norm: 0.2661, time(ms): 801.76, token/sec:653919.27, hellaswag_acc: 0.2821
Step:  7598, loss: 3.232552, norm: 0.2603, time(ms): 798.92, token/sec:656246.00, hellaswag_acc: 0.2821
Step:  7599, loss: 3.267164, norm: 0.2701, time(ms): 793.27, token/sec:660916.32, hellaswag_acc: 0.2821
Step:  7600, loss: 3.298929, norm: 0.3216, time(ms): 791.13, token/sec:662703.72, hellaswag_acc: 0.2821
Step:  7601, loss: 3.196530, norm: 0.2792, time(ms): 789.74, token/sec:663877.72, hellaswag_acc: 0.2821
Step:  7602, loss: 3.222885, norm: 0.2719, time(ms): 793.25, token/sec:660932.81, hellaswag_acc: 0.2821
Step:  7603, loss: 3.245713, norm: 0.2787, time(ms): 790.68, token/sec:663088.40, hellaswag_acc: 0.2821
Step:  7604, loss: 3.241281, norm: 0.2824, time(ms): 802.83, token/sec:653049.85, hellaswag_acc: 0.2821
Step:  7605, loss: 3.238430, norm: 0.3611, time(ms): 800.55, token/sec:654908.59, hellaswag_acc: 0.2821
Step:  7606, loss: 3.231590, norm: 0.3056, time(ms): 799.46, token/sec:655804.68, hellaswag_acc: 0.2821
Step:  7607, loss: 3.259482, norm: 0.2994, time(ms): 799.16, token/sec:656052.37, hellaswag_acc: 0.2821
Step:  7608, loss: 3.301125, norm: 0.3218, time(ms): 798.97, token/sec:656204.49, hellaswag_acc: 0.2821
Step:  7609, loss: 3.224559, norm: 0.3249, time(ms): 800.15, token/sec:655236.04, hellaswag_acc: 0.2821
Step:  7610, loss: 3.299452, norm: 0.3058, time(ms): 797.53, token/sec:657386.60, hellaswag_acc: 0.2821
Step:  7611, loss: 3.230955, norm: 0.3159, time(ms): 801.25, token/sec:654338.59, hellaswag_acc: 0.2821
Step:  7612, loss: 3.267782, norm: 0.3058, time(ms): 797.49, token/sec:657422.37, hellaswag_acc: 0.2821
Step:  7613, loss: 3.241272, norm: 0.3048, time(ms): 803.94, token/sec:652150.06, hellaswag_acc: 0.2821
Step:  7614, loss: 3.268520, norm: 0.2882, time(ms): 795.72, token/sec:658881.40, hellaswag_acc: 0.2821
Step:  7615, loss: 3.248220, norm: 0.2588, time(ms): 805.65, token/sec:650760.13, hellaswag_acc: 0.2821
Step:  7616, loss: 3.275141, norm: 0.2670, time(ms): 798.91, token/sec:656251.09, hellaswag_acc: 0.2821
Step:  7617, loss: 3.224680, norm: 0.2771, time(ms): 794.67, token/sec:659751.97, hellaswag_acc: 0.2821
Step:  7618, loss: 3.334576, norm: 0.2928, time(ms): 802.97, token/sec:652938.55, hellaswag_acc: 0.2821
Step:  7619, loss: 3.263465, norm: 0.2924, time(ms): 1334.12, token/sec:392983.08, hellaswag_acc: 0.2821
Step:  7620, loss: 3.241686, norm: 0.2869, time(ms): 771.94, token/sec:679183.58, hellaswag_acc: 0.2821
Step:  7621, loss: 3.224142, norm: 0.2453, time(ms): 797.17, token/sec:657684.66, hellaswag_acc: 0.2821
Step:  7622, loss: 3.257471, norm: 0.2958, time(ms): 798.13, token/sec:656897.03, hellaswag_acc: 0.2821
Step:  7623, loss: 3.326913, norm: 0.2721, time(ms): 783.66, token/sec:669025.91, hellaswag_acc: 0.2821
Step:  7624, loss: 3.212986, norm: 0.2663, time(ms): 783.65, token/sec:669030.79, hellaswag_acc: 0.2821
Step:  7625, loss: 3.226274, norm: 0.2872, time(ms): 788.53, token/sec:664891.20, hellaswag_acc: 0.2821
Step:  7626, loss: 3.243854, norm: 0.2747, time(ms): 801.75, token/sec:653926.46, hellaswag_acc: 0.2821
Step:  7627, loss: 3.260169, norm: 0.2731, time(ms): 800.67, token/sec:654810.11, hellaswag_acc: 0.2821
Step:  7628, loss: 3.232265, norm: 0.2549, time(ms): 792.02, token/sec:661963.01, hellaswag_acc: 0.2821
Step:  7629, loss: 3.299469, norm: 0.2616, time(ms): 793.36, token/sec:660841.84, hellaswag_acc: 0.2821
Step:  7630, loss: 3.204801, norm: 0.2674, time(ms): 794.67, token/sec:659755.93, hellaswag_acc: 0.2821
Step:  7631, loss: 3.222260, norm: 0.2688, time(ms): 790.20, token/sec:663487.73, hellaswag_acc: 0.2821
Step:  7632, loss: 3.184947, norm: 0.3001, time(ms): 790.00, token/sec:663657.33, hellaswag_acc: 0.2821
Step:  7633, loss: 3.285245, norm: 0.2431, time(ms): 791.48, token/sec:662417.46, hellaswag_acc: 0.2821
Step:  7634, loss: 3.268836, norm: 0.2826, time(ms): 790.99, token/sec:662823.37, hellaswag_acc: 0.2821
Step:  7635, loss: 3.194838, norm: 0.2653, time(ms): 786.64, token/sec:666486.81, hellaswag_acc: 0.2821
Step:  7636, loss: 3.333415, norm: 0.3027, time(ms): 790.38, token/sec:663339.82, hellaswag_acc: 0.2821
Step:  7637, loss: 3.278706, norm: 0.3288, time(ms): 790.71, token/sec:663062.60, hellaswag_acc: 0.2821
Step:  7638, loss: 3.232184, norm: 0.2563, time(ms): 790.73, token/sec:663039.61, hellaswag_acc: 0.2821
Step:  7639, loss: 3.272806, norm: 0.2813, time(ms): 790.58, token/sec:663166.18, hellaswag_acc: 0.2821
Step:  7640, loss: 3.293483, norm: 0.2880, time(ms): 794.80, token/sec:659651.63, hellaswag_acc: 0.2821
Step:  7641, loss: 3.190263, norm: 0.3003, time(ms): 792.07, token/sec:661923.36, hellaswag_acc: 0.2821
Step:  7642, loss: 3.253964, norm: 0.2840, time(ms): 797.96, token/sec:657033.05, hellaswag_acc: 0.2821
Step:  7643, loss: 3.207027, norm: 0.2930, time(ms): 788.67, token/sec:664778.64, hellaswag_acc: 0.2821
Step:  7644, loss: 3.297477, norm: 0.3199, time(ms): 786.42, token/sec:666676.75, hellaswag_acc: 0.2821
Step:  7645, loss: 3.269227, norm: 0.2752, time(ms): 790.83, token/sec:662961.45, hellaswag_acc: 0.2821
Step:  7646, loss: 3.214388, norm: 0.2908, time(ms): 795.44, token/sec:659113.84, hellaswag_acc: 0.2821
Step:  7647, loss: 3.206067, norm: 0.2831, time(ms): 794.93, token/sec:659538.07, hellaswag_acc: 0.2821
Step:  7648, loss: 3.260936, norm: 0.3355, time(ms): 799.48, token/sec:655782.19, hellaswag_acc: 0.2821
Step:  7649, loss: 3.276703, norm: 0.2732, time(ms): 805.76, token/sec:650672.52, hellaswag_acc: 0.2821
Step:  7650, loss: 3.256715, norm: 0.3056, time(ms): 797.14, token/sec:657713.97, hellaswag_acc: 0.2821
Step:  7651, loss: 3.254498, norm: 0.2825, time(ms): 793.32, token/sec:660879.58, hellaswag_acc: 0.2821
Step:  7652, loss: 3.206560, norm: 0.2929, time(ms): 799.80, token/sec:655520.63, hellaswag_acc: 0.2821
Step:  7653, loss: 3.275872, norm: 0.2729, time(ms): 791.03, token/sec:662789.81, hellaswag_acc: 0.2821
Step:  7654, loss: 3.238041, norm: 0.2773, time(ms): 787.51, token/sec:665754.76, hellaswag_acc: 0.2821
Step:  7655, loss: 3.241282, norm: 0.2574, time(ms): 791.14, token/sec:662698.13, hellaswag_acc: 0.2821
Step:  7656, loss: 3.194128, norm: 0.2693, time(ms): 790.11, token/sec:663564.61, hellaswag_acc: 0.2821
Step:  7657, loss: 3.266590, norm: 0.2722, time(ms): 801.85, token/sec:653851.99, hellaswag_acc: 0.2821
Step:  7658, loss: 3.287485, norm: 0.2743, time(ms): 803.71, token/sec:652336.36, hellaswag_acc: 0.2821
Step:  7659, loss: 3.239147, norm: 0.2626, time(ms): 801.12, token/sec:654441.41, hellaswag_acc: 0.2821
Step:  7660, loss: 3.162294, norm: 0.2666, time(ms): 790.02, token/sec:663638.10, hellaswag_acc: 0.2821
Step:  7661, loss: 3.254091, norm: 0.2843, time(ms): 791.02, token/sec:662801.80, hellaswag_acc: 0.2821
Step:  7662, loss: 3.216895, norm: 0.2910, time(ms): 797.04, token/sec:657792.87, hellaswag_acc: 0.2821
Step:  7663, loss: 3.205246, norm: 0.2626, time(ms): 792.25, token/sec:661768.39, hellaswag_acc: 0.2821
Step:  7664, loss: 3.203559, norm: 0.2661, time(ms): 790.60, token/sec:663151.38, hellaswag_acc: 0.2821
Step:  7665, loss: 3.242631, norm: 0.2766, time(ms): 786.13, token/sec:666924.84, hellaswag_acc: 0.2821
Step:  7666, loss: 3.232810, norm: 0.2537, time(ms): 792.51, token/sec:661557.55, hellaswag_acc: 0.2821
Step:  7667, loss: 3.247939, norm: 0.2438, time(ms): 798.51, token/sec:656583.61, hellaswag_acc: 0.2821
Step:  7668, loss: 3.232160, norm: 0.2624, time(ms): 800.32, token/sec:655097.25, hellaswag_acc: 0.2821
Step:  7669, loss: 3.214530, norm: 0.2469, time(ms): 801.48, token/sec:654151.14, hellaswag_acc: 0.2821
Step:  7670, loss: 3.221028, norm: 0.2614, time(ms): 797.14, token/sec:657708.46, hellaswag_acc: 0.2821
Step:  7671, loss: 3.250657, norm: 0.2597, time(ms): 789.76, token/sec:663857.88, hellaswag_acc: 0.2821
Step:  7672, loss: 3.263318, norm: 0.2867, time(ms): 790.80, token/sec:662981.64, hellaswag_acc: 0.2821
Step:  7673, loss: 3.243451, norm: 0.2668, time(ms): 791.35, token/sec:662526.82, hellaswag_acc: 0.2821
Step:  7674, loss: 3.241324, norm: 0.2567, time(ms): 791.22, token/sec:662629.04, hellaswag_acc: 0.2821
Step:  7675, loss: 3.266479, norm: 0.2908, time(ms): 792.39, token/sec:661657.87, hellaswag_acc: 0.2821
Step:  7676, loss: 3.254090, norm: 0.2807, time(ms): 796.54, token/sec:658204.56, hellaswag_acc: 0.2821
Step:  7677, loss: 3.259353, norm: 0.2543, time(ms): 792.45, token/sec:661600.54, hellaswag_acc: 0.2821
Step:  7678, loss: 3.276150, norm: 0.2794, time(ms): 789.03, token/sec:664470.30, hellaswag_acc: 0.2821
Step:  7679, loss: 3.198209, norm: 0.2542, time(ms): 792.17, token/sec:661841.08, hellaswag_acc: 0.2821
Step:  7680, loss: 3.242581, norm: 0.2823, time(ms): 789.35, token/sec:664198.75, hellaswag_acc: 0.2821
Step:  7681, loss: 3.267654, norm: 0.2916, time(ms): 796.26, token/sec:658439.68, hellaswag_acc: 0.2821
Step:  7682, loss: 3.258982, norm: 0.3054, time(ms): 790.51, token/sec:663223.39, hellaswag_acc: 0.2821
Step:  7683, loss: 3.286245, norm: 0.3283, time(ms): 798.78, token/sec:656362.94, hellaswag_acc: 0.2821
Step:  7684, loss: 3.260469, norm: 0.3052, time(ms): 783.52, token/sec:669147.24, hellaswag_acc: 0.2821
Step:  7685, loss: 3.213741, norm: 0.2679, time(ms): 790.29, token/sec:663408.66, hellaswag_acc: 0.2821
Step:  7686, loss: 3.198290, norm: 0.2887, time(ms): 796.65, token/sec:658116.31, hellaswag_acc: 0.2821
Step:  7687, loss: 3.291607, norm: 0.2579, time(ms): 791.78, token/sec:662165.73, hellaswag_acc: 0.2821
Step:  7688, loss: 3.297559, norm: 0.2866, time(ms): 786.74, token/sec:666408.85, hellaswag_acc: 0.2821
Step:  7689, loss: 3.258749, norm: 0.3160, time(ms): 790.47, token/sec:663260.79, hellaswag_acc: 0.2821
Step:  7690, loss: 3.203556, norm: 0.3187, time(ms): 797.17, token/sec:657682.50, hellaswag_acc: 0.2821
Step:  7691, loss: 3.272940, norm: 0.3378, time(ms): 798.56, token/sec:656540.48, hellaswag_acc: 0.2821
Step:  7692, loss: 3.247197, norm: 0.2731, time(ms): 797.42, token/sec:657478.39, hellaswag_acc: 0.2821
Step:  7693, loss: 3.193941, norm: 0.3287, time(ms): 793.83, token/sec:660456.99, hellaswag_acc: 0.2821
Step:  7694, loss: 3.219390, norm: 0.3257, time(ms): 788.86, token/sec:664611.48, hellaswag_acc: 0.2821
Step:  7695, loss: 3.195952, norm: 0.2548, time(ms): 792.66, token/sec:661432.19, hellaswag_acc: 0.2821
Step:  7696, loss: 3.211019, norm: 0.3508, time(ms): 790.94, token/sec:662865.13, hellaswag_acc: 0.2821
Step:  7697, loss: 3.215384, norm: 0.3200, time(ms): 787.38, token/sec:665862.41, hellaswag_acc: 0.2821
Step:  7698, loss: 3.325762, norm: 0.2995, time(ms): 789.44, token/sec:664127.94, hellaswag_acc: 0.2821
Step:  7699, loss: 3.266581, norm: 0.2931, time(ms): 793.10, token/sec:661062.15, hellaswag_acc: 0.2821
Step:  7700, loss: 3.275123, norm: 0.2708, time(ms): 792.49, token/sec:661570.69, hellaswag_acc: 0.2821
Step:  7701, loss: 3.194817, norm: 0.2761, time(ms): 793.88, token/sec:660413.16, hellaswag_acc: 0.2821
Step:  7702, loss: 3.168983, norm: 0.2456, time(ms): 792.34, token/sec:661692.12, hellaswag_acc: 0.2821
Step:  7703, loss: 3.251985, norm: 0.2856, time(ms): 794.28, token/sec:660078.34, hellaswag_acc: 0.2821
Step:  7704, loss: 3.260288, norm: 0.2739, time(ms): 794.42, token/sec:659966.61, hellaswag_acc: 0.2821
Step:  7705, loss: 3.316828, norm: 0.2825, time(ms): 793.63, token/sec:660623.66, hellaswag_acc: 0.2821
Step:  7706, loss: 3.325256, norm: 0.3157, time(ms): 799.12, token/sec:656081.34, hellaswag_acc: 0.2821
Step:  7707, loss: 3.284755, norm: 0.2785, time(ms): 789.81, token/sec:663811.59, hellaswag_acc: 0.2821
Step:  7708, loss: 3.259201, norm: 0.3191, time(ms): 788.67, token/sec:664772.21, hellaswag_acc: 0.2821
Step:  7709, loss: 3.242807, norm: 0.2904, time(ms): 791.21, token/sec:662640.82, hellaswag_acc: 0.2821
Step:  7710, loss: 3.219159, norm: 0.2734, time(ms): 795.31, token/sec:659224.29, hellaswag_acc: 0.2821
Step:  7711, loss: 3.265621, norm: 0.2733, time(ms): 800.73, token/sec:654763.12, hellaswag_acc: 0.2821
Step:  7712, loss: 3.248470, norm: 0.2593, time(ms): 800.49, token/sec:654955.80, hellaswag_acc: 0.2821
Step:  7713, loss: 3.245238, norm: 0.2879, time(ms): 799.99, token/sec:655364.73, hellaswag_acc: 0.2821
Step:  7714, loss: 3.213932, norm: 0.2520, time(ms): 796.42, token/sec:658304.85, hellaswag_acc: 0.2821
Step:  7715, loss: 3.272326, norm: 0.3388, time(ms): 800.62, token/sec:654854.18, hellaswag_acc: 0.2821
Step:  7716, loss: 3.327641, norm: 0.3108, time(ms): 798.49, token/sec:656596.74, hellaswag_acc: 0.2821
Step:  7717, loss: 3.271584, norm: 0.2958, time(ms): 803.72, token/sec:652330.55, hellaswag_acc: 0.2821
Step:  7718, loss: 3.240727, norm: 0.2967, time(ms): 794.18, token/sec:660165.33, hellaswag_acc: 0.2821
Step:  7719, loss: 3.247799, norm: 0.2817, time(ms): 795.79, token/sec:658828.69, hellaswag_acc: 0.2821
Step:  7720, loss: 3.286646, norm: 0.3011, time(ms): 791.72, token/sec:662217.78, hellaswag_acc: 0.2821
Step:  7721, loss: 3.280019, norm: 0.2831, time(ms): 787.49, token/sec:665767.86, hellaswag_acc: 0.2821
Step:  7722, loss: 3.258979, norm: 0.3047, time(ms): 792.40, token/sec:661644.54, hellaswag_acc: 0.2821
Step:  7723, loss: 3.227465, norm: 0.2759, time(ms): 788.94, token/sec:664544.39, hellaswag_acc: 0.2821
Step:  7724, loss: 3.208083, norm: 0.3100, time(ms): 804.26, token/sec:651885.39, hellaswag_acc: 0.2821
Step:  7725, loss: 3.290246, norm: 0.2718, time(ms): 804.17, token/sec:651961.93, hellaswag_acc: 0.2821
Step:  7726, loss: 3.305069, norm: 0.2958, time(ms): 795.85, token/sec:658780.34, hellaswag_acc: 0.2821
Step:  7727, loss: 3.253623, norm: 0.2524, time(ms): 794.57, token/sec:659840.07, hellaswag_acc: 0.2821
Step:  7728, loss: 3.234729, norm: 0.2831, time(ms): 791.24, token/sec:662612.67, hellaswag_acc: 0.2821
Step:  7729, loss: 3.227882, norm: 0.2524, time(ms): 791.90, token/sec:662063.26, hellaswag_acc: 0.2821
Step:  7730, loss: 3.245875, norm: 0.2623, time(ms): 795.60, token/sec:658982.29, hellaswag_acc: 0.2821
Step:  7731, loss: 3.230447, norm: 0.2784, time(ms): 787.97, token/sec:665364.37, hellaswag_acc: 0.2821
Step:  7732, loss: 3.194720, norm: 0.2721, time(ms): 791.82, token/sec:662133.43, hellaswag_acc: 0.2821
Step:  7733, loss: 3.224004, norm: 0.2477, time(ms): 789.63, token/sec:663964.92, hellaswag_acc: 0.2821
Step:  7734, loss: 3.229563, norm: 0.2782, time(ms): 796.41, token/sec:658317.47, hellaswag_acc: 0.2821
Step:  7735, loss: 3.224897, norm: 0.2576, time(ms): 789.41, token/sec:664149.00, hellaswag_acc: 0.2821
Step:  7736, loss: 3.247823, norm: 0.2688, time(ms): 791.44, token/sec:662447.19, hellaswag_acc: 0.2821
Step:  7737, loss: 3.194327, norm: 0.2881, time(ms): 792.17, token/sec:661838.49, hellaswag_acc: 0.2821
Step:  7738, loss: 3.197056, norm: 0.2883, time(ms): 791.12, token/sec:662712.31, hellaswag_acc: 0.2821
Step:  7739, loss: 3.215740, norm: 0.3222, time(ms): 795.38, token/sec:659166.39, hellaswag_acc: 0.2821
Step:  7740, loss: 3.253201, norm: 0.2824, time(ms): 798.11, token/sec:656909.59, hellaswag_acc: 0.2821
Step:  7741, loss: 3.318355, norm: 0.2919, time(ms): 799.97, token/sec:655383.48, hellaswag_acc: 0.2821
Step:  7742, loss: 3.251234, norm: 0.3169, time(ms): 803.52, token/sec:652488.50, hellaswag_acc: 0.2821
Step:  7743, loss: 3.267954, norm: 0.2964, time(ms): 794.04, token/sec:660277.92, hellaswag_acc: 0.2821
Step:  7744, loss: 3.233604, norm: 0.2783, time(ms): 796.85, token/sec:657947.76, hellaswag_acc: 0.2821
Step:  7745, loss: 3.239004, norm: 0.3070, time(ms): 791.44, token/sec:662448.59, hellaswag_acc: 0.2821
Step:  7746, loss: 3.246653, norm: 0.2735, time(ms): 793.01, token/sec:661136.49, hellaswag_acc: 0.2821
Step:  7747, loss: 3.290038, norm: 0.2987, time(ms): 794.93, token/sec:659539.45, hellaswag_acc: 0.2821
Step:  7748, loss: 3.263346, norm: 0.2939, time(ms): 790.62, token/sec:663136.39, hellaswag_acc: 0.2821
Step:  7749, loss: 3.313625, norm: 0.3435, time(ms): 789.37, token/sec:664187.52, hellaswag_acc: 0.2821
rank 0 sample 0: Hello, I'm a language model, and I need to learn and write, though some of the things you get in the books are actually quite difficult. The
rank 0 sample 1: Hello, I'm a language model, so for me, the grammar of English is very formal — I just go out to see you. What is it about
rank 0 sample 2: Hello, I'm a language model, so I thought it was easy to find a word, and my students have a few, and I'm a little annoyed
rank 0 sample 3: Hello, I'm a language model, and can't help you out, I can answer this question.
In my final problem, you might want to add
rank 1 sample 0: Hello, I'm a language model, and I'm a language model. Since my English teacher wants to teach me his English classes, my English teacher wants me
rank 1 sample 1: Hello, I'm a language model, not an expert in the language. And a lot of students are already looking for, because they've got a lot of
rank 1 sample 2: Hello, I'm a language model, but is the way to go?
I'm a model because the rules are the same for a language model but it
rank 1 sample 3: Hello, I'm a language model, and I'm interested to explore the role some of the principles of science education go beyond for themselves. I'm trying to
Step:  7750, loss: 3.220631, norm: 0.2970, time(ms): 3772.85, token/sec:138963.31, val_loss: 3.2443, hellaswag_acc: 0.2821
Step:  7751, loss: 3.331797, norm: 0.3111, time(ms): 782.02, token/sec:670429.42, hellaswag_acc: 0.2821
Step:  7752, loss: 3.252064, norm: 0.2747, time(ms): 784.47, token/sec:668333.97, hellaswag_acc: 0.2821
Step:  7753, loss: 3.229527, norm: 0.3161, time(ms): 801.51, token/sec:654128.76, hellaswag_acc: 0.2821
Step:  7754, loss: 3.339489, norm: 0.2948, time(ms): 794.75, token/sec:659689.23, hellaswag_acc: 0.2821
Step:  7755, loss: 3.250806, norm: 0.2664, time(ms): 793.62, token/sec:660632.59, hellaswag_acc: 0.2821
Step:  7756, loss: 3.246874, norm: 0.2863, time(ms): 789.58, token/sec:664008.82, hellaswag_acc: 0.2821
Step:  7757, loss: 3.242869, norm: 0.2794, time(ms): 792.95, token/sec:661185.98, hellaswag_acc: 0.2821
Step:  7758, loss: 3.239539, norm: 0.2734, time(ms): 788.62, token/sec:664818.43, hellaswag_acc: 0.2821
Step:  7759, loss: 3.330127, norm: 0.3404, time(ms): 791.69, token/sec:662235.92, hellaswag_acc: 0.2821
Step:  7760, loss: 3.288834, norm: 0.3476, time(ms): 788.31, token/sec:665078.42, hellaswag_acc: 0.2821
Step:  7761, loss: 3.265643, norm: 0.3798, time(ms): 804.63, token/sec:651586.39, hellaswag_acc: 0.2821
Step:  7762, loss: 3.240792, norm: 0.2832, time(ms): 800.24, token/sec:655160.88, hellaswag_acc: 0.2821
Step:  7763, loss: 3.227255, norm: 0.3327, time(ms): 802.81, token/sec:653070.02, hellaswag_acc: 0.2821
Step:  7764, loss: 3.255185, norm: 0.2894, time(ms): 789.80, token/sec:663821.61, hellaswag_acc: 0.2821
Step:  7765, loss: 3.244292, norm: 0.2960, time(ms): 804.81, token/sec:651439.30, hellaswag_acc: 0.2821
Step:  7766, loss: 3.197731, norm: 0.2754, time(ms): 803.39, token/sec:652594.80, hellaswag_acc: 0.2821
Step:  7767, loss: 3.283247, norm: 0.3328, time(ms): 798.14, token/sec:656884.67, hellaswag_acc: 0.2821
Step:  7768, loss: 3.209175, norm: 0.2618, time(ms): 794.64, token/sec:659778.10, hellaswag_acc: 0.2821
Step:  7769, loss: 3.190239, norm: 0.2971, time(ms): 805.49, token/sec:650891.30, hellaswag_acc: 0.2821
Step:  7770, loss: 3.211687, norm: 0.2703, time(ms): 799.05, token/sec:656142.22, hellaswag_acc: 0.2821
Step:  7771, loss: 3.221326, norm: 0.2728, time(ms): 797.62, token/sec:657319.20, hellaswag_acc: 0.2821
Step:  7772, loss: 3.267604, norm: 0.2322, time(ms): 799.79, token/sec:655528.64, hellaswag_acc: 0.2821
Step:  7773, loss: 3.288010, norm: 0.2559, time(ms): 802.28, token/sec:653496.80, hellaswag_acc: 0.2821
Step:  7774, loss: 3.187065, norm: 0.2694, time(ms): 802.95, token/sec:652950.96, hellaswag_acc: 0.2821
Step:  7775, loss: 3.274061, norm: 0.2921, time(ms): 793.48, token/sec:660748.12, hellaswag_acc: 0.2821
Step:  7776, loss: 3.282564, norm: 0.2871, time(ms): 797.39, token/sec:657506.89, hellaswag_acc: 0.2821
Step:  7777, loss: 3.231323, norm: 0.2681, time(ms): 805.92, token/sec:650549.71, hellaswag_acc: 0.2821
Step:  7778, loss: 3.201193, norm: 0.2818, time(ms): 801.60, token/sec:654055.80, hellaswag_acc: 0.2821
Step:  7779, loss: 3.267425, norm: 0.2716, time(ms): 798.88, token/sec:656275.97, hellaswag_acc: 0.2821
Step:  7780, loss: 3.229522, norm: 0.2994, time(ms): 798.30, token/sec:656757.15, hellaswag_acc: 0.2821
Step:  7781, loss: 3.215056, norm: 0.2738, time(ms): 799.87, token/sec:655467.28, hellaswag_acc: 0.2821
Step:  7782, loss: 3.289325, norm: 0.3733, time(ms): 800.89, token/sec:654634.28, hellaswag_acc: 0.2821
Step:  7783, loss: 3.228187, norm: 0.2867, time(ms): 800.74, token/sec:654755.71, hellaswag_acc: 0.2821
Step:  7784, loss: 3.232144, norm: 0.2803, time(ms): 790.71, token/sec:663057.81, hellaswag_acc: 0.2821
Step:  7785, loss: 3.248272, norm: 0.2760, time(ms): 791.32, token/sec:662550.78, hellaswag_acc: 0.2821
Step:  7786, loss: 3.273715, norm: 0.2893, time(ms): 788.19, token/sec:665179.41, hellaswag_acc: 0.2821
Step:  7787, loss: 3.237872, norm: 0.2787, time(ms): 790.44, token/sec:663288.80, hellaswag_acc: 0.2821
Step:  7788, loss: 3.360165, norm: 0.3155, time(ms): 797.43, token/sec:657470.13, hellaswag_acc: 0.2821
Step:  7789, loss: 3.294333, norm: 0.3811, time(ms): 798.70, token/sec:656428.58, hellaswag_acc: 0.2821
Step:  7790, loss: 3.193176, norm: 0.3037, time(ms): 799.37, token/sec:655872.55, hellaswag_acc: 0.2821
Step:  7791, loss: 3.223878, norm: 0.3212, time(ms): 801.81, token/sec:653879.21, hellaswag_acc: 0.2821
Step:  7792, loss: 3.257624, norm: 0.2686, time(ms): 797.65, token/sec:657287.17, hellaswag_acc: 0.2821
Step:  7793, loss: 3.258348, norm: 0.3186, time(ms): 796.29, token/sec:658410.30, hellaswag_acc: 0.2821
Step:  7794, loss: 3.297333, norm: 0.2737, time(ms): 797.02, token/sec:657807.62, hellaswag_acc: 0.2821
Step:  7795, loss: 3.279449, norm: 0.3100, time(ms): 792.26, token/sec:661761.02, hellaswag_acc: 0.2821
Step:  7796, loss: 3.294063, norm: 0.2772, time(ms): 789.04, token/sec:664462.47, hellaswag_acc: 0.2821
Step:  7797, loss: 3.232358, norm: 0.2727, time(ms): 791.09, token/sec:662741.47, hellaswag_acc: 0.2821
Step:  7798, loss: 3.220253, norm: 0.3134, time(ms): 786.59, token/sec:666529.84, hellaswag_acc: 0.2821
Step:  7799, loss: 3.270866, norm: 0.2983, time(ms): 790.06, token/sec:663608.46, hellaswag_acc: 0.2821
Step:  7800, loss: 3.197280, norm: 0.2800, time(ms): 792.40, token/sec:661649.51, hellaswag_acc: 0.2821
Step:  7801, loss: 3.196820, norm: 0.2850, time(ms): 800.57, token/sec:654896.30, hellaswag_acc: 0.2821
Step:  7802, loss: 3.209348, norm: 0.2534, time(ms): 803.72, token/sec:652327.84, hellaswag_acc: 0.2821
Step:  7803, loss: 3.256152, norm: 0.2703, time(ms): 804.10, token/sec:652014.90, hellaswag_acc: 0.2821
Step:  7804, loss: 3.159207, norm: 0.2494, time(ms): 795.53, token/sec:659038.38, hellaswag_acc: 0.2821
Step:  7805, loss: 3.250469, norm: 0.2509, time(ms): 800.62, token/sec:654852.03, hellaswag_acc: 0.2821
Step:  7806, loss: 3.294630, norm: 0.2590, time(ms): 798.60, token/sec:656504.81, hellaswag_acc: 0.2821
Step:  7807, loss: 3.163577, norm: 0.2720, time(ms): 804.61, token/sec:651607.62, hellaswag_acc: 0.2821
Step:  7808, loss: 3.233884, norm: 0.2635, time(ms): 797.21, token/sec:657653.58, hellaswag_acc: 0.2821
Step:  7809, loss: 3.235621, norm: 0.2745, time(ms): 791.00, token/sec:662813.78, hellaswag_acc: 0.2821
Step:  7810, loss: 3.219909, norm: 0.2814, time(ms): 1251.91, token/sec:418790.02, hellaswag_acc: 0.2821
Step:  7811, loss: 3.021940, norm: 0.3051, time(ms): 800.29, token/sec:655121.06, hellaswag_acc: 0.2821
Step:  7812, loss: 3.110744, norm: 0.3052, time(ms): 782.96, token/sec:669620.17, hellaswag_acc: 0.2821
Step:  7813, loss: 3.106207, norm: 0.2934, time(ms): 778.10, token/sec:673803.35, hellaswag_acc: 0.2821
Step:  7814, loss: 3.065799, norm: 0.2654, time(ms): 788.43, token/sec:664976.25, hellaswag_acc: 0.2821
Step:  7815, loss: 3.004080, norm: 0.3123, time(ms): 796.47, token/sec:658266.82, hellaswag_acc: 0.2821
Step:  7816, loss: 3.082079, norm: 0.3369, time(ms): 790.40, token/sec:663322.22, hellaswag_acc: 0.2821
Step:  7817, loss: 3.092541, norm: 0.2955, time(ms): 785.44, token/sec:667509.50, hellaswag_acc: 0.2821
Step:  7818, loss: 3.059680, norm: 0.2882, time(ms): 787.59, token/sec:665682.61, hellaswag_acc: 0.2821
Step:  7819, loss: 3.065543, norm: 0.2880, time(ms): 802.80, token/sec:653072.74, hellaswag_acc: 0.2821
Step:  7820, loss: 3.256993, norm: 0.2866, time(ms): 800.88, token/sec:654635.84, hellaswag_acc: 0.2821
Step:  7821, loss: 3.227728, norm: 0.3078, time(ms): 795.32, token/sec:659218.36, hellaswag_acc: 0.2821
Step:  7822, loss: 3.257638, norm: 0.2648, time(ms): 797.87, token/sec:657109.62, hellaswag_acc: 0.2821
Step:  7823, loss: 3.252779, norm: 0.2988, time(ms): 790.49, token/sec:663242.39, hellaswag_acc: 0.2821
Step:  7824, loss: 3.245314, norm: 0.2653, time(ms): 796.02, token/sec:658638.07, hellaswag_acc: 0.2821
Step:  7825, loss: 3.233274, norm: 0.2817, time(ms): 793.06, token/sec:661091.17, hellaswag_acc: 0.2821
Step:  7826, loss: 3.234087, norm: 0.2783, time(ms): 788.34, token/sec:665056.29, hellaswag_acc: 0.2821
Step:  7827, loss: 3.225268, norm: 0.3128, time(ms): 791.21, token/sec:662638.22, hellaswag_acc: 0.2821
Step:  7828, loss: 3.232739, norm: 0.2583, time(ms): 791.05, token/sec:662777.03, hellaswag_acc: 0.2821
Step:  7829, loss: 3.241320, norm: 0.3163, time(ms): 792.00, token/sec:661976.56, hellaswag_acc: 0.2821
Step:  7830, loss: 3.217180, norm: 0.2911, time(ms): 804.41, token/sec:651763.09, hellaswag_acc: 0.2821
Step:  7831, loss: 3.295323, norm: 0.2803, time(ms): 797.28, token/sec:657592.62, hellaswag_acc: 0.2821
Step:  7832, loss: 3.267689, norm: 0.2915, time(ms): 802.73, token/sec:653132.48, hellaswag_acc: 0.2821
Step:  7833, loss: 3.311498, norm: 0.2943, time(ms): 799.71, token/sec:655598.80, hellaswag_acc: 0.2821
Step:  7834, loss: 3.248352, norm: 0.2442, time(ms): 797.22, token/sec:657642.37, hellaswag_acc: 0.2821
Step:  7835, loss: 3.261349, norm: 0.2678, time(ms): 793.99, token/sec:660317.97, hellaswag_acc: 0.2821
Step:  7836, loss: 3.211736, norm: 0.2489, time(ms): 790.78, token/sec:663002.63, hellaswag_acc: 0.2821
Step:  7837, loss: 3.236872, norm: 0.2443, time(ms): 788.98, token/sec:664517.89, hellaswag_acc: 0.2821
Step:  7838, loss: 3.224876, norm: 0.2718, time(ms): 790.31, token/sec:663394.86, hellaswag_acc: 0.2821
Step:  7839, loss: 3.228522, norm: 0.2921, time(ms): 796.89, token/sec:657915.47, hellaswag_acc: 0.2821
Step:  7840, loss: 3.295344, norm: 0.2593, time(ms): 792.85, token/sec:661271.68, hellaswag_acc: 0.2821
Step:  7841, loss: 3.238259, norm: 0.2919, time(ms): 791.69, token/sec:662239.51, hellaswag_acc: 0.2821
Step:  7842, loss: 3.237735, norm: 0.2719, time(ms): 792.34, token/sec:661693.51, hellaswag_acc: 0.2821
Step:  7843, loss: 3.247552, norm: 0.2800, time(ms): 792.26, token/sec:661761.02, hellaswag_acc: 0.2821
Step:  7844, loss: 3.221410, norm: 0.2909, time(ms): 788.71, token/sec:664737.85, hellaswag_acc: 0.2821
Step:  7845, loss: 3.235198, norm: 0.2702, time(ms): 789.74, token/sec:663877.52, hellaswag_acc: 0.2821
Step:  7846, loss: 3.239439, norm: 0.2770, time(ms): 792.73, token/sec:661366.94, hellaswag_acc: 0.2821
Step:  7847, loss: 3.198084, norm: 0.2441, time(ms): 786.28, token/sec:666796.83, hellaswag_acc: 0.2821
Step:  7848, loss: 3.152569, norm: 0.2692, time(ms): 786.07, token/sec:666970.76, hellaswag_acc: 0.2821
Step:  7849, loss: 3.215560, norm: 0.2532, time(ms): 792.07, token/sec:661923.76, hellaswag_acc: 0.2821
Step:  7850, loss: 3.242518, norm: 0.2724, time(ms): 787.02, token/sec:666170.23, hellaswag_acc: 0.2821
Step:  7851, loss: 3.239885, norm: 0.2819, time(ms): 793.37, token/sec:660835.09, hellaswag_acc: 0.2821
Step:  7852, loss: 3.275500, norm: 0.3103, time(ms): 792.51, token/sec:661549.99, hellaswag_acc: 0.2821
Step:  7853, loss: 3.180611, norm: 0.2794, time(ms): 802.93, token/sec:652970.73, hellaswag_acc: 0.2821
Step:  7854, loss: 3.221292, norm: 0.3010, time(ms): 791.47, token/sec:662422.05, hellaswag_acc: 0.2821
Step:  7855, loss: 3.170135, norm: 0.3004, time(ms): 791.27, token/sec:662593.10, hellaswag_acc: 0.2821
Step:  7856, loss: 3.127974, norm: 0.2996, time(ms): 787.43, token/sec:665818.26, hellaswag_acc: 0.2821
Step:  7857, loss: 3.068026, norm: 0.3178, time(ms): 790.67, token/sec:663094.79, hellaswag_acc: 0.2821
Step:  7858, loss: 3.036183, norm: 0.2810, time(ms): 798.06, token/sec:656952.57, hellaswag_acc: 0.2821
Step:  7859, loss: 3.030022, norm: 0.2977, time(ms): 791.16, token/sec:662683.75, hellaswag_acc: 0.2821
Step:  7860, loss: 3.046161, norm: 0.2696, time(ms): 803.33, token/sec:652646.32, hellaswag_acc: 0.2821
Step:  7861, loss: 3.047083, norm: 0.2579, time(ms): 806.12, token/sec:650383.85, hellaswag_acc: 0.2821
Step:  7862, loss: 3.096492, norm: 0.2413, time(ms): 794.55, token/sec:659858.08, hellaswag_acc: 0.2821
Step:  7863, loss: 3.050316, norm: 0.2763, time(ms): 798.34, token/sec:656719.30, hellaswag_acc: 0.2821
Step:  7864, loss: 3.146834, norm: 0.2463, time(ms): 803.25, token/sec:652710.83, hellaswag_acc: 0.2821
Step:  7865, loss: 3.107788, norm: 0.2739, time(ms): 802.60, token/sec:653235.89, hellaswag_acc: 0.2821
Step:  7866, loss: 3.032464, norm: 0.2805, time(ms): 791.84, token/sec:662113.10, hellaswag_acc: 0.2821
Step:  7867, loss: 3.180168, norm: 0.2533, time(ms): 799.99, token/sec:655365.31, hellaswag_acc: 0.2821
Step:  7868, loss: 3.246250, norm: 0.2922, time(ms): 805.80, token/sec:650644.22, hellaswag_acc: 0.2821
Step:  7869, loss: 3.251514, norm: 0.2925, time(ms): 802.24, token/sec:653530.59, hellaswag_acc: 0.2821
Step:  7870, loss: 3.266431, norm: 0.2969, time(ms): 795.26, token/sec:659269.75, hellaswag_acc: 0.2821
Step:  7871, loss: 3.277531, norm: 0.2709, time(ms): 791.89, token/sec:662073.03, hellaswag_acc: 0.2821
Step:  7872, loss: 3.330089, norm: 0.2729, time(ms): 790.45, token/sec:663278.60, hellaswag_acc: 0.2821
Step:  7873, loss: 3.242108, norm: 0.2546, time(ms): 790.93, token/sec:662878.92, hellaswag_acc: 0.2821
Step:  7874, loss: 3.218354, norm: 0.2807, time(ms): 789.69, token/sec:663916.00, hellaswag_acc: 0.2821
Step:  7875, loss: 3.229359, norm: 0.2669, time(ms): 794.44, token/sec:659950.37, hellaswag_acc: 0.2821
Step:  7876, loss: 3.260353, norm: 0.2688, time(ms): 794.55, token/sec:659857.89, hellaswag_acc: 0.2821
Step:  7877, loss: 3.304538, norm: 0.2844, time(ms): 792.56, token/sec:661508.60, hellaswag_acc: 0.2821
Step:  7878, loss: 3.260587, norm: 0.2750, time(ms): 792.42, token/sec:661628.01, hellaswag_acc: 0.2821
Step:  7879, loss: 3.228581, norm: 0.2685, time(ms): 795.49, token/sec:659072.36, hellaswag_acc: 0.2821
Step:  7880, loss: 3.220570, norm: 0.2640, time(ms): 788.99, token/sec:664501.22, hellaswag_acc: 0.2821
Step:  7881, loss: 3.244225, norm: 0.2803, time(ms): 790.63, token/sec:663129.39, hellaswag_acc: 0.2821
Step:  7882, loss: 3.200697, norm: 0.2979, time(ms): 790.27, token/sec:663431.28, hellaswag_acc: 0.2821
Step:  7883, loss: 3.267565, norm: 0.2860, time(ms): 788.94, token/sec:664550.02, hellaswag_acc: 0.2821
Step:  7884, loss: 3.267246, norm: 0.2793, time(ms): 791.61, token/sec:662306.33, hellaswag_acc: 0.2821
Step:  7885, loss: 3.191492, norm: 0.3038, time(ms): 789.19, token/sec:664334.40, hellaswag_acc: 0.2821
Step:  7886, loss: 3.257792, norm: 0.2982, time(ms): 791.11, token/sec:662726.29, hellaswag_acc: 0.2821
Step:  7887, loss: 3.270105, norm: 0.2788, time(ms): 790.73, token/sec:663046.61, hellaswag_acc: 0.2821
Step:  7888, loss: 3.225518, norm: 0.2816, time(ms): 799.21, token/sec:656011.66, hellaswag_acc: 0.2821
Step:  7889, loss: 3.242299, norm: 0.2806, time(ms): 801.74, token/sec:653938.91, hellaswag_acc: 0.2821
Step:  7890, loss: 3.283506, norm: 0.2554, time(ms): 797.67, token/sec:657278.14, hellaswag_acc: 0.2821
Step:  7891, loss: 3.171330, norm: 0.2639, time(ms): 797.08, token/sec:657761.58, hellaswag_acc: 0.2821
Step:  7892, loss: 3.203994, norm: 0.2725, time(ms): 791.52, token/sec:662382.74, hellaswag_acc: 0.2821
Step:  7893, loss: 3.209849, norm: 0.2612, time(ms): 791.53, token/sec:662370.77, hellaswag_acc: 0.2821
Step:  7894, loss: 3.166183, norm: 0.2731, time(ms): 791.98, token/sec:661998.88, hellaswag_acc: 0.2821
Step:  7895, loss: 3.238998, norm: 0.2828, time(ms): 786.79, token/sec:666363.62, hellaswag_acc: 0.2821
Step:  7896, loss: 3.232274, norm: 0.2751, time(ms): 789.46, token/sec:664111.50, hellaswag_acc: 0.2821
Step:  7897, loss: 3.202254, norm: 0.2712, time(ms): 793.58, token/sec:660662.16, hellaswag_acc: 0.2821
Step:  7898, loss: 3.197071, norm: 0.2691, time(ms): 796.45, token/sec:658278.84, hellaswag_acc: 0.2821
Step:  7899, loss: 3.215737, norm: 0.2555, time(ms): 807.00, token/sec:649674.44, hellaswag_acc: 0.2821
Step:  7900, loss: 3.169449, norm: 0.2857, time(ms): 801.91, token/sec:653799.89, hellaswag_acc: 0.2821
Step:  7901, loss: 3.174392, norm: 0.2553, time(ms): 789.77, token/sec:663847.26, hellaswag_acc: 0.2821
Step:  7902, loss: 3.113570, norm: 0.2721, time(ms): 803.92, token/sec:652166.11, hellaswag_acc: 0.2821
Step:  7903, loss: 3.070012, norm: 0.2677, time(ms): 795.07, token/sec:659421.97, hellaswag_acc: 0.2821
Step:  7904, loss: 3.041653, norm: 0.3062, time(ms): 790.66, token/sec:663103.59, hellaswag_acc: 0.2821
Step:  7905, loss: 3.110470, norm: 0.2782, time(ms): 789.03, token/sec:664474.31, hellaswag_acc: 0.2821
Step:  7906, loss: 3.110846, norm: 0.2985, time(ms): 789.11, token/sec:664407.06, hellaswag_acc: 0.2821
Step:  7907, loss: 3.102628, norm: 0.2818, time(ms): 798.05, token/sec:656957.67, hellaswag_acc: 0.2821
Step:  7908, loss: 3.006412, norm: 0.2371, time(ms): 798.63, token/sec:656487.37, hellaswag_acc: 0.2821
Step:  7909, loss: 3.065632, norm: 0.2854, time(ms): 797.68, token/sec:657265.37, hellaswag_acc: 0.2821
Step:  7910, loss: 3.078906, norm: 0.2772, time(ms): 805.23, token/sec:651099.83, hellaswag_acc: 0.2821
Step:  7911, loss: 3.091778, norm: 0.2625, time(ms): 792.41, token/sec:661639.76, hellaswag_acc: 0.2821
Step:  7912, loss: 3.014973, norm: 0.2891, time(ms): 798.33, token/sec:656728.12, hellaswag_acc: 0.2821
Step:  7913, loss: 3.055850, norm: 0.2812, time(ms): 790.99, token/sec:662827.37, hellaswag_acc: 0.2821
Step:  7914, loss: 3.172940, norm: 0.2717, time(ms): 795.37, token/sec:659173.71, hellaswag_acc: 0.2821
Step:  7915, loss: 3.287515, norm: 0.2745, time(ms): 790.92, token/sec:662882.91, hellaswag_acc: 0.2821
Step:  7916, loss: 3.213078, norm: 0.2799, time(ms): 786.35, token/sec:666740.02, hellaswag_acc: 0.2821
Step:  7917, loss: 3.218876, norm: 0.2950, time(ms): 794.30, token/sec:660060.51, hellaswag_acc: 0.2821
Step:  7918, loss: 3.201833, norm: 0.2888, time(ms): 791.15, token/sec:662688.15, hellaswag_acc: 0.2821
Step:  7919, loss: 3.240815, norm: 0.2734, time(ms): 793.03, token/sec:661119.99, hellaswag_acc: 0.2821
Step:  7920, loss: 3.300877, norm: 0.3046, time(ms): 802.91, token/sec:652986.63, hellaswag_acc: 0.2821
Step:  7921, loss: 3.245913, norm: 0.2967, time(ms): 800.95, token/sec:654582.45, hellaswag_acc: 0.2821
Step:  7922, loss: 3.282967, norm: 0.2949, time(ms): 799.98, token/sec:655374.49, hellaswag_acc: 0.2821
Step:  7923, loss: 3.184211, norm: 0.2779, time(ms): 796.38, token/sec:658340.13, hellaswag_acc: 0.2821
Step:  7924, loss: 3.243853, norm: 0.2844, time(ms): 803.32, token/sec:652654.65, hellaswag_acc: 0.2821
Step:  7925, loss: 3.189948, norm: 0.3073, time(ms): 801.38, token/sec:654235.41, hellaswag_acc: 0.2821
Step:  7926, loss: 3.255464, norm: 0.2872, time(ms): 797.53, token/sec:657392.89, hellaswag_acc: 0.2821
Step:  7927, loss: 3.266881, norm: 0.3025, time(ms): 800.45, token/sec:654993.06, hellaswag_acc: 0.2821
Step:  7928, loss: 3.178928, norm: 0.2675, time(ms): 800.56, token/sec:654901.38, hellaswag_acc: 0.2821
Step:  7929, loss: 3.265869, norm: 0.2918, time(ms): 799.59, token/sec:655696.15, hellaswag_acc: 0.2821
Step:  7930, loss: 3.183047, norm: 0.2592, time(ms): 796.94, token/sec:657874.93, hellaswag_acc: 0.2821
Step:  7931, loss: 3.264639, norm: 0.2716, time(ms): 800.73, token/sec:654760.59, hellaswag_acc: 0.2821
Step:  7932, loss: 3.256496, norm: 0.2623, time(ms): 801.43, token/sec:654187.53, hellaswag_acc: 0.2821
Step:  7933, loss: 3.218578, norm: 0.2846, time(ms): 802.28, token/sec:653495.63, hellaswag_acc: 0.2821
Step:  7934, loss: 3.229338, norm: 0.2567, time(ms): 794.38, token/sec:659993.74, hellaswag_acc: 0.2821
Step:  7935, loss: 3.305090, norm: 0.3032, time(ms): 795.01, token/sec:659476.36, hellaswag_acc: 0.2821
Step:  7936, loss: 3.236386, norm: 0.2553, time(ms): 792.16, token/sec:661845.07, hellaswag_acc: 0.2821
Step:  7937, loss: 3.218074, norm: 0.2789, time(ms): 782.52, token/sec:669999.03, hellaswag_acc: 0.2821
Step:  7938, loss: 3.249185, norm: 0.2681, time(ms): 789.67, token/sec:663934.05, hellaswag_acc: 0.2821
Step:  7939, loss: 3.186485, norm: 0.2473, time(ms): 796.88, token/sec:657926.30, hellaswag_acc: 0.2821
Step:  7940, loss: 3.196635, norm: 0.2856, time(ms): 798.95, token/sec:656220.15, hellaswag_acc: 0.2821
Step:  7941, loss: 3.173224, norm: 0.2952, time(ms): 792.54, token/sec:661528.50, hellaswag_acc: 0.2821
Step:  7942, loss: 3.202180, norm: 0.2843, time(ms): 786.64, token/sec:666489.64, hellaswag_acc: 0.2821
Step:  7943, loss: 3.202858, norm: 0.2710, time(ms): 790.23, token/sec:663460.70, hellaswag_acc: 0.2821
Step:  7944, loss: 3.228255, norm: 0.2855, time(ms): 788.37, token/sec:665028.33, hellaswag_acc: 0.2821
Step:  7945, loss: 3.190358, norm: 0.2782, time(ms): 790.44, token/sec:663282.80, hellaswag_acc: 0.2821
Step:  7946, loss: 3.254592, norm: 0.3434, time(ms): 799.24, token/sec:655983.87, hellaswag_acc: 0.2821
Step:  7947, loss: 3.180878, norm: 0.4014, time(ms): 789.92, token/sec:663721.03, hellaswag_acc: 0.2821
Step:  7948, loss: 3.132476, norm: 0.2946, time(ms): 788.00, token/sec:665342.02, hellaswag_acc: 0.2821
Step:  7949, loss: 3.070059, norm: 0.3187, time(ms): 793.19, token/sec:660990.42, hellaswag_acc: 0.2821
Step:  7950, loss: 3.028458, norm: 0.3233, time(ms): 793.51, token/sec:660718.14, hellaswag_acc: 0.2821
Step:  7951, loss: 3.077759, norm: 0.3008, time(ms): 791.85, token/sec:662105.32, hellaswag_acc: 0.2821
Step:  7952, loss: 3.140828, norm: 0.3008, time(ms): 799.02, token/sec:656167.87, hellaswag_acc: 0.2821
Step:  7953, loss: 3.055215, norm: 0.2916, time(ms): 799.07, token/sec:656123.43, hellaswag_acc: 0.2821
Step:  7954, loss: 3.005197, norm: 0.2844, time(ms): 804.76, token/sec:651479.83, hellaswag_acc: 0.2821
Step:  7955, loss: 3.076850, norm: 0.3112, time(ms): 790.80, token/sec:662988.04, hellaswag_acc: 0.2821
Step:  7956, loss: 3.082832, norm: 0.2778, time(ms): 798.96, token/sec:656215.65, hellaswag_acc: 0.2821
Step:  7957, loss: 3.046877, norm: 0.2810, time(ms): 792.68, token/sec:661409.11, hellaswag_acc: 0.2821
Step:  7958, loss: 3.057536, norm: 0.2732, time(ms): 797.40, token/sec:657499.62, hellaswag_acc: 0.2821
Step:  7959, loss: 2.985598, norm: 0.2385, time(ms): 789.79, token/sec:663836.04, hellaswag_acc: 0.2821
Step:  7960, loss: 3.241691, norm: 0.2850, time(ms): 789.85, token/sec:663781.73, hellaswag_acc: 0.2821
Step:  7961, loss: 3.170967, norm: 0.2696, time(ms): 790.58, token/sec:663172.58, hellaswag_acc: 0.2821
Step:  7962, loss: 3.266960, norm: 0.2720, time(ms): 792.38, token/sec:661661.86, hellaswag_acc: 0.2821
Step:  7963, loss: 3.205748, norm: 0.2685, time(ms): 793.33, token/sec:660869.84, hellaswag_acc: 0.2821
Step:  7964, loss: 3.228922, norm: 0.2666, time(ms): 799.51, token/sec:655764.78, hellaswag_acc: 0.2821
Step:  7965, loss: 3.284616, norm: 0.2845, time(ms): 797.98, token/sec:657019.31, hellaswag_acc: 0.2821
Step:  7966, loss: 3.219879, norm: 0.2752, time(ms): 804.82, token/sec:651435.44, hellaswag_acc: 0.2821
Step:  7967, loss: 3.248578, norm: 0.2887, time(ms): 790.82, token/sec:662966.25, hellaswag_acc: 0.2821
Step:  7968, loss: 3.208446, norm: 0.2573, time(ms): 803.37, token/sec:652612.62, hellaswag_acc: 0.2821
Step:  7969, loss: 3.284203, norm: 0.2844, time(ms): 803.34, token/sec:652631.21, hellaswag_acc: 0.2821
Step:  7970, loss: 3.223451, norm: 0.2616, time(ms): 803.10, token/sec:652827.87, hellaswag_acc: 0.2821
Step:  7971, loss: 3.233510, norm: 0.3033, time(ms): 788.68, token/sec:664766.78, hellaswag_acc: 0.2821
Step:  7972, loss: 3.217720, norm: 0.2755, time(ms): 800.30, token/sec:655113.06, hellaswag_acc: 0.2821
Step:  7973, loss: 3.272168, norm: 0.2550, time(ms): 792.46, token/sec:661593.78, hellaswag_acc: 0.2821
Step:  7974, loss: 3.239285, norm: 0.2750, time(ms): 790.14, token/sec:663540.18, hellaswag_acc: 0.2821
Step:  7975, loss: 3.259973, norm: 0.2661, time(ms): 791.95, token/sec:662025.39, hellaswag_acc: 0.2821
Step:  7976, loss: 3.247538, norm: 0.2674, time(ms): 789.26, token/sec:664277.81, hellaswag_acc: 0.2821
Step:  7977, loss: 3.259746, norm: 0.2786, time(ms): 799.66, token/sec:655641.61, hellaswag_acc: 0.2821
Step:  7978, loss: 3.170171, norm: 0.2603, time(ms): 802.89, token/sec:653003.70, hellaswag_acc: 0.2821
Step:  7979, loss: 3.196455, norm: 0.2726, time(ms): 795.78, token/sec:658832.05, hellaswag_acc: 0.2821
Step:  7980, loss: 3.193192, norm: 0.2720, time(ms): 797.97, token/sec:657027.16, hellaswag_acc: 0.2821
Step:  7981, loss: 3.220714, norm: 0.2591, time(ms): 802.70, token/sec:653158.86, hellaswag_acc: 0.2821
Step:  7982, loss: 3.198005, norm: 0.2816, time(ms): 801.40, token/sec:654219.06, hellaswag_acc: 0.2821
Step:  7983, loss: 3.224981, norm: 0.3041, time(ms): 800.90, token/sec:654623.76, hellaswag_acc: 0.2821
Step:  7984, loss: 3.213618, norm: 0.2889, time(ms): 796.93, token/sec:657887.92, hellaswag_acc: 0.2821
Step:  7985, loss: 3.322297, norm: 0.2946, time(ms): 799.73, token/sec:655583.16, hellaswag_acc: 0.2821
Step:  7986, loss: 3.227596, norm: 0.2817, time(ms): 799.92, token/sec:655424.69, hellaswag_acc: 0.2821
Step:  7987, loss: 3.195675, norm: 0.2758, time(ms): 795.79, token/sec:658830.07, hellaswag_acc: 0.2821
Step:  7988, loss: 3.167731, norm: 0.2528, time(ms): 794.78, token/sec:659666.08, hellaswag_acc: 0.2821
Step:  7989, loss: 3.172878, norm: 0.2513, time(ms): 789.74, token/sec:663876.72, hellaswag_acc: 0.2821
Step:  7990, loss: 3.153992, norm: 0.2476, time(ms): 801.18, token/sec:654396.42, hellaswag_acc: 0.2821
Step:  7991, loss: 3.208894, norm: 0.2679, time(ms): 798.93, token/sec:656240.71, hellaswag_acc: 0.2821
Step:  7992, loss: 3.202746, norm: 0.2606, time(ms): 794.97, token/sec:659507.81, hellaswag_acc: 0.2821
Step:  7993, loss: 3.196361, norm: 0.2592, time(ms): 790.86, token/sec:662931.68, hellaswag_acc: 0.2821
Step:  7994, loss: 3.214693, norm: 0.2615, time(ms): 783.98, token/sec:668751.03, hellaswag_acc: 0.2821
Step:  7995, loss: 3.108272, norm: 0.2896, time(ms): 793.70, token/sec:660563.93, hellaswag_acc: 0.2821
Step:  7996, loss: 2.993200, norm: 0.2780, time(ms): 798.66, token/sec:656461.30, hellaswag_acc: 0.2821
Step:  7997, loss: 3.068665, norm: 0.2749, time(ms): 797.50, token/sec:657410.58, hellaswag_acc: 0.2821
Step:  7998, loss: 3.107843, norm: 0.2837, time(ms): 800.92, token/sec:654603.88, hellaswag_acc: 0.2821
Step:  7999, loss: 3.058562, norm: 0.2886, time(ms): 801.11, token/sec:654451.34, hellaswag_acc: 0.2821
rank 0 sample 0: Hello, I'm a language model, and I know that I was in love with programming. I know why every year I go to college to be a good
rank 0 sample 1: Hello, I'm a language model, I do not have the idea. Thanks for your interesting answer!
Is your question about the meaning of 'love'
rank 0 sample 2: Hello, I'm a language model, I'm sure that anyone knows how to write. I'm very proud of the support and help of the language models,
rank 0 sample 3: Hello, I'm a language model, you mean, we're talking to people, at the moment, people have been so fascinated in this work that I decided
rank 1 sample 0: Hello, I'm a language model, here are the steps I'm going to do
Step 1: I'm going to talk to some people and I'm
rank 1 sample 1: Hello, I'm a language model, not an app designer. I can't remember the time but I love it too, "Learn From The Book" is
rank 1 sample 2: Hello, I'm a language model, so everything that happens in the world is a language model that takes all those basic rules and makes a lot more complicated than
rank 1 sample 3: Hello, I'm a language model, and I'm using the GoogleDoc language or the DocKit language. And on the Chrome or Apple Safari, I'm
Step:  8000, loss: 3.058388, norm: 0.2875, time(ms): 364125.48, token/sec:1439.86, val_loss: 3.2438, hellaswag_acc: 0.2878
Step:  8001, loss: 3.226341, norm: 0.2780, time(ms): 771.67, token/sec:679417.56, hellaswag_acc: 0.2878
Step:  8002, loss: 3.218526, norm: 0.2757, time(ms): 788.36, token/sec:665040.00, hellaswag_acc: 0.2878
Step:  8003, loss: 3.200723, norm: 0.2872, time(ms): 797.85, token/sec:657126.70, hellaswag_acc: 0.2878
Step:  8004, loss: 3.246047, norm: 0.2912, time(ms): 787.32, token/sec:665916.45, hellaswag_acc: 0.2878
Step:  8005, loss: 3.196939, norm: 0.2707, time(ms): 786.77, token/sec:666377.15, hellaswag_acc: 0.2878
Step:  8006, loss: 3.208043, norm: 0.2714, time(ms): 794.92, token/sec:659548.16, hellaswag_acc: 0.2878
Step:  8007, loss: 3.227701, norm: 0.2612, time(ms): 794.67, token/sec:659755.34, hellaswag_acc: 0.2878
Step:  8008, loss: 3.182760, norm: 0.2504, time(ms): 794.92, token/sec:659546.77, hellaswag_acc: 0.2878
Step:  8009, loss: 3.199696, norm: 0.2496, time(ms): 787.89, token/sec:665433.23, hellaswag_acc: 0.2878
Step:  8010, loss: 3.252257, norm: 0.2729, time(ms): 783.88, token/sec:668833.41, hellaswag_acc: 0.2878
Step:  8011, loss: 3.228673, norm: 0.2840, time(ms): 792.59, token/sec:661485.71, hellaswag_acc: 0.2878
Step:  8012, loss: 3.205075, norm: 0.2678, time(ms): 797.45, token/sec:657453.62, hellaswag_acc: 0.2878
Step:  8013, loss: 3.267416, norm: 0.2883, time(ms): 786.22, token/sec:666844.95, hellaswag_acc: 0.2878
Step:  8014, loss: 3.185888, norm: 0.3612, time(ms): 787.01, token/sec:666172.85, hellaswag_acc: 0.2878
Step:  8015, loss: 3.212709, norm: 0.3147, time(ms): 799.25, token/sec:655976.24, hellaswag_acc: 0.2878
Step:  8016, loss: 3.223155, norm: 0.2804, time(ms): 790.43, token/sec:663297.01, hellaswag_acc: 0.2878
Step:  8017, loss: 3.251620, norm: 0.3368, time(ms): 795.18, token/sec:659328.65, hellaswag_acc: 0.2878
Step:  8018, loss: 3.239861, norm: 0.2951, time(ms): 795.13, token/sec:659374.92, hellaswag_acc: 0.2878
Step:  8019, loss: 3.270817, norm: 0.2974, time(ms): 800.88, token/sec:654637.01, hellaswag_acc: 0.2878
Step:  8020, loss: 3.186191, norm: 0.2826, time(ms): 804.41, token/sec:651768.89, hellaswag_acc: 0.2878
Step:  8021, loss: 3.185393, norm: 0.2829, time(ms): 796.91, token/sec:657901.69, hellaswag_acc: 0.2878
Step:  8022, loss: 3.203115, norm: 0.2759, time(ms): 794.95, token/sec:659519.67, hellaswag_acc: 0.2878
Step:  8023, loss: 3.218621, norm: 0.2916, time(ms): 802.62, token/sec:653218.04, hellaswag_acc: 0.2878
Step:  8024, loss: 3.248193, norm: 0.2576, time(ms): 804.36, token/sec:651811.58, hellaswag_acc: 0.2878
Step:  8025, loss: 3.186971, norm: 0.2683, time(ms): 791.86, token/sec:662099.94, hellaswag_acc: 0.2878
Step:  8026, loss: 3.222769, norm: 0.2848, time(ms): 796.85, token/sec:657953.66, hellaswag_acc: 0.2878
Step:  8027, loss: 3.155388, norm: 0.2882, time(ms): 792.30, token/sec:661730.75, hellaswag_acc: 0.2878
Step:  8028, loss: 3.232105, norm: 0.2670, time(ms): 799.26, token/sec:655965.29, hellaswag_acc: 0.2878
Step:  8029, loss: 3.226994, norm: 0.2595, time(ms): 794.64, token/sec:659782.85, hellaswag_acc: 0.2878
Step:  8030, loss: 3.205938, norm: 0.2457, time(ms): 800.23, token/sec:655170.25, hellaswag_acc: 0.2878
Step:  8031, loss: 3.245987, norm: 0.2789, time(ms): 797.17, token/sec:657686.24, hellaswag_acc: 0.2878
Step:  8032, loss: 3.213000, norm: 0.2700, time(ms): 798.03, token/sec:656980.25, hellaswag_acc: 0.2878
Step:  8033, loss: 3.233717, norm: 0.2689, time(ms): 790.97, token/sec:662840.95, hellaswag_acc: 0.2878
Step:  8034, loss: 3.200050, norm: 0.2461, time(ms): 782.47, token/sec:670044.56, hellaswag_acc: 0.2878
Step:  8035, loss: 3.214326, norm: 0.2687, time(ms): 789.43, token/sec:664132.16, hellaswag_acc: 0.2878
Step:  8036, loss: 3.265387, norm: 0.2727, time(ms): 802.42, token/sec:653379.71, hellaswag_acc: 0.2878
Step:  8037, loss: 3.210402, norm: 0.2500, time(ms): 801.81, token/sec:653883.68, hellaswag_acc: 0.2878
Step:  8038, loss: 3.227395, norm: 0.2571, time(ms): 793.75, token/sec:660516.31, hellaswag_acc: 0.2878
Step:  8039, loss: 3.189296, norm: 0.2609, time(ms): 796.69, token/sec:658081.06, hellaswag_acc: 0.2878
Step:  8040, loss: 3.212676, norm: 0.2604, time(ms): 808.60, token/sec:648388.89, hellaswag_acc: 0.2878
Step:  8041, loss: 3.222422, norm: 0.2955, time(ms): 801.29, token/sec:654307.44, hellaswag_acc: 0.2878
Step:  8042, loss: 3.224658, norm: 0.2649, time(ms): 783.65, token/sec:669032.83, hellaswag_acc: 0.2878
Step:  8043, loss: 3.224894, norm: 0.2781, time(ms): 791.52, token/sec:662379.15, hellaswag_acc: 0.2878
Step:  8044, loss: 3.216299, norm: 0.2622, time(ms): 792.98, token/sec:661163.32, hellaswag_acc: 0.2878
Step:  8045, loss: 3.252557, norm: 0.2788, time(ms): 792.42, token/sec:661628.01, hellaswag_acc: 0.2878
Step:  8046, loss: 3.235511, norm: 0.2788, time(ms): 791.78, token/sec:662164.53, hellaswag_acc: 0.2878
Step:  8047, loss: 3.270889, norm: 0.3350, time(ms): 799.15, token/sec:656060.40, hellaswag_acc: 0.2878
Step:  8048, loss: 3.240718, norm: 0.2906, time(ms): 804.52, token/sec:651677.14, hellaswag_acc: 0.2878
Step:  8049, loss: 3.224977, norm: 0.2779, time(ms): 799.73, token/sec:655578.86, hellaswag_acc: 0.2878
Step:  8050, loss: 3.240022, norm: 0.2940, time(ms): 794.08, token/sec:660243.03, hellaswag_acc: 0.2878
Step:  8051, loss: 3.175338, norm: 0.3022, time(ms): 797.63, token/sec:657306.03, hellaswag_acc: 0.2878
Step:  8052, loss: 3.245701, norm: 0.3033, time(ms): 793.87, token/sec:660418.71, hellaswag_acc: 0.2878
Step:  8053, loss: 3.210431, norm: 0.2850, time(ms): 796.21, token/sec:658475.76, hellaswag_acc: 0.2878
Step:  8054, loss: 3.209246, norm: 0.2891, time(ms): 789.93, token/sec:663714.02, hellaswag_acc: 0.2878
Step:  8055, loss: 3.278419, norm: 0.2897, time(ms): 792.03, token/sec:661954.05, hellaswag_acc: 0.2878
Step:  8056, loss: 3.284983, norm: 0.2870, time(ms): 788.25, token/sec:665125.69, hellaswag_acc: 0.2878
Step:  8057, loss: 3.273543, norm: 0.3013, time(ms): 793.38, token/sec:660827.34, hellaswag_acc: 0.2878
Step:  8058, loss: 3.260324, norm: 0.2975, time(ms): 795.03, token/sec:659454.80, hellaswag_acc: 0.2878
Step:  8059, loss: 3.273333, norm: 0.2983, time(ms): 793.75, token/sec:660521.27, hellaswag_acc: 0.2878
Step:  8060, loss: 3.194232, norm: 0.3081, time(ms): 799.95, token/sec:655404.18, hellaswag_acc: 0.2878
Step:  8061, loss: 3.243845, norm: 0.2629, time(ms): 805.94, token/sec:650526.81, hellaswag_acc: 0.2878
Step:  8062, loss: 3.215798, norm: 0.2973, time(ms): 800.23, token/sec:655175.33, hellaswag_acc: 0.2878
Step:  8063, loss: 3.186353, norm: 0.2510, time(ms): 791.17, token/sec:662676.56, hellaswag_acc: 0.2878
Step:  8064, loss: 3.232955, norm: 0.2693, time(ms): 805.85, token/sec:650601.68, hellaswag_acc: 0.2878
Step:  8065, loss: 3.224959, norm: 0.2625, time(ms): 800.92, token/sec:654605.63, hellaswag_acc: 0.2878
Step:  8066, loss: 3.232091, norm: 0.2570, time(ms): 799.62, token/sec:655668.39, hellaswag_acc: 0.2878
Step:  8067, loss: 3.249464, norm: 0.2652, time(ms): 799.92, token/sec:655426.65, hellaswag_acc: 0.2878
Step:  8068, loss: 3.206966, norm: 0.2656, time(ms): 797.59, token/sec:657343.17, hellaswag_acc: 0.2878
Step:  8069, loss: 3.278443, norm: 0.4323, time(ms): 801.88, token/sec:653824.00, hellaswag_acc: 0.2878
Step:  8070, loss: 3.222859, norm: 0.3389, time(ms): 801.67, token/sec:653998.23, hellaswag_acc: 0.2878
Step:  8071, loss: 3.198062, norm: 0.2797, time(ms): 792.78, token/sec:661330.94, hellaswag_acc: 0.2878
Step:  8072, loss: 3.216005, norm: 0.3036, time(ms): 798.06, token/sec:656954.53, hellaswag_acc: 0.2878
Step:  8073, loss: 3.199814, norm: 0.2829, time(ms): 807.33, token/sec:649413.32, hellaswag_acc: 0.2878
Step:  8074, loss: 3.160425, norm: 0.2686, time(ms): 800.97, token/sec:654563.16, hellaswag_acc: 0.2878
Step:  8075, loss: 3.213737, norm: 0.2633, time(ms): 789.20, token/sec:664330.18, hellaswag_acc: 0.2878
Step:  8076, loss: 3.232062, norm: 0.2751, time(ms): 791.83, token/sec:662121.47, hellaswag_acc: 0.2878
Step:  8077, loss: 3.170564, norm: 0.2585, time(ms): 790.10, token/sec:663573.02, hellaswag_acc: 0.2878
Step:  8078, loss: 3.254307, norm: 0.2699, time(ms): 790.45, token/sec:663276.60, hellaswag_acc: 0.2878
Step:  8079, loss: 3.230298, norm: 0.2719, time(ms): 794.19, token/sec:660155.82, hellaswag_acc: 0.2878
Step:  8080, loss: 3.225629, norm: 0.2552, time(ms): 792.49, token/sec:661569.29, hellaswag_acc: 0.2878
Step:  8081, loss: 3.199136, norm: 0.2871, time(ms): 791.74, token/sec:662196.24, hellaswag_acc: 0.2878
Step:  8082, loss: 3.206184, norm: 0.2728, time(ms): 796.42, token/sec:658304.26, hellaswag_acc: 0.2878
Step:  8083, loss: 3.158955, norm: 0.2820, time(ms): 792.06, token/sec:661926.95, hellaswag_acc: 0.2878
Step:  8084, loss: 3.243396, norm: 0.3058, time(ms): 787.74, token/sec:665562.93, hellaswag_acc: 0.2878
Step:  8085, loss: 3.236584, norm: 0.2469, time(ms): 794.30, token/sec:660059.12, hellaswag_acc: 0.2878
Step:  8086, loss: 3.186236, norm: 0.2816, time(ms): 791.30, token/sec:662562.16, hellaswag_acc: 0.2878
Step:  8087, loss: 3.163319, norm: 0.2564, time(ms): 794.02, token/sec:660298.34, hellaswag_acc: 0.2878
Step:  8088, loss: 3.221032, norm: 0.2631, time(ms): 798.70, token/sec:656423.68, hellaswag_acc: 0.2878
Step:  8089, loss: 3.236762, norm: 0.2890, time(ms): 802.16, token/sec:653595.86, hellaswag_acc: 0.2878
Step:  8090, loss: 3.225868, norm: 0.2677, time(ms): 799.25, token/sec:655974.48, hellaswag_acc: 0.2878
Step:  8091, loss: 3.244759, norm: 0.2706, time(ms): 795.18, token/sec:659331.62, hellaswag_acc: 0.2878
Step:  8092, loss: 3.237784, norm: 0.2906, time(ms): 801.18, token/sec:654397.98, hellaswag_acc: 0.2878
Step:  8093, loss: 3.247285, norm: 0.2862, time(ms): 805.03, token/sec:651262.38, hellaswag_acc: 0.2878
Step:  8094, loss: 3.216508, norm: 0.2675, time(ms): 794.26, token/sec:660097.56, hellaswag_acc: 0.2878
Step:  8095, loss: 3.249953, norm: 0.2651, time(ms): 798.73, token/sec:656401.73, hellaswag_acc: 0.2878
Step:  8096, loss: 3.176362, norm: 0.2568, time(ms): 803.66, token/sec:652376.03, hellaswag_acc: 0.2878
Step:  8097, loss: 3.207164, norm: 0.2764, time(ms): 802.54, token/sec:653284.02, hellaswag_acc: 0.2878
Step:  8098, loss: 3.165385, norm: 0.2955, time(ms): 797.10, token/sec:657746.04, hellaswag_acc: 0.2878
Step:  8099, loss: 3.200904, norm: 0.2983, time(ms): 795.18, token/sec:659330.04, hellaswag_acc: 0.2878
Step:  8100, loss: 3.195924, norm: 0.2699, time(ms): 804.15, token/sec:651980.29, hellaswag_acc: 0.2878
Step:  8101, loss: 3.249048, norm: 0.2866, time(ms): 803.01, token/sec:652906.95, hellaswag_acc: 0.2878
Step:  8102, loss: 3.210241, norm: 0.2778, time(ms): 790.49, token/sec:663244.99, hellaswag_acc: 0.2878
Step:  8103, loss: 3.191770, norm: 0.3159, time(ms): 802.63, token/sec:653216.29, hellaswag_acc: 0.2878
Step:  8104, loss: 3.186658, norm: 0.2829, time(ms): 803.35, token/sec:652626.18, hellaswag_acc: 0.2878
Step:  8105, loss: 3.235146, norm: 0.2973, time(ms): 802.89, token/sec:652999.82, hellaswag_acc: 0.2878
Step:  8106, loss: 3.226854, norm: 0.2882, time(ms): 794.49, token/sec:659909.17, hellaswag_acc: 0.2878
Step:  8107, loss: 3.237945, norm: 0.2855, time(ms): 793.05, token/sec:661101.11, hellaswag_acc: 0.2878
Step:  8108, loss: 3.217140, norm: 0.2709, time(ms): 791.90, token/sec:662060.47, hellaswag_acc: 0.2878
Step:  8109, loss: 3.204780, norm: 0.3032, time(ms): 786.23, token/sec:666839.29, hellaswag_acc: 0.2878
Step:  8110, loss: 3.190988, norm: 0.2485, time(ms): 789.36, token/sec:664197.35, hellaswag_acc: 0.2878
Step:  8111, loss: 3.219573, norm: 0.2846, time(ms): 798.21, token/sec:656833.46, hellaswag_acc: 0.2878
Step:  8112, loss: 3.275447, norm: 0.2671, time(ms): 804.04, token/sec:652069.61, hellaswag_acc: 0.2878
Step:  8113, loss: 3.227999, norm: 0.2549, time(ms): 792.45, token/sec:661603.93, hellaswag_acc: 0.2878
Step:  8114, loss: 3.238376, norm: 0.2966, time(ms): 794.67, token/sec:659756.52, hellaswag_acc: 0.2878
Step:  8115, loss: 3.234889, norm: 0.2507, time(ms): 792.25, token/sec:661769.58, hellaswag_acc: 0.2878
Step:  8116, loss: 3.224845, norm: 0.2834, time(ms): 793.16, token/sec:661013.67, hellaswag_acc: 0.2878
Step:  8117, loss: 3.266970, norm: 0.2679, time(ms): 792.55, token/sec:661519.94, hellaswag_acc: 0.2878
Step:  8118, loss: 3.225213, norm: 0.2576, time(ms): 784.17, token/sec:668589.39, hellaswag_acc: 0.2878
Step:  8119, loss: 3.164746, norm: 0.2582, time(ms): 790.35, token/sec:663361.03, hellaswag_acc: 0.2878
Step:  8120, loss: 3.243274, norm: 0.2930, time(ms): 799.14, token/sec:656064.31, hellaswag_acc: 0.2878
Step:  8121, loss: 3.248882, norm: 0.2688, time(ms): 794.81, token/sec:659642.73, hellaswag_acc: 0.2878
Step:  8122, loss: 3.237262, norm: 0.2676, time(ms): 803.22, token/sec:652736.21, hellaswag_acc: 0.2878
Step:  8123, loss: 3.211123, norm: 0.2918, time(ms): 802.44, token/sec:653364.76, hellaswag_acc: 0.2878
Step:  8124, loss: 3.245423, norm: 0.2620, time(ms): 798.05, token/sec:656958.26, hellaswag_acc: 0.2878
Step:  8125, loss: 3.234493, norm: 0.3199, time(ms): 791.77, token/sec:662169.32, hellaswag_acc: 0.2878
Step:  8126, loss: 3.250856, norm: 0.2702, time(ms): 807.39, token/sec:649358.48, hellaswag_acc: 0.2878
Step:  8127, loss: 3.221112, norm: 0.2956, time(ms): 792.13, token/sec:661874.95, hellaswag_acc: 0.2878
Step:  8128, loss: 3.425176, norm: 0.4017, time(ms): 792.66, token/sec:661428.61, hellaswag_acc: 0.2878
Step:  8129, loss: 3.165020, norm: 0.3925, time(ms): 790.40, token/sec:663321.01, hellaswag_acc: 0.2878
Step:  8130, loss: 3.232327, norm: 0.2999, time(ms): 796.44, token/sec:658286.13, hellaswag_acc: 0.2878
Step:  8131, loss: 3.254237, norm: 0.3593, time(ms): 790.94, token/sec:662870.33, hellaswag_acc: 0.2878
Step:  8132, loss: 3.189322, norm: 0.3994, time(ms): 797.77, token/sec:657191.71, hellaswag_acc: 0.2878
Step:  8133, loss: 3.244554, norm: 0.3327, time(ms): 792.93, token/sec:661199.70, hellaswag_acc: 0.2878
Step:  8134, loss: 3.157100, norm: 0.2816, time(ms): 804.63, token/sec:651590.44, hellaswag_acc: 0.2878
Step:  8135, loss: 3.246997, norm: 0.3145, time(ms): 802.58, token/sec:653251.80, hellaswag_acc: 0.2878
Step:  8136, loss: 3.254575, norm: 0.2894, time(ms): 790.45, token/sec:663277.80, hellaswag_acc: 0.2878
Step:  8137, loss: 3.244515, norm: 0.2950, time(ms): 792.12, token/sec:661878.73, hellaswag_acc: 0.2878
Step:  8138, loss: 3.227179, norm: 0.2889, time(ms): 795.57, token/sec:659011.52, hellaswag_acc: 0.2878
Step:  8139, loss: 3.231292, norm: 0.2677, time(ms): 801.09, token/sec:654469.06, hellaswag_acc: 0.2878
Step:  8140, loss: 3.202112, norm: 0.2968, time(ms): 793.82, token/sec:660465.12, hellaswag_acc: 0.2878
Step:  8141, loss: 3.311238, norm: 0.2862, time(ms): 801.28, token/sec:654314.83, hellaswag_acc: 0.2878
Step:  8142, loss: 3.226325, norm: 0.2874, time(ms): 797.87, token/sec:657111.78, hellaswag_acc: 0.2878
Step:  8143, loss: 3.197422, norm: 0.2632, time(ms): 800.81, token/sec:654701.13, hellaswag_acc: 0.2878
Step:  8144, loss: 3.213053, norm: 0.2528, time(ms): 796.37, token/sec:658349.59, hellaswag_acc: 0.2878
Step:  8145, loss: 3.210608, norm: 0.2809, time(ms): 790.92, token/sec:662887.71, hellaswag_acc: 0.2878
Step:  8146, loss: 3.187812, norm: 0.2701, time(ms): 788.25, token/sec:665129.51, hellaswag_acc: 0.2878
Step:  8147, loss: 3.226143, norm: 0.2691, time(ms): 790.38, token/sec:663332.62, hellaswag_acc: 0.2878
Step:  8148, loss: 3.219865, norm: 0.2623, time(ms): 796.35, token/sec:658364.97, hellaswag_acc: 0.2878
Step:  8149, loss: 3.238799, norm: 0.2600, time(ms): 799.92, token/sec:655425.87, hellaswag_acc: 0.2878
Step:  8150, loss: 3.285684, norm: 0.2578, time(ms): 798.18, token/sec:656850.53, hellaswag_acc: 0.2878
Step:  8151, loss: 3.234627, norm: 0.2485, time(ms): 802.28, token/sec:653494.27, hellaswag_acc: 0.2878
Step:  8152, loss: 3.242260, norm: 0.2528, time(ms): 800.66, token/sec:654821.42, hellaswag_acc: 0.2878
Step:  8153, loss: 3.234699, norm: 0.2411, time(ms): 800.33, token/sec:655086.13, hellaswag_acc: 0.2878
Step:  8154, loss: 3.191211, norm: 0.2534, time(ms): 799.30, token/sec:655930.65, hellaswag_acc: 0.2878
Step:  8155, loss: 3.170501, norm: 0.2494, time(ms): 793.95, token/sec:660351.48, hellaswag_acc: 0.2878
Step:  8156, loss: 3.259174, norm: 0.3325, time(ms): 804.49, token/sec:651703.21, hellaswag_acc: 0.2878
Step:  8157, loss: 3.342922, norm: 0.2944, time(ms): 802.45, token/sec:653362.24, hellaswag_acc: 0.2878
Step:  8158, loss: 3.234247, norm: 0.3020, time(ms): 799.41, token/sec:655840.08, hellaswag_acc: 0.2878
Step:  8159, loss: 3.305555, norm: 0.2937, time(ms): 789.54, token/sec:664046.32, hellaswag_acc: 0.2878
Step:  8160, loss: 3.234444, norm: 0.2926, time(ms): 790.93, token/sec:662874.92, hellaswag_acc: 0.2878
Step:  8161, loss: 3.253855, norm: 0.2813, time(ms): 789.33, token/sec:664222.43, hellaswag_acc: 0.2878
Step:  8162, loss: 3.263618, norm: 0.2873, time(ms): 791.36, token/sec:662514.65, hellaswag_acc: 0.2878
Step:  8163, loss: 3.242482, norm: 0.2781, time(ms): 796.08, token/sec:658587.18, hellaswag_acc: 0.2878
Step:  8164, loss: 3.275307, norm: 0.2724, time(ms): 790.07, token/sec:663595.25, hellaswag_acc: 0.2878
Step:  8165, loss: 3.419291, norm: 0.3008, time(ms): 791.24, token/sec:662614.86, hellaswag_acc: 0.2878
Step:  8166, loss: 3.220740, norm: 0.2729, time(ms): 797.59, token/sec:657340.22, hellaswag_acc: 0.2878
Step:  8167, loss: 3.250452, norm: 0.2756, time(ms): 793.73, token/sec:660535.35, hellaswag_acc: 0.2878
Step:  8168, loss: 3.208191, norm: 0.2726, time(ms): 790.22, token/sec:663469.31, hellaswag_acc: 0.2878
Step:  8169, loss: 3.152093, norm: 0.2564, time(ms): 792.22, token/sec:661795.07, hellaswag_acc: 0.2878
Step:  8170, loss: 3.211178, norm: 0.2674, time(ms): 791.13, token/sec:662706.12, hellaswag_acc: 0.2878
Step:  8171, loss: 3.218103, norm: 0.2787, time(ms): 789.65, token/sec:663951.49, hellaswag_acc: 0.2878
Step:  8172, loss: 3.226833, norm: 0.2698, time(ms): 801.73, token/sec:653946.30, hellaswag_acc: 0.2878
Step:  8173, loss: 3.202506, norm: 0.2806, time(ms): 800.63, token/sec:654844.43, hellaswag_acc: 0.2878
Step:  8174, loss: 3.187778, norm: 0.2701, time(ms): 802.17, token/sec:653587.31, hellaswag_acc: 0.2878
Step:  8175, loss: 3.255842, norm: 0.3102, time(ms): 795.16, token/sec:659353.17, hellaswag_acc: 0.2878
Step:  8176, loss: 3.231602, norm: 0.2985, time(ms): 800.40, token/sec:655034.03, hellaswag_acc: 0.2878
Step:  8177, loss: 3.221806, norm: 0.2720, time(ms): 804.71, token/sec:651522.49, hellaswag_acc: 0.2878
Step:  8178, loss: 3.197800, norm: 0.3011, time(ms): 793.63, token/sec:660619.49, hellaswag_acc: 0.2878
Step:  8179, loss: 3.267457, norm: 0.2941, time(ms): 798.61, token/sec:656502.85, hellaswag_acc: 0.2878
Step:  8180, loss: 3.222986, norm: 0.2472, time(ms): 804.99, token/sec:651300.58, hellaswag_acc: 0.2878
Step:  8181, loss: 3.206785, norm: 0.2838, time(ms): 801.93, token/sec:653783.76, hellaswag_acc: 0.2878
Step:  8182, loss: 3.220687, norm: 0.2620, time(ms): 783.29, token/sec:669342.77, hellaswag_acc: 0.2878
Step:  8183, loss: 3.211575, norm: 0.2697, time(ms): 791.07, token/sec:662761.25, hellaswag_acc: 0.2878
Step:  8184, loss: 3.313159, norm: 0.2674, time(ms): 794.30, token/sec:660062.68, hellaswag_acc: 0.2878
Step:  8185, loss: 3.209254, norm: 0.2975, time(ms): 793.30, token/sec:660892.49, hellaswag_acc: 0.2878
Step:  8186, loss: 3.235065, norm: 0.2919, time(ms): 788.75, token/sec:664710.92, hellaswag_acc: 0.2878
Step:  8187, loss: 3.169095, norm: 0.2591, time(ms): 792.68, token/sec:661416.08, hellaswag_acc: 0.2878
Step:  8188, loss: 3.248634, norm: 0.2576, time(ms): 794.53, token/sec:659869.37, hellaswag_acc: 0.2878
Step:  8189, loss: 3.183440, norm: 0.2517, time(ms): 797.38, token/sec:657511.22, hellaswag_acc: 0.2878
Step:  8190, loss: 3.224622, norm: 0.2565, time(ms): 798.26, token/sec:656785.40, hellaswag_acc: 0.2878
Step:  8191, loss: 3.238737, norm: 0.2776, time(ms): 1238.78, token/sec:423230.11, hellaswag_acc: 0.2878
Step:  8192, loss: 3.233244, norm: 0.2720, time(ms): 795.68, token/sec:658920.69, hellaswag_acc: 0.2878
Step:  8193, loss: 3.267725, norm: 0.2822, time(ms): 783.65, token/sec:669034.66, hellaswag_acc: 0.2878
Step:  8194, loss: 3.258517, norm: 0.2669, time(ms): 789.76, token/sec:663858.48, hellaswag_acc: 0.2878
Step:  8195, loss: 3.236843, norm: 0.2801, time(ms): 789.55, token/sec:664035.89, hellaswag_acc: 0.2878
Step:  8196, loss: 3.226789, norm: 0.2631, time(ms): 806.19, token/sec:650330.38, hellaswag_acc: 0.2878
Step:  8197, loss: 3.195499, norm: 0.2828, time(ms): 791.78, token/sec:662165.73, hellaswag_acc: 0.2878
Step:  8198, loss: 3.232905, norm: 0.2435, time(ms): 794.08, token/sec:660245.80, hellaswag_acc: 0.2878
Step:  8199, loss: 3.192871, norm: 0.2829, time(ms): 789.68, token/sec:663921.42, hellaswag_acc: 0.2878
Step:  8200, loss: 3.244488, norm: 0.2646, time(ms): 793.64, token/sec:660612.74, hellaswag_acc: 0.2878
Step:  8201, loss: 3.210789, norm: 0.2784, time(ms): 791.21, token/sec:662636.63, hellaswag_acc: 0.2878
Step:  8202, loss: 3.199744, norm: 0.2740, time(ms): 789.85, token/sec:663783.54, hellaswag_acc: 0.2878
Step:  8203, loss: 3.275252, norm: 0.2969, time(ms): 801.25, token/sec:654335.47, hellaswag_acc: 0.2878
Step:  8204, loss: 3.204767, norm: 0.2651, time(ms): 807.71, token/sec:649108.14, hellaswag_acc: 0.2878
Step:  8205, loss: 3.201246, norm: 0.2673, time(ms): 784.07, token/sec:668676.20, hellaswag_acc: 0.2878
Step:  8206, loss: 3.191939, norm: 0.2888, time(ms): 787.71, token/sec:665586.90, hellaswag_acc: 0.2878
Step:  8207, loss: 3.236707, norm: 0.2595, time(ms): 792.58, token/sec:661498.25, hellaswag_acc: 0.2878
Step:  8208, loss: 3.216732, norm: 0.2868, time(ms): 794.21, token/sec:660139.57, hellaswag_acc: 0.2878
Step:  8209, loss: 3.232650, norm: 0.2692, time(ms): 789.24, token/sec:664292.25, hellaswag_acc: 0.2878
Step:  8210, loss: 3.186944, norm: 0.3027, time(ms): 790.59, token/sec:663163.18, hellaswag_acc: 0.2878
Step:  8211, loss: 3.273489, norm: 0.2961, time(ms): 798.15, token/sec:656875.84, hellaswag_acc: 0.2878
Step:  8212, loss: 3.178827, norm: 0.2504, time(ms): 798.03, token/sec:656976.91, hellaswag_acc: 0.2878
Step:  8213, loss: 3.203801, norm: 0.2657, time(ms): 799.19, token/sec:656021.64, hellaswag_acc: 0.2878
Step:  8214, loss: 3.205904, norm: 0.3024, time(ms): 801.64, token/sec:654019.62, hellaswag_acc: 0.2878
Step:  8215, loss: 3.170672, norm: 0.2732, time(ms): 799.03, token/sec:656152.21, hellaswag_acc: 0.2878
Step:  8216, loss: 3.209250, norm: 0.2955, time(ms): 792.34, token/sec:661694.51, hellaswag_acc: 0.2878
Step:  8217, loss: 3.211628, norm: 0.2720, time(ms): 789.73, token/sec:663879.93, hellaswag_acc: 0.2878
Step:  8218, loss: 3.289225, norm: 0.3298, time(ms): 793.72, token/sec:660542.89, hellaswag_acc: 0.2878
Step:  8219, loss: 3.299087, norm: 0.3396, time(ms): 791.55, token/sec:662352.81, hellaswag_acc: 0.2878
Step:  8220, loss: 3.212188, norm: 0.3165, time(ms): 793.72, token/sec:660544.08, hellaswag_acc: 0.2878
Step:  8221, loss: 3.229172, norm: 0.3016, time(ms): 795.55, token/sec:659026.53, hellaswag_acc: 0.2878
Step:  8222, loss: 3.222780, norm: 0.2765, time(ms): 805.77, token/sec:650669.82, hellaswag_acc: 0.2878
Step:  8223, loss: 3.245513, norm: 0.2694, time(ms): 799.57, token/sec:655714.33, hellaswag_acc: 0.2878
Step:  8224, loss: 3.233558, norm: 0.2775, time(ms): 794.80, token/sec:659645.89, hellaswag_acc: 0.2878
Step:  8225, loss: 3.250226, norm: 0.2624, time(ms): 803.34, token/sec:652637.61, hellaswag_acc: 0.2878
Step:  8226, loss: 3.299194, norm: 0.2798, time(ms): 797.54, token/sec:657377.36, hellaswag_acc: 0.2878
Step:  8227, loss: 3.256833, norm: 0.2846, time(ms): 803.27, token/sec:652695.53, hellaswag_acc: 0.2878
Step:  8228, loss: 3.248801, norm: 0.2742, time(ms): 798.48, token/sec:656608.51, hellaswag_acc: 0.2878
Step:  8229, loss: 3.203785, norm: 0.3206, time(ms): 793.35, token/sec:660856.14, hellaswag_acc: 0.2878
Step:  8230, loss: 3.172771, norm: 0.2921, time(ms): 807.69, token/sec:649123.28, hellaswag_acc: 0.2878
Step:  8231, loss: 3.268970, norm: 0.2785, time(ms): 796.54, token/sec:658208.70, hellaswag_acc: 0.2878
Step:  8232, loss: 3.195260, norm: 0.2819, time(ms): 793.16, token/sec:661009.89, hellaswag_acc: 0.2878
Step:  8233, loss: 3.208654, norm: 0.2867, time(ms): 791.61, token/sec:662307.73, hellaswag_acc: 0.2878
Step:  8234, loss: 3.233523, norm: 0.2788, time(ms): 787.79, token/sec:665515.19, hellaswag_acc: 0.2878
Step:  8235, loss: 3.257953, norm: 0.2837, time(ms): 791.21, token/sec:662642.82, hellaswag_acc: 0.2878
Step:  8236, loss: 3.202838, norm: 0.2641, time(ms): 790.30, token/sec:663402.66, hellaswag_acc: 0.2878
Step:  8237, loss: 3.181317, norm: 0.2696, time(ms): 791.35, token/sec:662524.63, hellaswag_acc: 0.2878
Step:  8238, loss: 3.263520, norm: 0.2665, time(ms): 793.89, token/sec:660402.45, hellaswag_acc: 0.2878
Step:  8239, loss: 3.241233, norm: 0.3049, time(ms): 797.45, token/sec:657456.57, hellaswag_acc: 0.2878
Step:  8240, loss: 3.220869, norm: 0.2668, time(ms): 801.02, token/sec:654524.39, hellaswag_acc: 0.2878
Step:  8241, loss: 3.195435, norm: 0.2828, time(ms): 800.28, token/sec:655128.68, hellaswag_acc: 0.2878
Step:  8242, loss: 3.208351, norm: 0.2637, time(ms): 800.35, token/sec:655075.79, hellaswag_acc: 0.2878
Step:  8243, loss: 3.166768, norm: 0.2588, time(ms): 799.94, token/sec:655407.50, hellaswag_acc: 0.2878
Step:  8244, loss: 3.131286, norm: 0.2465, time(ms): 799.49, token/sec:655781.21, hellaswag_acc: 0.2878
Step:  8245, loss: 3.212677, norm: 0.2580, time(ms): 793.65, token/sec:660604.01, hellaswag_acc: 0.2878
Step:  8246, loss: 3.306649, norm: 0.2618, time(ms): 788.58, token/sec:664853.21, hellaswag_acc: 0.2878
Step:  8247, loss: 3.215543, norm: 0.2836, time(ms): 790.16, token/sec:663521.36, hellaswag_acc: 0.2878
Step:  8248, loss: 3.254338, norm: 0.2800, time(ms): 791.57, token/sec:662343.24, hellaswag_acc: 0.2878
Step:  8249, loss: 3.208586, norm: 0.2818, time(ms): 793.36, token/sec:660847.60, hellaswag_acc: 0.2878
rank 0 sample 0: Hello, I'm a language model, and I know that it's just too useful to be taken for granted. The thing to remember when writing your own program
rank 0 sample 1: Hello, I'm a language model, I do not know. I don't know what exactly and what's true in my mind.
Now, I think
rank 0 sample 2: Hello, I'm a language model, so I might have got more confused when I talk about the differences of English and how it's used in the English dialect
rank 0 sample 3: Hello, I'm a language model, I will put together a simple language (a whole language) that doesn't require "discovery"
- "That
rank 1 sample 0: Hello, I'm a language model, how are you going to use it by yourself? What should you do with a language model? Is it something you can
rank 1 sample 1: Hello, I'm a language model, not an interpreter. I'm a native speaker. I mean, I'm a system literate.
I'm a
rank 1 sample 2: Hello, I'm a language model, I work for some people, I'm a language model and what is it?
I don't think it will ever
rank 1 sample 3: Hello, I'm a language model, not a language-specific knowledge system. Just like that."
We don't know or take our word for it,
Step:  8250, loss: 3.211495, norm: 0.2630, time(ms): 3773.38, token/sec:138943.94, val_loss: 3.2333, hellaswag_acc: 0.2878
Step:  8251, loss: 3.183457, norm: 0.2618, time(ms): 785.92, token/sec:667096.81, hellaswag_acc: 0.2878
Step:  8252, loss: 3.196026, norm: 0.2722, time(ms): 795.18, token/sec:659335.38, hellaswag_acc: 0.2878
Step:  8253, loss: 3.245385, norm: 0.2806, time(ms): 793.21, token/sec:660968.37, hellaswag_acc: 0.2878
Step:  8254, loss: 3.262914, norm: 0.2860, time(ms): 797.00, token/sec:657827.10, hellaswag_acc: 0.2878
Step:  8255, loss: 3.273975, norm: 0.2673, time(ms): 788.32, token/sec:665065.95, hellaswag_acc: 0.2878
Step:  8256, loss: 3.184718, norm: 0.2748, time(ms): 786.88, token/sec:666289.92, hellaswag_acc: 0.2878
Step:  8257, loss: 3.247917, norm: 0.2635, time(ms): 789.89, token/sec:663750.28, hellaswag_acc: 0.2878
Step:  8258, loss: 3.306191, norm: 0.2567, time(ms): 788.70, token/sec:664749.10, hellaswag_acc: 0.2878
Step:  8259, loss: 3.197304, norm: 0.2824, time(ms): 797.90, token/sec:657086.65, hellaswag_acc: 0.2878
Step:  8260, loss: 3.259002, norm: 0.2984, time(ms): 805.94, token/sec:650532.58, hellaswag_acc: 0.2878
Step:  8261, loss: 3.172335, norm: 0.2773, time(ms): 802.24, token/sec:653530.01, hellaswag_acc: 0.2878
Step:  8262, loss: 3.246542, norm: 0.3083, time(ms): 784.24, token/sec:668529.43, hellaswag_acc: 0.2878
Step:  8263, loss: 3.260474, norm: 0.3009, time(ms): 787.44, token/sec:665812.21, hellaswag_acc: 0.2878
Step:  8264, loss: 3.261017, norm: 0.2671, time(ms): 797.20, token/sec:657664.60, hellaswag_acc: 0.2878
Step:  8265, loss: 3.237186, norm: 0.3074, time(ms): 792.60, token/sec:661480.54, hellaswag_acc: 0.2878
Step:  8266, loss: 3.161930, norm: 0.2955, time(ms): 788.27, token/sec:665112.81, hellaswag_acc: 0.2878
Step:  8267, loss: 3.208567, norm: 0.2732, time(ms): 792.68, token/sec:661413.49, hellaswag_acc: 0.2878
Step:  8268, loss: 3.221501, norm: 0.2981, time(ms): 792.06, token/sec:661928.14, hellaswag_acc: 0.2878
Step:  8269, loss: 3.202504, norm: 0.2531, time(ms): 802.24, token/sec:653532.53, hellaswag_acc: 0.2878
Step:  8270, loss: 3.186540, norm: 0.2684, time(ms): 796.88, token/sec:657926.69, hellaswag_acc: 0.2878
Step:  8271, loss: 3.208552, norm: 0.2733, time(ms): 790.56, token/sec:663186.18, hellaswag_acc: 0.2878
Step:  8272, loss: 3.217140, norm: 0.3156, time(ms): 785.81, token/sec:667197.60, hellaswag_acc: 0.2878
Step:  8273, loss: 3.157795, norm: 0.2864, time(ms): 791.19, token/sec:662658.39, hellaswag_acc: 0.2878
Step:  8274, loss: 3.225517, norm: 0.2823, time(ms): 789.99, token/sec:663667.14, hellaswag_acc: 0.2878
Step:  8275, loss: 3.197065, norm: 0.2740, time(ms): 793.88, token/sec:660411.97, hellaswag_acc: 0.2878
Step:  8276, loss: 3.195048, norm: 0.2544, time(ms): 791.23, token/sec:662621.05, hellaswag_acc: 0.2878
Step:  8277, loss: 3.170190, norm: 0.2549, time(ms): 786.59, token/sec:666532.07, hellaswag_acc: 0.2878
Step:  8278, loss: 3.214800, norm: 0.2557, time(ms): 791.14, token/sec:662700.53, hellaswag_acc: 0.2878
Step:  8279, loss: 3.198024, norm: 0.2612, time(ms): 794.63, token/sec:659790.37, hellaswag_acc: 0.2878
Step:  8280, loss: 3.210267, norm: 0.2630, time(ms): 804.23, token/sec:651913.22, hellaswag_acc: 0.2878
Step:  8281, loss: 3.238138, norm: 0.2575, time(ms): 798.77, token/sec:656365.29, hellaswag_acc: 0.2878
Step:  8282, loss: 3.188843, norm: 0.2783, time(ms): 795.52, token/sec:659048.26, hellaswag_acc: 0.2878
Step:  8283, loss: 3.238304, norm: 0.2589, time(ms): 800.60, token/sec:654867.25, hellaswag_acc: 0.2878
Step:  8284, loss: 3.173601, norm: 0.2918, time(ms): 807.03, token/sec:649649.30, hellaswag_acc: 0.2878
Step:  8285, loss: 3.204969, norm: 0.2714, time(ms): 791.38, token/sec:662501.27, hellaswag_acc: 0.2878
Step:  8286, loss: 3.213718, norm: 0.2708, time(ms): 792.18, token/sec:661830.13, hellaswag_acc: 0.2878
Step:  8287, loss: 3.258828, norm: 0.2792, time(ms): 794.96, token/sec:659515.91, hellaswag_acc: 0.2878
Step:  8288, loss: 3.252737, norm: 0.2637, time(ms): 795.17, token/sec:659342.89, hellaswag_acc: 0.2878
Step:  8289, loss: 3.284636, norm: 0.3292, time(ms): 798.16, token/sec:656872.11, hellaswag_acc: 0.2878
Step:  8290, loss: 3.276105, norm: 0.3121, time(ms): 790.93, token/sec:662872.32, hellaswag_acc: 0.2878
Step:  8291, loss: 3.241208, norm: 0.3407, time(ms): 787.76, token/sec:665539.36, hellaswag_acc: 0.2878
Step:  8292, loss: 3.247982, norm: 0.2934, time(ms): 789.91, token/sec:663732.85, hellaswag_acc: 0.2878
Step:  8293, loss: 3.339314, norm: 0.2962, time(ms): 796.75, token/sec:658037.34, hellaswag_acc: 0.2878
Step:  8294, loss: 3.257527, norm: 0.3265, time(ms): 796.52, token/sec:658226.82, hellaswag_acc: 0.2878
Step:  8295, loss: 3.276632, norm: 0.2980, time(ms): 803.57, token/sec:652450.55, hellaswag_acc: 0.2878
Step:  8296, loss: 3.241641, norm: 0.3335, time(ms): 796.21, token/sec:658478.52, hellaswag_acc: 0.2878
Step:  8297, loss: 3.249099, norm: 0.3329, time(ms): 803.66, token/sec:652374.68, hellaswag_acc: 0.2878
Step:  8298, loss: 3.172647, norm: 0.3133, time(ms): 797.87, token/sec:657107.07, hellaswag_acc: 0.2878
Step:  8299, loss: 3.162050, norm: 0.2848, time(ms): 801.07, token/sec:654483.87, hellaswag_acc: 0.2878
Step:  8300, loss: 3.216635, norm: 0.2809, time(ms): 801.33, token/sec:654269.08, hellaswag_acc: 0.2878
Step:  8301, loss: 3.212394, norm: 0.2681, time(ms): 799.76, token/sec:655556.97, hellaswag_acc: 0.2878
Step:  8302, loss: 3.173249, norm: 0.2865, time(ms): 794.19, token/sec:660153.04, hellaswag_acc: 0.2878
Step:  8303, loss: 3.232254, norm: 0.2479, time(ms): 804.92, token/sec:651355.17, hellaswag_acc: 0.2878
Step:  8304, loss: 3.199220, norm: 0.2672, time(ms): 801.51, token/sec:654124.29, hellaswag_acc: 0.2878
Step:  8305, loss: 3.186162, norm: 0.2681, time(ms): 797.06, token/sec:657773.98, hellaswag_acc: 0.2878
Step:  8306, loss: 3.156381, norm: 0.2465, time(ms): 794.18, token/sec:660161.96, hellaswag_acc: 0.2878
Step:  8307, loss: 3.199416, norm: 0.2741, time(ms): 805.45, token/sec:650923.87, hellaswag_acc: 0.2878
Step:  8308, loss: 3.176339, norm: 0.2566, time(ms): 792.63, token/sec:661449.70, hellaswag_acc: 0.2878
Step:  8309, loss: 3.214688, norm: 0.2717, time(ms): 791.96, token/sec:662009.45, hellaswag_acc: 0.2878
Step:  8310, loss: 3.199412, norm: 0.2381, time(ms): 787.47, token/sec:665788.62, hellaswag_acc: 0.2878
Step:  8311, loss: 3.194508, norm: 0.2755, time(ms): 791.74, token/sec:662200.82, hellaswag_acc: 0.2878
Step:  8312, loss: 3.200541, norm: 0.2382, time(ms): 792.90, token/sec:661230.52, hellaswag_acc: 0.2878
Step:  8313, loss: 3.216732, norm: 0.2694, time(ms): 794.11, token/sec:660218.25, hellaswag_acc: 0.2878
Step:  8314, loss: 3.176921, norm: 1.1585, time(ms): 790.62, token/sec:663134.39, hellaswag_acc: 0.2878
Step:  8315, loss: 3.207766, norm: 0.4957, time(ms): 795.51, token/sec:659060.31, hellaswag_acc: 0.2878
Step:  8316, loss: 3.229716, norm: 0.3989, time(ms): 792.86, token/sec:661258.95, hellaswag_acc: 0.2878
Step:  8317, loss: 3.209682, norm: 0.3208, time(ms): 788.85, token/sec:664620.11, hellaswag_acc: 0.2878
Step:  8318, loss: 3.231759, norm: 0.3334, time(ms): 786.36, token/sec:666725.66, hellaswag_acc: 0.2878
Step:  8319, loss: 3.170546, norm: 0.3232, time(ms): 789.93, token/sec:663715.42, hellaswag_acc: 0.2878
Step:  8320, loss: 3.253490, norm: 0.3085, time(ms): 803.98, token/sec:652112.93, hellaswag_acc: 0.2878
Step:  8321, loss: 3.171257, norm: 0.3140, time(ms): 796.72, token/sec:658056.83, hellaswag_acc: 0.2878
Step:  8322, loss: 3.239258, norm: 0.3223, time(ms): 803.53, token/sec:652481.33, hellaswag_acc: 0.2878
Step:  8323, loss: 3.270631, norm: 0.3073, time(ms): 794.80, token/sec:659646.49, hellaswag_acc: 0.2878
Step:  8324, loss: 3.260671, norm: 0.2880, time(ms): 803.30, token/sec:652669.76, hellaswag_acc: 0.2878
Step:  8325, loss: 3.265892, norm: 0.3042, time(ms): 798.09, token/sec:656927.25, hellaswag_acc: 0.2878
Step:  8326, loss: 3.233464, norm: 0.2985, time(ms): 803.78, token/sec:652275.21, hellaswag_acc: 0.2878
Step:  8327, loss: 3.283891, norm: 0.2553, time(ms): 795.57, token/sec:659008.95, hellaswag_acc: 0.2878
Step:  8328, loss: 3.255682, norm: 0.2682, time(ms): 796.13, token/sec:658546.95, hellaswag_acc: 0.2878
Step:  8329, loss: 3.217212, norm: 0.2560, time(ms): 805.77, token/sec:650669.05, hellaswag_acc: 0.2878
Step:  8330, loss: 3.191233, norm: 0.2637, time(ms): 802.28, token/sec:653500.87, hellaswag_acc: 0.2878
Step:  8331, loss: 3.233494, norm: 0.2629, time(ms): 790.83, token/sec:662960.85, hellaswag_acc: 0.2878
Step:  8332, loss: 3.253580, norm: 0.2665, time(ms): 799.43, token/sec:655825.60, hellaswag_acc: 0.2878
Step:  8333, loss: 3.222048, norm: 0.2625, time(ms): 805.03, token/sec:651267.20, hellaswag_acc: 0.2878
Step:  8334, loss: 3.242035, norm: 0.2640, time(ms): 799.53, token/sec:655748.55, hellaswag_acc: 0.2878
Step:  8335, loss: 3.207079, norm: 0.2444, time(ms): 792.93, token/sec:661200.70, hellaswag_acc: 0.2878
Step:  8336, loss: 3.191820, norm: 0.2576, time(ms): 791.03, token/sec:662789.01, hellaswag_acc: 0.2878
Step:  8337, loss: 3.292776, norm: 0.2666, time(ms): 791.00, token/sec:662812.78, hellaswag_acc: 0.2878
Step:  8338, loss: 3.208530, norm: 0.2825, time(ms): 790.00, token/sec:663659.33, hellaswag_acc: 0.2878
Step:  8339, loss: 3.209744, norm: 0.2493, time(ms): 791.44, token/sec:662450.58, hellaswag_acc: 0.2878
Step:  8340, loss: 3.252816, norm: 0.2811, time(ms): 802.84, token/sec:653045.59, hellaswag_acc: 0.2878
Step:  8341, loss: 3.212079, norm: 0.2725, time(ms): 802.17, token/sec:653584.01, hellaswag_acc: 0.2878
Step:  8342, loss: 3.244672, norm: 0.2705, time(ms): 802.03, token/sec:653699.22, hellaswag_acc: 0.2878
Step:  8343, loss: 3.280844, norm: 0.3140, time(ms): 791.15, token/sec:662695.14, hellaswag_acc: 0.2878
Step:  8344, loss: 3.179207, norm: 0.3211, time(ms): 797.80, token/sec:657170.10, hellaswag_acc: 0.2878
Step:  8345, loss: 3.186135, norm: 0.2611, time(ms): 792.06, token/sec:661929.94, hellaswag_acc: 0.2878
Step:  8346, loss: 3.193885, norm: 0.2666, time(ms): 790.41, token/sec:663308.81, hellaswag_acc: 0.2878
Step:  8347, loss: 3.209606, norm: 0.2610, time(ms): 798.45, token/sec:656634.98, hellaswag_acc: 0.2878
Step:  8348, loss: 3.202748, norm: 0.2578, time(ms): 790.50, token/sec:663238.19, hellaswag_acc: 0.2878
Step:  8349, loss: 3.194514, norm: 0.2673, time(ms): 783.73, token/sec:668963.02, hellaswag_acc: 0.2878
Step:  8350, loss: 3.193074, norm: 0.2526, time(ms): 792.56, token/sec:661511.38, hellaswag_acc: 0.2878
Step:  8351, loss: 3.237479, norm: 0.2524, time(ms): 798.78, token/sec:656359.41, hellaswag_acc: 0.2878
Step:  8352, loss: 3.212367, norm: 0.2583, time(ms): 802.70, token/sec:653156.34, hellaswag_acc: 0.2878
Step:  8353, loss: 3.209122, norm: 0.2493, time(ms): 793.25, token/sec:660935.99, hellaswag_acc: 0.2878
Step:  8354, loss: 3.268785, norm: 0.2561, time(ms): 801.29, token/sec:654301.01, hellaswag_acc: 0.2878
Step:  8355, loss: 3.199308, norm: 0.2710, time(ms): 803.02, token/sec:652898.03, hellaswag_acc: 0.2878
Step:  8356, loss: 3.191926, norm: 0.2519, time(ms): 802.02, token/sec:653707.77, hellaswag_acc: 0.2878
Step:  8357, loss: 3.154451, norm: 0.2647, time(ms): 791.49, token/sec:662409.08, hellaswag_acc: 0.2878
Step:  8358, loss: 3.180434, norm: 0.2680, time(ms): 806.49, token/sec:650085.07, hellaswag_acc: 0.2878
Step:  8359, loss: 3.282090, norm: 0.2696, time(ms): 801.93, token/sec:653779.48, hellaswag_acc: 0.2878
Step:  8360, loss: 3.242868, norm: 0.2804, time(ms): 797.78, token/sec:657180.32, hellaswag_acc: 0.2878
Step:  8361, loss: 3.160016, norm: 0.2492, time(ms): 792.23, token/sec:661787.31, hellaswag_acc: 0.2878
Step:  8362, loss: 3.236074, norm: 0.2753, time(ms): 808.66, token/sec:648345.69, hellaswag_acc: 0.2878
Step:  8363, loss: 3.178281, norm: 0.2686, time(ms): 800.14, token/sec:655241.70, hellaswag_acc: 0.2878
Step:  8364, loss: 3.211448, norm: 0.2952, time(ms): 792.30, token/sec:661730.55, hellaswag_acc: 0.2878
Step:  8365, loss: 3.254205, norm: 0.2530, time(ms): 803.49, token/sec:652510.96, hellaswag_acc: 0.2878
Step:  8366, loss: 3.290906, norm: 0.2960, time(ms): 803.77, token/sec:652285.27, hellaswag_acc: 0.2878
Step:  8367, loss: 3.227365, norm: 0.2519, time(ms): 798.24, token/sec:656808.55, hellaswag_acc: 0.2878
Step:  8368, loss: 3.210011, norm: 0.2768, time(ms): 800.40, token/sec:655036.18, hellaswag_acc: 0.2878
Step:  8369, loss: 3.231416, norm: 0.2956, time(ms): 798.06, token/sec:656950.22, hellaswag_acc: 0.2878
Step:  8370, loss: 3.235837, norm: 0.2762, time(ms): 800.71, token/sec:654778.91, hellaswag_acc: 0.2878
Step:  8371, loss: 3.212983, norm: 0.2676, time(ms): 800.07, token/sec:655298.91, hellaswag_acc: 0.2878
Step:  8372, loss: 3.215691, norm: 0.2695, time(ms): 795.76, token/sec:658848.43, hellaswag_acc: 0.2878
Step:  8373, loss: 3.265880, norm: 0.2657, time(ms): 805.67, token/sec:650746.65, hellaswag_acc: 0.2878
Step:  8374, loss: 3.220212, norm: 0.3185, time(ms): 796.45, token/sec:658282.58, hellaswag_acc: 0.2878
Step:  8375, loss: 3.253093, norm: 0.2564, time(ms): 795.19, token/sec:659321.34, hellaswag_acc: 0.2878
Step:  8376, loss: 3.203749, norm: 0.2991, time(ms): 806.05, token/sec:650439.64, hellaswag_acc: 0.2878
Step:  8377, loss: 3.196820, norm: 0.2894, time(ms): 801.38, token/sec:654233.46, hellaswag_acc: 0.2878
Step:  8378, loss: 3.236394, norm: 0.2636, time(ms): 790.17, token/sec:663513.15, hellaswag_acc: 0.2878
Step:  8379, loss: 3.244844, norm: 0.2955, time(ms): 803.73, token/sec:652317.39, hellaswag_acc: 0.2878
Step:  8380, loss: 3.225840, norm: 0.2971, time(ms): 805.85, token/sec:650606.49, hellaswag_acc: 0.2878
Step:  8381, loss: 3.227710, norm: 0.2792, time(ms): 1288.88, token/sec:406776.59, hellaswag_acc: 0.2878
Step:  8382, loss: 3.196823, norm: 0.2708, time(ms): 770.97, token/sec:680041.16, hellaswag_acc: 0.2878
Step:  8383, loss: 3.161994, norm: 0.2986, time(ms): 785.62, token/sec:667351.89, hellaswag_acc: 0.2878
Step:  8384, loss: 3.192668, norm: 0.2550, time(ms): 793.37, token/sec:660836.08, hellaswag_acc: 0.2878
Step:  8385, loss: 3.312027, norm: 0.2668, time(ms): 786.50, token/sec:666605.21, hellaswag_acc: 0.2878
Step:  8386, loss: 3.191943, norm: 0.2660, time(ms): 780.97, token/sec:671332.03, hellaswag_acc: 0.2878
Step:  8387, loss: 3.158346, norm: 0.2741, time(ms): 781.03, token/sec:671280.18, hellaswag_acc: 0.2878
Step:  8388, loss: 3.212487, norm: 0.2774, time(ms): 803.32, token/sec:652650.78, hellaswag_acc: 0.2878
Step:  8389, loss: 3.166622, norm: 0.2762, time(ms): 790.64, token/sec:663120.99, hellaswag_acc: 0.2878
Step:  8390, loss: 3.184351, norm: 0.2902, time(ms): 784.88, token/sec:667982.95, hellaswag_acc: 0.2878
Step:  8391, loss: 3.187314, norm: 0.2752, time(ms): 791.68, token/sec:662243.30, hellaswag_acc: 0.2878
Step:  8392, loss: 3.225069, norm: 0.2959, time(ms): 794.76, token/sec:659678.94, hellaswag_acc: 0.2878
Step:  8393, loss: 3.192973, norm: 0.3054, time(ms): 799.73, token/sec:655581.01, hellaswag_acc: 0.2878
Step:  8394, loss: 3.217849, norm: 0.2731, time(ms): 800.57, token/sec:654895.13, hellaswag_acc: 0.2878
Step:  8395, loss: 3.210683, norm: 0.2804, time(ms): 801.71, token/sec:653960.11, hellaswag_acc: 0.2878
Step:  8396, loss: 3.227945, norm: 0.3083, time(ms): 802.95, token/sec:652949.02, hellaswag_acc: 0.2878
Step:  8397, loss: 3.236309, norm: 0.2753, time(ms): 796.20, token/sec:658491.73, hellaswag_acc: 0.2878
Step:  8398, loss: 3.236870, norm: 0.2984, time(ms): 793.22, token/sec:660957.64, hellaswag_acc: 0.2878
Step:  8399, loss: 3.224338, norm: 0.2718, time(ms): 791.42, token/sec:662460.76, hellaswag_acc: 0.2878
Step:  8400, loss: 3.144083, norm: 0.2800, time(ms): 791.23, token/sec:662626.64, hellaswag_acc: 0.2878
Step:  8401, loss: 3.247670, norm: 0.2730, time(ms): 802.82, token/sec:653054.89, hellaswag_acc: 0.2878
Step:  8402, loss: 3.261851, norm: 0.2718, time(ms): 798.60, token/sec:656512.06, hellaswag_acc: 0.2878
Step:  8403, loss: 3.184026, norm: 0.2805, time(ms): 800.98, token/sec:654554.58, hellaswag_acc: 0.2878
Step:  8404, loss: 3.227743, norm: 0.2889, time(ms): 798.20, token/sec:656838.37, hellaswag_acc: 0.2878
Step:  8405, loss: 3.221766, norm: 0.2635, time(ms): 802.10, token/sec:653648.12, hellaswag_acc: 0.2878
Step:  8406, loss: 3.191746, norm: 0.2768, time(ms): 796.35, token/sec:658363.39, hellaswag_acc: 0.2878
Step:  8407, loss: 3.199729, norm: 0.2674, time(ms): 796.97, token/sec:657855.05, hellaswag_acc: 0.2878
Step:  8408, loss: 3.215853, norm: 0.2708, time(ms): 789.85, token/sec:663779.93, hellaswag_acc: 0.2878
Step:  8409, loss: 3.138672, norm: 0.2935, time(ms): 787.48, token/sec:665776.13, hellaswag_acc: 0.2878
Step:  8410, loss: 3.244440, norm: 0.2797, time(ms): 789.54, token/sec:664040.71, hellaswag_acc: 0.2878
Step:  8411, loss: 3.186351, norm: 0.2680, time(ms): 793.02, token/sec:661124.36, hellaswag_acc: 0.2878
Step:  8412, loss: 3.195761, norm: 0.2709, time(ms): 791.79, token/sec:662151.57, hellaswag_acc: 0.2878
Step:  8413, loss: 3.251804, norm: 0.2658, time(ms): 787.78, token/sec:665523.25, hellaswag_acc: 0.2878
Step:  8414, loss: 3.261222, norm: 0.2972, time(ms): 791.60, token/sec:662317.90, hellaswag_acc: 0.2878
Step:  8415, loss: 3.175645, norm: 0.2762, time(ms): 788.20, token/sec:665169.95, hellaswag_acc: 0.2878
Step:  8416, loss: 3.160171, norm: 0.2600, time(ms): 797.24, token/sec:657626.64, hellaswag_acc: 0.2878
Step:  8417, loss: 3.162091, norm: 0.2838, time(ms): 790.68, token/sec:663085.80, hellaswag_acc: 0.2878
Step:  8418, loss: 3.181220, norm: 0.2605, time(ms): 795.68, token/sec:658918.12, hellaswag_acc: 0.2878
Step:  8419, loss: 3.168051, norm: 0.3539, time(ms): 789.39, token/sec:664166.66, hellaswag_acc: 0.2878
Step:  8420, loss: 3.216185, norm: 0.2740, time(ms): 785.20, token/sec:667714.61, hellaswag_acc: 0.2878
Step:  8421, loss: 3.166737, norm: 0.2654, time(ms): 789.47, token/sec:664101.47, hellaswag_acc: 0.2878
Step:  8422, loss: 3.155764, norm: 0.2638, time(ms): 800.45, token/sec:654989.94, hellaswag_acc: 0.2878
Step:  8423, loss: 3.181217, norm: 0.2584, time(ms): 797.66, token/sec:657281.08, hellaswag_acc: 0.2878
Step:  8424, loss: 3.228241, norm: 0.2723, time(ms): 797.92, token/sec:657066.82, hellaswag_acc: 0.2878
Step:  8425, loss: 3.160183, norm: 0.2635, time(ms): 803.57, token/sec:652445.91, hellaswag_acc: 0.2878
Step:  8426, loss: 3.239848, norm: 0.2876, time(ms): 797.98, token/sec:657015.19, hellaswag_acc: 0.2878
Step:  8427, loss: 3.226587, norm: 0.3078, time(ms): 800.47, token/sec:654977.84, hellaswag_acc: 0.2878
Step:  8428, loss: 3.207338, norm: 0.2867, time(ms): 795.49, token/sec:659071.76, hellaswag_acc: 0.2878
Step:  8429, loss: 3.224823, norm: 0.2901, time(ms): 804.50, token/sec:651695.10, hellaswag_acc: 0.2878
Step:  8430, loss: 3.234945, norm: 0.3169, time(ms): 800.12, token/sec:655262.59, hellaswag_acc: 0.2878
Step:  8431, loss: 3.163258, norm: 0.2810, time(ms): 798.51, token/sec:656585.37, hellaswag_acc: 0.2878
Step:  8432, loss: 3.182236, norm: 0.3156, time(ms): 799.09, token/sec:656107.37, hellaswag_acc: 0.2878
Step:  8433, loss: 3.223290, norm: 0.2880, time(ms): 802.66, token/sec:653188.74, hellaswag_acc: 0.2878
Step:  8434, loss: 3.182130, norm: 0.2707, time(ms): 793.35, token/sec:660853.76, hellaswag_acc: 0.2878
Step:  8435, loss: 3.166324, norm: 0.2898, time(ms): 805.11, token/sec:651198.74, hellaswag_acc: 0.2878
Step:  8436, loss: 3.175616, norm: 0.2828, time(ms): 798.28, token/sec:656769.51, hellaswag_acc: 0.2878
Step:  8437, loss: 3.183093, norm: 0.2772, time(ms): 802.14, token/sec:653610.81, hellaswag_acc: 0.2878
Step:  8438, loss: 3.228760, norm: 0.2622, time(ms): 795.53, token/sec:659043.52, hellaswag_acc: 0.2878
Step:  8439, loss: 3.175150, norm: 0.2701, time(ms): 799.88, token/sec:655458.88, hellaswag_acc: 0.2878
Step:  8440, loss: 3.207302, norm: 0.2799, time(ms): 804.83, token/sec:651430.81, hellaswag_acc: 0.2878
Step:  8441, loss: 3.191811, norm: 0.2477, time(ms): 794.87, token/sec:659588.32, hellaswag_acc: 0.2878
Step:  8442, loss: 3.222142, norm: 0.2677, time(ms): 800.75, token/sec:654749.87, hellaswag_acc: 0.2878
Step:  8443, loss: 3.209382, norm: 0.2556, time(ms): 802.99, token/sec:652923.04, hellaswag_acc: 0.2878
Step:  8444, loss: 3.228807, norm: 0.2713, time(ms): 797.79, token/sec:657176.19, hellaswag_acc: 0.2878
Step:  8445, loss: 3.201675, norm: 0.2677, time(ms): 795.19, token/sec:659321.54, hellaswag_acc: 0.2878
Step:  8446, loss: 3.189165, norm: 0.2656, time(ms): 806.44, token/sec:650123.51, hellaswag_acc: 0.2878
Step:  8447, loss: 3.229327, norm: 0.2888, time(ms): 798.80, token/sec:656340.61, hellaswag_acc: 0.2878
Step:  8448, loss: 3.175904, norm: 0.2522, time(ms): 795.42, token/sec:659132.61, hellaswag_acc: 0.2878
Step:  8449, loss: 3.235473, norm: 0.2524, time(ms): 804.31, token/sec:651844.62, hellaswag_acc: 0.2878
Step:  8450, loss: 3.202621, norm: 0.2679, time(ms): 799.60, token/sec:655687.55, hellaswag_acc: 0.2878
Step:  8451, loss: 3.208957, norm: 0.3089, time(ms): 800.78, token/sec:654720.62, hellaswag_acc: 0.2878
Step:  8452, loss: 3.199773, norm: 0.3136, time(ms): 795.41, token/sec:659138.14, hellaswag_acc: 0.2878
Step:  8453, loss: 3.188367, norm: 0.2640, time(ms): 803.82, token/sec:652246.39, hellaswag_acc: 0.2878
Step:  8454, loss: 3.226493, norm: 0.2925, time(ms): 799.84, token/sec:655487.99, hellaswag_acc: 0.2878
Step:  8455, loss: 3.223316, norm: 0.2872, time(ms): 788.74, token/sec:664712.53, hellaswag_acc: 0.2878
Step:  8456, loss: 3.194436, norm: 0.2893, time(ms): 789.18, token/sec:664347.84, hellaswag_acc: 0.2878
Step:  8457, loss: 3.156729, norm: 0.2740, time(ms): 793.78, token/sec:660496.27, hellaswag_acc: 0.2878
Step:  8458, loss: 3.157037, norm: 0.2748, time(ms): 791.66, token/sec:662265.24, hellaswag_acc: 0.2878
Step:  8459, loss: 3.163469, norm: 0.2610, time(ms): 791.75, token/sec:662189.86, hellaswag_acc: 0.2878
Step:  8460, loss: 3.201031, norm: 0.2666, time(ms): 801.88, token/sec:653825.55, hellaswag_acc: 0.2878
Step:  8461, loss: 3.191246, norm: 0.2823, time(ms): 799.67, token/sec:655627.53, hellaswag_acc: 0.2878
Step:  8462, loss: 3.154142, norm: 0.2720, time(ms): 802.16, token/sec:653598.38, hellaswag_acc: 0.2878
Step:  8463, loss: 3.211250, norm: 0.2771, time(ms): 800.03, token/sec:655335.63, hellaswag_acc: 0.2878
Step:  8464, loss: 3.226716, norm: 0.2793, time(ms): 793.34, token/sec:660858.52, hellaswag_acc: 0.2878
Step:  8465, loss: 3.169385, norm: 0.2837, time(ms): 800.41, token/sec:655021.93, hellaswag_acc: 0.2878
Step:  8466, loss: 3.203655, norm: 0.2755, time(ms): 797.86, token/sec:657119.44, hellaswag_acc: 0.2878
Step:  8467, loss: 3.244147, norm: 0.2886, time(ms): 792.88, token/sec:661246.23, hellaswag_acc: 0.2878
Step:  8468, loss: 3.183540, norm: 0.2921, time(ms): 793.38, token/sec:660827.94, hellaswag_acc: 0.2878
Step:  8469, loss: 3.164787, norm: 0.2944, time(ms): 796.12, token/sec:658551.68, hellaswag_acc: 0.2878
Step:  8470, loss: 3.166066, norm: 0.2760, time(ms): 800.69, token/sec:654791.98, hellaswag_acc: 0.2878
Step:  8471, loss: 3.205579, norm: 0.3093, time(ms): 802.77, token/sec:653102.61, hellaswag_acc: 0.2878
Step:  8472, loss: 3.196648, norm: 0.2828, time(ms): 794.04, token/sec:660279.31, hellaswag_acc: 0.2878
Step:  8473, loss: 3.216187, norm: 0.2948, time(ms): 792.16, token/sec:661847.46, hellaswag_acc: 0.2878
Step:  8474, loss: 3.145903, norm: 0.2895, time(ms): 785.05, token/sec:667838.31, hellaswag_acc: 0.2878
Step:  8475, loss: 3.190545, norm: 0.2599, time(ms): 792.64, token/sec:661442.73, hellaswag_acc: 0.2878
Step:  8476, loss: 3.187690, norm: 0.2824, time(ms): 795.19, token/sec:659327.07, hellaswag_acc: 0.2878
Step:  8477, loss: 3.256334, norm: 0.2769, time(ms): 802.43, token/sec:653371.75, hellaswag_acc: 0.2878
Step:  8478, loss: 3.210515, norm: 0.2622, time(ms): 789.42, token/sec:664145.39, hellaswag_acc: 0.2878
Step:  8479, loss: 3.202995, norm: 0.2627, time(ms): 790.06, token/sec:663601.86, hellaswag_acc: 0.2878
Step:  8480, loss: 3.196754, norm: 0.2685, time(ms): 788.29, token/sec:665094.31, hellaswag_acc: 0.2878
Step:  8481, loss: 3.214353, norm: 0.2835, time(ms): 791.92, token/sec:662048.51, hellaswag_acc: 0.2878
Step:  8482, loss: 3.236362, norm: 0.2731, time(ms): 797.16, token/sec:657692.73, hellaswag_acc: 0.2878
Step:  8483, loss: 3.182990, norm: 0.2852, time(ms): 790.90, token/sec:662902.30, hellaswag_acc: 0.2878
Step:  8484, loss: 3.182183, norm: 0.2657, time(ms): 792.71, token/sec:661386.63, hellaswag_acc: 0.2878
Step:  8485, loss: 3.164158, norm: 0.2816, time(ms): 792.18, token/sec:661826.14, hellaswag_acc: 0.2878
Step:  8486, loss: 3.136930, norm: 0.2673, time(ms): 789.23, token/sec:664301.28, hellaswag_acc: 0.2878
Step:  8487, loss: 3.169569, norm: 0.2558, time(ms): 787.02, token/sec:666171.64, hellaswag_acc: 0.2878
Step:  8488, loss: 3.129323, norm: 0.2880, time(ms): 793.23, token/sec:660953.67, hellaswag_acc: 0.2878
Step:  8489, loss: 3.146852, norm: 0.2718, time(ms): 791.01, token/sec:662806.19, hellaswag_acc: 0.2878
Step:  8490, loss: 3.142585, norm: 0.2514, time(ms): 802.05, token/sec:653684.84, hellaswag_acc: 0.2878
Step:  8491, loss: 3.166791, norm: 0.2633, time(ms): 801.66, token/sec:654000.56, hellaswag_acc: 0.2878
Step:  8492, loss: 3.160741, norm: 0.2626, time(ms): 799.21, token/sec:656011.08, hellaswag_acc: 0.2878
Step:  8493, loss: 3.203410, norm: 0.2810, time(ms): 800.01, token/sec:655348.32, hellaswag_acc: 0.2878
Step:  8494, loss: 3.185119, norm: 0.2611, time(ms): 797.68, token/sec:657264.58, hellaswag_acc: 0.2878
Step:  8495, loss: 3.159949, norm: 0.2573, time(ms): 803.02, token/sec:652898.81, hellaswag_acc: 0.2878
Step:  8496, loss: 3.187872, norm: 0.2707, time(ms): 797.18, token/sec:657680.73, hellaswag_acc: 0.2878
Step:  8497, loss: 3.253283, norm: 0.2603, time(ms): 800.78, token/sec:654718.87, hellaswag_acc: 0.2878
Step:  8498, loss: 3.134795, norm: 0.2755, time(ms): 799.29, token/sec:655938.48, hellaswag_acc: 0.2878
Step:  8499, loss: 3.203567, norm: 0.2746, time(ms): 800.55, token/sec:654911.71, hellaswag_acc: 0.2878
rank 0 sample 0: Hello, I'm a language model, and I think that it's really hard to figure out how to describe such language. It's kind of a little trick
rank 0 sample 1: Hello, I'm a language model, so to translate it into a programming language, we usually convert the text/program to an expression, instead of the expression
rank 0 sample 2: Hello, I'm a language model, but I like that they'll go over the idea of a function that takes a function as an argument and returns an output
rank 0 sample 3: Hello, I'm a language model, so maybe I could use it as a language models.
One key issue in interpreting is that language models are generally constructed
rank 1 sample 0: Hello, I'm a language model, an app for the mobile app. On this I'll describe everything I've learned in a single app.
I'll
rank 1 sample 1: Hello, I'm a language model, not an interpreter.
I'll give you a short talk about two aspects of NCI, if I'm not familiar
rank 1 sample 2: Hello, I'm a language model, so people have to be able to understand it.
The only problem I'd like to get to is how much "
rank 1 sample 3: Hello, I'm a language model, and I'm doing my second language and learn a lot if I try to improve my training process. I'm working on
Step:  8500, loss: 3.179312, norm: 0.2688, time(ms): 3768.77, token/sec:139113.96, val_loss: 3.2264, hellaswag_acc: 0.2878
Step:  8501, loss: 3.191993, norm: 0.2609, time(ms): 785.16, token/sec:667744.01, hellaswag_acc: 0.2878
Step:  8502, loss: 3.176205, norm: 0.2630, time(ms): 793.59, token/sec:660655.61, hellaswag_acc: 0.2878
Step:  8503, loss: 3.185485, norm: 0.2703, time(ms): 792.78, token/sec:661329.75, hellaswag_acc: 0.2878
Step:  8504, loss: 3.180173, norm: 0.2562, time(ms): 799.84, token/sec:655493.46, hellaswag_acc: 0.2878
Step:  8505, loss: 3.236093, norm: 0.2608, time(ms): 789.71, token/sec:663900.17, hellaswag_acc: 0.2878
Step:  8506, loss: 3.151320, norm: 0.2585, time(ms): 786.34, token/sec:666747.09, hellaswag_acc: 0.2878
Step:  8507, loss: 3.193534, norm: 0.2597, time(ms): 794.36, token/sec:660010.19, hellaswag_acc: 0.2878
Step:  8508, loss: 3.165023, norm: 0.2595, time(ms): 790.61, token/sec:663142.39, hellaswag_acc: 0.2878
Step:  8509, loss: 3.248920, norm: 0.2868, time(ms): 791.00, token/sec:662815.58, hellaswag_acc: 0.2878
Step:  8510, loss: 3.231413, norm: 0.2710, time(ms): 796.99, token/sec:657836.94, hellaswag_acc: 0.2878
Step:  8511, loss: 3.156788, norm: 0.3145, time(ms): 791.71, token/sec:662221.17, hellaswag_acc: 0.2878
Step:  8512, loss: 3.172293, norm: 0.2822, time(ms): 785.81, token/sec:667195.58, hellaswag_acc: 0.2878
Step:  8513, loss: 3.176848, norm: 0.2473, time(ms): 789.52, token/sec:664055.95, hellaswag_acc: 0.2878
Step:  8514, loss: 3.328843, norm: 0.3110, time(ms): 799.78, token/sec:655538.21, hellaswag_acc: 0.2878
Step:  8515, loss: 3.177335, norm: 0.2690, time(ms): 800.01, token/sec:655355.74, hellaswag_acc: 0.2878
Step:  8516, loss: 3.155296, norm: 0.2605, time(ms): 797.35, token/sec:657540.71, hellaswag_acc: 0.2878
Step:  8517, loss: 3.198701, norm: 0.2735, time(ms): 796.07, token/sec:658591.91, hellaswag_acc: 0.2878
Step:  8518, loss: 3.199468, norm: 0.2713, time(ms): 792.36, token/sec:661680.97, hellaswag_acc: 0.2878
Step:  8519, loss: 3.194067, norm: 0.2999, time(ms): 794.98, token/sec:659499.89, hellaswag_acc: 0.2878
Step:  8520, loss: 3.177181, norm: 0.2542, time(ms): 794.85, token/sec:659610.28, hellaswag_acc: 0.2878
Step:  8521, loss: 3.113348, norm: 0.2695, time(ms): 802.64, token/sec:653201.35, hellaswag_acc: 0.2878
Step:  8522, loss: 3.160607, norm: 0.2757, time(ms): 803.13, token/sec:652807.52, hellaswag_acc: 0.2878
Step:  8523, loss: 3.187558, norm: 0.2518, time(ms): 793.69, token/sec:660572.06, hellaswag_acc: 0.2878
Step:  8524, loss: 3.112876, norm: 0.2828, time(ms): 801.64, token/sec:654022.15, hellaswag_acc: 0.2878
Step:  8525, loss: 3.119034, norm: 0.2784, time(ms): 799.55, token/sec:655732.52, hellaswag_acc: 0.2878
Step:  8526, loss: 3.177963, norm: 0.2813, time(ms): 805.26, token/sec:651081.51, hellaswag_acc: 0.2878
Step:  8527, loss: 3.149887, norm: 0.2748, time(ms): 793.32, token/sec:660877.39, hellaswag_acc: 0.2878
Step:  8528, loss: 3.190041, norm: 0.3088, time(ms): 795.66, token/sec:658934.31, hellaswag_acc: 0.2878
Step:  8529, loss: 3.168360, norm: 0.2942, time(ms): 787.52, token/sec:665746.70, hellaswag_acc: 0.2878
Step:  8530, loss: 3.168687, norm: 0.2912, time(ms): 791.03, token/sec:662795.60, hellaswag_acc: 0.2878
Step:  8531, loss: 3.133417, norm: 0.2749, time(ms): 789.14, token/sec:664381.16, hellaswag_acc: 0.2878
Step:  8532, loss: 3.231907, norm: 0.3172, time(ms): 801.01, token/sec:654536.86, hellaswag_acc: 0.2878
Step:  8533, loss: 3.208961, norm: 0.3000, time(ms): 794.44, token/sec:659943.63, hellaswag_acc: 0.2878
Step:  8534, loss: 3.229813, norm: 0.3114, time(ms): 803.03, token/sec:652885.05, hellaswag_acc: 0.2878
Step:  8535, loss: 3.241271, norm: 0.2996, time(ms): 801.77, token/sec:653915.18, hellaswag_acc: 0.2878
Step:  8536, loss: 3.238061, norm: 0.2903, time(ms): 802.01, token/sec:653719.82, hellaswag_acc: 0.2878
Step:  8537, loss: 3.174389, norm: 0.3351, time(ms): 783.22, token/sec:669397.37, hellaswag_acc: 0.2878
Step:  8538, loss: 3.198159, norm: 0.3091, time(ms): 788.86, token/sec:664613.08, hellaswag_acc: 0.2878
Step:  8539, loss: 3.245224, norm: 0.3069, time(ms): 797.45, token/sec:657454.60, hellaswag_acc: 0.2878
Step:  8540, loss: 3.207665, norm: 0.3116, time(ms): 792.65, token/sec:661435.77, hellaswag_acc: 0.2878
Step:  8541, loss: 3.209870, norm: 0.3017, time(ms): 787.37, token/sec:665871.68, hellaswag_acc: 0.2878
Step:  8542, loss: 3.200209, norm: 0.2933, time(ms): 797.92, token/sec:657066.23, hellaswag_acc: 0.2878
Step:  8543, loss: 3.171287, norm: 0.2785, time(ms): 791.47, token/sec:662424.24, hellaswag_acc: 0.2878
Step:  8544, loss: 3.230820, norm: 0.2922, time(ms): 798.16, token/sec:656868.78, hellaswag_acc: 0.2878
Step:  8545, loss: 3.187398, norm: 0.2723, time(ms): 790.04, token/sec:663622.08, hellaswag_acc: 0.2878
Step:  8546, loss: 3.204040, norm: 0.2945, time(ms): 790.37, token/sec:663347.63, hellaswag_acc: 0.2878
Step:  8547, loss: 3.188789, norm: 0.2816, time(ms): 791.69, token/sec:662239.71, hellaswag_acc: 0.2878
Step:  8548, loss: 3.168523, norm: 0.2691, time(ms): 792.88, token/sec:661243.84, hellaswag_acc: 0.2878
Step:  8549, loss: 3.231397, norm: 0.2778, time(ms): 794.70, token/sec:659730.00, hellaswag_acc: 0.2878
Step:  8550, loss: 3.204384, norm: 0.2778, time(ms): 797.10, token/sec:657741.91, hellaswag_acc: 0.2878
Step:  8551, loss: 3.176023, norm: 0.2549, time(ms): 797.11, token/sec:657738.37, hellaswag_acc: 0.2878
Step:  8552, loss: 3.205339, norm: 0.2746, time(ms): 806.24, token/sec:650286.92, hellaswag_acc: 0.2878
Step:  8553, loss: 3.171790, norm: 0.2586, time(ms): 784.74, token/sec:668106.14, hellaswag_acc: 0.2878
Step:  8554, loss: 3.185708, norm: 0.2521, time(ms): 785.98, token/sec:667049.25, hellaswag_acc: 0.2878
Step:  8555, loss: 3.247245, norm: 0.2588, time(ms): 793.71, token/sec:660553.81, hellaswag_acc: 0.2878
Step:  8556, loss: 3.182518, norm: 0.2718, time(ms): 794.50, token/sec:659895.51, hellaswag_acc: 0.2878
Step:  8557, loss: 3.169155, norm: 0.2635, time(ms): 789.40, token/sec:664158.63, hellaswag_acc: 0.2878
Step:  8558, loss: 3.152269, norm: 0.2457, time(ms): 791.99, token/sec:661985.33, hellaswag_acc: 0.2878
Step:  8559, loss: 3.170446, norm: 0.2581, time(ms): 789.93, token/sec:663715.82, hellaswag_acc: 0.2878
Step:  8560, loss: 3.177298, norm: 0.2934, time(ms): 797.20, token/sec:657658.31, hellaswag_acc: 0.2878
Step:  8561, loss: 3.209758, norm: 0.2855, time(ms): 787.37, token/sec:665874.91, hellaswag_acc: 0.2878
Step:  8562, loss: 3.131493, norm: 0.2551, time(ms): 789.96, token/sec:663685.57, hellaswag_acc: 0.2878
Step:  8563, loss: 3.183728, norm: 0.2884, time(ms): 791.61, token/sec:662304.93, hellaswag_acc: 0.2878
Step:  8564, loss: 3.162836, norm: 0.2780, time(ms): 800.01, token/sec:655348.52, hellaswag_acc: 0.2878
Step:  8565, loss: 3.141375, norm: 0.2824, time(ms): 793.27, token/sec:660923.08, hellaswag_acc: 0.2878
Step:  8566, loss: 3.203433, norm: 0.2732, time(ms): 804.29, token/sec:651862.98, hellaswag_acc: 0.2878
Step:  8567, loss: 3.166885, norm: 0.2729, time(ms): 802.97, token/sec:652938.74, hellaswag_acc: 0.2878
Step:  8568, loss: 3.214944, norm: 0.2901, time(ms): 794.11, token/sec:660224.00, hellaswag_acc: 0.2878
Step:  8569, loss: 3.208081, norm: 0.2741, time(ms): 798.97, token/sec:656206.84, hellaswag_acc: 0.2878
Step:  8570, loss: 3.160936, norm: 0.3049, time(ms): 807.23, token/sec:649491.77, hellaswag_acc: 0.2878
Step:  8571, loss: 3.191466, norm: 0.2793, time(ms): 784.73, token/sec:668111.01, hellaswag_acc: 0.2878
Step:  8572, loss: 3.195422, norm: 0.3078, time(ms): 1263.50, token/sec:414948.57, hellaswag_acc: 0.2878
Step:  8573, loss: 3.225389, norm: 0.2607, time(ms): 796.53, token/sec:658218.15, hellaswag_acc: 0.2878
Step:  8574, loss: 3.261141, norm: 0.3297, time(ms): 783.89, token/sec:668825.88, hellaswag_acc: 0.2878
Step:  8575, loss: 3.213191, norm: 0.2683, time(ms): 778.89, token/sec:673120.66, hellaswag_acc: 0.2878
Step:  8576, loss: 3.272153, norm: 0.3646, time(ms): 791.77, token/sec:662174.50, hellaswag_acc: 0.2878
Step:  8577, loss: 3.248075, norm: 0.3048, time(ms): 799.90, token/sec:655445.21, hellaswag_acc: 0.2878
Step:  8578, loss: 3.146982, norm: 0.3064, time(ms): 783.35, token/sec:669291.63, hellaswag_acc: 0.2878
Step:  8579, loss: 3.219650, norm: 0.2613, time(ms): 789.11, token/sec:664402.64, hellaswag_acc: 0.2878
Step:  8580, loss: 3.202167, norm: 0.2741, time(ms): 799.20, token/sec:656016.16, hellaswag_acc: 0.2878
Step:  8581, loss: 3.200759, norm: 0.2867, time(ms): 790.93, token/sec:662871.53, hellaswag_acc: 0.2878
Step:  8582, loss: 3.220930, norm: 0.2893, time(ms): 788.20, token/sec:665172.57, hellaswag_acc: 0.2878
Step:  8583, loss: 3.173962, norm: 0.2698, time(ms): 797.03, token/sec:657798.77, hellaswag_acc: 0.2878
Step:  8584, loss: 3.181289, norm: 0.2764, time(ms): 790.08, token/sec:663591.84, hellaswag_acc: 0.2878
Step:  8585, loss: 3.212870, norm: 0.2925, time(ms): 789.54, token/sec:664038.90, hellaswag_acc: 0.2878
Step:  8586, loss: 3.225871, norm: 0.2869, time(ms): 787.05, token/sec:666142.98, hellaswag_acc: 0.2878
Step:  8587, loss: 3.225718, norm: 0.2815, time(ms): 793.92, token/sec:660382.42, hellaswag_acc: 0.2878
Step:  8588, loss: 3.175027, norm: 0.3059, time(ms): 790.03, token/sec:663632.10, hellaswag_acc: 0.2878
Step:  8589, loss: 3.173614, norm: 0.2815, time(ms): 789.70, token/sec:663904.78, hellaswag_acc: 0.2878
Step:  8590, loss: 3.204825, norm: 0.2882, time(ms): 795.54, token/sec:659032.85, hellaswag_acc: 0.2878
Step:  8591, loss: 3.178651, norm: 0.2889, time(ms): 790.75, token/sec:663029.22, hellaswag_acc: 0.2878
Step:  8592, loss: 3.148392, norm: 0.2659, time(ms): 790.04, token/sec:663622.68, hellaswag_acc: 0.2878
Step:  8593, loss: 3.135338, norm: 0.2448, time(ms): 789.22, token/sec:664310.11, hellaswag_acc: 0.2878
Step:  8594, loss: 3.240426, norm: 0.2668, time(ms): 791.90, token/sec:662061.67, hellaswag_acc: 0.2878
Step:  8595, loss: 3.138268, norm: 0.2564, time(ms): 792.85, token/sec:661271.88, hellaswag_acc: 0.2878
Step:  8596, loss: 3.213992, norm: 0.2513, time(ms): 792.26, token/sec:661760.42, hellaswag_acc: 0.2878
Step:  8597, loss: 3.205265, norm: 0.2551, time(ms): 791.35, token/sec:662523.83, hellaswag_acc: 0.2878
Step:  8598, loss: 3.176979, norm: 0.2415, time(ms): 785.96, token/sec:667069.89, hellaswag_acc: 0.2878
Step:  8599, loss: 3.121006, norm: 0.2854, time(ms): 793.74, token/sec:660528.61, hellaswag_acc: 0.2878
Step:  8600, loss: 3.228509, norm: 0.2811, time(ms): 794.28, token/sec:660080.71, hellaswag_acc: 0.2878
Step:  8601, loss: 3.298008, norm: 0.3290, time(ms): 786.69, token/sec:666450.05, hellaswag_acc: 0.2878
Step:  8602, loss: 3.209449, norm: 0.3182, time(ms): 787.01, token/sec:666175.68, hellaswag_acc: 0.2878
Step:  8603, loss: 3.192656, norm: 0.3344, time(ms): 792.52, token/sec:661542.03, hellaswag_acc: 0.2878
Step:  8604, loss: 3.264479, norm: 0.3755, time(ms): 792.73, token/sec:661369.53, hellaswag_acc: 0.2878
Step:  8605, loss: 3.274042, norm: 0.3616, time(ms): 790.85, token/sec:662941.07, hellaswag_acc: 0.2878
Step:  8606, loss: 3.245070, norm: 0.3399, time(ms): 798.44, token/sec:656639.88, hellaswag_acc: 0.2878
Step:  8607, loss: 3.234759, norm: 0.3293, time(ms): 791.65, token/sec:662272.82, hellaswag_acc: 0.2878
Step:  8608, loss: 3.252340, norm: 0.2801, time(ms): 790.50, token/sec:663238.19, hellaswag_acc: 0.2878
Step:  8609, loss: 3.208885, norm: 0.2921, time(ms): 792.01, token/sec:661968.39, hellaswag_acc: 0.2878
Step:  8610, loss: 3.227167, norm: 0.3011, time(ms): 791.05, token/sec:662774.83, hellaswag_acc: 0.2878
Step:  8611, loss: 3.202043, norm: 0.2869, time(ms): 793.16, token/sec:661007.91, hellaswag_acc: 0.2878
Step:  8612, loss: 3.172072, norm: 0.2889, time(ms): 790.63, token/sec:663130.39, hellaswag_acc: 0.2878
Step:  8613, loss: 3.229284, norm: 0.2640, time(ms): 797.89, token/sec:657089.20, hellaswag_acc: 0.2878
Step:  8614, loss: 3.194361, norm: 0.2680, time(ms): 793.18, token/sec:660997.18, hellaswag_acc: 0.2878
Step:  8615, loss: 3.191574, norm: 0.2642, time(ms): 790.28, token/sec:663422.87, hellaswag_acc: 0.2878
Step:  8616, loss: 3.201325, norm: 0.2529, time(ms): 790.06, token/sec:663603.26, hellaswag_acc: 0.2878
Step:  8617, loss: 3.165077, norm: 0.2543, time(ms): 792.57, token/sec:661501.23, hellaswag_acc: 0.2878
Step:  8618, loss: 3.244850, norm: 0.2549, time(ms): 789.47, token/sec:664101.67, hellaswag_acc: 0.2878
Step:  8619, loss: 3.176749, norm: 0.2656, time(ms): 798.33, token/sec:656732.24, hellaswag_acc: 0.2878
Step:  8620, loss: 3.198402, norm: 0.2534, time(ms): 801.02, token/sec:654522.24, hellaswag_acc: 0.2878
Step:  8621, loss: 3.231080, norm: 0.2547, time(ms): 797.31, token/sec:657569.42, hellaswag_acc: 0.2878
Step:  8622, loss: 3.182409, norm: 0.2475, time(ms): 794.90, token/sec:659563.19, hellaswag_acc: 0.2878
Step:  8623, loss: 3.172391, norm: 0.2372, time(ms): 790.44, token/sec:663287.80, hellaswag_acc: 0.2878
Step:  8624, loss: 3.194195, norm: 0.2652, time(ms): 794.78, token/sec:659662.91, hellaswag_acc: 0.2878
Step:  8625, loss: 3.141235, norm: 0.2675, time(ms): 797.25, token/sec:657617.20, hellaswag_acc: 0.2878
Step:  8626, loss: 3.132497, norm: 0.2556, time(ms): 789.30, token/sec:664242.29, hellaswag_acc: 0.2878
Step:  8627, loss: 3.208433, norm: 0.2889, time(ms): 789.77, token/sec:663845.46, hellaswag_acc: 0.2878
Step:  8628, loss: 3.176870, norm: 0.2569, time(ms): 791.97, token/sec:662005.46, hellaswag_acc: 0.2878
Step:  8629, loss: 3.283055, norm: 0.2857, time(ms): 797.77, token/sec:657190.33, hellaswag_acc: 0.2878
Step:  8630, loss: 3.074611, norm: 0.2503, time(ms): 795.09, token/sec:659410.31, hellaswag_acc: 0.2878
Step:  8631, loss: 3.181893, norm: 0.2969, time(ms): 803.54, token/sec:652473.78, hellaswag_acc: 0.2878
Step:  8632, loss: 3.146914, norm: 0.2711, time(ms): 800.42, token/sec:655015.10, hellaswag_acc: 0.2878
Step:  8633, loss: 3.169965, norm: 0.2993, time(ms): 800.55, token/sec:654912.69, hellaswag_acc: 0.2878
Step:  8634, loss: 3.177756, norm: 0.2788, time(ms): 793.38, token/sec:660827.94, hellaswag_acc: 0.2878
Step:  8635, loss: 3.182349, norm: 0.2708, time(ms): 805.24, token/sec:651095.39, hellaswag_acc: 0.2878
Step:  8636, loss: 3.206878, norm: 0.2910, time(ms): 800.75, token/sec:654749.28, hellaswag_acc: 0.2878
Step:  8637, loss: 3.200885, norm: 0.2563, time(ms): 798.98, token/sec:656200.37, hellaswag_acc: 0.2878
Step:  8638, loss: 3.271114, norm: 0.3165, time(ms): 797.55, token/sec:657375.79, hellaswag_acc: 0.2878
Step:  8639, loss: 3.252472, norm: 0.2731, time(ms): 801.74, token/sec:653937.74, hellaswag_acc: 0.2878
Step:  8640, loss: 3.259017, norm: 0.2678, time(ms): 800.38, token/sec:655051.98, hellaswag_acc: 0.2878
Step:  8641, loss: 3.188437, norm: 0.2726, time(ms): 799.11, token/sec:656089.17, hellaswag_acc: 0.2878
Step:  8642, loss: 3.237223, norm: 0.2661, time(ms): 790.87, token/sec:662923.68, hellaswag_acc: 0.2878
Step:  8643, loss: 3.202489, norm: 0.3011, time(ms): 790.19, token/sec:663495.74, hellaswag_acc: 0.2878
Step:  8644, loss: 3.265530, norm: 0.2893, time(ms): 791.24, token/sec:662612.67, hellaswag_acc: 0.2878
Step:  8645, loss: 3.155415, norm: 0.2822, time(ms): 790.98, token/sec:662833.96, hellaswag_acc: 0.2878
Step:  8646, loss: 3.202681, norm: 0.2940, time(ms): 794.12, token/sec:660209.33, hellaswag_acc: 0.2878
Step:  8647, loss: 3.206295, norm: 0.2914, time(ms): 789.08, token/sec:664428.94, hellaswag_acc: 0.2878
Step:  8648, loss: 3.176889, norm: 0.2883, time(ms): 793.81, token/sec:660467.31, hellaswag_acc: 0.2878
Step:  8649, loss: 3.190044, norm: 0.2758, time(ms): 799.40, token/sec:655850.64, hellaswag_acc: 0.2878
Step:  8650, loss: 3.155163, norm: 0.2663, time(ms): 791.98, token/sec:662000.08, hellaswag_acc: 0.2878
Step:  8651, loss: 3.249027, norm: 0.2638, time(ms): 790.45, token/sec:663277.80, hellaswag_acc: 0.2878
Step:  8652, loss: 3.226202, norm: 0.3148, time(ms): 788.50, token/sec:664919.75, hellaswag_acc: 0.2878
Step:  8653, loss: 3.217242, norm: 0.2832, time(ms): 788.79, token/sec:664672.75, hellaswag_acc: 0.2878
Step:  8654, loss: 3.201288, norm: 0.2627, time(ms): 799.31, token/sec:655927.52, hellaswag_acc: 0.2878
Step:  8655, loss: 3.197254, norm: 0.2509, time(ms): 798.37, token/sec:656695.57, hellaswag_acc: 0.2878
Step:  8656, loss: 3.151899, norm: 0.2579, time(ms): 796.14, token/sec:658541.03, hellaswag_acc: 0.2878
Step:  8657, loss: 3.182186, norm: 0.2874, time(ms): 805.25, token/sec:651087.10, hellaswag_acc: 0.2878
Step:  8658, loss: 3.176400, norm: 0.2531, time(ms): 799.30, token/sec:655932.02, hellaswag_acc: 0.2878
Step:  8659, loss: 3.197650, norm: 0.2937, time(ms): 793.14, token/sec:661031.95, hellaswag_acc: 0.2878
Step:  8660, loss: 3.151578, norm: 0.2561, time(ms): 803.90, token/sec:652182.94, hellaswag_acc: 0.2878
Step:  8661, loss: 3.171704, norm: 0.2686, time(ms): 804.95, token/sec:651330.09, hellaswag_acc: 0.2878
Step:  8662, loss: 3.158421, norm: 0.2821, time(ms): 797.73, token/sec:657227.45, hellaswag_acc: 0.2878
Step:  8663, loss: 3.137646, norm: 0.2677, time(ms): 792.26, token/sec:661761.02, hellaswag_acc: 0.2878
Step:  8664, loss: 3.125617, norm: 0.2575, time(ms): 807.71, token/sec:649107.19, hellaswag_acc: 0.2878
Step:  8665, loss: 3.142800, norm: 0.2804, time(ms): 801.58, token/sec:654068.84, hellaswag_acc: 0.2878
Step:  8666, loss: 3.171768, norm: 0.2676, time(ms): 792.71, token/sec:661387.63, hellaswag_acc: 0.2878
Step:  8667, loss: 3.146903, norm: 0.2567, time(ms): 800.99, token/sec:654551.27, hellaswag_acc: 0.2878
Step:  8668, loss: 3.171399, norm: 0.2654, time(ms): 804.22, token/sec:651923.47, hellaswag_acc: 0.2878
Step:  8669, loss: 3.175744, norm: 0.2884, time(ms): 799.98, token/sec:655379.38, hellaswag_acc: 0.2878
Step:  8670, loss: 3.284739, norm: 0.3004, time(ms): 790.75, token/sec:663025.02, hellaswag_acc: 0.2878
Step:  8671, loss: 3.206606, norm: 0.2835, time(ms): 792.18, token/sec:661832.92, hellaswag_acc: 0.2878
Step:  8672, loss: 3.229712, norm: 0.2796, time(ms): 788.30, token/sec:665083.85, hellaswag_acc: 0.2878
Step:  8673, loss: 3.156477, norm: 0.2579, time(ms): 791.00, token/sec:662815.98, hellaswag_acc: 0.2878
Step:  8674, loss: 3.246916, norm: 0.2676, time(ms): 792.09, token/sec:661905.03, hellaswag_acc: 0.2878
Step:  8675, loss: 3.237406, norm: 0.2756, time(ms): 797.32, token/sec:657559.58, hellaswag_acc: 0.2878
Step:  8676, loss: 3.174611, norm: 0.2590, time(ms): 803.26, token/sec:652703.47, hellaswag_acc: 0.2878
Step:  8677, loss: 3.150938, norm: 0.2492, time(ms): 797.54, token/sec:657380.31, hellaswag_acc: 0.2878
Step:  8678, loss: 3.366116, norm: 0.4000, time(ms): 794.88, token/sec:659581.39, hellaswag_acc: 0.2878
Step:  8679, loss: 3.250026, norm: 0.4010, time(ms): 790.98, token/sec:662835.56, hellaswag_acc: 0.2878
Step:  8680, loss: 3.226849, norm: 0.3084, time(ms): 799.49, token/sec:655776.91, hellaswag_acc: 0.2878
Step:  8681, loss: 3.210234, norm: 0.3264, time(ms): 791.33, token/sec:662541.00, hellaswag_acc: 0.2878
Step:  8682, loss: 3.183488, norm: 0.3166, time(ms): 788.65, token/sec:664793.11, hellaswag_acc: 0.2878
Step:  8683, loss: 3.152332, norm: 0.3011, time(ms): 790.80, token/sec:662981.44, hellaswag_acc: 0.2878
Step:  8684, loss: 3.162983, norm: 0.2990, time(ms): 791.43, token/sec:662459.36, hellaswag_acc: 0.2878
Step:  8685, loss: 3.228634, norm: 0.3054, time(ms): 788.10, token/sec:665252.45, hellaswag_acc: 0.2878
Step:  8686, loss: 3.208831, norm: 0.2765, time(ms): 806.58, token/sec:650009.93, hellaswag_acc: 0.2878
Step:  8687, loss: 3.186695, norm: 0.2715, time(ms): 802.28, token/sec:653496.21, hellaswag_acc: 0.2878
Step:  8688, loss: 3.238663, norm: 0.2656, time(ms): 794.74, token/sec:659698.14, hellaswag_acc: 0.2878
Step:  8689, loss: 3.217392, norm: 0.2617, time(ms): 800.97, token/sec:654569.78, hellaswag_acc: 0.2878
Step:  8690, loss: 3.173195, norm: 0.2681, time(ms): 805.01, token/sec:651282.44, hellaswag_acc: 0.2878
Step:  8691, loss: 3.172563, norm: 0.2590, time(ms): 797.80, token/sec:657164.01, hellaswag_acc: 0.2878
Step:  8692, loss: 3.151922, norm: 0.2738, time(ms): 799.36, token/sec:655883.50, hellaswag_acc: 0.2878
Step:  8693, loss: 3.172365, norm: 0.2617, time(ms): 800.18, token/sec:655211.83, hellaswag_acc: 0.2878
Step:  8694, loss: 3.128201, norm: 0.2812, time(ms): 800.59, token/sec:654877.19, hellaswag_acc: 0.2878
Step:  8695, loss: 3.184258, norm: 0.3076, time(ms): 800.70, token/sec:654788.86, hellaswag_acc: 0.2878
Step:  8696, loss: 3.183013, norm: 0.2718, time(ms): 797.89, token/sec:657096.46, hellaswag_acc: 0.2878
Step:  8697, loss: 3.179771, norm: 0.2818, time(ms): 796.53, token/sec:658214.61, hellaswag_acc: 0.2878
Step:  8698, loss: 3.175478, norm: 0.2917, time(ms): 804.41, token/sec:651768.69, hellaswag_acc: 0.2878
Step:  8699, loss: 3.145765, norm: 0.2771, time(ms): 801.60, token/sec:654052.50, hellaswag_acc: 0.2878
Step:  8700, loss: 3.191792, norm: 0.2945, time(ms): 794.23, token/sec:660121.14, hellaswag_acc: 0.2878
Step:  8701, loss: 3.214450, norm: 0.2594, time(ms): 800.35, token/sec:655072.08, hellaswag_acc: 0.2878
Step:  8702, loss: 3.121899, norm: 0.3105, time(ms): 802.57, token/sec:653258.01, hellaswag_acc: 0.2878
Step:  8703, loss: 3.137949, norm: 0.2711, time(ms): 802.01, token/sec:653720.79, hellaswag_acc: 0.2878
Step:  8704, loss: 3.196806, norm: 0.2698, time(ms): 791.48, token/sec:662411.67, hellaswag_acc: 0.2878
Step:  8705, loss: 3.253958, norm: 0.2745, time(ms): 803.39, token/sec:652592.67, hellaswag_acc: 0.2878
Step:  8706, loss: 3.150012, norm: 0.2946, time(ms): 803.88, token/sec:652198.22, hellaswag_acc: 0.2878
Step:  8707, loss: 3.222378, norm: 0.2781, time(ms): 788.46, token/sec:664949.10, hellaswag_acc: 0.2878
Step:  8708, loss: 3.242680, norm: 0.2576, time(ms): 789.17, token/sec:664354.87, hellaswag_acc: 0.2878
Step:  8709, loss: 3.123305, norm: 0.3915, time(ms): 792.03, token/sec:661954.44, hellaswag_acc: 0.2878
Step:  8710, loss: 3.260350, norm: 0.3558, time(ms): 790.03, token/sec:663629.49, hellaswag_acc: 0.2878
Step:  8711, loss: 3.335495, norm: 0.3622, time(ms): 791.30, token/sec:662565.35, hellaswag_acc: 0.2878
Step:  8712, loss: 3.193922, norm: 0.3146, time(ms): 793.56, token/sec:660680.62, hellaswag_acc: 0.2878
Step:  8713, loss: 3.185205, norm: 0.2927, time(ms): 794.18, token/sec:660160.57, hellaswag_acc: 0.2878
Step:  8714, loss: 3.177721, norm: 0.3007, time(ms): 790.55, token/sec:663189.98, hellaswag_acc: 0.2878
Step:  8715, loss: 3.234211, norm: 0.2757, time(ms): 789.47, token/sec:664100.67, hellaswag_acc: 0.2878
Step:  8716, loss: 3.269905, norm: 0.2683, time(ms): 789.46, token/sec:664110.29, hellaswag_acc: 0.2878
Step:  8717, loss: 3.202791, norm: 0.2655, time(ms): 791.50, token/sec:662394.11, hellaswag_acc: 0.2878
Step:  8718, loss: 3.198174, norm: 0.2916, time(ms): 793.51, token/sec:660717.74, hellaswag_acc: 0.2878
Step:  8719, loss: 3.202102, norm: 0.2605, time(ms): 796.58, token/sec:658174.02, hellaswag_acc: 0.2878
Step:  8720, loss: 3.238240, norm: 0.2833, time(ms): 807.76, token/sec:649062.35, hellaswag_acc: 0.2878
Step:  8721, loss: 3.200866, norm: 0.2729, time(ms): 799.73, token/sec:655581.01, hellaswag_acc: 0.2878
Step:  8722, loss: 3.174545, norm: 0.2646, time(ms): 799.10, token/sec:656095.83, hellaswag_acc: 0.2878
Step:  8723, loss: 3.197776, norm: 0.2895, time(ms): 798.31, token/sec:656744.21, hellaswag_acc: 0.2878
Step:  8724, loss: 3.182272, norm: 0.2734, time(ms): 799.40, token/sec:655852.21, hellaswag_acc: 0.2878
Step:  8725, loss: 3.226685, norm: 0.2774, time(ms): 801.95, token/sec:653769.77, hellaswag_acc: 0.2878
Step:  8726, loss: 3.200653, norm: 0.3250, time(ms): 801.68, token/sec:653990.64, hellaswag_acc: 0.2878
Step:  8727, loss: 3.094723, norm: 0.2478, time(ms): 793.48, token/sec:660744.15, hellaswag_acc: 0.2878
Step:  8728, loss: 3.164077, norm: 0.2751, time(ms): 800.45, token/sec:654988.57, hellaswag_acc: 0.2878
Step:  8729, loss: 3.196221, norm: 0.2404, time(ms): 803.94, token/sec:652148.32, hellaswag_acc: 0.2878
Step:  8730, loss: 3.174305, norm: 0.2785, time(ms): 800.66, token/sec:654821.42, hellaswag_acc: 0.2878
Step:  8731, loss: 3.170063, norm: 0.2620, time(ms): 790.91, token/sec:662888.11, hellaswag_acc: 0.2878
Step:  8732, loss: 3.173174, norm: 0.2780, time(ms): 805.70, token/sec:650722.77, hellaswag_acc: 0.2878
Step:  8733, loss: 3.164213, norm: 0.2497, time(ms): 804.69, token/sec:651540.25, hellaswag_acc: 0.2878
Step:  8734, loss: 3.176071, norm: 0.2548, time(ms): 788.48, token/sec:664932.41, hellaswag_acc: 0.2878
Step:  8735, loss: 3.176593, norm: 0.2850, time(ms): 798.44, token/sec:656643.80, hellaswag_acc: 0.2878
Step:  8736, loss: 3.202900, norm: 0.2472, time(ms): 790.66, token/sec:663101.39, hellaswag_acc: 0.2878
Step:  8737, loss: 3.144224, norm: 0.2781, time(ms): 786.63, token/sec:666496.91, hellaswag_acc: 0.2878
Step:  8738, loss: 3.186658, norm: 0.2934, time(ms): 790.32, token/sec:663390.25, hellaswag_acc: 0.2878
Step:  8739, loss: 3.249293, norm: 0.2947, time(ms): 797.69, token/sec:657260.65, hellaswag_acc: 0.2878
Step:  8740, loss: 3.206610, norm: 0.3031, time(ms): 804.70, token/sec:651530.79, hellaswag_acc: 0.2878
Step:  8741, loss: 3.229708, norm: 0.3085, time(ms): 798.85, token/sec:656301.62, hellaswag_acc: 0.2878
Step:  8742, loss: 3.173532, norm: 0.2809, time(ms): 795.04, token/sec:659444.52, hellaswag_acc: 0.2878
Step:  8743, loss: 3.245812, norm: 0.3055, time(ms): 799.90, token/sec:655441.69, hellaswag_acc: 0.2878
Step:  8744, loss: 3.204230, norm: 0.2731, time(ms): 798.78, token/sec:656361.37, hellaswag_acc: 0.2878
Step:  8745, loss: 3.217257, norm: 0.3102, time(ms): 797.75, token/sec:657205.65, hellaswag_acc: 0.2878
Step:  8746, loss: 3.279219, norm: 0.2896, time(ms): 792.91, token/sec:661222.37, hellaswag_acc: 0.2878
Step:  8747, loss: 3.230142, norm: 0.2902, time(ms): 793.84, token/sec:660441.72, hellaswag_acc: 0.2878
Step:  8748, loss: 3.251011, norm: 0.3139, time(ms): 795.93, token/sec:658711.66, hellaswag_acc: 0.2878
Step:  8749, loss: 3.202821, norm: 0.3091, time(ms): 801.91, token/sec:653802.81, hellaswag_acc: 0.2878
rank 0 sample 0: Hello, I'm a language model, and I'll be using one, or multiple, for simplicity. (Or better yet, create it in Java.) But
rank 0 sample 1: Hello, I'm a language model, so, just like a language, no matter where an artificial intelligence comes from is not going to work and I'm not
rank 0 sample 2: Hello, I'm a language model, so I wanted to tell students that you are speaking a language like I am. But you don't know what language model
rank 0 sample 3: Hello, I'm a language model, I guess I've got a language learning thing ahead of me. I can see a great video where, "Hey Jim
rank 1 sample 0: Hello, I'm a language model, since the source code is the same length of code that comes between the source code and the interpreter and the interpreter.

rank 1 sample 1: Hello, I'm a language model, not an application/program. And this is the main argument for building a system. Any I wanted was to have a
rank 1 sample 2: Hello, I'm a language model, I got my hands on a language model, I'm an analyst and you're a language model, and you need a
rank 1 sample 3: Hello, I'm a language model, not a language expert, my career goals make me a person and so should be the world's greatest language model.

Step:  8750, loss: 3.241534, norm: 0.3007, time(ms): 3814.62, token/sec:137441.87, val_loss: 3.2222, hellaswag_acc: 0.2878
Step:  8751, loss: 3.154602, norm: 0.3286, time(ms): 793.79, token/sec:660488.14, hellaswag_acc: 0.2878
Step:  8752, loss: 3.213773, norm: 0.2828, time(ms): 788.14, token/sec:665221.06, hellaswag_acc: 0.2878
Step:  8753, loss: 3.163530, norm: 0.3022, time(ms): 801.51, token/sec:654121.56, hellaswag_acc: 0.2878
Step:  8754, loss: 3.213928, norm: 0.2747, time(ms): 802.32, token/sec:653461.07, hellaswag_acc: 0.2878
Step:  8755, loss: 3.213406, norm: 0.2779, time(ms): 792.14, token/sec:661860.01, hellaswag_acc: 0.2878
Step:  8756, loss: 3.187150, norm: 0.2689, time(ms): 789.43, token/sec:664137.77, hellaswag_acc: 0.2878
Step:  8757, loss: 3.225014, norm: 0.2722, time(ms): 789.86, token/sec:663770.91, hellaswag_acc: 0.2878
Step:  8758, loss: 3.216388, norm: 0.2628, time(ms): 793.04, token/sec:661111.84, hellaswag_acc: 0.2878
Step:  8759, loss: 3.212818, norm: 0.2683, time(ms): 797.16, token/sec:657694.50, hellaswag_acc: 0.2878
Step:  8760, loss: 3.204617, norm: 0.2667, time(ms): 796.02, token/sec:658633.14, hellaswag_acc: 0.2878
Step:  8761, loss: 3.186959, norm: 0.2834, time(ms): 797.02, token/sec:657811.16, hellaswag_acc: 0.2878
Step:  8762, loss: 3.132473, norm: 0.2627, time(ms): 1318.14, token/sec:397746.89, hellaswag_acc: 0.2878
Step:  8763, loss: 3.228896, norm: 0.2925, time(ms): 766.27, token/sec:684205.22, hellaswag_acc: 0.2878
Step:  8764, loss: 3.208357, norm: 0.2531, time(ms): 791.01, token/sec:662804.19, hellaswag_acc: 0.2878
Step:  8765, loss: 3.151388, norm: 0.2651, time(ms): 805.96, token/sec:650510.26, hellaswag_acc: 0.2878
Step:  8766, loss: 3.173828, norm: 0.2413, time(ms): 789.81, token/sec:663814.39, hellaswag_acc: 0.2878
Step:  8767, loss: 3.156954, norm: 0.2509, time(ms): 783.38, token/sec:669264.75, hellaswag_acc: 0.2878
Step:  8768, loss: 3.180715, norm: 0.2888, time(ms): 789.09, token/sec:664424.52, hellaswag_acc: 0.2878
Step:  8769, loss: 3.204492, norm: 0.2708, time(ms): 799.07, token/sec:656122.25, hellaswag_acc: 0.2878
Step:  8770, loss: 3.136072, norm: 0.3075, time(ms): 801.30, token/sec:654296.73, hellaswag_acc: 0.2878
Step:  8771, loss: 3.171764, norm: 0.2851, time(ms): 793.48, token/sec:660743.75, hellaswag_acc: 0.2878
Step:  8772, loss: 3.190693, norm: 0.2641, time(ms): 793.67, token/sec:660587.54, hellaswag_acc: 0.2878
Step:  8773, loss: 3.201822, norm: 0.2860, time(ms): 787.84, token/sec:665474.91, hellaswag_acc: 0.2878
Step:  8774, loss: 3.188480, norm: 0.2514, time(ms): 795.60, token/sec:658984.47, hellaswag_acc: 0.2878
Step:  8775, loss: 3.158597, norm: 0.2950, time(ms): 789.98, token/sec:663674.96, hellaswag_acc: 0.2878
Step:  8776, loss: 3.222886, norm: 0.2673, time(ms): 793.51, token/sec:660715.96, hellaswag_acc: 0.2878
Step:  8777, loss: 3.231899, norm: 0.2791, time(ms): 804.02, token/sec:652079.67, hellaswag_acc: 0.2878
Step:  8778, loss: 3.190218, norm: 0.2667, time(ms): 799.84, token/sec:655494.44, hellaswag_acc: 0.2878
Step:  8779, loss: 3.212697, norm: 0.2771, time(ms): 794.59, token/sec:659822.84, hellaswag_acc: 0.2878
Step:  8780, loss: 3.373410, norm: 0.2983, time(ms): 799.68, token/sec:655620.30, hellaswag_acc: 0.2878
Step:  8781, loss: 3.304697, norm: 0.3202, time(ms): 803.79, token/sec:652271.34, hellaswag_acc: 0.2878
Step:  8782, loss: 3.301424, norm: 0.3145, time(ms): 798.50, token/sec:656590.47, hellaswag_acc: 0.2878
Step:  8783, loss: 3.291521, norm: 0.3391, time(ms): 799.34, token/sec:655904.83, hellaswag_acc: 0.2878
Step:  8784, loss: 3.262237, norm: 0.3136, time(ms): 800.24, token/sec:655167.13, hellaswag_acc: 0.2878
Step:  8785, loss: 3.246179, norm: 0.2937, time(ms): 804.47, token/sec:651716.15, hellaswag_acc: 0.2878
Step:  8786, loss: 3.296641, norm: 0.3438, time(ms): 793.59, token/sec:660657.40, hellaswag_acc: 0.2878
Step:  8787, loss: 3.375668, norm: 0.2968, time(ms): 805.28, token/sec:651059.73, hellaswag_acc: 0.2878
Step:  8788, loss: 3.283858, norm: 0.3032, time(ms): 800.59, token/sec:654878.36, hellaswag_acc: 0.2878
Step:  8789, loss: 3.293891, norm: 0.2931, time(ms): 793.80, token/sec:660478.81, hellaswag_acc: 0.2878
Step:  8790, loss: 3.270154, norm: 0.2823, time(ms): 804.55, token/sec:651653.39, hellaswag_acc: 0.2878
Step:  8791, loss: 3.208579, norm: 0.2712, time(ms): 796.07, token/sec:658596.25, hellaswag_acc: 0.2878
Step:  8792, loss: 3.197722, norm: 0.2646, time(ms): 805.08, token/sec:651225.35, hellaswag_acc: 0.2878
Step:  8793, loss: 3.192818, norm: 0.2645, time(ms): 799.76, token/sec:655557.17, hellaswag_acc: 0.2878
Step:  8794, loss: 3.184995, norm: 0.2679, time(ms): 792.32, token/sec:661712.23, hellaswag_acc: 0.2878
Step:  8795, loss: 3.171811, norm: 0.2496, time(ms): 802.72, token/sec:653143.15, hellaswag_acc: 0.2878
Step:  8796, loss: 3.144570, norm: 0.2901, time(ms): 805.50, token/sec:650885.53, hellaswag_acc: 0.2878
Step:  8797, loss: 3.156868, norm: 0.2515, time(ms): 795.49, token/sec:659077.89, hellaswag_acc: 0.2878
Step:  8798, loss: 3.178684, norm: 0.2920, time(ms): 792.18, token/sec:661832.72, hellaswag_acc: 0.2878
Step:  8799, loss: 3.116355, norm: 0.2905, time(ms): 791.63, token/sec:662292.97, hellaswag_acc: 0.2878
Step:  8800, loss: 3.184387, norm: 0.2424, time(ms): 787.86, token/sec:665460.01, hellaswag_acc: 0.2878
Step:  8801, loss: 3.196707, norm: 0.2642, time(ms): 790.31, token/sec:663395.86, hellaswag_acc: 0.2878
Step:  8802, loss: 3.183182, norm: 0.2609, time(ms): 796.41, token/sec:658318.06, hellaswag_acc: 0.2878
Step:  8803, loss: 3.229088, norm: 0.2613, time(ms): 802.76, token/sec:653108.81, hellaswag_acc: 0.2878
Step:  8804, loss: 3.148484, norm: 0.2811, time(ms): 798.78, token/sec:656359.22, hellaswag_acc: 0.2878
Step:  8805, loss: 3.160660, norm: 0.2565, time(ms): 793.23, token/sec:660956.45, hellaswag_acc: 0.2878
Step:  8806, loss: 3.195468, norm: 0.2684, time(ms): 792.14, token/sec:661860.01, hellaswag_acc: 0.2878
Step:  8807, loss: 3.212135, norm: 0.2659, time(ms): 794.76, token/sec:659678.15, hellaswag_acc: 0.2878
Step:  8808, loss: 3.208313, norm: 0.2564, time(ms): 789.71, token/sec:663900.17, hellaswag_acc: 0.2878
Step:  8809, loss: 3.244926, norm: 0.2751, time(ms): 787.21, token/sec:666005.19, hellaswag_acc: 0.2878
Step:  8810, loss: 3.253321, norm: 0.2654, time(ms): 794.39, token/sec:659989.98, hellaswag_acc: 0.2878
Step:  8811, loss: 3.290815, norm: 0.2850, time(ms): 789.91, token/sec:663733.45, hellaswag_acc: 0.2878
Step:  8812, loss: 3.266025, norm: 0.2744, time(ms): 791.46, token/sec:662431.42, hellaswag_acc: 0.2878
Step:  8813, loss: 3.271142, norm: 0.3021, time(ms): 791.14, token/sec:662701.53, hellaswag_acc: 0.2878
Step:  8814, loss: 3.275433, norm: 0.2895, time(ms): 793.78, token/sec:660492.70, hellaswag_acc: 0.2878
Step:  8815, loss: 3.326227, norm: 0.3005, time(ms): 791.64, token/sec:662282.59, hellaswag_acc: 0.2878
Step:  8816, loss: 3.274316, norm: 0.3127, time(ms): 790.77, token/sec:663008.03, hellaswag_acc: 0.2878
Step:  8817, loss: 3.300029, norm: 0.2965, time(ms): 795.25, token/sec:659275.09, hellaswag_acc: 0.2878
Step:  8818, loss: 3.240597, norm: 0.2791, time(ms): 798.02, token/sec:656986.92, hellaswag_acc: 0.2878
Step:  8819, loss: 3.282108, norm: 0.2932, time(ms): 804.72, token/sec:651516.50, hellaswag_acc: 0.2878
Step:  8820, loss: 3.289478, norm: 0.2707, time(ms): 792.84, token/sec:661277.64, hellaswag_acc: 0.2878
Step:  8821, loss: 3.279971, norm: 0.3015, time(ms): 799.76, token/sec:655558.73, hellaswag_acc: 0.2878
Step:  8822, loss: 3.298843, norm: 0.2686, time(ms): 794.05, token/sec:660270.98, hellaswag_acc: 0.2878
Step:  8823, loss: 3.261972, norm: 0.2789, time(ms): 792.44, token/sec:661613.08, hellaswag_acc: 0.2878
Step:  8824, loss: 3.281637, norm: 0.3232, time(ms): 799.51, token/sec:655763.02, hellaswag_acc: 0.2878
Step:  8825, loss: 3.232365, norm: 0.2689, time(ms): 797.56, token/sec:657364.20, hellaswag_acc: 0.2878
Step:  8826, loss: 3.258924, norm: 0.2839, time(ms): 796.56, token/sec:658192.94, hellaswag_acc: 0.2878
Step:  8827, loss: 3.200317, norm: 0.2766, time(ms): 791.90, token/sec:662065.45, hellaswag_acc: 0.2878
Step:  8828, loss: 3.157320, norm: 0.2619, time(ms): 785.65, token/sec:667328.20, hellaswag_acc: 0.2878
Step:  8829, loss: 3.225885, norm: 0.2885, time(ms): 791.37, token/sec:662509.26, hellaswag_acc: 0.2878
Step:  8830, loss: 3.197804, norm: 0.2815, time(ms): 795.45, token/sec:659110.28, hellaswag_acc: 0.2878
Step:  8831, loss: 3.207788, norm: 0.2740, time(ms): 799.69, token/sec:655614.83, hellaswag_acc: 0.2878
Step:  8832, loss: 3.181500, norm: 0.2546, time(ms): 801.64, token/sec:654021.76, hellaswag_acc: 0.2878
Step:  8833, loss: 3.163161, norm: 0.2676, time(ms): 799.84, token/sec:655491.12, hellaswag_acc: 0.2878
Step:  8834, loss: 3.185274, norm: 0.2427, time(ms): 797.56, token/sec:657365.77, hellaswag_acc: 0.2878
Step:  8835, loss: 3.239650, norm: 0.2459, time(ms): 801.99, token/sec:653734.98, hellaswag_acc: 0.2878
Step:  8836, loss: 3.223863, norm: 0.3084, time(ms): 799.52, token/sec:655752.46, hellaswag_acc: 0.2878
Step:  8837, loss: 3.208667, norm: 0.2512, time(ms): 801.43, token/sec:654188.89, hellaswag_acc: 0.2878
Step:  8838, loss: 3.215758, norm: 0.2786, time(ms): 791.71, token/sec:662220.77, hellaswag_acc: 0.2878
Step:  8839, loss: 3.227865, norm: 0.3115, time(ms): 803.23, token/sec:652725.17, hellaswag_acc: 0.2878
Step:  8840, loss: 3.218082, norm: 0.3194, time(ms): 805.62, token/sec:650792.10, hellaswag_acc: 0.2878
Step:  8841, loss: 3.189336, norm: 0.2754, time(ms): 794.21, token/sec:660141.55, hellaswag_acc: 0.2878
Step:  8842, loss: 3.221185, norm: 0.3017, time(ms): 802.47, token/sec:653340.11, hellaswag_acc: 0.2878
Step:  8843, loss: 3.168781, norm: 0.2674, time(ms): 801.26, token/sec:654331.58, hellaswag_acc: 0.2878
Step:  8844, loss: 3.217041, norm: 0.3020, time(ms): 798.27, token/sec:656776.37, hellaswag_acc: 0.2878
Step:  8845, loss: 3.186242, norm: 0.2906, time(ms): 796.71, token/sec:658062.35, hellaswag_acc: 0.2878
Step:  8846, loss: 3.238958, norm: 0.2600, time(ms): 806.20, token/sec:650319.42, hellaswag_acc: 0.2878
Step:  8847, loss: 3.188163, norm: 0.3016, time(ms): 796.24, token/sec:658451.31, hellaswag_acc: 0.2878
Step:  8848, loss: 3.190184, norm: 0.3025, time(ms): 796.32, token/sec:658388.82, hellaswag_acc: 0.2878
Step:  8849, loss: 3.208249, norm: 0.3009, time(ms): 804.88, token/sec:651387.39, hellaswag_acc: 0.2878
Step:  8850, loss: 3.288479, norm: 0.3037, time(ms): 801.20, token/sec:654380.45, hellaswag_acc: 0.2878
Step:  8851, loss: 3.257790, norm: 0.3000, time(ms): 791.30, token/sec:662564.95, hellaswag_acc: 0.2878
Step:  8852, loss: 3.285874, norm: 0.3133, time(ms): 806.77, token/sec:649863.75, hellaswag_acc: 0.2878
Step:  8853, loss: 3.281096, norm: 0.2913, time(ms): 796.43, token/sec:658294.61, hellaswag_acc: 0.2878
Step:  8854, loss: 3.265817, norm: 0.2686, time(ms): 803.40, token/sec:652584.73, hellaswag_acc: 0.2878
Step:  8855, loss: 3.253062, norm: 0.2819, time(ms): 794.14, token/sec:660199.82, hellaswag_acc: 0.2878
Step:  8856, loss: 3.272358, norm: 0.2487, time(ms): 805.46, token/sec:650919.05, hellaswag_acc: 0.2878
Step:  8857, loss: 3.236394, norm: 0.2810, time(ms): 796.55, token/sec:658198.06, hellaswag_acc: 0.2878
Step:  8858, loss: 3.240717, norm: 0.2843, time(ms): 805.26, token/sec:651080.74, hellaswag_acc: 0.2878
Step:  8859, loss: 3.258140, norm: 0.2530, time(ms): 796.83, token/sec:657963.90, hellaswag_acc: 0.2878
Step:  8860, loss: 3.228644, norm: 0.2719, time(ms): 794.83, token/sec:659626.50, hellaswag_acc: 0.2878
Step:  8861, loss: 3.327545, norm: 0.3075, time(ms): 805.35, token/sec:651004.61, hellaswag_acc: 0.2878
Step:  8862, loss: 3.212755, norm: 0.3232, time(ms): 801.85, token/sec:653849.08, hellaswag_acc: 0.2878
Step:  8863, loss: 3.215735, norm: 0.3150, time(ms): 791.07, token/sec:662758.25, hellaswag_acc: 0.2878
Step:  8864, loss: 3.231960, norm: 0.2958, time(ms): 799.57, token/sec:655713.55, hellaswag_acc: 0.2878
Step:  8865, loss: 3.165223, norm: 0.2900, time(ms): 808.07, token/sec:648816.85, hellaswag_acc: 0.2878
Step:  8866, loss: 3.165835, norm: 0.3289, time(ms): 794.45, token/sec:659934.72, hellaswag_acc: 0.2878
Step:  8867, loss: 3.191149, norm: 0.2692, time(ms): 803.46, token/sec:652535.16, hellaswag_acc: 0.2878
Step:  8868, loss: 3.296242, norm: 0.3812, time(ms): 802.03, token/sec:653698.05, hellaswag_acc: 0.2878
Step:  8869, loss: 3.206096, norm: 0.3892, time(ms): 795.70, token/sec:658901.73, hellaswag_acc: 0.2878
Step:  8870, loss: 3.174023, norm: 0.3239, time(ms): 792.90, token/sec:661228.73, hellaswag_acc: 0.2878
Step:  8871, loss: 3.175127, norm: 0.2999, time(ms): 791.78, token/sec:662163.74, hellaswag_acc: 0.2878
Step:  8872, loss: 3.234470, norm: 0.3345, time(ms): 785.83, token/sec:667177.16, hellaswag_acc: 0.2878
Step:  8873, loss: 3.204142, norm: 0.3207, time(ms): 788.95, token/sec:664535.36, hellaswag_acc: 0.2878
Step:  8874, loss: 3.164135, norm: 0.2767, time(ms): 797.37, token/sec:657520.06, hellaswag_acc: 0.2878
Step:  8875, loss: 3.237819, norm: 0.3044, time(ms): 803.61, token/sec:652415.52, hellaswag_acc: 0.2878
Step:  8876, loss: 3.210333, norm: 0.2591, time(ms): 798.56, token/sec:656540.09, hellaswag_acc: 0.2878
Step:  8877, loss: 3.162358, norm: 0.2961, time(ms): 797.00, token/sec:657828.28, hellaswag_acc: 0.2878
Step:  8878, loss: 3.217796, norm: 0.2827, time(ms): 802.62, token/sec:653217.07, hellaswag_acc: 0.2878
Step:  8879, loss: 3.188513, norm: 0.2758, time(ms): 803.23, token/sec:652720.90, hellaswag_acc: 0.2878
Step:  8880, loss: 3.233813, norm: 0.2623, time(ms): 791.13, token/sec:662711.31, hellaswag_acc: 0.2878
Step:  8881, loss: 3.168144, norm: 0.2625, time(ms): 793.18, token/sec:660997.97, hellaswag_acc: 0.2878
Step:  8882, loss: 3.184404, norm: 0.2536, time(ms): 794.19, token/sec:660155.22, hellaswag_acc: 0.2878
Step:  8883, loss: 3.203309, norm: 0.2737, time(ms): 794.86, token/sec:659601.77, hellaswag_acc: 0.2878
Step:  8884, loss: 3.242265, norm: 0.2639, time(ms): 802.28, token/sec:653497.77, hellaswag_acc: 0.2878
Step:  8885, loss: 3.188005, norm: 0.2788, time(ms): 800.60, token/sec:654865.30, hellaswag_acc: 0.2878
Step:  8886, loss: 3.241397, norm: 0.2983, time(ms): 788.45, token/sec:664962.98, hellaswag_acc: 0.2878
Step:  8887, loss: 3.265354, norm: 0.2837, time(ms): 785.65, token/sec:667332.25, hellaswag_acc: 0.2878
Step:  8888, loss: 3.300104, norm: 0.2847, time(ms): 790.90, token/sec:662902.50, hellaswag_acc: 0.2878
Step:  8889, loss: 3.282987, norm: 0.2657, time(ms): 786.42, token/sec:666675.54, hellaswag_acc: 0.2878
Step:  8890, loss: 3.268219, norm: 0.2644, time(ms): 789.66, token/sec:663940.86, hellaswag_acc: 0.2878
Step:  8891, loss: 3.298960, norm: 0.3225, time(ms): 791.38, token/sec:662495.89, hellaswag_acc: 0.2878
Step:  8892, loss: 3.251980, norm: 0.2913, time(ms): 791.48, token/sec:662412.87, hellaswag_acc: 0.2878
Step:  8893, loss: 3.284681, norm: 0.2779, time(ms): 788.79, token/sec:664674.35, hellaswag_acc: 0.2878
Step:  8894, loss: 3.275783, norm: 0.2866, time(ms): 792.58, token/sec:661496.85, hellaswag_acc: 0.2878
Step:  8895, loss: 3.241666, norm: 0.2753, time(ms): 796.11, token/sec:658560.36, hellaswag_acc: 0.2878
Step:  8896, loss: 3.318085, norm: 0.2826, time(ms): 796.76, token/sec:658025.72, hellaswag_acc: 0.2878
Step:  8897, loss: 3.244843, norm: 0.2595, time(ms): 799.29, token/sec:655942.00, hellaswag_acc: 0.2878
Step:  8898, loss: 3.201766, norm: 0.2654, time(ms): 799.63, token/sec:655663.50, hellaswag_acc: 0.2878
Step:  8899, loss: 3.178811, norm: 0.2554, time(ms): 800.96, token/sec:654578.36, hellaswag_acc: 0.2878
Step:  8900, loss: 3.228267, norm: 0.2504, time(ms): 793.90, token/sec:660399.47, hellaswag_acc: 0.2878
Step:  8901, loss: 3.192186, norm: 0.2605, time(ms): 790.38, token/sec:663339.62, hellaswag_acc: 0.2878
Step:  8902, loss: 3.185759, norm: 0.2725, time(ms): 790.57, token/sec:663173.18, hellaswag_acc: 0.2878
Step:  8903, loss: 3.187770, norm: 0.2756, time(ms): 790.35, token/sec:663362.64, hellaswag_acc: 0.2878
Step:  8904, loss: 3.186235, norm: 0.2515, time(ms): 790.72, token/sec:663055.01, hellaswag_acc: 0.2878
Step:  8905, loss: 3.188581, norm: 0.2701, time(ms): 801.23, token/sec:654355.53, hellaswag_acc: 0.2878
Step:  8906, loss: 3.196700, norm: 0.2474, time(ms): 805.07, token/sec:651233.65, hellaswag_acc: 0.2878
Step:  8907, loss: 3.166658, norm: 0.2915, time(ms): 797.64, token/sec:657300.93, hellaswag_acc: 0.2878
Step:  8908, loss: 3.186254, norm: 0.3040, time(ms): 793.74, token/sec:660527.62, hellaswag_acc: 0.2878
Step:  8909, loss: 3.216506, norm: 0.2855, time(ms): 802.20, token/sec:653564.77, hellaswag_acc: 0.2878
Step:  8910, loss: 3.178234, norm: 0.2629, time(ms): 805.98, token/sec:650497.37, hellaswag_acc: 0.2878
Step:  8911, loss: 3.242397, norm: 0.2939, time(ms): 795.15, token/sec:659355.14, hellaswag_acc: 0.2878
Step:  8912, loss: 3.193778, norm: 0.2581, time(ms): 795.42, token/sec:659130.63, hellaswag_acc: 0.2878
Step:  8913, loss: 3.251900, norm: 0.2934, time(ms): 807.45, token/sec:649311.69, hellaswag_acc: 0.2878
Step:  8914, loss: 3.207745, norm: 0.2537, time(ms): 801.94, token/sec:653775.40, hellaswag_acc: 0.2878
Step:  8915, loss: 3.199488, norm: 0.2827, time(ms): 787.40, token/sec:665846.68, hellaswag_acc: 0.2878
Step:  8916, loss: 3.238819, norm: 0.2667, time(ms): 790.31, token/sec:663397.06, hellaswag_acc: 0.2878
Step:  8917, loss: 3.223656, norm: 0.3089, time(ms): 791.59, token/sec:662320.89, hellaswag_acc: 0.2878
Step:  8918, loss: 3.217483, norm: 0.2656, time(ms): 794.23, token/sec:660123.51, hellaswag_acc: 0.2878
Step:  8919, loss: 3.187407, norm: 0.2857, time(ms): 786.46, token/sec:666639.56, hellaswag_acc: 0.2878
Step:  8920, loss: 3.283951, norm: 0.2951, time(ms): 797.27, token/sec:657602.25, hellaswag_acc: 0.2878
Step:  8921, loss: 3.349429, norm: 0.3021, time(ms): 791.38, token/sec:662498.48, hellaswag_acc: 0.2878
Step:  8922, loss: 3.292427, norm: 0.3452, time(ms): 797.21, token/sec:657652.21, hellaswag_acc: 0.2878
Step:  8923, loss: 3.289941, norm: 0.3217, time(ms): 790.39, token/sec:663332.02, hellaswag_acc: 0.2878
Step:  8924, loss: 3.281255, norm: 0.2957, time(ms): 785.93, token/sec:667089.73, hellaswag_acc: 0.2878
Step:  8925, loss: 3.305620, norm: 0.3107, time(ms): 790.58, token/sec:663164.78, hellaswag_acc: 0.2878
Step:  8926, loss: 3.305086, norm: 0.3070, time(ms): 793.95, token/sec:660356.44, hellaswag_acc: 0.2878
Step:  8927, loss: 3.253199, norm: 0.2956, time(ms): 789.82, token/sec:663807.58, hellaswag_acc: 0.2878
Step:  8928, loss: 3.148465, norm: 0.3245, time(ms): 791.72, token/sec:662210.20, hellaswag_acc: 0.2878
Step:  8929, loss: 3.293540, norm: 0.3044, time(ms): 788.72, token/sec:664731.21, hellaswag_acc: 0.2878
Step:  8930, loss: 3.256127, norm: 0.2792, time(ms): 791.96, token/sec:662017.02, hellaswag_acc: 0.2878
Step:  8931, loss: 3.216191, norm: 0.3103, time(ms): 788.09, token/sec:665263.93, hellaswag_acc: 0.2878
Step:  8932, loss: 3.194434, norm: 0.2772, time(ms): 799.31, token/sec:655928.30, hellaswag_acc: 0.2878
Step:  8933, loss: 3.224225, norm: 0.2741, time(ms): 791.88, token/sec:662077.21, hellaswag_acc: 0.2878
Step:  8934, loss: 3.193759, norm: 0.2824, time(ms): 788.21, token/sec:665160.70, hellaswag_acc: 0.2878
Step:  8935, loss: 3.179041, norm: 0.2737, time(ms): 795.77, token/sec:658840.73, hellaswag_acc: 0.2878
Step:  8936, loss: 3.157289, norm: 0.2910, time(ms): 789.77, token/sec:663849.86, hellaswag_acc: 0.2878
Step:  8937, loss: 3.135647, norm: 0.2687, time(ms): 791.36, token/sec:662515.65, hellaswag_acc: 0.2878
Step:  8938, loss: 3.181111, norm: 0.3026, time(ms): 792.96, token/sec:661179.82, hellaswag_acc: 0.2878
Step:  8939, loss: 3.187344, norm: 0.2667, time(ms): 787.84, token/sec:665473.71, hellaswag_acc: 0.2878
Step:  8940, loss: 3.192510, norm: 0.2708, time(ms): 791.22, token/sec:662635.63, hellaswag_acc: 0.2878
Step:  8941, loss: 3.221543, norm: 0.2756, time(ms): 788.65, token/sec:664790.90, hellaswag_acc: 0.2878
Step:  8942, loss: 3.244172, norm: 0.2697, time(ms): 791.70, token/sec:662228.34, hellaswag_acc: 0.2878
Step:  8943, loss: 3.154867, norm: 0.3016, time(ms): 790.90, token/sec:662902.30, hellaswag_acc: 0.2878
Step:  8944, loss: 3.254077, norm: 0.2901, time(ms): 797.63, token/sec:657305.45, hellaswag_acc: 0.2878
Step:  8945, loss: 3.210129, norm: 0.3025, time(ms): 792.28, token/sec:661743.09, hellaswag_acc: 0.2878
Step:  8946, loss: 3.195113, norm: 0.2775, time(ms): 787.25, token/sec:665974.13, hellaswag_acc: 0.2878
Step:  8947, loss: 3.194590, norm: 0.2707, time(ms): 791.13, token/sec:662709.71, hellaswag_acc: 0.2878
Step:  8948, loss: 3.265703, norm: 0.2909, time(ms): 787.77, token/sec:665531.51, hellaswag_acc: 0.2878
Step:  8949, loss: 3.295796, norm: 0.3815, time(ms): 790.54, token/sec:663205.39, hellaswag_acc: 0.2878
Step:  8950, loss: 3.223127, norm: 0.3279, time(ms): 793.44, token/sec:660778.30, hellaswag_acc: 0.2878
Step:  8951, loss: 3.265180, norm: 0.2966, time(ms): 801.28, token/sec:654314.64, hellaswag_acc: 0.2878
Step:  8952, loss: 3.243088, norm: 0.3128, time(ms): 805.57, token/sec:650827.16, hellaswag_acc: 0.2878
Step:  8953, loss: 3.158521, norm: 0.2807, time(ms): 1261.53, token/sec:415596.88, hellaswag_acc: 0.2878
Step:  8954, loss: 3.153445, norm: 0.2982, time(ms): 792.16, token/sec:661844.07, hellaswag_acc: 0.2878
Step:  8955, loss: 3.268111, norm: 0.2877, time(ms): 792.31, token/sec:661719.00, hellaswag_acc: 0.2878
Step:  8956, loss: 3.165254, norm: 0.2861, time(ms): 782.23, token/sec:670248.58, hellaswag_acc: 0.2878
Step:  8957, loss: 3.179679, norm: 0.2748, time(ms): 796.88, token/sec:657923.94, hellaswag_acc: 0.2878
Step:  8958, loss: 3.191555, norm: 0.3084, time(ms): 788.34, token/sec:665052.27, hellaswag_acc: 0.2878
Step:  8959, loss: 3.156342, norm: 0.2718, time(ms): 790.30, token/sec:663401.26, hellaswag_acc: 0.2878
Step:  8960, loss: 3.207696, norm: 0.3006, time(ms): 790.25, token/sec:663446.89, hellaswag_acc: 0.2878
Step:  8961, loss: 3.174283, norm: 0.2805, time(ms): 791.50, token/sec:662397.10, hellaswag_acc: 0.2878
Step:  8962, loss: 3.168228, norm: 0.2727, time(ms): 790.87, token/sec:662921.48, hellaswag_acc: 0.2878
Step:  8963, loss: 3.181829, norm: 0.2874, time(ms): 788.15, token/sec:665216.03, hellaswag_acc: 0.2878
Step:  8964, loss: 3.168154, norm: 0.2705, time(ms): 788.93, token/sec:664559.06, hellaswag_acc: 0.2878
Step:  8965, loss: 3.214752, norm: 0.2799, time(ms): 796.46, token/sec:658271.16, hellaswag_acc: 0.2878
Step:  8966, loss: 3.225022, norm: 0.2974, time(ms): 802.69, token/sec:653164.49, hellaswag_acc: 0.2878
Step:  8967, loss: 3.217621, norm: 0.2664, time(ms): 800.08, token/sec:655294.03, hellaswag_acc: 0.2878
Step:  8968, loss: 3.260867, norm: 0.2568, time(ms): 793.09, token/sec:661072.09, hellaswag_acc: 0.2878
Step:  8969, loss: 3.199656, norm: 0.2551, time(ms): 789.69, token/sec:663918.61, hellaswag_acc: 0.2878
Step:  8970, loss: 3.214384, norm: 0.2472, time(ms): 793.81, token/sec:660467.50, hellaswag_acc: 0.2878
Step:  8971, loss: 3.187678, norm: 0.3068, time(ms): 796.45, token/sec:658277.26, hellaswag_acc: 0.2878
Step:  8972, loss: 3.165514, norm: 0.2577, time(ms): 789.48, token/sec:664093.05, hellaswag_acc: 0.2878
Step:  8973, loss: 3.229967, norm: 0.2704, time(ms): 788.23, token/sec:665147.22, hellaswag_acc: 0.2878
Step:  8974, loss: 3.212377, norm: 0.2636, time(ms): 790.50, token/sec:663234.59, hellaswag_acc: 0.2878
Step:  8975, loss: 3.193217, norm: 0.2864, time(ms): 794.54, token/sec:659867.39, hellaswag_acc: 0.2878
Step:  8976, loss: 3.167259, norm: 0.2558, time(ms): 800.97, token/sec:654570.17, hellaswag_acc: 0.2878
Step:  8977, loss: 3.069051, norm: 0.3649, time(ms): 806.02, token/sec:650463.12, hellaswag_acc: 0.2878
Step:  8978, loss: 3.146525, norm: 0.3498, time(ms): 795.50, token/sec:659064.65, hellaswag_acc: 0.2878
Step:  8979, loss: 3.117869, norm: 0.2800, time(ms): 799.90, token/sec:655442.28, hellaswag_acc: 0.2878
Step:  8980, loss: 3.137413, norm: 0.3382, time(ms): 802.16, token/sec:653596.24, hellaswag_acc: 0.2878
Step:  8981, loss: 3.156730, norm: 0.2845, time(ms): 801.60, token/sec:654052.89, hellaswag_acc: 0.2878
Step:  8982, loss: 3.155819, norm: 0.2891, time(ms): 789.92, token/sec:663719.43, hellaswag_acc: 0.2878
Step:  8983, loss: 3.144943, norm: 0.2991, time(ms): 791.15, token/sec:662686.95, hellaswag_acc: 0.2878
Step:  8984, loss: 3.155490, norm: 0.2872, time(ms): 787.60, token/sec:665679.79, hellaswag_acc: 0.2878
Step:  8985, loss: 3.231549, norm: 0.3179, time(ms): 790.49, token/sec:663240.79, hellaswag_acc: 0.2878
Step:  8986, loss: 3.175955, norm: 0.3432, time(ms): 792.70, token/sec:661391.61, hellaswag_acc: 0.2878
Step:  8987, loss: 3.231377, norm: 0.2885, time(ms): 802.42, token/sec:653387.28, hellaswag_acc: 0.2878
Step:  8988, loss: 3.134852, norm: 0.2881, time(ms): 803.14, token/sec:652800.54, hellaswag_acc: 0.2878
Step:  8989, loss: 3.254491, norm: 0.3246, time(ms): 794.16, token/sec:660181.58, hellaswag_acc: 0.2878
Step:  8990, loss: 3.096896, norm: 0.2743, time(ms): 797.03, token/sec:657803.69, hellaswag_acc: 0.2878
Step:  8991, loss: 3.231388, norm: 0.3299, time(ms): 791.52, token/sec:662381.14, hellaswag_acc: 0.2878
Step:  8992, loss: 3.162501, norm: 0.3249, time(ms): 796.25, token/sec:658447.17, hellaswag_acc: 0.2878
Step:  8993, loss: 3.153621, norm: 0.2869, time(ms): 791.06, token/sec:662762.44, hellaswag_acc: 0.2878
Step:  8994, loss: 3.244549, norm: 0.3077, time(ms): 788.80, token/sec:664661.70, hellaswag_acc: 0.2878
Step:  8995, loss: 3.141877, norm: 0.2927, time(ms): 797.90, token/sec:657084.29, hellaswag_acc: 0.2878
Step:  8996, loss: 3.236601, norm: 0.2971, time(ms): 789.65, token/sec:663946.47, hellaswag_acc: 0.2878
Step:  8997, loss: 3.163285, norm: 0.2574, time(ms): 792.58, token/sec:661492.88, hellaswag_acc: 0.2878
Step:  8998, loss: 3.262568, norm: 0.2901, time(ms): 798.11, token/sec:656908.02, hellaswag_acc: 0.2878
Step:  8999, loss: 3.167762, norm: 0.2840, time(ms): 800.82, token/sec:654692.56, hellaswag_acc: 0.2878
rank 0 sample 0: Hello, I'm a language model, and I was taught by Dr. Kottraj Haji when I'm a graduate student of English, and my
rank 0 sample 1: Hello, I'm a language model, so here's a little bit more fun. The fun aside, there is some pretty interesting vocabulary that needs to be understood
rank 0 sample 2: Hello, I'm a language model, but I understand how fast to program the computer's
functionals to work. In my first few years of working in
rank 0 sample 3: Hello, I'm a language model, so don't forget to be careful!<|endoftext|>To learn more about the various kinds of cancer you need to know the stages
rank 1 sample 0: Hello, I'm a language model, just what are you gonna do? As you probably guessed, they're gonna put the stuff you are trying to learn.
rank 1 sample 1: Hello, I'm a language model, not an engineer. I'm a student at the University that is involved in science and technological education at all levels. I
rank 1 sample 2: Hello, I'm a language model, so is this an example of a language model?
A Java interpreter will fetch the Java byte. It's really quick
rank 1 sample 3: Hello, I'm a language model, and I'm using a couple of expressions/expressions we wrote using Perl from the package to create a new project.
Step:  9000, loss: 3.133307, norm: 0.3047, time(ms): 363812.25, token/sec:1441.09, val_loss: 3.2126, hellaswag_acc: 0.2882
Step:  9001, loss: 3.206283, norm: 0.3015, time(ms): 793.79, token/sec:660483.77, hellaswag_acc: 0.2882
Step:  9002, loss: 3.156557, norm: 0.2799, time(ms): 796.81, token/sec:657980.44, hellaswag_acc: 0.2882
Step:  9003, loss: 3.229484, norm: 0.2798, time(ms): 804.32, token/sec:651839.02, hellaswag_acc: 0.2882
Step:  9004, loss: 3.182495, norm: 0.2922, time(ms): 791.49, token/sec:662405.88, hellaswag_acc: 0.2882
Step:  9005, loss: 3.153434, norm: 0.3005, time(ms): 806.85, token/sec:649796.92, hellaswag_acc: 0.2882
Step:  9006, loss: 3.223949, norm: 0.2707, time(ms): 796.42, token/sec:658304.66, hellaswag_acc: 0.2882
Step:  9007, loss: 3.178890, norm: 0.2624, time(ms): 799.52, token/sec:655753.05, hellaswag_acc: 0.2882
Step:  9008, loss: 3.194910, norm: 0.2759, time(ms): 800.93, token/sec:654600.76, hellaswag_acc: 0.2882
Step:  9009, loss: 3.229716, norm: 0.2859, time(ms): 797.95, token/sec:657047.77, hellaswag_acc: 0.2882
Step:  9010, loss: 3.218931, norm: 0.2939, time(ms): 803.80, token/sec:652262.83, hellaswag_acc: 0.2882
Step:  9011, loss: 3.204965, norm: 0.2866, time(ms): 799.28, token/sec:655949.44, hellaswag_acc: 0.2882
Step:  9012, loss: 3.174932, norm: 0.2585, time(ms): 789.84, token/sec:663791.15, hellaswag_acc: 0.2882
Step:  9013, loss: 3.154311, norm: 0.2802, time(ms): 807.10, token/sec:649597.87, hellaswag_acc: 0.2882
Step:  9014, loss: 3.160498, norm: 0.2544, time(ms): 802.65, token/sec:653199.80, hellaswag_acc: 0.2882
Step:  9015, loss: 3.132417, norm: 0.2660, time(ms): 790.01, token/sec:663647.72, hellaswag_acc: 0.2882
Step:  9016, loss: 3.130026, norm: 0.2645, time(ms): 800.97, token/sec:654570.37, hellaswag_acc: 0.2882
Step:  9017, loss: 3.205504, norm: 0.2570, time(ms): 808.80, token/sec:648229.68, hellaswag_acc: 0.2882
Step:  9018, loss: 3.168125, norm: 0.2726, time(ms): 798.03, token/sec:656976.71, hellaswag_acc: 0.2882
Step:  9019, loss: 3.195318, norm: 0.2683, time(ms): 791.30, token/sec:662566.95, hellaswag_acc: 0.2882
Step:  9020, loss: 3.113131, norm: 0.2607, time(ms): 798.45, token/sec:656635.76, hellaswag_acc: 0.2882
Step:  9021, loss: 3.150744, norm: 0.2605, time(ms): 790.22, token/sec:663470.71, hellaswag_acc: 0.2882
Step:  9022, loss: 3.140924, norm: 0.2561, time(ms): 790.87, token/sec:662929.48, hellaswag_acc: 0.2882
Step:  9023, loss: 3.187862, norm: 0.2669, time(ms): 790.77, token/sec:663013.22, hellaswag_acc: 0.2882
Step:  9024, loss: 3.284797, norm: 0.3047, time(ms): 794.71, token/sec:659724.26, hellaswag_acc: 0.2882
Step:  9025, loss: 3.234995, norm: 0.3314, time(ms): 798.64, token/sec:656475.41, hellaswag_acc: 0.2882
Step:  9026, loss: 3.180070, norm: 0.3320, time(ms): 801.69, token/sec:653979.36, hellaswag_acc: 0.2882
Step:  9027, loss: 3.205418, norm: 0.3107, time(ms): 805.74, token/sec:650693.70, hellaswag_acc: 0.2882
Step:  9028, loss: 3.185884, norm: 0.2655, time(ms): 794.94, token/sec:659528.57, hellaswag_acc: 0.2882
Step:  9029, loss: 3.184515, norm: 0.3105, time(ms): 792.77, token/sec:661339.49, hellaswag_acc: 0.2882
Step:  9030, loss: 3.213076, norm: 0.2753, time(ms): 805.47, token/sec:650910.57, hellaswag_acc: 0.2882
Step:  9031, loss: 3.159327, norm: 0.2773, time(ms): 803.44, token/sec:652554.33, hellaswag_acc: 0.2882
Step:  9032, loss: 3.157038, norm: 0.2894, time(ms): 798.33, token/sec:656733.22, hellaswag_acc: 0.2882
Step:  9033, loss: 3.133624, norm: 0.2776, time(ms): 795.92, token/sec:658723.31, hellaswag_acc: 0.2882
Step:  9034, loss: 3.149353, norm: 0.2663, time(ms): 803.03, token/sec:652884.85, hellaswag_acc: 0.2882
Step:  9035, loss: 3.187031, norm: 0.3030, time(ms): 801.45, token/sec:654173.13, hellaswag_acc: 0.2882
Step:  9036, loss: 3.135016, norm: 0.2776, time(ms): 798.01, token/sec:656993.40, hellaswag_acc: 0.2882
Step:  9037, loss: 3.229070, norm: 0.2953, time(ms): 802.40, token/sec:653401.84, hellaswag_acc: 0.2882
Step:  9038, loss: 3.235125, norm: 0.3094, time(ms): 798.69, token/sec:656435.83, hellaswag_acc: 0.2882
Step:  9039, loss: 3.239600, norm: 0.3248, time(ms): 793.78, token/sec:660492.70, hellaswag_acc: 0.2882
Step:  9040, loss: 3.216954, norm: 0.2970, time(ms): 800.38, token/sec:655052.76, hellaswag_acc: 0.2882
Step:  9041, loss: 3.229018, norm: 0.2900, time(ms): 805.24, token/sec:651093.85, hellaswag_acc: 0.2882
Step:  9042, loss: 3.274977, norm: 0.2810, time(ms): 800.35, token/sec:655071.69, hellaswag_acc: 0.2882
Step:  9043, loss: 3.239020, norm: 0.3166, time(ms): 796.83, token/sec:657970.59, hellaswag_acc: 0.2882
Step:  9044, loss: 3.229519, norm: 0.3113, time(ms): 799.89, token/sec:655448.33, hellaswag_acc: 0.2882
Step:  9045, loss: 3.225924, norm: 0.2879, time(ms): 803.47, token/sec:652532.83, hellaswag_acc: 0.2882
Step:  9046, loss: 3.192225, norm: 0.2965, time(ms): 800.34, token/sec:655079.30, hellaswag_acc: 0.2882
Step:  9047, loss: 3.191050, norm: 0.2907, time(ms): 792.30, token/sec:661731.35, hellaswag_acc: 0.2882
Step:  9048, loss: 3.162797, norm: 0.2744, time(ms): 803.77, token/sec:652288.18, hellaswag_acc: 0.2882
Step:  9049, loss: 3.118634, norm: 0.3036, time(ms): 802.27, token/sec:653504.95, hellaswag_acc: 0.2882
Step:  9050, loss: 3.120918, norm: 0.2811, time(ms): 797.70, token/sec:657246.12, hellaswag_acc: 0.2882
Step:  9051, loss: 3.104762, norm: 0.2654, time(ms): 802.18, token/sec:653581.87, hellaswag_acc: 0.2882
Step:  9052, loss: 3.154342, norm: 0.2750, time(ms): 799.48, token/sec:655783.55, hellaswag_acc: 0.2882
Step:  9053, loss: 3.168064, norm: 0.2878, time(ms): 796.47, token/sec:658263.27, hellaswag_acc: 0.2882
Step:  9054, loss: 3.132524, norm: 0.2563, time(ms): 800.33, token/sec:655091.20, hellaswag_acc: 0.2882
Step:  9055, loss: 3.117940, norm: 0.2876, time(ms): 801.34, token/sec:654266.75, hellaswag_acc: 0.2882
Step:  9056, loss: 3.132731, norm: 0.2999, time(ms): 799.71, token/sec:655593.72, hellaswag_acc: 0.2882
Step:  9057, loss: 3.151478, norm: 0.2919, time(ms): 799.86, token/sec:655471.58, hellaswag_acc: 0.2882
Step:  9058, loss: 3.144643, norm: 0.2781, time(ms): 796.98, token/sec:657842.45, hellaswag_acc: 0.2882
Step:  9059, loss: 3.161154, norm: 0.2911, time(ms): 796.32, token/sec:658386.65, hellaswag_acc: 0.2882
Step:  9060, loss: 3.171045, norm: 0.3197, time(ms): 791.92, token/sec:662047.91, hellaswag_acc: 0.2882
Step:  9061, loss: 3.198325, norm: 0.3143, time(ms): 794.21, token/sec:660139.37, hellaswag_acc: 0.2882
Step:  9062, loss: 3.169354, norm: 0.2820, time(ms): 791.45, token/sec:662437.01, hellaswag_acc: 0.2882
Step:  9063, loss: 3.143786, norm: 0.3340, time(ms): 784.66, token/sec:668172.73, hellaswag_acc: 0.2882
Step:  9064, loss: 3.205976, norm: 0.2875, time(ms): 791.94, token/sec:662025.99, hellaswag_acc: 0.2882
Step:  9065, loss: 3.146642, norm: 0.2990, time(ms): 791.74, token/sec:662197.83, hellaswag_acc: 0.2882
Step:  9066, loss: 3.210634, norm: 0.2793, time(ms): 793.51, token/sec:660721.91, hellaswag_acc: 0.2882
Step:  9067, loss: 3.240818, norm: 0.2942, time(ms): 804.34, token/sec:651821.44, hellaswag_acc: 0.2882
Step:  9068, loss: 3.210260, norm: 0.2686, time(ms): 804.94, token/sec:651336.46, hellaswag_acc: 0.2882
Step:  9069, loss: 3.153479, norm: 0.2775, time(ms): 796.07, token/sec:658591.52, hellaswag_acc: 0.2882
Step:  9070, loss: 3.276268, norm: 0.2974, time(ms): 791.81, token/sec:662141.80, hellaswag_acc: 0.2882
Step:  9071, loss: 3.165842, norm: 0.2625, time(ms): 791.41, token/sec:662475.73, hellaswag_acc: 0.2882
Step:  9072, loss: 3.173566, norm: 0.2756, time(ms): 794.03, token/sec:660290.41, hellaswag_acc: 0.2882
Step:  9073, loss: 3.219203, norm: 0.2833, time(ms): 791.01, token/sec:662804.99, hellaswag_acc: 0.2882
Step:  9074, loss: 3.214049, norm: 0.2762, time(ms): 787.06, token/sec:666131.08, hellaswag_acc: 0.2882
Step:  9075, loss: 3.220081, norm: 0.2857, time(ms): 803.13, token/sec:652808.29, hellaswag_acc: 0.2882
Step:  9076, loss: 3.180587, norm: 0.2706, time(ms): 802.71, token/sec:653145.28, hellaswag_acc: 0.2882
Step:  9077, loss: 3.156852, norm: 0.2635, time(ms): 793.59, token/sec:660650.25, hellaswag_acc: 0.2882
Step:  9078, loss: 3.116439, norm: 0.2498, time(ms): 796.47, token/sec:658263.67, hellaswag_acc: 0.2882
Step:  9079, loss: 3.203198, norm: 0.2592, time(ms): 792.09, token/sec:661906.62, hellaswag_acc: 0.2882
Step:  9080, loss: 3.182988, norm: 0.2526, time(ms): 795.04, token/sec:659448.47, hellaswag_acc: 0.2882
Step:  9081, loss: 3.186358, norm: 0.2482, time(ms): 791.43, token/sec:662454.97, hellaswag_acc: 0.2882
Step:  9082, loss: 3.202089, norm: 0.3028, time(ms): 789.62, token/sec:663974.74, hellaswag_acc: 0.2882
Step:  9083, loss: 3.150236, norm: 0.2714, time(ms): 789.53, token/sec:664052.34, hellaswag_acc: 0.2882
Step:  9084, loss: 3.124259, norm: 0.2766, time(ms): 789.47, token/sec:664099.06, hellaswag_acc: 0.2882
Step:  9085, loss: 3.158493, norm: 0.3028, time(ms): 799.09, token/sec:656105.22, hellaswag_acc: 0.2882
Step:  9086, loss: 3.120811, norm: 0.2707, time(ms): 803.54, token/sec:652475.53, hellaswag_acc: 0.2882
Step:  9087, loss: 3.128058, norm: 0.2822, time(ms): 793.53, token/sec:660702.66, hellaswag_acc: 0.2882
Step:  9088, loss: 3.235303, norm: 0.3016, time(ms): 799.81, token/sec:655515.94, hellaswag_acc: 0.2882
Step:  9089, loss: 3.145084, norm: 0.2855, time(ms): 803.53, token/sec:652479.40, hellaswag_acc: 0.2882
Step:  9090, loss: 3.193563, norm: 0.2682, time(ms): 798.55, token/sec:656549.11, hellaswag_acc: 0.2882
Step:  9091, loss: 3.162618, norm: 0.2907, time(ms): 802.86, token/sec:653024.83, hellaswag_acc: 0.2882
Step:  9092, loss: 3.152039, norm: 0.2638, time(ms): 793.24, token/sec:660942.34, hellaswag_acc: 0.2882
Step:  9093, loss: 3.146498, norm: 0.2595, time(ms): 804.78, token/sec:651464.20, hellaswag_acc: 0.2882
Step:  9094, loss: 3.157377, norm: 0.2759, time(ms): 799.23, token/sec:655988.18, hellaswag_acc: 0.2882
Step:  9095, loss: 3.258509, norm: 0.2790, time(ms): 797.55, token/sec:657370.48, hellaswag_acc: 0.2882
Step:  9096, loss: 3.311359, norm: 0.2850, time(ms): 803.31, token/sec:652655.62, hellaswag_acc: 0.2882
Step:  9097, loss: 3.142106, norm: 0.2671, time(ms): 800.77, token/sec:654729.40, hellaswag_acc: 0.2882
Step:  9098, loss: 3.246249, norm: 0.2734, time(ms): 797.11, token/sec:657734.63, hellaswag_acc: 0.2882
Step:  9099, loss: 3.230036, norm: 0.3286, time(ms): 800.84, token/sec:654672.67, hellaswag_acc: 0.2882
Step:  9100, loss: 3.252908, norm: 0.3292, time(ms): 801.31, token/sec:654289.72, hellaswag_acc: 0.2882
Step:  9101, loss: 3.193190, norm: 0.2785, time(ms): 799.18, token/sec:656030.65, hellaswag_acc: 0.2882
Step:  9102, loss: 3.191068, norm: 0.2938, time(ms): 800.31, token/sec:655109.55, hellaswag_acc: 0.2882
Step:  9103, loss: 3.132929, norm: 0.2644, time(ms): 799.23, token/sec:655988.96, hellaswag_acc: 0.2882
Step:  9104, loss: 3.201441, norm: 0.2789, time(ms): 798.06, token/sec:656956.89, hellaswag_acc: 0.2882
Step:  9105, loss: 3.124556, norm: 0.2536, time(ms): 802.78, token/sec:653091.75, hellaswag_acc: 0.2882
Step:  9106, loss: 3.153799, norm: 0.2564, time(ms): 797.90, token/sec:657087.63, hellaswag_acc: 0.2882
Step:  9107, loss: 3.150282, norm: 0.2495, time(ms): 795.12, token/sec:659384.60, hellaswag_acc: 0.2882
Step:  9108, loss: 3.164614, norm: 0.2643, time(ms): 805.42, token/sec:650949.11, hellaswag_acc: 0.2882
Step:  9109, loss: 3.176608, norm: 0.2564, time(ms): 796.19, token/sec:658498.43, hellaswag_acc: 0.2882
Step:  9110, loss: 3.137791, norm: 0.2659, time(ms): 804.78, token/sec:651471.14, hellaswag_acc: 0.2882
Step:  9111, loss: 3.131987, norm: 0.2630, time(ms): 794.22, token/sec:660132.04, hellaswag_acc: 0.2882
Step:  9112, loss: 3.200924, norm: 0.2580, time(ms): 803.55, token/sec:652462.55, hellaswag_acc: 0.2882
Step:  9113, loss: 3.195018, norm: 0.2582, time(ms): 800.72, token/sec:654772.29, hellaswag_acc: 0.2882
Step:  9114, loss: 3.179610, norm: 0.2545, time(ms): 798.41, token/sec:656667.92, hellaswag_acc: 0.2882
Step:  9115, loss: 3.149384, norm: 0.2579, time(ms): 796.37, token/sec:658347.62, hellaswag_acc: 0.2882
Step:  9116, loss: 3.163509, norm: 0.2398, time(ms): 804.00, token/sec:652102.48, hellaswag_acc: 0.2882
Step:  9117, loss: 3.234496, norm: 0.2669, time(ms): 801.61, token/sec:654046.66, hellaswag_acc: 0.2882
Step:  9118, loss: 3.166044, norm: 0.2462, time(ms): 790.47, token/sec:663259.99, hellaswag_acc: 0.2882
Step:  9119, loss: 3.129766, norm: 0.2678, time(ms): 804.85, token/sec:651410.74, hellaswag_acc: 0.2882
Step:  9120, loss: 3.099014, norm: 0.2666, time(ms): 804.50, token/sec:651694.52, hellaswag_acc: 0.2882
Step:  9121, loss: 3.123797, norm: 0.2525, time(ms): 796.50, token/sec:658241.01, hellaswag_acc: 0.2882
Step:  9122, loss: 3.170315, norm: 0.2691, time(ms): 796.64, token/sec:658127.14, hellaswag_acc: 0.2882
Step:  9123, loss: 3.165628, norm: 0.2537, time(ms): 804.55, token/sec:651653.97, hellaswag_acc: 0.2882
Step:  9124, loss: 3.125544, norm: 0.2704, time(ms): 797.88, token/sec:657104.12, hellaswag_acc: 0.2882
Step:  9125, loss: 3.166013, norm: 0.2749, time(ms): 803.29, token/sec:652678.09, hellaswag_acc: 0.2882
Step:  9126, loss: 3.247855, norm: 0.3065, time(ms): 791.99, token/sec:661984.14, hellaswag_acc: 0.2882
Step:  9127, loss: 3.163279, norm: 0.2973, time(ms): 802.87, token/sec:653013.59, hellaswag_acc: 0.2882
Step:  9128, loss: 3.187378, norm: 0.2985, time(ms): 804.36, token/sec:651810.04, hellaswag_acc: 0.2882
Step:  9129, loss: 3.181686, norm: 0.3172, time(ms): 791.50, token/sec:662400.89, hellaswag_acc: 0.2882
Step:  9130, loss: 3.137418, norm: 0.3190, time(ms): 801.49, token/sec:654142.77, hellaswag_acc: 0.2882
Step:  9131, loss: 3.147089, norm: 0.2920, time(ms): 804.53, token/sec:651667.10, hellaswag_acc: 0.2882
Step:  9132, loss: 3.219356, norm: 0.3026, time(ms): 797.37, token/sec:657525.57, hellaswag_acc: 0.2882
Step:  9133, loss: 3.118032, norm: 0.2988, time(ms): 803.34, token/sec:652638.19, hellaswag_acc: 0.2882
Step:  9134, loss: 3.191548, norm: 0.3332, time(ms): 795.41, token/sec:659141.89, hellaswag_acc: 0.2882
Step:  9135, loss: 3.185204, norm: 0.3282, time(ms): 805.91, token/sec:650554.91, hellaswag_acc: 0.2882
Step:  9136, loss: 3.171501, norm: 0.3265, time(ms): 794.29, token/sec:660067.24, hellaswag_acc: 0.2882
Step:  9137, loss: 3.221684, norm: 0.3050, time(ms): 796.91, token/sec:657898.55, hellaswag_acc: 0.2882
Step:  9138, loss: 3.209496, norm: 0.3124, time(ms): 807.25, token/sec:649477.38, hellaswag_acc: 0.2882
Step:  9139, loss: 3.218547, norm: 0.2843, time(ms): 798.86, token/sec:656295.16, hellaswag_acc: 0.2882
Step:  9140, loss: 3.155303, norm: 0.2968, time(ms): 795.33, token/sec:659207.50, hellaswag_acc: 0.2882
Step:  9141, loss: 3.220528, norm: 0.3524, time(ms): 800.97, token/sec:654569.59, hellaswag_acc: 0.2882
Step:  9142, loss: 3.138140, norm: 0.2907, time(ms): 804.61, token/sec:651602.41, hellaswag_acc: 0.2882
Step:  9143, loss: 3.204415, norm: 0.3015, time(ms): 1299.39, token/sec:403486.73, hellaswag_acc: 0.2882
Step:  9144, loss: 3.150709, norm: 0.3016, time(ms): 769.29, token/sec:681519.20, hellaswag_acc: 0.2882
Step:  9145, loss: 3.176805, norm: 0.2554, time(ms): 788.90, token/sec:664577.33, hellaswag_acc: 0.2882
Step:  9146, loss: 3.172264, norm: 0.2759, time(ms): 799.46, token/sec:655806.24, hellaswag_acc: 0.2882
Step:  9147, loss: 3.165558, norm: 0.2626, time(ms): 792.23, token/sec:661787.90, hellaswag_acc: 0.2882
Step:  9148, loss: 3.175148, norm: 0.2513, time(ms): 788.27, token/sec:665112.61, hellaswag_acc: 0.2882
Step:  9149, loss: 3.147345, norm: 0.2767, time(ms): 789.42, token/sec:664139.58, hellaswag_acc: 0.2882
Step:  9150, loss: 3.165564, norm: 0.2530, time(ms): 788.63, token/sec:664806.78, hellaswag_acc: 0.2882
Step:  9151, loss: 3.206666, norm: 0.2747, time(ms): 791.16, token/sec:662683.35, hellaswag_acc: 0.2882
Step:  9152, loss: 3.199157, norm: 0.2599, time(ms): 791.02, token/sec:662803.79, hellaswag_acc: 0.2882
Step:  9153, loss: 3.141171, norm: 0.2526, time(ms): 794.66, token/sec:659762.66, hellaswag_acc: 0.2882
Step:  9154, loss: 3.150920, norm: 0.3300, time(ms): 801.63, token/sec:654029.35, hellaswag_acc: 0.2882
Step:  9155, loss: 3.160759, norm: 0.2788, time(ms): 803.71, token/sec:652338.10, hellaswag_acc: 0.2882
Step:  9156, loss: 3.270084, norm: 0.2766, time(ms): 791.27, token/sec:662592.10, hellaswag_acc: 0.2882
Step:  9157, loss: 3.314286, norm: 0.3379, time(ms): 796.86, token/sec:657945.20, hellaswag_acc: 0.2882
Step:  9158, loss: 3.168315, norm: 0.3182, time(ms): 791.46, token/sec:662430.03, hellaswag_acc: 0.2882
Step:  9159, loss: 3.203269, norm: 0.2734, time(ms): 787.12, token/sec:666080.64, hellaswag_acc: 0.2882
Step:  9160, loss: 3.180295, norm: 0.3014, time(ms): 788.18, token/sec:665188.26, hellaswag_acc: 0.2882
Step:  9161, loss: 3.230346, norm: 0.2591, time(ms): 799.46, token/sec:655802.53, hellaswag_acc: 0.2882
Step:  9162, loss: 3.271410, norm: 0.3188, time(ms): 803.22, token/sec:652736.40, hellaswag_acc: 0.2882
Step:  9163, loss: 3.239878, norm: 0.2909, time(ms): 793.71, token/sec:660553.81, hellaswag_acc: 0.2882
Step:  9164, loss: 3.192453, norm: 0.2987, time(ms): 798.48, token/sec:656610.27, hellaswag_acc: 0.2882
Step:  9165, loss: 3.173212, norm: 0.2805, time(ms): 798.52, token/sec:656574.98, hellaswag_acc: 0.2882
Step:  9166, loss: 3.213340, norm: 0.2928, time(ms): 792.23, token/sec:661785.31, hellaswag_acc: 0.2882
Step:  9167, loss: 3.202240, norm: 0.2720, time(ms): 789.27, token/sec:664269.58, hellaswag_acc: 0.2882
Step:  9168, loss: 3.196316, norm: 0.2876, time(ms): 792.41, token/sec:661634.38, hellaswag_acc: 0.2882
Step:  9169, loss: 3.227579, norm: 0.2592, time(ms): 788.08, token/sec:665274.79, hellaswag_acc: 0.2882
Step:  9170, loss: 3.236253, norm: 0.2836, time(ms): 796.31, token/sec:658400.05, hellaswag_acc: 0.2882
Step:  9171, loss: 3.240473, norm: 0.2560, time(ms): 791.81, token/sec:662141.80, hellaswag_acc: 0.2882
Step:  9172, loss: 3.258513, norm: 0.2966, time(ms): 796.25, token/sec:658443.62, hellaswag_acc: 0.2882
Step:  9173, loss: 3.231791, norm: 0.2684, time(ms): 788.99, token/sec:664503.63, hellaswag_acc: 0.2882
Step:  9174, loss: 3.211433, norm: 0.2867, time(ms): 791.29, token/sec:662575.33, hellaswag_acc: 0.2882
Step:  9175, loss: 3.262221, norm: 0.2535, time(ms): 790.76, token/sec:663018.42, hellaswag_acc: 0.2882
Step:  9176, loss: 3.193782, norm: 0.2871, time(ms): 791.49, token/sec:662405.09, hellaswag_acc: 0.2882
Step:  9177, loss: 3.240088, norm: 0.2909, time(ms): 790.23, token/sec:663459.70, hellaswag_acc: 0.2882
Step:  9178, loss: 3.167053, norm: 0.2995, time(ms): 792.13, token/sec:661867.98, hellaswag_acc: 0.2882
Step:  9179, loss: 3.330415, norm: 0.2987, time(ms): 797.16, token/sec:657698.63, hellaswag_acc: 0.2882
Step:  9180, loss: 3.163982, norm: 0.3225, time(ms): 793.20, token/sec:660979.10, hellaswag_acc: 0.2882
Step:  9181, loss: 3.115506, norm: 0.2911, time(ms): 799.68, token/sec:655623.62, hellaswag_acc: 0.2882
Step:  9182, loss: 3.156923, norm: 0.2649, time(ms): 803.04, token/sec:652880.39, hellaswag_acc: 0.2882
Step:  9183, loss: 3.184189, norm: 0.2746, time(ms): 795.82, token/sec:658798.69, hellaswag_acc: 0.2882
Step:  9184, loss: 3.244795, norm: 0.3091, time(ms): 796.94, token/sec:657875.71, hellaswag_acc: 0.2882
Step:  9185, loss: 3.212574, norm: 0.2814, time(ms): 789.98, token/sec:663673.75, hellaswag_acc: 0.2882
Step:  9186, loss: 3.140468, norm: 0.2764, time(ms): 788.15, token/sec:665215.83, hellaswag_acc: 0.2882
Step:  9187, loss: 3.128842, norm: 0.2863, time(ms): 789.81, token/sec:663813.39, hellaswag_acc: 0.2882
Step:  9188, loss: 3.114093, norm: 0.2581, time(ms): 801.50, token/sec:654134.21, hellaswag_acc: 0.2882
Step:  9189, loss: 3.179239, norm: 0.2925, time(ms): 788.95, token/sec:664535.76, hellaswag_acc: 0.2882
Step:  9190, loss: 3.244559, norm: 0.3231, time(ms): 790.76, token/sec:663020.42, hellaswag_acc: 0.2882
Step:  9191, loss: 3.214954, norm: 0.3092, time(ms): 790.60, token/sec:663149.39, hellaswag_acc: 0.2882
Step:  9192, loss: 3.194457, norm: 0.2805, time(ms): 791.97, token/sec:662006.46, hellaswag_acc: 0.2882
Step:  9193, loss: 3.178096, norm: 0.3143, time(ms): 792.52, token/sec:661543.42, hellaswag_acc: 0.2882
Step:  9194, loss: 3.231082, norm: 0.2710, time(ms): 798.30, token/sec:656754.80, hellaswag_acc: 0.2882
Step:  9195, loss: 3.271342, norm: 0.2738, time(ms): 802.40, token/sec:653402.43, hellaswag_acc: 0.2882
Step:  9196, loss: 3.185942, norm: 0.2654, time(ms): 803.97, token/sec:652125.88, hellaswag_acc: 0.2882
Step:  9197, loss: 3.201098, norm: 0.2797, time(ms): 790.86, token/sec:662932.67, hellaswag_acc: 0.2882
Step:  9198, loss: 3.164128, norm: 0.2639, time(ms): 800.57, token/sec:654893.18, hellaswag_acc: 0.2882
Step:  9199, loss: 3.137357, norm: 0.2997, time(ms): 806.73, token/sec:649896.40, hellaswag_acc: 0.2882
Step:  9200, loss: 3.234207, norm: 0.2883, time(ms): 796.98, token/sec:657847.37, hellaswag_acc: 0.2882
Step:  9201, loss: 3.206990, norm: 0.2762, time(ms): 797.06, token/sec:657775.55, hellaswag_acc: 0.2882
Step:  9202, loss: 3.179267, norm: 0.2902, time(ms): 802.59, token/sec:653246.76, hellaswag_acc: 0.2882
Step:  9203, loss: 3.185320, norm: 0.2855, time(ms): 801.70, token/sec:653968.08, hellaswag_acc: 0.2882
Step:  9204, loss: 3.188597, norm: 0.2549, time(ms): 791.71, token/sec:662222.56, hellaswag_acc: 0.2882
Step:  9205, loss: 3.235466, norm: 0.2847, time(ms): 791.54, token/sec:662368.17, hellaswag_acc: 0.2882
Step:  9206, loss: 3.175983, norm: 0.2762, time(ms): 794.25, token/sec:660107.86, hellaswag_acc: 0.2882
Step:  9207, loss: 3.257938, norm: 0.2906, time(ms): 798.97, token/sec:656204.09, hellaswag_acc: 0.2882
Step:  9208, loss: 3.200169, norm: 0.2795, time(ms): 800.37, token/sec:655056.47, hellaswag_acc: 0.2882
Step:  9209, loss: 3.174576, norm: 0.2843, time(ms): 801.47, token/sec:654157.56, hellaswag_acc: 0.2882
Step:  9210, loss: 3.283719, norm: 0.3143, time(ms): 800.00, token/sec:655360.82, hellaswag_acc: 0.2882
Step:  9211, loss: 3.272387, norm: 0.2903, time(ms): 797.73, token/sec:657223.53, hellaswag_acc: 0.2882
Step:  9212, loss: 3.221405, norm: 0.3390, time(ms): 799.39, token/sec:655861.20, hellaswag_acc: 0.2882
Step:  9213, loss: 3.165890, norm: 0.2902, time(ms): 800.78, token/sec:654724.33, hellaswag_acc: 0.2882
Step:  9214, loss: 3.221878, norm: 0.2973, time(ms): 802.85, token/sec:653031.43, hellaswag_acc: 0.2882
Step:  9215, loss: 3.213045, norm: 0.2982, time(ms): 796.33, token/sec:658381.52, hellaswag_acc: 0.2882
Step:  9216, loss: 3.174918, norm: 0.2869, time(ms): 800.51, token/sec:654944.87, hellaswag_acc: 0.2882
Step:  9217, loss: 3.182393, norm: 0.2941, time(ms): 800.17, token/sec:655223.93, hellaswag_acc: 0.2882
Step:  9218, loss: 3.159552, norm: 0.3058, time(ms): 802.25, token/sec:653522.24, hellaswag_acc: 0.2882
Step:  9219, loss: 3.168443, norm: 0.3039, time(ms): 796.18, token/sec:658503.96, hellaswag_acc: 0.2882
Step:  9220, loss: 3.106168, norm: 0.2897, time(ms): 798.02, token/sec:656984.37, hellaswag_acc: 0.2882
Step:  9221, loss: 3.164735, norm: 0.2780, time(ms): 798.41, token/sec:656663.80, hellaswag_acc: 0.2882
Step:  9222, loss: 3.213396, norm: 0.2885, time(ms): 798.20, token/sec:656834.64, hellaswag_acc: 0.2882
Step:  9223, loss: 3.190681, norm: 0.3001, time(ms): 789.35, token/sec:664205.17, hellaswag_acc: 0.2882
Step:  9224, loss: 3.191112, norm: 0.2892, time(ms): 787.61, token/sec:665666.09, hellaswag_acc: 0.2882
Step:  9225, loss: 3.234226, norm: 0.3044, time(ms): 791.52, token/sec:662381.74, hellaswag_acc: 0.2882
Step:  9226, loss: 3.204112, norm: 0.2871, time(ms): 796.33, token/sec:658378.17, hellaswag_acc: 0.2882
Step:  9227, loss: 3.192585, norm: 0.3039, time(ms): 804.49, token/sec:651700.70, hellaswag_acc: 0.2882
Step:  9228, loss: 3.175666, norm: 0.2769, time(ms): 798.68, token/sec:656445.82, hellaswag_acc: 0.2882
Step:  9229, loss: 3.261147, norm: 0.3071, time(ms): 798.67, token/sec:656452.48, hellaswag_acc: 0.2882
Step:  9230, loss: 3.204744, norm: 0.2906, time(ms): 795.72, token/sec:658887.91, hellaswag_acc: 0.2882
Step:  9231, loss: 3.186342, norm: 0.2829, time(ms): 803.33, token/sec:652644.00, hellaswag_acc: 0.2882
Step:  9232, loss: 3.280371, norm: 0.3144, time(ms): 803.04, token/sec:652880.39, hellaswag_acc: 0.2882
Step:  9233, loss: 3.206640, norm: 0.3105, time(ms): 789.94, token/sec:663704.40, hellaswag_acc: 0.2882
Step:  9234, loss: 3.213104, norm: 0.2816, time(ms): 804.17, token/sec:651958.64, hellaswag_acc: 0.2882
Step:  9235, loss: 3.242129, norm: 0.3022, time(ms): 804.33, token/sec:651828.78, hellaswag_acc: 0.2882
Step:  9236, loss: 3.197478, norm: 0.2823, time(ms): 799.17, token/sec:656040.04, hellaswag_acc: 0.2882
Step:  9237, loss: 3.231664, norm: 0.2732, time(ms): 789.37, token/sec:664188.72, hellaswag_acc: 0.2882
Step:  9238, loss: 3.203487, norm: 0.2666, time(ms): 791.05, token/sec:662772.23, hellaswag_acc: 0.2882
Step:  9239, loss: 3.234575, norm: 0.2875, time(ms): 790.50, token/sec:663238.59, hellaswag_acc: 0.2882
Step:  9240, loss: 3.226871, norm: 0.2702, time(ms): 792.84, token/sec:661275.65, hellaswag_acc: 0.2882
Step:  9241, loss: 3.248987, norm: 0.2689, time(ms): 791.42, token/sec:662465.55, hellaswag_acc: 0.2882
Step:  9242, loss: 3.240505, norm: 0.2665, time(ms): 799.42, token/sec:655839.10, hellaswag_acc: 0.2882
Step:  9243, loss: 3.209560, norm: 0.2601, time(ms): 800.60, token/sec:654869.39, hellaswag_acc: 0.2882
Step:  9244, loss: 3.203058, norm: 0.2768, time(ms): 804.32, token/sec:651836.51, hellaswag_acc: 0.2882
Step:  9245, loss: 3.178608, norm: 0.2574, time(ms): 790.74, token/sec:663031.62, hellaswag_acc: 0.2882
Step:  9246, loss: 3.206423, norm: 0.2576, time(ms): 792.40, token/sec:661649.71, hellaswag_acc: 0.2882
Step:  9247, loss: 3.195463, norm: 0.2547, time(ms): 793.44, token/sec:660775.91, hellaswag_acc: 0.2882
Step:  9248, loss: 3.124816, norm: 0.2691, time(ms): 802.31, token/sec:653473.88, hellaswag_acc: 0.2882
Step:  9249, loss: 3.186062, norm: 0.2745, time(ms): 797.85, token/sec:657129.45, hellaswag_acc: 0.2882
rank 0 sample 0: Hello, I'm a language model, and I know that you want people to find language for your language that does a good job of it? If you can
rank 0 sample 1: Hello, I'm a language model, so to speak, a language is going to use variables instead of functions to do things, whereas I believe the words of
rank 0 sample 2: Hello, I'm a language model, so I're able to find a thing that the real world isn't that good. I'm not a language model.
rank 0 sample 3: Hello, I'm a language model, a set of language models that have been designed by the language model's designer to communicate, with a minimum of the words
rank 1 sample 0: Hello, I'm a language model, with an assumption that everything we've touched in one day (if you're speaking a different language than you) is true
rank 1 sample 1: Hello, I'm a language model, not an anthropologist. I'm a paleontologist to the paleontology of Australia, not an anthropologist.
rank 1 sample 2: Hello, I'm a language model, I did the following:
- I'm a language model! (It's a language model.)
- We are
rank 1 sample 3: Hello, I'm a language model, not a language modeling expert:
In reality, when all three speakers (people, organizations, and the public) are
Step:  9250, loss: 3.181119, norm: 0.2811, time(ms): 3788.66, token/sec:138383.56, val_loss: 3.2067, hellaswag_acc: 0.2882
Step:  9251, loss: 3.141320, norm: 0.2793, time(ms): 778.69, token/sec:673290.68, hellaswag_acc: 0.2882
Step:  9252, loss: 3.215434, norm: 0.3055, time(ms): 783.00, token/sec:669585.10, hellaswag_acc: 0.2882
Step:  9253, loss: 3.140964, norm: 0.2893, time(ms): 792.10, token/sec:661893.48, hellaswag_acc: 0.2882
Step:  9254, loss: 3.178818, norm: 0.3169, time(ms): 788.34, token/sec:665049.25, hellaswag_acc: 0.2882
Step:  9255, loss: 3.200918, norm: 0.2696, time(ms): 791.58, token/sec:662332.06, hellaswag_acc: 0.2882
Step:  9256, loss: 3.156550, norm: 0.2708, time(ms): 793.21, token/sec:660971.94, hellaswag_acc: 0.2882
Step:  9257, loss: 3.142926, norm: 0.2500, time(ms): 801.27, token/sec:654317.36, hellaswag_acc: 0.2882
Step:  9258, loss: 3.170942, norm: 0.2660, time(ms): 804.08, token/sec:652037.90, hellaswag_acc: 0.2882
Step:  9259, loss: 3.231089, norm: 0.2813, time(ms): 791.68, token/sec:662250.08, hellaswag_acc: 0.2882
Step:  9260, loss: 3.231611, norm: 0.2866, time(ms): 798.20, token/sec:656840.33, hellaswag_acc: 0.2882
Step:  9261, loss: 3.183910, norm: 0.2929, time(ms): 799.36, token/sec:655885.66, hellaswag_acc: 0.2882
Step:  9262, loss: 3.221485, norm: 0.3153, time(ms): 791.71, token/sec:662218.57, hellaswag_acc: 0.2882
Step:  9263, loss: 3.188909, norm: 0.2801, time(ms): 792.91, token/sec:661221.37, hellaswag_acc: 0.2882
Step:  9264, loss: 3.187154, norm: 0.2949, time(ms): 793.76, token/sec:660510.55, hellaswag_acc: 0.2882
Step:  9265, loss: 3.173225, norm: 0.3472, time(ms): 789.41, token/sec:664154.42, hellaswag_acc: 0.2882
Step:  9266, loss: 3.246275, norm: 0.3055, time(ms): 786.47, token/sec:666632.69, hellaswag_acc: 0.2882
Step:  9267, loss: 3.204675, norm: 0.2872, time(ms): 788.63, token/sec:664806.98, hellaswag_acc: 0.2882
Step:  9268, loss: 3.214290, norm: 0.3029, time(ms): 793.98, token/sec:660327.88, hellaswag_acc: 0.2882
Step:  9269, loss: 3.207798, norm: 0.2760, time(ms): 791.76, token/sec:662178.69, hellaswag_acc: 0.2882
Step:  9270, loss: 3.161353, norm: 0.3016, time(ms): 788.38, token/sec:665015.46, hellaswag_acc: 0.2882
Step:  9271, loss: 3.273255, norm: 0.3155, time(ms): 788.60, token/sec:664831.10, hellaswag_acc: 0.2882
Step:  9272, loss: 3.200049, norm: 0.2798, time(ms): 793.90, token/sec:660392.53, hellaswag_acc: 0.2882
Step:  9273, loss: 3.208220, norm: 0.2708, time(ms): 798.74, token/sec:656397.22, hellaswag_acc: 0.2882
Step:  9274, loss: 3.141137, norm: 0.2774, time(ms): 792.02, token/sec:661966.40, hellaswag_acc: 0.2882
Step:  9275, loss: 3.227666, norm: 0.2667, time(ms): 784.12, token/sec:668629.03, hellaswag_acc: 0.2882
Step:  9276, loss: 3.204391, norm: 0.2941, time(ms): 787.47, token/sec:665791.44, hellaswag_acc: 0.2882
Step:  9277, loss: 3.219727, norm: 0.2428, time(ms): 793.24, token/sec:660944.33, hellaswag_acc: 0.2882
Step:  9278, loss: 3.164030, norm: 0.2729, time(ms): 792.16, token/sec:661843.27, hellaswag_acc: 0.2882
Step:  9279, loss: 3.161525, norm: 0.2967, time(ms): 783.82, token/sec:668884.07, hellaswag_acc: 0.2882
Step:  9280, loss: 3.113339, norm: 0.3006, time(ms): 787.99, token/sec:665344.44, hellaswag_acc: 0.2882
Step:  9281, loss: 3.145431, norm: 0.2801, time(ms): 797.26, token/sec:657616.22, hellaswag_acc: 0.2882
Step:  9282, loss: 3.159980, norm: 0.2991, time(ms): 791.41, token/sec:662473.53, hellaswag_acc: 0.2882
Step:  9283, loss: 3.183547, norm: 0.2718, time(ms): 798.82, token/sec:656332.18, hellaswag_acc: 0.2882
Step:  9284, loss: 3.215142, norm: 0.2880, time(ms): 789.63, token/sec:663969.53, hellaswag_acc: 0.2882
Step:  9285, loss: 3.143240, norm: 0.2826, time(ms): 791.39, token/sec:662490.50, hellaswag_acc: 0.2882
Step:  9286, loss: 3.157370, norm: 0.2699, time(ms): 795.84, token/sec:658781.92, hellaswag_acc: 0.2882
Step:  9287, loss: 3.126831, norm: 0.2667, time(ms): 795.11, token/sec:659391.13, hellaswag_acc: 0.2882
Step:  9288, loss: 3.186557, norm: 0.2641, time(ms): 797.45, token/sec:657453.62, hellaswag_acc: 0.2882
Step:  9289, loss: 3.154775, norm: 0.2743, time(ms): 787.74, token/sec:665563.54, hellaswag_acc: 0.2882
Step:  9290, loss: 3.183603, norm: 0.2397, time(ms): 789.47, token/sec:664097.46, hellaswag_acc: 0.2882
Step:  9291, loss: 3.122931, norm: 0.2489, time(ms): 788.22, token/sec:665153.45, hellaswag_acc: 0.2882
Step:  9292, loss: 3.181340, norm: 0.2454, time(ms): 798.22, token/sec:656821.49, hellaswag_acc: 0.2882
Step:  9293, loss: 3.158007, norm: 0.2542, time(ms): 802.85, token/sec:653034.92, hellaswag_acc: 0.2882
Step:  9294, loss: 3.239688, norm: 0.2679, time(ms): 802.36, token/sec:653435.82, hellaswag_acc: 0.2882
Step:  9295, loss: 3.212056, norm: 0.2645, time(ms): 799.30, token/sec:655936.13, hellaswag_acc: 0.2882
Step:  9296, loss: 3.247749, norm: 0.3049, time(ms): 795.18, token/sec:659334.19, hellaswag_acc: 0.2882
Step:  9297, loss: 3.247811, norm: 0.3013, time(ms): 798.50, token/sec:656592.04, hellaswag_acc: 0.2882
Step:  9298, loss: 3.208522, norm: 0.3063, time(ms): 797.30, token/sec:657577.08, hellaswag_acc: 0.2882
Step:  9299, loss: 3.172708, norm: 0.3148, time(ms): 791.59, token/sec:662324.68, hellaswag_acc: 0.2882
Step:  9300, loss: 3.196185, norm: 0.3116, time(ms): 785.52, token/sec:667444.05, hellaswag_acc: 0.2882
Step:  9301, loss: 3.189617, norm: 0.2897, time(ms): 788.44, token/sec:664964.59, hellaswag_acc: 0.2882
Step:  9302, loss: 3.249288, norm: 0.2996, time(ms): 797.69, token/sec:657261.83, hellaswag_acc: 0.2882
Step:  9303, loss: 3.337723, norm: 0.3198, time(ms): 802.80, token/sec:653071.57, hellaswag_acc: 0.2882
Step:  9304, loss: 3.259667, norm: 0.2957, time(ms): 795.42, token/sec:659130.44, hellaswag_acc: 0.2882
Step:  9305, loss: 3.199826, norm: 0.2995, time(ms): 797.81, token/sec:657154.98, hellaswag_acc: 0.2882
Step:  9306, loss: 3.205311, norm: 0.3020, time(ms): 802.97, token/sec:652939.71, hellaswag_acc: 0.2882
Step:  9307, loss: 3.199308, norm: 0.2816, time(ms): 795.77, token/sec:658846.65, hellaswag_acc: 0.2882
Step:  9308, loss: 3.152675, norm: 0.2724, time(ms): 791.23, token/sec:662620.65, hellaswag_acc: 0.2882
Step:  9309, loss: 3.167065, norm: 0.2845, time(ms): 792.08, token/sec:661916.39, hellaswag_acc: 0.2882
Step:  9310, loss: 3.169776, norm: 0.2703, time(ms): 799.60, token/sec:655689.89, hellaswag_acc: 0.2882
Step:  9311, loss: 3.151395, norm: 0.3307, time(ms): 801.32, token/sec:654278.23, hellaswag_acc: 0.2882
Step:  9312, loss: 3.179823, norm: 0.3568, time(ms): 798.97, token/sec:656201.74, hellaswag_acc: 0.2882
Step:  9313, loss: 3.163530, norm: 0.2879, time(ms): 796.08, token/sec:658586.98, hellaswag_acc: 0.2882
Step:  9314, loss: 3.180037, norm: 0.3111, time(ms): 790.01, token/sec:663650.12, hellaswag_acc: 0.2882
Step:  9315, loss: 3.221205, norm: 0.3094, time(ms): 787.96, token/sec:665371.62, hellaswag_acc: 0.2882
Step:  9316, loss: 3.172408, norm: 0.2932, time(ms): 791.39, token/sec:662490.30, hellaswag_acc: 0.2882
Step:  9317, loss: 3.154961, norm: 0.3096, time(ms): 795.22, token/sec:659301.77, hellaswag_acc: 0.2882
Step:  9318, loss: 3.173235, norm: 0.2946, time(ms): 797.14, token/sec:657710.82, hellaswag_acc: 0.2882
Step:  9319, loss: 3.128378, norm: 0.3043, time(ms): 805.59, token/sec:650809.63, hellaswag_acc: 0.2882
Step:  9320, loss: 3.121404, norm: 0.2742, time(ms): 798.82, token/sec:656326.50, hellaswag_acc: 0.2882
Step:  9321, loss: 3.190101, norm: 0.2768, time(ms): 796.47, token/sec:658261.30, hellaswag_acc: 0.2882
Step:  9322, loss: 3.132899, norm: 0.2566, time(ms): 802.92, token/sec:652976.55, hellaswag_acc: 0.2882
Step:  9323, loss: 3.129659, norm: 0.2500, time(ms): 800.35, token/sec:655075.20, hellaswag_acc: 0.2882
Step:  9324, loss: 3.163426, norm: 0.2736, time(ms): 799.38, token/sec:655872.35, hellaswag_acc: 0.2882
Step:  9325, loss: 3.134818, norm: 0.2610, time(ms): 798.90, token/sec:656260.89, hellaswag_acc: 0.2882
Step:  9326, loss: 3.171906, norm: 0.2639, time(ms): 799.08, token/sec:656111.09, hellaswag_acc: 0.2882
Step:  9327, loss: 3.181843, norm: 0.2558, time(ms): 803.39, token/sec:652596.74, hellaswag_acc: 0.2882
Step:  9328, loss: 3.192282, norm: 0.2722, time(ms): 796.78, token/sec:658011.74, hellaswag_acc: 0.2882
Step:  9329, loss: 3.220072, norm: 0.2656, time(ms): 791.86, token/sec:662095.75, hellaswag_acc: 0.2882
Step:  9330, loss: 3.219281, norm: 0.2723, time(ms): 789.23, token/sec:664301.49, hellaswag_acc: 0.2882
Step:  9331, loss: 3.207760, norm: 0.2617, time(ms): 793.15, token/sec:661023.80, hellaswag_acc: 0.2882
Step:  9332, loss: 3.269529, norm: 0.2673, time(ms): 790.57, token/sec:663176.98, hellaswag_acc: 0.2882
Step:  9333, loss: 3.235978, norm: 0.2489, time(ms): 789.54, token/sec:664039.50, hellaswag_acc: 0.2882
Step:  9334, loss: 3.124444, norm: 0.2781, time(ms): 1246.52, token/sec:420600.05, hellaswag_acc: 0.2882
Step:  9335, loss: 3.043241, norm: 0.2680, time(ms): 790.35, token/sec:663359.23, hellaswag_acc: 0.2882
Step:  9336, loss: 2.999990, norm: 0.2855, time(ms): 786.03, token/sec:667005.96, hellaswag_acc: 0.2882
Step:  9337, loss: 3.042363, norm: 0.3211, time(ms): 786.84, token/sec:666316.97, hellaswag_acc: 0.2882
Step:  9338, loss: 3.073723, norm: 0.2548, time(ms): 789.82, token/sec:663808.18, hellaswag_acc: 0.2882
Step:  9339, loss: 2.966604, norm: 0.2786, time(ms): 805.87, token/sec:650589.36, hellaswag_acc: 0.2882
Step:  9340, loss: 3.178308, norm: 0.2880, time(ms): 790.44, token/sec:663286.20, hellaswag_acc: 0.2882
Step:  9341, loss: 3.317403, norm: 0.2865, time(ms): 788.78, token/sec:664682.59, hellaswag_acc: 0.2882
Step:  9342, loss: 3.237955, norm: 0.2660, time(ms): 796.02, token/sec:658636.30, hellaswag_acc: 0.2882
Step:  9343, loss: 3.286894, norm: 0.2979, time(ms): 802.67, token/sec:653178.07, hellaswag_acc: 0.2882
Step:  9344, loss: 3.220838, norm: 0.2805, time(ms): 800.17, token/sec:655218.27, hellaswag_acc: 0.2882
Step:  9345, loss: 3.184214, norm: 0.2845, time(ms): 792.98, token/sec:661165.51, hellaswag_acc: 0.2882
Step:  9346, loss: 3.240079, norm: 0.3037, time(ms): 789.49, token/sec:664085.83, hellaswag_acc: 0.2882
Step:  9347, loss: 3.204355, norm: 0.2834, time(ms): 790.21, token/sec:663475.72, hellaswag_acc: 0.2882
Step:  9348, loss: 3.245641, norm: 0.2842, time(ms): 790.98, token/sec:662832.76, hellaswag_acc: 0.2882
Step:  9349, loss: 3.286463, norm: 0.3278, time(ms): 789.07, token/sec:664438.58, hellaswag_acc: 0.2882
Step:  9350, loss: 3.251916, norm: 0.3068, time(ms): 798.50, token/sec:656590.47, hellaswag_acc: 0.2882
Step:  9351, loss: 3.231490, norm: 0.2763, time(ms): 790.98, token/sec:662831.36, hellaswag_acc: 0.2882
Step:  9352, loss: 3.256046, norm: 0.3093, time(ms): 791.71, token/sec:662223.76, hellaswag_acc: 0.2882
Step:  9353, loss: 3.208722, norm: 0.2971, time(ms): 790.81, token/sec:662973.45, hellaswag_acc: 0.2882
Step:  9354, loss: 3.183990, norm: 0.2802, time(ms): 788.31, token/sec:665077.41, hellaswag_acc: 0.2882
Step:  9355, loss: 3.145145, norm: 0.3021, time(ms): 797.29, token/sec:657589.67, hellaswag_acc: 0.2882
Step:  9356, loss: 3.152653, norm: 0.2605, time(ms): 792.48, token/sec:661581.44, hellaswag_acc: 0.2882
Step:  9357, loss: 3.144689, norm: 0.3109, time(ms): 792.09, token/sec:661908.42, hellaswag_acc: 0.2882
Step:  9358, loss: 3.165331, norm: 0.2800, time(ms): 797.84, token/sec:657136.13, hellaswag_acc: 0.2882
Step:  9359, loss: 3.160498, norm: 0.2781, time(ms): 791.54, token/sec:662363.78, hellaswag_acc: 0.2882
Step:  9360, loss: 3.208509, norm: 0.2936, time(ms): 786.46, token/sec:666641.38, hellaswag_acc: 0.2882
Step:  9361, loss: 3.243973, norm: 0.2936, time(ms): 788.98, token/sec:664515.48, hellaswag_acc: 0.2882
Step:  9362, loss: 3.188462, norm: 0.2849, time(ms): 792.80, token/sec:661312.64, hellaswag_acc: 0.2882
Step:  9363, loss: 3.239695, norm: 0.3047, time(ms): 806.05, token/sec:650441.18, hellaswag_acc: 0.2882
Step:  9364, loss: 3.185962, norm: 0.2859, time(ms): 801.09, token/sec:654469.26, hellaswag_acc: 0.2882
Step:  9365, loss: 3.155780, norm: 0.2803, time(ms): 792.00, token/sec:661979.95, hellaswag_acc: 0.2882
Step:  9366, loss: 3.201027, norm: 0.2829, time(ms): 806.73, token/sec:649895.25, hellaswag_acc: 0.2882
Step:  9367, loss: 3.158703, norm: 0.2912, time(ms): 798.98, token/sec:656198.41, hellaswag_acc: 0.2882
Step:  9368, loss: 3.218754, norm: 0.2865, time(ms): 802.97, token/sec:652932.15, hellaswag_acc: 0.2882
Step:  9369, loss: 3.174899, norm: 0.2954, time(ms): 788.76, token/sec:664700.87, hellaswag_acc: 0.2882
Step:  9370, loss: 3.159117, norm: 0.3018, time(ms): 799.17, token/sec:656044.54, hellaswag_acc: 0.2882
Step:  9371, loss: 3.143503, norm: 0.2832, time(ms): 789.84, token/sec:663787.94, hellaswag_acc: 0.2882
Step:  9372, loss: 3.255433, norm: 0.3181, time(ms): 788.64, token/sec:664796.73, hellaswag_acc: 0.2882
Step:  9373, loss: 3.181641, norm: 0.2988, time(ms): 792.01, token/sec:661967.80, hellaswag_acc: 0.2882
Step:  9374, loss: 3.176587, norm: 0.2859, time(ms): 796.37, token/sec:658345.85, hellaswag_acc: 0.2882
Step:  9375, loss: 3.061639, norm: 0.3106, time(ms): 798.68, token/sec:656444.25, hellaswag_acc: 0.2882
Step:  9376, loss: 3.027187, norm: 0.2997, time(ms): 800.86, token/sec:654655.72, hellaswag_acc: 0.2882
Step:  9377, loss: 3.027005, norm: 0.3390, time(ms): 801.70, token/sec:653974.30, hellaswag_acc: 0.2882
Step:  9378, loss: 3.005203, norm: 0.3268, time(ms): 794.28, token/sec:660081.51, hellaswag_acc: 0.2882
Step:  9379, loss: 3.042572, norm: 0.2847, time(ms): 801.10, token/sec:654464.00, hellaswag_acc: 0.2882
Step:  9380, loss: 3.034366, norm: 0.2934, time(ms): 802.27, token/sec:653504.37, hellaswag_acc: 0.2882
Step:  9381, loss: 2.979656, norm: 0.2730, time(ms): 793.72, token/sec:660546.66, hellaswag_acc: 0.2882
Step:  9382, loss: 3.059768, norm: 0.2708, time(ms): 791.61, token/sec:662302.34, hellaswag_acc: 0.2882
Step:  9383, loss: 3.050074, norm: 0.2756, time(ms): 790.89, token/sec:662909.09, hellaswag_acc: 0.2882
Step:  9384, loss: 3.039736, norm: 0.2569, time(ms): 794.13, token/sec:660205.96, hellaswag_acc: 0.2882
Step:  9385, loss: 2.971749, norm: 0.2617, time(ms): 791.31, token/sec:662558.36, hellaswag_acc: 0.2882
Step:  9386, loss: 3.021038, norm: 0.2713, time(ms): 791.09, token/sec:662743.67, hellaswag_acc: 0.2882
Step:  9387, loss: 3.263711, norm: 0.3067, time(ms): 790.41, token/sec:663311.81, hellaswag_acc: 0.2882
Step:  9388, loss: 3.232468, norm: 0.2931, time(ms): 795.01, token/sec:659473.00, hellaswag_acc: 0.2882
Step:  9389, loss: 3.192525, norm: 0.2720, time(ms): 800.96, token/sec:654571.73, hellaswag_acc: 0.2882
Step:  9390, loss: 3.198249, norm: 0.2682, time(ms): 803.73, token/sec:652319.52, hellaswag_acc: 0.2882
Step:  9391, loss: 3.247032, norm: 0.2805, time(ms): 797.41, token/sec:657490.97, hellaswag_acc: 0.2882
Step:  9392, loss: 3.254746, norm: 0.2842, time(ms): 792.96, token/sec:661176.24, hellaswag_acc: 0.2882
Step:  9393, loss: 3.204147, norm: 0.2788, time(ms): 803.02, token/sec:652892.61, hellaswag_acc: 0.2882
Step:  9394, loss: 3.249330, norm: 0.3134, time(ms): 804.60, token/sec:651612.07, hellaswag_acc: 0.2882
Step:  9395, loss: 3.172794, norm: 0.3514, time(ms): 796.31, token/sec:658395.91, hellaswag_acc: 0.2882
Step:  9396, loss: 3.202080, norm: 0.2602, time(ms): 802.85, token/sec:653034.53, hellaswag_acc: 0.2882
Step:  9397, loss: 3.215562, norm: 0.3146, time(ms): 800.37, token/sec:655054.32, hellaswag_acc: 0.2882
Step:  9398, loss: 3.139664, norm: 0.2848, time(ms): 794.88, token/sec:659577.44, hellaswag_acc: 0.2882
Step:  9399, loss: 3.175229, norm: 0.2774, time(ms): 803.84, token/sec:652228.78, hellaswag_acc: 0.2882
Step:  9400, loss: 3.120977, norm: 0.2764, time(ms): 800.00, token/sec:655363.75, hellaswag_acc: 0.2882
Step:  9401, loss: 3.181231, norm: 0.2622, time(ms): 799.42, token/sec:655836.36, hellaswag_acc: 0.2882
Step:  9402, loss: 3.177778, norm: 0.2623, time(ms): 800.72, token/sec:654767.22, hellaswag_acc: 0.2882
Step:  9403, loss: 3.180200, norm: 0.2566, time(ms): 792.53, token/sec:661533.47, hellaswag_acc: 0.2882
Step:  9404, loss: 3.167197, norm: 0.2796, time(ms): 806.59, token/sec:650002.06, hellaswag_acc: 0.2882
Step:  9405, loss: 3.185844, norm: 0.2662, time(ms): 799.82, token/sec:655504.99, hellaswag_acc: 0.2882
Step:  9406, loss: 3.237892, norm: 0.2582, time(ms): 796.90, token/sec:657911.73, hellaswag_acc: 0.2882
Step:  9407, loss: 3.201432, norm: 0.2683, time(ms): 796.23, token/sec:658466.10, hellaswag_acc: 0.2882
Step:  9408, loss: 3.221528, norm: 0.2733, time(ms): 806.53, token/sec:650052.21, hellaswag_acc: 0.2882
Step:  9409, loss: 3.218756, norm: 0.2683, time(ms): 801.23, token/sec:654356.50, hellaswag_acc: 0.2882
Step:  9410, loss: 3.116612, norm: 0.2573, time(ms): 790.34, token/sec:663366.84, hellaswag_acc: 0.2882
Step:  9411, loss: 3.183868, norm: 0.3133, time(ms): 800.42, token/sec:655016.66, hellaswag_acc: 0.2882
Step:  9412, loss: 3.157078, norm: 0.2816, time(ms): 797.86, token/sec:657116.88, hellaswag_acc: 0.2882
Step:  9413, loss: 3.159667, norm: 0.2784, time(ms): 790.84, token/sec:662949.26, hellaswag_acc: 0.2882
Step:  9414, loss: 3.164674, norm: 0.3065, time(ms): 786.62, token/sec:666507.01, hellaswag_acc: 0.2882
Step:  9415, loss: 3.261225, norm: 0.2977, time(ms): 790.28, token/sec:663418.47, hellaswag_acc: 0.2882
Step:  9416, loss: 3.130064, norm: 0.2825, time(ms): 796.34, token/sec:658368.32, hellaswag_acc: 0.2882
Step:  9417, loss: 3.187870, norm: 0.2845, time(ms): 800.71, token/sec:654782.23, hellaswag_acc: 0.2882
Step:  9418, loss: 3.155087, norm: 0.2549, time(ms): 798.81, token/sec:656333.36, hellaswag_acc: 0.2882
Step:  9419, loss: 3.168425, norm: 0.2729, time(ms): 797.65, token/sec:657293.26, hellaswag_acc: 0.2882
Step:  9420, loss: 3.176688, norm: 0.2649, time(ms): 798.21, token/sec:656832.68, hellaswag_acc: 0.2882
Step:  9421, loss: 3.155101, norm: 0.2592, time(ms): 793.34, token/sec:660863.69, hellaswag_acc: 0.2882
Step:  9422, loss: 3.044693, norm: 0.2802, time(ms): 793.76, token/sec:660510.16, hellaswag_acc: 0.2882
Step:  9423, loss: 3.053438, norm: 0.3065, time(ms): 787.62, token/sec:665661.05, hellaswag_acc: 0.2882
Step:  9424, loss: 3.058234, norm: 0.2852, time(ms): 788.39, token/sec:665012.65, hellaswag_acc: 0.2882
Step:  9425, loss: 2.987478, norm: 0.2930, time(ms): 796.52, token/sec:658224.06, hellaswag_acc: 0.2882
Step:  9426, loss: 3.053163, norm: 0.3118, time(ms): 791.50, token/sec:662395.31, hellaswag_acc: 0.2882
Step:  9427, loss: 3.035381, norm: 0.2835, time(ms): 787.78, token/sec:665523.05, hellaswag_acc: 0.2882
Step:  9428, loss: 3.035706, norm: 0.2618, time(ms): 788.03, token/sec:665312.43, hellaswag_acc: 0.2882
Step:  9429, loss: 3.043155, norm: 0.2918, time(ms): 794.50, token/sec:659897.49, hellaswag_acc: 0.2882
Step:  9430, loss: 3.062583, norm: 0.2933, time(ms): 791.40, token/sec:662485.31, hellaswag_acc: 0.2882
Step:  9431, loss: 3.041476, norm: 0.2772, time(ms): 793.70, token/sec:660564.72, hellaswag_acc: 0.2882
Step:  9432, loss: 3.013297, norm: 0.2761, time(ms): 796.22, token/sec:658467.67, hellaswag_acc: 0.2882
Step:  9433, loss: 3.019561, norm: 0.3048, time(ms): 801.61, token/sec:654044.13, hellaswag_acc: 0.2882
Step:  9434, loss: 3.175860, norm: 0.2867, time(ms): 802.44, token/sec:653370.98, hellaswag_acc: 0.2882
Step:  9435, loss: 3.255939, norm: 0.2931, time(ms): 796.23, token/sec:658466.89, hellaswag_acc: 0.2882
Step:  9436, loss: 3.294023, norm: 0.3432, time(ms): 795.03, token/sec:659457.77, hellaswag_acc: 0.2882
Step:  9437, loss: 3.225749, norm: 0.3142, time(ms): 804.19, token/sec:651943.18, hellaswag_acc: 0.2882
Step:  9438, loss: 3.198848, norm: 0.3310, time(ms): 800.86, token/sec:654656.50, hellaswag_acc: 0.2882
Step:  9439, loss: 3.190856, norm: 0.3232, time(ms): 793.84, token/sec:660448.07, hellaswag_acc: 0.2882
Step:  9440, loss: 3.224013, norm: 0.3389, time(ms): 791.00, token/sec:662815.78, hellaswag_acc: 0.2882
Step:  9441, loss: 3.212100, norm: 0.3067, time(ms): 794.11, token/sec:660221.62, hellaswag_acc: 0.2882
Step:  9442, loss: 3.226517, norm: 0.3080, time(ms): 793.67, token/sec:660584.96, hellaswag_acc: 0.2882
Step:  9443, loss: 3.246523, norm: 0.3084, time(ms): 789.26, token/sec:664276.40, hellaswag_acc: 0.2882
Step:  9444, loss: 3.232723, norm: 0.2799, time(ms): 787.81, token/sec:665503.92, hellaswag_acc: 0.2882
Step:  9445, loss: 3.202651, norm: 0.2820, time(ms): 793.42, token/sec:660791.20, hellaswag_acc: 0.2882
Step:  9446, loss: 3.238922, norm: 0.2556, time(ms): 793.43, token/sec:660786.24, hellaswag_acc: 0.2882
Step:  9447, loss: 3.169009, norm: 0.2625, time(ms): 793.47, token/sec:660754.87, hellaswag_acc: 0.2882
Step:  9448, loss: 3.235837, norm: 0.2572, time(ms): 789.63, token/sec:663965.32, hellaswag_acc: 0.2882
Step:  9449, loss: 3.212311, norm: 0.2898, time(ms): 789.39, token/sec:664172.07, hellaswag_acc: 0.2882
Step:  9450, loss: 3.267931, norm: 0.2745, time(ms): 793.47, token/sec:660754.67, hellaswag_acc: 0.2882
Step:  9451, loss: 3.199170, norm: 0.3404, time(ms): 789.55, token/sec:664038.10, hellaswag_acc: 0.2882
Step:  9452, loss: 3.195105, norm: 0.2998, time(ms): 798.74, token/sec:656390.96, hellaswag_acc: 0.2882
Step:  9453, loss: 3.244941, norm: 0.2821, time(ms): 790.85, token/sec:662940.67, hellaswag_acc: 0.2882
Step:  9454, loss: 3.197446, norm: 0.2707, time(ms): 795.33, token/sec:659204.93, hellaswag_acc: 0.2882
Step:  9455, loss: 3.158096, norm: 0.2710, time(ms): 790.10, token/sec:663573.82, hellaswag_acc: 0.2882
Step:  9456, loss: 3.211115, norm: 0.2817, time(ms): 788.54, token/sec:664885.37, hellaswag_acc: 0.2882
Step:  9457, loss: 3.187867, norm: 0.2647, time(ms): 789.23, token/sec:664300.28, hellaswag_acc: 0.2882
Step:  9458, loss: 3.174258, norm: 0.2854, time(ms): 794.01, token/sec:660307.26, hellaswag_acc: 0.2882
Step:  9459, loss: 3.163848, norm: 0.2555, time(ms): 792.46, token/sec:661591.98, hellaswag_acc: 0.2882
Step:  9460, loss: 3.162939, norm: 0.2739, time(ms): 804.24, token/sec:651902.01, hellaswag_acc: 0.2882
Step:  9461, loss: 3.234155, norm: 0.2520, time(ms): 803.77, token/sec:652287.60, hellaswag_acc: 0.2882
Step:  9462, loss: 3.148292, norm: 0.2485, time(ms): 801.05, token/sec:654504.91, hellaswag_acc: 0.2882
Step:  9463, loss: 3.176744, norm: 0.2668, time(ms): 794.34, token/sec:660027.82, hellaswag_acc: 0.2882
Step:  9464, loss: 3.152766, norm: 0.2630, time(ms): 799.68, token/sec:655623.62, hellaswag_acc: 0.2882
Step:  9465, loss: 3.142731, norm: 0.2499, time(ms): 801.67, token/sec:653996.28, hellaswag_acc: 0.2882
Step:  9466, loss: 3.118557, norm: 0.2631, time(ms): 802.92, token/sec:652973.84, hellaswag_acc: 0.2882
Step:  9467, loss: 3.143375, norm: 0.2650, time(ms): 795.78, token/sec:658838.36, hellaswag_acc: 0.2882
Step:  9468, loss: 3.127989, norm: 0.2554, time(ms): 797.38, token/sec:657511.81, hellaswag_acc: 0.2882
Step:  9469, loss: 3.045766, norm: 0.2825, time(ms): 804.91, token/sec:651361.92, hellaswag_acc: 0.2882
Step:  9470, loss: 3.040217, norm: 0.2689, time(ms): 800.71, token/sec:654774.82, hellaswag_acc: 0.2882
Step:  9471, loss: 3.052820, norm: 0.2676, time(ms): 794.90, token/sec:659563.19, hellaswag_acc: 0.2882
Step:  9472, loss: 3.035704, norm: 0.3145, time(ms): 802.01, token/sec:653716.90, hellaswag_acc: 0.2882
Step:  9473, loss: 2.986914, norm: 0.2966, time(ms): 804.57, token/sec:651635.62, hellaswag_acc: 0.2882
Step:  9474, loss: 3.021731, norm: 0.2736, time(ms): 798.95, token/sec:656224.07, hellaswag_acc: 0.2882
Step:  9475, loss: 3.077535, norm: 0.2957, time(ms): 786.60, token/sec:666520.75, hellaswag_acc: 0.2882
Step:  9476, loss: 3.046668, norm: 0.2838, time(ms): 790.93, token/sec:662877.52, hellaswag_acc: 0.2882
Step:  9477, loss: 3.022200, norm: 0.2881, time(ms): 796.48, token/sec:658259.92, hellaswag_acc: 0.2882
Step:  9478, loss: 2.984992, norm: 0.2648, time(ms): 794.21, token/sec:660136.79, hellaswag_acc: 0.2882
Step:  9479, loss: 3.047494, norm: 0.2929, time(ms): 790.54, token/sec:663200.58, hellaswag_acc: 0.2882
Step:  9480, loss: 2.989924, norm: 0.2900, time(ms): 797.66, token/sec:657284.03, hellaswag_acc: 0.2882
Step:  9481, loss: 3.225411, norm: 0.2857, time(ms): 796.87, token/sec:657934.76, hellaswag_acc: 0.2882
Step:  9482, loss: 3.177248, norm: 0.3563, time(ms): 802.41, token/sec:653391.17, hellaswag_acc: 0.2882
Step:  9483, loss: 3.248535, norm: 0.3277, time(ms): 797.43, token/sec:657472.69, hellaswag_acc: 0.2882
Step:  9484, loss: 3.233725, norm: 0.2981, time(ms): 796.16, token/sec:658517.76, hellaswag_acc: 0.2882
Step:  9485, loss: 3.160462, norm: 0.2972, time(ms): 798.23, token/sec:656816.20, hellaswag_acc: 0.2882
Step:  9486, loss: 3.224506, norm: 0.3710, time(ms): 792.22, token/sec:661793.68, hellaswag_acc: 0.2882
Step:  9487, loss: 3.210663, norm: 0.3097, time(ms): 790.46, token/sec:663268.60, hellaswag_acc: 0.2882
Step:  9488, loss: 3.208611, norm: 0.2902, time(ms): 787.88, token/sec:665438.67, hellaswag_acc: 0.2882
Step:  9489, loss: 3.239845, norm: 0.3003, time(ms): 789.27, token/sec:664272.19, hellaswag_acc: 0.2882
Step:  9490, loss: 3.244038, norm: 0.2869, time(ms): 789.25, token/sec:664283.63, hellaswag_acc: 0.2882
Step:  9491, loss: 3.200142, norm: 0.2847, time(ms): 796.88, token/sec:657929.45, hellaswag_acc: 0.2882
Step:  9492, loss: 3.197302, norm: 0.2630, time(ms): 795.84, token/sec:658782.70, hellaswag_acc: 0.2882
Step:  9493, loss: 3.231467, norm: 0.2909, time(ms): 806.29, token/sec:650250.00, hellaswag_acc: 0.2882
Step:  9494, loss: 3.166826, norm: 0.2845, time(ms): 799.99, token/sec:655365.12, hellaswag_acc: 0.2882
Step:  9495, loss: 3.228246, norm: 0.2757, time(ms): 791.57, token/sec:662342.44, hellaswag_acc: 0.2882
Step:  9496, loss: 3.245675, norm: 0.2733, time(ms): 797.69, token/sec:657259.67, hellaswag_acc: 0.2882
Step:  9497, loss: 3.223354, norm: 0.2843, time(ms): 791.15, token/sec:662688.94, hellaswag_acc: 0.2882
Step:  9498, loss: 3.150194, norm: 0.2845, time(ms): 788.37, token/sec:665026.12, hellaswag_acc: 0.2882
Step:  9499, loss: 3.230077, norm: 0.2938, time(ms): 790.26, token/sec:663436.48, hellaswag_acc: 0.2882
rank 0 sample 0: Hello, I'm a language model, and I'll be the first. You, guys, how can we possibly work together to tackle that. If you are
rank 0 sample 1: Hello, I'm a language model, so now I'm a language model if you wanna create language model of program in a Java program, if you wanna create
rank 0 sample 2: Hello, I'm a language model, I'm currently at the level of being a learner, a beginner, a native speaker, a native speaker.

rank 0 sample 3: Hello, I'm a language model, so please add my name. I'd love to hear from you.
I haven't noticed it all yet but in
rank 1 sample 0: Hello, I'm a language model, with lots of examples, but I must be an experienced beginner:
- the language, and what it means.

rank 1 sample 1: Hello, I'm a language model, not an interpreter. I'm going to start with a definition of the language I want to parse in the first place.
rank 1 sample 2: Hello, I'm a language model, so after the class, I'm going to ask you some things about what makes a language work so well, you can
rank 1 sample 3: Hello, I'm a language model, and I'm an interpreter-only one"
As he started making up text, both kids began to build an interpreter
Step:  9500, loss: 3.206317, norm: 0.2541, time(ms): 3807.09, token/sec:137713.44, val_loss: 3.2013, hellaswag_acc: 0.2882
Step:  9501, loss: 3.172503, norm: 0.2900, time(ms): 786.28, token/sec:666797.84, hellaswag_acc: 0.2882
Step:  9502, loss: 3.264672, norm: 0.2575, time(ms): 791.11, token/sec:662727.89, hellaswag_acc: 0.2882
Step:  9503, loss: 3.219299, norm: 0.2745, time(ms): 794.32, token/sec:660048.22, hellaswag_acc: 0.2882
Step:  9504, loss: 3.215267, norm: 0.2783, time(ms): 799.17, token/sec:656038.67, hellaswag_acc: 0.2882
Step:  9505, loss: 3.155833, norm: 0.2704, time(ms): 797.52, token/sec:657398.39, hellaswag_acc: 0.2882
Step:  9506, loss: 3.119743, norm: 0.2543, time(ms): 795.21, token/sec:659307.90, hellaswag_acc: 0.2882
Step:  9507, loss: 3.218275, norm: 0.2806, time(ms): 793.67, token/sec:660586.75, hellaswag_acc: 0.2882
Step:  9508, loss: 3.218147, norm: 0.2981, time(ms): 785.66, token/sec:667319.49, hellaswag_acc: 0.2882
Step:  9509, loss: 3.197310, norm: 0.2713, time(ms): 793.79, token/sec:660489.72, hellaswag_acc: 0.2882
Step:  9510, loss: 3.182525, norm: 0.2918, time(ms): 794.11, token/sec:660221.62, hellaswag_acc: 0.2882
Step:  9511, loss: 3.192472, norm: 0.2690, time(ms): 790.63, token/sec:663126.79, hellaswag_acc: 0.2882
Step:  9512, loss: 3.110636, norm: 0.2695, time(ms): 792.34, token/sec:661698.29, hellaswag_acc: 0.2882
Step:  9513, loss: 3.143226, norm: 0.2657, time(ms): 790.45, token/sec:663277.20, hellaswag_acc: 0.2882
Step:  9514, loss: 3.171163, norm: 0.2636, time(ms): 792.06, token/sec:661933.52, hellaswag_acc: 0.2882
Step:  9515, loss: 3.132032, norm: 0.2860, time(ms): 795.39, token/sec:659159.48, hellaswag_acc: 0.2882
Step:  9516, loss: 3.091777, norm: 0.2391, time(ms): 791.08, token/sec:662752.26, hellaswag_acc: 0.2882
Step:  9517, loss: 3.046532, norm: 0.2798, time(ms): 791.47, token/sec:662420.85, hellaswag_acc: 0.2882
Step:  9518, loss: 3.055489, norm: 0.3126, time(ms): 795.92, token/sec:658717.39, hellaswag_acc: 0.2882
Step:  9519, loss: 2.970918, norm: 0.3206, time(ms): 789.99, token/sec:663663.14, hellaswag_acc: 0.2882
Step:  9520, loss: 3.040669, norm: 0.3236, time(ms): 789.10, token/sec:664415.89, hellaswag_acc: 0.2882
Step:  9521, loss: 2.985066, norm: 0.2697, time(ms): 786.98, token/sec:666204.94, hellaswag_acc: 0.2882
Step:  9522, loss: 3.025878, norm: 0.2956, time(ms): 791.64, token/sec:662278.80, hellaswag_acc: 0.2882
Step:  9523, loss: 3.038152, norm: 0.3331, time(ms): 798.77, token/sec:656372.93, hellaswag_acc: 0.2882
Step:  9524, loss: 3.030626, norm: 0.3110, time(ms): 1314.41, token/sec:398876.85, hellaswag_acc: 0.2882
Step:  9525, loss: 3.161865, norm: 0.2880, time(ms): 763.43, token/sec:686754.39, hellaswag_acc: 0.2882
Step:  9526, loss: 3.100208, norm: 0.2607, time(ms): 791.03, token/sec:662788.41, hellaswag_acc: 0.2882
Step:  9527, loss: 3.139899, norm: 0.2804, time(ms): 797.65, token/sec:657288.94, hellaswag_acc: 0.2882
Step:  9528, loss: 3.128692, norm: 0.2625, time(ms): 787.31, token/sec:665926.13, hellaswag_acc: 0.2882
Step:  9529, loss: 3.154332, norm: 0.2546, time(ms): 782.31, token/sec:670180.15, hellaswag_acc: 0.2882
Step:  9530, loss: 3.062497, norm: 0.2595, time(ms): 792.66, token/sec:661428.41, hellaswag_acc: 0.2882
Step:  9531, loss: 3.067899, norm: 0.2686, time(ms): 790.34, token/sec:663372.84, hellaswag_acc: 0.2882
Step:  9532, loss: 3.104708, norm: 0.2390, time(ms): 790.52, token/sec:663221.19, hellaswag_acc: 0.2882
Step:  9533, loss: 3.063258, norm: 0.2541, time(ms): 787.53, token/sec:665733.60, hellaswag_acc: 0.2882
Step:  9534, loss: 3.127424, norm: 0.2363, time(ms): 793.13, token/sec:661035.13, hellaswag_acc: 0.2882
Step:  9535, loss: 3.104646, norm: 0.2623, time(ms): 792.13, token/sec:661874.75, hellaswag_acc: 0.2882
Step:  9536, loss: 3.160324, norm: 0.2796, time(ms): 788.13, token/sec:665230.32, hellaswag_acc: 0.2882
Step:  9537, loss: 3.194662, norm: 0.2720, time(ms): 791.29, token/sec:662575.93, hellaswag_acc: 0.2882
Step:  9538, loss: 3.203519, norm: 0.2666, time(ms): 796.67, token/sec:658099.96, hellaswag_acc: 0.2882
Step:  9539, loss: 3.246052, norm: 0.2745, time(ms): 795.53, token/sec:659039.17, hellaswag_acc: 0.2882
Step:  9540, loss: 3.169565, norm: 0.2740, time(ms): 803.23, token/sec:652721.87, hellaswag_acc: 0.2882
Step:  9541, loss: 3.171854, norm: 0.2588, time(ms): 794.79, token/sec:659656.18, hellaswag_acc: 0.2882
Step:  9542, loss: 3.141160, norm: 0.3020, time(ms): 794.74, token/sec:659693.78, hellaswag_acc: 0.2882
Step:  9543, loss: 3.203980, norm: 0.3237, time(ms): 792.63, token/sec:661452.48, hellaswag_acc: 0.2882
Step:  9544, loss: 3.172924, norm: 0.3297, time(ms): 790.44, token/sec:663285.80, hellaswag_acc: 0.2882
Step:  9545, loss: 3.212637, norm: 0.2990, time(ms): 789.07, token/sec:664441.79, hellaswag_acc: 0.2882
Step:  9546, loss: 3.260751, norm: 0.3070, time(ms): 791.79, token/sec:662156.76, hellaswag_acc: 0.2882
Step:  9547, loss: 3.210780, norm: 0.3172, time(ms): 790.29, token/sec:663408.66, hellaswag_acc: 0.2882
Step:  9548, loss: 3.169806, norm: 0.3086, time(ms): 792.40, token/sec:661647.52, hellaswag_acc: 0.2882
Step:  9549, loss: 3.200900, norm: 0.2822, time(ms): 803.11, token/sec:652821.86, hellaswag_acc: 0.2882
Step:  9550, loss: 3.145481, norm: 0.3339, time(ms): 802.50, token/sec:653321.67, hellaswag_acc: 0.2882
Step:  9551, loss: 3.178209, norm: 0.2794, time(ms): 800.80, token/sec:654707.37, hellaswag_acc: 0.2882
Step:  9552, loss: 3.184867, norm: 0.3011, time(ms): 789.80, token/sec:663826.02, hellaswag_acc: 0.2882
Step:  9553, loss: 3.140155, norm: 0.3226, time(ms): 803.98, token/sec:652113.70, hellaswag_acc: 0.2882
Step:  9554, loss: 3.164981, norm: 0.3487, time(ms): 804.93, token/sec:651342.82, hellaswag_acc: 0.2882
Step:  9555, loss: 3.212864, norm: 0.3221, time(ms): 801.03, token/sec:654514.26, hellaswag_acc: 0.2882
Step:  9556, loss: 3.178483, norm: 0.3087, time(ms): 790.04, token/sec:663622.08, hellaswag_acc: 0.2882
Step:  9557, loss: 3.191271, norm: 0.2724, time(ms): 801.03, token/sec:654513.48, hellaswag_acc: 0.2882
Step:  9558, loss: 3.168254, norm: 0.3057, time(ms): 807.35, token/sec:649392.99, hellaswag_acc: 0.2882
Step:  9559, loss: 3.181934, norm: 0.2760, time(ms): 792.10, token/sec:661892.28, hellaswag_acc: 0.2882
Step:  9560, loss: 3.121605, norm: 0.3041, time(ms): 798.44, token/sec:656638.70, hellaswag_acc: 0.2882
Step:  9561, loss: 3.120470, norm: 0.2954, time(ms): 805.89, token/sec:650566.45, hellaswag_acc: 0.2882
Step:  9562, loss: 3.099586, norm: 0.2911, time(ms): 803.13, token/sec:652807.91, hellaswag_acc: 0.2882
Step:  9563, loss: 3.099904, norm: 0.2803, time(ms): 791.59, token/sec:662322.29, hellaswag_acc: 0.2882
Step:  9564, loss: 3.124175, norm: 0.2689, time(ms): 799.04, token/sec:656149.86, hellaswag_acc: 0.2882
Step:  9565, loss: 3.121995, norm: 0.2791, time(ms): 806.71, token/sec:649907.73, hellaswag_acc: 0.2882
Step:  9566, loss: 3.114184, norm: 0.2680, time(ms): 792.06, token/sec:661933.32, hellaswag_acc: 0.2882
Step:  9567, loss: 3.127175, norm: 0.2644, time(ms): 791.11, token/sec:662724.69, hellaswag_acc: 0.2882
Step:  9568, loss: 3.165947, norm: 0.2796, time(ms): 791.06, token/sec:662766.04, hellaswag_acc: 0.2882
Step:  9569, loss: 3.073891, norm: 0.2713, time(ms): 791.65, token/sec:662274.42, hellaswag_acc: 0.2882
Step:  9570, loss: 3.059343, norm: 0.2610, time(ms): 793.45, token/sec:660769.56, hellaswag_acc: 0.2882
Step:  9571, loss: 3.152961, norm: 0.2959, time(ms): 796.29, token/sec:658411.29, hellaswag_acc: 0.2882
Step:  9572, loss: 3.148273, norm: 0.2742, time(ms): 800.11, token/sec:655266.69, hellaswag_acc: 0.2882
Step:  9573, loss: 3.178129, norm: 0.3037, time(ms): 805.52, token/sec:650870.31, hellaswag_acc: 0.2882
Step:  9574, loss: 3.252793, norm: 0.2743, time(ms): 789.70, token/sec:663907.99, hellaswag_acc: 0.2882
Step:  9575, loss: 3.208398, norm: 0.3069, time(ms): 793.73, token/sec:660535.35, hellaswag_acc: 0.2882
Step:  9576, loss: 3.243737, norm: 0.2798, time(ms): 795.28, token/sec:659245.44, hellaswag_acc: 0.2882
Step:  9577, loss: 3.240296, norm: 0.3264, time(ms): 794.22, token/sec:660133.03, hellaswag_acc: 0.2882
Step:  9578, loss: 3.160187, norm: 0.2670, time(ms): 802.49, token/sec:653329.63, hellaswag_acc: 0.2882
Step:  9579, loss: 3.241494, norm: 0.2992, time(ms): 795.44, token/sec:659116.80, hellaswag_acc: 0.2882
Step:  9580, loss: 3.231306, norm: 0.2979, time(ms): 804.01, token/sec:652093.40, hellaswag_acc: 0.2882
Step:  9581, loss: 3.214734, norm: 0.3467, time(ms): 797.40, token/sec:657500.01, hellaswag_acc: 0.2882
Step:  9582, loss: 3.198345, norm: 0.2908, time(ms): 791.38, token/sec:662499.88, hellaswag_acc: 0.2882
Step:  9583, loss: 3.207463, norm: 0.3090, time(ms): 790.16, token/sec:663521.16, hellaswag_acc: 0.2882
Step:  9584, loss: 3.212691, norm: 0.2886, time(ms): 790.12, token/sec:663557.20, hellaswag_acc: 0.2882
Step:  9585, loss: 3.173195, norm: 0.2784, time(ms): 793.45, token/sec:660770.35, hellaswag_acc: 0.2882
Step:  9586, loss: 3.184597, norm: 0.2801, time(ms): 789.76, token/sec:663855.28, hellaswag_acc: 0.2882
Step:  9587, loss: 3.196869, norm: 0.2827, time(ms): 804.43, token/sec:651754.01, hellaswag_acc: 0.2882
Step:  9588, loss: 3.196398, norm: 0.2876, time(ms): 804.25, token/sec:651894.67, hellaswag_acc: 0.2882
Step:  9589, loss: 3.120508, norm: 0.2913, time(ms): 797.23, token/sec:657635.10, hellaswag_acc: 0.2882
Step:  9590, loss: 3.162531, norm: 0.2734, time(ms): 796.69, token/sec:658086.18, hellaswag_acc: 0.2882
Step:  9591, loss: 3.153975, norm: 0.2671, time(ms): 804.27, token/sec:651877.86, hellaswag_acc: 0.2882
Step:  9592, loss: 3.144196, norm: 0.2647, time(ms): 803.75, token/sec:652300.17, hellaswag_acc: 0.2882
Step:  9593, loss: 3.188997, norm: 0.2457, time(ms): 786.04, token/sec:666998.88, hellaswag_acc: 0.2882
Step:  9594, loss: 3.161211, norm: 0.2497, time(ms): 790.01, token/sec:663646.92, hellaswag_acc: 0.2882
Step:  9595, loss: 3.130308, norm: 0.2580, time(ms): 794.95, token/sec:659523.83, hellaswag_acc: 0.2882
Step:  9596, loss: 3.131402, norm: 0.2599, time(ms): 790.82, token/sec:662968.65, hellaswag_acc: 0.2882
Step:  9597, loss: 3.088756, norm: 0.2486, time(ms): 790.04, token/sec:663618.88, hellaswag_acc: 0.2882
Step:  9598, loss: 3.130507, norm: 0.2565, time(ms): 796.03, token/sec:658631.96, hellaswag_acc: 0.2882
Step:  9599, loss: 3.127389, norm: 0.2642, time(ms): 799.73, token/sec:655581.79, hellaswag_acc: 0.2882
Step:  9600, loss: 3.101453, norm: 0.2639, time(ms): 792.38, token/sec:661665.24, hellaswag_acc: 0.2882
Step:  9601, loss: 3.122789, norm: 0.2511, time(ms): 787.96, token/sec:665375.64, hellaswag_acc: 0.2882
Step:  9602, loss: 3.100291, norm: 0.2869, time(ms): 790.44, token/sec:663283.00, hellaswag_acc: 0.2882
Step:  9603, loss: 3.091738, norm: 0.2581, time(ms): 787.16, token/sec:666054.21, hellaswag_acc: 0.2882
Step:  9604, loss: 3.079970, norm: 0.2503, time(ms): 792.14, token/sec:661859.41, hellaswag_acc: 0.2882
Step:  9605, loss: 3.076071, norm: 0.2725, time(ms): 797.91, token/sec:657079.97, hellaswag_acc: 0.2882
Step:  9606, loss: 3.068980, norm: 0.2664, time(ms): 789.76, token/sec:663856.68, hellaswag_acc: 0.2882
Step:  9607, loss: 3.145447, norm: 0.2569, time(ms): 791.36, token/sec:662518.04, hellaswag_acc: 0.2882
Step:  9608, loss: 3.166128, norm: 0.2657, time(ms): 793.25, token/sec:660939.56, hellaswag_acc: 0.2882
Step:  9609, loss: 3.213272, norm: 0.2592, time(ms): 790.38, token/sec:663335.22, hellaswag_acc: 0.2882
Step:  9610, loss: 3.172444, norm: 0.2685, time(ms): 794.58, token/sec:659829.18, hellaswag_acc: 0.2882
Step:  9611, loss: 3.202192, norm: 0.2728, time(ms): 789.95, token/sec:663693.79, hellaswag_acc: 0.2882
Step:  9612, loss: 3.160292, norm: 0.2937, time(ms): 792.22, token/sec:661798.26, hellaswag_acc: 0.2882
Step:  9613, loss: 3.165353, norm: 0.2676, time(ms): 795.24, token/sec:659284.97, hellaswag_acc: 0.2882
Step:  9614, loss: 3.210760, norm: 0.2782, time(ms): 799.09, token/sec:656108.94, hellaswag_acc: 0.2882
Step:  9615, loss: 3.212945, norm: 0.2905, time(ms): 795.29, token/sec:659237.53, hellaswag_acc: 0.2882
Step:  9616, loss: 3.277409, norm: 0.2882, time(ms): 803.05, token/sec:652874.39, hellaswag_acc: 0.2882
Step:  9617, loss: 3.231735, norm: 0.2977, time(ms): 795.09, token/sec:659404.18, hellaswag_acc: 0.2882
Step:  9618, loss: 3.184971, norm: 0.3017, time(ms): 791.69, token/sec:662242.11, hellaswag_acc: 0.2882
Step:  9619, loss: 3.172471, norm: 0.3179, time(ms): 785.43, token/sec:667521.25, hellaswag_acc: 0.2882
Step:  9620, loss: 3.228492, norm: 0.2686, time(ms): 792.43, token/sec:661624.43, hellaswag_acc: 0.2882
Step:  9621, loss: 3.163538, norm: 0.3028, time(ms): 794.40, token/sec:659983.05, hellaswag_acc: 0.2882
Step:  9622, loss: 3.241713, norm: 0.3021, time(ms): 803.19, token/sec:652759.66, hellaswag_acc: 0.2882
Step:  9623, loss: 3.176824, norm: 0.3097, time(ms): 793.91, token/sec:660386.18, hellaswag_acc: 0.2882
Step:  9624, loss: 3.175159, norm: 0.2950, time(ms): 808.09, token/sec:648801.72, hellaswag_acc: 0.2882
Step:  9625, loss: 3.217723, norm: 0.3111, time(ms): 795.76, token/sec:658854.75, hellaswag_acc: 0.2882
Step:  9626, loss: 3.174458, norm: 0.2949, time(ms): 798.12, token/sec:656901.35, hellaswag_acc: 0.2882
Step:  9627, loss: 3.237544, norm: 0.3145, time(ms): 803.75, token/sec:652304.62, hellaswag_acc: 0.2882
Step:  9628, loss: 3.203275, norm: 0.3235, time(ms): 800.23, token/sec:655171.23, hellaswag_acc: 0.2882
Step:  9629, loss: 3.196656, norm: 0.2825, time(ms): 800.12, token/sec:655259.66, hellaswag_acc: 0.2882
Step:  9630, loss: 3.112024, norm: 0.2714, time(ms): 800.64, token/sec:654838.77, hellaswag_acc: 0.2882
Step:  9631, loss: 3.147070, norm: 0.2624, time(ms): 797.87, token/sec:657109.23, hellaswag_acc: 0.2882
Step:  9632, loss: 3.109519, norm: 0.2672, time(ms): 790.56, token/sec:663182.78, hellaswag_acc: 0.2882
Step:  9633, loss: 3.157367, norm: 0.2656, time(ms): 791.42, token/sec:662464.95, hellaswag_acc: 0.2882
Step:  9634, loss: 3.130152, norm: 0.2739, time(ms): 790.05, token/sec:663616.67, hellaswag_acc: 0.2882
Step:  9635, loss: 3.112897, norm: 0.2725, time(ms): 791.42, token/sec:662464.55, hellaswag_acc: 0.2882
Step:  9636, loss: 3.072631, norm: 0.2644, time(ms): 788.84, token/sec:664633.97, hellaswag_acc: 0.2882
Step:  9637, loss: 3.094477, norm: 0.2522, time(ms): 799.04, token/sec:656149.27, hellaswag_acc: 0.2882
Step:  9638, loss: 3.159604, norm: 0.2833, time(ms): 792.71, token/sec:661388.82, hellaswag_acc: 0.2882
Step:  9639, loss: 3.101672, norm: 0.2570, time(ms): 797.48, token/sec:657434.36, hellaswag_acc: 0.2882
Step:  9640, loss: 3.105901, norm: 0.2466, time(ms): 783.48, token/sec:669180.02, hellaswag_acc: 0.2882
Step:  9641, loss: 3.110903, norm: 0.2772, time(ms): 787.54, token/sec:665727.55, hellaswag_acc: 0.2882
Step:  9642, loss: 3.145575, norm: 0.2670, time(ms): 793.61, token/sec:660637.35, hellaswag_acc: 0.2882
Step:  9643, loss: 3.173954, norm: 0.2736, time(ms): 791.92, token/sec:662048.11, hellaswag_acc: 0.2882
Step:  9644, loss: 3.199018, norm: 0.3006, time(ms): 789.57, token/sec:664015.04, hellaswag_acc: 0.2882
Step:  9645, loss: 3.389157, norm: 0.3166, time(ms): 789.51, token/sec:664067.98, hellaswag_acc: 0.2882
Step:  9646, loss: 3.207877, norm: 0.2912, time(ms): 792.15, token/sec:661853.23, hellaswag_acc: 0.2882
Step:  9647, loss: 3.247217, norm: 0.2808, time(ms): 790.31, token/sec:663397.26, hellaswag_acc: 0.2882
Step:  9648, loss: 3.191367, norm: 0.2836, time(ms): 791.14, token/sec:662701.73, hellaswag_acc: 0.2882
Step:  9649, loss: 3.188606, norm: 0.2824, time(ms): 804.68, token/sec:651547.58, hellaswag_acc: 0.2882
Step:  9650, loss: 3.168120, norm: 0.3023, time(ms): 801.51, token/sec:654123.90, hellaswag_acc: 0.2882
Step:  9651, loss: 3.198423, norm: 0.2548, time(ms): 792.73, token/sec:661371.52, hellaswag_acc: 0.2882
Step:  9652, loss: 3.231205, norm: 0.2689, time(ms): 792.09, token/sec:661906.62, hellaswag_acc: 0.2882
Step:  9653, loss: 3.238065, norm: 0.3152, time(ms): 794.63, token/sec:659786.61, hellaswag_acc: 0.2882
Step:  9654, loss: 3.188155, norm: 0.2920, time(ms): 796.95, token/sec:657871.58, hellaswag_acc: 0.2882
Step:  9655, loss: 3.138496, norm: 0.2710, time(ms): 797.99, token/sec:657007.73, hellaswag_acc: 0.2882
Step:  9656, loss: 3.258130, norm: 0.2874, time(ms): 798.37, token/sec:656694.78, hellaswag_acc: 0.2882
Step:  9657, loss: 3.160184, norm: 0.2892, time(ms): 798.35, token/sec:656717.34, hellaswag_acc: 0.2882
Step:  9658, loss: 3.160171, norm: 0.2737, time(ms): 790.81, token/sec:662975.65, hellaswag_acc: 0.2882
Step:  9659, loss: 3.133066, norm: 0.2889, time(ms): 788.71, token/sec:664742.27, hellaswag_acc: 0.2882
Step:  9660, loss: 3.175530, norm: 0.2529, time(ms): 789.43, token/sec:664132.36, hellaswag_acc: 0.2882
Step:  9661, loss: 3.164375, norm: 0.2816, time(ms): 796.40, token/sec:658322.79, hellaswag_acc: 0.2882
Step:  9662, loss: 3.207170, norm: 0.2770, time(ms): 801.49, token/sec:654140.63, hellaswag_acc: 0.2882
Step:  9663, loss: 3.185606, norm: 0.2766, time(ms): 800.06, token/sec:655309.26, hellaswag_acc: 0.2882
Step:  9664, loss: 3.184397, norm: 0.2555, time(ms): 801.31, token/sec:654288.94, hellaswag_acc: 0.2882
Step:  9665, loss: 3.105926, norm: 0.2611, time(ms): 794.09, token/sec:660239.86, hellaswag_acc: 0.2882
Step:  9666, loss: 3.074222, norm: 0.2768, time(ms): 806.88, token/sec:649772.54, hellaswag_acc: 0.2882
Step:  9667, loss: 3.070082, norm: 0.2441, time(ms): 798.38, token/sec:656687.92, hellaswag_acc: 0.2882
Step:  9668, loss: 3.083319, norm: 0.2842, time(ms): 796.76, token/sec:658028.67, hellaswag_acc: 0.2882
Step:  9669, loss: 3.046702, norm: 0.2497, time(ms): 800.98, token/sec:654561.99, hellaswag_acc: 0.2882
Step:  9670, loss: 3.090895, norm: 0.2560, time(ms): 802.48, token/sec:653332.93, hellaswag_acc: 0.2882
Step:  9671, loss: 3.077201, norm: 0.2558, time(ms): 796.34, token/sec:658374.03, hellaswag_acc: 0.2882
Step:  9672, loss: 3.119327, norm: 0.2637, time(ms): 801.33, token/sec:654272.98, hellaswag_acc: 0.2882
Step:  9673, loss: 3.089756, norm: 0.2417, time(ms): 799.74, token/sec:655577.10, hellaswag_acc: 0.2882
Step:  9674, loss: 3.055573, norm: 0.2726, time(ms): 801.47, token/sec:654161.65, hellaswag_acc: 0.2882
Step:  9675, loss: 3.015629, norm: 0.2642, time(ms): 800.22, token/sec:655180.60, hellaswag_acc: 0.2882
Step:  9676, loss: 3.075596, norm: 0.2491, time(ms): 787.52, token/sec:665743.88, hellaswag_acc: 0.2882
Step:  9677, loss: 3.161445, norm: 0.2685, time(ms): 791.35, token/sec:662519.44, hellaswag_acc: 0.2882
Step:  9678, loss: 3.199056, norm: 0.2716, time(ms): 787.69, token/sec:665598.99, hellaswag_acc: 0.2882
Step:  9679, loss: 3.195763, norm: 0.2833, time(ms): 792.44, token/sec:661610.89, hellaswag_acc: 0.2882
Step:  9680, loss: 3.126403, norm: 0.2761, time(ms): 797.44, token/sec:657463.25, hellaswag_acc: 0.2882
Step:  9681, loss: 3.192543, norm: 0.2818, time(ms): 801.44, token/sec:654186.17, hellaswag_acc: 0.2882
Step:  9682, loss: 3.157605, norm: 0.2886, time(ms): 797.60, token/sec:657329.61, hellaswag_acc: 0.2882
Step:  9683, loss: 3.208317, norm: 0.3072, time(ms): 796.07, token/sec:658591.72, hellaswag_acc: 0.2882
Step:  9684, loss: 3.147945, norm: 0.2976, time(ms): 801.37, token/sec:654241.25, hellaswag_acc: 0.2882
Step:  9685, loss: 3.221208, norm: 0.2930, time(ms): 802.36, token/sec:653429.61, hellaswag_acc: 0.2882
Step:  9686, loss: 3.224633, norm: 0.3056, time(ms): 794.09, token/sec:660241.24, hellaswag_acc: 0.2882
Step:  9687, loss: 3.199524, norm: 0.2997, time(ms): 797.42, token/sec:657477.01, hellaswag_acc: 0.2882
Step:  9688, loss: 3.109002, norm: 0.2896, time(ms): 792.45, token/sec:661602.34, hellaswag_acc: 0.2882
Step:  9689, loss: 3.201586, norm: 0.2930, time(ms): 793.81, token/sec:660469.49, hellaswag_acc: 0.2882
Step:  9690, loss: 3.151496, norm: 0.2881, time(ms): 793.10, token/sec:661062.95, hellaswag_acc: 0.2882
Step:  9691, loss: 3.163162, norm: 0.2939, time(ms): 789.04, token/sec:664463.47, hellaswag_acc: 0.2882
Step:  9692, loss: 3.202119, norm: 0.2933, time(ms): 791.07, token/sec:662761.65, hellaswag_acc: 0.2882
Step:  9693, loss: 3.112821, norm: 0.3328, time(ms): 790.89, token/sec:662912.29, hellaswag_acc: 0.2882
Step:  9694, loss: 3.159737, norm: 0.2597, time(ms): 797.92, token/sec:657067.60, hellaswag_acc: 0.2882
Step:  9695, loss: 3.164890, norm: 0.2922, time(ms): 790.90, token/sec:662900.50, hellaswag_acc: 0.2882
Step:  9696, loss: 3.198382, norm: 0.2923, time(ms): 791.80, token/sec:662143.60, hellaswag_acc: 0.2882
Step:  9697, loss: 3.125622, norm: 0.2694, time(ms): 788.40, token/sec:665000.18, hellaswag_acc: 0.2882
Step:  9698, loss: 3.193147, norm: 0.3232, time(ms): 791.36, token/sec:662518.44, hellaswag_acc: 0.2882
Step:  9699, loss: 3.202130, norm: 0.2743, time(ms): 792.85, token/sec:661267.70, hellaswag_acc: 0.2882
Step:  9700, loss: 3.074803, norm: 0.2724, time(ms): 798.25, token/sec:656796.78, hellaswag_acc: 0.2882
Step:  9701, loss: 3.113550, norm: 0.2393, time(ms): 801.98, token/sec:653742.36, hellaswag_acc: 0.2882
Step:  9702, loss: 3.115611, norm: 0.2742, time(ms): 806.00, token/sec:650482.16, hellaswag_acc: 0.2882
Step:  9703, loss: 3.027919, norm: 0.2695, time(ms): 789.68, token/sec:663924.22, hellaswag_acc: 0.2882
Step:  9704, loss: 3.028536, norm: 0.2570, time(ms): 793.92, token/sec:660376.86, hellaswag_acc: 0.2882
Step:  9705, loss: 3.089103, norm: 0.2793, time(ms): 794.36, token/sec:660014.15, hellaswag_acc: 0.2882
Step:  9706, loss: 3.068384, norm: 0.2541, time(ms): 793.89, token/sec:660405.42, hellaswag_acc: 0.2882
Step:  9707, loss: 3.173272, norm: 0.2618, time(ms): 797.21, token/sec:657654.37, hellaswag_acc: 0.2882
Step:  9708, loss: 3.084832, norm: 0.2664, time(ms): 789.62, token/sec:663974.74, hellaswag_acc: 0.2882
Step:  9709, loss: 3.118859, norm: 0.2578, time(ms): 789.14, token/sec:664377.55, hellaswag_acc: 0.2882
Step:  9710, loss: 3.093229, norm: 0.2690, time(ms): 791.39, token/sec:662493.09, hellaswag_acc: 0.2882
Step:  9711, loss: 3.135212, norm: 0.2773, time(ms): 795.37, token/sec:659178.25, hellaswag_acc: 0.2882
Step:  9712, loss: 3.222148, norm: 0.2912, time(ms): 795.71, token/sec:658896.40, hellaswag_acc: 0.2882
Step:  9713, loss: 3.154263, norm: 0.2712, time(ms): 805.53, token/sec:650857.78, hellaswag_acc: 0.2882
Step:  9714, loss: 3.138353, norm: 0.2936, time(ms): 787.28, token/sec:665949.92, hellaswag_acc: 0.2882
Step:  9715, loss: 3.154264, norm: 0.2835, time(ms): 1291.28, token/sec:406021.92, hellaswag_acc: 0.2882
Step:  9716, loss: 3.201711, norm: 0.3065, time(ms): 795.36, token/sec:659181.21, hellaswag_acc: 0.2882
Step:  9717, loss: 3.269975, norm: 0.3298, time(ms): 793.88, token/sec:660414.54, hellaswag_acc: 0.2882
Step:  9718, loss: 3.239287, norm: 0.3149, time(ms): 784.71, token/sec:668129.08, hellaswag_acc: 0.2882
Step:  9719, loss: 3.228715, norm: 0.3005, time(ms): 795.66, token/sec:658931.74, hellaswag_acc: 0.2882
Step:  9720, loss: 3.191898, norm: 0.3270, time(ms): 799.92, token/sec:655423.33, hellaswag_acc: 0.2882
Step:  9721, loss: 3.204926, norm: 0.2994, time(ms): 792.30, token/sec:661729.35, hellaswag_acc: 0.2882
Step:  9722, loss: 3.300992, norm: 0.3061, time(ms): 785.43, token/sec:667514.16, hellaswag_acc: 0.2882
Step:  9723, loss: 3.189570, norm: 0.2818, time(ms): 784.51, token/sec:668301.47, hellaswag_acc: 0.2882
Step:  9724, loss: 3.148213, norm: 0.2960, time(ms): 790.15, token/sec:663531.57, hellaswag_acc: 0.2882
Step:  9725, loss: 3.196728, norm: 0.2928, time(ms): 796.06, token/sec:658601.78, hellaswag_acc: 0.2882
Step:  9726, loss: 3.119141, norm: 0.2924, time(ms): 787.99, token/sec:665352.29, hellaswag_acc: 0.2882
Step:  9727, loss: 3.214367, norm: 0.3337, time(ms): 787.70, token/sec:665590.73, hellaswag_acc: 0.2882
Step:  9728, loss: 3.207322, norm: 0.2762, time(ms): 791.59, token/sec:662322.49, hellaswag_acc: 0.2882
Step:  9729, loss: 3.209112, norm: 0.3041, time(ms): 793.49, token/sec:660739.58, hellaswag_acc: 0.2882
Step:  9730, loss: 3.219045, norm: 0.2725, time(ms): 786.18, token/sec:666883.38, hellaswag_acc: 0.2882
Step:  9731, loss: 3.216417, norm: 0.2863, time(ms): 793.19, token/sec:660984.66, hellaswag_acc: 0.2882
Step:  9732, loss: 3.174172, norm: 0.2787, time(ms): 801.07, token/sec:654487.57, hellaswag_acc: 0.2882
Step:  9733, loss: 3.171007, norm: 0.2920, time(ms): 790.78, token/sec:662999.83, hellaswag_acc: 0.2882
Step:  9734, loss: 3.165820, norm: 0.2781, time(ms): 788.13, token/sec:665229.71, hellaswag_acc: 0.2882
Step:  9735, loss: 3.109094, norm: 0.2738, time(ms): 791.13, token/sec:662704.92, hellaswag_acc: 0.2882
Step:  9736, loss: 3.184795, norm: 0.2815, time(ms): 790.43, token/sec:663297.41, hellaswag_acc: 0.2882
Step:  9737, loss: 3.152707, norm: 0.2712, time(ms): 795.57, token/sec:659005.60, hellaswag_acc: 0.2882
Step:  9738, loss: 3.221125, norm: 0.2844, time(ms): 795.20, token/sec:659314.03, hellaswag_acc: 0.2882
Step:  9739, loss: 3.122135, norm: 0.2720, time(ms): 806.40, token/sec:650157.72, hellaswag_acc: 0.2882
Step:  9740, loss: 3.185972, norm: 0.2745, time(ms): 802.22, token/sec:653545.16, hellaswag_acc: 0.2882
Step:  9741, loss: 3.149146, norm: 0.3028, time(ms): 792.03, token/sec:661955.04, hellaswag_acc: 0.2882
Step:  9742, loss: 3.289218, norm: 0.3205, time(ms): 804.95, token/sec:651332.60, hellaswag_acc: 0.2882
Step:  9743, loss: 3.143467, norm: 0.3111, time(ms): 801.86, token/sec:653837.41, hellaswag_acc: 0.2882
Step:  9744, loss: 3.198042, norm: 0.3263, time(ms): 796.62, token/sec:658142.11, hellaswag_acc: 0.2882
Step:  9745, loss: 3.059094, norm: 0.3212, time(ms): 794.63, token/sec:659786.61, hellaswag_acc: 0.2882
Step:  9746, loss: 3.025960, norm: 0.2795, time(ms): 806.58, token/sec:650012.82, hellaswag_acc: 0.2882
Step:  9747, loss: 3.120844, norm: 0.2971, time(ms): 800.98, token/sec:654561.21, hellaswag_acc: 0.2882
Step:  9748, loss: 3.035410, norm: 0.2782, time(ms): 789.65, token/sec:663947.88, hellaswag_acc: 0.2882
Step:  9749, loss: 3.034449, norm: 0.2860, time(ms): 791.08, token/sec:662747.86, hellaswag_acc: 0.2882
rank 0 sample 0: Hello, I'm a language model, and I'll be able to read that back," he says. This shows him that language is very powerful, and it
rank 0 sample 1: Hello, I'm a language model, so to speak, you're just adding a few code files. The ones we need, those that look like this:
rank 0 sample 2: Hello, I'm a language model, I'm talking to English students. The language in question is "native English" and it's not a native speaker of
rank 0 sample 3: Hello, I'm a language model, which isn't my first language, but it probably works for me. The first place to start is here. The idea
rank 1 sample 0: Hello, I'm a language model,
a teacher, a leader, any other one who needs all the tools that I can. The
solution is
rank 1 sample 1: Hello, I'm a language model, not an interpreter. I'm a professional English speaker, even if I'm not an educated speaker, I'm not a
rank 1 sample 2: Hello, I'm a language model, so whenever I talk to a person, I'm often thinking if he is "in the same spot, that would mean
rank 1 sample 3: Hello, I'm a language model, and I'm really excited about this idea – it's being considered around the home. Why people don't use it?
Step:  9750, loss: 3.086007, norm: 0.2807, time(ms): 3785.85, token/sec:138486.23, val_loss: 3.2013, hellaswag_acc: 0.2882
Step:  9751, loss: 3.008216, norm: 0.2902, time(ms): 791.50, token/sec:662398.70, hellaswag_acc: 0.2882
Step:  9752, loss: 3.019766, norm: 0.2901, time(ms): 791.66, token/sec:662260.25, hellaswag_acc: 0.2882
Step:  9753, loss: 2.953346, norm: 0.2746, time(ms): 804.25, token/sec:651895.25, hellaswag_acc: 0.2882
Step:  9754, loss: 2.997677, norm: 0.2851, time(ms): 795.75, token/sec:658860.08, hellaswag_acc: 0.2882
Step:  9755, loss: 3.042332, norm: 0.2641, time(ms): 792.26, token/sec:661760.22, hellaswag_acc: 0.2882
Step:  9756, loss: 3.189494, norm: 0.3361, time(ms): 786.48, token/sec:666627.03, hellaswag_acc: 0.2882
Step:  9757, loss: 3.224867, norm: 0.4233, time(ms): 786.40, token/sec:666691.10, hellaswag_acc: 0.2882
Step:  9758, loss: 3.238337, norm: 0.3187, time(ms): 791.18, token/sec:662667.98, hellaswag_acc: 0.2882
Step:  9759, loss: 3.247701, norm: 0.3572, time(ms): 793.59, token/sec:660650.85, hellaswag_acc: 0.2882
Step:  9760, loss: 3.336358, norm: 0.4849, time(ms): 788.46, token/sec:664953.93, hellaswag_acc: 0.2882
Step:  9761, loss: 3.244388, norm: 0.3629, time(ms): 788.33, token/sec:665060.31, hellaswag_acc: 0.2882
Step:  9762, loss: 3.230233, norm: 0.3402, time(ms): 792.20, token/sec:661810.01, hellaswag_acc: 0.2882
Step:  9763, loss: 3.177773, norm: 0.3206, time(ms): 793.15, token/sec:661018.83, hellaswag_acc: 0.2882
Step:  9764, loss: 3.243707, norm: 0.3332, time(ms): 792.36, token/sec:661682.56, hellaswag_acc: 0.2882
Step:  9765, loss: 3.150947, norm: 0.3486, time(ms): 793.05, token/sec:661099.72, hellaswag_acc: 0.2882
Step:  9766, loss: 3.256785, norm: 0.3143, time(ms): 793.38, token/sec:660830.12, hellaswag_acc: 0.2882
Step:  9767, loss: 3.211732, norm: 0.3124, time(ms): 795.65, token/sec:658945.76, hellaswag_acc: 0.2882
Step:  9768, loss: 3.206753, norm: 0.2975, time(ms): 794.25, token/sec:660102.31, hellaswag_acc: 0.2882
Step:  9769, loss: 3.199776, norm: 0.2902, time(ms): 795.42, token/sec:659131.62, hellaswag_acc: 0.2882
Step:  9770, loss: 3.139816, norm: 0.3061, time(ms): 790.22, token/sec:663475.12, hellaswag_acc: 0.2882
Step:  9771, loss: 3.166643, norm: 0.2743, time(ms): 790.47, token/sec:663261.19, hellaswag_acc: 0.2882
Step:  9772, loss: 3.208808, norm: 0.2839, time(ms): 791.37, token/sec:662508.66, hellaswag_acc: 0.2882
Step:  9773, loss: 3.216249, norm: 0.3057, time(ms): 791.64, token/sec:662283.99, hellaswag_acc: 0.2882
Step:  9774, loss: 3.274751, norm: 0.2874, time(ms): 802.82, token/sec:653055.09, hellaswag_acc: 0.2882
Step:  9775, loss: 3.131321, norm: 0.2722, time(ms): 804.12, token/sec:652001.56, hellaswag_acc: 0.2882
Step:  9776, loss: 3.196945, norm: 0.2806, time(ms): 791.36, token/sec:662511.45, hellaswag_acc: 0.2882
Step:  9777, loss: 3.292468, norm: 0.2806, time(ms): 798.16, token/sec:656870.15, hellaswag_acc: 0.2882
Step:  9778, loss: 3.182569, norm: 0.2925, time(ms): 803.44, token/sec:652551.04, hellaswag_acc: 0.2882
Step:  9779, loss: 3.173507, norm: 0.2764, time(ms): 797.34, token/sec:657547.59, hellaswag_acc: 0.2882
Step:  9780, loss: 3.218205, norm: 0.2684, time(ms): 792.96, token/sec:661181.01, hellaswag_acc: 0.2882
Step:  9781, loss: 3.148783, norm: 0.2829, time(ms): 787.77, token/sec:665535.74, hellaswag_acc: 0.2882
Step:  9782, loss: 3.120054, norm: 0.2564, time(ms): 791.10, token/sec:662735.68, hellaswag_acc: 0.2882
Step:  9783, loss: 3.159699, norm: 0.2691, time(ms): 794.58, token/sec:659826.41, hellaswag_acc: 0.2882
Step:  9784, loss: 3.187529, norm: 0.2555, time(ms): 793.09, token/sec:661070.70, hellaswag_acc: 0.2882
Step:  9785, loss: 3.192437, norm: 0.2510, time(ms): 805.04, token/sec:651254.09, hellaswag_acc: 0.2882
Step:  9786, loss: 3.114091, norm: 0.2452, time(ms): 801.31, token/sec:654285.63, hellaswag_acc: 0.2882
Step:  9787, loss: 3.151883, norm: 0.2405, time(ms): 793.85, token/sec:660438.74, hellaswag_acc: 0.2882
Step:  9788, loss: 3.142025, norm: 0.2460, time(ms): 799.23, token/sec:655987.98, hellaswag_acc: 0.2882
Step:  9789, loss: 3.175054, norm: 0.2520, time(ms): 798.94, token/sec:656228.77, hellaswag_acc: 0.2882
Step:  9790, loss: 3.164135, norm: 0.2307, time(ms): 793.30, token/sec:660894.47, hellaswag_acc: 0.2882
Step:  9791, loss: 3.080434, norm: 0.2336, time(ms): 788.18, token/sec:665191.28, hellaswag_acc: 0.2882
Step:  9792, loss: 3.077262, norm: 0.2509, time(ms): 789.44, token/sec:664127.74, hellaswag_acc: 0.2882
Step:  9793, loss: 2.996243, norm: 0.2752, time(ms): 789.22, token/sec:664313.53, hellaswag_acc: 0.2882
Step:  9794, loss: 2.992414, norm: 0.2572, time(ms): 791.04, token/sec:662786.41, hellaswag_acc: 0.2882
Step:  9795, loss: 3.012363, norm: 0.2661, time(ms): 794.23, token/sec:660117.77, hellaswag_acc: 0.2882
Step:  9796, loss: 2.995020, norm: 0.2813, time(ms): 796.46, token/sec:658273.32, hellaswag_acc: 0.2882
Step:  9797, loss: 2.947921, norm: 0.2776, time(ms): 805.50, token/sec:650887.64, hellaswag_acc: 0.2882
Step:  9798, loss: 3.010133, norm: 0.2850, time(ms): 800.84, token/sec:654672.09, hellaswag_acc: 0.2882
Step:  9799, loss: 3.034519, norm: 0.2781, time(ms): 794.24, token/sec:660110.63, hellaswag_acc: 0.2882
Step:  9800, loss: 3.073542, norm: 0.2691, time(ms): 803.52, token/sec:652489.27, hellaswag_acc: 0.2882
Step:  9801, loss: 2.998695, norm: 0.2745, time(ms): 799.40, token/sec:655852.99, hellaswag_acc: 0.2882
Step:  9802, loss: 2.975791, norm: 0.2802, time(ms): 801.47, token/sec:654155.81, hellaswag_acc: 0.2882
Step:  9803, loss: 3.099281, norm: 0.2743, time(ms): 787.79, token/sec:665514.39, hellaswag_acc: 0.2882
Step:  9804, loss: 3.238977, norm: 0.2733, time(ms): 790.29, token/sec:663415.87, hellaswag_acc: 0.2882
Step:  9805, loss: 3.205307, norm: 0.2812, time(ms): 791.11, token/sec:662721.30, hellaswag_acc: 0.2882
Step:  9806, loss: 3.342794, norm: 0.3160, time(ms): 791.47, token/sec:662421.25, hellaswag_acc: 0.2882
Step:  9807, loss: 3.333821, norm: 0.3571, time(ms): 789.03, token/sec:664474.92, hellaswag_acc: 0.2882
Step:  9808, loss: 3.256330, norm: 0.4260, time(ms): 798.61, token/sec:656501.48, hellaswag_acc: 0.2882
Step:  9809, loss: 3.239538, norm: 0.3598, time(ms): 793.22, token/sec:660962.01, hellaswag_acc: 0.2882
Step:  9810, loss: 3.146900, norm: 0.3360, time(ms): 794.45, token/sec:659935.91, hellaswag_acc: 0.2882
Step:  9811, loss: 3.208091, norm: 0.3495, time(ms): 796.45, token/sec:658281.01, hellaswag_acc: 0.2882
Step:  9812, loss: 3.240117, norm: 0.3092, time(ms): 801.75, token/sec:653927.44, hellaswag_acc: 0.2882
Step:  9813, loss: 3.212068, norm: 0.3322, time(ms): 800.88, token/sec:654642.66, hellaswag_acc: 0.2882
Step:  9814, loss: 3.187829, norm: 0.2914, time(ms): 792.40, token/sec:661643.14, hellaswag_acc: 0.2882
Step:  9815, loss: 3.201562, norm: 0.3062, time(ms): 790.66, token/sec:663104.59, hellaswag_acc: 0.2882
Step:  9816, loss: 3.206470, norm: 0.3038, time(ms): 789.04, token/sec:664465.28, hellaswag_acc: 0.2882
Step:  9817, loss: 3.228072, norm: 0.3119, time(ms): 791.37, token/sec:662507.86, hellaswag_acc: 0.2882
Step:  9818, loss: 3.163154, norm: 0.2773, time(ms): 796.21, token/sec:658480.69, hellaswag_acc: 0.2882
Step:  9819, loss: 3.175395, norm: 0.2884, time(ms): 794.85, token/sec:659609.49, hellaswag_acc: 0.2882
Step:  9820, loss: 3.205191, norm: 0.2784, time(ms): 805.06, token/sec:651239.62, hellaswag_acc: 0.2882
Step:  9821, loss: 3.220976, norm: 0.2749, time(ms): 803.49, token/sec:652509.60, hellaswag_acc: 0.2882
Step:  9822, loss: 3.172727, norm: 0.2870, time(ms): 789.56, token/sec:664029.28, hellaswag_acc: 0.2882
Step:  9823, loss: 3.182287, norm: 0.2835, time(ms): 803.70, token/sec:652346.23, hellaswag_acc: 0.2882
Step:  9824, loss: 3.187860, norm: 0.2771, time(ms): 806.43, token/sec:650131.00, hellaswag_acc: 0.2882
Step:  9825, loss: 3.195919, norm: 0.2576, time(ms): 790.90, token/sec:662898.90, hellaswag_acc: 0.2882
Step:  9826, loss: 3.207670, norm: 0.2598, time(ms): 798.36, token/sec:656708.71, hellaswag_acc: 0.2882
Step:  9827, loss: 3.160578, norm: 0.2481, time(ms): 808.10, token/sec:648789.28, hellaswag_acc: 0.2882
Step:  9828, loss: 3.227439, norm: 0.3041, time(ms): 799.31, token/sec:655927.72, hellaswag_acc: 0.2882
Step:  9829, loss: 3.152473, norm: 0.2958, time(ms): 800.06, token/sec:655313.75, hellaswag_acc: 0.2882
Step:  9830, loss: 3.163476, norm: 0.2895, time(ms): 794.09, token/sec:660234.50, hellaswag_acc: 0.2882
Step:  9831, loss: 3.163285, norm: 0.3005, time(ms): 804.87, token/sec:651398.00, hellaswag_acc: 0.2882
Step:  9832, loss: 3.180053, norm: 0.2989, time(ms): 796.67, token/sec:658097.60, hellaswag_acc: 0.2882
Step:  9833, loss: 3.152780, norm: 0.2959, time(ms): 805.17, token/sec:651154.77, hellaswag_acc: 0.2882
Step:  9834, loss: 3.144805, norm: 0.2557, time(ms): 790.36, token/sec:663352.43, hellaswag_acc: 0.2882
Step:  9835, loss: 3.123475, norm: 0.2977, time(ms): 803.98, token/sec:652116.60, hellaswag_acc: 0.2882
Step:  9836, loss: 3.193361, norm: 0.2546, time(ms): 803.93, token/sec:652153.73, hellaswag_acc: 0.2882
Step:  9837, loss: 3.163678, norm: 0.2826, time(ms): 793.21, token/sec:660968.37, hellaswag_acc: 0.2882
Step:  9838, loss: 3.013074, norm: 0.2855, time(ms): 799.65, token/sec:655642.78, hellaswag_acc: 0.2882
Step:  9839, loss: 2.989794, norm: 0.3086, time(ms): 806.94, token/sec:649721.86, hellaswag_acc: 0.2882
Step:  9840, loss: 3.063253, norm: 0.3120, time(ms): 801.12, token/sec:654447.25, hellaswag_acc: 0.2882
Step:  9841, loss: 3.026560, norm: 0.3298, time(ms): 792.48, token/sec:661579.05, hellaswag_acc: 0.2882
Step:  9842, loss: 2.959948, norm: 0.3554, time(ms): 802.61, token/sec:653228.52, hellaswag_acc: 0.2882
Step:  9843, loss: 2.974447, norm: 0.2791, time(ms): 803.95, token/sec:652137.10, hellaswag_acc: 0.2882
Step:  9844, loss: 3.044292, norm: 0.3366, time(ms): 789.85, token/sec:663779.93, hellaswag_acc: 0.2882
Step:  9845, loss: 3.031649, norm: 0.3339, time(ms): 800.37, token/sec:655060.76, hellaswag_acc: 0.2882
Step:  9846, loss: 3.037293, norm: 0.2795, time(ms): 809.43, token/sec:647725.80, hellaswag_acc: 0.2882
Step:  9847, loss: 2.999477, norm: 0.2862, time(ms): 791.05, token/sec:662772.43, hellaswag_acc: 0.2882
Step:  9848, loss: 3.032199, norm: 0.2857, time(ms): 794.22, token/sec:660126.49, hellaswag_acc: 0.2882
Step:  9849, loss: 3.024441, norm: 0.2654, time(ms): 790.96, token/sec:662849.55, hellaswag_acc: 0.2882
Step:  9850, loss: 3.224123, norm: 0.2951, time(ms): 793.31, token/sec:660886.53, hellaswag_acc: 0.2882
Step:  9851, loss: 3.281396, norm: 0.3020, time(ms): 791.13, token/sec:662711.11, hellaswag_acc: 0.2882
Step:  9852, loss: 3.201377, norm: 0.2744, time(ms): 791.17, token/sec:662673.57, hellaswag_acc: 0.2882
Step:  9853, loss: 3.160897, norm: 0.2798, time(ms): 796.78, token/sec:658008.98, hellaswag_acc: 0.2882
Step:  9854, loss: 3.248107, norm: 0.3068, time(ms): 791.80, token/sec:662149.38, hellaswag_acc: 0.2882
Step:  9855, loss: 3.207507, norm: 0.3171, time(ms): 793.07, token/sec:661088.39, hellaswag_acc: 0.2882
Step:  9856, loss: 3.217770, norm: 0.3014, time(ms): 798.47, token/sec:656617.72, hellaswag_acc: 0.2882
Step:  9857, loss: 3.223344, norm: 0.3021, time(ms): 798.25, token/sec:656797.76, hellaswag_acc: 0.2882
Step:  9858, loss: 3.282341, norm: 0.3391, time(ms): 791.92, token/sec:662043.93, hellaswag_acc: 0.2882
Step:  9859, loss: 3.210204, norm: 0.2962, time(ms): 787.12, token/sec:666081.44, hellaswag_acc: 0.2882
Step:  9860, loss: 3.191262, norm: 0.2769, time(ms): 790.92, token/sec:662886.71, hellaswag_acc: 0.2882
Step:  9861, loss: 3.251512, norm: 0.2736, time(ms): 793.62, token/sec:660627.43, hellaswag_acc: 0.2882
Step:  9862, loss: 3.199486, norm: 0.2672, time(ms): 802.35, token/sec:653443.01, hellaswag_acc: 0.2882
Step:  9863, loss: 3.187418, norm: 0.2582, time(ms): 799.92, token/sec:655422.74, hellaswag_acc: 0.2882
Step:  9864, loss: 3.225464, norm: 0.2821, time(ms): 799.46, token/sec:655800.57, hellaswag_acc: 0.2882
Step:  9865, loss: 3.221039, norm: 0.2756, time(ms): 798.95, token/sec:656219.17, hellaswag_acc: 0.2882
Step:  9866, loss: 3.223152, norm: 0.2916, time(ms): 800.29, token/sec:655120.09, hellaswag_acc: 0.2882
Step:  9867, loss: 3.187470, norm: 0.2763, time(ms): 797.37, token/sec:657521.64, hellaswag_acc: 0.2882
Step:  9868, loss: 3.195189, norm: 0.2766, time(ms): 802.67, token/sec:653180.01, hellaswag_acc: 0.2882
Step:  9869, loss: 3.215989, norm: 0.2929, time(ms): 799.84, token/sec:655491.12, hellaswag_acc: 0.2882
Step:  9870, loss: 3.148912, norm: 0.2899, time(ms): 796.74, token/sec:658039.50, hellaswag_acc: 0.2882
Step:  9871, loss: 3.208703, norm: 0.2795, time(ms): 802.27, token/sec:653503.79, hellaswag_acc: 0.2882
Step:  9872, loss: 3.100764, norm: 0.2840, time(ms): 801.93, token/sec:653781.23, hellaswag_acc: 0.2882
Step:  9873, loss: 3.145669, norm: 0.2733, time(ms): 795.34, token/sec:659199.79, hellaswag_acc: 0.2882
Step:  9874, loss: 3.197371, norm: 0.3054, time(ms): 803.02, token/sec:652898.23, hellaswag_acc: 0.2882
Step:  9875, loss: 3.172553, norm: 0.2939, time(ms): 799.66, token/sec:655634.96, hellaswag_acc: 0.2882
Step:  9876, loss: 3.162073, norm: 0.2944, time(ms): 801.82, token/sec:653871.24, hellaswag_acc: 0.2882
Step:  9877, loss: 3.091339, norm: 0.4643, time(ms): 794.47, token/sec:659919.67, hellaswag_acc: 0.2882
Step:  9878, loss: 3.233899, norm: 0.3296, time(ms): 803.30, token/sec:652665.31, hellaswag_acc: 0.2882
Step:  9879, loss: 3.143204, norm: 0.3196, time(ms): 800.97, token/sec:654569.59, hellaswag_acc: 0.2882
Step:  9880, loss: 3.105274, norm: 0.5057, time(ms): 795.47, token/sec:659088.75, hellaswag_acc: 0.2882
Step:  9881, loss: 3.203698, norm: 0.3922, time(ms): 802.43, token/sec:653372.53, hellaswag_acc: 0.2882
Step:  9882, loss: 3.163789, norm: 0.3277, time(ms): 802.18, token/sec:653578.76, hellaswag_acc: 0.2882
Step:  9883, loss: 3.152233, norm: 0.3267, time(ms): 792.91, token/sec:661224.16, hellaswag_acc: 0.2882
Step:  9884, loss: 3.177576, norm: 0.3030, time(ms): 802.88, token/sec:653006.22, hellaswag_acc: 0.2882
Step:  9885, loss: 3.041643, norm: 0.3204, time(ms): 802.40, token/sec:653396.21, hellaswag_acc: 0.2882
Step:  9886, loss: 3.021529, norm: 0.2998, time(ms): 794.59, token/sec:659823.44, hellaswag_acc: 0.2882
Step:  9887, loss: 2.978863, norm: 0.2980, time(ms): 804.98, token/sec:651306.75, hellaswag_acc: 0.2882
Step:  9888, loss: 3.059874, norm: 0.2936, time(ms): 801.15, token/sec:654419.40, hellaswag_acc: 0.2882
Step:  9889, loss: 3.263057, norm: 0.4473, time(ms): 797.74, token/sec:657219.60, hellaswag_acc: 0.2882
Step:  9890, loss: 3.096342, norm: 0.4249, time(ms): 795.58, token/sec:658999.28, hellaswag_acc: 0.2882
Step:  9891, loss: 2.973822, norm: 0.3150, time(ms): 804.47, token/sec:651717.12, hellaswag_acc: 0.2882
Step:  9892, loss: 3.060514, norm: 0.3213, time(ms): 792.30, token/sec:661732.94, hellaswag_acc: 0.2882
Step:  9893, loss: 3.044232, norm: 0.3437, time(ms): 794.52, token/sec:659881.05, hellaswag_acc: 0.2882
Step:  9894, loss: 3.112044, norm: 0.3159, time(ms): 790.85, token/sec:662944.87, hellaswag_acc: 0.2882
Step:  9895, loss: 3.012006, norm: 0.3040, time(ms): 793.04, token/sec:661110.65, hellaswag_acc: 0.2882
Step:  9896, loss: 3.041895, norm: 0.3532, time(ms): 790.11, token/sec:663565.41, hellaswag_acc: 0.2882
Step:  9897, loss: 3.176386, norm: 0.3219, time(ms): 792.56, token/sec:661514.17, hellaswag_acc: 0.2882
Step:  9898, loss: 3.205313, norm: 0.2940, time(ms): 797.22, token/sec:657648.08, hellaswag_acc: 0.2882
Step:  9899, loss: 3.307872, norm: 0.2903, time(ms): 799.29, token/sec:655945.91, hellaswag_acc: 0.2882
Step:  9900, loss: 3.226313, norm: 0.2947, time(ms): 791.47, token/sec:662424.84, hellaswag_acc: 0.2882
Step:  9901, loss: 3.193326, norm: 0.2860, time(ms): 790.15, token/sec:663528.77, hellaswag_acc: 0.2882
Step:  9902, loss: 3.200576, norm: 0.2717, time(ms): 792.07, token/sec:661919.58, hellaswag_acc: 0.2882
Step:  9903, loss: 3.216570, norm: 0.3283, time(ms): 785.79, token/sec:667208.94, hellaswag_acc: 0.2882
Step:  9904, loss: 3.224222, norm: 0.2592, time(ms): 792.37, token/sec:661673.80, hellaswag_acc: 0.2882
Step:  9905, loss: 3.256514, norm: 0.2745, time(ms): 1374.13, token/sec:381540.91, hellaswag_acc: 0.2882
Step:  9906, loss: 3.178505, norm: 0.2761, time(ms): 769.42, token/sec:681408.97, hellaswag_acc: 0.2882
Step:  9907, loss: 3.161520, norm: 0.2756, time(ms): 785.43, token/sec:667514.97, hellaswag_acc: 0.2882
Step:  9908, loss: 3.133665, norm: 0.2558, time(ms): 805.04, token/sec:651253.12, hellaswag_acc: 0.2882
Step:  9909, loss: 3.181998, norm: 0.2672, time(ms): 787.27, token/sec:665956.98, hellaswag_acc: 0.2882
Step:  9910, loss: 3.269431, norm: 0.2783, time(ms): 787.62, token/sec:665659.64, hellaswag_acc: 0.2882
Step:  9911, loss: 3.179011, norm: 0.2728, time(ms): 784.99, token/sec:667894.09, hellaswag_acc: 0.2882
Step:  9912, loss: 3.186828, norm: 0.2719, time(ms): 791.47, token/sec:662421.05, hellaswag_acc: 0.2882
Step:  9913, loss: 3.199512, norm: 0.2774, time(ms): 790.86, token/sec:662935.07, hellaswag_acc: 0.2882
Step:  9914, loss: 3.141237, norm: 0.2996, time(ms): 786.06, token/sec:666983.10, hellaswag_acc: 0.2882
Step:  9915, loss: 3.222458, norm: 0.2616, time(ms): 788.25, token/sec:665127.90, hellaswag_acc: 0.2882
Step:  9916, loss: 3.150981, norm: 0.2934, time(ms): 797.32, token/sec:657565.29, hellaswag_acc: 0.2882
Step:  9917, loss: 3.219991, norm: 0.2672, time(ms): 803.25, token/sec:652710.25, hellaswag_acc: 0.2882
Step:  9918, loss: 3.209021, norm: 0.2914, time(ms): 801.86, token/sec:653841.69, hellaswag_acc: 0.2882
Step:  9919, loss: 3.215846, norm: 0.2939, time(ms): 793.48, token/sec:660746.13, hellaswag_acc: 0.2882
Step:  9920, loss: 3.182830, norm: 0.2675, time(ms): 797.62, token/sec:657316.25, hellaswag_acc: 0.2882
Step:  9921, loss: 3.162722, norm: 0.2950, time(ms): 793.84, token/sec:660445.88, hellaswag_acc: 0.2882
Step:  9922, loss: 3.242618, norm: 0.2868, time(ms): 798.54, token/sec:656556.75, hellaswag_acc: 0.2882
Step:  9923, loss: 3.258934, norm: 0.2801, time(ms): 789.35, token/sec:664203.97, hellaswag_acc: 0.2882
Step:  9924, loss: 3.217368, norm: 0.3044, time(ms): 794.95, token/sec:659527.39, hellaswag_acc: 0.2882
Step:  9925, loss: 3.119607, norm: 0.2707, time(ms): 791.98, token/sec:661997.29, hellaswag_acc: 0.2882
Step:  9926, loss: 3.241893, norm: 0.2926, time(ms): 787.61, token/sec:665665.88, hellaswag_acc: 0.2882
Step:  9927, loss: 3.193357, norm: 0.2789, time(ms): 794.87, token/sec:659588.51, hellaswag_acc: 0.2882
Step:  9928, loss: 3.193992, norm: 0.2705, time(ms): 794.14, token/sec:660199.82, hellaswag_acc: 0.2882
Step:  9929, loss: 3.135948, norm: 0.2741, time(ms): 804.36, token/sec:651807.33, hellaswag_acc: 0.2882
Step:  9930, loss: 3.171226, norm: 0.2538, time(ms): 794.24, token/sec:660108.85, hellaswag_acc: 0.2882
Step:  9931, loss: 3.193406, norm: 0.3021, time(ms): 795.66, token/sec:658931.94, hellaswag_acc: 0.2882
Step:  9932, loss: 3.167358, norm: 0.2751, time(ms): 807.78, token/sec:649048.18, hellaswag_acc: 0.2882
Step:  9933, loss: 3.171675, norm: 0.2681, time(ms): 799.54, token/sec:655737.99, hellaswag_acc: 0.2882
Step:  9934, loss: 3.155020, norm: 0.2814, time(ms): 793.62, token/sec:660626.64, hellaswag_acc: 0.2882
Step:  9935, loss: 3.162624, norm: 0.2930, time(ms): 800.70, token/sec:654790.81, hellaswag_acc: 0.2882
Step:  9936, loss: 3.129100, norm: 0.2961, time(ms): 805.96, token/sec:650514.49, hellaswag_acc: 0.2882
Step:  9937, loss: 3.172066, norm: 0.2905, time(ms): 800.17, token/sec:655219.44, hellaswag_acc: 0.2882
Step:  9938, loss: 3.155763, norm: 0.2470, time(ms): 796.35, token/sec:658359.84, hellaswag_acc: 0.2882
Step:  9939, loss: 3.149946, norm: 0.2779, time(ms): 802.86, token/sec:653027.16, hellaswag_acc: 0.2882
Step:  9940, loss: 3.185297, norm: 0.2731, time(ms): 800.21, token/sec:655191.33, hellaswag_acc: 0.2882
Step:  9941, loss: 3.019103, norm: 0.2825, time(ms): 800.05, token/sec:655320.78, hellaswag_acc: 0.2882
Step:  9942, loss: 3.029115, norm: 0.3071, time(ms): 794.61, token/sec:659808.59, hellaswag_acc: 0.2882
Step:  9943, loss: 2.984657, norm: 0.3159, time(ms): 804.79, token/sec:651462.07, hellaswag_acc: 0.2882
Step:  9944, loss: 3.009104, norm: 0.2902, time(ms): 800.02, token/sec:655347.54, hellaswag_acc: 0.2882
Step:  9945, loss: 2.996274, norm: 0.3024, time(ms): 794.24, token/sec:660114.20, hellaswag_acc: 0.2882
Step:  9946, loss: 2.956557, norm: 0.3440, time(ms): 801.10, token/sec:654461.47, hellaswag_acc: 0.2882
Step:  9947, loss: 3.038164, norm: 0.2877, time(ms): 802.59, token/sec:653248.50, hellaswag_acc: 0.2882
Step:  9948, loss: 3.029898, norm: 0.3219, time(ms): 799.67, token/sec:655631.64, hellaswag_acc: 0.2882
Step:  9949, loss: 3.036218, norm: 0.2988, time(ms): 799.71, token/sec:655597.63, hellaswag_acc: 0.2882
Step:  9950, loss: 3.006436, norm: 0.3117, time(ms): 795.00, token/sec:659481.50, hellaswag_acc: 0.2882
Step:  9951, loss: 2.999937, norm: 0.2681, time(ms): 807.39, token/sec:649363.27, hellaswag_acc: 0.2882
Step:  9952, loss: 3.160783, norm: 0.3024, time(ms): 799.51, token/sec:655762.04, hellaswag_acc: 0.2882
Step:  9953, loss: 3.177894, norm: 0.2798, time(ms): 790.28, token/sec:663419.27, hellaswag_acc: 0.2882
Step:  9954, loss: 3.197477, norm: 0.2819, time(ms): 797.22, token/sec:657642.37, hellaswag_acc: 0.2882
Step:  9955, loss: 3.205629, norm: 0.2846, time(ms): 790.07, token/sec:663598.25, hellaswag_acc: 0.2882
Step:  9956, loss: 3.227920, norm: 0.2937, time(ms): 791.05, token/sec:662770.63, hellaswag_acc: 0.2882
Step:  9957, loss: 3.194223, norm: 0.3136, time(ms): 787.72, token/sec:665576.83, hellaswag_acc: 0.2882
Step:  9958, loss: 3.178041, norm: 0.3038, time(ms): 793.61, token/sec:660633.18, hellaswag_acc: 0.2882
Step:  9959, loss: 3.218492, norm: 0.2953, time(ms): 802.73, token/sec:653131.51, hellaswag_acc: 0.2882
Step:  9960, loss: 3.164357, norm: 0.2847, time(ms): 797.63, token/sec:657306.43, hellaswag_acc: 0.2882
Step:  9961, loss: 3.138446, norm: 0.2885, time(ms): 793.32, token/sec:660879.97, hellaswag_acc: 0.2882
Step:  9962, loss: 3.230407, norm: 0.2577, time(ms): 791.32, token/sec:662545.79, hellaswag_acc: 0.2882
Step:  9963, loss: 3.206250, norm: 0.2962, time(ms): 797.99, token/sec:657007.73, hellaswag_acc: 0.2882
Step:  9964, loss: 3.237289, norm: 0.2610, time(ms): 805.20, token/sec:651130.87, hellaswag_acc: 0.2882
Step:  9965, loss: 3.215268, norm: 0.2634, time(ms): 792.10, token/sec:661899.05, hellaswag_acc: 0.2882
Step:  9966, loss: 3.218238, norm: 0.2909, time(ms): 791.83, token/sec:662118.88, hellaswag_acc: 0.2882
Step:  9967, loss: 3.194136, norm: 0.2659, time(ms): 788.04, token/sec:665305.39, hellaswag_acc: 0.2882
Step:  9968, loss: 3.182573, norm: 0.2818, time(ms): 790.89, token/sec:662906.49, hellaswag_acc: 0.2882
Step:  9969, loss: 3.227139, norm: 0.2588, time(ms): 798.21, token/sec:656829.73, hellaswag_acc: 0.2882
Step:  9970, loss: 3.207293, norm: 0.2544, time(ms): 790.05, token/sec:663613.67, hellaswag_acc: 0.2882
Step:  9971, loss: 3.224136, norm: 0.2582, time(ms): 806.51, token/sec:650067.00, hellaswag_acc: 0.2882
Step:  9972, loss: 3.147683, norm: 0.2594, time(ms): 801.82, token/sec:653870.85, hellaswag_acc: 0.2882
Step:  9973, loss: 3.188020, norm: 0.2519, time(ms): 799.52, token/sec:655756.76, hellaswag_acc: 0.2882
Step:  9974, loss: 3.218831, norm: 0.2647, time(ms): 787.71, token/sec:665582.27, hellaswag_acc: 0.2882
Step:  9975, loss: 3.177587, norm: 0.2640, time(ms): 789.63, token/sec:663963.11, hellaswag_acc: 0.2882
Step:  9976, loss: 3.165034, norm: 0.2606, time(ms): 792.06, token/sec:661932.92, hellaswag_acc: 0.2882
Step:  9977, loss: 3.180070, norm: 0.2608, time(ms): 791.91, token/sec:662058.68, hellaswag_acc: 0.2882
Step:  9978, loss: 3.150033, norm: 0.2770, time(ms): 789.04, token/sec:664461.06, hellaswag_acc: 0.2882
Step:  9979, loss: 3.115738, norm: 0.2464, time(ms): 796.17, token/sec:658515.98, hellaswag_acc: 0.2882
Step:  9980, loss: 3.180215, norm: 0.2706, time(ms): 792.86, token/sec:661258.75, hellaswag_acc: 0.2882
Step:  9981, loss: 3.174774, norm: 0.2495, time(ms): 793.74, token/sec:660530.79, hellaswag_acc: 0.2882
Step:  9982, loss: 3.174120, norm: 0.2782, time(ms): 790.65, token/sec:663108.99, hellaswag_acc: 0.2882
Step:  9983, loss: 3.172214, norm: 0.2790, time(ms): 789.94, token/sec:663710.21, hellaswag_acc: 0.2882
Step:  9984, loss: 3.175703, norm: 0.2475, time(ms): 794.04, token/sec:660277.92, hellaswag_acc: 0.2882
Step:  9985, loss: 3.158075, norm: 0.2869, time(ms): 790.84, token/sec:662949.26, hellaswag_acc: 0.2882
Step:  9986, loss: 3.155200, norm: 0.2419, time(ms): 790.97, token/sec:662843.75, hellaswag_acc: 0.2882
Step:  9987, loss: 2.978857, norm: 0.2859, time(ms): 803.78, token/sec:652281.02, hellaswag_acc: 0.2882
Step:  9988, loss: 2.945198, norm: 0.2802, time(ms): 800.49, token/sec:654957.75, hellaswag_acc: 0.2882
Step:  9989, loss: 2.953537, norm: 0.2654, time(ms): 804.79, token/sec:651463.04, hellaswag_acc: 0.2882
Step:  9990, loss: 2.985599, norm: 0.2955, time(ms): 794.63, token/sec:659791.76, hellaswag_acc: 0.2882
Step:  9991, loss: 2.976412, norm: 0.2627, time(ms): 800.05, token/sec:655322.54, hellaswag_acc: 0.2882
Step:  9992, loss: 2.972614, norm: 0.2646, time(ms): 803.71, token/sec:652337.13, hellaswag_acc: 0.2882
Step:  9993, loss: 3.023972, norm: 0.2933, time(ms): 800.35, token/sec:655073.84, hellaswag_acc: 0.2882
Step:  9994, loss: 3.048320, norm: 0.2944, time(ms): 789.46, token/sec:664109.49, hellaswag_acc: 0.2882
Step:  9995, loss: 2.968131, norm: 0.3102, time(ms): 802.30, token/sec:653484.95, hellaswag_acc: 0.2882
Step:  9996, loss: 3.034122, norm: 0.2903, time(ms): 807.97, token/sec:648898.41, hellaswag_acc: 0.2882
Step:  9997, loss: 3.034953, norm: 0.2627, time(ms): 791.67, token/sec:662251.68, hellaswag_acc: 0.2882
Step:  9998, loss: 2.923196, norm: 0.2783, time(ms): 806.02, token/sec:650466.00, hellaswag_acc: 0.2882
Step:  9999, loss: 3.207418, norm: 0.3077, time(ms): 796.23, token/sec:658464.32, hellaswag_acc: 0.2882
rank 0 sample 0: Hello, I'm a language model, and I understand that it's the easiest question you can ask. For years and years I've taught my own language and
rank 0 sample 1: Hello, I'm a language model, so to think of the model, its size and purpose depends on its underlying concept, its data type, its data type
rank 0 sample 2: Hello, I'm a language model, so I haven't worked it out with my children. I want the language model to understand what it's like for her
rank 0 sample 3: Hello, I'm a language model, and can't tell you what I'm doing next. I'm using Java to my advantage.
There are some special
rank 1 sample 0: Hello, I'm a language model, how did I get the answer? Have I made it possible for you to tell me?
A. Yes, I
rank 1 sample 1: Hello, I'm a language model, a computer programmer, a programmer, a teacher, a data scientist, a software developer of students in a university, a
rank 1 sample 2: Hello, I'm a language model, I read and understand the language. I'm a very enthusiastic bilingual. And I'm a fluent, and a lot more
rank 1 sample 3: Hello, I'm a language model, and I'm looking for somebody to make computer programming for others. They know someone who likes Java. I'm also a
Step: 10000, loss: 3.186300, norm: 0.2724, time(ms): 363937.97, token/sec:1440.60, val_loss: 3.1923, hellaswag_acc: 0.2950
Step: 10001, loss: 3.183710, norm: 0.3147, time(ms): 794.30, token/sec:660059.71, hellaswag_acc: 0.2950
Step: 10002, loss: 3.190648, norm: 0.3003, time(ms): 786.40, token/sec:666692.51, hellaswag_acc: 0.2950
Step: 10003, loss: 3.173616, norm: 0.3152, time(ms): 795.94, token/sec:658702.98, hellaswag_acc: 0.2950
Step: 10004, loss: 3.202967, norm: 0.2859, time(ms): 789.48, token/sec:664095.45, hellaswag_acc: 0.2950
Step: 10005, loss: 3.206945, norm: 0.3112, time(ms): 802.49, token/sec:653330.02, hellaswag_acc: 0.2950
Step: 10006, loss: 3.181136, norm: 0.2768, time(ms): 802.72, token/sec:653139.66, hellaswag_acc: 0.2950
Step: 10007, loss: 3.267186, norm: 0.3234, time(ms): 793.78, token/sec:660497.46, hellaswag_acc: 0.2950
Step: 10008, loss: 3.199458, norm: 0.3297, time(ms): 802.18, token/sec:653577.40, hellaswag_acc: 0.2950
Step: 10009, loss: 3.135729, norm: 0.3090, time(ms): 801.48, token/sec:654148.61, hellaswag_acc: 0.2950
Step: 10010, loss: 3.167976, norm: 0.3123, time(ms): 798.34, token/sec:656725.97, hellaswag_acc: 0.2950
Step: 10011, loss: 3.240823, norm: 0.2902, time(ms): 800.80, token/sec:654709.32, hellaswag_acc: 0.2950
Step: 10012, loss: 3.140364, norm: 0.2867, time(ms): 799.97, token/sec:655385.04, hellaswag_acc: 0.2950
Step: 10013, loss: 3.215442, norm: 0.2693, time(ms): 798.96, token/sec:656211.73, hellaswag_acc: 0.2950
Step: 10014, loss: 3.189084, norm: 0.2683, time(ms): 800.45, token/sec:654991.69, hellaswag_acc: 0.2950
Step: 10015, loss: 3.194015, norm: 0.2621, time(ms): 800.42, token/sec:655017.64, hellaswag_acc: 0.2950
Step: 10016, loss: 3.200722, norm: 0.2751, time(ms): 800.56, token/sec:654899.62, hellaswag_acc: 0.2950
Step: 10017, loss: 3.190758, norm: 0.2685, time(ms): 797.68, token/sec:657269.49, hellaswag_acc: 0.2950
Step: 10018, loss: 3.201128, norm: 0.2720, time(ms): 799.19, token/sec:656027.32, hellaswag_acc: 0.2950
Step: 10019, loss: 3.169948, norm: 0.2737, time(ms): 800.62, token/sec:654854.18, hellaswag_acc: 0.2950
Step: 10020, loss: 3.186261, norm: 0.2369, time(ms): 802.36, token/sec:653431.74, hellaswag_acc: 0.2950
Step: 10021, loss: 3.175909, norm: 0.2511, time(ms): 792.38, token/sec:661659.07, hellaswag_acc: 0.2950
Step: 10022, loss: 3.114870, norm: 0.2501, time(ms): 804.49, token/sec:651700.12, hellaswag_acc: 0.2950
Step: 10023, loss: 3.176510, norm: 0.2421, time(ms): 801.95, token/sec:653763.74, hellaswag_acc: 0.2950
Step: 10024, loss: 3.152253, norm: 0.3042, time(ms): 799.72, token/sec:655587.85, hellaswag_acc: 0.2950
Step: 10025, loss: 3.097215, norm: 0.3182, time(ms): 797.90, token/sec:657087.24, hellaswag_acc: 0.2950
Step: 10026, loss: 3.136754, norm: 0.2620, time(ms): 800.06, token/sec:655309.65, hellaswag_acc: 0.2950
Step: 10027, loss: 3.176210, norm: 0.3319, time(ms): 800.57, token/sec:654896.69, hellaswag_acc: 0.2950
Step: 10028, loss: 3.184425, norm: 0.2762, time(ms): 789.14, token/sec:664375.14, hellaswag_acc: 0.2950
Step: 10029, loss: 3.125911, norm: 0.2975, time(ms): 789.99, token/sec:663661.94, hellaswag_acc: 0.2950
Step: 10030, loss: 3.147951, norm: 0.2672, time(ms): 794.17, token/sec:660168.70, hellaswag_acc: 0.2950
Step: 10031, loss: 3.134922, norm: 0.2956, time(ms): 791.83, token/sec:662125.66, hellaswag_acc: 0.2950
Step: 10032, loss: 3.131987, norm: 0.2634, time(ms): 794.43, token/sec:659951.55, hellaswag_acc: 0.2950
Step: 10033, loss: 3.069478, norm: 0.2909, time(ms): 798.76, token/sec:656378.22, hellaswag_acc: 0.2950
Step: 10034, loss: 3.027569, norm: 0.2886, time(ms): 795.78, token/sec:658834.61, hellaswag_acc: 0.2950
Step: 10035, loss: 2.994513, norm: 0.2732, time(ms): 800.61, token/sec:654861.79, hellaswag_acc: 0.2950
Step: 10036, loss: 3.041298, norm: 0.3347, time(ms): 805.02, token/sec:651275.88, hellaswag_acc: 0.2950
Step: 10037, loss: 2.945872, norm: 0.2785, time(ms): 793.56, token/sec:660681.81, hellaswag_acc: 0.2950
Step: 10038, loss: 3.002000, norm: 0.2968, time(ms): 791.84, token/sec:662116.88, hellaswag_acc: 0.2950
Step: 10039, loss: 3.017426, norm: 0.2708, time(ms): 795.28, token/sec:659248.60, hellaswag_acc: 0.2950
Step: 10040, loss: 3.018511, norm: 0.2948, time(ms): 797.49, token/sec:657420.01, hellaswag_acc: 0.2950
Step: 10041, loss: 3.040344, norm: 0.2801, time(ms): 790.20, token/sec:663484.73, hellaswag_acc: 0.2950
Step: 10042, loss: 3.049336, norm: 0.2836, time(ms): 789.32, token/sec:664229.45, hellaswag_acc: 0.2950
Step: 10043, loss: 3.047386, norm: 0.2688, time(ms): 792.97, token/sec:661165.91, hellaswag_acc: 0.2950
Step: 10044, loss: 2.954211, norm: 0.2615, time(ms): 793.12, token/sec:661044.67, hellaswag_acc: 0.2950
Step: 10045, loss: 3.158523, norm: 0.2895, time(ms): 792.77, token/sec:661340.89, hellaswag_acc: 0.2950
Step: 10046, loss: 3.147904, norm: 0.2687, time(ms): 799.20, token/sec:656013.42, hellaswag_acc: 0.2950
Step: 10047, loss: 3.222210, norm: 0.2907, time(ms): 801.94, token/sec:653776.18, hellaswag_acc: 0.2950
Step: 10048, loss: 3.134627, norm: 0.2993, time(ms): 798.60, token/sec:656507.75, hellaswag_acc: 0.2950
Step: 10049, loss: 3.266759, norm: 0.2712, time(ms): 799.77, token/sec:655547.01, hellaswag_acc: 0.2950
Step: 10050, loss: 3.251085, norm: 0.2647, time(ms): 799.86, token/sec:655475.29, hellaswag_acc: 0.2950
Step: 10051, loss: 3.210012, norm: 0.2948, time(ms): 795.66, token/sec:658938.65, hellaswag_acc: 0.2950
Step: 10052, loss: 3.223688, norm: 0.2938, time(ms): 804.43, token/sec:651748.80, hellaswag_acc: 0.2950
Step: 10053, loss: 3.236244, norm: 0.2966, time(ms): 801.03, token/sec:654517.18, hellaswag_acc: 0.2950
Step: 10054, loss: 3.190462, norm: 0.3306, time(ms): 792.15, token/sec:661855.03, hellaswag_acc: 0.2950
Step: 10055, loss: 3.139149, norm: 0.3203, time(ms): 805.69, token/sec:650735.10, hellaswag_acc: 0.2950
Step: 10056, loss: 3.140405, norm: 0.2594, time(ms): 801.91, token/sec:653802.42, hellaswag_acc: 0.2950
Step: 10057, loss: 3.217782, norm: 0.3084, time(ms): 789.04, token/sec:664459.46, hellaswag_acc: 0.2950
Step: 10058, loss: 3.215334, norm: 0.2603, time(ms): 803.46, token/sec:652540.97, hellaswag_acc: 0.2950
Step: 10059, loss: 3.139746, norm: 0.2793, time(ms): 804.54, token/sec:651663.82, hellaswag_acc: 0.2950
Step: 10060, loss: 3.200049, norm: 0.2804, time(ms): 802.63, token/sec:653214.55, hellaswag_acc: 0.2950
Step: 10061, loss: 3.267959, norm: 0.2921, time(ms): 792.72, token/sec:661375.49, hellaswag_acc: 0.2950
Step: 10062, loss: 3.193196, norm: 0.3134, time(ms): 800.55, token/sec:654907.62, hellaswag_acc: 0.2950
Step: 10063, loss: 3.181071, norm: 0.3117, time(ms): 805.15, token/sec:651164.61, hellaswag_acc: 0.2950
Step: 10064, loss: 3.222939, norm: 0.3004, time(ms): 800.99, token/sec:654551.08, hellaswag_acc: 0.2950
Step: 10065, loss: 3.208231, norm: 0.2814, time(ms): 789.57, token/sec:664019.25, hellaswag_acc: 0.2950
Step: 10066, loss: 3.221742, norm: 0.2685, time(ms): 803.20, token/sec:652747.06, hellaswag_acc: 0.2950
Step: 10067, loss: 3.178180, norm: 0.2614, time(ms): 805.91, token/sec:650551.25, hellaswag_acc: 0.2950
Step: 10068, loss: 3.183300, norm: 0.2739, time(ms): 790.13, token/sec:663547.19, hellaswag_acc: 0.2950
Step: 10069, loss: 3.130948, norm: 0.2450, time(ms): 795.66, token/sec:658937.67, hellaswag_acc: 0.2950
Step: 10070, loss: 3.135862, norm: 0.2553, time(ms): 790.35, token/sec:663364.64, hellaswag_acc: 0.2950
Step: 10071, loss: 3.169746, norm: 0.2657, time(ms): 790.97, token/sec:662843.95, hellaswag_acc: 0.2950
Step: 10072, loss: 3.160450, norm: 0.2649, time(ms): 791.24, token/sec:662612.27, hellaswag_acc: 0.2950
Step: 10073, loss: 3.146806, norm: 0.2581, time(ms): 790.42, token/sec:663304.21, hellaswag_acc: 0.2950
Step: 10074, loss: 3.169204, norm: 0.2545, time(ms): 794.29, token/sec:660074.97, hellaswag_acc: 0.2950
Step: 10075, loss: 3.195560, norm: 0.2677, time(ms): 794.03, token/sec:660286.25, hellaswag_acc: 0.2950
Step: 10076, loss: 3.160758, norm: 0.2661, time(ms): 793.65, token/sec:660605.60, hellaswag_acc: 0.2950
Step: 10077, loss: 3.151914, norm: 0.2640, time(ms): 798.64, token/sec:656476.78, hellaswag_acc: 0.2950
Step: 10078, loss: 3.175618, norm: 0.2581, time(ms): 793.75, token/sec:660522.46, hellaswag_acc: 0.2950
Step: 10079, loss: 3.003719, norm: 0.2803, time(ms): 786.78, token/sec:666369.27, hellaswag_acc: 0.2950
Step: 10080, loss: 2.992868, norm: 0.2628, time(ms): 790.26, token/sec:663438.69, hellaswag_acc: 0.2950
Step: 10081, loss: 3.024122, norm: 0.2760, time(ms): 795.73, token/sec:658877.84, hellaswag_acc: 0.2950
Step: 10082, loss: 3.065698, norm: 0.2980, time(ms): 792.46, token/sec:661592.78, hellaswag_acc: 0.2950
Step: 10083, loss: 3.040813, norm: 0.2848, time(ms): 808.10, token/sec:648791.96, hellaswag_acc: 0.2950
Step: 10084, loss: 3.055254, norm: 0.2729, time(ms): 801.83, token/sec:653863.66, hellaswag_acc: 0.2950
Step: 10085, loss: 2.988824, norm: 0.3023, time(ms): 783.54, token/sec:669130.14, hellaswag_acc: 0.2950
Step: 10086, loss: 2.978857, norm: 0.2873, time(ms): 790.68, token/sec:663088.40, hellaswag_acc: 0.2950
Step: 10087, loss: 2.961070, norm: 0.2604, time(ms): 794.74, token/sec:659698.53, hellaswag_acc: 0.2950
Step: 10088, loss: 3.039446, norm: 0.2938, time(ms): 791.94, token/sec:662027.98, hellaswag_acc: 0.2950
Step: 10089, loss: 2.986633, norm: 0.2847, time(ms): 791.56, token/sec:662350.62, hellaswag_acc: 0.2950
Step: 10090, loss: 2.983936, norm: 0.2807, time(ms): 795.22, token/sec:659300.58, hellaswag_acc: 0.2950
Step: 10091, loss: 3.162732, norm: 0.3001, time(ms): 791.82, token/sec:662133.83, hellaswag_acc: 0.2950
Step: 10092, loss: 3.190004, norm: 0.3182, time(ms): 793.68, token/sec:660575.24, hellaswag_acc: 0.2950
Step: 10093, loss: 3.202436, norm: 0.2880, time(ms): 795.25, token/sec:659271.53, hellaswag_acc: 0.2950
Step: 10094, loss: 3.196217, norm: 0.2941, time(ms): 791.18, token/sec:662662.98, hellaswag_acc: 0.2950
Step: 10095, loss: 3.245483, norm: 0.2866, time(ms): 788.97, token/sec:664522.51, hellaswag_acc: 0.2950
Step: 10096, loss: 3.220899, norm: 0.3055, time(ms): 1314.15, token/sec:398956.31, hellaswag_acc: 0.2950
Step: 10097, loss: 3.185439, norm: 0.2826, time(ms): 793.51, token/sec:660717.94, hellaswag_acc: 0.2950
Step: 10098, loss: 3.208216, norm: 0.3049, time(ms): 786.31, token/sec:666767.71, hellaswag_acc: 0.2950
Step: 10099, loss: 3.216420, norm: 0.2950, time(ms): 784.59, token/sec:668230.59, hellaswag_acc: 0.2950
Step: 10100, loss: 3.171106, norm: 0.2924, time(ms): 805.34, token/sec:651016.17, hellaswag_acc: 0.2950
Step: 10101, loss: 3.211635, norm: 0.2983, time(ms): 803.85, token/sec:652223.37, hellaswag_acc: 0.2950
Step: 10102, loss: 3.221352, norm: 0.2730, time(ms): 795.60, token/sec:658984.47, hellaswag_acc: 0.2950
Step: 10103, loss: 3.210826, norm: 0.3190, time(ms): 794.15, token/sec:660189.71, hellaswag_acc: 0.2950
Step: 10104, loss: 3.233876, norm: 0.2893, time(ms): 794.62, token/sec:659798.49, hellaswag_acc: 0.2950
Step: 10105, loss: 3.192398, norm: 0.3275, time(ms): 790.34, token/sec:663368.64, hellaswag_acc: 0.2950
Step: 10106, loss: 3.181088, norm: 0.2847, time(ms): 790.39, token/sec:663325.42, hellaswag_acc: 0.2950
Step: 10107, loss: 3.176888, norm: 0.2738, time(ms): 789.60, token/sec:663990.78, hellaswag_acc: 0.2950
Step: 10108, loss: 3.162502, norm: 0.3056, time(ms): 798.53, token/sec:656567.93, hellaswag_acc: 0.2950
Step: 10109, loss: 3.151615, norm: 0.2784, time(ms): 801.62, token/sec:654032.85, hellaswag_acc: 0.2950
Step: 10110, loss: 3.166299, norm: 0.2768, time(ms): 799.68, token/sec:655623.23, hellaswag_acc: 0.2950
Step: 10111, loss: 3.115013, norm: 0.2910, time(ms): 795.05, token/sec:659440.36, hellaswag_acc: 0.2950
Step: 10112, loss: 3.167228, norm: 0.2640, time(ms): 798.44, token/sec:656642.03, hellaswag_acc: 0.2950
Step: 10113, loss: 3.155059, norm: 0.2660, time(ms): 792.25, token/sec:661773.36, hellaswag_acc: 0.2950
Step: 10114, loss: 3.194431, norm: 0.2712, time(ms): 788.57, token/sec:664859.64, hellaswag_acc: 0.2950
Step: 10115, loss: 3.152990, norm: 0.2743, time(ms): 793.03, token/sec:661124.16, hellaswag_acc: 0.2950
Step: 10116, loss: 3.169596, norm: 0.2790, time(ms): 786.60, token/sec:666524.19, hellaswag_acc: 0.2950
Step: 10117, loss: 2.997735, norm: 0.2941, time(ms): 791.93, token/sec:662041.53, hellaswag_acc: 0.2950
Step: 10118, loss: 2.952628, norm: 0.2928, time(ms): 795.38, token/sec:659166.20, hellaswag_acc: 0.2950
Step: 10119, loss: 2.944012, norm: 0.2796, time(ms): 800.17, token/sec:655219.44, hellaswag_acc: 0.2950
Step: 10120, loss: 3.027292, norm: 0.3409, time(ms): 795.23, token/sec:659289.71, hellaswag_acc: 0.2950
Step: 10121, loss: 2.908269, norm: 0.2968, time(ms): 804.46, token/sec:651730.64, hellaswag_acc: 0.2950
Step: 10122, loss: 2.983158, norm: 0.2801, time(ms): 799.31, token/sec:655928.89, hellaswag_acc: 0.2950
Step: 10123, loss: 2.937523, norm: 0.3131, time(ms): 797.50, token/sec:657411.36, hellaswag_acc: 0.2950
Step: 10124, loss: 2.966669, norm: 0.2731, time(ms): 801.36, token/sec:654243.78, hellaswag_acc: 0.2950
Step: 10125, loss: 2.955713, norm: 0.2801, time(ms): 801.31, token/sec:654289.33, hellaswag_acc: 0.2950
Step: 10126, loss: 3.020116, norm: 0.2768, time(ms): 794.91, token/sec:659557.26, hellaswag_acc: 0.2950
Step: 10127, loss: 2.973591, norm: 0.2666, time(ms): 797.49, token/sec:657424.53, hellaswag_acc: 0.2950
Step: 10128, loss: 3.045339, norm: 0.2560, time(ms): 806.05, token/sec:650441.18, hellaswag_acc: 0.2950
Step: 10129, loss: 3.128909, norm: 0.3046, time(ms): 802.38, token/sec:653416.21, hellaswag_acc: 0.2950
Step: 10130, loss: 3.250876, norm: 0.3309, time(ms): 789.33, token/sec:664222.23, hellaswag_acc: 0.2950
Step: 10131, loss: 3.176579, norm: 0.3063, time(ms): 793.01, token/sec:661137.08, hellaswag_acc: 0.2950
Step: 10132, loss: 3.162929, norm: 0.2879, time(ms): 793.94, token/sec:660360.60, hellaswag_acc: 0.2950
Step: 10133, loss: 3.233056, norm: 0.3095, time(ms): 789.48, token/sec:664094.05, hellaswag_acc: 0.2950
Step: 10134, loss: 3.174251, norm: 0.2842, time(ms): 788.80, token/sec:664666.52, hellaswag_acc: 0.2950
Step: 10135, loss: 3.139882, norm: 0.2769, time(ms): 797.58, token/sec:657352.21, hellaswag_acc: 0.2950
Step: 10136, loss: 3.216665, norm: 0.3248, time(ms): 802.73, token/sec:653131.32, hellaswag_acc: 0.2950
Step: 10137, loss: 3.224283, norm: 0.2822, time(ms): 799.05, token/sec:656135.57, hellaswag_acc: 0.2950
Step: 10138, loss: 3.295214, norm: 0.4236, time(ms): 794.86, token/sec:659595.44, hellaswag_acc: 0.2950
Step: 10139, loss: 3.225579, norm: 0.3554, time(ms): 791.38, token/sec:662494.69, hellaswag_acc: 0.2950
Step: 10140, loss: 3.168270, norm: 0.3427, time(ms): 797.28, token/sec:657595.37, hellaswag_acc: 0.2950
Step: 10141, loss: 3.228445, norm: 0.3449, time(ms): 788.11, token/sec:665246.22, hellaswag_acc: 0.2950
Step: 10142, loss: 3.212422, norm: 0.3026, time(ms): 787.11, token/sec:666088.30, hellaswag_acc: 0.2950
Step: 10143, loss: 3.176939, norm: 0.3026, time(ms): 789.11, token/sec:664407.06, hellaswag_acc: 0.2950
Step: 10144, loss: 3.161760, norm: 0.2873, time(ms): 789.95, token/sec:663694.39, hellaswag_acc: 0.2950
Step: 10145, loss: 3.176661, norm: 0.2970, time(ms): 802.47, token/sec:653343.80, hellaswag_acc: 0.2950
Step: 10146, loss: 3.181577, norm: 0.2925, time(ms): 802.95, token/sec:652952.32, hellaswag_acc: 0.2950
Step: 10147, loss: 3.215387, norm: 0.3132, time(ms): 798.49, token/sec:656598.51, hellaswag_acc: 0.2950
Step: 10148, loss: 3.248430, norm: 0.2652, time(ms): 800.40, token/sec:655033.05, hellaswag_acc: 0.2950
Step: 10149, loss: 3.164075, norm: 0.3033, time(ms): 798.89, token/sec:656268.52, hellaswag_acc: 0.2950
Step: 10150, loss: 3.276739, norm: 0.3157, time(ms): 800.20, token/sec:655192.11, hellaswag_acc: 0.2950
Step: 10151, loss: 3.224816, norm: 0.3483, time(ms): 799.91, token/sec:655430.16, hellaswag_acc: 0.2950
Step: 10152, loss: 3.168558, norm: 0.2962, time(ms): 797.14, token/sec:657707.48, hellaswag_acc: 0.2950
Step: 10153, loss: 3.192749, norm: 0.3302, time(ms): 802.12, token/sec:653631.60, hellaswag_acc: 0.2950
Step: 10154, loss: 3.163232, norm: 0.2946, time(ms): 800.69, token/sec:654798.22, hellaswag_acc: 0.2950
Step: 10155, loss: 3.211157, norm: 0.3041, time(ms): 798.41, token/sec:656664.78, hellaswag_acc: 0.2950
Step: 10156, loss: 3.140100, norm: 0.2795, time(ms): 796.30, token/sec:658408.73, hellaswag_acc: 0.2950
Step: 10157, loss: 3.183083, norm: 0.3249, time(ms): 804.01, token/sec:652087.98, hellaswag_acc: 0.2950
Step: 10158, loss: 3.126328, norm: 0.2658, time(ms): 801.85, token/sec:653848.30, hellaswag_acc: 0.2950
Step: 10159, loss: 3.102045, norm: 0.2914, time(ms): 792.38, token/sec:661662.06, hellaswag_acc: 0.2950
Step: 10160, loss: 3.170561, norm: 0.2801, time(ms): 801.49, token/sec:654144.13, hellaswag_acc: 0.2950
Step: 10161, loss: 3.160477, norm: 0.2863, time(ms): 805.40, token/sec:650962.40, hellaswag_acc: 0.2950
Step: 10162, loss: 3.122639, norm: 0.2716, time(ms): 793.20, token/sec:660975.32, hellaswag_acc: 0.2950
Step: 10163, loss: 3.171560, norm: 0.2669, time(ms): 804.34, token/sec:651823.75, hellaswag_acc: 0.2950
Step: 10164, loss: 3.026728, norm: 0.3418, time(ms): 798.92, token/sec:656245.02, hellaswag_acc: 0.2950
Step: 10165, loss: 3.010921, norm: 0.3112, time(ms): 801.38, token/sec:654233.46, hellaswag_acc: 0.2950
Step: 10166, loss: 2.944524, norm: 0.2869, time(ms): 795.89, token/sec:658747.18, hellaswag_acc: 0.2950
Step: 10167, loss: 2.946018, norm: 0.2977, time(ms): 804.22, token/sec:651924.63, hellaswag_acc: 0.2950
Step: 10168, loss: 3.008722, norm: 0.2770, time(ms): 800.71, token/sec:654775.40, hellaswag_acc: 0.2950
Step: 10169, loss: 2.941618, norm: 0.2727, time(ms): 792.67, token/sec:661422.24, hellaswag_acc: 0.2950
Step: 10170, loss: 2.983558, norm: 0.2869, time(ms): 800.38, token/sec:655051.40, hellaswag_acc: 0.2950
Step: 10171, loss: 2.955228, norm: 0.2812, time(ms): 804.86, token/sec:651399.93, hellaswag_acc: 0.2950
Step: 10172, loss: 2.989624, norm: 0.2827, time(ms): 799.45, token/sec:655813.09, hellaswag_acc: 0.2950
Step: 10173, loss: 2.979471, norm: 0.2997, time(ms): 789.84, token/sec:663788.75, hellaswag_acc: 0.2950
Step: 10174, loss: 2.966194, norm: 0.2752, time(ms): 789.66, token/sec:663943.47, hellaswag_acc: 0.2950
Step: 10175, loss: 3.055293, norm: 0.3255, time(ms): 792.24, token/sec:661779.34, hellaswag_acc: 0.2950
Step: 10176, loss: 3.165643, norm: 0.3296, time(ms): 792.95, token/sec:661187.77, hellaswag_acc: 0.2950
Step: 10177, loss: 3.173794, norm: 0.2958, time(ms): 791.61, token/sec:662307.13, hellaswag_acc: 0.2950
Step: 10178, loss: 3.146361, norm: 0.3339, time(ms): 793.85, token/sec:660439.73, hellaswag_acc: 0.2950
Step: 10179, loss: 3.160595, norm: 0.2730, time(ms): 790.98, token/sec:662835.36, hellaswag_acc: 0.2950
Step: 10180, loss: 3.164098, norm: 0.3133, time(ms): 799.35, token/sec:655896.02, hellaswag_acc: 0.2950
Step: 10181, loss: 3.205008, norm: 0.2700, time(ms): 791.56, token/sec:662348.62, hellaswag_acc: 0.2950
Step: 10182, loss: 3.190834, norm: 0.2572, time(ms): 797.07, token/sec:657769.06, hellaswag_acc: 0.2950
Step: 10183, loss: 3.166553, norm: 0.2814, time(ms): 789.43, token/sec:664130.95, hellaswag_acc: 0.2950
Step: 10184, loss: 3.120072, norm: 0.2577, time(ms): 789.39, token/sec:664167.06, hellaswag_acc: 0.2950
Step: 10185, loss: 3.183083, norm: 0.2652, time(ms): 795.88, token/sec:658754.48, hellaswag_acc: 0.2950
Step: 10186, loss: 3.220623, norm: 0.2662, time(ms): 790.65, token/sec:663107.99, hellaswag_acc: 0.2950
Step: 10187, loss: 3.245368, norm: 0.2615, time(ms): 796.00, token/sec:658652.67, hellaswag_acc: 0.2950
Step: 10188, loss: 3.207866, norm: 0.2724, time(ms): 806.60, token/sec:649999.37, hellaswag_acc: 0.2950
Step: 10189, loss: 3.178705, norm: 0.2558, time(ms): 798.22, token/sec:656821.69, hellaswag_acc: 0.2950
Step: 10190, loss: 3.191258, norm: 0.2739, time(ms): 798.58, token/sec:656525.19, hellaswag_acc: 0.2950
Step: 10191, loss: 3.182242, norm: 0.2589, time(ms): 800.20, token/sec:655200.12, hellaswag_acc: 0.2950
Step: 10192, loss: 3.237061, norm: 0.2616, time(ms): 804.81, token/sec:651441.81, hellaswag_acc: 0.2950
Step: 10193, loss: 3.125402, norm: 0.2668, time(ms): 793.07, token/sec:661083.42, hellaswag_acc: 0.2950
Step: 10194, loss: 3.180280, norm: 0.2731, time(ms): 797.63, token/sec:657304.07, hellaswag_acc: 0.2950
Step: 10195, loss: 3.182285, norm: 0.2733, time(ms): 808.08, token/sec:648809.38, hellaswag_acc: 0.2950
Step: 10196, loss: 3.213737, norm: 0.2761, time(ms): 799.40, token/sec:655850.44, hellaswag_acc: 0.2950
Step: 10197, loss: 3.203125, norm: 0.2587, time(ms): 797.90, token/sec:657087.82, hellaswag_acc: 0.2950
Step: 10198, loss: 3.236378, norm: 0.3002, time(ms): 799.86, token/sec:655476.08, hellaswag_acc: 0.2950
Step: 10199, loss: 3.152995, norm: 0.2634, time(ms): 802.60, token/sec:653233.17, hellaswag_acc: 0.2950
Step: 10200, loss: 3.120264, norm: 0.2695, time(ms): 789.86, token/sec:663772.52, hellaswag_acc: 0.2950
Step: 10201, loss: 3.126153, norm: 0.2541, time(ms): 792.45, token/sec:661606.32, hellaswag_acc: 0.2950
Step: 10202, loss: 3.182529, norm: 0.3195, time(ms): 791.84, token/sec:662109.51, hellaswag_acc: 0.2950
Step: 10203, loss: 3.156021, norm: 0.2632, time(ms): 789.78, token/sec:663838.04, hellaswag_acc: 0.2950
Step: 10204, loss: 3.143566, norm: 0.2802, time(ms): 793.52, token/sec:660709.40, hellaswag_acc: 0.2950
Step: 10205, loss: 3.143501, norm: 0.2580, time(ms): 796.10, token/sec:658573.37, hellaswag_acc: 0.2950
Step: 10206, loss: 3.084685, norm: 0.2696, time(ms): 799.91, token/sec:655435.24, hellaswag_acc: 0.2950
Step: 10207, loss: 3.156199, norm: 0.2646, time(ms): 803.27, token/sec:652690.68, hellaswag_acc: 0.2950
Step: 10208, loss: 3.103172, norm: 0.2616, time(ms): 797.88, token/sec:657101.37, hellaswag_acc: 0.2950
Step: 10209, loss: 3.165743, norm: 0.2585, time(ms): 794.52, token/sec:659880.26, hellaswag_acc: 0.2950
Step: 10210, loss: 2.975784, norm: 0.3242, time(ms): 791.31, token/sec:662554.57, hellaswag_acc: 0.2950
Step: 10211, loss: 3.018365, norm: 0.3618, time(ms): 796.06, token/sec:658604.93, hellaswag_acc: 0.2950
Step: 10212, loss: 2.992933, norm: 0.3202, time(ms): 790.39, token/sec:663324.42, hellaswag_acc: 0.2950
Step: 10213, loss: 2.973635, norm: 0.3005, time(ms): 788.76, token/sec:664698.46, hellaswag_acc: 0.2950
Step: 10214, loss: 2.938186, norm: 0.3584, time(ms): 792.44, token/sec:661613.68, hellaswag_acc: 0.2950
Step: 10215, loss: 2.915286, norm: 0.3052, time(ms): 793.25, token/sec:660932.61, hellaswag_acc: 0.2950
Step: 10216, loss: 2.923027, norm: 0.2716, time(ms): 791.04, token/sec:662786.22, hellaswag_acc: 0.2950
Step: 10217, loss: 2.973585, norm: 0.3570, time(ms): 800.37, token/sec:655060.76, hellaswag_acc: 0.2950
Step: 10218, loss: 2.948304, norm: 0.2981, time(ms): 804.46, token/sec:651729.29, hellaswag_acc: 0.2950
Step: 10219, loss: 2.946932, norm: 0.2969, time(ms): 795.63, token/sec:658959.58, hellaswag_acc: 0.2950
Step: 10220, loss: 2.928444, norm: 0.3051, time(ms): 796.47, token/sec:658262.29, hellaswag_acc: 0.2950
Step: 10221, loss: 3.068316, norm: 0.2809, time(ms): 805.62, token/sec:650789.02, hellaswag_acc: 0.2950
Step: 10222, loss: 3.185664, norm: 0.2927, time(ms): 801.01, token/sec:654536.66, hellaswag_acc: 0.2950
Step: 10223, loss: 3.165196, norm: 0.3005, time(ms): 795.25, token/sec:659273.50, hellaswag_acc: 0.2950
Step: 10224, loss: 3.161399, norm: 0.2796, time(ms): 796.14, token/sec:658540.24, hellaswag_acc: 0.2950
Step: 10225, loss: 3.186956, norm: 0.2721, time(ms): 807.01, token/sec:649665.42, hellaswag_acc: 0.2950
Step: 10226, loss: 3.133776, norm: 0.2849, time(ms): 799.18, token/sec:656034.76, hellaswag_acc: 0.2950
Step: 10227, loss: 3.292698, norm: 0.3150, time(ms): 797.17, token/sec:657687.81, hellaswag_acc: 0.2950
Step: 10228, loss: 3.128082, norm: 0.2854, time(ms): 803.45, token/sec:652545.23, hellaswag_acc: 0.2950
Step: 10229, loss: 3.201578, norm: 0.2984, time(ms): 799.45, token/sec:655808.00, hellaswag_acc: 0.2950
Step: 10230, loss: 3.202379, norm: 0.2861, time(ms): 799.94, token/sec:655408.09, hellaswag_acc: 0.2950
Step: 10231, loss: 3.073206, norm: 0.2914, time(ms): 798.90, token/sec:656261.28, hellaswag_acc: 0.2950
Step: 10232, loss: 3.214175, norm: 0.2972, time(ms): 801.35, token/sec:654259.16, hellaswag_acc: 0.2950
Step: 10233, loss: 3.218269, norm: 0.2862, time(ms): 796.43, token/sec:658297.56, hellaswag_acc: 0.2950
Step: 10234, loss: 3.271181, norm: 0.2930, time(ms): 794.85, token/sec:659609.88, hellaswag_acc: 0.2950
Step: 10235, loss: 3.221919, norm: 0.3233, time(ms): 798.63, token/sec:656480.31, hellaswag_acc: 0.2950
Step: 10236, loss: 3.226570, norm: 0.2861, time(ms): 791.21, token/sec:662638.42, hellaswag_acc: 0.2950
Step: 10237, loss: 3.204601, norm: 0.3344, time(ms): 788.42, token/sec:664986.91, hellaswag_acc: 0.2950
Step: 10238, loss: 3.234085, norm: 0.3165, time(ms): 790.23, token/sec:663464.11, hellaswag_acc: 0.2950
Step: 10239, loss: 3.205188, norm: 0.2854, time(ms): 793.82, token/sec:660458.98, hellaswag_acc: 0.2950
Step: 10240, loss: 3.257995, norm: 0.2928, time(ms): 799.60, token/sec:655691.65, hellaswag_acc: 0.2950
Step: 10241, loss: 3.283110, norm: 0.3006, time(ms): 801.46, token/sec:654164.37, hellaswag_acc: 0.2950
Step: 10242, loss: 3.215386, norm: 0.3037, time(ms): 799.56, token/sec:655724.11, hellaswag_acc: 0.2950
Step: 10243, loss: 3.231291, norm: 0.3161, time(ms): 798.80, token/sec:656340.41, hellaswag_acc: 0.2950
Step: 10244, loss: 3.189230, norm: 0.2776, time(ms): 801.82, token/sec:653875.71, hellaswag_acc: 0.2950
Step: 10245, loss: 3.141928, norm: 0.2954, time(ms): 796.63, token/sec:658134.23, hellaswag_acc: 0.2950
Step: 10246, loss: 3.164407, norm: 0.2828, time(ms): 797.99, token/sec:657013.42, hellaswag_acc: 0.2950
Step: 10247, loss: 3.191135, norm: 0.2937, time(ms): 793.48, token/sec:660745.54, hellaswag_acc: 0.2950
Step: 10248, loss: 3.104760, norm: 0.2752, time(ms): 792.80, token/sec:661310.66, hellaswag_acc: 0.2950
Step: 10249, loss: 3.150448, norm: 0.2880, time(ms): 797.02, token/sec:657814.12, hellaswag_acc: 0.2950
rank 0 sample 0: Hello, I'm a language model, and I think it is great because all classes don't have a verb of "I think your child has an interest,
rank 0 sample 1: Hello, I'm a language model, so to speak. But why should it be a case of "language"? The answer lies in a complex relationship between grammar
rank 0 sample 2: Hello, I'm a language model, so I hope this resource explains some of the more common idiocy, idioms, idioms, and idiomatic expressions
rank 0 sample 3: Hello, I'm a language model, so, and you can get the code that uses the language model here. I learned to play with code from the Language
rank 1 sample 0: Hello, I'm a language model, and I'm a big geek. Okay so you've got three things going on here in my mind. So, I
rank 1 sample 1: Hello, I'm a language model, not an interpreter. I'm a native speaker, and understand the idea of how any code should behave in a language.
rank 1 sample 2: Hello, I'm a language model, but more often than not, I'm a language model that looks like it's a language model in its own right,
rank 1 sample 3: Hello, I'm a language model, and I'm going to create a script this week. Well, now this seems like very exciting to me. If you
Step: 10250, loss: 3.146520, norm: 0.2783, time(ms): 3793.45, token/sec:138208.79, val_loss: 3.1856, hellaswag_acc: 0.2950
Step: 10251, loss: 3.136945, norm: 0.2861, time(ms): 787.96, token/sec:665373.23, hellaswag_acc: 0.2950
Step: 10252, loss: 3.105458, norm: 0.2871, time(ms): 786.58, token/sec:666545.40, hellaswag_acc: 0.2950
Step: 10253, loss: 3.128776, norm: 0.2784, time(ms): 794.33, token/sec:660041.29, hellaswag_acc: 0.2950
Step: 10254, loss: 3.159676, norm: 0.2804, time(ms): 802.08, token/sec:653664.24, hellaswag_acc: 0.2950
Step: 10255, loss: 3.163379, norm: 0.2979, time(ms): 793.08, token/sec:661077.46, hellaswag_acc: 0.2950
Step: 10256, loss: 3.045640, norm: 0.2868, time(ms): 804.79, token/sec:651460.91, hellaswag_acc: 0.2950
Step: 10257, loss: 2.944910, norm: 0.2746, time(ms): 800.15, token/sec:655237.02, hellaswag_acc: 0.2950
Step: 10258, loss: 2.919964, norm: 0.2890, time(ms): 801.17, token/sec:654402.65, hellaswag_acc: 0.2950
Step: 10259, loss: 2.956382, norm: 0.2980, time(ms): 794.72, token/sec:659710.01, hellaswag_acc: 0.2950
Step: 10260, loss: 3.003757, norm: 0.2589, time(ms): 797.82, token/sec:657150.46, hellaswag_acc: 0.2950
Step: 10261, loss: 2.962806, norm: 0.2904, time(ms): 804.65, token/sec:651571.91, hellaswag_acc: 0.2950
Step: 10262, loss: 2.955184, norm: 0.2823, time(ms): 803.04, token/sec:652879.81, hellaswag_acc: 0.2950
Step: 10263, loss: 2.953763, norm: 0.3010, time(ms): 792.98, token/sec:661161.73, hellaswag_acc: 0.2950
Step: 10264, loss: 2.973464, norm: 0.2989, time(ms): 801.69, token/sec:653980.14, hellaswag_acc: 0.2950
Step: 10265, loss: 3.037319, norm: 0.2818, time(ms): 803.73, token/sec:652318.75, hellaswag_acc: 0.2950
Step: 10266, loss: 3.008150, norm: 0.2565, time(ms): 791.50, token/sec:662396.70, hellaswag_acc: 0.2950
Step: 10267, loss: 3.004372, norm: 0.3109, time(ms): 791.30, token/sec:662567.55, hellaswag_acc: 0.2950
Step: 10268, loss: 3.193244, norm: 0.3043, time(ms): 787.35, token/sec:665891.85, hellaswag_acc: 0.2950
Step: 10269, loss: 3.270437, norm: 0.3056, time(ms): 791.13, token/sec:662707.52, hellaswag_acc: 0.2950
Step: 10270, loss: 3.126715, norm: 0.3499, time(ms): 786.90, token/sec:666268.93, hellaswag_acc: 0.2950
Step: 10271, loss: 3.146016, norm: 0.3465, time(ms): 790.85, token/sec:662946.06, hellaswag_acc: 0.2950
Step: 10272, loss: 3.222748, norm: 0.2957, time(ms): 795.11, token/sec:659387.57, hellaswag_acc: 0.2950
Step: 10273, loss: 3.232372, norm: 0.3023, time(ms): 798.37, token/sec:656694.00, hellaswag_acc: 0.2950
Step: 10274, loss: 3.218023, norm: 0.3450, time(ms): 792.87, token/sec:661251.99, hellaswag_acc: 0.2950
Step: 10275, loss: 3.221914, norm: 0.3107, time(ms): 786.30, token/sec:666779.64, hellaswag_acc: 0.2950
Step: 10276, loss: 3.170786, norm: 0.3281, time(ms): 790.33, token/sec:663375.04, hellaswag_acc: 0.2950
Step: 10277, loss: 3.222614, norm: 0.3043, time(ms): 792.07, token/sec:661923.36, hellaswag_acc: 0.2950
Step: 10278, loss: 3.252282, norm: 0.3061, time(ms): 799.16, token/sec:656049.63, hellaswag_acc: 0.2950
Step: 10279, loss: 3.148941, norm: 0.3167, time(ms): 805.22, token/sec:651108.89, hellaswag_acc: 0.2950
Step: 10280, loss: 3.223311, norm: 0.2618, time(ms): 799.16, token/sec:656052.76, hellaswag_acc: 0.2950
Step: 10281, loss: 3.173975, norm: 0.2779, time(ms): 793.14, token/sec:661027.97, hellaswag_acc: 0.2950
Step: 10282, loss: 3.227389, norm: 0.2874, time(ms): 803.51, token/sec:652493.92, hellaswag_acc: 0.2950
Step: 10283, loss: 3.183167, norm: 0.2941, time(ms): 803.86, token/sec:652209.24, hellaswag_acc: 0.2950
Step: 10284, loss: 3.229942, norm: 0.3024, time(ms): 794.76, token/sec:659683.29, hellaswag_acc: 0.2950
Step: 10285, loss: 3.221827, norm: 0.2844, time(ms): 803.98, token/sec:652112.35, hellaswag_acc: 0.2950
Step: 10286, loss: 3.206678, norm: 0.2769, time(ms): 1304.36, token/sec:401949.82, hellaswag_acc: 0.2950
Step: 10287, loss: 3.141370, norm: 0.3155, time(ms): 765.96, token/sec:684488.47, hellaswag_acc: 0.2950
Step: 10288, loss: 3.155936, norm: 0.2618, time(ms): 788.51, token/sec:664906.88, hellaswag_acc: 0.2950
Step: 10289, loss: 3.123682, norm: 0.3025, time(ms): 801.31, token/sec:654291.08, hellaswag_acc: 0.2950
Step: 10290, loss: 3.158829, norm: 0.2836, time(ms): 787.16, token/sec:666052.59, hellaswag_acc: 0.2950
Step: 10291, loss: 3.177658, norm: 0.2824, time(ms): 785.76, token/sec:667237.28, hellaswag_acc: 0.2950
Step: 10292, loss: 3.197774, norm: 0.2709, time(ms): 793.05, token/sec:661107.07, hellaswag_acc: 0.2950
Step: 10293, loss: 3.135045, norm: 0.2834, time(ms): 792.99, token/sec:661156.56, hellaswag_acc: 0.2950
Step: 10294, loss: 3.191411, norm: 0.2738, time(ms): 792.46, token/sec:661598.55, hellaswag_acc: 0.2950
Step: 10295, loss: 3.141267, norm: 0.2719, time(ms): 786.69, token/sec:666447.22, hellaswag_acc: 0.2950
Step: 10296, loss: 3.179747, norm: 0.2718, time(ms): 790.92, token/sec:662886.71, hellaswag_acc: 0.2950
Step: 10297, loss: 3.175711, norm: 0.2996, time(ms): 805.37, token/sec:650991.70, hellaswag_acc: 0.2950
Step: 10298, loss: 3.213903, norm: 0.3009, time(ms): 803.05, token/sec:652868.38, hellaswag_acc: 0.2950
Step: 10299, loss: 3.199081, norm: 0.2967, time(ms): 790.90, token/sec:662900.50, hellaswag_acc: 0.2950
Step: 10300, loss: 3.191882, norm: 0.3075, time(ms): 792.02, token/sec:661964.01, hellaswag_acc: 0.2950
Step: 10301, loss: 3.178082, norm: 0.2950, time(ms): 789.50, token/sec:664075.00, hellaswag_acc: 0.2950
Step: 10302, loss: 3.161876, norm: 0.3045, time(ms): 791.49, token/sec:662404.29, hellaswag_acc: 0.2950
Step: 10303, loss: 3.192085, norm: 0.2786, time(ms): 787.18, token/sec:666035.45, hellaswag_acc: 0.2950
Step: 10304, loss: 3.140836, norm: 0.3126, time(ms): 793.00, token/sec:661142.85, hellaswag_acc: 0.2950
Step: 10305, loss: 3.195744, norm: 0.2840, time(ms): 794.15, token/sec:660186.73, hellaswag_acc: 0.2950
Step: 10306, loss: 3.156857, norm: 0.2840, time(ms): 798.09, token/sec:656924.51, hellaswag_acc: 0.2950
Step: 10307, loss: 3.167654, norm: 0.2905, time(ms): 798.60, token/sec:656511.67, hellaswag_acc: 0.2950
Step: 10308, loss: 3.167239, norm: 0.2865, time(ms): 800.65, token/sec:654831.36, hellaswag_acc: 0.2950
Step: 10309, loss: 3.176472, norm: 0.2922, time(ms): 793.91, token/sec:660387.18, hellaswag_acc: 0.2950
Step: 10310, loss: 3.206046, norm: 0.2862, time(ms): 789.53, token/sec:664054.34, hellaswag_acc: 0.2950
Step: 10311, loss: 3.190706, norm: 0.3079, time(ms): 790.73, token/sec:663045.41, hellaswag_acc: 0.2950
Step: 10312, loss: 3.164566, norm: 0.2513, time(ms): 789.67, token/sec:663929.23, hellaswag_acc: 0.2950
Step: 10313, loss: 3.156037, norm: 0.2700, time(ms): 794.12, token/sec:660213.89, hellaswag_acc: 0.2950
Step: 10314, loss: 3.135796, norm: 0.2728, time(ms): 794.40, token/sec:659982.85, hellaswag_acc: 0.2950
Step: 10315, loss: 3.143426, norm: 0.2569, time(ms): 791.10, token/sec:662737.08, hellaswag_acc: 0.2950
Step: 10316, loss: 3.144373, norm: 0.2735, time(ms): 786.19, token/sec:666872.66, hellaswag_acc: 0.2950
Step: 10317, loss: 3.168448, norm: 0.2540, time(ms): 794.21, token/sec:660139.17, hellaswag_acc: 0.2950
Step: 10318, loss: 3.117737, norm: 0.2695, time(ms): 790.06, token/sec:663605.46, hellaswag_acc: 0.2950
Step: 10319, loss: 3.122326, norm: 0.2650, time(ms): 806.79, token/sec:649843.01, hellaswag_acc: 0.2950
Step: 10320, loss: 3.130630, norm: 0.2592, time(ms): 798.91, token/sec:656251.09, hellaswag_acc: 0.2950
Step: 10321, loss: 3.153944, norm: 0.2681, time(ms): 792.20, token/sec:661812.40, hellaswag_acc: 0.2950
Step: 10322, loss: 3.155923, norm: 0.2658, time(ms): 792.11, token/sec:661891.68, hellaswag_acc: 0.2950
Step: 10323, loss: 3.148427, norm: 0.2659, time(ms): 795.50, token/sec:659071.17, hellaswag_acc: 0.2950
Step: 10324, loss: 3.216076, norm: 0.2693, time(ms): 795.98, token/sec:658673.58, hellaswag_acc: 0.2950
Step: 10325, loss: 3.144279, norm: 0.2564, time(ms): 802.54, token/sec:653289.84, hellaswag_acc: 0.2950
Step: 10326, loss: 3.179533, norm: 0.2717, time(ms): 793.20, token/sec:660979.89, hellaswag_acc: 0.2950
Step: 10327, loss: 3.156174, norm: 0.2747, time(ms): 789.58, token/sec:664012.63, hellaswag_acc: 0.2950
Step: 10328, loss: 3.148986, norm: 0.2611, time(ms): 785.86, token/sec:667156.11, hellaswag_acc: 0.2950
Step: 10329, loss: 3.191149, norm: 0.2579, time(ms): 794.56, token/sec:659843.43, hellaswag_acc: 0.2950
Step: 10330, loss: 3.165525, norm: 0.2862, time(ms): 786.85, token/sec:666314.35, hellaswag_acc: 0.2950
Step: 10331, loss: 3.188599, norm: 0.2855, time(ms): 790.06, token/sec:663608.06, hellaswag_acc: 0.2950
Step: 10332, loss: 3.222494, norm: 0.3069, time(ms): 793.46, token/sec:660764.60, hellaswag_acc: 0.2950
Step: 10333, loss: 3.156336, norm: 0.2669, time(ms): 792.69, token/sec:661407.12, hellaswag_acc: 0.2950
Step: 10334, loss: 3.231095, norm: 0.3143, time(ms): 791.71, token/sec:662225.15, hellaswag_acc: 0.2950
Step: 10335, loss: 3.162912, norm: 0.3239, time(ms): 793.39, token/sec:660816.22, hellaswag_acc: 0.2950
Step: 10336, loss: 3.176152, norm: 0.2908, time(ms): 791.99, token/sec:661990.71, hellaswag_acc: 0.2950
Step: 10337, loss: 3.196162, norm: 0.3060, time(ms): 789.46, token/sec:664108.09, hellaswag_acc: 0.2950
Step: 10338, loss: 3.234401, norm: 0.3015, time(ms): 798.21, token/sec:656830.52, hellaswag_acc: 0.2950
Step: 10339, loss: 3.246494, norm: 0.2963, time(ms): 788.50, token/sec:664920.55, hellaswag_acc: 0.2950
Step: 10340, loss: 3.190711, norm: 0.3133, time(ms): 789.72, token/sec:663888.14, hellaswag_acc: 0.2950
Step: 10341, loss: 3.167393, norm: 0.2745, time(ms): 790.98, token/sec:662829.97, hellaswag_acc: 0.2950
Step: 10342, loss: 3.156581, norm: 0.3068, time(ms): 789.25, token/sec:664283.83, hellaswag_acc: 0.2950
Step: 10343, loss: 3.125560, norm: 0.2676, time(ms): 797.37, token/sec:657521.64, hellaswag_acc: 0.2950
Step: 10344, loss: 3.167756, norm: 0.2898, time(ms): 792.11, token/sec:661888.30, hellaswag_acc: 0.2950
Step: 10345, loss: 3.129093, norm: 0.2751, time(ms): 787.16, token/sec:666053.40, hellaswag_acc: 0.2950
Step: 10346, loss: 3.195482, norm: 0.2943, time(ms): 788.60, token/sec:664832.10, hellaswag_acc: 0.2950
Step: 10347, loss: 3.137108, norm: 0.2657, time(ms): 795.43, token/sec:659126.48, hellaswag_acc: 0.2950
Step: 10348, loss: 3.159840, norm: 0.2655, time(ms): 799.39, token/sec:655859.25, hellaswag_acc: 0.2950
Step: 10349, loss: 3.138071, norm: 0.2726, time(ms): 792.04, token/sec:661943.88, hellaswag_acc: 0.2950
Step: 10350, loss: 3.237725, norm: 0.2869, time(ms): 786.94, token/sec:666239.86, hellaswag_acc: 0.2950
Step: 10351, loss: 3.183961, norm: 0.2901, time(ms): 788.73, token/sec:664724.78, hellaswag_acc: 0.2950
Step: 10352, loss: 3.211079, norm: 0.2599, time(ms): 791.61, token/sec:662309.52, hellaswag_acc: 0.2950
Step: 10353, loss: 3.155076, norm: 0.2878, time(ms): 798.37, token/sec:656699.49, hellaswag_acc: 0.2950
Step: 10354, loss: 3.164411, norm: 0.2739, time(ms): 791.44, token/sec:662448.59, hellaswag_acc: 0.2950
Step: 10355, loss: 3.184413, norm: 0.2703, time(ms): 786.07, token/sec:666977.23, hellaswag_acc: 0.2950
Step: 10356, loss: 3.232238, norm: 0.2670, time(ms): 790.01, token/sec:663643.51, hellaswag_acc: 0.2950
Step: 10357, loss: 3.126826, norm: 0.2804, time(ms): 793.51, token/sec:660720.32, hellaswag_acc: 0.2950
Step: 10358, loss: 3.159537, norm: 0.2631, time(ms): 794.61, token/sec:659806.01, hellaswag_acc: 0.2950
Step: 10359, loss: 3.179748, norm: 0.2734, time(ms): 791.74, token/sec:662195.64, hellaswag_acc: 0.2950
Step: 10360, loss: 3.163935, norm: 0.2843, time(ms): 798.11, token/sec:656913.52, hellaswag_acc: 0.2950
Step: 10361, loss: 3.168052, norm: 0.3244, time(ms): 801.95, token/sec:653766.07, hellaswag_acc: 0.2950
Step: 10362, loss: 3.131374, norm: 0.2944, time(ms): 794.79, token/sec:659653.21, hellaswag_acc: 0.2950
Step: 10363, loss: 3.168449, norm: 0.2716, time(ms): 799.21, token/sec:656011.08, hellaswag_acc: 0.2950
Step: 10364, loss: 3.164852, norm: 0.3041, time(ms): 799.19, token/sec:656027.12, hellaswag_acc: 0.2950
Step: 10365, loss: 3.152161, norm: 0.2853, time(ms): 798.90, token/sec:656262.06, hellaswag_acc: 0.2950
Step: 10366, loss: 3.247270, norm: 0.3020, time(ms): 792.17, token/sec:661834.11, hellaswag_acc: 0.2950
Step: 10367, loss: 3.222580, norm: 0.3290, time(ms): 793.08, token/sec:661078.45, hellaswag_acc: 0.2950
Step: 10368, loss: 3.187387, norm: 0.2856, time(ms): 797.46, token/sec:657446.54, hellaswag_acc: 0.2950
Step: 10369, loss: 3.152413, norm: 0.3307, time(ms): 802.52, token/sec:653304.98, hellaswag_acc: 0.2950
Step: 10370, loss: 3.221832, norm: 0.2849, time(ms): 798.39, token/sec:656685.57, hellaswag_acc: 0.2950
Step: 10371, loss: 3.196738, norm: 0.3185, time(ms): 795.68, token/sec:658918.32, hellaswag_acc: 0.2950
Step: 10372, loss: 3.149449, norm: 0.2759, time(ms): 790.23, token/sec:663461.71, hellaswag_acc: 0.2950
Step: 10373, loss: 3.167423, norm: 0.2864, time(ms): 788.51, token/sec:664911.10, hellaswag_acc: 0.2950
Step: 10374, loss: 3.206200, norm: 0.2972, time(ms): 791.33, token/sec:662537.20, hellaswag_acc: 0.2950
Step: 10375, loss: 3.187988, norm: 0.3452, time(ms): 787.33, token/sec:665902.94, hellaswag_acc: 0.2950
Step: 10376, loss: 3.188114, norm: 0.2953, time(ms): 790.07, token/sec:663598.25, hellaswag_acc: 0.2950
Step: 10377, loss: 3.227064, norm: 0.3352, time(ms): 790.57, token/sec:663179.38, hellaswag_acc: 0.2950
Step: 10378, loss: 3.226231, norm: 0.2948, time(ms): 790.13, token/sec:663544.19, hellaswag_acc: 0.2950
Step: 10379, loss: 3.116195, norm: 0.2977, time(ms): 792.18, token/sec:661832.52, hellaswag_acc: 0.2950
Step: 10380, loss: 3.139849, norm: 0.3471, time(ms): 795.76, token/sec:658852.77, hellaswag_acc: 0.2950
Step: 10381, loss: 3.190037, norm: 0.3530, time(ms): 791.73, token/sec:662203.22, hellaswag_acc: 0.2950
Step: 10382, loss: 3.197709, norm: 0.2961, time(ms): 790.84, token/sec:662949.86, hellaswag_acc: 0.2950
Step: 10383, loss: 3.143169, norm: 0.3117, time(ms): 788.66, token/sec:664782.66, hellaswag_acc: 0.2950
Step: 10384, loss: 3.152095, norm: 0.2927, time(ms): 785.92, token/sec:667103.08, hellaswag_acc: 0.2950
Step: 10385, loss: 3.161622, norm: 0.2928, time(ms): 792.73, token/sec:661366.94, hellaswag_acc: 0.2950
Step: 10386, loss: 3.132759, norm: 0.2769, time(ms): 797.27, token/sec:657605.20, hellaswag_acc: 0.2950
Step: 10387, loss: 3.177536, norm: 0.2755, time(ms): 803.54, token/sec:652469.52, hellaswag_acc: 0.2950
Step: 10388, loss: 3.124888, norm: 0.2816, time(ms): 799.80, token/sec:655524.53, hellaswag_acc: 0.2950
Step: 10389, loss: 3.164082, norm: 0.2817, time(ms): 793.51, token/sec:660718.34, hellaswag_acc: 0.2950
Step: 10390, loss: 3.169852, norm: 0.2658, time(ms): 798.08, token/sec:656935.10, hellaswag_acc: 0.2950
Step: 10391, loss: 3.160860, norm: 0.3493, time(ms): 805.99, token/sec:650491.98, hellaswag_acc: 0.2950
Step: 10392, loss: 3.188443, norm: 0.2922, time(ms): 790.43, token/sec:663294.80, hellaswag_acc: 0.2950
Step: 10393, loss: 3.161185, norm: 0.2621, time(ms): 787.09, token/sec:666106.06, hellaswag_acc: 0.2950
Step: 10394, loss: 3.147720, norm: 0.2819, time(ms): 792.04, token/sec:661948.27, hellaswag_acc: 0.2950
Step: 10395, loss: 3.157756, norm: 0.2744, time(ms): 791.69, token/sec:662241.51, hellaswag_acc: 0.2950
Step: 10396, loss: 3.169026, norm: 0.3007, time(ms): 794.87, token/sec:659587.33, hellaswag_acc: 0.2950
Step: 10397, loss: 3.117621, norm: 0.2636, time(ms): 798.70, token/sec:656423.68, hellaswag_acc: 0.2950
Step: 10398, loss: 3.186220, norm: 0.2756, time(ms): 802.75, token/sec:653116.77, hellaswag_acc: 0.2950
Step: 10399, loss: 3.185960, norm: 0.2660, time(ms): 802.00, token/sec:653726.62, hellaswag_acc: 0.2950
Step: 10400, loss: 3.208140, norm: 0.2958, time(ms): 798.04, token/sec:656971.81, hellaswag_acc: 0.2950
Step: 10401, loss: 3.141350, norm: 0.2876, time(ms): 795.51, token/sec:659060.31, hellaswag_acc: 0.2950
Step: 10402, loss: 3.147136, norm: 0.2982, time(ms): 804.13, token/sec:651995.56, hellaswag_acc: 0.2950
Step: 10403, loss: 3.230302, norm: 0.2652, time(ms): 799.07, token/sec:656120.30, hellaswag_acc: 0.2950
Step: 10404, loss: 3.136320, norm: 0.3000, time(ms): 799.64, token/sec:655657.05, hellaswag_acc: 0.2950
Step: 10405, loss: 3.200477, norm: 0.2874, time(ms): 800.37, token/sec:655053.15, hellaswag_acc: 0.2950
Step: 10406, loss: 3.160143, norm: 0.3093, time(ms): 797.67, token/sec:657275.78, hellaswag_acc: 0.2950
Step: 10407, loss: 3.182559, norm: 0.2922, time(ms): 802.31, token/sec:653474.85, hellaswag_acc: 0.2950
Step: 10408, loss: 3.150356, norm: 0.2801, time(ms): 800.54, token/sec:654918.34, hellaswag_acc: 0.2950
Step: 10409, loss: 3.126579, norm: 0.2720, time(ms): 798.00, token/sec:657003.60, hellaswag_acc: 0.2950
Step: 10410, loss: 3.180390, norm: 0.2810, time(ms): 795.78, token/sec:658834.22, hellaswag_acc: 0.2950
Step: 10411, loss: 3.134969, norm: 0.2563, time(ms): 797.52, token/sec:657401.14, hellaswag_acc: 0.2950
Step: 10412, loss: 3.205791, norm: 0.2864, time(ms): 790.43, token/sec:663293.80, hellaswag_acc: 0.2950
Step: 10413, loss: 3.206952, norm: 0.2824, time(ms): 789.72, token/sec:663894.56, hellaswag_acc: 0.2950
Step: 10414, loss: 3.168288, norm: 0.2718, time(ms): 789.86, token/sec:663771.31, hellaswag_acc: 0.2950
Step: 10415, loss: 3.157516, norm: 0.2745, time(ms): 790.63, token/sec:663126.59, hellaswag_acc: 0.2950
Step: 10416, loss: 3.169996, norm: 0.2747, time(ms): 791.14, token/sec:662701.53, hellaswag_acc: 0.2950
Step: 10417, loss: 3.174137, norm: 0.2815, time(ms): 790.98, token/sec:662833.56, hellaswag_acc: 0.2950
Step: 10418, loss: 3.171870, norm: 0.2684, time(ms): 805.35, token/sec:651006.92, hellaswag_acc: 0.2950
Step: 10419, loss: 3.153599, norm: 0.2946, time(ms): 801.28, token/sec:654313.28, hellaswag_acc: 0.2950
Step: 10420, loss: 3.209332, norm: 0.2953, time(ms): 795.24, token/sec:659283.19, hellaswag_acc: 0.2950
Step: 10421, loss: 3.360344, norm: 0.3681, time(ms): 802.71, token/sec:653144.70, hellaswag_acc: 0.2950
Step: 10422, loss: 3.134930, norm: 0.3605, time(ms): 802.49, token/sec:653323.03, hellaswag_acc: 0.2950
Step: 10423, loss: 3.143329, norm: 0.3069, time(ms): 798.68, token/sec:656441.90, hellaswag_acc: 0.2950
Step: 10424, loss: 3.101963, norm: 0.3117, time(ms): 799.11, token/sec:656087.02, hellaswag_acc: 0.2950
Step: 10425, loss: 3.134807, norm: 0.3041, time(ms): 800.04, token/sec:655329.96, hellaswag_acc: 0.2950
Step: 10426, loss: 3.105548, norm: 0.2970, time(ms): 798.13, token/sec:656897.23, hellaswag_acc: 0.2950
Step: 10427, loss: 3.152493, norm: 0.3173, time(ms): 802.63, token/sec:653210.28, hellaswag_acc: 0.2950
Step: 10428, loss: 3.108934, norm: 0.3017, time(ms): 795.00, token/sec:659479.72, hellaswag_acc: 0.2950
Step: 10429, loss: 3.125417, norm: 0.3130, time(ms): 803.04, token/sec:652875.55, hellaswag_acc: 0.2950
Step: 10430, loss: 3.144382, norm: 0.2663, time(ms): 800.14, token/sec:655246.00, hellaswag_acc: 0.2950
Step: 10431, loss: 3.133170, norm: 0.3094, time(ms): 797.02, token/sec:657810.38, hellaswag_acc: 0.2950
Step: 10432, loss: 3.191636, norm: 0.2862, time(ms): 801.34, token/sec:654260.71, hellaswag_acc: 0.2950
Step: 10433, loss: 3.179134, norm: 0.3097, time(ms): 802.53, token/sec:653290.62, hellaswag_acc: 0.2950
Step: 10434, loss: 3.150589, norm: 0.2864, time(ms): 797.12, token/sec:657724.20, hellaswag_acc: 0.2950
Step: 10435, loss: 3.226275, norm: 0.3014, time(ms): 800.89, token/sec:654630.97, hellaswag_acc: 0.2950
Step: 10436, loss: 3.282827, norm: 0.2967, time(ms): 799.70, token/sec:655602.12, hellaswag_acc: 0.2950
Step: 10437, loss: 3.166302, norm: 0.3284, time(ms): 801.28, token/sec:654310.16, hellaswag_acc: 0.2950
Step: 10438, loss: 3.139019, norm: 0.2840, time(ms): 794.39, token/sec:659984.24, hellaswag_acc: 0.2950
Step: 10439, loss: 3.179876, norm: 0.3059, time(ms): 804.46, token/sec:651722.91, hellaswag_acc: 0.2950
Step: 10440, loss: 3.172169, norm: 0.3313, time(ms): 801.59, token/sec:654056.97, hellaswag_acc: 0.2950
Step: 10441, loss: 3.175457, norm: 0.2714, time(ms): 798.61, token/sec:656497.95, hellaswag_acc: 0.2950
Step: 10442, loss: 3.198824, norm: 0.3413, time(ms): 799.09, token/sec:656107.18, hellaswag_acc: 0.2950
Step: 10443, loss: 3.205914, norm: 0.2766, time(ms): 798.45, token/sec:656628.11, hellaswag_acc: 0.2950
Step: 10444, loss: 3.168967, norm: 0.3083, time(ms): 800.88, token/sec:654641.49, hellaswag_acc: 0.2950
Step: 10445, loss: 3.170124, norm: 0.2763, time(ms): 797.58, token/sec:657345.14, hellaswag_acc: 0.2950
Step: 10446, loss: 3.175149, norm: 0.2722, time(ms): 801.17, token/sec:654400.90, hellaswag_acc: 0.2950
Step: 10447, loss: 3.187065, norm: 0.2949, time(ms): 797.43, token/sec:657470.33, hellaswag_acc: 0.2950
Step: 10448, loss: 3.228432, norm: 0.2796, time(ms): 802.88, token/sec:653011.07, hellaswag_acc: 0.2950
Step: 10449, loss: 3.112871, norm: 0.2727, time(ms): 800.79, token/sec:654713.02, hellaswag_acc: 0.2950
Step: 10450, loss: 3.249586, norm: 0.3109, time(ms): 792.93, token/sec:661200.50, hellaswag_acc: 0.2950
Step: 10451, loss: 3.127539, norm: 0.3101, time(ms): 805.30, token/sec:651048.74, hellaswag_acc: 0.2950
Step: 10452, loss: 3.202418, norm: 0.2795, time(ms): 803.18, token/sec:652767.21, hellaswag_acc: 0.2950
Step: 10453, loss: 3.118081, norm: 0.2899, time(ms): 791.89, token/sec:662072.83, hellaswag_acc: 0.2950
Step: 10454, loss: 3.160529, norm: 0.2746, time(ms): 801.61, token/sec:654045.49, hellaswag_acc: 0.2950
Step: 10455, loss: 3.125964, norm: 0.2953, time(ms): 803.68, token/sec:652359.19, hellaswag_acc: 0.2950
Step: 10456, loss: 3.205805, norm: 0.2815, time(ms): 796.26, token/sec:658436.52, hellaswag_acc: 0.2950
Step: 10457, loss: 3.178722, norm: 0.3016, time(ms): 797.29, token/sec:657585.74, hellaswag_acc: 0.2950
Step: 10458, loss: 3.169837, norm: 0.2460, time(ms): 806.43, token/sec:650133.12, hellaswag_acc: 0.2950
Step: 10459, loss: 3.131035, norm: 0.2771, time(ms): 799.99, token/sec:655368.05, hellaswag_acc: 0.2950
Step: 10460, loss: 3.209639, norm: 0.2745, time(ms): 791.12, token/sec:662717.70, hellaswag_acc: 0.2950
Step: 10461, loss: 3.124585, norm: 0.2734, time(ms): 807.90, token/sec:648950.30, hellaswag_acc: 0.2950
Step: 10462, loss: 3.181295, norm: 0.2623, time(ms): 801.82, token/sec:653871.24, hellaswag_acc: 0.2950
Step: 10463, loss: 3.156137, norm: 0.2696, time(ms): 790.04, token/sec:663625.69, hellaswag_acc: 0.2950
Step: 10464, loss: 3.110716, norm: 0.2652, time(ms): 800.89, token/sec:654632.14, hellaswag_acc: 0.2950
Step: 10465, loss: 3.182884, norm: 0.2727, time(ms): 808.01, token/sec:648866.43, hellaswag_acc: 0.2950
Step: 10466, loss: 3.218432, norm: 0.2707, time(ms): 792.02, token/sec:661960.42, hellaswag_acc: 0.2950
Step: 10467, loss: 3.205851, norm: 0.2703, time(ms): 799.19, token/sec:656020.67, hellaswag_acc: 0.2950
Step: 10468, loss: 3.160131, norm: 0.2823, time(ms): 808.05, token/sec:648827.37, hellaswag_acc: 0.2950
Step: 10469, loss: 3.173629, norm: 0.2946, time(ms): 800.75, token/sec:654745.97, hellaswag_acc: 0.2950
Step: 10470, loss: 3.199234, norm: 0.2979, time(ms): 795.77, token/sec:658839.75, hellaswag_acc: 0.2950
Step: 10471, loss: 3.155684, norm: 0.3177, time(ms): 795.92, token/sec:658716.40, hellaswag_acc: 0.2950
Step: 10472, loss: 3.148564, norm: 0.2896, time(ms): 806.18, token/sec:650337.88, hellaswag_acc: 0.2950
Step: 10473, loss: 3.142278, norm: 0.2894, time(ms): 801.94, token/sec:653775.60, hellaswag_acc: 0.2950
Step: 10474, loss: 3.292784, norm: 0.2907, time(ms): 789.30, token/sec:664242.09, hellaswag_acc: 0.2950
Step: 10475, loss: 3.213485, norm: 0.3040, time(ms): 801.55, token/sec:654094.13, hellaswag_acc: 0.2950
Step: 10476, loss: 3.209206, norm: 0.3030, time(ms): 805.35, token/sec:651007.31, hellaswag_acc: 0.2950
Step: 10477, loss: 3.186122, norm: 0.2849, time(ms): 1303.51, token/sec:402212.06, hellaswag_acc: 0.2950
Step: 10478, loss: 3.221443, norm: 0.2756, time(ms): 794.75, token/sec:659691.41, hellaswag_acc: 0.2950
Step: 10479, loss: 3.340702, norm: 0.3679, time(ms): 786.71, token/sec:666428.44, hellaswag_acc: 0.2950
Step: 10480, loss: 3.213234, norm: 0.3288, time(ms): 781.28, token/sec:671063.25, hellaswag_acc: 0.2950
Step: 10481, loss: 3.154588, norm: 0.3035, time(ms): 794.78, token/sec:659661.92, hellaswag_acc: 0.2950
Step: 10482, loss: 3.180268, norm: 0.3180, time(ms): 798.70, token/sec:656425.83, hellaswag_acc: 0.2950
Step: 10483, loss: 3.252506, norm: 0.3646, time(ms): 800.69, token/sec:654791.20, hellaswag_acc: 0.2950
Step: 10484, loss: 3.202626, norm: 0.2938, time(ms): 791.72, token/sec:662215.78, hellaswag_acc: 0.2950
Step: 10485, loss: 3.214686, norm: 0.3568, time(ms): 797.65, token/sec:657287.76, hellaswag_acc: 0.2950
Step: 10486, loss: 3.196075, norm: 0.2898, time(ms): 792.17, token/sec:661834.51, hellaswag_acc: 0.2950
Step: 10487, loss: 3.147644, norm: 0.3388, time(ms): 789.76, token/sec:663854.27, hellaswag_acc: 0.2950
Step: 10488, loss: 3.190086, norm: 0.2846, time(ms): 788.68, token/sec:664769.19, hellaswag_acc: 0.2950
Step: 10489, loss: 3.129726, norm: 0.2996, time(ms): 784.32, token/sec:668463.38, hellaswag_acc: 0.2950
Step: 10490, loss: 3.148509, norm: 0.2987, time(ms): 790.89, token/sec:662909.49, hellaswag_acc: 0.2950
Step: 10491, loss: 3.169077, norm: 0.2848, time(ms): 804.29, token/sec:651865.68, hellaswag_acc: 0.2950
Step: 10492, loss: 3.173732, norm: 0.2753, time(ms): 790.97, token/sec:662841.75, hellaswag_acc: 0.2950
Step: 10493, loss: 3.192259, norm: 0.3191, time(ms): 792.96, token/sec:661179.42, hellaswag_acc: 0.2950
Step: 10494, loss: 3.155591, norm: 0.2739, time(ms): 791.77, token/sec:662170.52, hellaswag_acc: 0.2950
Step: 10495, loss: 3.132209, norm: 0.2768, time(ms): 790.94, token/sec:662869.13, hellaswag_acc: 0.2950
Step: 10496, loss: 3.191172, norm: 0.2734, time(ms): 792.07, token/sec:661918.58, hellaswag_acc: 0.2950
Step: 10497, loss: 3.149311, norm: 0.2973, time(ms): 795.11, token/sec:659391.92, hellaswag_acc: 0.2950
Step: 10498, loss: 3.197447, norm: 0.2840, time(ms): 795.85, token/sec:658781.13, hellaswag_acc: 0.2950
Step: 10499, loss: 3.194495, norm: 0.2696, time(ms): 791.98, token/sec:661993.50, hellaswag_acc: 0.2950
rank 0 sample 0: Hello, I'm a language model, and I don't understand. But as there are lots of people there was something that's unique, it was a little
rank 0 sample 1: Hello, I'm a language model, I mean, I think, a picture of what one may be, when they're going to be more likely to have
rank 0 sample 2: Hello, I'm a language model, so I guess that's really simple, but actually I'm also thinking about how people actually understand language.
So my
rank 0 sample 3: Hello, I'm a language model, I believe that we can build our own, one step at a time. And even with our language model, it becomes
rank 1 sample 0: Hello, I'm a language model, in the languages of the world, "The only languages that speak the same language are languages from outside the world."

rank 1 sample 1: Hello, I'm a language model, not an artist. I'm a person. I'm looking for work that speaks another programming language like Java. I'm
rank 1 sample 2: Hello, I'm a language model, I used the
"O" type of the address in Python
and I'm using Python 2.1 to generate
rank 1 sample 3: Hello, I'm a language model, and I'm looking at everything I should post in my school, all around where I belong. It's a big,
Step: 10500, loss: 3.195275, norm: 0.2820, time(ms): 3807.58, token/sec:137696.00, val_loss: 3.1796, hellaswag_acc: 0.2950
Step: 10501, loss: 3.215126, norm: 0.2852, time(ms): 791.96, token/sec:662009.25, hellaswag_acc: 0.2950
Step: 10502, loss: 3.227897, norm: 0.2786, time(ms): 784.12, token/sec:668633.30, hellaswag_acc: 0.2950
Step: 10503, loss: 3.183954, norm: 0.2802, time(ms): 791.31, token/sec:662554.17, hellaswag_acc: 0.2950
Step: 10504, loss: 3.337368, norm: 0.3100, time(ms): 794.22, token/sec:660130.65, hellaswag_acc: 0.2950
Step: 10505, loss: 3.236398, norm: 0.2880, time(ms): 789.46, token/sec:664109.69, hellaswag_acc: 0.2950
Step: 10506, loss: 3.165540, norm: 0.2917, time(ms): 781.12, token/sec:671200.48, hellaswag_acc: 0.2950
Step: 10507, loss: 3.266536, norm: 0.3114, time(ms): 789.82, token/sec:663805.78, hellaswag_acc: 0.2950
Step: 10508, loss: 3.193029, norm: 0.2807, time(ms): 798.11, token/sec:656913.32, hellaswag_acc: 0.2950
Step: 10509, loss: 3.238563, norm: 0.2903, time(ms): 792.39, token/sec:661652.50, hellaswag_acc: 0.2950
Step: 10510, loss: 3.205920, norm: 0.3268, time(ms): 790.45, token/sec:663280.60, hellaswag_acc: 0.2950
Step: 10511, loss: 3.154597, norm: 0.3079, time(ms): 794.19, token/sec:660155.42, hellaswag_acc: 0.2950
Step: 10512, loss: 3.122764, norm: 0.3121, time(ms): 791.86, token/sec:662094.16, hellaswag_acc: 0.2950
Step: 10513, loss: 3.147870, norm: 0.2941, time(ms): 792.52, token/sec:661548.79, hellaswag_acc: 0.2950
Step: 10514, loss: 3.165917, norm: 0.2874, time(ms): 794.37, token/sec:660002.46, hellaswag_acc: 0.2950
Step: 10515, loss: 3.153434, norm: 0.2910, time(ms): 787.43, token/sec:665823.70, hellaswag_acc: 0.2950
Step: 10516, loss: 3.177673, norm: 0.2765, time(ms): 789.03, token/sec:664474.72, hellaswag_acc: 0.2950
Step: 10517, loss: 3.128957, norm: 0.2673, time(ms): 795.17, token/sec:659343.09, hellaswag_acc: 0.2950
Step: 10518, loss: 3.178710, norm: 0.2683, time(ms): 792.02, token/sec:661960.82, hellaswag_acc: 0.2950
Step: 10519, loss: 3.123567, norm: 0.2566, time(ms): 802.09, token/sec:653648.70, hellaswag_acc: 0.2950
Step: 10520, loss: 3.122467, norm: 0.2667, time(ms): 805.68, token/sec:650741.45, hellaswag_acc: 0.2950
Step: 10521, loss: 3.159068, norm: 0.2580, time(ms): 782.75, token/sec:669804.75, hellaswag_acc: 0.2950
Step: 10522, loss: 3.180740, norm: 0.2578, time(ms): 783.44, token/sec:669211.79, hellaswag_acc: 0.2950
Step: 10523, loss: 3.183937, norm: 0.2668, time(ms): 798.44, token/sec:656636.74, hellaswag_acc: 0.2950
Step: 10524, loss: 3.261619, norm: 0.2607, time(ms): 792.87, token/sec:661253.78, hellaswag_acc: 0.2950
Step: 10525, loss: 3.115272, norm: 0.2604, time(ms): 789.62, token/sec:663976.14, hellaswag_acc: 0.2950
Step: 10526, loss: 3.188354, norm: 0.2651, time(ms): 790.29, token/sec:663414.67, hellaswag_acc: 0.2950
Step: 10527, loss: 3.143206, norm: 0.2548, time(ms): 795.99, token/sec:658660.17, hellaswag_acc: 0.2950
Step: 10528, loss: 3.125920, norm: 0.2577, time(ms): 801.53, token/sec:654109.89, hellaswag_acc: 0.2950
Step: 10529, loss: 3.176103, norm: 0.2466, time(ms): 793.45, token/sec:660768.96, hellaswag_acc: 0.2950
Step: 10530, loss: 3.212519, norm: 0.2540, time(ms): 796.26, token/sec:658434.95, hellaswag_acc: 0.2950
Step: 10531, loss: 3.181311, norm: 0.2652, time(ms): 786.86, token/sec:666304.66, hellaswag_acc: 0.2950
Step: 10532, loss: 3.271236, norm: 0.2958, time(ms): 790.28, token/sec:663421.07, hellaswag_acc: 0.2950
Step: 10533, loss: 3.193541, norm: 0.2748, time(ms): 794.27, token/sec:660089.23, hellaswag_acc: 0.2950
Step: 10534, loss: 3.199258, norm: 0.2733, time(ms): 791.01, token/sec:662809.79, hellaswag_acc: 0.2950
Step: 10535, loss: 3.214455, norm: 0.2741, time(ms): 807.23, token/sec:649488.13, hellaswag_acc: 0.2950
Step: 10536, loss: 3.171268, norm: 0.2856, time(ms): 802.96, token/sec:652943.40, hellaswag_acc: 0.2950
Step: 10537, loss: 3.179488, norm: 0.2889, time(ms): 788.87, token/sec:664606.46, hellaswag_acc: 0.2950
Step: 10538, loss: 3.259401, norm: 0.2844, time(ms): 795.95, token/sec:658695.09, hellaswag_acc: 0.2950
Step: 10539, loss: 3.256386, norm: 0.3013, time(ms): 791.25, token/sec:662611.27, hellaswag_acc: 0.2950
Step: 10540, loss: 3.194860, norm: 0.3004, time(ms): 792.62, token/sec:661463.82, hellaswag_acc: 0.2950
Step: 10541, loss: 3.144388, norm: 0.2985, time(ms): 790.73, token/sec:663043.81, hellaswag_acc: 0.2950
Step: 10542, loss: 3.156372, norm: 0.3092, time(ms): 788.06, token/sec:665286.67, hellaswag_acc: 0.2950
Step: 10543, loss: 3.167222, norm: 0.2928, time(ms): 794.34, token/sec:660033.36, hellaswag_acc: 0.2950
Step: 10544, loss: 3.157997, norm: 0.2881, time(ms): 795.31, token/sec:659228.64, hellaswag_acc: 0.2950
Step: 10545, loss: 3.245975, norm: 0.2956, time(ms): 791.37, token/sec:662508.46, hellaswag_acc: 0.2950
Step: 10546, loss: 3.212124, norm: 0.2803, time(ms): 791.34, token/sec:662529.42, hellaswag_acc: 0.2950
Step: 10547, loss: 3.157498, norm: 0.2956, time(ms): 786.98, token/sec:666205.55, hellaswag_acc: 0.2950
Step: 10548, loss: 3.175152, norm: 0.2558, time(ms): 795.55, token/sec:659023.77, hellaswag_acc: 0.2950
Step: 10549, loss: 3.228348, norm: 0.3069, time(ms): 789.97, token/sec:663676.96, hellaswag_acc: 0.2950
Step: 10550, loss: 3.113897, norm: 0.2818, time(ms): 798.09, token/sec:656924.90, hellaswag_acc: 0.2950
Step: 10551, loss: 3.208103, norm: 0.2768, time(ms): 805.75, token/sec:650686.00, hellaswag_acc: 0.2950
Step: 10552, loss: 3.119931, norm: 0.2711, time(ms): 800.46, token/sec:654981.94, hellaswag_acc: 0.2950
Step: 10553, loss: 3.180724, norm: 0.2582, time(ms): 786.95, token/sec:666230.57, hellaswag_acc: 0.2950
Step: 10554, loss: 3.173293, norm: 0.2784, time(ms): 789.98, token/sec:663671.55, hellaswag_acc: 0.2950
Step: 10555, loss: 3.156780, norm: 0.2671, time(ms): 793.93, token/sec:660366.55, hellaswag_acc: 0.2950
Step: 10556, loss: 3.093395, norm: 0.2693, time(ms): 793.39, token/sec:660823.37, hellaswag_acc: 0.2950
Step: 10557, loss: 3.181562, norm: 0.2548, time(ms): 794.14, token/sec:660195.65, hellaswag_acc: 0.2950
Step: 10558, loss: 3.152774, norm: 0.2677, time(ms): 794.35, token/sec:660020.29, hellaswag_acc: 0.2950
Step: 10559, loss: 3.138477, norm: 0.2716, time(ms): 799.54, token/sec:655738.38, hellaswag_acc: 0.2950
Step: 10560, loss: 3.159927, norm: 0.2716, time(ms): 803.83, token/sec:652236.71, hellaswag_acc: 0.2950
Step: 10561, loss: 3.158660, norm: 0.2932, time(ms): 793.73, token/sec:660538.73, hellaswag_acc: 0.2950
Step: 10562, loss: 3.156864, norm: 0.2536, time(ms): 796.07, token/sec:658597.63, hellaswag_acc: 0.2950
Step: 10563, loss: 3.158732, norm: 0.2818, time(ms): 792.68, token/sec:661413.49, hellaswag_acc: 0.2950
Step: 10564, loss: 3.142487, norm: 0.2657, time(ms): 796.13, token/sec:658543.40, hellaswag_acc: 0.2950
Step: 10565, loss: 3.090143, norm: 0.2899, time(ms): 793.95, token/sec:660351.88, hellaswag_acc: 0.2950
Step: 10566, loss: 3.179669, norm: 0.3127, time(ms): 791.93, token/sec:662038.54, hellaswag_acc: 0.2950
Step: 10567, loss: 3.253730, norm: 0.3023, time(ms): 786.20, token/sec:666863.35, hellaswag_acc: 0.2950
Step: 10568, loss: 3.187235, norm: 0.3188, time(ms): 792.97, token/sec:661170.08, hellaswag_acc: 0.2950
Step: 10569, loss: 3.129873, norm: 0.2739, time(ms): 790.29, token/sec:663408.06, hellaswag_acc: 0.2950
Step: 10570, loss: 3.204114, norm: 0.3148, time(ms): 805.41, token/sec:650960.09, hellaswag_acc: 0.2950
Step: 10571, loss: 3.120115, norm: 0.2786, time(ms): 801.54, token/sec:654102.50, hellaswag_acc: 0.2950
Step: 10572, loss: 3.047889, norm: 0.3120, time(ms): 798.12, token/sec:656902.53, hellaswag_acc: 0.2950
Step: 10573, loss: 3.176810, norm: 0.3088, time(ms): 794.58, token/sec:659832.74, hellaswag_acc: 0.2950
Step: 10574, loss: 3.186391, norm: 0.3035, time(ms): 806.02, token/sec:650467.35, hellaswag_acc: 0.2950
Step: 10575, loss: 3.172464, norm: 0.3280, time(ms): 800.23, token/sec:655174.15, hellaswag_acc: 0.2950
Step: 10576, loss: 3.197189, norm: 0.3185, time(ms): 800.32, token/sec:655099.01, hellaswag_acc: 0.2950
Step: 10577, loss: 3.191547, norm: 0.3302, time(ms): 795.46, token/sec:659103.76, hellaswag_acc: 0.2950
Step: 10578, loss: 3.155086, norm: 0.3315, time(ms): 803.38, token/sec:652602.36, hellaswag_acc: 0.2950
Step: 10579, loss: 3.132531, norm: 0.2803, time(ms): 794.95, token/sec:659523.43, hellaswag_acc: 0.2950
Step: 10580, loss: 3.163543, norm: 0.3132, time(ms): 799.89, token/sec:655452.24, hellaswag_acc: 0.2950
Step: 10581, loss: 3.082786, norm: 0.2556, time(ms): 803.28, token/sec:652686.61, hellaswag_acc: 0.2950
Step: 10582, loss: 3.154976, norm: 0.3127, time(ms): 796.96, token/sec:657860.56, hellaswag_acc: 0.2950
Step: 10583, loss: 3.185834, norm: 0.2675, time(ms): 803.47, token/sec:652526.25, hellaswag_acc: 0.2950
Step: 10584, loss: 3.143049, norm: 0.2856, time(ms): 800.02, token/sec:655347.15, hellaswag_acc: 0.2950
Step: 10585, loss: 3.139970, norm: 0.2727, time(ms): 799.83, token/sec:655500.30, hellaswag_acc: 0.2950
Step: 10586, loss: 3.124297, norm: 0.2792, time(ms): 799.94, token/sec:655405.55, hellaswag_acc: 0.2950
Step: 10587, loss: 3.179048, norm: 0.2660, time(ms): 799.47, token/sec:655791.77, hellaswag_acc: 0.2950
Step: 10588, loss: 3.105784, norm: 0.2951, time(ms): 799.34, token/sec:655899.94, hellaswag_acc: 0.2950
Step: 10589, loss: 3.165939, norm: 0.2826, time(ms): 798.64, token/sec:656478.55, hellaswag_acc: 0.2950
Step: 10590, loss: 3.142783, norm: 0.3004, time(ms): 799.56, token/sec:655723.33, hellaswag_acc: 0.2950
Step: 10591, loss: 3.140188, norm: 0.2710, time(ms): 803.06, token/sec:652866.05, hellaswag_acc: 0.2950
Step: 10592, loss: 3.166426, norm: 0.2725, time(ms): 798.70, token/sec:656426.62, hellaswag_acc: 0.2950
Step: 10593, loss: 3.114628, norm: 0.3099, time(ms): 795.79, token/sec:658823.76, hellaswag_acc: 0.2950
Step: 10594, loss: 3.150524, norm: 0.2571, time(ms): 802.98, token/sec:652929.05, hellaswag_acc: 0.2950
Step: 10595, loss: 3.158036, norm: 0.2915, time(ms): 802.81, token/sec:653068.28, hellaswag_acc: 0.2950
Step: 10596, loss: 3.184708, norm: 0.2793, time(ms): 789.03, token/sec:664468.89, hellaswag_acc: 0.2950
Step: 10597, loss: 3.126722, norm: 0.2776, time(ms): 800.38, token/sec:655052.57, hellaswag_acc: 0.2950
Step: 10598, loss: 3.175808, norm: 0.2707, time(ms): 793.25, token/sec:660937.38, hellaswag_acc: 0.2950
Step: 10599, loss: 3.136719, norm: 0.2626, time(ms): 790.40, token/sec:663322.42, hellaswag_acc: 0.2950
Step: 10600, loss: 3.185163, norm: 0.2722, time(ms): 791.10, token/sec:662735.68, hellaswag_acc: 0.2950
Step: 10601, loss: 3.151452, norm: 0.2729, time(ms): 793.49, token/sec:660737.20, hellaswag_acc: 0.2950
Step: 10602, loss: 3.168799, norm: 0.2792, time(ms): 794.83, token/sec:659626.50, hellaswag_acc: 0.2950
Step: 10603, loss: 3.212854, norm: 0.2773, time(ms): 802.98, token/sec:652924.40, hellaswag_acc: 0.2950
Step: 10604, loss: 3.142417, norm: 0.3043, time(ms): 798.91, token/sec:656255.40, hellaswag_acc: 0.2950
Step: 10605, loss: 3.190621, norm: 0.2882, time(ms): 796.95, token/sec:657865.28, hellaswag_acc: 0.2950
Step: 10606, loss: 3.137131, norm: 0.3173, time(ms): 802.04, token/sec:653689.50, hellaswag_acc: 0.2950
Step: 10607, loss: 3.160480, norm: 0.2895, time(ms): 804.08, token/sec:652038.48, hellaswag_acc: 0.2950
Step: 10608, loss: 3.118966, norm: 0.3079, time(ms): 793.54, token/sec:660694.12, hellaswag_acc: 0.2950
Step: 10609, loss: 3.116570, norm: 0.3031, time(ms): 799.63, token/sec:655663.70, hellaswag_acc: 0.2950
Step: 10610, loss: 3.119861, norm: 0.2888, time(ms): 802.13, token/sec:653619.17, hellaswag_acc: 0.2950
Step: 10611, loss: 3.170970, norm: 0.2883, time(ms): 802.91, token/sec:652985.66, hellaswag_acc: 0.2950
Step: 10612, loss: 3.164111, norm: 0.2886, time(ms): 793.71, token/sec:660551.82, hellaswag_acc: 0.2950
Step: 10613, loss: 3.163786, norm: 0.2977, time(ms): 798.85, token/sec:656304.37, hellaswag_acc: 0.2950
Step: 10614, loss: 3.199545, norm: 0.2838, time(ms): 799.72, token/sec:655586.29, hellaswag_acc: 0.2950
Step: 10615, loss: 3.202867, norm: 0.2861, time(ms): 793.34, token/sec:660858.72, hellaswag_acc: 0.2950
Step: 10616, loss: 3.145813, norm: 0.2766, time(ms): 794.61, token/sec:659803.84, hellaswag_acc: 0.2950
Step: 10617, loss: 3.220143, norm: 0.2797, time(ms): 795.00, token/sec:659482.69, hellaswag_acc: 0.2950
Step: 10618, loss: 3.203373, norm: 0.2886, time(ms): 799.02, token/sec:656161.60, hellaswag_acc: 0.2950
Step: 10619, loss: 3.138670, norm: 0.2823, time(ms): 802.47, token/sec:653341.28, hellaswag_acc: 0.2950
Step: 10620, loss: 3.171537, norm: 0.2689, time(ms): 800.65, token/sec:654828.83, hellaswag_acc: 0.2950
Step: 10621, loss: 3.210739, norm: 0.3171, time(ms): 792.88, token/sec:661244.24, hellaswag_acc: 0.2950
Step: 10622, loss: 3.210759, norm: 0.2781, time(ms): 790.88, token/sec:662916.49, hellaswag_acc: 0.2950
Step: 10623, loss: 3.186084, norm: 0.2676, time(ms): 790.07, token/sec:663595.25, hellaswag_acc: 0.2950
Step: 10624, loss: 3.145343, norm: 0.2758, time(ms): 791.23, token/sec:662625.64, hellaswag_acc: 0.2950
Step: 10625, loss: 3.190362, norm: 0.2783, time(ms): 795.89, token/sec:658743.24, hellaswag_acc: 0.2950
Step: 10626, loss: 3.200130, norm: 0.2773, time(ms): 783.78, token/sec:668924.76, hellaswag_acc: 0.2950
Step: 10627, loss: 3.152968, norm: 0.2730, time(ms): 790.03, token/sec:663627.29, hellaswag_acc: 0.2950
Step: 10628, loss: 3.123031, norm: 0.2548, time(ms): 796.60, token/sec:658154.72, hellaswag_acc: 0.2950
Step: 10629, loss: 3.136668, norm: 0.2734, time(ms): 792.75, token/sec:661354.21, hellaswag_acc: 0.2950
Step: 10630, loss: 3.176313, norm: 0.2523, time(ms): 788.68, token/sec:664768.59, hellaswag_acc: 0.2950
Step: 10631, loss: 3.105713, norm: 0.2647, time(ms): 797.75, token/sec:657204.47, hellaswag_acc: 0.2950
Step: 10632, loss: 3.218232, norm: 0.2613, time(ms): 791.82, token/sec:662134.03, hellaswag_acc: 0.2950
Step: 10633, loss: 3.195877, norm: 0.2742, time(ms): 796.26, token/sec:658440.07, hellaswag_acc: 0.2950
Step: 10634, loss: 3.191254, norm: 0.2680, time(ms): 795.23, token/sec:659292.87, hellaswag_acc: 0.2950
Step: 10635, loss: 3.179717, norm: 0.2932, time(ms): 801.44, token/sec:654179.16, hellaswag_acc: 0.2950
Step: 10636, loss: 3.135279, norm: 0.2631, time(ms): 803.55, token/sec:652461.59, hellaswag_acc: 0.2950
Step: 10637, loss: 3.115676, norm: 0.2767, time(ms): 792.28, token/sec:661745.28, hellaswag_acc: 0.2950
Step: 10638, loss: 3.163467, norm: 0.2988, time(ms): 794.48, token/sec:659916.30, hellaswag_acc: 0.2950
Step: 10639, loss: 3.127672, norm: 0.2992, time(ms): 788.45, token/sec:664960.16, hellaswag_acc: 0.2950
Step: 10640, loss: 3.128691, norm: 0.2899, time(ms): 790.61, token/sec:663142.19, hellaswag_acc: 0.2950
Step: 10641, loss: 3.223375, norm: 0.2962, time(ms): 792.60, token/sec:661476.96, hellaswag_acc: 0.2950
Step: 10642, loss: 3.187741, norm: 0.3074, time(ms): 792.05, token/sec:661934.32, hellaswag_acc: 0.2950
Step: 10643, loss: 3.153179, norm: 0.2856, time(ms): 806.37, token/sec:650182.90, hellaswag_acc: 0.2950
Step: 10644, loss: 3.157701, norm: 0.2914, time(ms): 803.55, token/sec:652461.78, hellaswag_acc: 0.2950
Step: 10645, loss: 3.091823, norm: 0.2658, time(ms): 795.40, token/sec:659151.38, hellaswag_acc: 0.2950
Step: 10646, loss: 3.180887, norm: 0.2840, time(ms): 801.11, token/sec:654449.59, hellaswag_acc: 0.2950
Step: 10647, loss: 3.239219, norm: 0.2818, time(ms): 799.74, token/sec:655573.19, hellaswag_acc: 0.2950
Step: 10648, loss: 3.136758, norm: 0.3094, time(ms): 803.24, token/sec:652719.16, hellaswag_acc: 0.2950
Step: 10649, loss: 3.131606, norm: 0.2642, time(ms): 787.81, token/sec:665496.66, hellaswag_acc: 0.2950
Step: 10650, loss: 3.153579, norm: 0.2903, time(ms): 792.08, token/sec:661911.21, hellaswag_acc: 0.2950
Step: 10651, loss: 3.217722, norm: 0.2514, time(ms): 791.68, token/sec:662244.70, hellaswag_acc: 0.2950
Step: 10652, loss: 3.215927, norm: 0.3393, time(ms): 796.45, token/sec:658280.22, hellaswag_acc: 0.2950
Step: 10653, loss: 3.150964, norm: 0.2575, time(ms): 791.09, token/sec:662737.28, hellaswag_acc: 0.2950
Step: 10654, loss: 3.150725, norm: 0.3101, time(ms): 788.67, token/sec:664776.23, hellaswag_acc: 0.2950
Step: 10655, loss: 3.174884, norm: 0.2677, time(ms): 794.18, token/sec:660164.34, hellaswag_acc: 0.2950
Step: 10656, loss: 3.170317, norm: 0.2995, time(ms): 792.52, token/sec:661545.81, hellaswag_acc: 0.2950
Step: 10657, loss: 3.192328, norm: 0.2583, time(ms): 795.82, token/sec:658801.06, hellaswag_acc: 0.2950
Step: 10658, loss: 3.160470, norm: 0.2864, time(ms): 802.10, token/sec:653642.68, hellaswag_acc: 0.2950
Step: 10659, loss: 3.166871, norm: 0.2744, time(ms): 800.63, token/sec:654841.11, hellaswag_acc: 0.2950
Step: 10660, loss: 3.179393, norm: 0.2602, time(ms): 801.18, token/sec:654391.75, hellaswag_acc: 0.2950
Step: 10661, loss: 3.197083, norm: 0.3068, time(ms): 799.92, token/sec:655423.13, hellaswag_acc: 0.2950
Step: 10662, loss: 3.178577, norm: 0.2660, time(ms): 799.44, token/sec:655815.04, hellaswag_acc: 0.2950
Step: 10663, loss: 3.156515, norm: 0.2810, time(ms): 798.80, token/sec:656347.66, hellaswag_acc: 0.2950
Step: 10664, loss: 3.157580, norm: 0.2909, time(ms): 803.22, token/sec:652729.62, hellaswag_acc: 0.2950
Step: 10665, loss: 3.102408, norm: 0.2773, time(ms): 796.98, token/sec:657844.62, hellaswag_acc: 0.2950
Step: 10666, loss: 3.138755, norm: 0.2674, time(ms): 792.73, token/sec:661371.52, hellaswag_acc: 0.2950
Step: 10667, loss: 3.108103, norm: 0.2653, time(ms): 1323.33, token/sec:396189.21, hellaswag_acc: 0.2950
Step: 10668, loss: 3.124796, norm: 0.2625, time(ms): 771.34, token/sec:679707.58, hellaswag_acc: 0.2950
Step: 10669, loss: 3.138530, norm: 0.2652, time(ms): 794.66, token/sec:659761.08, hellaswag_acc: 0.2950
Step: 10670, loss: 3.139106, norm: 0.2901, time(ms): 798.89, token/sec:656273.22, hellaswag_acc: 0.2950
Step: 10671, loss: 3.194969, norm: 0.2922, time(ms): 790.12, token/sec:663552.80, hellaswag_acc: 0.2950
Step: 10672, loss: 3.131843, norm: 0.2998, time(ms): 790.84, token/sec:662953.46, hellaswag_acc: 0.2950
Step: 10673, loss: 3.160580, norm: 0.3125, time(ms): 788.59, token/sec:664846.37, hellaswag_acc: 0.2950
Step: 10674, loss: 3.134380, norm: 0.3107, time(ms): 791.26, token/sec:662601.68, hellaswag_acc: 0.2950
Step: 10675, loss: 3.171546, norm: 0.3023, time(ms): 789.34, token/sec:664207.78, hellaswag_acc: 0.2950
Step: 10676, loss: 3.205319, norm: 0.2974, time(ms): 790.92, token/sec:662880.72, hellaswag_acc: 0.2950
Step: 10677, loss: 3.169908, norm: 0.3200, time(ms): 790.51, token/sec:663227.99, hellaswag_acc: 0.2950
Step: 10678, loss: 3.171394, norm: 0.3146, time(ms): 800.97, token/sec:654565.11, hellaswag_acc: 0.2950
Step: 10679, loss: 3.096328, norm: 0.2836, time(ms): 806.03, token/sec:650456.96, hellaswag_acc: 0.2950
Step: 10680, loss: 3.097038, norm: 0.2701, time(ms): 792.44, token/sec:661612.49, hellaswag_acc: 0.2950
Step: 10681, loss: 3.100518, norm: 0.3064, time(ms): 794.44, token/sec:659950.56, hellaswag_acc: 0.2950
Step: 10682, loss: 3.122765, norm: 0.2776, time(ms): 793.35, token/sec:660856.54, hellaswag_acc: 0.2950
Step: 10683, loss: 3.055215, norm: 0.3075, time(ms): 796.31, token/sec:658398.48, hellaswag_acc: 0.2950
Step: 10684, loss: 3.075810, norm: 0.2706, time(ms): 800.36, token/sec:655063.30, hellaswag_acc: 0.2950
Step: 10685, loss: 3.086032, norm: 0.2999, time(ms): 803.73, token/sec:652316.43, hellaswag_acc: 0.2950
Step: 10686, loss: 3.100754, norm: 0.2695, time(ms): 788.54, token/sec:664880.55, hellaswag_acc: 0.2950
Step: 10687, loss: 3.039048, norm: 0.3124, time(ms): 787.81, token/sec:665497.67, hellaswag_acc: 0.2950
Step: 10688, loss: 3.128834, norm: 0.2833, time(ms): 791.90, token/sec:662063.06, hellaswag_acc: 0.2950
Step: 10689, loss: 3.111578, norm: 0.3164, time(ms): 793.96, token/sec:660346.52, hellaswag_acc: 0.2950
Step: 10690, loss: 3.092894, norm: 0.2956, time(ms): 787.77, token/sec:665536.14, hellaswag_acc: 0.2950
Step: 10691, loss: 3.280396, norm: 0.3199, time(ms): 802.95, token/sec:652956.19, hellaswag_acc: 0.2950
Step: 10692, loss: 3.216071, norm: 0.3417, time(ms): 804.72, token/sec:651516.31, hellaswag_acc: 0.2950
Step: 10693, loss: 3.201563, norm: 0.3276, time(ms): 801.61, token/sec:654044.91, hellaswag_acc: 0.2950
Step: 10694, loss: 3.205792, norm: 0.4570, time(ms): 792.11, token/sec:661889.29, hellaswag_acc: 0.2950
Step: 10695, loss: 3.191504, norm: 0.3284, time(ms): 804.02, token/sec:652083.15, hellaswag_acc: 0.2950
Step: 10696, loss: 3.240721, norm: 0.3113, time(ms): 803.70, token/sec:652339.84, hellaswag_acc: 0.2950
Step: 10697, loss: 3.212362, norm: 0.3224, time(ms): 794.21, token/sec:660138.58, hellaswag_acc: 0.2950
Step: 10698, loss: 3.201560, norm: 0.3105, time(ms): 800.97, token/sec:654566.86, hellaswag_acc: 0.2950
Step: 10699, loss: 3.209943, norm: 0.3178, time(ms): 801.13, token/sec:654436.15, hellaswag_acc: 0.2950
Step: 10700, loss: 3.199162, norm: 0.3161, time(ms): 802.97, token/sec:652937.97, hellaswag_acc: 0.2950
Step: 10701, loss: 3.205304, norm: 0.3710, time(ms): 787.13, token/sec:666077.61, hellaswag_acc: 0.2950
Step: 10702, loss: 3.170242, norm: 0.3316, time(ms): 790.56, token/sec:663188.18, hellaswag_acc: 0.2950
Step: 10703, loss: 3.179841, norm: 0.3085, time(ms): 795.46, token/sec:659098.23, hellaswag_acc: 0.2950
Step: 10704, loss: 3.155916, norm: 0.2761, time(ms): 790.84, token/sec:662951.86, hellaswag_acc: 0.2950
Step: 10705, loss: 3.152980, norm: 0.3042, time(ms): 794.79, token/sec:659656.38, hellaswag_acc: 0.2950
Step: 10706, loss: 3.146163, norm: 0.2797, time(ms): 790.44, token/sec:663285.40, hellaswag_acc: 0.2950
Step: 10707, loss: 3.129015, norm: 0.2827, time(ms): 796.09, token/sec:658581.07, hellaswag_acc: 0.2950
Step: 10708, loss: 3.159904, norm: 0.2974, time(ms): 792.43, token/sec:661618.66, hellaswag_acc: 0.2950
Step: 10709, loss: 3.165207, norm: 0.2721, time(ms): 789.14, token/sec:664376.95, hellaswag_acc: 0.2950
Step: 10710, loss: 3.099165, norm: 0.2743, time(ms): 788.23, token/sec:665146.41, hellaswag_acc: 0.2950
Step: 10711, loss: 3.166134, norm: 0.2748, time(ms): 790.77, token/sec:663010.23, hellaswag_acc: 0.2950
Step: 10712, loss: 3.136733, norm: 0.2611, time(ms): 791.24, token/sec:662619.25, hellaswag_acc: 0.2950
Step: 10713, loss: 3.123819, norm: 0.2796, time(ms): 799.73, token/sec:655581.60, hellaswag_acc: 0.2950
Step: 10714, loss: 3.115671, norm: 0.2709, time(ms): 799.07, token/sec:656125.78, hellaswag_acc: 0.2950
Step: 10715, loss: 3.113662, norm: 0.2694, time(ms): 797.89, token/sec:657089.79, hellaswag_acc: 0.2950
Step: 10716, loss: 3.105966, norm: 0.2542, time(ms): 801.54, token/sec:654103.66, hellaswag_acc: 0.2950
Step: 10717, loss: 3.138757, norm: 0.2855, time(ms): 800.96, token/sec:654574.07, hellaswag_acc: 0.2950
Step: 10718, loss: 3.144535, norm: 0.2932, time(ms): 794.76, token/sec:659684.48, hellaswag_acc: 0.2950
Step: 10719, loss: 3.084428, norm: 0.2744, time(ms): 804.35, token/sec:651814.48, hellaswag_acc: 0.2950
Step: 10720, loss: 3.050204, norm: 0.2740, time(ms): 797.75, token/sec:657209.97, hellaswag_acc: 0.2950
Step: 10721, loss: 3.090321, norm: 0.2521, time(ms): 800.90, token/sec:654623.56, hellaswag_acc: 0.2950
Step: 10722, loss: 3.114145, norm: 0.2750, time(ms): 799.44, token/sec:655816.80, hellaswag_acc: 0.2950
Step: 10723, loss: 3.159460, norm: 0.2688, time(ms): 800.53, token/sec:654923.22, hellaswag_acc: 0.2950
Step: 10724, loss: 3.104687, norm: 0.2512, time(ms): 799.79, token/sec:655528.25, hellaswag_acc: 0.2950
Step: 10725, loss: 3.091845, norm: 0.2576, time(ms): 795.76, token/sec:658851.59, hellaswag_acc: 0.2950
Step: 10726, loss: 3.081212, norm: 0.2856, time(ms): 800.81, token/sec:654693.53, hellaswag_acc: 0.2950
Step: 10727, loss: 3.166327, norm: 0.2798, time(ms): 804.04, token/sec:652070.77, hellaswag_acc: 0.2950
Step: 10728, loss: 3.182526, norm: 0.2905, time(ms): 796.88, token/sec:657926.89, hellaswag_acc: 0.2950
Step: 10729, loss: 3.175560, norm: 0.2933, time(ms): 794.86, token/sec:659598.01, hellaswag_acc: 0.2950
Step: 10730, loss: 3.171687, norm: 0.2785, time(ms): 806.38, token/sec:650177.90, hellaswag_acc: 0.2950
Step: 10731, loss: 3.150252, norm: 0.2896, time(ms): 802.06, token/sec:653675.71, hellaswag_acc: 0.2950
Step: 10732, loss: 3.226310, norm: 0.2829, time(ms): 783.75, token/sec:668948.98, hellaswag_acc: 0.2950
Step: 10733, loss: 3.208455, norm: 0.2846, time(ms): 789.92, token/sec:663726.04, hellaswag_acc: 0.2950
Step: 10734, loss: 3.203521, norm: 0.2811, time(ms): 794.45, token/sec:659939.67, hellaswag_acc: 0.2950
Step: 10735, loss: 3.152241, norm: 0.2709, time(ms): 793.00, token/sec:661142.25, hellaswag_acc: 0.2950
Step: 10736, loss: 3.199658, norm: 0.2783, time(ms): 791.28, token/sec:662583.92, hellaswag_acc: 0.2950
Step: 10737, loss: 3.188126, norm: 0.2754, time(ms): 802.67, token/sec:653178.26, hellaswag_acc: 0.2950
Step: 10738, loss: 3.227323, norm: 0.2762, time(ms): 800.05, token/sec:655316.10, hellaswag_acc: 0.2950
Step: 10739, loss: 3.146633, norm: 0.2958, time(ms): 802.68, token/sec:653172.64, hellaswag_acc: 0.2950
Step: 10740, loss: 3.148531, norm: 0.3022, time(ms): 791.09, token/sec:662741.07, hellaswag_acc: 0.2950
Step: 10741, loss: 3.169532, norm: 0.2579, time(ms): 798.83, token/sec:656323.95, hellaswag_acc: 0.2950
Step: 10742, loss: 3.135644, norm: 0.2964, time(ms): 794.07, token/sec:660254.33, hellaswag_acc: 0.2950
Step: 10743, loss: 3.118747, norm: 0.2595, time(ms): 795.02, token/sec:659468.05, hellaswag_acc: 0.2950
Step: 10744, loss: 3.128973, norm: 0.2669, time(ms): 786.50, token/sec:666612.89, hellaswag_acc: 0.2950
Step: 10745, loss: 3.138542, norm: 0.2927, time(ms): 786.08, token/sec:666961.65, hellaswag_acc: 0.2950
Step: 10746, loss: 3.191094, norm: 0.2693, time(ms): 800.90, token/sec:654623.17, hellaswag_acc: 0.2950
Step: 10747, loss: 3.119330, norm: 0.2876, time(ms): 789.98, token/sec:663675.36, hellaswag_acc: 0.2950
Step: 10748, loss: 3.136827, norm: 0.2590, time(ms): 789.00, token/sec:664500.82, hellaswag_acc: 0.2950
Step: 10749, loss: 3.169149, norm: 0.2786, time(ms): 793.69, token/sec:660567.50, hellaswag_acc: 0.2950
rank 0 sample 0: Hello, I'm a language model, and I am a computer programming professional. Let's say I have 5 programming tasks. One is,
A.I
rank 0 sample 1: Hello, I'm a language model, so how do I know if the right answer? For starters, we see it in English. But also in Italian,
rank 0 sample 2: Hello, I'm a language model, so I had the grammar but I wasn't even able to figure this out. I had a lot of grammar, and
rank 0 sample 3: Hello, I'm a language model, but we're all trying to make a point which is true in real life and if you take the examples of people as
rank 1 sample 0: Hello, I'm a language model, my computer makes a program that reads or executes something on me, and I try to get my work done, but I
rank 1 sample 1: Hello, I'm a language model, not an expert in the field. That's why I came up with this blog. "Not necessarily. I'm a
rank 1 sample 2: Hello, I'm a language model, but do you mean that?
I'm a language model I know how to use. That I have to have native
rank 1 sample 3: Hello, I'm a language model, not a language
- Why are language interfaces important? Languages are abstract. Each language on the internet is a separate language
Step: 10750, loss: 3.116160, norm: 0.2530, time(ms): 3798.84, token/sec:138012.78, val_loss: 3.1727, hellaswag_acc: 0.2950
Step: 10751, loss: 3.037515, norm: 0.2838, time(ms): 783.39, token/sec:669252.12, hellaswag_acc: 0.2950
Step: 10752, loss: 3.145843, norm: 0.2761, time(ms): 791.18, token/sec:662663.38, hellaswag_acc: 0.2950
Step: 10753, loss: 3.099028, norm: 0.2518, time(ms): 791.00, token/sec:662820.18, hellaswag_acc: 0.2950
Step: 10754, loss: 3.095813, norm: 0.2641, time(ms): 806.76, token/sec:649872.20, hellaswag_acc: 0.2950
Step: 10755, loss: 3.103132, norm: 0.2730, time(ms): 792.60, token/sec:661477.95, hellaswag_acc: 0.2950
Step: 10756, loss: 3.104161, norm: 0.2422, time(ms): 792.40, token/sec:661643.94, hellaswag_acc: 0.2950
Step: 10757, loss: 3.084793, norm: 0.2798, time(ms): 791.96, token/sec:662015.82, hellaswag_acc: 0.2950
Step: 10758, loss: 3.084552, norm: 0.2478, time(ms): 797.63, token/sec:657311.14, hellaswag_acc: 0.2950
Step: 10759, loss: 3.099036, norm: 0.2936, time(ms): 799.32, token/sec:655916.76, hellaswag_acc: 0.2950
Step: 10760, loss: 3.112016, norm: 0.2832, time(ms): 792.10, token/sec:661897.06, hellaswag_acc: 0.2950
Step: 10761, loss: 3.120764, norm: 0.2725, time(ms): 787.03, token/sec:666156.71, hellaswag_acc: 0.2950
Step: 10762, loss: 3.137300, norm: 0.2864, time(ms): 791.26, token/sec:662595.30, hellaswag_acc: 0.2950
Step: 10763, loss: 3.186889, norm: 0.2770, time(ms): 790.95, token/sec:662857.94, hellaswag_acc: 0.2950
Step: 10764, loss: 3.177578, norm: 0.3233, time(ms): 800.54, token/sec:654918.34, hellaswag_acc: 0.2950
Step: 10765, loss: 3.238986, norm: 0.2782, time(ms): 803.82, token/sec:652248.71, hellaswag_acc: 0.2950
Step: 10766, loss: 3.191292, norm: 0.3069, time(ms): 795.62, token/sec:658969.66, hellaswag_acc: 0.2950
Step: 10767, loss: 3.194667, norm: 0.2751, time(ms): 802.82, token/sec:653057.80, hellaswag_acc: 0.2950
Step: 10768, loss: 3.213935, norm: 0.2918, time(ms): 793.21, token/sec:660966.78, hellaswag_acc: 0.2950
Step: 10769, loss: 3.193443, norm: 0.3001, time(ms): 808.00, token/sec:648868.73, hellaswag_acc: 0.2950
Step: 10770, loss: 3.197176, norm: 0.2777, time(ms): 800.13, token/sec:655251.46, hellaswag_acc: 0.2950
Step: 10771, loss: 3.127153, norm: 0.2782, time(ms): 790.07, token/sec:663594.25, hellaswag_acc: 0.2950
Step: 10772, loss: 3.279811, norm: 0.3019, time(ms): 806.30, token/sec:650236.73, hellaswag_acc: 0.2950
Step: 10773, loss: 3.189014, norm: 0.2895, time(ms): 803.06, token/sec:652865.28, hellaswag_acc: 0.2950
Step: 10774, loss: 3.174260, norm: 0.3013, time(ms): 796.29, token/sec:658412.67, hellaswag_acc: 0.2950
Step: 10775, loss: 3.130166, norm: 0.2809, time(ms): 797.87, token/sec:657107.46, hellaswag_acc: 0.2950
Step: 10776, loss: 3.133432, norm: 0.2895, time(ms): 802.95, token/sec:652948.24, hellaswag_acc: 0.2950
Step: 10777, loss: 3.141107, norm: 0.2841, time(ms): 802.55, token/sec:653276.64, hellaswag_acc: 0.2950
Step: 10778, loss: 3.186196, norm: 0.2878, time(ms): 789.26, token/sec:664281.82, hellaswag_acc: 0.2950
Step: 10779, loss: 3.163574, norm: 0.3265, time(ms): 801.12, token/sec:654446.67, hellaswag_acc: 0.2950
Step: 10780, loss: 3.136865, norm: 0.2719, time(ms): 807.80, token/sec:649032.85, hellaswag_acc: 0.2950
Step: 10781, loss: 3.110170, norm: 0.2866, time(ms): 796.54, token/sec:658209.68, hellaswag_acc: 0.2950
Step: 10782, loss: 3.192179, norm: 0.3126, time(ms): 794.36, token/sec:660014.35, hellaswag_acc: 0.2950
Step: 10783, loss: 3.138895, norm: 0.2596, time(ms): 804.78, token/sec:651465.55, hellaswag_acc: 0.2950
Step: 10784, loss: 3.162805, norm: 0.3137, time(ms): 804.74, token/sec:651502.03, hellaswag_acc: 0.2950
Step: 10785, loss: 3.099218, norm: 0.2582, time(ms): 790.39, token/sec:663331.02, hellaswag_acc: 0.2950
Step: 10786, loss: 3.100556, norm: 0.3092, time(ms): 799.24, token/sec:655979.37, hellaswag_acc: 0.2950
Step: 10787, loss: 3.079132, norm: 0.2909, time(ms): 804.45, token/sec:651737.98, hellaswag_acc: 0.2950
Step: 10788, loss: 3.080042, norm: 0.2740, time(ms): 805.93, token/sec:650540.09, hellaswag_acc: 0.2950
Step: 10789, loss: 3.146873, norm: 0.3197, time(ms): 788.32, token/sec:665072.18, hellaswag_acc: 0.2950
Step: 10790, loss: 3.058006, norm: 0.2642, time(ms): 795.82, token/sec:658805.01, hellaswag_acc: 0.2950
Step: 10791, loss: 3.129800, norm: 0.3387, time(ms): 793.44, token/sec:660780.68, hellaswag_acc: 0.2950
Step: 10792, loss: 3.089369, norm: 0.3323, time(ms): 790.87, token/sec:662927.08, hellaswag_acc: 0.2950
Step: 10793, loss: 3.064193, norm: 0.3054, time(ms): 790.82, token/sec:662969.85, hellaswag_acc: 0.2950
Step: 10794, loss: 3.100867, norm: 0.3374, time(ms): 796.04, token/sec:658620.12, hellaswag_acc: 0.2950
Step: 10795, loss: 3.072974, norm: 0.3382, time(ms): 797.17, token/sec:657687.42, hellaswag_acc: 0.2950
Step: 10796, loss: 3.110189, norm: 0.3192, time(ms): 800.19, token/sec:655207.93, hellaswag_acc: 0.2950
Step: 10797, loss: 3.148495, norm: 0.3282, time(ms): 804.80, token/sec:651451.07, hellaswag_acc: 0.2950
Step: 10798, loss: 3.193244, norm: 0.3210, time(ms): 790.81, token/sec:662975.05, hellaswag_acc: 0.2950
Step: 10799, loss: 3.248204, norm: 0.3218, time(ms): 797.05, token/sec:657784.01, hellaswag_acc: 0.2950
Step: 10800, loss: 3.224093, norm: 0.3214, time(ms): 791.40, token/sec:662478.92, hellaswag_acc: 0.2950
Step: 10801, loss: 3.208867, norm: 0.2958, time(ms): 799.34, token/sec:655905.02, hellaswag_acc: 0.2950
Step: 10802, loss: 3.163237, norm: 0.3299, time(ms): 790.35, token/sec:663358.63, hellaswag_acc: 0.2950
Step: 10803, loss: 3.204410, norm: 0.2820, time(ms): 788.30, token/sec:665084.45, hellaswag_acc: 0.2950
Step: 10804, loss: 3.213200, norm: 0.2983, time(ms): 791.89, token/sec:662068.24, hellaswag_acc: 0.2950
Step: 10805, loss: 3.206717, norm: 0.2868, time(ms): 796.49, token/sec:658247.51, hellaswag_acc: 0.2950
Step: 10806, loss: 3.174885, norm: 0.2895, time(ms): 790.17, token/sec:663514.55, hellaswag_acc: 0.2950
Step: 10807, loss: 3.215848, norm: 0.2898, time(ms): 796.91, token/sec:657901.30, hellaswag_acc: 0.2950
Step: 10808, loss: 3.197292, norm: 0.3024, time(ms): 804.58, token/sec:651627.13, hellaswag_acc: 0.2950
Step: 10809, loss: 3.082276, norm: 0.2920, time(ms): 801.49, token/sec:654143.16, hellaswag_acc: 0.2950
Step: 10810, loss: 3.125560, norm: 0.2822, time(ms): 789.60, token/sec:663993.39, hellaswag_acc: 0.2950
Step: 10811, loss: 3.141951, norm: 0.2768, time(ms): 805.68, token/sec:650737.79, hellaswag_acc: 0.2950
Step: 10812, loss: 3.186646, norm: 0.2755, time(ms): 803.94, token/sec:652145.22, hellaswag_acc: 0.2950
Step: 10813, loss: 3.157071, norm: 0.2810, time(ms): 796.28, token/sec:658418.98, hellaswag_acc: 0.2950
Step: 10814, loss: 3.184052, norm: 0.2839, time(ms): 801.98, token/sec:653744.31, hellaswag_acc: 0.2950
Step: 10815, loss: 3.132004, norm: 0.2816, time(ms): 795.70, token/sec:658900.75, hellaswag_acc: 0.2950
Step: 10816, loss: 3.196606, norm: 0.2717, time(ms): 804.21, token/sec:651928.11, hellaswag_acc: 0.2950
Step: 10817, loss: 3.128492, norm: 0.2935, time(ms): 795.83, token/sec:658795.93, hellaswag_acc: 0.2950
Step: 10818, loss: 3.133021, norm: 0.2895, time(ms): 803.83, token/sec:652233.81, hellaswag_acc: 0.2950
Step: 10819, loss: 3.139096, norm: 0.2840, time(ms): 796.96, token/sec:657856.03, hellaswag_acc: 0.2950
Step: 10820, loss: 3.151484, norm: 0.2563, time(ms): 802.81, token/sec:653063.23, hellaswag_acc: 0.2950
Step: 10821, loss: 3.135598, norm: 0.2875, time(ms): 799.44, token/sec:655819.74, hellaswag_acc: 0.2950
Step: 10822, loss: 3.144533, norm: 0.2724, time(ms): 800.11, token/sec:655271.96, hellaswag_acc: 0.2950
Step: 10823, loss: 3.045868, norm: 0.2661, time(ms): 799.35, token/sec:655890.94, hellaswag_acc: 0.2950
Step: 10824, loss: 3.010534, norm: 0.2656, time(ms): 801.70, token/sec:653969.83, hellaswag_acc: 0.2950
Step: 10825, loss: 3.073213, norm: 0.2847, time(ms): 793.70, token/sec:660565.71, hellaswag_acc: 0.2950
Step: 10826, loss: 3.063278, norm: 0.2576, time(ms): 802.92, token/sec:652976.75, hellaswag_acc: 0.2950
Step: 10827, loss: 3.120812, norm: 0.2521, time(ms): 802.61, token/sec:653227.35, hellaswag_acc: 0.2950
Step: 10828, loss: 3.102694, norm: 0.2905, time(ms): 798.42, token/sec:656653.80, hellaswag_acc: 0.2950
Step: 10829, loss: 3.135871, norm: 0.2523, time(ms): 792.48, token/sec:661577.26, hellaswag_acc: 0.2950
Step: 10830, loss: 3.114901, norm: 0.2681, time(ms): 802.46, token/sec:653348.65, hellaswag_acc: 0.2950
Step: 10831, loss: 3.059155, norm: 0.2644, time(ms): 805.85, token/sec:650601.68, hellaswag_acc: 0.2950
Step: 10832, loss: 3.077733, norm: 0.2670, time(ms): 792.75, token/sec:661352.82, hellaswag_acc: 0.2950
Step: 10833, loss: 3.176845, norm: 0.2675, time(ms): 800.68, token/sec:654803.48, hellaswag_acc: 0.2950
Step: 10834, loss: 3.186921, norm: 0.2982, time(ms): 805.97, token/sec:650508.33, hellaswag_acc: 0.2950
Step: 10835, loss: 3.156013, norm: 0.3023, time(ms): 797.34, token/sec:657547.00, hellaswag_acc: 0.2950
Step: 10836, loss: 3.171723, norm: 0.2776, time(ms): 794.28, token/sec:660083.49, hellaswag_acc: 0.2950
Step: 10837, loss: 3.187581, norm: 0.2703, time(ms): 807.41, token/sec:649346.97, hellaswag_acc: 0.2950
Step: 10838, loss: 3.182725, norm: 0.2812, time(ms): 801.61, token/sec:654040.63, hellaswag_acc: 0.2950
Step: 10839, loss: 3.158566, norm: 0.2916, time(ms): 790.92, token/sec:662883.71, hellaswag_acc: 0.2950
Step: 10840, loss: 3.156463, norm: 0.3025, time(ms): 798.93, token/sec:656235.23, hellaswag_acc: 0.2950
Step: 10841, loss: 3.264891, norm: 0.2755, time(ms): 808.50, token/sec:648469.20, hellaswag_acc: 0.2950
Step: 10842, loss: 3.225580, norm: 0.2794, time(ms): 791.77, token/sec:662170.32, hellaswag_acc: 0.2950
Step: 10843, loss: 3.241401, norm: 0.2630, time(ms): 803.33, token/sec:652645.94, hellaswag_acc: 0.2950
Step: 10844, loss: 3.178018, norm: 0.2777, time(ms): 803.47, token/sec:652529.74, hellaswag_acc: 0.2950
Step: 10845, loss: 3.155941, norm: 0.2804, time(ms): 801.35, token/sec:654257.41, hellaswag_acc: 0.2950
Step: 10846, loss: 3.109874, norm: 0.2632, time(ms): 794.46, token/sec:659927.99, hellaswag_acc: 0.2950
Step: 10847, loss: 3.112372, norm: 0.2629, time(ms): 797.80, token/sec:657170.30, hellaswag_acc: 0.2950
Step: 10848, loss: 3.154071, norm: 0.2634, time(ms): 804.82, token/sec:651436.21, hellaswag_acc: 0.2950
Step: 10849, loss: 3.156931, norm: 0.2580, time(ms): 801.60, token/sec:654049.58, hellaswag_acc: 0.2950
Step: 10850, loss: 3.151531, norm: 0.2548, time(ms): 791.02, token/sec:662802.00, hellaswag_acc: 0.2950
Step: 10851, loss: 3.178614, norm: 0.2649, time(ms): 802.89, token/sec:653003.89, hellaswag_acc: 0.2950
Step: 10852, loss: 3.146181, norm: 0.2513, time(ms): 805.92, token/sec:650549.13, hellaswag_acc: 0.2950
Step: 10853, loss: 3.152760, norm: 0.2553, time(ms): 796.31, token/sec:658399.07, hellaswag_acc: 0.2950
Step: 10854, loss: 3.110407, norm: 0.2437, time(ms): 798.50, token/sec:656595.18, hellaswag_acc: 0.2950
Step: 10855, loss: 3.156593, norm: 0.2523, time(ms): 803.61, token/sec:652419.39, hellaswag_acc: 0.2950
Step: 10856, loss: 3.128538, norm: 0.2553, time(ms): 796.02, token/sec:658640.64, hellaswag_acc: 0.2950
Step: 10857, loss: 3.102245, norm: 0.2377, time(ms): 805.26, token/sec:651076.31, hellaswag_acc: 0.2950
Step: 10858, loss: 3.137166, norm: 0.2615, time(ms): 1341.86, token/sec:390717.83, hellaswag_acc: 0.2950
Step: 10859, loss: 3.205718, norm: 0.2843, time(ms): 789.68, token/sec:663924.02, hellaswag_acc: 0.2950
Step: 10860, loss: 3.196106, norm: 0.2763, time(ms): 802.16, token/sec:653597.80, hellaswag_acc: 0.2950
Step: 10861, loss: 3.203563, norm: 0.2862, time(ms): 795.91, token/sec:658728.24, hellaswag_acc: 0.2950
Step: 10862, loss: 3.187357, norm: 0.2817, time(ms): 790.57, token/sec:663178.78, hellaswag_acc: 0.2950
Step: 10863, loss: 3.195838, norm: 0.2939, time(ms): 792.26, token/sec:661766.39, hellaswag_acc: 0.2950
Step: 10864, loss: 3.190018, norm: 0.2601, time(ms): 793.05, token/sec:661100.71, hellaswag_acc: 0.2950
Step: 10865, loss: 3.353887, norm: 0.4055, time(ms): 792.31, token/sec:661718.40, hellaswag_acc: 0.2950
Step: 10866, loss: 3.158735, norm: 0.3684, time(ms): 794.62, token/sec:659796.12, hellaswag_acc: 0.2950
Step: 10867, loss: 3.184085, norm: 0.2980, time(ms): 803.81, token/sec:652256.06, hellaswag_acc: 0.2950
Step: 10868, loss: 3.207388, norm: 0.3117, time(ms): 798.24, token/sec:656804.43, hellaswag_acc: 0.2950
Step: 10869, loss: 3.188596, norm: 0.2876, time(ms): 801.83, token/sec:653862.69, hellaswag_acc: 0.2950
Step: 10870, loss: 3.185248, norm: 0.2968, time(ms): 799.83, token/sec:655497.37, hellaswag_acc: 0.2950
Step: 10871, loss: 3.190353, norm: 0.2942, time(ms): 800.51, token/sec:654941.75, hellaswag_acc: 0.2950
Step: 10872, loss: 3.169120, norm: 0.2707, time(ms): 799.10, token/sec:656097.00, hellaswag_acc: 0.2950
Step: 10873, loss: 3.143576, norm: 0.3177, time(ms): 799.92, token/sec:655425.28, hellaswag_acc: 0.2950
Step: 10874, loss: 3.193904, norm: 0.2902, time(ms): 799.32, token/sec:655915.00, hellaswag_acc: 0.2950
Step: 10875, loss: 3.198989, norm: 0.2862, time(ms): 800.47, token/sec:654977.65, hellaswag_acc: 0.2950
Step: 10876, loss: 3.185169, norm: 0.2924, time(ms): 795.82, token/sec:658802.05, hellaswag_acc: 0.2950
Step: 10877, loss: 3.215998, norm: 0.2873, time(ms): 803.66, token/sec:652375.64, hellaswag_acc: 0.2950
Step: 10878, loss: 3.199278, norm: 0.2825, time(ms): 800.27, token/sec:655134.92, hellaswag_acc: 0.2950
Step: 10879, loss: 3.149244, norm: 0.2628, time(ms): 796.20, token/sec:658484.43, hellaswag_acc: 0.2950
Step: 10880, loss: 3.118129, norm: 0.2820, time(ms): 803.05, token/sec:652870.31, hellaswag_acc: 0.2950
Step: 10881, loss: 3.156950, norm: 0.2628, time(ms): 801.48, token/sec:654146.86, hellaswag_acc: 0.2950
Step: 10882, loss: 3.129300, norm: 0.3015, time(ms): 792.25, token/sec:661774.96, hellaswag_acc: 0.2950
Step: 10883, loss: 3.130788, norm: 0.2936, time(ms): 801.45, token/sec:654175.47, hellaswag_acc: 0.2950
Step: 10884, loss: 3.107626, norm: 0.2823, time(ms): 804.83, token/sec:651425.79, hellaswag_acc: 0.2950
Step: 10885, loss: 3.102162, norm: 0.2709, time(ms): 791.80, token/sec:662144.40, hellaswag_acc: 0.2950
Step: 10886, loss: 3.176781, norm: 0.2852, time(ms): 804.55, token/sec:651651.26, hellaswag_acc: 0.2950
Step: 10887, loss: 3.174664, norm: 0.2759, time(ms): 803.92, token/sec:652165.53, hellaswag_acc: 0.2950
Step: 10888, loss: 3.159713, norm: 0.2669, time(ms): 792.55, token/sec:661521.13, hellaswag_acc: 0.2950
Step: 10889, loss: 3.126894, norm: 0.2698, time(ms): 798.87, token/sec:656285.56, hellaswag_acc: 0.2950
Step: 10890, loss: 3.153862, norm: 0.2694, time(ms): 806.76, token/sec:649867.40, hellaswag_acc: 0.2950
Step: 10891, loss: 3.117449, norm: 0.2797, time(ms): 801.25, token/sec:654339.56, hellaswag_acc: 0.2950
Step: 10892, loss: 3.126118, norm: 0.2813, time(ms): 795.63, token/sec:658958.99, hellaswag_acc: 0.2950
Step: 10893, loss: 3.102471, norm: 0.3332, time(ms): 792.91, token/sec:661221.97, hellaswag_acc: 0.2950
Step: 10894, loss: 3.100701, norm: 0.3196, time(ms): 789.60, token/sec:663992.78, hellaswag_acc: 0.2950
Step: 10895, loss: 3.156346, norm: 0.3137, time(ms): 792.46, token/sec:661592.38, hellaswag_acc: 0.2950
Step: 10896, loss: 3.162894, norm: 0.3297, time(ms): 792.22, token/sec:661794.67, hellaswag_acc: 0.2950
Step: 10897, loss: 3.127317, norm: 0.2834, time(ms): 791.43, token/sec:662454.17, hellaswag_acc: 0.2950
Step: 10898, loss: 3.163987, norm: 0.3132, time(ms): 797.39, token/sec:657508.07, hellaswag_acc: 0.2950
Step: 10899, loss: 3.165070, norm: 0.2759, time(ms): 805.19, token/sec:651136.65, hellaswag_acc: 0.2950
Step: 10900, loss: 3.143186, norm: 0.3220, time(ms): 792.28, token/sec:661747.48, hellaswag_acc: 0.2950
Step: 10901, loss: 3.118913, norm: 0.2764, time(ms): 793.78, token/sec:660494.68, hellaswag_acc: 0.2950
Step: 10902, loss: 3.181926, norm: 0.3192, time(ms): 791.58, token/sec:662329.07, hellaswag_acc: 0.2950
Step: 10903, loss: 3.166718, norm: 0.2764, time(ms): 799.25, token/sec:655970.96, hellaswag_acc: 0.2950
Step: 10904, loss: 3.232907, norm: 0.3053, time(ms): 801.47, token/sec:654156.01, hellaswag_acc: 0.2950
Step: 10905, loss: 3.161596, norm: 0.2604, time(ms): 796.83, token/sec:657967.44, hellaswag_acc: 0.2950
Step: 10906, loss: 3.162307, norm: 0.2994, time(ms): 796.30, token/sec:658408.33, hellaswag_acc: 0.2950
Step: 10907, loss: 3.172846, norm: 0.2614, time(ms): 792.19, token/sec:661824.95, hellaswag_acc: 0.2950
Step: 10908, loss: 3.189925, norm: 0.2804, time(ms): 788.03, token/sec:665312.23, hellaswag_acc: 0.2950
Step: 10909, loss: 3.171993, norm: 0.2521, time(ms): 792.57, token/sec:661503.42, hellaswag_acc: 0.2950
Step: 10910, loss: 3.215346, norm: 0.2652, time(ms): 792.39, token/sec:661654.69, hellaswag_acc: 0.2950
Step: 10911, loss: 3.181719, norm: 0.2638, time(ms): 796.21, token/sec:658479.11, hellaswag_acc: 0.2950
Step: 10912, loss: 3.157997, norm: 0.2589, time(ms): 806.65, token/sec:649957.87, hellaswag_acc: 0.2950
Step: 10913, loss: 3.154775, norm: 0.2563, time(ms): 795.41, token/sec:659139.52, hellaswag_acc: 0.2950
Step: 10914, loss: 3.161203, norm: 0.2814, time(ms): 795.78, token/sec:658838.36, hellaswag_acc: 0.2950
Step: 10915, loss: 3.177105, norm: 0.2786, time(ms): 805.93, token/sec:650539.51, hellaswag_acc: 0.2950
Step: 10916, loss: 3.139161, norm: 0.2654, time(ms): 803.01, token/sec:652903.46, hellaswag_acc: 0.2950
Step: 10917, loss: 3.135462, norm: 0.2780, time(ms): 792.31, token/sec:661717.80, hellaswag_acc: 0.2950
Step: 10918, loss: 3.152899, norm: 0.2554, time(ms): 802.16, token/sec:653592.16, hellaswag_acc: 0.2950
Step: 10919, loss: 3.118875, norm: 0.2929, time(ms): 803.93, token/sec:652152.96, hellaswag_acc: 0.2950
Step: 10920, loss: 3.159015, norm: 0.2937, time(ms): 790.39, token/sec:663329.42, hellaswag_acc: 0.2950
Step: 10921, loss: 3.124301, norm: 0.2828, time(ms): 791.61, token/sec:662302.94, hellaswag_acc: 0.2950
Step: 10922, loss: 3.089726, norm: 0.2618, time(ms): 787.78, token/sec:665522.65, hellaswag_acc: 0.2950
Step: 10923, loss: 3.150844, norm: 0.2570, time(ms): 796.76, token/sec:658024.54, hellaswag_acc: 0.2950
Step: 10924, loss: 3.120749, norm: 0.2779, time(ms): 793.65, token/sec:660602.03, hellaswag_acc: 0.2950
Step: 10925, loss: 3.147852, norm: 0.2791, time(ms): 786.71, token/sec:666433.69, hellaswag_acc: 0.2950
Step: 10926, loss: 3.179014, norm: 0.3050, time(ms): 789.90, token/sec:663737.46, hellaswag_acc: 0.2950
Step: 10927, loss: 3.157671, norm: 0.2647, time(ms): 801.31, token/sec:654285.83, hellaswag_acc: 0.2950
Step: 10928, loss: 3.186821, norm: 0.2971, time(ms): 791.30, token/sec:662567.95, hellaswag_acc: 0.2950
Step: 10929, loss: 3.185622, norm: 0.3567, time(ms): 792.37, token/sec:661669.02, hellaswag_acc: 0.2950
Step: 10930, loss: 3.184200, norm: 0.3949, time(ms): 786.20, token/sec:666866.99, hellaswag_acc: 0.2950
Step: 10931, loss: 3.125613, norm: 0.3008, time(ms): 791.52, token/sec:662381.14, hellaswag_acc: 0.2950
Step: 10932, loss: 3.095607, norm: 0.3303, time(ms): 793.97, token/sec:660338.00, hellaswag_acc: 0.2950
Step: 10933, loss: 3.141066, norm: 0.2887, time(ms): 799.27, token/sec:655958.24, hellaswag_acc: 0.2950
Step: 10934, loss: 3.190861, norm: 0.3688, time(ms): 805.49, token/sec:650893.23, hellaswag_acc: 0.2950
Step: 10935, loss: 3.169471, norm: 0.3111, time(ms): 799.24, token/sec:655980.94, hellaswag_acc: 0.2950
Step: 10936, loss: 3.232009, norm: 0.3323, time(ms): 790.15, token/sec:663529.17, hellaswag_acc: 0.2950
Step: 10937, loss: 3.201267, norm: 0.3294, time(ms): 795.10, token/sec:659401.41, hellaswag_acc: 0.2950
Step: 10938, loss: 3.220371, norm: 0.2935, time(ms): 792.11, token/sec:661888.69, hellaswag_acc: 0.2950
Step: 10939, loss: 3.178027, norm: 0.3196, time(ms): 791.56, token/sec:662343.83, hellaswag_acc: 0.2950
Step: 10940, loss: 3.210738, norm: 0.2695, time(ms): 789.96, token/sec:663687.98, hellaswag_acc: 0.2950
Step: 10941, loss: 3.175292, norm: 0.3030, time(ms): 797.15, token/sec:657703.15, hellaswag_acc: 0.2950
Step: 10942, loss: 3.173723, norm: 0.2660, time(ms): 797.52, token/sec:657396.62, hellaswag_acc: 0.2950
Step: 10943, loss: 3.204152, norm: 0.2898, time(ms): 797.36, token/sec:657530.29, hellaswag_acc: 0.2950
Step: 10944, loss: 3.197227, norm: 0.2790, time(ms): 796.05, token/sec:658614.99, hellaswag_acc: 0.2950
Step: 10945, loss: 3.207429, norm: 0.2789, time(ms): 791.62, token/sec:662301.34, hellaswag_acc: 0.2950
Step: 10946, loss: 3.140051, norm: 0.2579, time(ms): 798.06, token/sec:656957.09, hellaswag_acc: 0.2950
Step: 10947, loss: 3.198157, norm: 0.2761, time(ms): 798.71, token/sec:656417.80, hellaswag_acc: 0.2950
Step: 10948, loss: 3.215351, norm: 0.2720, time(ms): 799.32, token/sec:655916.37, hellaswag_acc: 0.2950
Step: 10949, loss: 3.154702, norm: 0.2956, time(ms): 793.53, token/sec:660704.84, hellaswag_acc: 0.2950
Step: 10950, loss: 3.132784, norm: 0.2756, time(ms): 789.53, token/sec:664051.73, hellaswag_acc: 0.2950
Step: 10951, loss: 3.173266, norm: 0.2917, time(ms): 789.73, token/sec:663878.52, hellaswag_acc: 0.2950
Step: 10952, loss: 3.111233, norm: 0.2785, time(ms): 792.27, token/sec:661754.05, hellaswag_acc: 0.2950
Step: 10953, loss: 3.178435, norm: 0.2981, time(ms): 788.95, token/sec:664535.56, hellaswag_acc: 0.2950
Step: 10954, loss: 3.189163, norm: 0.2848, time(ms): 803.87, token/sec:652201.89, hellaswag_acc: 0.2950
Step: 10955, loss: 3.171172, norm: 0.2898, time(ms): 804.75, token/sec:651488.13, hellaswag_acc: 0.2950
Step: 10956, loss: 3.167791, norm: 0.2739, time(ms): 792.28, token/sec:661741.90, hellaswag_acc: 0.2950
Step: 10957, loss: 3.170592, norm: 0.2954, time(ms): 805.36, token/sec:650999.79, hellaswag_acc: 0.2950
Step: 10958, loss: 3.141556, norm: 0.2688, time(ms): 801.33, token/sec:654272.78, hellaswag_acc: 0.2950
Step: 10959, loss: 3.160209, norm: 0.2696, time(ms): 795.49, token/sec:659071.76, hellaswag_acc: 0.2950
Step: 10960, loss: 3.106523, norm: 0.2866, time(ms): 802.25, token/sec:653519.91, hellaswag_acc: 0.2950
Step: 10961, loss: 3.196193, norm: 0.3046, time(ms): 800.59, token/sec:654875.05, hellaswag_acc: 0.2950
Step: 10962, loss: 3.187570, norm: 0.2885, time(ms): 801.93, token/sec:653783.76, hellaswag_acc: 0.2950
Step: 10963, loss: 3.109766, norm: 0.3072, time(ms): 793.81, token/sec:660466.71, hellaswag_acc: 0.2950
Step: 10964, loss: 3.113968, norm: 0.2959, time(ms): 803.88, token/sec:652200.35, hellaswag_acc: 0.2950
Step: 10965, loss: 3.214275, norm: 0.2986, time(ms): 800.89, token/sec:654628.43, hellaswag_acc: 0.2950
Step: 10966, loss: 3.145352, norm: 0.2852, time(ms): 799.15, token/sec:656059.22, hellaswag_acc: 0.2950
Step: 10967, loss: 3.181379, norm: 0.2800, time(ms): 796.57, token/sec:658184.07, hellaswag_acc: 0.2950
Step: 10968, loss: 3.149163, norm: 0.2809, time(ms): 803.04, token/sec:652880.39, hellaswag_acc: 0.2950
Step: 10969, loss: 3.182022, norm: 0.2834, time(ms): 797.09, token/sec:657755.29, hellaswag_acc: 0.2950
Step: 10970, loss: 3.153100, norm: 0.2658, time(ms): 803.27, token/sec:652694.94, hellaswag_acc: 0.2950
Step: 10971, loss: 3.185560, norm: 0.2711, time(ms): 795.33, token/sec:659205.72, hellaswag_acc: 0.2950
Step: 10972, loss: 3.226794, norm: 0.2812, time(ms): 800.84, token/sec:654671.90, hellaswag_acc: 0.2950
Step: 10973, loss: 3.176057, norm: 0.3003, time(ms): 802.70, token/sec:653151.69, hellaswag_acc: 0.2950
Step: 10974, loss: 3.193889, norm: 0.2914, time(ms): 797.45, token/sec:657454.21, hellaswag_acc: 0.2950
Step: 10975, loss: 3.176562, norm: 0.2818, time(ms): 800.39, token/sec:655038.71, hellaswag_acc: 0.2950
Step: 10976, loss: 3.191321, norm: 0.2673, time(ms): 796.65, token/sec:658114.73, hellaswag_acc: 0.2950
Step: 10977, loss: 3.198969, norm: 0.2858, time(ms): 804.38, token/sec:651791.30, hellaswag_acc: 0.2950
Step: 10978, loss: 3.197741, norm: 0.2840, time(ms): 797.36, token/sec:657528.52, hellaswag_acc: 0.2950
Step: 10979, loss: 3.188635, norm: 0.2733, time(ms): 798.03, token/sec:656976.12, hellaswag_acc: 0.2950
Step: 10980, loss: 3.178171, norm: 0.2767, time(ms): 805.56, token/sec:650837.17, hellaswag_acc: 0.2950
Step: 10981, loss: 3.185297, norm: 0.2672, time(ms): 796.23, token/sec:658459.00, hellaswag_acc: 0.2950
Step: 10982, loss: 3.174567, norm: 0.2773, time(ms): 795.33, token/sec:659212.24, hellaswag_acc: 0.2950
Step: 10983, loss: 3.106532, norm: 0.2931, time(ms): 802.95, token/sec:652955.22, hellaswag_acc: 0.2950
Step: 10984, loss: 3.180554, norm: 0.2560, time(ms): 804.99, token/sec:651298.84, hellaswag_acc: 0.2950
Step: 10985, loss: 3.145044, norm: 0.3296, time(ms): 795.51, token/sec:659060.50, hellaswag_acc: 0.2950
Step: 10986, loss: 3.177943, norm: 0.2898, time(ms): 793.18, token/sec:660998.57, hellaswag_acc: 0.2950
Step: 10987, loss: 3.184736, norm: 0.3104, time(ms): 790.15, token/sec:663530.37, hellaswag_acc: 0.2950
Step: 10988, loss: 3.210752, norm: 0.2754, time(ms): 788.88, token/sec:664598.42, hellaswag_acc: 0.2950
Step: 10989, loss: 3.130197, norm: 0.2955, time(ms): 797.06, token/sec:657773.98, hellaswag_acc: 0.2950
Step: 10990, loss: 3.106906, norm: 0.2578, time(ms): 791.88, token/sec:662082.79, hellaswag_acc: 0.2950
Step: 10991, loss: 3.137557, norm: 0.2909, time(ms): 797.37, token/sec:657519.87, hellaswag_acc: 0.2950
Step: 10992, loss: 3.157887, norm: 0.2717, time(ms): 800.78, token/sec:654724.13, hellaswag_acc: 0.2950
Step: 10993, loss: 3.104770, norm: 0.2587, time(ms): 803.09, token/sec:652837.56, hellaswag_acc: 0.2950
Step: 10994, loss: 3.123696, norm: 0.2811, time(ms): 790.69, token/sec:663073.40, hellaswag_acc: 0.2950
Step: 10995, loss: 3.186087, norm: 0.3114, time(ms): 792.58, token/sec:661496.26, hellaswag_acc: 0.2950
Step: 10996, loss: 3.172315, norm: 0.2863, time(ms): 796.26, token/sec:658438.30, hellaswag_acc: 0.2950
Step: 10997, loss: 3.156208, norm: 0.3126, time(ms): 790.14, token/sec:663538.58, hellaswag_acc: 0.2950
Step: 10998, loss: 3.234894, norm: 0.3215, time(ms): 789.09, token/sec:664418.90, hellaswag_acc: 0.2950
Step: 10999, loss: 3.161792, norm: 0.3085, time(ms): 790.85, token/sec:662939.87, hellaswag_acc: 0.2950
rank 0 sample 0: Hello, I'm a language model, and I am a programmer. The best person to help you, your best to help your client is a human. The
rank 0 sample 1: Hello, I'm a language model, so here's the problem: the output is the data input. It's like a program with the ability to represent the
rank 0 sample 2: Hello, I'm a language model, so I must say that "commented" refers to the type. In other words, the type is the type.
rank 0 sample 3: Hello, I'm a language model, and all the data I can see has a pretty good idea of what that's been written. I am making this more
rank 1 sample 0: Hello, I'm a language model, i.e. you're speaking without the rules and in case you're asking for permission, there's no need to
rank 1 sample 1: Hello, I'm a language model, I can tell you the answer of my "I need/want" question from a series of people who are not native
rank 1 sample 2: Hello, I'm a language model, but is there another way to describe it?
As far as language modeling is concerned, there is no such definition of
rank 1 sample 3: Hello, I'm a language model, and I'm doing some data analysis that supports the fact that this code could give you new input data.
This is
Step: 11000, loss: 3.096735, norm: 0.2967, time(ms): 363848.73, token/sec:1440.95, val_loss: 3.1664, hellaswag_acc: 0.2915
Step: 11001, loss: 3.167066, norm: 0.3073, time(ms): 802.16, token/sec:653594.69, hellaswag_acc: 0.2915
Step: 11002, loss: 3.111551, norm: 0.2801, time(ms): 802.68, token/sec:653174.19, hellaswag_acc: 0.2915
Step: 11003, loss: 3.134633, norm: 0.2984, time(ms): 792.54, token/sec:661530.09, hellaswag_acc: 0.2915
Step: 11004, loss: 3.175986, norm: 0.2889, time(ms): 799.87, token/sec:655466.11, hellaswag_acc: 0.2915
Step: 11005, loss: 3.161624, norm: 0.2823, time(ms): 804.15, token/sec:651980.68, hellaswag_acc: 0.2915
Step: 11006, loss: 3.204514, norm: 0.2772, time(ms): 803.63, token/sec:652395.77, hellaswag_acc: 0.2915
Step: 11007, loss: 3.124841, norm: 0.2890, time(ms): 793.79, token/sec:660485.56, hellaswag_acc: 0.2915
Step: 11008, loss: 3.186990, norm: 0.2703, time(ms): 795.11, token/sec:659388.56, hellaswag_acc: 0.2915
Step: 11009, loss: 3.140536, norm: 0.2753, time(ms): 796.35, token/sec:658366.94, hellaswag_acc: 0.2915
Step: 11010, loss: 3.209482, norm: 0.2986, time(ms): 794.67, token/sec:659758.11, hellaswag_acc: 0.2915
Step: 11011, loss: 3.167777, norm: 0.2949, time(ms): 785.67, token/sec:667316.05, hellaswag_acc: 0.2915
Step: 11012, loss: 3.216282, norm: 0.2982, time(ms): 788.13, token/sec:665234.14, hellaswag_acc: 0.2915
Step: 11013, loss: 3.175020, norm: 0.3229, time(ms): 797.19, token/sec:657666.37, hellaswag_acc: 0.2915
Step: 11014, loss: 3.171895, norm: 0.2830, time(ms): 791.69, token/sec:662234.93, hellaswag_acc: 0.2915
Step: 11015, loss: 3.164000, norm: 0.2950, time(ms): 794.13, token/sec:660207.35, hellaswag_acc: 0.2915
Step: 11016, loss: 3.163442, norm: 0.2634, time(ms): 789.80, token/sec:663827.42, hellaswag_acc: 0.2915
Step: 11017, loss: 3.162175, norm: 0.2765, time(ms): 807.78, token/sec:649047.60, hellaswag_acc: 0.2915
Step: 11018, loss: 3.156534, norm: 0.2712, time(ms): 803.41, token/sec:652576.02, hellaswag_acc: 0.2915
Step: 11019, loss: 3.159771, norm: 0.2996, time(ms): 798.64, token/sec:656474.63, hellaswag_acc: 0.2915
Step: 11020, loss: 3.125531, norm: 0.2689, time(ms): 797.03, token/sec:657800.34, hellaswag_acc: 0.2915
Step: 11021, loss: 3.144401, norm: 0.2834, time(ms): 801.55, token/sec:654096.27, hellaswag_acc: 0.2915
Step: 11022, loss: 3.105777, norm: 0.2600, time(ms): 802.97, token/sec:652934.48, hellaswag_acc: 0.2915
Step: 11023, loss: 3.165301, norm: 0.2639, time(ms): 793.20, token/sec:660979.69, hellaswag_acc: 0.2915
Step: 11024, loss: 3.114810, norm: 0.2537, time(ms): 801.22, token/sec:654364.87, hellaswag_acc: 0.2915
Step: 11025, loss: 3.117461, norm: 0.2682, time(ms): 801.82, token/sec:653872.21, hellaswag_acc: 0.2915
Step: 11026, loss: 3.157343, norm: 0.2790, time(ms): 802.53, token/sec:653291.01, hellaswag_acc: 0.2915
Step: 11027, loss: 3.149996, norm: 0.2561, time(ms): 787.97, token/sec:665361.55, hellaswag_acc: 0.2915
Step: 11028, loss: 3.171172, norm: 0.2716, time(ms): 792.58, token/sec:661491.28, hellaswag_acc: 0.2915
Step: 11029, loss: 3.143803, norm: 0.2591, time(ms): 793.37, token/sec:660836.68, hellaswag_acc: 0.2915
Step: 11030, loss: 3.150218, norm: 0.2829, time(ms): 793.10, token/sec:661059.17, hellaswag_acc: 0.2915
Step: 11031, loss: 3.144294, norm: 0.2580, time(ms): 793.12, token/sec:661042.48, hellaswag_acc: 0.2915
Step: 11032, loss: 3.157175, norm: 0.2871, time(ms): 790.85, token/sec:662939.27, hellaswag_acc: 0.2915
Step: 11033, loss: 3.139988, norm: 0.2757, time(ms): 795.95, token/sec:658694.10, hellaswag_acc: 0.2915
Step: 11034, loss: 3.176018, norm: 0.3033, time(ms): 791.42, token/sec:662460.76, hellaswag_acc: 0.2915
Step: 11035, loss: 3.028111, norm: 0.3599, time(ms): 799.60, token/sec:655685.59, hellaswag_acc: 0.2915
Step: 11036, loss: 3.148718, norm: 0.3232, time(ms): 796.40, token/sec:658326.14, hellaswag_acc: 0.2915
Step: 11037, loss: 3.130006, norm: 0.2764, time(ms): 796.73, token/sec:658051.32, hellaswag_acc: 0.2915
Step: 11038, loss: 3.173235, norm: 0.3623, time(ms): 805.75, token/sec:650686.77, hellaswag_acc: 0.2915
Step: 11039, loss: 3.155099, norm: 0.3553, time(ms): 800.68, token/sec:654805.04, hellaswag_acc: 0.2915
Step: 11040, loss: 3.180628, norm: 0.3039, time(ms): 796.52, token/sec:658226.43, hellaswag_acc: 0.2915
Step: 11041, loss: 3.105823, norm: 0.3154, time(ms): 798.71, token/sec:656415.45, hellaswag_acc: 0.2915
Step: 11042, loss: 3.159348, norm: 0.3045, time(ms): 803.79, token/sec:652271.54, hellaswag_acc: 0.2915
Step: 11043, loss: 3.160875, norm: 0.3021, time(ms): 799.64, token/sec:655657.44, hellaswag_acc: 0.2915
Step: 11044, loss: 3.176459, norm: 0.3106, time(ms): 790.88, token/sec:662918.49, hellaswag_acc: 0.2915
Step: 11045, loss: 3.223971, norm: 0.3133, time(ms): 797.95, token/sec:657039.72, hellaswag_acc: 0.2915
Step: 11046, loss: 3.182647, norm: 0.3466, time(ms): 790.48, token/sec:663249.99, hellaswag_acc: 0.2915
Step: 11047, loss: 3.255074, norm: 0.3062, time(ms): 790.43, token/sec:663296.41, hellaswag_acc: 0.2915
Step: 11048, loss: 3.351359, norm: 0.3678, time(ms): 1304.88, token/sec:401791.70, hellaswag_acc: 0.2915
Step: 11049, loss: 3.198912, norm: 0.3794, time(ms): 764.67, token/sec:685643.71, hellaswag_acc: 0.2915
Step: 11050, loss: 3.125660, norm: 0.2932, time(ms): 787.37, token/sec:665873.09, hellaswag_acc: 0.2915
Step: 11051, loss: 3.162680, norm: 0.3331, time(ms): 803.31, token/sec:652656.01, hellaswag_acc: 0.2915
Step: 11052, loss: 3.173552, norm: 0.2674, time(ms): 791.38, token/sec:662501.47, hellaswag_acc: 0.2915
Step: 11053, loss: 3.167807, norm: 0.3301, time(ms): 785.50, token/sec:667461.68, hellaswag_acc: 0.2915
Step: 11054, loss: 3.194470, norm: 0.2941, time(ms): 787.38, token/sec:665867.45, hellaswag_acc: 0.2915
Step: 11055, loss: 3.149160, norm: 0.3103, time(ms): 800.61, token/sec:654862.18, hellaswag_acc: 0.2915
Step: 11056, loss: 3.168185, norm: 0.3036, time(ms): 802.75, token/sec:653115.80, hellaswag_acc: 0.2915
Step: 11057, loss: 3.120419, norm: 0.3209, time(ms): 791.66, token/sec:662266.44, hellaswag_acc: 0.2915
Step: 11058, loss: 3.159341, norm: 0.3031, time(ms): 792.44, token/sec:661610.30, hellaswag_acc: 0.2915
Step: 11059, loss: 3.199440, norm: 0.3019, time(ms): 790.33, token/sec:663379.85, hellaswag_acc: 0.2915
Step: 11060, loss: 3.186405, norm: 0.2928, time(ms): 795.93, token/sec:658712.26, hellaswag_acc: 0.2915
Step: 11061, loss: 3.152177, norm: 0.3084, time(ms): 793.03, token/sec:661123.37, hellaswag_acc: 0.2915
Step: 11062, loss: 3.155615, norm: 0.2849, time(ms): 789.26, token/sec:664274.60, hellaswag_acc: 0.2915
Step: 11063, loss: 3.248053, norm: 0.3962, time(ms): 798.94, token/sec:656230.14, hellaswag_acc: 0.2915
Step: 11064, loss: 3.148156, norm: 0.3042, time(ms): 804.83, token/sec:651428.88, hellaswag_acc: 0.2915
Step: 11065, loss: 3.183873, norm: 0.3117, time(ms): 803.38, token/sec:652599.45, hellaswag_acc: 0.2915
Step: 11066, loss: 3.183202, norm: 0.3061, time(ms): 789.48, token/sec:664093.25, hellaswag_acc: 0.2915
Step: 11067, loss: 3.189309, norm: 0.3263, time(ms): 804.94, token/sec:651334.53, hellaswag_acc: 0.2915
Step: 11068, loss: 3.222755, norm: 0.3166, time(ms): 803.96, token/sec:652132.46, hellaswag_acc: 0.2915
Step: 11069, loss: 3.415276, norm: 0.4447, time(ms): 800.84, token/sec:654672.28, hellaswag_acc: 0.2915
Step: 11070, loss: 3.190314, norm: 0.3487, time(ms): 792.10, token/sec:661893.28, hellaswag_acc: 0.2915
Step: 11071, loss: 3.177359, norm: 0.3309, time(ms): 799.32, token/sec:655920.09, hellaswag_acc: 0.2915
Step: 11072, loss: 3.358799, norm: 0.3803, time(ms): 805.66, token/sec:650754.93, hellaswag_acc: 0.2915
Step: 11073, loss: 3.192440, norm: 0.3353, time(ms): 802.70, token/sec:653156.73, hellaswag_acc: 0.2915
Step: 11074, loss: 3.166085, norm: 0.3071, time(ms): 792.00, token/sec:661979.75, hellaswag_acc: 0.2915
Step: 11075, loss: 3.168332, norm: 0.2904, time(ms): 804.11, token/sec:652014.32, hellaswag_acc: 0.2915
Step: 11076, loss: 3.197711, norm: 0.3107, time(ms): 800.96, token/sec:654577.58, hellaswag_acc: 0.2915
Step: 11077, loss: 3.182902, norm: 0.2873, time(ms): 800.60, token/sec:654869.00, hellaswag_acc: 0.2915
Step: 11078, loss: 3.218343, norm: 0.3005, time(ms): 795.41, token/sec:659138.93, hellaswag_acc: 0.2915
Step: 11079, loss: 3.158846, norm: 0.2971, time(ms): 804.68, token/sec:651548.74, hellaswag_acc: 0.2915
Step: 11080, loss: 3.127279, norm: 0.2883, time(ms): 798.91, token/sec:656250.31, hellaswag_acc: 0.2915
Step: 11081, loss: 3.224008, norm: 0.3151, time(ms): 797.87, token/sec:657107.07, hellaswag_acc: 0.2915
Step: 11082, loss: 3.188089, norm: 0.2891, time(ms): 799.56, token/sec:655720.59, hellaswag_acc: 0.2915
Step: 11083, loss: 3.187860, norm: 0.2803, time(ms): 803.14, token/sec:652795.70, hellaswag_acc: 0.2915
Step: 11084, loss: 3.219025, norm: 0.2932, time(ms): 792.29, token/sec:661734.93, hellaswag_acc: 0.2915
Step: 11085, loss: 3.183334, norm: 0.2649, time(ms): 805.58, token/sec:650821.76, hellaswag_acc: 0.2915
Step: 11086, loss: 3.183267, norm: 0.2761, time(ms): 802.08, token/sec:653657.83, hellaswag_acc: 0.2915
Step: 11087, loss: 3.165011, norm: 0.2583, time(ms): 792.78, token/sec:661331.14, hellaswag_acc: 0.2915
Step: 11088, loss: 3.271580, norm: 0.2778, time(ms): 797.51, token/sec:657405.07, hellaswag_acc: 0.2915
Step: 11089, loss: 3.155240, norm: 0.2792, time(ms): 807.34, token/sec:649399.13, hellaswag_acc: 0.2915
Step: 11090, loss: 3.135242, norm: 0.2584, time(ms): 799.33, token/sec:655910.31, hellaswag_acc: 0.2915
Step: 11091, loss: 3.087626, norm: 0.2646, time(ms): 799.51, token/sec:655758.91, hellaswag_acc: 0.2915
Step: 11092, loss: 3.163355, norm: 0.2866, time(ms): 793.99, token/sec:660323.92, hellaswag_acc: 0.2915
Step: 11093, loss: 3.210957, norm: 0.2875, time(ms): 802.45, token/sec:653357.78, hellaswag_acc: 0.2915
Step: 11094, loss: 3.124964, norm: 0.2713, time(ms): 804.03, token/sec:652074.64, hellaswag_acc: 0.2915
Step: 11095, loss: 3.134720, norm: 0.2587, time(ms): 799.99, token/sec:655369.22, hellaswag_acc: 0.2915
Step: 11096, loss: 3.173483, norm: 0.3111, time(ms): 798.54, token/sec:656561.65, hellaswag_acc: 0.2915
Step: 11097, loss: 3.168894, norm: 0.2586, time(ms): 796.88, token/sec:657927.09, hellaswag_acc: 0.2915
Step: 11098, loss: 3.124290, norm: 0.2806, time(ms): 803.47, token/sec:652529.54, hellaswag_acc: 0.2915
Step: 11099, loss: 3.148878, norm: 0.2500, time(ms): 802.10, token/sec:653642.87, hellaswag_acc: 0.2915
Step: 11100, loss: 3.169363, norm: 0.2840, time(ms): 790.14, token/sec:663536.58, hellaswag_acc: 0.2915
Step: 11101, loss: 3.139531, norm: 0.2837, time(ms): 797.09, token/sec:657752.14, hellaswag_acc: 0.2915
Step: 11102, loss: 3.181218, norm: 0.2900, time(ms): 791.19, token/sec:662653.80, hellaswag_acc: 0.2915
Step: 11103, loss: 3.195793, norm: 0.2701, time(ms): 787.57, token/sec:665703.16, hellaswag_acc: 0.2915
Step: 11104, loss: 3.155783, norm: 0.3018, time(ms): 789.70, token/sec:663907.39, hellaswag_acc: 0.2915
Step: 11105, loss: 3.206302, norm: 0.2871, time(ms): 794.76, token/sec:659683.49, hellaswag_acc: 0.2915
Step: 11106, loss: 3.159183, norm: 0.2789, time(ms): 807.25, token/sec:649474.70, hellaswag_acc: 0.2915
Step: 11107, loss: 3.229832, norm: 0.3054, time(ms): 789.38, token/sec:664178.69, hellaswag_acc: 0.2915
Step: 11108, loss: 3.183749, norm: 0.2750, time(ms): 791.25, token/sec:662608.07, hellaswag_acc: 0.2915
Step: 11109, loss: 3.236114, norm: 0.2949, time(ms): 795.17, token/sec:659340.52, hellaswag_acc: 0.2915
Step: 11110, loss: 3.215780, norm: 0.2843, time(ms): 804.18, token/sec:651956.71, hellaswag_acc: 0.2915
Step: 11111, loss: 3.071839, norm: 0.2923, time(ms): 798.47, token/sec:656612.04, hellaswag_acc: 0.2915
Step: 11112, loss: 3.175047, norm: 0.2970, time(ms): 797.26, token/sec:657610.71, hellaswag_acc: 0.2915
Step: 11113, loss: 3.186337, norm: 0.2889, time(ms): 800.51, token/sec:654944.48, hellaswag_acc: 0.2915
Step: 11114, loss: 3.179540, norm: 0.2785, time(ms): 800.07, token/sec:655300.08, hellaswag_acc: 0.2915
Step: 11115, loss: 3.206260, norm: 0.2905, time(ms): 794.03, token/sec:660290.01, hellaswag_acc: 0.2915
Step: 11116, loss: 3.191126, norm: 0.2866, time(ms): 792.59, token/sec:661489.89, hellaswag_acc: 0.2915
Step: 11117, loss: 3.254387, norm: 0.2921, time(ms): 785.63, token/sec:667343.99, hellaswag_acc: 0.2915
Step: 11118, loss: 3.197464, norm: 0.2856, time(ms): 791.53, token/sec:662370.97, hellaswag_acc: 0.2915
Step: 11119, loss: 3.193491, norm: 0.2768, time(ms): 798.16, token/sec:656872.31, hellaswag_acc: 0.2915
Step: 11120, loss: 3.183814, norm: 0.2919, time(ms): 788.58, token/sec:664849.39, hellaswag_acc: 0.2915
Step: 11121, loss: 3.165447, norm: 0.2666, time(ms): 790.34, token/sec:663370.84, hellaswag_acc: 0.2915
Step: 11122, loss: 3.223487, norm: 0.3121, time(ms): 793.35, token/sec:660854.15, hellaswag_acc: 0.2915
Step: 11123, loss: 3.124827, norm: 0.2764, time(ms): 793.35, token/sec:660855.94, hellaswag_acc: 0.2915
Step: 11124, loss: 3.182590, norm: 0.2859, time(ms): 794.40, token/sec:659981.26, hellaswag_acc: 0.2915
Step: 11125, loss: 3.187725, norm: 0.2753, time(ms): 794.09, token/sec:660241.64, hellaswag_acc: 0.2915
Step: 11126, loss: 3.109442, norm: 0.2793, time(ms): 802.16, token/sec:653596.44, hellaswag_acc: 0.2915
Step: 11127, loss: 3.212004, norm: 0.3026, time(ms): 804.14, token/sec:651983.97, hellaswag_acc: 0.2915
Step: 11128, loss: 3.138810, norm: 0.3282, time(ms): 789.94, token/sec:663704.60, hellaswag_acc: 0.2915
Step: 11129, loss: 3.144046, norm: 0.3130, time(ms): 798.77, token/sec:656366.07, hellaswag_acc: 0.2915
Step: 11130, loss: 3.213196, norm: 0.2900, time(ms): 792.05, token/sec:661936.51, hellaswag_acc: 0.2915
Step: 11131, loss: 3.117803, norm: 0.3118, time(ms): 793.59, token/sec:660652.83, hellaswag_acc: 0.2915
Step: 11132, loss: 3.132013, norm: 0.2567, time(ms): 791.47, token/sec:662423.24, hellaswag_acc: 0.2915
Step: 11133, loss: 3.187163, norm: 0.3179, time(ms): 787.19, token/sec:666021.53, hellaswag_acc: 0.2915
Step: 11134, loss: 3.117553, norm: 0.3023, time(ms): 792.40, token/sec:661648.12, hellaswag_acc: 0.2915
Step: 11135, loss: 3.193535, norm: 0.3261, time(ms): 791.87, token/sec:662091.96, hellaswag_acc: 0.2915
Step: 11136, loss: 3.143099, norm: 0.3022, time(ms): 800.79, token/sec:654714.19, hellaswag_acc: 0.2915
Step: 11137, loss: 3.144644, norm: 0.2728, time(ms): 796.40, token/sec:658323.77, hellaswag_acc: 0.2915
Step: 11138, loss: 3.184221, norm: 0.3468, time(ms): 800.33, token/sec:655088.47, hellaswag_acc: 0.2915
Step: 11139, loss: 3.178250, norm: 0.3577, time(ms): 800.59, token/sec:654877.19, hellaswag_acc: 0.2915
Step: 11140, loss: 3.179322, norm: 0.2846, time(ms): 801.93, token/sec:653785.51, hellaswag_acc: 0.2915
Step: 11141, loss: 3.217546, norm: 0.3371, time(ms): 797.86, token/sec:657119.83, hellaswag_acc: 0.2915
Step: 11142, loss: 3.183053, norm: 0.2876, time(ms): 796.41, token/sec:658311.75, hellaswag_acc: 0.2915
Step: 11143, loss: 3.330607, norm: 0.3370, time(ms): 804.50, token/sec:651694.14, hellaswag_acc: 0.2915
Step: 11144, loss: 3.207747, norm: 0.3343, time(ms): 800.86, token/sec:654654.35, hellaswag_acc: 0.2915
Step: 11145, loss: 3.188364, norm: 0.3133, time(ms): 787.29, token/sec:665936.61, hellaswag_acc: 0.2915
Step: 11146, loss: 3.139565, norm: 0.3052, time(ms): 792.57, token/sec:661504.62, hellaswag_acc: 0.2915
Step: 11147, loss: 3.239810, norm: 0.2986, time(ms): 793.51, token/sec:660719.33, hellaswag_acc: 0.2915
Step: 11148, loss: 3.209262, norm: 0.3046, time(ms): 790.47, token/sec:663258.79, hellaswag_acc: 0.2915
Step: 11149, loss: 3.186961, norm: 0.2946, time(ms): 794.14, token/sec:660193.67, hellaswag_acc: 0.2915
Step: 11150, loss: 3.231009, norm: 0.3030, time(ms): 795.59, token/sec:658996.12, hellaswag_acc: 0.2915
Step: 11151, loss: 3.188665, norm: 0.2822, time(ms): 803.67, token/sec:652368.87, hellaswag_acc: 0.2915
Step: 11152, loss: 3.224239, norm: 0.2714, time(ms): 797.76, token/sec:657201.33, hellaswag_acc: 0.2915
Step: 11153, loss: 3.156240, norm: 0.2797, time(ms): 799.33, token/sec:655909.33, hellaswag_acc: 0.2915
Step: 11154, loss: 3.141428, norm: 0.2678, time(ms): 801.73, token/sec:653941.83, hellaswag_acc: 0.2915
Step: 11155, loss: 3.200018, norm: 0.2936, time(ms): 799.59, token/sec:655695.95, hellaswag_acc: 0.2915
Step: 11156, loss: 3.249872, norm: 0.3086, time(ms): 791.77, token/sec:662175.50, hellaswag_acc: 0.2915
Step: 11157, loss: 3.218438, norm: 0.3200, time(ms): 791.93, token/sec:662038.74, hellaswag_acc: 0.2915
Step: 11158, loss: 3.126194, norm: 0.2729, time(ms): 795.98, token/sec:658668.85, hellaswag_acc: 0.2915
Step: 11159, loss: 3.194395, norm: 0.2915, time(ms): 791.75, token/sec:662190.26, hellaswag_acc: 0.2915
Step: 11160, loss: 3.182032, norm: 0.2874, time(ms): 788.77, token/sec:664691.63, hellaswag_acc: 0.2915
Step: 11161, loss: 3.188174, norm: 0.2914, time(ms): 790.82, token/sec:662967.85, hellaswag_acc: 0.2915
Step: 11162, loss: 3.175959, norm: 0.2591, time(ms): 791.07, token/sec:662754.45, hellaswag_acc: 0.2915
Step: 11163, loss: 3.120020, norm: 0.2630, time(ms): 793.32, token/sec:660881.16, hellaswag_acc: 0.2915
Step: 11164, loss: 3.197786, norm: 0.2819, time(ms): 798.68, token/sec:656441.51, hellaswag_acc: 0.2915
Step: 11165, loss: 3.138030, norm: 0.2701, time(ms): 806.46, token/sec:650111.21, hellaswag_acc: 0.2915
Step: 11166, loss: 3.121199, norm: 0.2743, time(ms): 799.19, token/sec:656027.52, hellaswag_acc: 0.2915
Step: 11167, loss: 3.168805, norm: 0.2588, time(ms): 789.68, token/sec:663925.63, hellaswag_acc: 0.2915
Step: 11168, loss: 3.124078, norm: 0.2535, time(ms): 805.75, token/sec:650681.76, hellaswag_acc: 0.2915
Step: 11169, loss: 3.157141, norm: 0.2690, time(ms): 804.45, token/sec:651733.35, hellaswag_acc: 0.2915
Step: 11170, loss: 3.185901, norm: 0.2604, time(ms): 798.20, token/sec:656834.44, hellaswag_acc: 0.2915
Step: 11171, loss: 3.225153, norm: 0.2837, time(ms): 796.79, token/sec:657998.35, hellaswag_acc: 0.2915
Step: 11172, loss: 3.139090, norm: 0.2756, time(ms): 802.31, token/sec:653471.36, hellaswag_acc: 0.2915
Step: 11173, loss: 3.190778, norm: 0.2996, time(ms): 801.59, token/sec:654061.83, hellaswag_acc: 0.2915
Step: 11174, loss: 3.120152, norm: 0.2800, time(ms): 795.98, token/sec:658669.05, hellaswag_acc: 0.2915
Step: 11175, loss: 3.184335, norm: 0.3022, time(ms): 802.75, token/sec:653111.72, hellaswag_acc: 0.2915
Step: 11176, loss: 3.175305, norm: 0.2850, time(ms): 800.24, token/sec:655166.35, hellaswag_acc: 0.2915
Step: 11177, loss: 3.145867, norm: 0.2809, time(ms): 799.37, token/sec:655872.74, hellaswag_acc: 0.2915
Step: 11178, loss: 3.191290, norm: 0.2829, time(ms): 793.78, token/sec:660492.10, hellaswag_acc: 0.2915
Step: 11179, loss: 3.158970, norm: 0.2949, time(ms): 805.70, token/sec:650720.27, hellaswag_acc: 0.2915
Step: 11180, loss: 3.145875, norm: 0.2665, time(ms): 801.60, token/sec:654054.44, hellaswag_acc: 0.2915
Step: 11181, loss: 3.129820, norm: 0.2893, time(ms): 795.69, token/sec:658908.64, hellaswag_acc: 0.2915
Step: 11182, loss: 3.217833, norm: 0.2764, time(ms): 801.76, token/sec:653921.41, hellaswag_acc: 0.2915
Step: 11183, loss: 3.156750, norm: 0.3138, time(ms): 802.48, token/sec:653332.54, hellaswag_acc: 0.2915
Step: 11184, loss: 3.163064, norm: 0.2825, time(ms): 799.05, token/sec:656142.61, hellaswag_acc: 0.2915
Step: 11185, loss: 3.190295, norm: 0.3233, time(ms): 795.09, token/sec:659407.34, hellaswag_acc: 0.2915
Step: 11186, loss: 3.213679, norm: 0.2746, time(ms): 803.99, token/sec:652105.38, hellaswag_acc: 0.2915
Step: 11187, loss: 3.230911, norm: 0.2957, time(ms): 798.96, token/sec:656213.10, hellaswag_acc: 0.2915
Step: 11188, loss: 3.244318, norm: 0.2852, time(ms): 796.15, token/sec:658529.39, hellaswag_acc: 0.2915
Step: 11189, loss: 3.150369, norm: 0.2910, time(ms): 803.75, token/sec:652305.20, hellaswag_acc: 0.2915
Step: 11190, loss: 3.181133, norm: 0.2890, time(ms): 801.99, token/sec:653736.34, hellaswag_acc: 0.2915
Step: 11191, loss: 3.149463, norm: 0.2844, time(ms): 794.51, token/sec:659886.99, hellaswag_acc: 0.2915
Step: 11192, loss: 3.200401, norm: 0.2884, time(ms): 799.62, token/sec:655672.88, hellaswag_acc: 0.2915
Step: 11193, loss: 3.135952, norm: 0.2655, time(ms): 802.98, token/sec:652931.38, hellaswag_acc: 0.2915
Step: 11194, loss: 3.180478, norm: 0.3087, time(ms): 802.29, token/sec:653490.97, hellaswag_acc: 0.2915
Step: 11195, loss: 3.151980, norm: 0.2839, time(ms): 793.61, token/sec:660640.53, hellaswag_acc: 0.2915
Step: 11196, loss: 3.154310, norm: 0.2986, time(ms): 799.31, token/sec:655925.37, hellaswag_acc: 0.2915
Step: 11197, loss: 3.165572, norm: 0.2961, time(ms): 805.58, token/sec:650822.34, hellaswag_acc: 0.2915
Step: 11198, loss: 3.159165, norm: 0.2698, time(ms): 800.81, token/sec:654697.04, hellaswag_acc: 0.2915
Step: 11199, loss: 3.128549, norm: 0.2757, time(ms): 794.61, token/sec:659805.82, hellaswag_acc: 0.2915
Step: 11200, loss: 3.196365, norm: 0.2695, time(ms): 797.57, token/sec:657356.34, hellaswag_acc: 0.2915
Step: 11201, loss: 3.104911, norm: 0.2658, time(ms): 806.82, token/sec:649817.28, hellaswag_acc: 0.2915
Step: 11202, loss: 3.124258, norm: 0.2696, time(ms): 794.41, token/sec:659973.34, hellaswag_acc: 0.2915
Step: 11203, loss: 3.205629, norm: 0.2703, time(ms): 800.10, token/sec:655274.31, hellaswag_acc: 0.2915
Step: 11204, loss: 3.123640, norm: 0.2832, time(ms): 802.71, token/sec:653149.75, hellaswag_acc: 0.2915
Step: 11205, loss: 3.287580, norm: 0.2947, time(ms): 800.63, token/sec:654845.40, hellaswag_acc: 0.2915
Step: 11206, loss: 3.152334, norm: 0.2739, time(ms): 797.41, token/sec:657491.95, hellaswag_acc: 0.2915
Step: 11207, loss: 3.144694, norm: 0.2956, time(ms): 803.87, token/sec:652206.92, hellaswag_acc: 0.2915
Step: 11208, loss: 3.121222, norm: 0.2952, time(ms): 797.66, token/sec:657282.07, hellaswag_acc: 0.2915
Step: 11209, loss: 3.116084, norm: 0.2798, time(ms): 796.92, token/sec:657893.03, hellaswag_acc: 0.2915
Step: 11210, loss: 3.139821, norm: 0.2777, time(ms): 804.73, token/sec:651504.34, hellaswag_acc: 0.2915
Step: 11211, loss: 3.120470, norm: 0.2879, time(ms): 800.35, token/sec:655073.06, hellaswag_acc: 0.2915
Step: 11212, loss: 3.099975, norm: 0.2983, time(ms): 790.67, token/sec:663094.79, hellaswag_acc: 0.2915
Step: 11213, loss: 3.146224, norm: 0.2832, time(ms): 807.34, token/sec:649398.36, hellaswag_acc: 0.2915
Step: 11214, loss: 3.160074, norm: 0.2949, time(ms): 801.75, token/sec:653928.99, hellaswag_acc: 0.2915
Step: 11215, loss: 3.097281, norm: 0.2820, time(ms): 793.21, token/sec:660970.36, hellaswag_acc: 0.2915
Step: 11216, loss: 3.112980, norm: 0.3018, time(ms): 798.20, token/sec:656835.42, hellaswag_acc: 0.2915
Step: 11217, loss: 3.146843, norm: 0.2850, time(ms): 806.19, token/sec:650325.77, hellaswag_acc: 0.2915
Step: 11218, loss: 3.157360, norm: 0.3380, time(ms): 800.76, token/sec:654736.41, hellaswag_acc: 0.2915
Step: 11219, loss: 3.176463, norm: 0.3573, time(ms): 791.60, token/sec:662314.51, hellaswag_acc: 0.2915
Step: 11220, loss: 3.189805, norm: 0.2908, time(ms): 806.55, token/sec:650036.83, hellaswag_acc: 0.2915
Step: 11221, loss: 3.172464, norm: 0.3125, time(ms): 799.53, token/sec:655743.47, hellaswag_acc: 0.2915
Step: 11222, loss: 3.151385, norm: 0.2948, time(ms): 802.19, token/sec:653573.90, hellaswag_acc: 0.2915
Step: 11223, loss: 3.157706, norm: 0.3456, time(ms): 795.66, token/sec:658933.52, hellaswag_acc: 0.2915
Step: 11224, loss: 3.214372, norm: 0.3405, time(ms): 803.35, token/sec:652630.44, hellaswag_acc: 0.2915
Step: 11225, loss: 3.197981, norm: 0.2933, time(ms): 795.66, token/sec:658936.48, hellaswag_acc: 0.2915
Step: 11226, loss: 3.157743, norm: 0.3340, time(ms): 803.52, token/sec:652492.37, hellaswag_acc: 0.2915
Step: 11227, loss: 3.253441, norm: 0.3141, time(ms): 800.77, token/sec:654729.20, hellaswag_acc: 0.2915
Step: 11228, loss: 3.224985, norm: 0.2791, time(ms): 789.65, token/sec:663950.48, hellaswag_acc: 0.2915
Step: 11229, loss: 3.173893, norm: 0.2928, time(ms): 798.98, token/sec:656192.93, hellaswag_acc: 0.2915
Step: 11230, loss: 3.183166, norm: 0.2876, time(ms): 792.02, token/sec:661960.62, hellaswag_acc: 0.2915
Step: 11231, loss: 3.148348, norm: 0.2917, time(ms): 789.01, token/sec:664490.78, hellaswag_acc: 0.2915
Step: 11232, loss: 3.227827, norm: 0.2765, time(ms): 791.26, token/sec:662596.09, hellaswag_acc: 0.2915
Step: 11233, loss: 3.181811, norm: 0.3162, time(ms): 792.59, token/sec:661487.90, hellaswag_acc: 0.2915
Step: 11234, loss: 3.110637, norm: 0.2851, time(ms): 796.08, token/sec:658590.73, hellaswag_acc: 0.2915
Step: 11235, loss: 3.203363, norm: 0.2917, time(ms): 807.91, token/sec:648942.45, hellaswag_acc: 0.2915
Step: 11236, loss: 3.158433, norm: 0.2705, time(ms): 795.89, token/sec:658741.06, hellaswag_acc: 0.2915
Step: 11237, loss: 3.149359, norm: 0.2803, time(ms): 793.85, token/sec:660440.13, hellaswag_acc: 0.2915
Step: 11238, loss: 3.135093, norm: 0.2825, time(ms): 790.41, token/sec:663308.01, hellaswag_acc: 0.2915
Step: 11239, loss: 3.219794, norm: 0.2858, time(ms): 1285.87, token/sec:407729.85, hellaswag_acc: 0.2915
Step: 11240, loss: 3.165608, norm: 0.2862, time(ms): 797.05, token/sec:657782.44, hellaswag_acc: 0.2915
Step: 11241, loss: 3.134938, norm: 0.2516, time(ms): 780.99, token/sec:671314.00, hellaswag_acc: 0.2915
Step: 11242, loss: 3.150658, norm: 0.2636, time(ms): 781.17, token/sec:671155.00, hellaswag_acc: 0.2915
Step: 11243, loss: 3.154213, norm: 0.2534, time(ms): 796.02, token/sec:658634.52, hellaswag_acc: 0.2915
Step: 11244, loss: 3.154480, norm: 0.2582, time(ms): 794.86, token/sec:659599.59, hellaswag_acc: 0.2915
Step: 11245, loss: 3.119187, norm: 0.2449, time(ms): 788.31, token/sec:665081.03, hellaswag_acc: 0.2915
Step: 11246, loss: 3.160817, norm: 0.2707, time(ms): 787.74, token/sec:665556.89, hellaswag_acc: 0.2915
Step: 11247, loss: 3.042388, norm: 0.2429, time(ms): 799.40, token/sec:655855.73, hellaswag_acc: 0.2915
Step: 11248, loss: 3.137388, norm: 0.2675, time(ms): 807.10, token/sec:649592.11, hellaswag_acc: 0.2915
Step: 11249, loss: 3.134419, norm: 0.2610, time(ms): 790.90, token/sec:662901.30, hellaswag_acc: 0.2915
rank 0 sample 0: Hello, I'm a language model, and I know that's why you see an unaided language such as the one we learn on a regular basis is
rank 0 sample 1: Hello, I'm a language model, so to speak, but I think those are all useful functions, not simply functional programming languages. I just need to be
rank 0 sample 2: Hello, I'm a language model, so I like that to build real life applications using Python. This post has been written for a beginner Python beginner, and
rank 0 sample 3: Hello, I'm a language model, which we're trying to do. Let me break it down in four steps, below you are a typical approach, so
rank 1 sample 0: Hello, I'm a language model, how I build it, how I got the result from it.
And you can get this on the website:

rank 1 sample 1: Hello, I'm a language model, not an interpreter. I'm trying to give you a general idea of what to do if you aren't familiar with the
rank 1 sample 2: Hello, I'm a language model, I actually need to write a program to do this. But there is one thing I can do: the compiler does it
rank 1 sample 3: Hello, I'm a language model, and I'm the one sitting at the time. We like to put ourselves between the systems while we're working. We
Step: 11250, loss: 3.141368, norm: 0.2470, time(ms): 3814.90, token/sec:137431.54, val_loss: 3.1611, hellaswag_acc: 0.2915
Step: 11251, loss: 3.136414, norm: 0.2624, time(ms): 786.13, token/sec:666921.20, hellaswag_acc: 0.2915
Step: 11252, loss: 3.108740, norm: 0.2525, time(ms): 790.77, token/sec:663012.23, hellaswag_acc: 0.2915
Step: 11253, loss: 3.114583, norm: 0.2766, time(ms): 791.45, token/sec:662442.80, hellaswag_acc: 0.2915
Step: 11254, loss: 3.134074, norm: 0.2690, time(ms): 803.81, token/sec:652253.74, hellaswag_acc: 0.2915
Step: 11255, loss: 3.084529, norm: 0.2902, time(ms): 791.75, token/sec:662185.47, hellaswag_acc: 0.2915
Step: 11256, loss: 3.005171, norm: 0.2732, time(ms): 789.15, token/sec:664371.13, hellaswag_acc: 0.2915
Step: 11257, loss: 2.942588, norm: 0.2792, time(ms): 787.08, token/sec:666120.38, hellaswag_acc: 0.2915
Step: 11258, loss: 3.028740, norm: 0.3172, time(ms): 786.20, token/sec:666866.59, hellaswag_acc: 0.2915
Step: 11259, loss: 3.048752, norm: 0.2850, time(ms): 804.62, token/sec:651593.53, hellaswag_acc: 0.2915
Step: 11260, loss: 2.944166, norm: 0.3036, time(ms): 791.74, token/sec:662196.84, hellaswag_acc: 0.2915
Step: 11261, loss: 3.002641, norm: 0.3095, time(ms): 802.28, token/sec:653496.21, hellaswag_acc: 0.2915
Step: 11262, loss: 3.012044, norm: 0.3651, time(ms): 805.74, token/sec:650691.96, hellaswag_acc: 0.2915
Step: 11263, loss: 2.999824, norm: 0.3107, time(ms): 785.66, token/sec:667321.72, hellaswag_acc: 0.2915
Step: 11264, loss: 3.023271, norm: 0.2984, time(ms): 789.29, token/sec:664248.91, hellaswag_acc: 0.2915
Step: 11265, loss: 2.966841, norm: 0.3118, time(ms): 790.93, token/sec:662875.52, hellaswag_acc: 0.2915
Step: 11266, loss: 2.919869, norm: 0.2697, time(ms): 791.61, token/sec:662303.74, hellaswag_acc: 0.2915
Step: 11267, loss: 2.983370, norm: 0.2930, time(ms): 796.36, token/sec:658352.55, hellaswag_acc: 0.2915
Step: 11268, loss: 3.203661, norm: 0.3050, time(ms): 803.19, token/sec:652755.01, hellaswag_acc: 0.2915
Step: 11269, loss: 3.136000, norm: 0.2984, time(ms): 801.47, token/sec:654155.81, hellaswag_acc: 0.2915
Step: 11270, loss: 3.178326, norm: 0.3005, time(ms): 797.92, token/sec:657067.60, hellaswag_acc: 0.2915
Step: 11271, loss: 3.168125, norm: 0.2856, time(ms): 796.95, token/sec:657870.99, hellaswag_acc: 0.2915
Step: 11272, loss: 3.165947, norm: 0.3041, time(ms): 804.43, token/sec:651750.54, hellaswag_acc: 0.2915
Step: 11273, loss: 3.181044, norm: 0.2881, time(ms): 798.32, token/sec:656736.95, hellaswag_acc: 0.2915
Step: 11274, loss: 3.165476, norm: 0.2733, time(ms): 795.75, token/sec:658861.85, hellaswag_acc: 0.2915
Step: 11275, loss: 3.185405, norm: 0.3057, time(ms): 800.97, token/sec:654565.69, hellaswag_acc: 0.2915
Step: 11276, loss: 3.159987, norm: 0.2752, time(ms): 798.57, token/sec:656535.97, hellaswag_acc: 0.2915
Step: 11277, loss: 3.185912, norm: 0.2945, time(ms): 798.61, token/sec:656503.63, hellaswag_acc: 0.2915
Step: 11278, loss: 3.125874, norm: 0.2726, time(ms): 797.09, token/sec:657756.66, hellaswag_acc: 0.2915
Step: 11279, loss: 3.205930, norm: 0.2848, time(ms): 792.71, token/sec:661385.64, hellaswag_acc: 0.2915
Step: 11280, loss: 3.135835, norm: 0.2847, time(ms): 794.02, token/sec:660295.56, hellaswag_acc: 0.2915
Step: 11281, loss: 3.215910, norm: 0.2925, time(ms): 797.57, token/sec:657358.50, hellaswag_acc: 0.2915
Step: 11282, loss: 3.205043, norm: 0.2803, time(ms): 798.04, token/sec:656969.25, hellaswag_acc: 0.2915
Step: 11283, loss: 3.131826, norm: 0.2731, time(ms): 790.04, token/sec:663624.08, hellaswag_acc: 0.2915
Step: 11284, loss: 3.130064, norm: 0.3042, time(ms): 782.66, token/sec:669876.37, hellaswag_acc: 0.2915
Step: 11285, loss: 3.179539, norm: 0.3078, time(ms): 786.88, token/sec:666287.90, hellaswag_acc: 0.2915
Step: 11286, loss: 3.169912, norm: 0.3353, time(ms): 806.46, token/sec:650114.09, hellaswag_acc: 0.2915
Step: 11287, loss: 3.153998, norm: 0.2951, time(ms): 800.99, token/sec:654550.10, hellaswag_acc: 0.2915
Step: 11288, loss: 3.224096, norm: 0.3170, time(ms): 795.54, token/sec:659034.04, hellaswag_acc: 0.2915
Step: 11289, loss: 3.227968, norm: 0.3231, time(ms): 802.98, token/sec:652924.01, hellaswag_acc: 0.2915
Step: 11290, loss: 3.153851, norm: 0.3164, time(ms): 800.47, token/sec:654975.50, hellaswag_acc: 0.2915
Step: 11291, loss: 3.047264, norm: 0.2817, time(ms): 800.47, token/sec:654978.62, hellaswag_acc: 0.2915
Step: 11292, loss: 3.156476, norm: 0.2916, time(ms): 788.18, token/sec:665189.07, hellaswag_acc: 0.2915
Step: 11293, loss: 3.110427, norm: 0.2725, time(ms): 789.71, token/sec:663897.56, hellaswag_acc: 0.2915
Step: 11294, loss: 3.101147, norm: 0.2898, time(ms): 793.46, token/sec:660763.21, hellaswag_acc: 0.2915
Step: 11295, loss: 3.221506, norm: 0.2890, time(ms): 790.40, token/sec:663318.21, hellaswag_acc: 0.2915
Step: 11296, loss: 3.107638, norm: 0.2795, time(ms): 796.31, token/sec:658398.67, hellaswag_acc: 0.2915
Step: 11297, loss: 3.138377, norm: 0.2918, time(ms): 790.61, token/sec:663144.59, hellaswag_acc: 0.2915
Step: 11298, loss: 3.210912, norm: 0.2945, time(ms): 790.98, token/sec:662831.96, hellaswag_acc: 0.2915
Step: 11299, loss: 3.155038, norm: 0.2789, time(ms): 792.80, token/sec:661314.23, hellaswag_acc: 0.2915
Step: 11300, loss: 3.118501, norm: 0.2888, time(ms): 797.23, token/sec:657633.52, hellaswag_acc: 0.2915
Step: 11301, loss: 3.111920, norm: 0.2513, time(ms): 789.38, token/sec:664181.10, hellaswag_acc: 0.2915
Step: 11302, loss: 3.157092, norm: 0.3034, time(ms): 790.45, token/sec:663280.60, hellaswag_acc: 0.2915
Step: 11303, loss: 3.022028, norm: 0.3018, time(ms): 790.79, token/sec:662996.03, hellaswag_acc: 0.2915
Step: 11304, loss: 2.988596, norm: 0.2917, time(ms): 787.04, token/sec:666150.65, hellaswag_acc: 0.2915
Step: 11305, loss: 2.962468, norm: 0.2862, time(ms): 791.64, token/sec:662282.99, hellaswag_acc: 0.2915
Step: 11306, loss: 3.010890, norm: 0.3160, time(ms): 790.56, token/sec:663183.18, hellaswag_acc: 0.2915
Step: 11307, loss: 3.015616, norm: 0.2982, time(ms): 793.64, token/sec:660615.72, hellaswag_acc: 0.2915
Step: 11308, loss: 2.968645, norm: 0.3153, time(ms): 794.65, token/sec:659772.76, hellaswag_acc: 0.2915
Step: 11309, loss: 2.956321, norm: 0.2948, time(ms): 794.19, token/sec:660155.82, hellaswag_acc: 0.2915
Step: 11310, loss: 3.033582, norm: 0.2866, time(ms): 799.81, token/sec:655517.69, hellaswag_acc: 0.2915
Step: 11311, loss: 2.988385, norm: 0.3188, time(ms): 800.82, token/sec:654686.90, hellaswag_acc: 0.2915
Step: 11312, loss: 2.991808, norm: 0.2869, time(ms): 797.82, token/sec:657150.27, hellaswag_acc: 0.2915
Step: 11313, loss: 3.000328, norm: 0.2868, time(ms): 804.99, token/sec:651294.40, hellaswag_acc: 0.2915
Step: 11314, loss: 2.948604, norm: 0.2699, time(ms): 801.43, token/sec:654193.76, hellaswag_acc: 0.2915
Step: 11315, loss: 3.116973, norm: 0.3161, time(ms): 792.46, token/sec:661593.58, hellaswag_acc: 0.2915
Step: 11316, loss: 3.135931, norm: 0.2974, time(ms): 798.70, token/sec:656426.22, hellaswag_acc: 0.2915
Step: 11317, loss: 3.182236, norm: 0.3058, time(ms): 806.51, token/sec:650070.08, hellaswag_acc: 0.2915
Step: 11318, loss: 3.108457, norm: 0.2914, time(ms): 802.39, token/sec:653404.56, hellaswag_acc: 0.2915
Step: 11319, loss: 3.117842, norm: 0.2943, time(ms): 797.62, token/sec:657313.70, hellaswag_acc: 0.2915
Step: 11320, loss: 3.108608, norm: 0.2657, time(ms): 791.15, token/sec:662694.74, hellaswag_acc: 0.2915
Step: 11321, loss: 3.159223, norm: 0.2965, time(ms): 795.10, token/sec:659397.06, hellaswag_acc: 0.2915
Step: 11322, loss: 3.131067, norm: 0.2780, time(ms): 795.19, token/sec:659325.29, hellaswag_acc: 0.2915
Step: 11323, loss: 3.131454, norm: 0.3847, time(ms): 794.15, token/sec:660183.96, hellaswag_acc: 0.2915
Step: 11324, loss: 3.121546, norm: 0.3005, time(ms): 802.40, token/sec:653401.26, hellaswag_acc: 0.2915
Step: 11325, loss: 3.092713, norm: 0.2667, time(ms): 802.01, token/sec:653718.85, hellaswag_acc: 0.2915
Step: 11326, loss: 3.135952, norm: 0.3292, time(ms): 798.75, token/sec:656384.49, hellaswag_acc: 0.2915
Step: 11327, loss: 3.153647, norm: 0.2775, time(ms): 793.36, token/sec:660844.42, hellaswag_acc: 0.2915
Step: 11328, loss: 3.223810, norm: 0.3100, time(ms): 792.12, token/sec:661882.52, hellaswag_acc: 0.2915
Step: 11329, loss: 3.214959, norm: 0.3051, time(ms): 791.69, token/sec:662241.71, hellaswag_acc: 0.2915
Step: 11330, loss: 3.204852, norm: 0.2914, time(ms): 788.43, token/sec:664973.23, hellaswag_acc: 0.2915
Step: 11331, loss: 3.200488, norm: 0.3193, time(ms): 791.84, token/sec:662109.51, hellaswag_acc: 0.2915
Step: 11332, loss: 3.283419, norm: 0.3026, time(ms): 800.14, token/sec:655242.48, hellaswag_acc: 0.2915
Step: 11333, loss: 3.167608, norm: 0.2952, time(ms): 803.69, token/sec:652347.97, hellaswag_acc: 0.2915
Step: 11334, loss: 3.223493, norm: 0.2756, time(ms): 799.13, token/sec:656072.34, hellaswag_acc: 0.2915
Step: 11335, loss: 3.247822, norm: 0.3072, time(ms): 789.23, token/sec:664303.49, hellaswag_acc: 0.2915
Step: 11336, loss: 3.149663, norm: 0.2598, time(ms): 799.25, token/sec:655973.11, hellaswag_acc: 0.2915
Step: 11337, loss: 3.178743, norm: 0.3044, time(ms): 790.88, token/sec:662913.69, hellaswag_acc: 0.2915
Step: 11338, loss: 3.187790, norm: 0.2613, time(ms): 790.55, token/sec:663190.98, hellaswag_acc: 0.2915
Step: 11339, loss: 3.127596, norm: 0.3088, time(ms): 793.60, token/sec:660649.26, hellaswag_acc: 0.2915
Step: 11340, loss: 3.148719, norm: 0.2608, time(ms): 791.40, token/sec:662479.32, hellaswag_acc: 0.2915
Step: 11341, loss: 3.092374, norm: 0.2768, time(ms): 800.88, token/sec:654638.18, hellaswag_acc: 0.2915
Step: 11342, loss: 3.126507, norm: 0.2785, time(ms): 801.09, token/sec:654467.51, hellaswag_acc: 0.2915
Step: 11343, loss: 3.187091, norm: 0.2782, time(ms): 794.73, token/sec:659703.08, hellaswag_acc: 0.2915
Step: 11344, loss: 3.127800, norm: 0.2849, time(ms): 800.13, token/sec:655249.71, hellaswag_acc: 0.2915
Step: 11345, loss: 3.105273, norm: 0.2628, time(ms): 805.24, token/sec:651098.29, hellaswag_acc: 0.2915
Step: 11346, loss: 3.090447, norm: 0.2801, time(ms): 800.73, token/sec:654759.81, hellaswag_acc: 0.2915
Step: 11347, loss: 3.121072, norm: 0.2711, time(ms): 791.85, token/sec:662101.93, hellaswag_acc: 0.2915
Step: 11348, loss: 3.135258, norm: 0.2797, time(ms): 800.81, token/sec:654699.57, hellaswag_acc: 0.2915
Step: 11349, loss: 3.142350, norm: 0.2443, time(ms): 807.61, token/sec:649182.30, hellaswag_acc: 0.2915
Step: 11350, loss: 3.036594, norm: 0.2899, time(ms): 788.43, token/sec:664979.47, hellaswag_acc: 0.2915
Step: 11351, loss: 2.954589, norm: 0.2735, time(ms): 792.45, token/sec:661605.52, hellaswag_acc: 0.2915
Step: 11352, loss: 3.066506, norm: 0.2856, time(ms): 790.55, token/sec:663196.18, hellaswag_acc: 0.2915
Step: 11353, loss: 3.003657, norm: 0.2913, time(ms): 806.59, token/sec:650004.55, hellaswag_acc: 0.2915
Step: 11354, loss: 2.971804, norm: 0.2759, time(ms): 801.16, token/sec:654409.47, hellaswag_acc: 0.2915
Step: 11355, loss: 3.018094, norm: 0.2778, time(ms): 787.91, token/sec:665417.52, hellaswag_acc: 0.2915
Step: 11356, loss: 2.945342, norm: 0.2754, time(ms): 788.29, token/sec:665093.30, hellaswag_acc: 0.2915
Step: 11357, loss: 2.913665, norm: 0.2651, time(ms): 793.03, token/sec:661119.19, hellaswag_acc: 0.2915
Step: 11358, loss: 3.031873, norm: 0.2613, time(ms): 794.71, token/sec:659723.27, hellaswag_acc: 0.2915
Step: 11359, loss: 2.964136, norm: 0.2638, time(ms): 792.72, token/sec:661378.28, hellaswag_acc: 0.2915
Step: 11360, loss: 2.963546, norm: 0.2711, time(ms): 789.15, token/sec:664366.91, hellaswag_acc: 0.2915
Step: 11361, loss: 2.974652, norm: 0.2568, time(ms): 791.77, token/sec:662175.50, hellaswag_acc: 0.2915
Step: 11362, loss: 3.134258, norm: 0.3071, time(ms): 786.71, token/sec:666432.28, hellaswag_acc: 0.2915
Step: 11363, loss: 3.117429, norm: 0.2983, time(ms): 794.98, token/sec:659501.28, hellaswag_acc: 0.2915
Step: 11364, loss: 3.163305, norm: 0.2897, time(ms): 790.21, token/sec:663481.92, hellaswag_acc: 0.2915
Step: 11365, loss: 3.149223, norm: 0.3234, time(ms): 804.57, token/sec:651634.27, hellaswag_acc: 0.2915
Step: 11366, loss: 3.112800, norm: 0.2737, time(ms): 802.53, token/sec:653296.63, hellaswag_acc: 0.2915
Step: 11367, loss: 3.125022, norm: 0.3100, time(ms): 797.30, token/sec:657582.59, hellaswag_acc: 0.2915
Step: 11368, loss: 3.160604, norm: 0.2656, time(ms): 799.50, token/sec:655766.35, hellaswag_acc: 0.2915
Step: 11369, loss: 3.108044, norm: 0.3060, time(ms): 799.67, token/sec:655629.88, hellaswag_acc: 0.2915
Step: 11370, loss: 3.130219, norm: 0.2790, time(ms): 797.95, token/sec:657040.90, hellaswag_acc: 0.2915
Step: 11371, loss: 3.173220, norm: 0.2776, time(ms): 801.91, token/sec:653803.00, hellaswag_acc: 0.2915
Step: 11372, loss: 3.150137, norm: 0.2817, time(ms): 803.76, token/sec:652292.05, hellaswag_acc: 0.2915
Step: 11373, loss: 3.136045, norm: 0.3004, time(ms): 798.19, token/sec:656846.41, hellaswag_acc: 0.2915
Step: 11374, loss: 3.135076, norm: 0.2852, time(ms): 797.68, token/sec:657266.35, hellaswag_acc: 0.2915
Step: 11375, loss: 3.181340, norm: 0.2848, time(ms): 800.45, token/sec:654995.20, hellaswag_acc: 0.2915
Step: 11376, loss: 3.188888, norm: 0.2903, time(ms): 802.69, token/sec:653163.91, hellaswag_acc: 0.2915
Step: 11377, loss: 3.050399, norm: 0.3191, time(ms): 793.79, token/sec:660484.76, hellaswag_acc: 0.2915
Step: 11378, loss: 3.205884, norm: 0.3180, time(ms): 796.38, token/sec:658339.93, hellaswag_acc: 0.2915
Step: 11379, loss: 3.159246, norm: 0.3118, time(ms): 793.39, token/sec:660817.41, hellaswag_acc: 0.2915
Step: 11380, loss: 3.138979, norm: 0.3036, time(ms): 786.79, token/sec:666359.78, hellaswag_acc: 0.2915
Step: 11381, loss: 3.132297, norm: 0.3135, time(ms): 790.53, token/sec:663210.79, hellaswag_acc: 0.2915
Step: 11382, loss: 3.126042, norm: 0.2879, time(ms): 788.54, token/sec:664880.34, hellaswag_acc: 0.2915
Step: 11383, loss: 3.156306, norm: 0.3210, time(ms): 790.54, token/sec:663203.18, hellaswag_acc: 0.2915
Step: 11384, loss: 3.168325, norm: 0.2922, time(ms): 797.50, token/sec:657416.87, hellaswag_acc: 0.2915
Step: 11385, loss: 3.108491, norm: 0.3058, time(ms): 791.51, token/sec:662391.52, hellaswag_acc: 0.2915
Step: 11386, loss: 3.114821, norm: 0.2632, time(ms): 806.23, token/sec:650294.42, hellaswag_acc: 0.2915
Step: 11387, loss: 3.135095, norm: 0.3016, time(ms): 804.81, token/sec:651445.86, hellaswag_acc: 0.2915
Step: 11388, loss: 3.137968, norm: 0.2571, time(ms): 793.91, token/sec:660385.19, hellaswag_acc: 0.2915
Step: 11389, loss: 3.107759, norm: 0.2797, time(ms): 800.74, token/sec:654757.08, hellaswag_acc: 0.2915
Step: 11390, loss: 3.119574, norm: 0.2559, time(ms): 803.12, token/sec:652812.75, hellaswag_acc: 0.2915
Step: 11391, loss: 3.130651, norm: 0.2742, time(ms): 801.07, token/sec:654488.54, hellaswag_acc: 0.2915
Step: 11392, loss: 3.127050, norm: 0.2604, time(ms): 788.70, token/sec:664752.92, hellaswag_acc: 0.2915
Step: 11393, loss: 3.059032, norm: 0.2808, time(ms): 799.97, token/sec:655381.13, hellaswag_acc: 0.2915
Step: 11394, loss: 3.208861, norm: 0.3244, time(ms): 791.78, token/sec:662160.35, hellaswag_acc: 0.2915
Step: 11395, loss: 3.178164, norm: 0.3279, time(ms): 788.28, token/sec:665100.54, hellaswag_acc: 0.2915
Step: 11396, loss: 3.112342, norm: 0.2952, time(ms): 790.86, token/sec:662936.67, hellaswag_acc: 0.2915
Step: 11397, loss: 3.007192, norm: 0.2764, time(ms): 788.85, token/sec:664626.74, hellaswag_acc: 0.2915
Step: 11398, loss: 3.037105, norm: 0.2940, time(ms): 793.52, token/sec:660710.99, hellaswag_acc: 0.2915
Step: 11399, loss: 3.020840, norm: 0.2773, time(ms): 794.35, token/sec:660017.91, hellaswag_acc: 0.2915
Step: 11400, loss: 2.953735, norm: 0.2861, time(ms): 798.45, token/sec:656636.15, hellaswag_acc: 0.2915
Step: 11401, loss: 2.935952, norm: 0.2905, time(ms): 797.52, token/sec:657397.21, hellaswag_acc: 0.2915
Step: 11402, loss: 2.930453, norm: 0.2761, time(ms): 798.24, token/sec:656804.82, hellaswag_acc: 0.2915
Step: 11403, loss: 2.999007, norm: 0.2735, time(ms): 797.51, token/sec:657403.11, hellaswag_acc: 0.2915
Step: 11404, loss: 3.015361, norm: 0.2711, time(ms): 790.88, token/sec:662918.29, hellaswag_acc: 0.2915
Step: 11405, loss: 3.022070, norm: 0.2735, time(ms): 786.07, token/sec:666970.15, hellaswag_acc: 0.2915
Step: 11406, loss: 2.955204, norm: 0.2556, time(ms): 791.47, token/sec:662425.04, hellaswag_acc: 0.2915
Step: 11407, loss: 2.968406, norm: 0.2523, time(ms): 797.40, token/sec:657499.62, hellaswag_acc: 0.2915
Step: 11408, loss: 3.008877, norm: 0.2634, time(ms): 803.47, token/sec:652527.80, hellaswag_acc: 0.2915
Step: 11409, loss: 3.199873, norm: 0.3121, time(ms): 792.82, token/sec:661297.93, hellaswag_acc: 0.2915
Step: 11410, loss: 3.179595, norm: 0.3076, time(ms): 800.50, token/sec:654949.94, hellaswag_acc: 0.2915
Step: 11411, loss: 3.148454, norm: 0.2895, time(ms): 804.00, token/sec:652100.74, hellaswag_acc: 0.2915
Step: 11412, loss: 3.166319, norm: 0.2727, time(ms): 801.84, token/sec:653856.08, hellaswag_acc: 0.2915
Step: 11413, loss: 3.170466, norm: 0.2788, time(ms): 789.59, token/sec:664000.20, hellaswag_acc: 0.2915
Step: 11414, loss: 3.150157, norm: 0.2851, time(ms): 807.15, token/sec:649552.01, hellaswag_acc: 0.2915
Step: 11415, loss: 3.161496, norm: 0.2861, time(ms): 803.71, token/sec:652333.84, hellaswag_acc: 0.2915
Step: 11416, loss: 3.168525, norm: 0.2802, time(ms): 791.16, token/sec:662684.95, hellaswag_acc: 0.2915
Step: 11417, loss: 3.129471, norm: 0.2725, time(ms): 804.43, token/sec:651749.18, hellaswag_acc: 0.2915
Step: 11418, loss: 3.183532, norm: 0.2993, time(ms): 802.37, token/sec:653423.20, hellaswag_acc: 0.2915
Step: 11419, loss: 3.163785, norm: 0.2736, time(ms): 795.85, token/sec:658779.74, hellaswag_acc: 0.2915
Step: 11420, loss: 3.139793, norm: 0.3042, time(ms): 792.88, token/sec:661243.64, hellaswag_acc: 0.2915
Step: 11421, loss: 3.151652, norm: 0.2705, time(ms): 790.64, token/sec:663119.19, hellaswag_acc: 0.2915
Step: 11422, loss: 3.166634, norm: 0.2953, time(ms): 788.79, token/sec:664675.56, hellaswag_acc: 0.2915
Step: 11423, loss: 3.282680, norm: 0.2888, time(ms): 792.00, token/sec:661980.75, hellaswag_acc: 0.2915
Step: 11424, loss: 3.156347, norm: 0.2990, time(ms): 793.25, token/sec:660938.17, hellaswag_acc: 0.2915
Step: 11425, loss: 3.169401, norm: 0.2907, time(ms): 798.57, token/sec:656535.78, hellaswag_acc: 0.2915
Step: 11426, loss: 3.176667, norm: 0.2992, time(ms): 800.74, token/sec:654757.66, hellaswag_acc: 0.2915
Step: 11427, loss: 3.197738, norm: 0.2791, time(ms): 806.16, token/sec:650354.42, hellaswag_acc: 0.2915
Step: 11428, loss: 3.186873, norm: 0.2944, time(ms): 796.90, token/sec:657912.91, hellaswag_acc: 0.2915
Step: 11429, loss: 3.393254, norm: 0.4639, time(ms): 1304.70, token/sec:401844.34, hellaswag_acc: 0.2915
Step: 11430, loss: 3.151678, norm: 0.3627, time(ms): 765.64, token/sec:684768.76, hellaswag_acc: 0.2915
Step: 11431, loss: 3.167213, norm: 0.3263, time(ms): 793.20, token/sec:660978.10, hellaswag_acc: 0.2915
Step: 11432, loss: 3.107165, norm: 0.3148, time(ms): 797.66, token/sec:657285.01, hellaswag_acc: 0.2915
Step: 11433, loss: 3.101174, norm: 0.2986, time(ms): 786.66, token/sec:666476.11, hellaswag_acc: 0.2915
Step: 11434, loss: 3.161445, norm: 0.3041, time(ms): 779.28, token/sec:672788.06, hellaswag_acc: 0.2915
Step: 11435, loss: 3.155910, norm: 0.2677, time(ms): 786.39, token/sec:666702.82, hellaswag_acc: 0.2915
Step: 11436, loss: 3.114463, norm: 0.3120, time(ms): 800.52, token/sec:654934.73, hellaswag_acc: 0.2915
Step: 11437, loss: 3.112305, norm: 0.2811, time(ms): 797.52, token/sec:657397.80, hellaswag_acc: 0.2915
Step: 11438, loss: 3.063609, norm: 0.2825, time(ms): 790.27, token/sec:663427.08, hellaswag_acc: 0.2915
Step: 11439, loss: 3.039937, norm: 0.2738, time(ms): 787.50, token/sec:665761.81, hellaswag_acc: 0.2915
Step: 11440, loss: 3.115622, norm: 0.2786, time(ms): 792.49, token/sec:661570.29, hellaswag_acc: 0.2915
Step: 11441, loss: 3.085485, norm: 0.2691, time(ms): 799.63, token/sec:655666.82, hellaswag_acc: 0.2915
Step: 11442, loss: 3.096010, norm: 0.2728, time(ms): 788.61, token/sec:664829.09, hellaswag_acc: 0.2915
Step: 11443, loss: 3.071616, norm: 0.2638, time(ms): 789.42, token/sec:664144.19, hellaswag_acc: 0.2915
Step: 11444, loss: 3.085618, norm: 0.2623, time(ms): 790.43, token/sec:663294.60, hellaswag_acc: 0.2915
Step: 11445, loss: 3.131009, norm: 0.2672, time(ms): 789.79, token/sec:663835.64, hellaswag_acc: 0.2915
Step: 11446, loss: 3.083979, norm: 0.2607, time(ms): 787.66, token/sec:665628.41, hellaswag_acc: 0.2915
Step: 11447, loss: 3.064064, norm: 0.2605, time(ms): 791.08, token/sec:662750.26, hellaswag_acc: 0.2915
Step: 11448, loss: 3.189556, norm: 0.2872, time(ms): 787.00, token/sec:666183.95, hellaswag_acc: 0.2915
Step: 11449, loss: 3.245870, norm: 0.2493, time(ms): 793.12, token/sec:661042.48, hellaswag_acc: 0.2915
Step: 11450, loss: 3.157977, norm: 0.3166, time(ms): 794.60, token/sec:659817.30, hellaswag_acc: 0.2915
Step: 11451, loss: 3.219660, norm: 0.2703, time(ms): 798.36, token/sec:656708.32, hellaswag_acc: 0.2915
Step: 11452, loss: 3.197248, norm: 0.3050, time(ms): 803.58, token/sec:652438.74, hellaswag_acc: 0.2915
Step: 11453, loss: 3.130096, norm: 0.3466, time(ms): 799.63, token/sec:655666.82, hellaswag_acc: 0.2915
Step: 11454, loss: 3.190506, norm: 0.2819, time(ms): 799.80, token/sec:655524.73, hellaswag_acc: 0.2915
Step: 11455, loss: 3.180862, norm: 0.2987, time(ms): 800.53, token/sec:654922.44, hellaswag_acc: 0.2915
Step: 11456, loss: 3.231950, norm: 0.2796, time(ms): 799.72, token/sec:655592.54, hellaswag_acc: 0.2915
Step: 11457, loss: 3.168397, norm: 0.3186, time(ms): 802.75, token/sec:653112.89, hellaswag_acc: 0.2915
Step: 11458, loss: 3.177279, norm: 0.3111, time(ms): 797.84, token/sec:657137.70, hellaswag_acc: 0.2915
Step: 11459, loss: 3.090392, norm: 0.2849, time(ms): 797.85, token/sec:657125.13, hellaswag_acc: 0.2915
Step: 11460, loss: 3.137459, norm: 0.2804, time(ms): 799.71, token/sec:655597.63, hellaswag_acc: 0.2915
Step: 11461, loss: 3.115384, norm: 0.2632, time(ms): 801.56, token/sec:654081.48, hellaswag_acc: 0.2915
Step: 11462, loss: 3.180937, norm: 0.3097, time(ms): 794.21, token/sec:660139.17, hellaswag_acc: 0.2915
Step: 11463, loss: 3.127969, norm: 0.2647, time(ms): 797.60, token/sec:657332.95, hellaswag_acc: 0.2915
Step: 11464, loss: 3.128092, norm: 0.2839, time(ms): 793.62, token/sec:660628.22, hellaswag_acc: 0.2915
Step: 11465, loss: 3.160256, norm: 0.2597, time(ms): 794.79, token/sec:659655.19, hellaswag_acc: 0.2915
Step: 11466, loss: 3.166065, norm: 0.2708, time(ms): 798.13, token/sec:656891.74, hellaswag_acc: 0.2915
Step: 11467, loss: 3.104915, norm: 0.2870, time(ms): 799.35, token/sec:655891.92, hellaswag_acc: 0.2915
Step: 11468, loss: 3.177736, norm: 0.2992, time(ms): 803.18, token/sec:652761.98, hellaswag_acc: 0.2915
Step: 11469, loss: 3.165550, norm: 0.2725, time(ms): 797.39, token/sec:657508.07, hellaswag_acc: 0.2915
Step: 11470, loss: 3.130541, norm: 0.2842, time(ms): 800.38, token/sec:655052.18, hellaswag_acc: 0.2915
Step: 11471, loss: 3.090775, norm: 0.2665, time(ms): 800.44, token/sec:654999.89, hellaswag_acc: 0.2915
Step: 11472, loss: 3.093286, norm: 0.2762, time(ms): 797.21, token/sec:657652.60, hellaswag_acc: 0.2915
Step: 11473, loss: 3.077158, norm: 0.2613, time(ms): 799.02, token/sec:656167.48, hellaswag_acc: 0.2915
Step: 11474, loss: 3.078204, norm: 0.2769, time(ms): 802.01, token/sec:653713.60, hellaswag_acc: 0.2915
Step: 11475, loss: 3.115983, norm: 0.2666, time(ms): 793.73, token/sec:660536.15, hellaswag_acc: 0.2915
Step: 11476, loss: 3.072729, norm: 0.2708, time(ms): 790.17, token/sec:663511.75, hellaswag_acc: 0.2915
Step: 11477, loss: 3.066955, norm: 0.2850, time(ms): 788.62, token/sec:664819.64, hellaswag_acc: 0.2915
Step: 11478, loss: 3.069069, norm: 0.2560, time(ms): 795.98, token/sec:658673.58, hellaswag_acc: 0.2915
Step: 11479, loss: 3.100502, norm: 0.2736, time(ms): 789.49, token/sec:664086.63, hellaswag_acc: 0.2915
Step: 11480, loss: 3.051806, norm: 0.2693, time(ms): 797.13, token/sec:657722.04, hellaswag_acc: 0.2915
Step: 11481, loss: 3.096584, norm: 0.2484, time(ms): 806.09, token/sec:650410.79, hellaswag_acc: 0.2915
Step: 11482, loss: 3.172503, norm: 0.2811, time(ms): 800.00, token/sec:655362.19, hellaswag_acc: 0.2915
Step: 11483, loss: 3.131149, norm: 0.2835, time(ms): 793.53, token/sec:660704.84, hellaswag_acc: 0.2915
Step: 11484, loss: 3.169069, norm: 0.2699, time(ms): 805.03, token/sec:651266.05, hellaswag_acc: 0.2915
Step: 11485, loss: 3.155556, norm: 0.2790, time(ms): 802.21, token/sec:653553.51, hellaswag_acc: 0.2915
Step: 11486, loss: 3.138188, norm: 0.2647, time(ms): 789.80, token/sec:663826.02, hellaswag_acc: 0.2915
Step: 11487, loss: 3.161958, norm: 0.2796, time(ms): 792.35, token/sec:661685.95, hellaswag_acc: 0.2915
Step: 11488, loss: 3.194711, norm: 0.2832, time(ms): 792.33, token/sec:661703.87, hellaswag_acc: 0.2915
Step: 11489, loss: 3.150487, norm: 0.2707, time(ms): 791.16, token/sec:662682.15, hellaswag_acc: 0.2915
Step: 11490, loss: 3.151705, norm: 0.3774, time(ms): 792.84, token/sec:661275.85, hellaswag_acc: 0.2915
Step: 11491, loss: 3.160501, norm: 0.2970, time(ms): 793.94, token/sec:660361.99, hellaswag_acc: 0.2915
Step: 11492, loss: 3.133703, norm: 0.3068, time(ms): 799.38, token/sec:655864.53, hellaswag_acc: 0.2915
Step: 11493, loss: 3.109735, norm: 0.3050, time(ms): 803.31, token/sec:652661.04, hellaswag_acc: 0.2915
Step: 11494, loss: 3.057841, norm: 0.3317, time(ms): 798.65, token/sec:656468.36, hellaswag_acc: 0.2915
Step: 11495, loss: 3.103013, norm: 0.2754, time(ms): 799.00, token/sec:656180.20, hellaswag_acc: 0.2915
Step: 11496, loss: 3.106349, norm: 0.3171, time(ms): 800.81, token/sec:654697.82, hellaswag_acc: 0.2915
Step: 11497, loss: 3.206986, norm: 0.3018, time(ms): 802.79, token/sec:653085.34, hellaswag_acc: 0.2915
Step: 11498, loss: 3.135613, norm: 0.3176, time(ms): 801.82, token/sec:653876.10, hellaswag_acc: 0.2915
Step: 11499, loss: 3.116870, norm: 0.2973, time(ms): 792.55, token/sec:661520.73, hellaswag_acc: 0.2915
rank 0 sample 0: Hello, I'm a language model, and I don't have it to go backwards from that.
A thing like this can be seen by any language interpreter
rank 0 sample 1: Hello, I'm a language model, I understand that I am a linguist, I're one, I'm just one person.
When I was a
rank 0 sample 2: Hello, I'm a language model, so I use this approach at the time. When I'm using Python, I always start with the smallest number of symbols
rank 0 sample 3: Hello, I'm a language model, I believe that there are two kinds of people within the world who make language learning that works with just one language and people
rank 1 sample 0: Hello, I'm a language model, that means that I'm not actually following a single programming language so I'm following a lot of things. But I'm
rank 1 sample 1: Hello, I'm a language model, not an interpreter. I'm a person but I'm able to explain something new to the program! I'm a person
rank 1 sample 2: Hello, I'm a language model, I won't tell you how to write a program that is able to read two languages. You could use the "d
rank 1 sample 3: Hello, I'm a language model, and I'm working with language models as follows:
a = 3 -> p -> 10 -> 1 -> 2 -> 3
Step: 11500, loss: 3.155602, norm: 0.3030, time(ms): 3815.21, token/sec:137420.62, val_loss: 3.1580, hellaswag_acc: 0.2915
Step: 11501, loss: 3.147611, norm: 0.3004, time(ms): 793.45, token/sec:660766.18, hellaswag_acc: 0.2915
Step: 11502, loss: 3.125309, norm: 0.2838, time(ms): 785.26, token/sec:667658.66, hellaswag_acc: 0.2915
Step: 11503, loss: 3.135103, norm: 0.2880, time(ms): 792.82, token/sec:661295.94, hellaswag_acc: 0.2915
Step: 11504, loss: 3.180721, norm: 0.2811, time(ms): 797.25, token/sec:657617.00, hellaswag_acc: 0.2915
Step: 11505, loss: 3.143795, norm: 0.2610, time(ms): 796.65, token/sec:658117.69, hellaswag_acc: 0.2915
Step: 11506, loss: 3.124900, norm: 0.2686, time(ms): 802.42, token/sec:653385.73, hellaswag_acc: 0.2915
Step: 11507, loss: 3.079243, norm: 0.3059, time(ms): 799.39, token/sec:655858.27, hellaswag_acc: 0.2915
Step: 11508, loss: 3.092915, norm: 0.2713, time(ms): 798.30, token/sec:656759.51, hellaswag_acc: 0.2915
Step: 11509, loss: 3.099975, norm: 0.2716, time(ms): 800.36, token/sec:655064.86, hellaswag_acc: 0.2915
Step: 11510, loss: 3.104627, norm: 0.2784, time(ms): 800.28, token/sec:655127.50, hellaswag_acc: 0.2915
Step: 11511, loss: 3.081430, norm: 0.2878, time(ms): 795.64, token/sec:658950.90, hellaswag_acc: 0.2915
Step: 11512, loss: 3.020370, norm: 0.2592, time(ms): 797.27, token/sec:657604.61, hellaswag_acc: 0.2915
Step: 11513, loss: 3.050576, norm: 0.2720, time(ms): 788.63, token/sec:664809.99, hellaswag_acc: 0.2915
Step: 11514, loss: 3.038687, norm: 0.2550, time(ms): 787.09, token/sec:666106.66, hellaswag_acc: 0.2915
Step: 11515, loss: 3.095510, norm: 0.2553, time(ms): 793.21, token/sec:660966.38, hellaswag_acc: 0.2915
Step: 11516, loss: 3.089241, norm: 0.2615, time(ms): 790.47, token/sec:663262.39, hellaswag_acc: 0.2915
Step: 11517, loss: 3.093184, norm: 0.2501, time(ms): 802.30, token/sec:653483.40, hellaswag_acc: 0.2915
Step: 11518, loss: 3.181905, norm: 0.2827, time(ms): 808.06, token/sec:648822.78, hellaswag_acc: 0.2915
Step: 11519, loss: 3.149006, norm: 0.2451, time(ms): 799.83, token/sec:655498.15, hellaswag_acc: 0.2915
Step: 11520, loss: 3.157415, norm: 0.2813, time(ms): 784.26, token/sec:668515.00, hellaswag_acc: 0.2915
Step: 11521, loss: 3.216228, norm: 0.2679, time(ms): 790.16, token/sec:663520.16, hellaswag_acc: 0.2915
Step: 11522, loss: 3.129814, norm: 0.2688, time(ms): 799.05, token/sec:656137.91, hellaswag_acc: 0.2915
Step: 11523, loss: 3.181974, norm: 0.2575, time(ms): 790.54, token/sec:663205.99, hellaswag_acc: 0.2915
Step: 11524, loss: 3.173993, norm: 0.2703, time(ms): 794.13, token/sec:660202.19, hellaswag_acc: 0.2915
Step: 11525, loss: 3.219555, norm: 0.2690, time(ms): 795.14, token/sec:659365.82, hellaswag_acc: 0.2915
Step: 11526, loss: 3.188646, norm: 0.2767, time(ms): 798.75, token/sec:656388.80, hellaswag_acc: 0.2915
Step: 11527, loss: 3.179809, norm: 0.2936, time(ms): 802.52, token/sec:653298.38, hellaswag_acc: 0.2915
Step: 11528, loss: 3.137349, norm: 0.2788, time(ms): 796.78, token/sec:658004.65, hellaswag_acc: 0.2915
Step: 11529, loss: 3.062758, norm: 0.2615, time(ms): 797.13, token/sec:657719.87, hellaswag_acc: 0.2915
Step: 11530, loss: 3.084683, norm: 0.3003, time(ms): 793.45, token/sec:660770.35, hellaswag_acc: 0.2915
Step: 11531, loss: 3.156939, norm: 0.2861, time(ms): 795.56, token/sec:659020.01, hellaswag_acc: 0.2915
Step: 11532, loss: 3.237347, norm: 0.3119, time(ms): 796.29, token/sec:658410.70, hellaswag_acc: 0.2915
Step: 11533, loss: 3.149011, norm: 0.2766, time(ms): 796.94, token/sec:657878.67, hellaswag_acc: 0.2915
Step: 11534, loss: 3.109815, norm: 0.3032, time(ms): 797.29, token/sec:657587.31, hellaswag_acc: 0.2915
Step: 11535, loss: 3.118729, norm: 0.2836, time(ms): 790.11, token/sec:663566.21, hellaswag_acc: 0.2915
Step: 11536, loss: 3.103857, norm: 0.2896, time(ms): 787.83, token/sec:665485.99, hellaswag_acc: 0.2915
Step: 11537, loss: 3.088374, norm: 0.2794, time(ms): 790.43, token/sec:663294.80, hellaswag_acc: 0.2915
Step: 11538, loss: 3.141335, norm: 0.2980, time(ms): 798.47, token/sec:656617.92, hellaswag_acc: 0.2915
Step: 11539, loss: 3.119646, norm: 0.2569, time(ms): 797.04, token/sec:657794.44, hellaswag_acc: 0.2915
Step: 11540, loss: 3.178721, norm: 0.2710, time(ms): 804.37, token/sec:651801.92, hellaswag_acc: 0.2915
Step: 11541, loss: 3.094905, norm: 0.2838, time(ms): 794.68, token/sec:659749.60, hellaswag_acc: 0.2915
Step: 11542, loss: 3.095188, norm: 0.2910, time(ms): 802.53, token/sec:653290.42, hellaswag_acc: 0.2915
Step: 11543, loss: 3.054950, norm: 0.3366, time(ms): 801.86, token/sec:653836.64, hellaswag_acc: 0.2915
Step: 11544, loss: 3.135289, norm: 0.3164, time(ms): 799.26, token/sec:655963.92, hellaswag_acc: 0.2915
Step: 11545, loss: 3.097117, norm: 0.2935, time(ms): 795.42, token/sec:659129.65, hellaswag_acc: 0.2915
Step: 11546, loss: 3.141817, norm: 0.2798, time(ms): 802.47, token/sec:653341.47, hellaswag_acc: 0.2915
Step: 11547, loss: 3.060508, norm: 0.2828, time(ms): 802.52, token/sec:653304.79, hellaswag_acc: 0.2915
Step: 11548, loss: 3.077833, norm: 0.2727, time(ms): 795.30, token/sec:659235.75, hellaswag_acc: 0.2915
Step: 11549, loss: 3.076196, norm: 0.3098, time(ms): 796.95, token/sec:657866.07, hellaswag_acc: 0.2915
Step: 11550, loss: 3.069386, norm: 0.2774, time(ms): 805.81, token/sec:650638.25, hellaswag_acc: 0.2915
Step: 11551, loss: 3.045377, norm: 0.2807, time(ms): 801.83, token/sec:653864.83, hellaswag_acc: 0.2915
Step: 11552, loss: 3.123294, norm: 0.2942, time(ms): 793.99, token/sec:660319.95, hellaswag_acc: 0.2915
Step: 11553, loss: 3.113731, norm: 0.2971, time(ms): 802.54, token/sec:653283.05, hellaswag_acc: 0.2915
Step: 11554, loss: 3.111377, norm: 0.3120, time(ms): 802.55, token/sec:653274.32, hellaswag_acc: 0.2915
Step: 11555, loss: 3.167898, norm: 0.3322, time(ms): 795.03, token/sec:659457.37, hellaswag_acc: 0.2915
Step: 11556, loss: 3.191599, norm: 0.3066, time(ms): 802.79, token/sec:653082.24, hellaswag_acc: 0.2915
Step: 11557, loss: 3.126026, norm: 0.3070, time(ms): 797.91, token/sec:657075.85, hellaswag_acc: 0.2915
Step: 11558, loss: 3.176329, norm: 0.2993, time(ms): 804.25, token/sec:651899.50, hellaswag_acc: 0.2915
Step: 11559, loss: 3.212044, norm: 0.2899, time(ms): 794.79, token/sec:659659.55, hellaswag_acc: 0.2915
Step: 11560, loss: 3.141228, norm: 0.3184, time(ms): 802.46, token/sec:653354.67, hellaswag_acc: 0.2915
Step: 11561, loss: 3.131217, norm: 0.2983, time(ms): 799.67, token/sec:655632.22, hellaswag_acc: 0.2915
Step: 11562, loss: 3.144663, norm: 0.2732, time(ms): 799.54, token/sec:655737.40, hellaswag_acc: 0.2915
Step: 11563, loss: 3.264952, norm: 0.2886, time(ms): 802.51, token/sec:653311.77, hellaswag_acc: 0.2915
Step: 11564, loss: 3.187783, norm: 0.2952, time(ms): 785.84, token/sec:667168.05, hellaswag_acc: 0.2915
Step: 11565, loss: 3.107187, norm: 0.2633, time(ms): 791.08, token/sec:662751.26, hellaswag_acc: 0.2915
Step: 11566, loss: 3.120306, norm: 0.2941, time(ms): 792.54, token/sec:661528.50, hellaswag_acc: 0.2915
Step: 11567, loss: 3.174706, norm: 0.2587, time(ms): 794.83, token/sec:659625.91, hellaswag_acc: 0.2915
Step: 11568, loss: 3.045217, norm: 0.2925, time(ms): 788.92, token/sec:664564.28, hellaswag_acc: 0.2915
Step: 11569, loss: 3.079865, norm: 0.2577, time(ms): 794.75, token/sec:659685.67, hellaswag_acc: 0.2915
Step: 11570, loss: 3.139024, norm: 0.2760, time(ms): 792.03, token/sec:661958.23, hellaswag_acc: 0.2915
Step: 11571, loss: 3.071476, norm: 0.2825, time(ms): 795.67, token/sec:658923.45, hellaswag_acc: 0.2915
Step: 11572, loss: 3.110150, norm: 0.2450, time(ms): 786.88, token/sec:666288.51, hellaswag_acc: 0.2915
Step: 11573, loss: 3.129988, norm: 0.2818, time(ms): 784.34, token/sec:668443.67, hellaswag_acc: 0.2915
Step: 11574, loss: 3.149661, norm: 0.2554, time(ms): 796.21, token/sec:658475.96, hellaswag_acc: 0.2915
Step: 11575, loss: 3.160860, norm: 0.2735, time(ms): 794.91, token/sec:659559.83, hellaswag_acc: 0.2915
Step: 11576, loss: 3.129758, norm: 0.2545, time(ms): 786.10, token/sec:666949.11, hellaswag_acc: 0.2915
Step: 11577, loss: 3.096384, norm: 0.2524, time(ms): 790.19, token/sec:663493.33, hellaswag_acc: 0.2915
Step: 11578, loss: 3.078941, norm: 0.2600, time(ms): 797.47, token/sec:657439.66, hellaswag_acc: 0.2915
Step: 11579, loss: 3.095531, norm: 0.2528, time(ms): 791.59, token/sec:662323.29, hellaswag_acc: 0.2915
Step: 11580, loss: 3.040510, norm: 0.2883, time(ms): 793.36, token/sec:660846.01, hellaswag_acc: 0.2915
Step: 11581, loss: 3.043025, norm: 0.2597, time(ms): 792.04, token/sec:661947.47, hellaswag_acc: 0.2915
Step: 11582, loss: 3.086995, norm: 0.2687, time(ms): 803.19, token/sec:652758.88, hellaswag_acc: 0.2915
Step: 11583, loss: 3.133442, norm: 0.2738, time(ms): 803.89, token/sec:652191.64, hellaswag_acc: 0.2915
Step: 11584, loss: 3.063458, norm: 0.2728, time(ms): 800.99, token/sec:654553.81, hellaswag_acc: 0.2915
Step: 11585, loss: 3.119520, norm: 0.2817, time(ms): 790.80, token/sec:662980.64, hellaswag_acc: 0.2915
Step: 11586, loss: 3.047879, norm: 0.2849, time(ms): 807.21, token/sec:649505.01, hellaswag_acc: 0.2915
Step: 11587, loss: 3.027681, norm: 0.2774, time(ms): 800.32, token/sec:655100.96, hellaswag_acc: 0.2915
Step: 11588, loss: 3.126583, norm: 0.3099, time(ms): 793.40, token/sec:660815.23, hellaswag_acc: 0.2915
Step: 11589, loss: 3.196477, norm: 0.3040, time(ms): 804.10, token/sec:652020.89, hellaswag_acc: 0.2915
Step: 11590, loss: 3.259879, norm: 0.3559, time(ms): 802.05, token/sec:653688.53, hellaswag_acc: 0.2915
Step: 11591, loss: 3.150171, norm: 0.4178, time(ms): 790.46, token/sec:663265.80, hellaswag_acc: 0.2915
Step: 11592, loss: 3.179509, norm: 0.3126, time(ms): 791.94, token/sec:662032.56, hellaswag_acc: 0.2915
Step: 11593, loss: 3.197810, norm: 0.3316, time(ms): 795.18, token/sec:659328.46, hellaswag_acc: 0.2915
Step: 11594, loss: 3.188052, norm: 0.3361, time(ms): 798.91, token/sec:656251.09, hellaswag_acc: 0.2915
Step: 11595, loss: 3.200663, norm: 0.3095, time(ms): 801.27, token/sec:654318.34, hellaswag_acc: 0.2915
Step: 11596, loss: 3.143168, norm: 0.3102, time(ms): 797.85, token/sec:657122.78, hellaswag_acc: 0.2915
Step: 11597, loss: 3.165075, norm: 0.2901, time(ms): 797.82, token/sec:657148.89, hellaswag_acc: 0.2915
Step: 11598, loss: 3.162370, norm: 0.3230, time(ms): 799.15, token/sec:656058.44, hellaswag_acc: 0.2915
Step: 11599, loss: 3.143338, norm: 0.2813, time(ms): 799.01, token/sec:656171.79, hellaswag_acc: 0.2915
Step: 11600, loss: 3.144647, norm: 0.2921, time(ms): 797.67, token/sec:657276.96, hellaswag_acc: 0.2915
Step: 11601, loss: 3.190540, norm: 0.2883, time(ms): 790.76, token/sec:663019.82, hellaswag_acc: 0.2915
Step: 11602, loss: 3.175429, norm: 0.2987, time(ms): 785.42, token/sec:667529.35, hellaswag_acc: 0.2915
Step: 11603, loss: 3.125289, norm: 0.2934, time(ms): 789.04, token/sec:664460.26, hellaswag_acc: 0.2915
Step: 11604, loss: 3.191861, norm: 0.2794, time(ms): 803.38, token/sec:652605.84, hellaswag_acc: 0.2915
Step: 11605, loss: 3.186888, norm: 0.2694, time(ms): 799.80, token/sec:655520.63, hellaswag_acc: 0.2915
Step: 11606, loss: 3.107536, norm: 0.2901, time(ms): 791.83, token/sec:662121.27, hellaswag_acc: 0.2915
Step: 11607, loss: 3.139559, norm: 0.2919, time(ms): 805.42, token/sec:650949.30, hellaswag_acc: 0.2915
Step: 11608, loss: 3.106182, norm: 0.2725, time(ms): 803.37, token/sec:652609.13, hellaswag_acc: 0.2915
Step: 11609, loss: 3.111420, norm: 0.3090, time(ms): 788.22, token/sec:665156.07, hellaswag_acc: 0.2915
Step: 11610, loss: 3.142072, norm: 0.2587, time(ms): 792.21, token/sec:661808.42, hellaswag_acc: 0.2915
Step: 11611, loss: 3.110270, norm: 0.2768, time(ms): 794.05, token/sec:660274.55, hellaswag_acc: 0.2915
Step: 11612, loss: 3.081104, norm: 0.2834, time(ms): 794.34, token/sec:660032.77, hellaswag_acc: 0.2915
Step: 11613, loss: 3.157938, norm: 0.2805, time(ms): 791.91, token/sec:662056.68, hellaswag_acc: 0.2915
Step: 11614, loss: 3.071986, norm: 0.2860, time(ms): 788.01, token/sec:665335.58, hellaswag_acc: 0.2915
Step: 11615, loss: 3.099251, norm: 0.2754, time(ms): 794.85, token/sec:659603.16, hellaswag_acc: 0.2915
Step: 11616, loss: 3.049706, norm: 0.2701, time(ms): 794.00, token/sec:660313.01, hellaswag_acc: 0.2915
Step: 11617, loss: 3.151166, norm: 0.2807, time(ms): 790.82, token/sec:662970.25, hellaswag_acc: 0.2915
Step: 11618, loss: 3.063587, norm: 0.2721, time(ms): 790.01, token/sec:663648.32, hellaswag_acc: 0.2915
Step: 11619, loss: 3.078617, norm: 0.2811, time(ms): 787.26, token/sec:665962.83, hellaswag_acc: 0.2915
Step: 11620, loss: 3.039412, norm: 0.2716, time(ms): 1259.51, token/sec:416263.14, hellaswag_acc: 0.2915
Step: 11621, loss: 3.200955, norm: 0.2932, time(ms): 794.95, token/sec:659520.27, hellaswag_acc: 0.2915
Step: 11622, loss: 3.173633, norm: 0.3026, time(ms): 783.91, token/sec:668815.51, hellaswag_acc: 0.2915
Step: 11623, loss: 3.168705, norm: 0.2745, time(ms): 786.96, token/sec:666218.87, hellaswag_acc: 0.2915
Step: 11624, loss: 3.161264, norm: 0.2906, time(ms): 803.46, token/sec:652534.38, hellaswag_acc: 0.2915
Step: 11625, loss: 3.116815, norm: 0.2606, time(ms): 793.70, token/sec:660565.71, hellaswag_acc: 0.2915
Step: 11626, loss: 3.171143, norm: 0.3103, time(ms): 791.43, token/sec:662458.56, hellaswag_acc: 0.2915
Step: 11627, loss: 3.137635, norm: 0.2833, time(ms): 786.82, token/sec:666340.19, hellaswag_acc: 0.2915
Step: 11628, loss: 3.159330, norm: 0.3000, time(ms): 793.45, token/sec:660773.13, hellaswag_acc: 0.2915
Step: 11629, loss: 3.172769, norm: 0.2768, time(ms): 790.45, token/sec:663274.00, hellaswag_acc: 0.2915
Step: 11630, loss: 3.188541, norm: 0.2891, time(ms): 803.44, token/sec:652551.81, hellaswag_acc: 0.2915
Step: 11631, loss: 3.134861, norm: 0.2645, time(ms): 797.54, token/sec:657385.03, hellaswag_acc: 0.2915
Step: 11632, loss: 3.124754, norm: 0.2859, time(ms): 800.03, token/sec:655335.24, hellaswag_acc: 0.2915
Step: 11633, loss: 3.214353, norm: 0.2817, time(ms): 803.83, token/sec:652235.55, hellaswag_acc: 0.2915
Step: 11634, loss: 3.136866, norm: 0.2724, time(ms): 800.71, token/sec:654779.30, hellaswag_acc: 0.2915
Step: 11635, loss: 3.116652, norm: 0.2771, time(ms): 784.55, token/sec:668262.88, hellaswag_acc: 0.2915
Step: 11636, loss: 3.166662, norm: 0.2708, time(ms): 787.24, token/sec:665980.38, hellaswag_acc: 0.2915
Step: 11637, loss: 3.180405, norm: 0.2987, time(ms): 800.25, token/sec:655158.93, hellaswag_acc: 0.2915
Step: 11638, loss: 3.121557, norm: 0.2756, time(ms): 791.87, token/sec:662087.18, hellaswag_acc: 0.2915
Step: 11639, loss: 3.125640, norm: 0.3073, time(ms): 794.55, token/sec:659854.12, hellaswag_acc: 0.2915
Step: 11640, loss: 3.100169, norm: 0.2861, time(ms): 789.26, token/sec:664276.80, hellaswag_acc: 0.2915
Step: 11641, loss: 3.141440, norm: 0.2921, time(ms): 791.67, token/sec:662258.86, hellaswag_acc: 0.2915
Step: 11642, loss: 3.126767, norm: 0.3140, time(ms): 797.01, token/sec:657821.79, hellaswag_acc: 0.2915
Step: 11643, loss: 3.176344, norm: 0.2670, time(ms): 791.54, token/sec:662362.39, hellaswag_acc: 0.2915
Step: 11644, loss: 3.159379, norm: 0.3263, time(ms): 788.82, token/sec:664649.24, hellaswag_acc: 0.2915
Step: 11645, loss: 3.103218, norm: 0.2835, time(ms): 790.25, token/sec:663442.09, hellaswag_acc: 0.2915
Step: 11646, loss: 3.124085, norm: 0.3014, time(ms): 791.25, token/sec:662608.27, hellaswag_acc: 0.2915
Step: 11647, loss: 3.132135, norm: 0.2816, time(ms): 799.13, token/sec:656076.05, hellaswag_acc: 0.2915
Step: 11648, loss: 3.093380, norm: 0.2806, time(ms): 794.69, token/sec:659741.68, hellaswag_acc: 0.2915
Step: 11649, loss: 3.142410, norm: 0.3018, time(ms): 798.85, token/sec:656306.13, hellaswag_acc: 0.2915
Step: 11650, loss: 3.017173, norm: 0.2793, time(ms): 806.30, token/sec:650236.35, hellaswag_acc: 0.2915
Step: 11651, loss: 3.023126, norm: 0.2732, time(ms): 800.17, token/sec:655220.23, hellaswag_acc: 0.2915
Step: 11652, loss: 2.925203, norm: 0.2626, time(ms): 792.96, token/sec:661181.21, hellaswag_acc: 0.2915
Step: 11653, loss: 2.973933, norm: 0.2967, time(ms): 803.06, token/sec:652858.88, hellaswag_acc: 0.2915
Step: 11654, loss: 2.981859, norm: 0.2867, time(ms): 802.44, token/sec:653370.98, hellaswag_acc: 0.2915
Step: 11655, loss: 2.894750, norm: 0.2714, time(ms): 800.21, token/sec:655185.87, hellaswag_acc: 0.2915
Step: 11656, loss: 3.041424, norm: 0.3054, time(ms): 789.33, token/sec:664223.03, hellaswag_acc: 0.2915
Step: 11657, loss: 3.015651, norm: 0.3194, time(ms): 791.45, token/sec:662439.81, hellaswag_acc: 0.2915
Step: 11658, loss: 3.002062, norm: 0.2921, time(ms): 793.70, token/sec:660564.12, hellaswag_acc: 0.2915
Step: 11659, loss: 3.018445, norm: 0.2751, time(ms): 794.64, token/sec:659778.89, hellaswag_acc: 0.2915
Step: 11660, loss: 3.028464, norm: 0.2792, time(ms): 791.81, token/sec:662138.02, hellaswag_acc: 0.2915
Step: 11661, loss: 2.989341, norm: 0.3018, time(ms): 796.29, token/sec:658414.64, hellaswag_acc: 0.2915
Step: 11662, loss: 3.137691, norm: 0.3222, time(ms): 791.17, token/sec:662676.56, hellaswag_acc: 0.2915
Step: 11663, loss: 3.196371, norm: 0.3265, time(ms): 791.73, token/sec:662207.61, hellaswag_acc: 0.2915
Step: 11664, loss: 3.161594, norm: 0.3059, time(ms): 798.16, token/sec:656873.68, hellaswag_acc: 0.2915
Step: 11665, loss: 3.202250, norm: 0.3617, time(ms): 794.22, token/sec:660131.24, hellaswag_acc: 0.2915
Step: 11666, loss: 3.205284, norm: 0.3715, time(ms): 798.66, token/sec:656457.58, hellaswag_acc: 0.2915
Step: 11667, loss: 3.164831, norm: 0.3173, time(ms): 805.72, token/sec:650709.68, hellaswag_acc: 0.2915
Step: 11668, loss: 3.152908, norm: 0.3556, time(ms): 795.35, token/sec:659194.26, hellaswag_acc: 0.2915
Step: 11669, loss: 3.128944, norm: 0.2768, time(ms): 793.23, token/sec:660955.46, hellaswag_acc: 0.2915
Step: 11670, loss: 3.119461, norm: 0.3290, time(ms): 790.25, token/sec:663444.09, hellaswag_acc: 0.2915
Step: 11671, loss: 3.138693, norm: 0.3008, time(ms): 792.03, token/sec:661951.26, hellaswag_acc: 0.2915
Step: 11672, loss: 3.182487, norm: 0.3025, time(ms): 792.60, token/sec:661481.93, hellaswag_acc: 0.2915
Step: 11673, loss: 3.146445, norm: 0.3077, time(ms): 784.66, token/sec:668168.46, hellaswag_acc: 0.2915
Step: 11674, loss: 3.128412, norm: 0.2946, time(ms): 791.07, token/sec:662760.65, hellaswag_acc: 0.2915
Step: 11675, loss: 3.168303, norm: 0.2976, time(ms): 790.74, token/sec:663036.81, hellaswag_acc: 0.2915
Step: 11676, loss: 3.140476, norm: 0.2891, time(ms): 792.13, token/sec:661871.16, hellaswag_acc: 0.2915
Step: 11677, loss: 3.216691, norm: 0.2739, time(ms): 787.14, token/sec:666070.75, hellaswag_acc: 0.2915
Step: 11678, loss: 3.098487, norm: 0.3006, time(ms): 789.42, token/sec:664144.19, hellaswag_acc: 0.2915
Step: 11679, loss: 3.130298, norm: 0.2756, time(ms): 796.67, token/sec:658099.96, hellaswag_acc: 0.2915
Step: 11680, loss: 3.153956, norm: 0.2757, time(ms): 799.17, token/sec:656037.50, hellaswag_acc: 0.2915
Step: 11681, loss: 3.134861, norm: 0.2910, time(ms): 800.95, token/sec:654585.56, hellaswag_acc: 0.2915
Step: 11682, loss: 3.169162, norm: 0.2673, time(ms): 799.63, token/sec:655666.43, hellaswag_acc: 0.2915
Step: 11683, loss: 3.182454, norm: 0.2660, time(ms): 796.71, token/sec:658068.85, hellaswag_acc: 0.2915
Step: 11684, loss: 3.250967, norm: 0.2853, time(ms): 800.94, token/sec:654590.05, hellaswag_acc: 0.2915
Step: 11685, loss: 3.102505, norm: 0.2729, time(ms): 803.37, token/sec:652613.98, hellaswag_acc: 0.2915
Step: 11686, loss: 3.093923, norm: 0.2785, time(ms): 794.81, token/sec:659636.00, hellaswag_acc: 0.2915
Step: 11687, loss: 3.154618, norm: 0.2622, time(ms): 796.02, token/sec:658636.49, hellaswag_acc: 0.2915
Step: 11688, loss: 3.219776, norm: 0.3042, time(ms): 789.47, token/sec:664099.06, hellaswag_acc: 0.2915
Step: 11689, loss: 3.150256, norm: 0.2707, time(ms): 790.51, token/sec:663227.99, hellaswag_acc: 0.2915
Step: 11690, loss: 3.188313, norm: 0.2930, time(ms): 791.89, token/sec:662069.04, hellaswag_acc: 0.2915
Step: 11691, loss: 3.099995, norm: 0.2600, time(ms): 789.30, token/sec:664240.48, hellaswag_acc: 0.2915
Step: 11692, loss: 3.196514, norm: 0.3239, time(ms): 799.32, token/sec:655915.98, hellaswag_acc: 0.2915
Step: 11693, loss: 3.065138, norm: 0.2916, time(ms): 809.93, token/sec:647326.34, hellaswag_acc: 0.2915
Step: 11694, loss: 3.111563, norm: 0.3235, time(ms): 801.08, token/sec:654476.86, hellaswag_acc: 0.2915
Step: 11695, loss: 3.137302, norm: 0.2976, time(ms): 782.06, token/sec:670395.29, hellaswag_acc: 0.2915
Step: 11696, loss: 3.105592, norm: 0.3165, time(ms): 788.54, token/sec:664885.77, hellaswag_acc: 0.2915
Step: 11697, loss: 2.979693, norm: 0.2842, time(ms): 796.83, token/sec:657970.79, hellaswag_acc: 0.2915
Step: 11698, loss: 3.008543, norm: 0.3474, time(ms): 790.53, token/sec:663208.59, hellaswag_acc: 0.2915
Step: 11699, loss: 2.959227, norm: 0.3011, time(ms): 790.84, token/sec:662947.46, hellaswag_acc: 0.2915
Step: 11700, loss: 3.014175, norm: 0.3429, time(ms): 798.00, token/sec:657001.25, hellaswag_acc: 0.2915
Step: 11701, loss: 3.001520, norm: 0.2690, time(ms): 790.88, token/sec:662916.29, hellaswag_acc: 0.2915
Step: 11702, loss: 2.921135, norm: 0.3080, time(ms): 792.85, token/sec:661268.89, hellaswag_acc: 0.2915
Step: 11703, loss: 2.962578, norm: 0.2742, time(ms): 794.05, token/sec:660268.80, hellaswag_acc: 0.2915
Step: 11704, loss: 2.933151, norm: 0.3133, time(ms): 789.58, token/sec:664012.63, hellaswag_acc: 0.2915
Step: 11705, loss: 2.970499, norm: 0.2946, time(ms): 788.76, token/sec:664701.28, hellaswag_acc: 0.2915
Step: 11706, loss: 2.956450, norm: 0.2607, time(ms): 792.56, token/sec:661510.39, hellaswag_acc: 0.2915
Step: 11707, loss: 2.922911, norm: 0.2840, time(ms): 799.14, token/sec:656066.46, hellaswag_acc: 0.2915
Step: 11708, loss: 2.935038, norm: 0.2704, time(ms): 801.52, token/sec:654114.17, hellaswag_acc: 0.2915
Step: 11709, loss: 3.159305, norm: 0.3499, time(ms): 792.17, token/sec:661839.69, hellaswag_acc: 0.2915
Step: 11710, loss: 3.137264, norm: 0.2998, time(ms): 805.58, token/sec:650818.10, hellaswag_acc: 0.2915
Step: 11711, loss: 3.116316, norm: 0.3179, time(ms): 802.21, token/sec:653550.79, hellaswag_acc: 0.2915
Step: 11712, loss: 3.207575, norm: 0.3078, time(ms): 797.06, token/sec:657773.98, hellaswag_acc: 0.2915
Step: 11713, loss: 3.200440, norm: 0.2972, time(ms): 798.40, token/sec:656673.21, hellaswag_acc: 0.2915
Step: 11714, loss: 3.122890, norm: 0.3055, time(ms): 803.12, token/sec:652810.81, hellaswag_acc: 0.2915
Step: 11715, loss: 3.160787, norm: 0.2899, time(ms): 800.60, token/sec:654866.08, hellaswag_acc: 0.2915
Step: 11716, loss: 3.152837, norm: 0.3074, time(ms): 793.93, token/sec:660368.93, hellaswag_acc: 0.2915
Step: 11717, loss: 3.178042, norm: 0.2809, time(ms): 804.15, token/sec:651975.85, hellaswag_acc: 0.2915
Step: 11718, loss: 3.142625, norm: 0.3051, time(ms): 799.75, token/sec:655568.70, hellaswag_acc: 0.2915
Step: 11719, loss: 3.150439, norm: 0.2843, time(ms): 800.38, token/sec:655046.52, hellaswag_acc: 0.2915
Step: 11720, loss: 3.166356, norm: 0.3118, time(ms): 800.04, token/sec:655329.77, hellaswag_acc: 0.2915
Step: 11721, loss: 3.181602, norm: 0.2802, time(ms): 799.59, token/sec:655697.13, hellaswag_acc: 0.2915
Step: 11722, loss: 3.164239, norm: 0.2995, time(ms): 799.32, token/sec:655916.17, hellaswag_acc: 0.2915
Step: 11723, loss: 3.206920, norm: 0.2898, time(ms): 799.55, token/sec:655732.52, hellaswag_acc: 0.2915
Step: 11724, loss: 3.253515, norm: 0.3096, time(ms): 799.84, token/sec:655491.90, hellaswag_acc: 0.2915
Step: 11725, loss: 3.208368, norm: 0.3535, time(ms): 800.51, token/sec:654944.09, hellaswag_acc: 0.2915
Step: 11726, loss: 3.198647, norm: 0.3001, time(ms): 798.51, token/sec:656584.39, hellaswag_acc: 0.2915
Step: 11727, loss: 3.215588, norm: 0.2881, time(ms): 801.48, token/sec:654153.28, hellaswag_acc: 0.2915
Step: 11728, loss: 3.089783, norm: 0.3000, time(ms): 798.73, token/sec:656403.49, hellaswag_acc: 0.2915
Step: 11729, loss: 3.156196, norm: 0.2830, time(ms): 800.33, token/sec:655086.13, hellaswag_acc: 0.2915
Step: 11730, loss: 3.174496, norm: 0.2767, time(ms): 800.42, token/sec:655014.52, hellaswag_acc: 0.2915
Step: 11731, loss: 3.191516, norm: 0.2858, time(ms): 799.24, token/sec:655985.44, hellaswag_acc: 0.2915
Step: 11732, loss: 3.162997, norm: 0.2898, time(ms): 800.94, token/sec:654590.63, hellaswag_acc: 0.2915
Step: 11733, loss: 3.174503, norm: 0.2722, time(ms): 797.68, token/sec:657267.14, hellaswag_acc: 0.2915
Step: 11734, loss: 3.135689, norm: 0.2884, time(ms): 801.07, token/sec:654482.70, hellaswag_acc: 0.2915
Step: 11735, loss: 3.138127, norm: 0.2816, time(ms): 797.28, token/sec:657596.75, hellaswag_acc: 0.2915
Step: 11736, loss: 3.147741, norm: 0.2810, time(ms): 802.05, token/sec:653681.15, hellaswag_acc: 0.2915
Step: 11737, loss: 3.111836, norm: 0.2683, time(ms): 794.02, token/sec:660299.73, hellaswag_acc: 0.2915
Step: 11738, loss: 3.120669, norm: 0.3062, time(ms): 804.99, token/sec:651296.52, hellaswag_acc: 0.2915
Step: 11739, loss: 3.117718, norm: 0.2743, time(ms): 801.96, token/sec:653757.52, hellaswag_acc: 0.2915
Step: 11740, loss: 3.103533, norm: 0.2987, time(ms): 788.78, token/sec:664678.57, hellaswag_acc: 0.2915
Step: 11741, loss: 3.066854, norm: 0.2797, time(ms): 790.32, token/sec:663387.85, hellaswag_acc: 0.2915
Step: 11742, loss: 3.136448, norm: 0.2880, time(ms): 789.69, token/sec:663915.00, hellaswag_acc: 0.2915
Step: 11743, loss: 3.069493, norm: 0.2892, time(ms): 791.25, token/sec:662609.87, hellaswag_acc: 0.2915
Step: 11744, loss: 3.023828, norm: 0.3223, time(ms): 796.63, token/sec:658130.49, hellaswag_acc: 0.2915
Step: 11745, loss: 2.938496, norm: 0.3105, time(ms): 795.99, token/sec:658658.39, hellaswag_acc: 0.2915
Step: 11746, loss: 2.990281, norm: 0.3075, time(ms): 803.01, token/sec:652902.30, hellaswag_acc: 0.2915
Step: 11747, loss: 2.991384, norm: 0.3082, time(ms): 803.59, token/sec:652430.42, hellaswag_acc: 0.2915
Step: 11748, loss: 2.916218, norm: 0.2905, time(ms): 789.54, token/sec:664044.72, hellaswag_acc: 0.2915
Step: 11749, loss: 2.941966, norm: 0.2836, time(ms): 792.76, token/sec:661347.85, hellaswag_acc: 0.2915
rank 0 sample 0: Hello, I'm a language model, so I want to make all that a real contribution to the language so that you can be involved, but also to improve
rank 0 sample 1: Hello, I'm a language model, and all the parts that I want to do with you now, but with that I have to make all my tools available
rank 0 sample 2: Hello, I'm a language model, and I work as a Java developer myself. It's a really interesting concept, and it's a really good idea to
rank 0 sample 3: Hello, I'm a language model, I love to talk about things like I want to know how to type an expression if someone knows what language to learn because
rank 1 sample 0: Hello, I'm a language model, as well. I understand the syntax nicely and you should feel competent.
There are some questions and answers, but I
rank 1 sample 1: Hello, I'm a language model, not an engineer. I'm a designer. I'm very interested in the idea that one of the things that I want
rank 1 sample 2: Hello, I'm a language model, I wrote my Python code in Python and I'm happy I made the mistake of not having the ability to understand all of
rank 1 sample 3: Hello, I'm a language model, so I'm gonna be building an XML converter.”
After getting there, some comments on the machine were:
Step: 11750, loss: 3.018298, norm: 0.2944, time(ms): 3804.61, token/sec:137803.35, val_loss: 3.1590, hellaswag_acc: 0.2915
Step: 11751, loss: 2.972629, norm: 0.2795, time(ms): 794.74, token/sec:659694.18, hellaswag_acc: 0.2915
Step: 11752, loss: 3.043135, norm: 0.2896, time(ms): 786.37, token/sec:666720.21, hellaswag_acc: 0.2915
Step: 11753, loss: 3.002061, norm: 0.2783, time(ms): 790.98, token/sec:662832.96, hellaswag_acc: 0.2915
Step: 11754, loss: 2.959229, norm: 0.2930, time(ms): 798.53, token/sec:656566.75, hellaswag_acc: 0.2915
Step: 11755, loss: 3.062941, norm: 0.4083, time(ms): 783.55, token/sec:669117.51, hellaswag_acc: 0.2915
Step: 11756, loss: 3.170521, norm: 0.3390, time(ms): 784.08, token/sec:668664.41, hellaswag_acc: 0.2915
Step: 11757, loss: 3.144053, norm: 0.3071, time(ms): 790.40, token/sec:663318.81, hellaswag_acc: 0.2915
Step: 11758, loss: 3.207812, norm: 0.3220, time(ms): 791.22, token/sec:662634.63, hellaswag_acc: 0.2915
Step: 11759, loss: 3.116362, norm: 0.3148, time(ms): 790.81, token/sec:662973.45, hellaswag_acc: 0.2915
Step: 11760, loss: 3.184296, norm: 0.3168, time(ms): 790.41, token/sec:663312.81, hellaswag_acc: 0.2915
Step: 11761, loss: 3.163093, norm: 0.3126, time(ms): 802.28, token/sec:653496.80, hellaswag_acc: 0.2915
Step: 11762, loss: 3.184207, norm: 0.3049, time(ms): 805.99, token/sec:650492.17, hellaswag_acc: 0.2915
Step: 11763, loss: 3.226089, norm: 0.3519, time(ms): 791.95, token/sec:662021.00, hellaswag_acc: 0.2915
Step: 11764, loss: 3.139153, norm: 0.2881, time(ms): 797.39, token/sec:657505.91, hellaswag_acc: 0.2915
Step: 11765, loss: 3.162609, norm: 0.3035, time(ms): 792.86, token/sec:661265.12, hellaswag_acc: 0.2915
Step: 11766, loss: 3.122776, norm: 0.3501, time(ms): 789.35, token/sec:664205.17, hellaswag_acc: 0.2915
Step: 11767, loss: 3.144506, norm: 0.3356, time(ms): 793.40, token/sec:660810.07, hellaswag_acc: 0.2915
Step: 11768, loss: 3.158360, norm: 0.2989, time(ms): 788.53, token/sec:664892.41, hellaswag_acc: 0.2915
Step: 11769, loss: 3.164773, norm: 0.3624, time(ms): 791.22, token/sec:662629.64, hellaswag_acc: 0.2915
Step: 11770, loss: 3.167998, norm: 0.3056, time(ms): 792.36, token/sec:661677.58, hellaswag_acc: 0.2915
Step: 11771, loss: 3.137919, norm: 0.3146, time(ms): 788.62, token/sec:664818.03, hellaswag_acc: 0.2915
Step: 11772, loss: 3.157911, norm: 0.2830, time(ms): 790.96, token/sec:662853.94, hellaswag_acc: 0.2915
Step: 11773, loss: 3.190139, norm: 0.4052, time(ms): 794.51, token/sec:659887.39, hellaswag_acc: 0.2915
Step: 11774, loss: 3.256267, norm: 0.3705, time(ms): 791.00, token/sec:662813.78, hellaswag_acc: 0.2915
Step: 11775, loss: 3.148144, norm: 0.3158, time(ms): 793.90, token/sec:660391.94, hellaswag_acc: 0.2915
Step: 11776, loss: 3.230361, norm: 0.3331, time(ms): 796.23, token/sec:658459.00, hellaswag_acc: 0.2915
Step: 11777, loss: 3.131678, norm: 0.2999, time(ms): 804.38, token/sec:651793.23, hellaswag_acc: 0.2915
Step: 11778, loss: 3.156166, norm: 0.2855, time(ms): 799.78, token/sec:655539.78, hellaswag_acc: 0.2915
Step: 11779, loss: 3.139113, norm: 0.2884, time(ms): 793.06, token/sec:661096.34, hellaswag_acc: 0.2915
Step: 11780, loss: 3.110433, norm: 0.2820, time(ms): 801.85, token/sec:653851.60, hellaswag_acc: 0.2915
Step: 11781, loss: 3.122409, norm: 0.2840, time(ms): 799.76, token/sec:655556.58, hellaswag_acc: 0.2915
Step: 11782, loss: 3.088488, norm: 0.2777, time(ms): 796.40, token/sec:658320.03, hellaswag_acc: 0.2915
Step: 11783, loss: 3.099466, norm: 0.2672, time(ms): 792.62, token/sec:661458.05, hellaswag_acc: 0.2915
Step: 11784, loss: 3.145736, norm: 0.2790, time(ms): 795.89, token/sec:658747.38, hellaswag_acc: 0.2915
Step: 11785, loss: 3.137036, norm: 0.2608, time(ms): 793.34, token/sec:660859.52, hellaswag_acc: 0.2915
Step: 11786, loss: 3.114032, norm: 0.2679, time(ms): 800.76, token/sec:654740.51, hellaswag_acc: 0.2915
Step: 11787, loss: 3.150360, norm: 0.3070, time(ms): 804.40, token/sec:651773.33, hellaswag_acc: 0.2915
Step: 11788, loss: 3.066078, norm: 0.3126, time(ms): 791.29, token/sec:662570.74, hellaswag_acc: 0.2915
Step: 11789, loss: 3.092994, norm: 0.2780, time(ms): 789.96, token/sec:663690.38, hellaswag_acc: 0.2915
Step: 11790, loss: 3.134712, norm: 0.2684, time(ms): 789.90, token/sec:663737.26, hellaswag_acc: 0.2915
Step: 11791, loss: 2.946692, norm: 0.3248, time(ms): 795.24, token/sec:659285.56, hellaswag_acc: 0.2915
Step: 11792, loss: 2.982953, norm: 0.2671, time(ms): 792.43, token/sec:661619.85, hellaswag_acc: 0.2915
Step: 11793, loss: 2.988794, norm: 0.3189, time(ms): 796.41, token/sec:658310.37, hellaswag_acc: 0.2915
Step: 11794, loss: 3.001942, norm: 0.3154, time(ms): 801.58, token/sec:654065.92, hellaswag_acc: 0.2915
Step: 11795, loss: 3.003196, norm: 0.2792, time(ms): 803.09, token/sec:652839.88, hellaswag_acc: 0.2915
Step: 11796, loss: 2.981960, norm: 0.2775, time(ms): 800.22, token/sec:655176.11, hellaswag_acc: 0.2915
Step: 11797, loss: 2.963096, norm: 0.2997, time(ms): 799.28, token/sec:655953.74, hellaswag_acc: 0.2915
Step: 11798, loss: 2.952562, norm: 0.2949, time(ms): 799.74, token/sec:655573.59, hellaswag_acc: 0.2915
Step: 11799, loss: 2.974803, norm: 0.2734, time(ms): 800.43, token/sec:655011.20, hellaswag_acc: 0.2915
Step: 11800, loss: 3.002522, norm: 0.2966, time(ms): 798.36, token/sec:656706.55, hellaswag_acc: 0.2915
Step: 11801, loss: 2.953376, norm: 0.2729, time(ms): 799.42, token/sec:655836.95, hellaswag_acc: 0.2915
Step: 11802, loss: 3.095748, norm: 0.2937, time(ms): 801.42, token/sec:654202.13, hellaswag_acc: 0.2915
Step: 11803, loss: 3.148852, norm: 0.2966, time(ms): 800.97, token/sec:654570.37, hellaswag_acc: 0.2915
Step: 11804, loss: 3.173271, norm: 0.2972, time(ms): 789.63, token/sec:663965.32, hellaswag_acc: 0.2915
Step: 11805, loss: 3.175749, norm: 0.3162, time(ms): 800.26, token/sec:655148.58, hellaswag_acc: 0.2915
Step: 11806, loss: 3.090120, norm: 0.2809, time(ms): 802.11, token/sec:653639.18, hellaswag_acc: 0.2915
Step: 11807, loss: 3.144137, norm: 0.3559, time(ms): 795.76, token/sec:658850.21, hellaswag_acc: 0.2915
Step: 11808, loss: 3.160751, norm: 0.2967, time(ms): 789.17, token/sec:664349.85, hellaswag_acc: 0.2915
Step: 11809, loss: 3.234461, norm: 0.3102, time(ms): 791.78, token/sec:662162.34, hellaswag_acc: 0.2915
Step: 11810, loss: 3.179774, norm: 0.2900, time(ms): 1295.67, token/sec:404644.75, hellaswag_acc: 0.2915
Step: 11811, loss: 3.105072, norm: 0.2895, time(ms): 766.19, token/sec:684277.18, hellaswag_acc: 0.2915
Step: 11812, loss: 3.113023, norm: 0.2658, time(ms): 790.09, token/sec:663577.02, hellaswag_acc: 0.2915
Step: 11813, loss: 3.159741, norm: 0.2756, time(ms): 794.18, token/sec:660164.93, hellaswag_acc: 0.2915
Step: 11814, loss: 3.153870, norm: 0.2732, time(ms): 788.54, token/sec:664888.39, hellaswag_acc: 0.2915
Step: 11815, loss: 3.049866, norm: 0.2807, time(ms): 780.20, token/sec:671988.71, hellaswag_acc: 0.2915
Step: 11816, loss: 2.980732, norm: 0.2868, time(ms): 784.10, token/sec:668652.41, hellaswag_acc: 0.2915
Step: 11817, loss: 3.004869, norm: 0.2857, time(ms): 800.88, token/sec:654643.83, hellaswag_acc: 0.2915
Step: 11818, loss: 2.997455, norm: 0.2818, time(ms): 791.41, token/sec:662475.93, hellaswag_acc: 0.2915
Step: 11819, loss: 2.929981, norm: 0.2648, time(ms): 784.23, token/sec:668539.59, hellaswag_acc: 0.2915
Step: 11820, loss: 2.967853, norm: 0.2945, time(ms): 784.32, token/sec:668458.10, hellaswag_acc: 0.2915
Step: 11821, loss: 2.974610, norm: 0.2607, time(ms): 802.47, token/sec:653341.66, hellaswag_acc: 0.2915
Step: 11822, loss: 2.932700, norm: 0.2724, time(ms): 803.00, token/sec:652914.70, hellaswag_acc: 0.2915
Step: 11823, loss: 2.992212, norm: 0.2635, time(ms): 793.57, token/sec:660666.73, hellaswag_acc: 0.2915
Step: 11824, loss: 2.988353, norm: 0.2797, time(ms): 790.38, token/sec:663335.02, hellaswag_acc: 0.2915
Step: 11825, loss: 2.919365, norm: 0.2884, time(ms): 786.84, token/sec:666324.65, hellaswag_acc: 0.2915
Step: 11826, loss: 2.960783, norm: 0.2721, time(ms): 791.09, token/sec:662743.27, hellaswag_acc: 0.2915
Step: 11827, loss: 3.082558, norm: 0.2620, time(ms): 799.63, token/sec:655663.70, hellaswag_acc: 0.2915
Step: 11828, loss: 3.228736, norm: 0.3185, time(ms): 795.35, token/sec:659190.30, hellaswag_acc: 0.2915
Step: 11829, loss: 3.160069, norm: 0.2974, time(ms): 803.89, token/sec:652185.84, hellaswag_acc: 0.2915
Step: 11830, loss: 3.170534, norm: 0.3082, time(ms): 798.53, token/sec:656567.53, hellaswag_acc: 0.2915
Step: 11831, loss: 3.235344, norm: 0.3098, time(ms): 798.12, token/sec:656899.98, hellaswag_acc: 0.2915
Step: 11832, loss: 3.167579, norm: 0.2935, time(ms): 798.26, token/sec:656789.71, hellaswag_acc: 0.2915
Step: 11833, loss: 3.148754, norm: 0.2922, time(ms): 805.15, token/sec:651165.19, hellaswag_acc: 0.2915
Step: 11834, loss: 3.183060, norm: 0.2917, time(ms): 800.10, token/sec:655279.38, hellaswag_acc: 0.2915
Step: 11835, loss: 3.170843, norm: 0.2909, time(ms): 793.05, token/sec:661107.07, hellaswag_acc: 0.2915
Step: 11836, loss: 3.205295, norm: 0.2878, time(ms): 800.61, token/sec:654856.91, hellaswag_acc: 0.2915
Step: 11837, loss: 3.154368, norm: 0.3057, time(ms): 806.22, token/sec:650303.65, hellaswag_acc: 0.2915
Step: 11838, loss: 3.138480, norm: 0.2824, time(ms): 795.90, token/sec:658737.32, hellaswag_acc: 0.2915
Step: 11839, loss: 3.182543, norm: 0.2997, time(ms): 795.15, token/sec:659357.71, hellaswag_acc: 0.2915
Step: 11840, loss: 3.146284, norm: 0.3151, time(ms): 802.49, token/sec:653327.11, hellaswag_acc: 0.2915
Step: 11841, loss: 3.182764, norm: 0.2729, time(ms): 800.02, token/sec:655339.92, hellaswag_acc: 0.2915
Step: 11842, loss: 3.077210, norm: 0.3030, time(ms): 801.04, token/sec:654512.11, hellaswag_acc: 0.2915
Step: 11843, loss: 3.165593, norm: 0.2790, time(ms): 799.49, token/sec:655774.56, hellaswag_acc: 0.2915
Step: 11844, loss: 3.119696, norm: 0.2886, time(ms): 804.47, token/sec:651714.80, hellaswag_acc: 0.2915
Step: 11845, loss: 3.141567, norm: 0.2812, time(ms): 795.32, token/sec:659215.00, hellaswag_acc: 0.2915
Step: 11846, loss: 3.140779, norm: 0.2823, time(ms): 802.78, token/sec:653091.55, hellaswag_acc: 0.2915
Step: 11847, loss: 3.136121, norm: 0.2781, time(ms): 801.01, token/sec:654534.32, hellaswag_acc: 0.2915
Step: 11848, loss: 3.158452, norm: 0.3276, time(ms): 799.33, token/sec:655909.33, hellaswag_acc: 0.2915
Step: 11849, loss: 3.141704, norm: 0.2991, time(ms): 791.93, token/sec:662037.75, hellaswag_acc: 0.2915
Step: 11850, loss: 3.165143, norm: 0.2877, time(ms): 807.20, token/sec:649513.06, hellaswag_acc: 0.2915
Step: 11851, loss: 3.115252, norm: 0.2879, time(ms): 801.23, token/sec:654350.07, hellaswag_acc: 0.2915
Step: 11852, loss: 3.099062, norm: 0.2690, time(ms): 792.61, token/sec:661471.98, hellaswag_acc: 0.2915
Step: 11853, loss: 3.103875, norm: 0.2750, time(ms): 803.72, token/sec:652325.52, hellaswag_acc: 0.2915
Step: 11854, loss: 3.145544, norm: 0.2859, time(ms): 800.56, token/sec:654898.45, hellaswag_acc: 0.2915
Step: 11855, loss: 3.117897, norm: 0.2579, time(ms): 803.01, token/sec:652902.30, hellaswag_acc: 0.2915
Step: 11856, loss: 3.108526, norm: 0.2843, time(ms): 794.66, token/sec:659767.21, hellaswag_acc: 0.2915
Step: 11857, loss: 3.059525, norm: 0.2713, time(ms): 797.04, token/sec:657789.91, hellaswag_acc: 0.2915
Step: 11858, loss: 3.144371, norm: 0.2981, time(ms): 804.74, token/sec:651498.36, hellaswag_acc: 0.2915
Step: 11859, loss: 3.106659, norm: 0.2851, time(ms): 803.02, token/sec:652897.06, hellaswag_acc: 0.2915
Step: 11860, loss: 3.045783, norm: 0.2870, time(ms): 786.71, token/sec:666432.68, hellaswag_acc: 0.2915
Step: 11861, loss: 3.079742, norm: 0.2712, time(ms): 789.95, token/sec:663700.20, hellaswag_acc: 0.2915
Step: 11862, loss: 3.112824, norm: 0.2866, time(ms): 791.76, token/sec:662181.28, hellaswag_acc: 0.2915
Step: 11863, loss: 2.973327, norm: 0.2914, time(ms): 791.06, token/sec:662762.64, hellaswag_acc: 0.2915
Step: 11864, loss: 2.956032, norm: 0.2896, time(ms): 790.97, token/sec:662841.75, hellaswag_acc: 0.2915
Step: 11865, loss: 2.940620, norm: 0.2982, time(ms): 798.19, token/sec:656848.57, hellaswag_acc: 0.2915
Step: 11866, loss: 2.935574, norm: 0.2907, time(ms): 795.82, token/sec:658803.03, hellaswag_acc: 0.2915
Step: 11867, loss: 2.929279, norm: 0.2780, time(ms): 794.58, token/sec:659833.93, hellaswag_acc: 0.2915
Step: 11868, loss: 3.008051, norm: 0.3078, time(ms): 794.48, token/sec:659910.36, hellaswag_acc: 0.2915
Step: 11869, loss: 3.003161, norm: 0.2572, time(ms): 800.52, token/sec:654936.87, hellaswag_acc: 0.2915
Step: 11870, loss: 2.951488, norm: 0.2951, time(ms): 796.10, token/sec:658569.63, hellaswag_acc: 0.2915
Step: 11871, loss: 3.023965, norm: 0.2971, time(ms): 790.73, token/sec:663045.01, hellaswag_acc: 0.2915
Step: 11872, loss: 3.015555, norm: 0.3011, time(ms): 782.38, token/sec:670119.70, hellaswag_acc: 0.2915
Step: 11873, loss: 3.007734, norm: 0.2731, time(ms): 789.37, token/sec:664189.12, hellaswag_acc: 0.2915
Step: 11874, loss: 3.006615, norm: 0.3046, time(ms): 803.30, token/sec:652669.18, hellaswag_acc: 0.2915
Step: 11875, loss: 3.157875, norm: 0.2905, time(ms): 798.85, token/sec:656305.54, hellaswag_acc: 0.2915
Step: 11876, loss: 3.186049, norm: 0.3004, time(ms): 790.93, token/sec:662875.72, hellaswag_acc: 0.2915
Step: 11877, loss: 3.112035, norm: 0.2864, time(ms): 790.74, token/sec:663031.02, hellaswag_acc: 0.2915
Step: 11878, loss: 3.173597, norm: 0.2789, time(ms): 789.49, token/sec:664086.03, hellaswag_acc: 0.2915
Step: 11879, loss: 3.154910, norm: 0.3136, time(ms): 792.93, token/sec:661202.29, hellaswag_acc: 0.2915
Step: 11880, loss: 3.144400, norm: 0.2907, time(ms): 790.51, token/sec:663230.39, hellaswag_acc: 0.2915
Step: 11881, loss: 3.140501, norm: 0.3061, time(ms): 798.51, token/sec:656584.20, hellaswag_acc: 0.2915
Step: 11882, loss: 3.216671, norm: 0.2923, time(ms): 806.05, token/sec:650442.91, hellaswag_acc: 0.2915
Step: 11883, loss: 3.210519, norm: 0.3015, time(ms): 801.17, token/sec:654402.85, hellaswag_acc: 0.2915
Step: 11884, loss: 3.149877, norm: 0.2993, time(ms): 790.93, token/sec:662873.92, hellaswag_acc: 0.2915
Step: 11885, loss: 3.184909, norm: 0.2951, time(ms): 804.08, token/sec:652038.48, hellaswag_acc: 0.2915
Step: 11886, loss: 3.113098, norm: 0.3041, time(ms): 801.22, token/sec:654364.87, hellaswag_acc: 0.2915
Step: 11887, loss: 3.133263, norm: 0.3017, time(ms): 800.81, token/sec:654693.14, hellaswag_acc: 0.2915
Step: 11888, loss: 3.051856, norm: 0.5325, time(ms): 800.82, token/sec:654690.80, hellaswag_acc: 0.2915
Step: 11889, loss: 3.102651, norm: 0.3090, time(ms): 797.38, token/sec:657512.20, hellaswag_acc: 0.2915
Step: 11890, loss: 3.134226, norm: 0.3174, time(ms): 797.93, token/sec:657057.20, hellaswag_acc: 0.2915
Step: 11891, loss: 3.154117, norm: 0.3066, time(ms): 802.91, token/sec:652982.37, hellaswag_acc: 0.2915
Step: 11892, loss: 3.098680, norm: 0.3243, time(ms): 799.31, token/sec:655926.74, hellaswag_acc: 0.2915
Step: 11893, loss: 3.166845, norm: 0.3048, time(ms): 794.10, token/sec:660231.93, hellaswag_acc: 0.2915
Step: 11894, loss: 3.173611, norm: 0.2933, time(ms): 804.92, token/sec:651351.50, hellaswag_acc: 0.2915
Step: 11895, loss: 3.194465, norm: 0.2893, time(ms): 802.61, token/sec:653228.32, hellaswag_acc: 0.2915
Step: 11896, loss: 3.168511, norm: 0.2983, time(ms): 801.23, token/sec:654356.50, hellaswag_acc: 0.2915
Step: 11897, loss: 3.194474, norm: 0.3102, time(ms): 794.03, token/sec:660287.04, hellaswag_acc: 0.2915
Step: 11898, loss: 3.102961, norm: 0.2797, time(ms): 801.90, token/sec:653804.17, hellaswag_acc: 0.2915
Step: 11899, loss: 3.091502, norm: 0.2797, time(ms): 802.98, token/sec:652931.76, hellaswag_acc: 0.2915
Step: 11900, loss: 3.100395, norm: 0.3103, time(ms): 795.56, token/sec:659019.82, hellaswag_acc: 0.2915
Step: 11901, loss: 3.074895, norm: 0.2734, time(ms): 803.38, token/sec:652602.74, hellaswag_acc: 0.2915
Step: 11902, loss: 3.109653, norm: 0.2721, time(ms): 799.44, token/sec:655822.08, hellaswag_acc: 0.2915
Step: 11903, loss: 3.082423, norm: 0.2960, time(ms): 792.03, token/sec:661954.84, hellaswag_acc: 0.2915
Step: 11904, loss: 3.120810, norm: 0.3003, time(ms): 793.18, token/sec:660994.20, hellaswag_acc: 0.2915
Step: 11905, loss: 3.102446, norm: 0.2779, time(ms): 795.81, token/sec:658812.11, hellaswag_acc: 0.2915
Step: 11906, loss: 3.083301, norm: 0.2852, time(ms): 791.55, token/sec:662359.00, hellaswag_acc: 0.2915
Step: 11907, loss: 3.164779, norm: 0.2963, time(ms): 796.39, token/sec:658332.64, hellaswag_acc: 0.2915
Step: 11908, loss: 3.082592, norm: 0.2970, time(ms): 789.51, token/sec:664069.98, hellaswag_acc: 0.2915
Step: 11909, loss: 3.078414, norm: 0.2909, time(ms): 789.17, token/sec:664355.07, hellaswag_acc: 0.2915
Step: 11910, loss: 2.980459, norm: 0.2920, time(ms): 791.49, token/sec:662403.49, hellaswag_acc: 0.2915
Step: 11911, loss: 3.026849, norm: 0.2980, time(ms): 796.03, token/sec:658625.65, hellaswag_acc: 0.2915
Step: 11912, loss: 2.976677, norm: 0.3072, time(ms): 802.28, token/sec:653497.38, hellaswag_acc: 0.2915
Step: 11913, loss: 2.979667, norm: 0.2854, time(ms): 802.42, token/sec:653383.01, hellaswag_acc: 0.2915
Step: 11914, loss: 3.027870, norm: 0.3622, time(ms): 796.19, token/sec:658499.22, hellaswag_acc: 0.2915
Step: 11915, loss: 3.008971, norm: 0.2845, time(ms): 797.25, token/sec:657619.95, hellaswag_acc: 0.2915
Step: 11916, loss: 3.044393, norm: 0.3083, time(ms): 804.81, token/sec:651443.55, hellaswag_acc: 0.2915
Step: 11917, loss: 2.998793, norm: 0.3105, time(ms): 801.31, token/sec:654285.63, hellaswag_acc: 0.2915
Step: 11918, loss: 3.031273, norm: 0.2947, time(ms): 794.73, token/sec:659701.90, hellaswag_acc: 0.2915
Step: 11919, loss: 2.923741, norm: 0.3179, time(ms): 801.72, token/sec:653955.83, hellaswag_acc: 0.2915
Step: 11920, loss: 2.922198, norm: 0.2917, time(ms): 803.09, token/sec:652838.14, hellaswag_acc: 0.2915
Step: 11921, loss: 3.000522, norm: 0.2862, time(ms): 793.77, token/sec:660506.59, hellaswag_acc: 0.2915
Step: 11922, loss: 3.216991, norm: 0.3024, time(ms): 797.29, token/sec:657583.97, hellaswag_acc: 0.2915
Step: 11923, loss: 3.180727, norm: 0.3288, time(ms): 808.14, token/sec:648759.04, hellaswag_acc: 0.2915
Step: 11924, loss: 3.170117, norm: 0.2677, time(ms): 795.78, token/sec:658833.63, hellaswag_acc: 0.2915
Step: 11925, loss: 3.208555, norm: 0.3162, time(ms): 801.47, token/sec:654156.20, hellaswag_acc: 0.2915
Step: 11926, loss: 3.239521, norm: 0.2795, time(ms): 802.63, token/sec:653211.83, hellaswag_acc: 0.2915
Step: 11927, loss: 3.234087, norm: 0.3195, time(ms): 799.38, token/sec:655867.27, hellaswag_acc: 0.2915
Step: 11928, loss: 3.221766, norm: 0.3271, time(ms): 789.43, token/sec:664133.36, hellaswag_acc: 0.2915
Step: 11929, loss: 3.159779, norm: 0.2900, time(ms): 793.48, token/sec:660746.73, hellaswag_acc: 0.2915
Step: 11930, loss: 3.154828, norm: 0.2867, time(ms): 794.34, token/sec:660031.38, hellaswag_acc: 0.2915
Step: 11931, loss: 3.137516, norm: 0.2875, time(ms): 790.39, token/sec:663324.82, hellaswag_acc: 0.2915
Step: 11932, loss: 3.155351, norm: 0.2908, time(ms): 791.38, token/sec:662496.48, hellaswag_acc: 0.2915
Step: 11933, loss: 3.152284, norm: 0.2968, time(ms): 794.80, token/sec:659645.89, hellaswag_acc: 0.2915
Step: 11934, loss: 3.115891, norm: 0.3017, time(ms): 801.57, token/sec:654079.15, hellaswag_acc: 0.2915
Step: 11935, loss: 3.125183, norm: 0.3051, time(ms): 798.56, token/sec:656538.52, hellaswag_acc: 0.2915
Step: 11936, loss: 3.086442, norm: 0.2980, time(ms): 803.38, token/sec:652601.19, hellaswag_acc: 0.2915
Step: 11937, loss: 3.130026, norm: 0.2806, time(ms): 796.62, token/sec:658144.67, hellaswag_acc: 0.2915
Step: 11938, loss: 3.134117, norm: 0.2709, time(ms): 798.08, token/sec:656940.60, hellaswag_acc: 0.2915
Step: 11939, loss: 3.169275, norm: 0.3002, time(ms): 802.34, token/sec:653448.64, hellaswag_acc: 0.2915
Step: 11940, loss: 3.108354, norm: 0.2690, time(ms): 801.33, token/sec:654268.70, hellaswag_acc: 0.2915
Step: 11941, loss: 3.144221, norm: 0.2826, time(ms): 794.75, token/sec:659687.65, hellaswag_acc: 0.2915
Step: 11942, loss: 3.161896, norm: 0.2696, time(ms): 804.29, token/sec:651861.43, hellaswag_acc: 0.2915
Step: 11943, loss: 3.175290, norm: 0.2693, time(ms): 801.79, token/sec:653894.57, hellaswag_acc: 0.2915
Step: 11944, loss: 3.112719, norm: 0.2722, time(ms): 790.55, token/sec:663191.18, hellaswag_acc: 0.2915
Step: 11945, loss: 3.119425, norm: 0.2696, time(ms): 789.49, token/sec:664082.22, hellaswag_acc: 0.2915
Step: 11946, loss: 3.074961, norm: 0.2504, time(ms): 798.06, token/sec:656954.93, hellaswag_acc: 0.2915
Step: 11947, loss: 3.086991, norm: 0.2704, time(ms): 799.67, token/sec:655630.27, hellaswag_acc: 0.2915
Step: 11948, loss: 3.106961, norm: 0.2760, time(ms): 799.30, token/sec:655929.87, hellaswag_acc: 0.2915
Step: 11949, loss: 3.112210, norm: 0.2706, time(ms): 800.05, token/sec:655317.07, hellaswag_acc: 0.2915
Step: 11950, loss: 3.095216, norm: 0.2660, time(ms): 796.04, token/sec:658616.37, hellaswag_acc: 0.2915
Step: 11951, loss: 3.113078, norm: 0.2530, time(ms): 796.10, token/sec:658570.02, hellaswag_acc: 0.2915
Step: 11952, loss: 3.146979, norm: 0.2799, time(ms): 789.92, token/sec:663723.23, hellaswag_acc: 0.2915
Step: 11953, loss: 3.095404, norm: 0.3002, time(ms): 788.45, token/sec:664964.18, hellaswag_acc: 0.2915
Step: 11954, loss: 3.083046, norm: 0.2725, time(ms): 789.42, token/sec:664142.79, hellaswag_acc: 0.2915
Step: 11955, loss: 3.103352, norm: 0.2976, time(ms): 802.10, token/sec:653645.59, hellaswag_acc: 0.2915
Step: 11956, loss: 2.987495, norm: 0.2600, time(ms): 796.83, token/sec:657964.69, hellaswag_acc: 0.2915
Step: 11957, loss: 2.935676, norm: 0.2824, time(ms): 801.32, token/sec:654279.99, hellaswag_acc: 0.2915
Step: 11958, loss: 3.036368, norm: 0.3065, time(ms): 801.13, token/sec:654432.06, hellaswag_acc: 0.2915
Step: 11959, loss: 2.978316, norm: 0.2882, time(ms): 799.30, token/sec:655934.76, hellaswag_acc: 0.2915
Step: 11960, loss: 2.960857, norm: 0.3035, time(ms): 798.39, token/sec:656685.37, hellaswag_acc: 0.2915
Step: 11961, loss: 2.981200, norm: 0.2570, time(ms): 793.78, token/sec:660494.29, hellaswag_acc: 0.2915
Step: 11962, loss: 2.975264, norm: 0.2679, time(ms): 806.34, token/sec:650206.55, hellaswag_acc: 0.2915
Step: 11963, loss: 3.019334, norm: 0.2607, time(ms): 799.95, token/sec:655403.01, hellaswag_acc: 0.2915
Step: 11964, loss: 2.989299, norm: 0.2867, time(ms): 796.85, token/sec:657947.17, hellaswag_acc: 0.2915
Step: 11965, loss: 2.937856, norm: 0.2792, time(ms): 798.50, token/sec:656590.86, hellaswag_acc: 0.2915
Step: 11966, loss: 2.957693, norm: 0.2748, time(ms): 805.81, token/sec:650636.90, hellaswag_acc: 0.2915
Step: 11967, loss: 3.132115, norm: 0.2725, time(ms): 798.41, token/sec:656667.13, hellaswag_acc: 0.2915
Step: 11968, loss: 3.180879, norm: 0.2697, time(ms): 793.50, token/sec:660726.48, hellaswag_acc: 0.2915
Step: 11969, loss: 3.180480, norm: 0.2999, time(ms): 802.13, token/sec:653617.42, hellaswag_acc: 0.2915
Step: 11970, loss: 3.158853, norm: 0.2720, time(ms): 805.67, token/sec:650749.35, hellaswag_acc: 0.2915
Step: 11971, loss: 3.147432, norm: 0.2962, time(ms): 796.06, token/sec:658603.75, hellaswag_acc: 0.2915
Step: 11972, loss: 3.120913, norm: 0.2789, time(ms): 794.77, token/sec:659671.62, hellaswag_acc: 0.2915
Step: 11973, loss: 3.129131, norm: 0.2985, time(ms): 805.53, token/sec:650859.13, hellaswag_acc: 0.2915
Step: 11974, loss: 3.163566, norm: 0.2773, time(ms): 803.53, token/sec:652477.27, hellaswag_acc: 0.2915
Step: 11975, loss: 3.138633, norm: 0.2985, time(ms): 790.61, token/sec:663146.59, hellaswag_acc: 0.2915
Step: 11976, loss: 3.100716, norm: 0.2832, time(ms): 803.73, token/sec:652320.30, hellaswag_acc: 0.2915
Step: 11977, loss: 3.183386, norm: 0.2768, time(ms): 803.97, token/sec:652126.46, hellaswag_acc: 0.2915
Step: 11978, loss: 3.167096, norm: 0.2692, time(ms): 794.99, token/sec:659494.16, hellaswag_acc: 0.2915
Step: 11979, loss: 3.102753, norm: 0.2756, time(ms): 799.76, token/sec:655559.32, hellaswag_acc: 0.2915
Step: 11980, loss: 3.165339, norm: 0.2821, time(ms): 803.29, token/sec:652676.54, hellaswag_acc: 0.2915
Step: 11981, loss: 3.160836, norm: 0.2736, time(ms): 795.65, token/sec:658944.78, hellaswag_acc: 0.2915
Step: 11982, loss: 3.136797, norm: 0.2744, time(ms): 801.78, token/sec:653905.27, hellaswag_acc: 0.2915
Step: 11983, loss: 3.201880, norm: 0.2863, time(ms): 802.71, token/sec:653144.31, hellaswag_acc: 0.2915
Step: 11984, loss: 3.121646, norm: 0.2700, time(ms): 799.95, token/sec:655403.99, hellaswag_acc: 0.2915
Step: 11985, loss: 3.138168, norm: 0.3089, time(ms): 800.28, token/sec:655134.34, hellaswag_acc: 0.2915
Step: 11986, loss: 3.127213, norm: 0.2959, time(ms): 794.73, token/sec:659703.08, hellaswag_acc: 0.2915
Step: 11987, loss: 3.147328, norm: 0.2990, time(ms): 804.39, token/sec:651779.32, hellaswag_acc: 0.2915
Step: 11988, loss: 3.115718, norm: 0.3052, time(ms): 799.97, token/sec:655381.91, hellaswag_acc: 0.2915
Step: 11989, loss: 3.131076, norm: 0.2842, time(ms): 795.89, token/sec:658747.38, hellaswag_acc: 0.2915
Step: 11990, loss: 3.126647, norm: 0.2854, time(ms): 802.07, token/sec:653665.60, hellaswag_acc: 0.2915
Step: 11991, loss: 3.150501, norm: 0.2960, time(ms): 802.18, token/sec:653578.76, hellaswag_acc: 0.2915
Step: 11992, loss: 3.100005, norm: 0.2861, time(ms): 791.24, token/sec:662615.66, hellaswag_acc: 0.2915
Step: 11993, loss: 3.136619, norm: 0.2598, time(ms): 800.48, token/sec:654969.65, hellaswag_acc: 0.2915
Step: 11994, loss: 3.119629, norm: 0.2901, time(ms): 800.66, token/sec:654818.10, hellaswag_acc: 0.2915
Step: 11995, loss: 3.117885, norm: 0.2635, time(ms): 808.26, token/sec:648664.31, hellaswag_acc: 0.2915
Step: 11996, loss: 3.112067, norm: 0.2892, time(ms): 792.48, token/sec:661578.05, hellaswag_acc: 0.2915
Step: 11997, loss: 3.098679, norm: 0.2703, time(ms): 803.71, token/sec:652334.62, hellaswag_acc: 0.2915
Step: 11998, loss: 3.165587, norm: 0.2907, time(ms): 799.98, token/sec:655374.49, hellaswag_acc: 0.2915
Step: 11999, loss: 3.122989, norm: 0.2726, time(ms): 802.81, token/sec:653062.46, hellaswag_acc: 0.2915
rank 0 sample 0: Hello, I'm a language model, and I'll be using an open source environment such as Sun's web pages (I've come here from the University of
rank 0 sample 1: Hello, I'm a language model, so,
I am a machine model, but...a language model is one of my keys. But...
A
rank 0 sample 2: Hello, I'm a language model, so I see it as another language model. However, I've never actually seen it, but I think it is probably
rank 0 sample 3: Hello, I'm a language model, so i'm using a language called X. Because I'm making x in the third part of my first language (Y
rank 1 sample 0: Hello, I'm a language model, because that's what makes it so clear to others about AI algorithms.
To be sure, we're still in the
rank 1 sample 1: Hello, I'm a language model, not an interpreter. I'm not really the only one at the moment. You were here at Bionic, and I
rank 1 sample 2: Hello, I'm a language model, but those words can be heard in other languages.
So far we're talking about the "classification of objects".
rank 1 sample 3: Hello, I'm a language model, and I'm using the data as a key to compute machine learning objects. Since I see "P" as a key
Step: 12000, loss: 3.086074, norm: 0.2813, time(ms): 363936.81, token/sec:1440.60, val_loss: 3.1482, hellaswag_acc: 0.2955
Step: 12001, loss: 3.138145, norm: 0.2599, time(ms): 1266.00, token/sec:414128.28, hellaswag_acc: 0.2955
Step: 12002, loss: 3.130181, norm: 0.2782, time(ms): 793.99, token/sec:660318.17, hellaswag_acc: 0.2955
Step: 12003, loss: 3.164087, norm: 0.2658, time(ms): 792.50, token/sec:661562.33, hellaswag_acc: 0.2955
Step: 12004, loss: 3.235027, norm: 0.3698, time(ms): 780.11, token/sec:672070.25, hellaswag_acc: 0.2955
Step: 12005, loss: 3.168588, norm: 0.3722, time(ms): 792.58, token/sec:661494.47, hellaswag_acc: 0.2955
Step: 12006, loss: 3.159245, norm: 0.3311, time(ms): 800.88, token/sec:654642.86, hellaswag_acc: 0.2955
Step: 12007, loss: 3.173324, norm: 0.3234, time(ms): 791.56, token/sec:662347.42, hellaswag_acc: 0.2955
Step: 12008, loss: 3.152915, norm: 0.2948, time(ms): 791.59, token/sec:662324.48, hellaswag_acc: 0.2955
Step: 12009, loss: 3.158473, norm: 0.3143, time(ms): 795.45, token/sec:659111.07, hellaswag_acc: 0.2955
Step: 12010, loss: 3.183506, norm: 0.3066, time(ms): 798.54, token/sec:656558.91, hellaswag_acc: 0.2955
Step: 12011, loss: 3.141173, norm: 0.2959, time(ms): 791.11, token/sec:662722.30, hellaswag_acc: 0.2955
Step: 12012, loss: 3.147826, norm: 0.2737, time(ms): 789.16, token/sec:664364.70, hellaswag_acc: 0.2955
Step: 12013, loss: 3.158915, norm: 0.3069, time(ms): 789.81, token/sec:663815.80, hellaswag_acc: 0.2955
Step: 12014, loss: 3.143139, norm: 0.2707, time(ms): 790.74, token/sec:663035.81, hellaswag_acc: 0.2955
Step: 12015, loss: 3.125037, norm: 0.2719, time(ms): 791.59, token/sec:662325.28, hellaswag_acc: 0.2955
Step: 12016, loss: 3.117268, norm: 0.2730, time(ms): 806.64, token/sec:649962.29, hellaswag_acc: 0.2955
Step: 12017, loss: 3.100668, norm: 0.2677, time(ms): 801.05, token/sec:654501.59, hellaswag_acc: 0.2955
Step: 12018, loss: 3.123899, norm: 0.2926, time(ms): 794.08, token/sec:660246.20, hellaswag_acc: 0.2955
Step: 12019, loss: 3.200178, norm: 0.2930, time(ms): 804.43, token/sec:651749.96, hellaswag_acc: 0.2955
Step: 12020, loss: 3.069795, norm: 0.2613, time(ms): 801.44, token/sec:654182.47, hellaswag_acc: 0.2955
Step: 12021, loss: 3.053277, norm: 0.2550, time(ms): 797.91, token/sec:657077.42, hellaswag_acc: 0.2955
Step: 12022, loss: 3.043319, norm: 0.2612, time(ms): 798.68, token/sec:656439.35, hellaswag_acc: 0.2955
Step: 12023, loss: 3.086073, norm: 0.2758, time(ms): 801.10, token/sec:654463.61, hellaswag_acc: 0.2955
Step: 12024, loss: 3.061625, norm: 0.2607, time(ms): 800.97, token/sec:654562.77, hellaswag_acc: 0.2955
Step: 12025, loss: 3.084653, norm: 0.2594, time(ms): 791.62, token/sec:662295.36, hellaswag_acc: 0.2955
Step: 12026, loss: 3.010387, norm: 0.2646, time(ms): 807.68, token/sec:649125.58, hellaswag_acc: 0.2955
Step: 12027, loss: 3.064040, norm: 0.2599, time(ms): 799.38, token/sec:655864.33, hellaswag_acc: 0.2955
Step: 12028, loss: 3.065479, norm: 0.2775, time(ms): 796.09, token/sec:658579.49, hellaswag_acc: 0.2955
Step: 12029, loss: 3.053088, norm: 0.2609, time(ms): 803.49, token/sec:652511.92, hellaswag_acc: 0.2955
Step: 12030, loss: 3.094232, norm: 0.2629, time(ms): 800.34, token/sec:655080.47, hellaswag_acc: 0.2955
Step: 12031, loss: 3.014171, norm: 0.2674, time(ms): 798.61, token/sec:656501.28, hellaswag_acc: 0.2955
Step: 12032, loss: 3.162100, norm: 0.2819, time(ms): 800.17, token/sec:655224.13, hellaswag_acc: 0.2955
Step: 12033, loss: 3.195598, norm: 0.2737, time(ms): 801.40, token/sec:654211.86, hellaswag_acc: 0.2955
Step: 12034, loss: 3.162197, norm: 0.3123, time(ms): 793.75, token/sec:660522.85, hellaswag_acc: 0.2955
Step: 12035, loss: 3.153829, norm: 0.2624, time(ms): 802.98, token/sec:652931.18, hellaswag_acc: 0.2955
Step: 12036, loss: 3.208929, norm: 0.3112, time(ms): 803.40, token/sec:652587.06, hellaswag_acc: 0.2955
Step: 12037, loss: 3.163861, norm: 0.3058, time(ms): 795.23, token/sec:659287.54, hellaswag_acc: 0.2955
Step: 12038, loss: 3.214714, norm: 0.2844, time(ms): 802.68, token/sec:653173.41, hellaswag_acc: 0.2955
Step: 12039, loss: 3.211253, norm: 0.3404, time(ms): 801.00, token/sec:654538.61, hellaswag_acc: 0.2955
Step: 12040, loss: 3.226045, norm: 0.3026, time(ms): 800.25, token/sec:655157.17, hellaswag_acc: 0.2955
Step: 12041, loss: 3.183793, norm: 0.3007, time(ms): 795.92, token/sec:658719.16, hellaswag_acc: 0.2955
Step: 12042, loss: 3.153329, norm: 0.3033, time(ms): 803.16, token/sec:652778.65, hellaswag_acc: 0.2955
Step: 12043, loss: 3.166193, norm: 0.2893, time(ms): 798.80, token/sec:656346.29, hellaswag_acc: 0.2955
Step: 12044, loss: 3.158446, norm: 0.2720, time(ms): 799.47, token/sec:655795.09, hellaswag_acc: 0.2955
Step: 12045, loss: 3.106332, norm: 0.2929, time(ms): 802.19, token/sec:653573.90, hellaswag_acc: 0.2955
Step: 12046, loss: 3.075457, norm: 0.2647, time(ms): 797.24, token/sec:657629.79, hellaswag_acc: 0.2955
Step: 12047, loss: 3.120118, norm: 0.2719, time(ms): 799.05, token/sec:656135.17, hellaswag_acc: 0.2955
Step: 12048, loss: 3.157040, norm: 0.2582, time(ms): 802.29, token/sec:653487.86, hellaswag_acc: 0.2955
Step: 12049, loss: 3.124957, norm: 0.2903, time(ms): 799.46, token/sec:655805.07, hellaswag_acc: 0.2955
Step: 12050, loss: 3.256938, norm: 0.3039, time(ms): 798.37, token/sec:656694.98, hellaswag_acc: 0.2955
Step: 12051, loss: 3.121994, norm: 0.3016, time(ms): 801.07, token/sec:654486.40, hellaswag_acc: 0.2955
Step: 12052, loss: 3.086993, norm: 0.2735, time(ms): 800.28, token/sec:655128.48, hellaswag_acc: 0.2955
Step: 12053, loss: 3.159844, norm: 0.2982, time(ms): 800.50, token/sec:654952.29, hellaswag_acc: 0.2955
Step: 12054, loss: 3.049747, norm: 0.3124, time(ms): 794.39, token/sec:659988.40, hellaswag_acc: 0.2955
Step: 12055, loss: 3.084789, norm: 0.2919, time(ms): 802.08, token/sec:653664.44, hellaswag_acc: 0.2955
Step: 12056, loss: 3.078328, norm: 0.2820, time(ms): 803.30, token/sec:652665.69, hellaswag_acc: 0.2955
Step: 12057, loss: 3.077624, norm: 0.3024, time(ms): 793.71, token/sec:660555.59, hellaswag_acc: 0.2955
Step: 12058, loss: 3.023800, norm: 0.2960, time(ms): 804.35, token/sec:651813.90, hellaswag_acc: 0.2955
Step: 12059, loss: 3.023311, norm: 0.2789, time(ms): 800.37, token/sec:655060.76, hellaswag_acc: 0.2955
Step: 12060, loss: 3.114580, norm: 0.2990, time(ms): 800.66, token/sec:654817.91, hellaswag_acc: 0.2955
Step: 12061, loss: 3.028241, norm: 0.2836, time(ms): 793.98, token/sec:660327.09, hellaswag_acc: 0.2955
Step: 12062, loss: 3.008288, norm: 0.2858, time(ms): 804.01, token/sec:652093.01, hellaswag_acc: 0.2955
Step: 12063, loss: 3.086225, norm: 0.2725, time(ms): 799.78, token/sec:655543.88, hellaswag_acc: 0.2955
Step: 12064, loss: 3.078546, norm: 0.3001, time(ms): 796.91, token/sec:657904.25, hellaswag_acc: 0.2955
Step: 12065, loss: 3.048808, norm: 0.2715, time(ms): 803.30, token/sec:652669.18, hellaswag_acc: 0.2955
Step: 12066, loss: 3.106593, norm: 0.3163, time(ms): 798.56, token/sec:656543.62, hellaswag_acc: 0.2955
Step: 12067, loss: 3.265747, norm: 0.3457, time(ms): 800.01, token/sec:655352.81, hellaswag_acc: 0.2955
Step: 12068, loss: 3.153730, norm: 0.4125, time(ms): 799.65, token/sec:655646.88, hellaswag_acc: 0.2955
Step: 12069, loss: 3.257037, norm: 0.3642, time(ms): 799.05, token/sec:656137.13, hellaswag_acc: 0.2955
Step: 12070, loss: 3.148463, norm: 0.3035, time(ms): 801.86, token/sec:653843.44, hellaswag_acc: 0.2955
Step: 12071, loss: 3.116572, norm: 0.3205, time(ms): 799.84, token/sec:655490.92, hellaswag_acc: 0.2955
Step: 12072, loss: 3.148432, norm: 0.3020, time(ms): 800.72, token/sec:654770.14, hellaswag_acc: 0.2955
Step: 12073, loss: 3.178197, norm: 0.3017, time(ms): 793.34, token/sec:660859.91, hellaswag_acc: 0.2955
Step: 12074, loss: 3.186042, norm: 0.3094, time(ms): 804.52, token/sec:651678.11, hellaswag_acc: 0.2955
Step: 12075, loss: 3.140926, norm: 0.2880, time(ms): 801.57, token/sec:654077.59, hellaswag_acc: 0.2955
Step: 12076, loss: 3.179059, norm: 0.2926, time(ms): 800.54, token/sec:654919.32, hellaswag_acc: 0.2955
Step: 12077, loss: 3.145338, norm: 0.2889, time(ms): 798.05, token/sec:656962.19, hellaswag_acc: 0.2955
Step: 12078, loss: 3.142308, norm: 0.3014, time(ms): 798.18, token/sec:656855.44, hellaswag_acc: 0.2955
Step: 12079, loss: 3.098903, norm: 0.3033, time(ms): 802.99, token/sec:652923.04, hellaswag_acc: 0.2955
Step: 12080, loss: 3.113250, norm: 0.2816, time(ms): 798.55, token/sec:656547.34, hellaswag_acc: 0.2955
Step: 12081, loss: 3.133293, norm: 0.2929, time(ms): 793.33, token/sec:660873.42, hellaswag_acc: 0.2955
Step: 12082, loss: 3.104998, norm: 0.2747, time(ms): 803.74, token/sec:652307.53, hellaswag_acc: 0.2955
Step: 12083, loss: 3.188573, norm: 0.2884, time(ms): 803.78, token/sec:652280.24, hellaswag_acc: 0.2955
Step: 12084, loss: 3.172849, norm: 0.2824, time(ms): 799.53, token/sec:655743.66, hellaswag_acc: 0.2955
Step: 12085, loss: 3.158634, norm: 0.2592, time(ms): 792.22, token/sec:661799.26, hellaswag_acc: 0.2955
Step: 12086, loss: 3.136375, norm: 0.2805, time(ms): 805.95, token/sec:650523.92, hellaswag_acc: 0.2955
Step: 12087, loss: 3.091131, norm: 0.2769, time(ms): 802.00, token/sec:653726.81, hellaswag_acc: 0.2955
Step: 12088, loss: 3.141966, norm: 0.2915, time(ms): 792.99, token/sec:661152.79, hellaswag_acc: 0.2955
Step: 12089, loss: 3.110407, norm: 0.2879, time(ms): 799.41, token/sec:655846.92, hellaswag_acc: 0.2955
Step: 12090, loss: 3.091450, norm: 0.3038, time(ms): 801.70, token/sec:653968.86, hellaswag_acc: 0.2955
Step: 12091, loss: 3.077599, norm: 0.2762, time(ms): 804.69, token/sec:651541.02, hellaswag_acc: 0.2955
Step: 12092, loss: 3.086792, norm: 0.3006, time(ms): 790.72, token/sec:663047.81, hellaswag_acc: 0.2955
Step: 12093, loss: 3.023061, norm: 0.2728, time(ms): 803.44, token/sec:652551.81, hellaswag_acc: 0.2955
Step: 12094, loss: 3.036282, norm: 0.2840, time(ms): 805.64, token/sec:650769.38, hellaswag_acc: 0.2955
Step: 12095, loss: 3.034969, norm: 0.2710, time(ms): 796.01, token/sec:658645.17, hellaswag_acc: 0.2955
Step: 12096, loss: 3.021082, norm: 0.2707, time(ms): 802.17, token/sec:653586.34, hellaswag_acc: 0.2955
Step: 12097, loss: 3.074045, norm: 0.2850, time(ms): 798.77, token/sec:656370.19, hellaswag_acc: 0.2955
Step: 12098, loss: 3.123639, norm: 0.2822, time(ms): 799.26, token/sec:655969.98, hellaswag_acc: 0.2955
Step: 12099, loss: 3.111022, norm: 0.2857, time(ms): 802.98, token/sec:652927.11, hellaswag_acc: 0.2955
Step: 12100, loss: 3.088248, norm: 0.2895, time(ms): 794.39, token/sec:659991.17, hellaswag_acc: 0.2955
Step: 12101, loss: 3.026827, norm: 0.2817, time(ms): 803.66, token/sec:652376.61, hellaswag_acc: 0.2955
Step: 12102, loss: 3.119777, norm: 0.2928, time(ms): 799.63, token/sec:655666.63, hellaswag_acc: 0.2955
Step: 12103, loss: 3.180770, norm: 0.2893, time(ms): 801.79, token/sec:653893.60, hellaswag_acc: 0.2955
Step: 12104, loss: 3.100809, norm: 0.2972, time(ms): 792.83, token/sec:661290.57, hellaswag_acc: 0.2955
Step: 12105, loss: 3.187338, norm: 0.2888, time(ms): 804.02, token/sec:652081.02, hellaswag_acc: 0.2955
Step: 12106, loss: 3.194611, norm: 0.2871, time(ms): 803.03, token/sec:652889.50, hellaswag_acc: 0.2955
Step: 12107, loss: 3.183281, norm: 0.2870, time(ms): 797.22, token/sec:657649.26, hellaswag_acc: 0.2955
Step: 12108, loss: 3.164072, norm: 0.2771, time(ms): 795.22, token/sec:659295.64, hellaswag_acc: 0.2955
Step: 12109, loss: 3.161252, norm: 0.2805, time(ms): 806.16, token/sec:650350.00, hellaswag_acc: 0.2955
Step: 12110, loss: 3.161796, norm: 0.2657, time(ms): 799.76, token/sec:655554.04, hellaswag_acc: 0.2955
Step: 12111, loss: 3.146090, norm: 0.2932, time(ms): 800.29, token/sec:655118.53, hellaswag_acc: 0.2955
Step: 12112, loss: 3.162503, norm: 0.2863, time(ms): 798.21, token/sec:656832.68, hellaswag_acc: 0.2955
Step: 12113, loss: 3.150675, norm: 0.2714, time(ms): 798.03, token/sec:656978.48, hellaswag_acc: 0.2955
Step: 12114, loss: 3.121217, norm: 0.3195, time(ms): 803.63, token/sec:652401.19, hellaswag_acc: 0.2955
Step: 12115, loss: 3.186508, norm: 0.2791, time(ms): 798.09, token/sec:656925.88, hellaswag_acc: 0.2955
Step: 12116, loss: 3.105840, norm: 0.3275, time(ms): 792.68, token/sec:661410.70, hellaswag_acc: 0.2955
Step: 12117, loss: 3.155003, norm: 0.2770, time(ms): 805.73, token/sec:650702.94, hellaswag_acc: 0.2955
Step: 12118, loss: 3.184820, norm: 0.3031, time(ms): 802.51, token/sec:653311.00, hellaswag_acc: 0.2955
Step: 12119, loss: 3.165575, norm: 0.2801, time(ms): 793.23, token/sec:660951.68, hellaswag_acc: 0.2955
Step: 12120, loss: 3.070999, norm: 0.2992, time(ms): 804.94, token/sec:651339.74, hellaswag_acc: 0.2955
Step: 12121, loss: 3.143126, norm: 0.2687, time(ms): 798.54, token/sec:656561.85, hellaswag_acc: 0.2955
Step: 12122, loss: 3.157063, norm: 0.2974, time(ms): 800.46, token/sec:654980.77, hellaswag_acc: 0.2955
Step: 12123, loss: 3.091831, norm: 0.2763, time(ms): 801.89, token/sec:653811.95, hellaswag_acc: 0.2955
Step: 12124, loss: 3.171612, norm: 0.3056, time(ms): 793.00, token/sec:661147.62, hellaswag_acc: 0.2955
Step: 12125, loss: 3.097554, norm: 0.2827, time(ms): 802.14, token/sec:653610.62, hellaswag_acc: 0.2955
Step: 12126, loss: 3.052699, norm: 0.2934, time(ms): 804.72, token/sec:651519.59, hellaswag_acc: 0.2955
Step: 12127, loss: 3.040123, norm: 0.3000, time(ms): 791.41, token/sec:662472.73, hellaswag_acc: 0.2955
Step: 12128, loss: 3.031189, norm: 0.2875, time(ms): 803.11, token/sec:652818.18, hellaswag_acc: 0.2955
Step: 12129, loss: 3.097020, norm: 0.2778, time(ms): 802.88, token/sec:653011.45, hellaswag_acc: 0.2955
Step: 12130, loss: 3.084568, norm: 0.2841, time(ms): 800.05, token/sec:655321.56, hellaswag_acc: 0.2955
Step: 12131, loss: 3.054649, norm: 0.2923, time(ms): 789.83, token/sec:663799.17, hellaswag_acc: 0.2955
Step: 12132, loss: 3.097822, norm: 0.3074, time(ms): 790.33, token/sec:663378.84, hellaswag_acc: 0.2955
Step: 12133, loss: 3.097332, norm: 0.2827, time(ms): 796.53, token/sec:658217.76, hellaswag_acc: 0.2955
Step: 12134, loss: 3.032909, norm: 0.2811, time(ms): 795.17, token/sec:659338.93, hellaswag_acc: 0.2955
Step: 12135, loss: 3.041965, norm: 0.2609, time(ms): 790.74, token/sec:663033.62, hellaswag_acc: 0.2955
Step: 12136, loss: 3.070115, norm: 0.2903, time(ms): 787.25, token/sec:665976.34, hellaswag_acc: 0.2955
Step: 12137, loss: 3.084623, norm: 0.2594, time(ms): 790.18, token/sec:663506.75, hellaswag_acc: 0.2955
Step: 12138, loss: 3.143428, norm: 0.3114, time(ms): 799.82, token/sec:655506.36, hellaswag_acc: 0.2955
Step: 12139, loss: 3.143306, norm: 0.2662, time(ms): 794.60, token/sec:659813.93, hellaswag_acc: 0.2955
Step: 12140, loss: 3.168815, norm: 0.2843, time(ms): 799.68, token/sec:655624.21, hellaswag_acc: 0.2955
Step: 12141, loss: 3.168412, norm: 0.2854, time(ms): 797.88, token/sec:657102.35, hellaswag_acc: 0.2955
Step: 12142, loss: 3.211344, norm: 0.2929, time(ms): 804.23, token/sec:651914.00, hellaswag_acc: 0.2955
Step: 12143, loss: 3.145950, norm: 0.2841, time(ms): 799.58, token/sec:655702.01, hellaswag_acc: 0.2955
Step: 12144, loss: 3.126150, norm: 0.2754, time(ms): 799.28, token/sec:655953.35, hellaswag_acc: 0.2955
Step: 12145, loss: 3.198720, norm: 0.2980, time(ms): 800.19, token/sec:655208.32, hellaswag_acc: 0.2955
Step: 12146, loss: 3.215423, norm: 0.2751, time(ms): 799.93, token/sec:655419.03, hellaswag_acc: 0.2955
Step: 12147, loss: 3.118980, norm: 0.3075, time(ms): 798.18, token/sec:656857.01, hellaswag_acc: 0.2955
Step: 12148, loss: 3.125112, norm: 0.2622, time(ms): 799.43, token/sec:655830.69, hellaswag_acc: 0.2955
Step: 12149, loss: 3.087986, norm: 0.3003, time(ms): 796.16, token/sec:658521.90, hellaswag_acc: 0.2955
Step: 12150, loss: 3.093142, norm: 0.2778, time(ms): 790.71, token/sec:663063.40, hellaswag_acc: 0.2955
Step: 12151, loss: 3.197774, norm: 0.3110, time(ms): 792.33, token/sec:661703.87, hellaswag_acc: 0.2955
Step: 12152, loss: 3.180901, norm: 0.2715, time(ms): 797.48, token/sec:657433.18, hellaswag_acc: 0.2955
Step: 12153, loss: 3.102760, norm: 0.3087, time(ms): 788.43, token/sec:664975.65, hellaswag_acc: 0.2955
Step: 12154, loss: 3.115272, norm: 0.2846, time(ms): 793.33, token/sec:660867.66, hellaswag_acc: 0.2955
Step: 12155, loss: 3.110988, norm: 0.3544, time(ms): 801.81, token/sec:653881.35, hellaswag_acc: 0.2955
Step: 12156, loss: 3.135089, norm: 0.3009, time(ms): 804.65, token/sec:651573.45, hellaswag_acc: 0.2955
Step: 12157, loss: 3.099960, norm: 0.2733, time(ms): 789.95, token/sec:663696.99, hellaswag_acc: 0.2955
Step: 12158, loss: 3.100986, norm: 0.3069, time(ms): 802.16, token/sec:653599.35, hellaswag_acc: 0.2955
Step: 12159, loss: 3.077808, norm: 0.2913, time(ms): 807.22, token/sec:649495.22, hellaswag_acc: 0.2955
Step: 12160, loss: 3.117019, norm: 0.3001, time(ms): 791.22, token/sec:662631.83, hellaswag_acc: 0.2955
Step: 12161, loss: 3.051244, norm: 0.2708, time(ms): 803.89, token/sec:652191.64, hellaswag_acc: 0.2955
Step: 12162, loss: 3.072491, norm: 0.2958, time(ms): 804.15, token/sec:651981.84, hellaswag_acc: 0.2955
Step: 12163, loss: 3.095624, norm: 0.3124, time(ms): 800.19, token/sec:655202.26, hellaswag_acc: 0.2955
Step: 12164, loss: 3.035492, norm: 0.2806, time(ms): 794.09, token/sec:660241.05, hellaswag_acc: 0.2955
Step: 12165, loss: 3.049714, norm: 0.2694, time(ms): 802.95, token/sec:652949.02, hellaswag_acc: 0.2955
Step: 12166, loss: 3.004616, norm: 0.2629, time(ms): 799.27, token/sec:655962.35, hellaswag_acc: 0.2955
Step: 12167, loss: 3.063737, norm: 0.2817, time(ms): 799.84, token/sec:655493.27, hellaswag_acc: 0.2955
Step: 12168, loss: 3.078129, norm: 0.2812, time(ms): 802.16, token/sec:653593.91, hellaswag_acc: 0.2955
Step: 12169, loss: 3.038319, norm: 0.2819, time(ms): 797.97, token/sec:657028.53, hellaswag_acc: 0.2955
Step: 12170, loss: 3.061869, norm: 0.2952, time(ms): 801.01, token/sec:654532.37, hellaswag_acc: 0.2955
Step: 12171, loss: 3.039869, norm: 0.2631, time(ms): 798.48, token/sec:656603.61, hellaswag_acc: 0.2955
Step: 12172, loss: 3.066057, norm: 0.2861, time(ms): 802.11, token/sec:653633.16, hellaswag_acc: 0.2955
Step: 12173, loss: 3.169401, norm: 0.3202, time(ms): 797.18, token/sec:657677.97, hellaswag_acc: 0.2955
Step: 12174, loss: 3.226350, norm: 0.2873, time(ms): 799.39, token/sec:655863.94, hellaswag_acc: 0.2955
Step: 12175, loss: 3.152395, norm: 0.2742, time(ms): 801.22, token/sec:654359.42, hellaswag_acc: 0.2955
Step: 12176, loss: 3.119613, norm: 0.3495, time(ms): 801.95, token/sec:653769.38, hellaswag_acc: 0.2955
Step: 12177, loss: 3.209455, norm: 0.3333, time(ms): 789.76, token/sec:663858.88, hellaswag_acc: 0.2955
Step: 12178, loss: 3.183371, norm: 0.3547, time(ms): 790.34, token/sec:663369.44, hellaswag_acc: 0.2955
Step: 12179, loss: 3.204018, norm: 0.2911, time(ms): 793.93, token/sec:660368.14, hellaswag_acc: 0.2955
Step: 12180, loss: 3.174490, norm: 0.3359, time(ms): 796.64, token/sec:658121.43, hellaswag_acc: 0.2955
Step: 12181, loss: 3.161069, norm: 0.2834, time(ms): 790.28, token/sec:663423.47, hellaswag_acc: 0.2955
Step: 12182, loss: 3.193172, norm: 0.3325, time(ms): 792.59, token/sec:661486.51, hellaswag_acc: 0.2955
Step: 12183, loss: 3.187789, norm: 0.2806, time(ms): 799.27, token/sec:655959.81, hellaswag_acc: 0.2955
Step: 12184, loss: 3.093781, norm: 0.2822, time(ms): 802.08, token/sec:653661.52, hellaswag_acc: 0.2955
Step: 12185, loss: 3.142477, norm: 0.2818, time(ms): 804.30, token/sec:651858.53, hellaswag_acc: 0.2955
Step: 12186, loss: 3.110944, norm: 0.2756, time(ms): 798.87, token/sec:656290.46, hellaswag_acc: 0.2955
Step: 12187, loss: 3.109563, norm: 0.2791, time(ms): 791.68, token/sec:662249.29, hellaswag_acc: 0.2955
Step: 12188, loss: 3.106192, norm: 0.2758, time(ms): 799.02, token/sec:656159.84, hellaswag_acc: 0.2955
Step: 12189, loss: 3.105618, norm: 0.2668, time(ms): 793.10, token/sec:661060.76, hellaswag_acc: 0.2955
Step: 12190, loss: 3.114544, norm: 0.2863, time(ms): 792.66, token/sec:661425.43, hellaswag_acc: 0.2955
Step: 12191, loss: 3.116030, norm: 0.2841, time(ms): 1346.11, token/sec:389482.78, hellaswag_acc: 0.2955
Step: 12192, loss: 3.210347, norm: 0.2951, time(ms): 765.93, token/sec:684507.65, hellaswag_acc: 0.2955
Step: 12193, loss: 3.139292, norm: 0.2934, time(ms): 791.87, token/sec:662087.98, hellaswag_acc: 0.2955
Step: 12194, loss: 3.139515, norm: 0.2729, time(ms): 800.17, token/sec:655221.20, hellaswag_acc: 0.2955
Step: 12195, loss: 3.101799, norm: 0.2902, time(ms): 785.93, token/sec:667089.52, hellaswag_acc: 0.2955
Step: 12196, loss: 3.108684, norm: 0.2567, time(ms): 780.53, token/sec:671705.24, hellaswag_acc: 0.2955
Step: 12197, loss: 3.147472, norm: 0.2793, time(ms): 784.50, token/sec:668307.15, hellaswag_acc: 0.2955
Step: 12198, loss: 3.171928, norm: 0.2792, time(ms): 805.66, token/sec:650758.98, hellaswag_acc: 0.2955
Step: 12199, loss: 3.164526, norm: 0.2840, time(ms): 800.29, token/sec:655121.45, hellaswag_acc: 0.2955
Step: 12200, loss: 3.116148, norm: 0.2904, time(ms): 790.41, token/sec:663309.01, hellaswag_acc: 0.2955
Step: 12201, loss: 3.155406, norm: 0.2757, time(ms): 792.45, token/sec:661607.31, hellaswag_acc: 0.2955
Step: 12202, loss: 3.114807, norm: 0.2751, time(ms): 790.26, token/sec:663439.89, hellaswag_acc: 0.2955
Step: 12203, loss: 3.140882, norm: 0.2912, time(ms): 792.06, token/sec:661925.95, hellaswag_acc: 0.2955
Step: 12204, loss: 3.143316, norm: 0.2778, time(ms): 789.23, token/sec:664300.48, hellaswag_acc: 0.2955
Step: 12205, loss: 3.222905, norm: 0.2802, time(ms): 796.01, token/sec:658641.03, hellaswag_acc: 0.2955
Step: 12206, loss: 3.186998, norm: 0.3607, time(ms): 792.03, token/sec:661955.24, hellaswag_acc: 0.2955
Step: 12207, loss: 3.166674, norm: 0.2716, time(ms): 789.67, token/sec:663936.85, hellaswag_acc: 0.2955
Step: 12208, loss: 3.143261, norm: 0.3104, time(ms): 796.30, token/sec:658406.95, hellaswag_acc: 0.2955
Step: 12209, loss: 3.124440, norm: 0.2801, time(ms): 788.62, token/sec:664813.21, hellaswag_acc: 0.2955
Step: 12210, loss: 3.202077, norm: 0.2846, time(ms): 789.81, token/sec:663811.99, hellaswag_acc: 0.2955
Step: 12211, loss: 3.133290, norm: 0.2856, time(ms): 792.32, token/sec:661712.23, hellaswag_acc: 0.2955
Step: 12212, loss: 3.216043, norm: 0.2755, time(ms): 786.07, token/sec:666974.80, hellaswag_acc: 0.2955
Step: 12213, loss: 3.167313, norm: 0.2774, time(ms): 788.14, token/sec:665218.85, hellaswag_acc: 0.2955
Step: 12214, loss: 3.153023, norm: 0.2798, time(ms): 797.93, token/sec:657060.53, hellaswag_acc: 0.2955
Step: 12215, loss: 3.114394, norm: 0.2551, time(ms): 791.11, token/sec:662728.49, hellaswag_acc: 0.2955
Step: 12216, loss: 3.095872, norm: 0.2717, time(ms): 794.20, token/sec:660146.50, hellaswag_acc: 0.2955
Step: 12217, loss: 3.107708, norm: 0.2691, time(ms): 795.84, token/sec:658784.28, hellaswag_acc: 0.2955
Step: 12218, loss: 3.113885, norm: 0.3047, time(ms): 800.56, token/sec:654900.40, hellaswag_acc: 0.2955
Step: 12219, loss: 3.134637, norm: 0.2833, time(ms): 803.62, token/sec:652410.29, hellaswag_acc: 0.2955
Step: 12220, loss: 3.066208, norm: 0.2726, time(ms): 793.13, token/sec:661032.55, hellaswag_acc: 0.2955
Step: 12221, loss: 3.128427, norm: 0.2847, time(ms): 796.79, token/sec:657996.78, hellaswag_acc: 0.2955
Step: 12222, loss: 3.051599, norm: 0.2826, time(ms): 791.57, token/sec:662336.45, hellaswag_acc: 0.2955
Step: 12223, loss: 3.116193, norm: 0.2914, time(ms): 795.12, token/sec:659380.65, hellaswag_acc: 0.2955
Step: 12224, loss: 3.165366, norm: 0.2773, time(ms): 797.62, token/sec:657314.68, hellaswag_acc: 0.2955
Step: 12225, loss: 3.197050, norm: 0.2811, time(ms): 799.21, token/sec:656005.20, hellaswag_acc: 0.2955
Step: 12226, loss: 3.126186, norm: 0.2911, time(ms): 799.34, token/sec:655897.20, hellaswag_acc: 0.2955
Step: 12227, loss: 3.123350, norm: 0.2878, time(ms): 797.44, token/sec:657466.20, hellaswag_acc: 0.2955
Step: 12228, loss: 3.164358, norm: 0.3027, time(ms): 790.83, token/sec:662956.66, hellaswag_acc: 0.2955
Step: 12229, loss: 3.178997, norm: 0.2868, time(ms): 789.39, token/sec:664165.65, hellaswag_acc: 0.2955
Step: 12230, loss: 3.138712, norm: 0.2986, time(ms): 787.55, token/sec:665716.67, hellaswag_acc: 0.2955
Step: 12231, loss: 3.160684, norm: 0.2680, time(ms): 797.30, token/sec:657580.43, hellaswag_acc: 0.2955
Step: 12232, loss: 3.150293, norm: 0.2971, time(ms): 802.20, token/sec:653563.42, hellaswag_acc: 0.2955
Step: 12233, loss: 3.172194, norm: 0.3022, time(ms): 802.44, token/sec:653363.79, hellaswag_acc: 0.2955
Step: 12234, loss: 3.126969, norm: 0.3088, time(ms): 785.82, token/sec:667186.67, hellaswag_acc: 0.2955
Step: 12235, loss: 3.159341, norm: 0.3032, time(ms): 790.21, token/sec:663480.72, hellaswag_acc: 0.2955
Step: 12236, loss: 3.157960, norm: 0.3000, time(ms): 797.27, token/sec:657604.81, hellaswag_acc: 0.2955
Step: 12237, loss: 3.160753, norm: 0.2811, time(ms): 795.17, token/sec:659343.09, hellaswag_acc: 0.2955
Step: 12238, loss: 3.117734, norm: 0.2911, time(ms): 792.10, token/sec:661897.66, hellaswag_acc: 0.2955
Step: 12239, loss: 3.159343, norm: 0.3174, time(ms): 792.19, token/sec:661817.38, hellaswag_acc: 0.2955
Step: 12240, loss: 3.168531, norm: 0.3053, time(ms): 798.86, token/sec:656298.49, hellaswag_acc: 0.2955
Step: 12241, loss: 3.186342, norm: 0.3204, time(ms): 803.39, token/sec:652592.48, hellaswag_acc: 0.2955
Step: 12242, loss: 3.167336, norm: 0.2882, time(ms): 798.01, token/sec:656997.91, hellaswag_acc: 0.2955
Step: 12243, loss: 3.140298, norm: 0.2909, time(ms): 796.76, token/sec:658024.93, hellaswag_acc: 0.2955
Step: 12244, loss: 3.154549, norm: 0.2784, time(ms): 806.50, token/sec:650074.50, hellaswag_acc: 0.2955
Step: 12245, loss: 3.195536, norm: 0.2707, time(ms): 799.71, token/sec:655595.28, hellaswag_acc: 0.2955
Step: 12246, loss: 3.216128, norm: 0.3002, time(ms): 792.66, token/sec:661428.61, hellaswag_acc: 0.2955
Step: 12247, loss: 3.213706, norm: 0.2782, time(ms): 801.79, token/sec:653893.80, hellaswag_acc: 0.2955
Step: 12248, loss: 3.180232, norm: 0.3125, time(ms): 804.79, token/sec:651456.67, hellaswag_acc: 0.2955
Step: 12249, loss: 3.135516, norm: 0.2948, time(ms): 794.87, token/sec:659589.90, hellaswag_acc: 0.2955
rank 0 sample 0: Hello, I'm a language model, and I know that's my way of defining data. That's pretty complicated because I know that the language in which to
rank 0 sample 1: Hello, I'm a language model, so, since I'm a computer model, and is looking for ways to improve the quality of my translation, I have
rank 0 sample 2: Hello, I'm a language model, so I had to come up with some rules (it's called 'tutorials' in the language model) to
rank 0 sample 3: Hello, I'm a language model, but one of the things I've written in book 1 is that "a lot of it in this article is a mix
rank 1 sample 0: Hello, I'm a language model, my first stop is with the
A-D and
If you're the type
a in the first group,
rank 1 sample 1: Hello, I'm a language model, not an interpreter. I'm the compiler. I'm always in the middle of how something works in the language. I
rank 1 sample 2: Hello, I'm a language model, but other than this, I'm not a language model; what's a language model? A language model is just the
rank 1 sample 3: Hello, I'm a language model, and I'm doing some stuff right now while I'm back with those languages but I always got that wrong. If you
Step: 12250, loss: 3.194890, norm: 0.2928, time(ms): 3829.66, token/sec:136901.92, val_loss: 3.1433, hellaswag_acc: 0.2955
Step: 12251, loss: 3.164536, norm: 0.2923, time(ms): 781.77, token/sec:670643.50, hellaswag_acc: 0.2955
Step: 12252, loss: 3.157582, norm: 0.2996, time(ms): 786.06, token/sec:666982.08, hellaswag_acc: 0.2955
Step: 12253, loss: 3.070829, norm: 0.2743, time(ms): 799.79, token/sec:655531.37, hellaswag_acc: 0.2955
Step: 12254, loss: 3.119578, norm: 0.2814, time(ms): 808.01, token/sec:648860.11, hellaswag_acc: 0.2955
Step: 12255, loss: 3.089374, norm: 0.2726, time(ms): 790.63, token/sec:663128.39, hellaswag_acc: 0.2955
Step: 12256, loss: 3.104654, norm: 0.2783, time(ms): 792.76, token/sec:661349.24, hellaswag_acc: 0.2955
Step: 12257, loss: 3.060966, norm: 0.2897, time(ms): 789.87, token/sec:663762.30, hellaswag_acc: 0.2955
Step: 12258, loss: 3.070124, norm: 0.2873, time(ms): 800.01, token/sec:655350.27, hellaswag_acc: 0.2955
Step: 12259, loss: 3.070596, norm: 0.2939, time(ms): 796.33, token/sec:658377.38, hellaswag_acc: 0.2955
Step: 12260, loss: 3.115298, norm: 0.2971, time(ms): 791.14, token/sec:662699.73, hellaswag_acc: 0.2955
Step: 12261, loss: 3.123104, norm: 0.2884, time(ms): 783.64, token/sec:669044.43, hellaswag_acc: 0.2955
Step: 12262, loss: 3.098467, norm: 0.2865, time(ms): 791.28, token/sec:662582.92, hellaswag_acc: 0.2955
Step: 12263, loss: 3.198504, norm: 0.2797, time(ms): 801.65, token/sec:654010.48, hellaswag_acc: 0.2955
Step: 12264, loss: 3.135151, norm: 0.3218, time(ms): 800.91, token/sec:654618.30, hellaswag_acc: 0.2955
Step: 12265, loss: 3.147103, norm: 0.3008, time(ms): 798.77, token/sec:656372.93, hellaswag_acc: 0.2955
Step: 12266, loss: 3.130975, norm: 0.2977, time(ms): 796.94, token/sec:657877.29, hellaswag_acc: 0.2955
Step: 12267, loss: 3.149143, norm: 0.2853, time(ms): 801.71, token/sec:653963.22, hellaswag_acc: 0.2955
Step: 12268, loss: 3.117646, norm: 0.3016, time(ms): 802.15, token/sec:653600.52, hellaswag_acc: 0.2955
Step: 12269, loss: 3.138293, norm: 0.2989, time(ms): 793.18, token/sec:660991.81, hellaswag_acc: 0.2955
Step: 12270, loss: 3.185532, norm: 0.2974, time(ms): 804.53, token/sec:651670.77, hellaswag_acc: 0.2955
Step: 12271, loss: 3.185392, norm: 0.2953, time(ms): 802.04, token/sec:653689.89, hellaswag_acc: 0.2955
Step: 12272, loss: 3.221376, norm: 0.3287, time(ms): 795.31, token/sec:659220.93, hellaswag_acc: 0.2955
Step: 12273, loss: 3.119184, norm: 0.3342, time(ms): 802.60, token/sec:653236.09, hellaswag_acc: 0.2955
Step: 12274, loss: 3.179280, norm: 0.3166, time(ms): 796.92, token/sec:657889.29, hellaswag_acc: 0.2955
Step: 12275, loss: 3.160333, norm: 0.3135, time(ms): 802.41, token/sec:653387.67, hellaswag_acc: 0.2955
Step: 12276, loss: 3.149637, norm: 0.3204, time(ms): 800.35, token/sec:655071.10, hellaswag_acc: 0.2955
Step: 12277, loss: 3.174919, norm: 0.3001, time(ms): 795.06, token/sec:659429.49, hellaswag_acc: 0.2955
Step: 12278, loss: 3.272380, norm: 0.3116, time(ms): 804.00, token/sec:652102.68, hellaswag_acc: 0.2955
Step: 12279, loss: 3.135622, norm: 0.3046, time(ms): 800.87, token/sec:654647.53, hellaswag_acc: 0.2955
Step: 12280, loss: 3.182819, norm: 0.3075, time(ms): 792.46, token/sec:661598.75, hellaswag_acc: 0.2955
Step: 12281, loss: 3.162369, norm: 0.3222, time(ms): 799.41, token/sec:655844.19, hellaswag_acc: 0.2955
Step: 12282, loss: 3.202352, norm: 0.3047, time(ms): 804.20, token/sec:651938.93, hellaswag_acc: 0.2955
Step: 12283, loss: 3.207559, norm: 0.3315, time(ms): 804.99, token/sec:651296.52, hellaswag_acc: 0.2955
Step: 12284, loss: 3.170058, norm: 0.2818, time(ms): 787.71, token/sec:665586.90, hellaswag_acc: 0.2955
Step: 12285, loss: 3.171823, norm: 0.3120, time(ms): 788.68, token/sec:664770.40, hellaswag_acc: 0.2955
Step: 12286, loss: 3.087702, norm: 0.3022, time(ms): 796.58, token/sec:658173.04, hellaswag_acc: 0.2955
Step: 12287, loss: 3.163132, norm: 0.2955, time(ms): 790.38, token/sec:663338.82, hellaswag_acc: 0.2955
Step: 12288, loss: 3.079801, norm: 0.2915, time(ms): 795.28, token/sec:659252.16, hellaswag_acc: 0.2955
Step: 12289, loss: 3.137050, norm: 0.2954, time(ms): 788.74, token/sec:664719.56, hellaswag_acc: 0.2955
Step: 12290, loss: 3.108752, norm: 0.2640, time(ms): 791.44, token/sec:662449.19, hellaswag_acc: 0.2955
Step: 12291, loss: 3.088999, norm: 0.2769, time(ms): 797.65, token/sec:657290.12, hellaswag_acc: 0.2955
Step: 12292, loss: 3.098325, norm: 0.2666, time(ms): 791.10, token/sec:662731.48, hellaswag_acc: 0.2955
Step: 12293, loss: 3.064627, norm: 0.2733, time(ms): 791.27, token/sec:662588.51, hellaswag_acc: 0.2955
Step: 12294, loss: 3.138260, norm: 0.2828, time(ms): 787.24, token/sec:665984.21, hellaswag_acc: 0.2955
Step: 12295, loss: 3.152492, norm: 0.2648, time(ms): 792.82, token/sec:661295.74, hellaswag_acc: 0.2955
Step: 12296, loss: 3.118498, norm: 0.2840, time(ms): 796.32, token/sec:658391.77, hellaswag_acc: 0.2955
Step: 12297, loss: 3.120851, norm: 0.2833, time(ms): 796.01, token/sec:658641.43, hellaswag_acc: 0.2955
Step: 12298, loss: 3.131290, norm: 0.2829, time(ms): 803.31, token/sec:652660.66, hellaswag_acc: 0.2955
Step: 12299, loss: 3.157146, norm: 0.3223, time(ms): 802.03, token/sec:653702.52, hellaswag_acc: 0.2955
Step: 12300, loss: 3.205510, norm: 0.2898, time(ms): 793.72, token/sec:660543.29, hellaswag_acc: 0.2955
Step: 12301, loss: 3.151213, norm: 0.2999, time(ms): 803.53, token/sec:652480.95, hellaswag_acc: 0.2955
Step: 12302, loss: 3.168360, norm: 0.2803, time(ms): 796.58, token/sec:658175.01, hellaswag_acc: 0.2955
Step: 12303, loss: 3.155171, norm: 0.2696, time(ms): 806.19, token/sec:650332.11, hellaswag_acc: 0.2955
Step: 12304, loss: 3.154081, norm: 0.3004, time(ms): 794.06, token/sec:660261.86, hellaswag_acc: 0.2955
Step: 12305, loss: 3.130953, norm: 0.2823, time(ms): 803.13, token/sec:652802.09, hellaswag_acc: 0.2955
Step: 12306, loss: 3.105083, norm: 0.2709, time(ms): 800.30, token/sec:655111.31, hellaswag_acc: 0.2955
Step: 12307, loss: 3.135857, norm: 0.2958, time(ms): 801.04, token/sec:654508.22, hellaswag_acc: 0.2955
Step: 12308, loss: 3.191696, norm: 0.2942, time(ms): 791.94, token/sec:662028.98, hellaswag_acc: 0.2955
Step: 12309, loss: 3.146051, norm: 0.3158, time(ms): 799.22, token/sec:655996.40, hellaswag_acc: 0.2955
Step: 12310, loss: 3.162575, norm: 0.2793, time(ms): 808.00, token/sec:648872.37, hellaswag_acc: 0.2955
Step: 12311, loss: 3.209517, norm: 0.3051, time(ms): 794.16, token/sec:660180.00, hellaswag_acc: 0.2955
Step: 12312, loss: 3.176140, norm: 0.2820, time(ms): 798.78, token/sec:656360.59, hellaswag_acc: 0.2955
Step: 12313, loss: 3.188547, norm: 0.3106, time(ms): 805.24, token/sec:651098.48, hellaswag_acc: 0.2955
Step: 12314, loss: 3.146485, norm: 0.2800, time(ms): 802.20, token/sec:653560.89, hellaswag_acc: 0.2955
Step: 12315, loss: 3.160580, norm: 0.3193, time(ms): 798.73, token/sec:656404.28, hellaswag_acc: 0.2955
Step: 12316, loss: 3.246711, norm: 0.3080, time(ms): 795.25, token/sec:659278.25, hellaswag_acc: 0.2955
Step: 12317, loss: 3.144762, norm: 0.3064, time(ms): 802.21, token/sec:653556.23, hellaswag_acc: 0.2955
Step: 12318, loss: 3.184293, norm: 0.2904, time(ms): 802.72, token/sec:653141.79, hellaswag_acc: 0.2955
Step: 12319, loss: 3.150705, norm: 0.2856, time(ms): 794.44, token/sec:659948.58, hellaswag_acc: 0.2955
Step: 12320, loss: 3.121680, norm: 0.2819, time(ms): 798.52, token/sec:656573.81, hellaswag_acc: 0.2955
Step: 12321, loss: 3.097641, norm: 0.2654, time(ms): 805.21, token/sec:651119.88, hellaswag_acc: 0.2955
Step: 12322, loss: 3.128279, norm: 0.2970, time(ms): 794.70, token/sec:659732.77, hellaswag_acc: 0.2955
Step: 12323, loss: 3.085544, norm: 0.2707, time(ms): 798.65, token/sec:656471.49, hellaswag_acc: 0.2955
Step: 12324, loss: 3.123168, norm: 0.2707, time(ms): 806.90, token/sec:649757.18, hellaswag_acc: 0.2955
Step: 12325, loss: 3.100207, norm: 0.2767, time(ms): 790.60, token/sec:663154.58, hellaswag_acc: 0.2955
Step: 12326, loss: 3.114966, norm: 0.2844, time(ms): 792.36, token/sec:661678.58, hellaswag_acc: 0.2955
Step: 12327, loss: 3.165192, norm: 0.3165, time(ms): 788.34, token/sec:665051.46, hellaswag_acc: 0.2955
Step: 12328, loss: 3.092198, norm: 0.2815, time(ms): 791.99, token/sec:661990.11, hellaswag_acc: 0.2955
Step: 12329, loss: 3.080249, norm: 0.2901, time(ms): 789.98, token/sec:663673.55, hellaswag_acc: 0.2955
Step: 12330, loss: 3.143981, norm: 0.2804, time(ms): 795.88, token/sec:658755.08, hellaswag_acc: 0.2955
Step: 12331, loss: 3.180597, norm: 0.2907, time(ms): 791.29, token/sec:662575.93, hellaswag_acc: 0.2955
Step: 12332, loss: 3.130301, norm: 0.2896, time(ms): 789.05, token/sec:664456.65, hellaswag_acc: 0.2955
Step: 12333, loss: 3.148066, norm: 0.2946, time(ms): 790.55, token/sec:663191.98, hellaswag_acc: 0.2955
Step: 12334, loss: 3.184613, norm: 0.3098, time(ms): 787.62, token/sec:665661.65, hellaswag_acc: 0.2955
Step: 12335, loss: 3.107831, norm: 0.2980, time(ms): 790.93, token/sec:662875.12, hellaswag_acc: 0.2955
Step: 12336, loss: 3.167372, norm: 0.2786, time(ms): 791.36, token/sec:662518.04, hellaswag_acc: 0.2955
Step: 12337, loss: 3.137342, norm: 0.2882, time(ms): 803.33, token/sec:652646.52, hellaswag_acc: 0.2955
Step: 12338, loss: 3.221714, norm: 0.2843, time(ms): 805.85, token/sec:650603.79, hellaswag_acc: 0.2955
Step: 12339, loss: 3.169441, norm: 0.2870, time(ms): 787.40, token/sec:665846.88, hellaswag_acc: 0.2955
Step: 12340, loss: 3.134348, norm: 0.2709, time(ms): 790.65, token/sec:663107.99, hellaswag_acc: 0.2955
Step: 12341, loss: 3.121395, norm: 0.2890, time(ms): 791.73, token/sec:662208.80, hellaswag_acc: 0.2955
Step: 12342, loss: 3.147473, norm: 0.2857, time(ms): 791.46, token/sec:662430.43, hellaswag_acc: 0.2955
Step: 12343, loss: 3.159510, norm: 0.2850, time(ms): 790.59, token/sec:663160.58, hellaswag_acc: 0.2955
Step: 12344, loss: 3.154966, norm: 0.3198, time(ms): 799.07, token/sec:656119.12, hellaswag_acc: 0.2955
Step: 12345, loss: 3.253908, norm: 0.2832, time(ms): 805.91, token/sec:650551.83, hellaswag_acc: 0.2955
Step: 12346, loss: 3.152534, norm: 0.3021, time(ms): 801.59, token/sec:654057.94, hellaswag_acc: 0.2955
Step: 12347, loss: 3.254869, norm: 0.2999, time(ms): 791.21, token/sec:662640.02, hellaswag_acc: 0.2955
Step: 12348, loss: 3.136572, norm: 0.3040, time(ms): 797.56, token/sec:657364.39, hellaswag_acc: 0.2955
Step: 12349, loss: 3.170712, norm: 0.2882, time(ms): 791.54, token/sec:662362.79, hellaswag_acc: 0.2955
Step: 12350, loss: 3.169667, norm: 0.2928, time(ms): 789.62, token/sec:663976.75, hellaswag_acc: 0.2955
Step: 12351, loss: 3.147801, norm: 0.2951, time(ms): 793.03, token/sec:661120.19, hellaswag_acc: 0.2955
Step: 12352, loss: 3.155628, norm: 0.2579, time(ms): 786.40, token/sec:666694.74, hellaswag_acc: 0.2955
Step: 12353, loss: 3.169777, norm: 0.2868, time(ms): 793.54, token/sec:660694.12, hellaswag_acc: 0.2955
Step: 12354, loss: 3.119262, norm: 0.2711, time(ms): 796.10, token/sec:658569.43, hellaswag_acc: 0.2955
Step: 12355, loss: 3.106072, norm: 0.2685, time(ms): 784.58, token/sec:668238.71, hellaswag_acc: 0.2955
Step: 12356, loss: 3.100650, norm: 0.2702, time(ms): 790.75, token/sec:663026.22, hellaswag_acc: 0.2955
Step: 12357, loss: 3.064144, norm: 0.2593, time(ms): 797.19, token/sec:657669.12, hellaswag_acc: 0.2955
Step: 12358, loss: 3.112978, norm: 0.2881, time(ms): 795.58, token/sec:659004.61, hellaswag_acc: 0.2955
Step: 12359, loss: 3.114552, norm: 0.2670, time(ms): 791.97, token/sec:662006.85, hellaswag_acc: 0.2955
Step: 12360, loss: 3.107971, norm: 0.2642, time(ms): 795.54, token/sec:659031.67, hellaswag_acc: 0.2955
Step: 12361, loss: 3.115930, norm: 0.2605, time(ms): 795.85, token/sec:658779.94, hellaswag_acc: 0.2955
Step: 12362, loss: 3.090024, norm: 0.2879, time(ms): 801.67, token/sec:653995.70, hellaswag_acc: 0.2955
Step: 12363, loss: 3.122288, norm: 0.2826, time(ms): 803.84, token/sec:652228.98, hellaswag_acc: 0.2955
Step: 12364, loss: 3.099607, norm: 0.2936, time(ms): 798.22, token/sec:656817.57, hellaswag_acc: 0.2955
Step: 12365, loss: 3.145317, norm: 0.3294, time(ms): 793.37, token/sec:660835.88, hellaswag_acc: 0.2955
Step: 12366, loss: 3.096896, norm: 0.2686, time(ms): 806.16, token/sec:650351.54, hellaswag_acc: 0.2955
Step: 12367, loss: 3.179497, norm: 0.3150, time(ms): 803.38, token/sec:652604.49, hellaswag_acc: 0.2955
Step: 12368, loss: 3.124128, norm: 0.2769, time(ms): 795.43, token/sec:659128.26, hellaswag_acc: 0.2955
Step: 12369, loss: 3.166640, norm: 0.2969, time(ms): 797.79, token/sec:657177.96, hellaswag_acc: 0.2955
Step: 12370, loss: 3.161756, norm: 0.2743, time(ms): 801.35, token/sec:654255.07, hellaswag_acc: 0.2955
Step: 12371, loss: 3.177357, norm: 0.2989, time(ms): 802.83, token/sec:653050.24, hellaswag_acc: 0.2955
Step: 12372, loss: 3.211265, norm: 0.3365, time(ms): 795.65, token/sec:658946.55, hellaswag_acc: 0.2955
Step: 12373, loss: 3.215404, norm: 0.3096, time(ms): 795.20, token/sec:659312.25, hellaswag_acc: 0.2955
Step: 12374, loss: 3.116559, norm: 0.3078, time(ms): 798.77, token/sec:656366.66, hellaswag_acc: 0.2955
Step: 12375, loss: 3.196911, norm: 0.3032, time(ms): 792.38, token/sec:661665.64, hellaswag_acc: 0.2955
Step: 12376, loss: 3.168487, norm: 0.2951, time(ms): 797.53, token/sec:657390.33, hellaswag_acc: 0.2955
Step: 12377, loss: 3.157208, norm: 0.3058, time(ms): 791.53, token/sec:662374.36, hellaswag_acc: 0.2955
Step: 12378, loss: 3.138139, norm: 0.2604, time(ms): 798.80, token/sec:656341.78, hellaswag_acc: 0.2955
Step: 12379, loss: 3.202599, norm: 0.2987, time(ms): 789.29, token/sec:664248.71, hellaswag_acc: 0.2955
Step: 12380, loss: 3.168970, norm: 0.2812, time(ms): 787.75, token/sec:665552.05, hellaswag_acc: 0.2955
Step: 12381, loss: 3.173950, norm: 0.2846, time(ms): 793.47, token/sec:660752.49, hellaswag_acc: 0.2955
Step: 12382, loss: 3.123617, norm: 0.2733, time(ms): 1349.22, token/sec:388586.61, hellaswag_acc: 0.2955
Step: 12383, loss: 3.160974, norm: 0.2881, time(ms): 796.83, token/sec:657969.80, hellaswag_acc: 0.2955
Step: 12384, loss: 3.166290, norm: 0.2942, time(ms): 785.92, token/sec:667100.65, hellaswag_acc: 0.2955
Step: 12385, loss: 3.154430, norm: 0.3132, time(ms): 790.96, token/sec:662849.75, hellaswag_acc: 0.2955
Step: 12386, loss: 3.104385, norm: 0.2995, time(ms): 784.77, token/sec:668076.30, hellaswag_acc: 0.2955
Step: 12387, loss: 3.071451, norm: 0.3196, time(ms): 791.47, token/sec:662423.24, hellaswag_acc: 0.2955
Step: 12388, loss: 3.146782, norm: 0.3406, time(ms): 791.77, token/sec:662173.11, hellaswag_acc: 0.2955
Step: 12389, loss: 3.144457, norm: 0.2942, time(ms): 794.65, token/sec:659773.15, hellaswag_acc: 0.2955
Step: 12390, loss: 3.076896, norm: 0.3586, time(ms): 788.93, token/sec:664556.24, hellaswag_acc: 0.2955
Step: 12391, loss: 3.112687, norm: 0.3339, time(ms): 795.88, token/sec:658750.73, hellaswag_acc: 0.2955
Step: 12392, loss: 3.124925, norm: 0.3007, time(ms): 792.34, token/sec:661693.71, hellaswag_acc: 0.2955
Step: 12393, loss: 3.070161, norm: 0.2837, time(ms): 795.00, token/sec:659485.26, hellaswag_acc: 0.2955
Step: 12394, loss: 3.123437, norm: 0.3022, time(ms): 789.30, token/sec:664242.89, hellaswag_acc: 0.2955
Step: 12395, loss: 3.095743, norm: 0.2726, time(ms): 797.45, token/sec:657453.42, hellaswag_acc: 0.2955
Step: 12396, loss: 3.157277, norm: 0.3262, time(ms): 791.50, token/sec:662396.31, hellaswag_acc: 0.2955
Step: 12397, loss: 3.195949, norm: 0.2947, time(ms): 797.57, token/sec:657360.46, hellaswag_acc: 0.2955
Step: 12398, loss: 3.143632, norm: 0.3108, time(ms): 796.90, token/sec:657910.16, hellaswag_acc: 0.2955
Step: 12399, loss: 3.127992, norm: 0.2845, time(ms): 802.08, token/sec:653658.80, hellaswag_acc: 0.2955
Step: 12400, loss: 3.106410, norm: 0.2921, time(ms): 799.50, token/sec:655770.45, hellaswag_acc: 0.2955
Step: 12401, loss: 3.177436, norm: 0.3377, time(ms): 794.87, token/sec:659593.66, hellaswag_acc: 0.2955
Step: 12402, loss: 3.198071, norm: 0.3201, time(ms): 791.13, token/sec:662703.72, hellaswag_acc: 0.2955
Step: 12403, loss: 3.142958, norm: 0.3154, time(ms): 786.52, token/sec:666593.49, hellaswag_acc: 0.2955
Step: 12404, loss: 3.249385, norm: 0.3301, time(ms): 786.10, token/sec:666951.74, hellaswag_acc: 0.2955
Step: 12405, loss: 3.163628, norm: 0.3188, time(ms): 798.56, token/sec:656543.03, hellaswag_acc: 0.2955
Step: 12406, loss: 3.136782, norm: 0.3181, time(ms): 806.54, token/sec:650049.52, hellaswag_acc: 0.2955
Step: 12407, loss: 3.152246, norm: 0.3249, time(ms): 798.88, token/sec:656281.25, hellaswag_acc: 0.2955
Step: 12408, loss: 3.151556, norm: 0.2891, time(ms): 790.22, token/sec:663469.31, hellaswag_acc: 0.2955
Step: 12409, loss: 3.147168, norm: 0.3011, time(ms): 801.15, token/sec:654416.87, hellaswag_acc: 0.2955
Step: 12410, loss: 3.123944, norm: 0.2897, time(ms): 790.70, token/sec:663065.20, hellaswag_acc: 0.2955
Step: 12411, loss: 3.164353, norm: 0.3272, time(ms): 788.00, token/sec:665344.24, hellaswag_acc: 0.2955
Step: 12412, loss: 3.114528, norm: 0.2836, time(ms): 788.85, token/sec:664620.52, hellaswag_acc: 0.2955
Step: 12413, loss: 3.136372, norm: 0.2952, time(ms): 798.47, token/sec:656616.94, hellaswag_acc: 0.2955
Step: 12414, loss: 3.121205, norm: 0.2983, time(ms): 795.51, token/sec:659059.32, hellaswag_acc: 0.2955
Step: 12415, loss: 3.172243, norm: 0.2936, time(ms): 802.54, token/sec:653283.05, hellaswag_acc: 0.2955
Step: 12416, loss: 3.138984, norm: 0.2904, time(ms): 803.03, token/sec:652890.86, hellaswag_acc: 0.2955
Step: 12417, loss: 3.123808, norm: 0.2946, time(ms): 794.02, token/sec:660299.53, hellaswag_acc: 0.2955
Step: 12418, loss: 3.162898, norm: 0.2876, time(ms): 801.53, token/sec:654108.53, hellaswag_acc: 0.2955
Step: 12419, loss: 3.173057, norm: 0.2913, time(ms): 800.29, token/sec:655121.84, hellaswag_acc: 0.2955
Step: 12420, loss: 3.119899, norm: 0.3453, time(ms): 802.76, token/sec:653105.71, hellaswag_acc: 0.2955
Step: 12421, loss: 3.102625, norm: 0.3224, time(ms): 797.81, token/sec:657156.94, hellaswag_acc: 0.2955
Step: 12422, loss: 3.112928, norm: 0.3013, time(ms): 799.02, token/sec:656161.21, hellaswag_acc: 0.2955
Step: 12423, loss: 3.101972, norm: 0.3129, time(ms): 802.63, token/sec:653210.28, hellaswag_acc: 0.2955
Step: 12424, loss: 3.095259, norm: 0.2998, time(ms): 794.87, token/sec:659588.12, hellaswag_acc: 0.2955
Step: 12425, loss: 3.165246, norm: 0.2930, time(ms): 796.54, token/sec:658208.50, hellaswag_acc: 0.2955
Step: 12426, loss: 3.068566, norm: 0.2983, time(ms): 795.52, token/sec:659051.22, hellaswag_acc: 0.2955
Step: 12427, loss: 3.116586, norm: 0.2780, time(ms): 794.74, token/sec:659697.54, hellaswag_acc: 0.2955
Step: 12428, loss: 3.120229, norm: 0.2844, time(ms): 787.89, token/sec:665431.22, hellaswag_acc: 0.2955
Step: 12429, loss: 3.060424, norm: 0.2778, time(ms): 790.29, token/sec:663412.47, hellaswag_acc: 0.2955
Step: 12430, loss: 3.107424, norm: 0.2681, time(ms): 794.74, token/sec:659695.76, hellaswag_acc: 0.2955
Step: 12431, loss: 3.129936, norm: 0.2863, time(ms): 795.77, token/sec:658840.73, hellaswag_acc: 0.2955
Step: 12432, loss: 3.141517, norm: 0.2784, time(ms): 790.58, token/sec:663170.38, hellaswag_acc: 0.2955
Step: 12433, loss: 3.154350, norm: 0.2817, time(ms): 792.28, token/sec:661745.48, hellaswag_acc: 0.2955
Step: 12434, loss: 3.125534, norm: 0.2746, time(ms): 804.17, token/sec:651960.96, hellaswag_acc: 0.2955
Step: 12435, loss: 3.242321, norm: 0.3043, time(ms): 799.96, token/sec:655390.31, hellaswag_acc: 0.2955
Step: 12436, loss: 3.142856, norm: 0.2798, time(ms): 801.96, token/sec:653760.63, hellaswag_acc: 0.2955
Step: 12437, loss: 3.167579, norm: 0.2970, time(ms): 794.91, token/sec:659559.24, hellaswag_acc: 0.2955
Step: 12438, loss: 3.142708, norm: 0.2739, time(ms): 802.74, token/sec:653123.94, hellaswag_acc: 0.2955
Step: 12439, loss: 3.123348, norm: 0.3178, time(ms): 799.47, token/sec:655791.57, hellaswag_acc: 0.2955
Step: 12440, loss: 3.155740, norm: 0.2823, time(ms): 800.47, token/sec:654977.84, hellaswag_acc: 0.2955
Step: 12441, loss: 3.153095, norm: 0.3350, time(ms): 798.13, token/sec:656894.88, hellaswag_acc: 0.2955
Step: 12442, loss: 3.250162, norm: 0.2850, time(ms): 800.05, token/sec:655322.54, hellaswag_acc: 0.2955
Step: 12443, loss: 3.205346, norm: 0.3407, time(ms): 803.52, token/sec:652487.72, hellaswag_acc: 0.2955
Step: 12444, loss: 3.140666, norm: 0.2961, time(ms): 795.77, token/sec:658847.05, hellaswag_acc: 0.2955
Step: 12445, loss: 3.063134, norm: 0.2844, time(ms): 796.22, token/sec:658467.28, hellaswag_acc: 0.2955
Step: 12446, loss: 3.121491, norm: 0.3047, time(ms): 801.73, token/sec:653947.27, hellaswag_acc: 0.2955
Step: 12447, loss: 3.168896, norm: 0.2823, time(ms): 805.62, token/sec:650786.90, hellaswag_acc: 0.2955
Step: 12448, loss: 3.143754, norm: 0.3025, time(ms): 791.03, token/sec:662794.41, hellaswag_acc: 0.2955
Step: 12449, loss: 3.150582, norm: 0.3023, time(ms): 806.36, token/sec:650193.09, hellaswag_acc: 0.2955
Step: 12450, loss: 3.140313, norm: 0.2596, time(ms): 799.41, token/sec:655843.21, hellaswag_acc: 0.2955
Step: 12451, loss: 3.148722, norm: 0.2978, time(ms): 802.29, token/sec:653488.06, hellaswag_acc: 0.2955
Step: 12452, loss: 3.120971, norm: 0.2697, time(ms): 798.37, token/sec:656698.90, hellaswag_acc: 0.2955
Step: 12453, loss: 3.209485, norm: 0.2790, time(ms): 799.27, token/sec:655961.37, hellaswag_acc: 0.2955
Step: 12454, loss: 3.153044, norm: 0.2850, time(ms): 800.35, token/sec:655075.59, hellaswag_acc: 0.2955
Step: 12455, loss: 3.112318, norm: 0.3020, time(ms): 801.39, token/sec:654224.90, hellaswag_acc: 0.2955
Step: 12456, loss: 3.162202, norm: 0.2787, time(ms): 789.55, token/sec:664035.29, hellaswag_acc: 0.2955
Step: 12457, loss: 3.079908, norm: 0.2997, time(ms): 793.79, token/sec:660489.33, hellaswag_acc: 0.2955
Step: 12458, loss: 3.094018, norm: 0.3015, time(ms): 791.44, token/sec:662450.98, hellaswag_acc: 0.2955
Step: 12459, loss: 3.099889, norm: 0.2693, time(ms): 791.12, token/sec:662718.70, hellaswag_acc: 0.2955
Step: 12460, loss: 3.102323, norm: 0.2767, time(ms): 792.12, token/sec:661883.32, hellaswag_acc: 0.2955
Step: 12461, loss: 3.134145, norm: 0.2614, time(ms): 795.19, token/sec:659321.73, hellaswag_acc: 0.2955
Step: 12462, loss: 3.147905, norm: 0.2726, time(ms): 804.00, token/sec:652098.42, hellaswag_acc: 0.2955
Step: 12463, loss: 3.101538, norm: 0.2911, time(ms): 800.62, token/sec:654856.52, hellaswag_acc: 0.2955
Step: 12464, loss: 3.131142, norm: 0.3050, time(ms): 796.68, token/sec:658088.54, hellaswag_acc: 0.2955
Step: 12465, loss: 3.148954, norm: 0.2975, time(ms): 799.20, token/sec:656019.49, hellaswag_acc: 0.2955
Step: 12466, loss: 3.141720, norm: 0.2788, time(ms): 803.62, token/sec:652404.68, hellaswag_acc: 0.2955
Step: 12467, loss: 3.123209, norm: 0.2698, time(ms): 796.26, token/sec:658442.24, hellaswag_acc: 0.2955
Step: 12468, loss: 3.100005, norm: 0.3015, time(ms): 795.02, token/sec:659462.71, hellaswag_acc: 0.2955
Step: 12469, loss: 3.113870, norm: 0.2804, time(ms): 803.95, token/sec:652137.29, hellaswag_acc: 0.2955
Step: 12470, loss: 3.169817, norm: 0.2811, time(ms): 801.97, token/sec:653748.19, hellaswag_acc: 0.2955
Step: 12471, loss: 3.045823, norm: 0.2980, time(ms): 798.74, token/sec:656390.37, hellaswag_acc: 0.2955
Step: 12472, loss: 3.094299, norm: 0.2707, time(ms): 797.09, token/sec:657755.48, hellaswag_acc: 0.2955
Step: 12473, loss: 3.126960, norm: 0.2934, time(ms): 802.98, token/sec:652926.34, hellaswag_acc: 0.2955
Step: 12474, loss: 3.116688, norm: 0.3020, time(ms): 802.72, token/sec:653142.76, hellaswag_acc: 0.2955
Step: 12475, loss: 3.152689, norm: 0.3200, time(ms): 798.21, token/sec:656828.16, hellaswag_acc: 0.2955
Step: 12476, loss: 3.109777, norm: 0.3004, time(ms): 793.37, token/sec:660839.46, hellaswag_acc: 0.2955
Step: 12477, loss: 3.101446, norm: 0.2858, time(ms): 802.13, token/sec:653619.36, hellaswag_acc: 0.2955
Step: 12478, loss: 3.072456, norm: 0.2810, time(ms): 802.69, token/sec:653160.03, hellaswag_acc: 0.2955
Step: 12479, loss: 3.135825, norm: 0.3024, time(ms): 800.33, token/sec:655088.28, hellaswag_acc: 0.2955
Step: 12480, loss: 3.181407, norm: 0.2948, time(ms): 800.94, token/sec:654593.75, hellaswag_acc: 0.2955
Step: 12481, loss: 3.146034, norm: 0.2988, time(ms): 801.48, token/sec:654151.53, hellaswag_acc: 0.2955
Step: 12482, loss: 3.136241, norm: 0.3166, time(ms): 797.46, token/sec:657449.49, hellaswag_acc: 0.2955
Step: 12483, loss: 3.102899, norm: 0.3020, time(ms): 798.45, token/sec:656632.23, hellaswag_acc: 0.2955
Step: 12484, loss: 3.154095, norm: 0.3275, time(ms): 800.40, token/sec:655035.40, hellaswag_acc: 0.2955
Step: 12485, loss: 3.154774, norm: 0.2970, time(ms): 800.25, token/sec:655155.61, hellaswag_acc: 0.2955
Step: 12486, loss: 3.123158, norm: 0.2964, time(ms): 802.63, token/sec:653214.16, hellaswag_acc: 0.2955
Step: 12487, loss: 3.163686, norm: 0.2950, time(ms): 796.99, token/sec:657834.39, hellaswag_acc: 0.2955
Step: 12488, loss: 3.177727, norm: 0.2655, time(ms): 798.84, token/sec:656315.53, hellaswag_acc: 0.2955
Step: 12489, loss: 3.168197, norm: 0.3011, time(ms): 800.82, token/sec:654687.10, hellaswag_acc: 0.2955
Step: 12490, loss: 3.172310, norm: 0.2847, time(ms): 802.61, token/sec:653231.82, hellaswag_acc: 0.2955
Step: 12491, loss: 3.110855, norm: 0.2871, time(ms): 797.45, token/sec:657452.24, hellaswag_acc: 0.2955
Step: 12492, loss: 3.082244, norm: 0.3010, time(ms): 794.82, token/sec:659633.03, hellaswag_acc: 0.2955
Step: 12493, loss: 3.138208, norm: 0.2787, time(ms): 801.84, token/sec:653855.49, hellaswag_acc: 0.2955
Step: 12494, loss: 3.128757, norm: 0.2809, time(ms): 800.36, token/sec:655067.01, hellaswag_acc: 0.2955
Step: 12495, loss: 3.088376, norm: 0.2727, time(ms): 800.66, token/sec:654820.83, hellaswag_acc: 0.2955
Step: 12496, loss: 3.111808, norm: 0.2706, time(ms): 800.62, token/sec:654852.03, hellaswag_acc: 0.2955
Step: 12497, loss: 3.104412, norm: 0.2755, time(ms): 799.09, token/sec:656105.61, hellaswag_acc: 0.2955
Step: 12498, loss: 3.079560, norm: 0.2828, time(ms): 798.89, token/sec:656266.96, hellaswag_acc: 0.2955
Step: 12499, loss: 3.093464, norm: 0.2728, time(ms): 799.76, token/sec:655555.41, hellaswag_acc: 0.2955
rank 0 sample 0: Hello, I'm a language model, and I know that it's the one they love. But, let's go back, one by one.
Let
rank 0 sample 1: Hello, I'm a language model, so when I do it, it usually means something entirely different, as it would be a nice example on this site.
rank 0 sample 2: Hello, I'm a language model, so I had to give one of the best language models I’ve seen. I was a little surprised at the
rank 0 sample 3: Hello, I'm a language model, a community of researchers, educators and administrators, helping to shape the direction of education policy in Nigeria. Our work in academia
rank 1 sample 0: Hello, I'm a language model, what are you doing?
So one way would be to show the model some data points from some data.
I
rank 1 sample 1: Hello, I'm a language model, not an artist. I'm a person. I'm somebody. I'm something, even a beginner, and I'm
rank 1 sample 2: Hello, I'm a language model, I didn't even know it. I'm a great linguist. And I'm a teacher in the field where you
rank 1 sample 3: Hello, I'm a language model, and I'm doing it the right way — I'm running with one simple sentence. After working out the sentence, I
Step: 12500, loss: 3.056793, norm: 0.2696, time(ms): 3809.71, token/sec:137618.90, val_loss: 3.1394, hellaswag_acc: 0.2955
Step: 12501, loss: 3.149756, norm: 0.2725, time(ms): 783.03, token/sec:669562.06, hellaswag_acc: 0.2955
Step: 12502, loss: 3.066871, norm: 0.2706, time(ms): 782.06, token/sec:670391.20, hellaswag_acc: 0.2955
Step: 12503, loss: 3.149071, norm: 0.3329, time(ms): 804.86, token/sec:651404.76, hellaswag_acc: 0.2955
Step: 12504, loss: 3.114620, norm: 0.3044, time(ms): 801.03, token/sec:654515.23, hellaswag_acc: 0.2955
Step: 12505, loss: 3.121886, norm: 0.3531, time(ms): 792.09, token/sec:661902.44, hellaswag_acc: 0.2955
Step: 12506, loss: 3.124139, norm: 0.2956, time(ms): 786.11, token/sec:666936.77, hellaswag_acc: 0.2955
Step: 12507, loss: 3.195873, norm: 0.3374, time(ms): 794.80, token/sec:659649.06, hellaswag_acc: 0.2955
Step: 12508, loss: 3.139986, norm: 0.3380, time(ms): 790.79, token/sec:662991.44, hellaswag_acc: 0.2955
Step: 12509, loss: 3.136101, norm: 0.2898, time(ms): 797.60, token/sec:657330.60, hellaswag_acc: 0.2955
Step: 12510, loss: 3.150523, norm: 0.3307, time(ms): 790.20, token/sec:663485.73, hellaswag_acc: 0.2955
Step: 12511, loss: 3.154992, norm: 0.2787, time(ms): 789.28, token/sec:664261.55, hellaswag_acc: 0.2955
Step: 12512, loss: 3.127882, norm: 0.3056, time(ms): 792.16, token/sec:661847.46, hellaswag_acc: 0.2955
Step: 12513, loss: 3.119914, norm: 0.2890, time(ms): 790.74, token/sec:663030.62, hellaswag_acc: 0.2955
Step: 12514, loss: 3.103603, norm: 0.2842, time(ms): 791.84, token/sec:662116.29, hellaswag_acc: 0.2955
Step: 12515, loss: 3.174841, norm: 0.3238, time(ms): 798.24, token/sec:656804.62, hellaswag_acc: 0.2955
Step: 12516, loss: 3.211478, norm: 0.2681, time(ms): 798.42, token/sec:656659.68, hellaswag_acc: 0.2955
Step: 12517, loss: 3.158010, norm: 0.3357, time(ms): 792.42, token/sec:661630.40, hellaswag_acc: 0.2955
Step: 12518, loss: 3.165694, norm: 0.2845, time(ms): 788.12, token/sec:665239.37, hellaswag_acc: 0.2955
Step: 12519, loss: 3.162364, norm: 0.3013, time(ms): 792.40, token/sec:661643.14, hellaswag_acc: 0.2955
Step: 12520, loss: 3.089926, norm: 0.2883, time(ms): 791.51, token/sec:662387.93, hellaswag_acc: 0.2955
Step: 12521, loss: 3.189881, norm: 0.2748, time(ms): 793.89, token/sec:660401.26, hellaswag_acc: 0.2955
Step: 12522, loss: 3.174974, norm: 0.2953, time(ms): 789.81, token/sec:663819.40, hellaswag_acc: 0.2955
Step: 12523, loss: 3.125761, norm: 0.2703, time(ms): 797.11, token/sec:657739.55, hellaswag_acc: 0.2955
Step: 12524, loss: 3.171894, norm: 0.2928, time(ms): 797.47, token/sec:657435.14, hellaswag_acc: 0.2955
Step: 12525, loss: 3.099740, norm: 0.2694, time(ms): 801.15, token/sec:654415.50, hellaswag_acc: 0.2955
Step: 12526, loss: 3.102505, norm: 0.2889, time(ms): 802.07, token/sec:653667.16, hellaswag_acc: 0.2955
Step: 12527, loss: 3.102177, norm: 0.2575, time(ms): 803.35, token/sec:652624.05, hellaswag_acc: 0.2955
Step: 12528, loss: 3.101510, norm: 0.2897, time(ms): 787.86, token/sec:665458.20, hellaswag_acc: 0.2955
Step: 12529, loss: 3.163386, norm: 0.2816, time(ms): 792.42, token/sec:661627.42, hellaswag_acc: 0.2955
Step: 12530, loss: 3.137690, norm: 0.2811, time(ms): 789.79, token/sec:663832.23, hellaswag_acc: 0.2955
Step: 12531, loss: 3.107130, norm: 0.2891, time(ms): 792.09, token/sec:661903.04, hellaswag_acc: 0.2955
Step: 12532, loss: 3.136706, norm: 0.2757, time(ms): 792.75, token/sec:661354.41, hellaswag_acc: 0.2955
Step: 12533, loss: 3.109258, norm: 0.3059, time(ms): 796.55, token/sec:658201.01, hellaswag_acc: 0.2955
Step: 12534, loss: 3.113240, norm: 0.2719, time(ms): 803.13, token/sec:652803.26, hellaswag_acc: 0.2955
Step: 12535, loss: 3.102582, norm: 0.2769, time(ms): 804.18, token/sec:651956.32, hellaswag_acc: 0.2955
Step: 12536, loss: 3.065459, norm: 0.2769, time(ms): 794.75, token/sec:659687.65, hellaswag_acc: 0.2955
Step: 12537, loss: 3.089479, norm: 0.2752, time(ms): 793.17, token/sec:661001.75, hellaswag_acc: 0.2955
Step: 12538, loss: 3.072705, norm: 0.3064, time(ms): 791.19, token/sec:662659.99, hellaswag_acc: 0.2955
Step: 12539, loss: 3.167744, norm: 0.3204, time(ms): 794.69, token/sec:659742.87, hellaswag_acc: 0.2955
Step: 12540, loss: 3.120073, norm: 0.2978, time(ms): 790.02, token/sec:663635.30, hellaswag_acc: 0.2955
Step: 12541, loss: 3.109629, norm: 0.2972, time(ms): 789.99, token/sec:663664.94, hellaswag_acc: 0.2955
Step: 12542, loss: 3.134761, norm: 0.2781, time(ms): 792.66, token/sec:661429.01, hellaswag_acc: 0.2955
Step: 12543, loss: 3.137903, norm: 0.2997, time(ms): 791.15, token/sec:662694.94, hellaswag_acc: 0.2955
Step: 12544, loss: 3.121862, norm: 0.2874, time(ms): 798.84, token/sec:656312.01, hellaswag_acc: 0.2955
Step: 12545, loss: 3.161223, norm: 0.3153, time(ms): 793.13, token/sec:661038.51, hellaswag_acc: 0.2955
Step: 12546, loss: 3.124111, norm: 0.2741, time(ms): 803.29, token/sec:652673.83, hellaswag_acc: 0.2955
Step: 12547, loss: 3.100470, norm: 0.3308, time(ms): 803.68, token/sec:652361.52, hellaswag_acc: 0.2955
Step: 12548, loss: 3.133797, norm: 0.3114, time(ms): 800.77, token/sec:654729.20, hellaswag_acc: 0.2955
Step: 12549, loss: 3.138417, norm: 0.2982, time(ms): 787.65, token/sec:665639.89, hellaswag_acc: 0.2955
Step: 12550, loss: 3.232733, norm: 0.3361, time(ms): 791.65, token/sec:662276.01, hellaswag_acc: 0.2955
Step: 12551, loss: 3.189148, norm: 0.3146, time(ms): 797.08, token/sec:657760.79, hellaswag_acc: 0.2955
Step: 12552, loss: 3.150236, norm: 0.3077, time(ms): 789.79, token/sec:663831.43, hellaswag_acc: 0.2955
Step: 12553, loss: 3.170718, norm: 0.3019, time(ms): 789.44, token/sec:664129.55, hellaswag_acc: 0.2955
Step: 12554, loss: 3.160630, norm: 0.3041, time(ms): 799.81, token/sec:655513.59, hellaswag_acc: 0.2955
Step: 12555, loss: 3.164111, norm: 0.2968, time(ms): 799.07, token/sec:656123.23, hellaswag_acc: 0.2955
Step: 12556, loss: 3.148392, norm: 0.2992, time(ms): 799.33, token/sec:655906.20, hellaswag_acc: 0.2955
Step: 12557, loss: 3.159191, norm: 0.2871, time(ms): 800.64, token/sec:654836.63, hellaswag_acc: 0.2955
Step: 12558, loss: 3.148378, norm: 0.3060, time(ms): 801.62, token/sec:654034.21, hellaswag_acc: 0.2955
Step: 12559, loss: 3.113980, norm: 0.2791, time(ms): 800.31, token/sec:655106.04, hellaswag_acc: 0.2955
Step: 12560, loss: 3.115041, norm: 0.3257, time(ms): 793.56, token/sec:660680.62, hellaswag_acc: 0.2955
Step: 12561, loss: 3.134801, norm: 0.2949, time(ms): 802.56, token/sec:653271.21, hellaswag_acc: 0.2955
Step: 12562, loss: 3.106829, norm: 0.2926, time(ms): 805.22, token/sec:651108.31, hellaswag_acc: 0.2955
Step: 12563, loss: 3.133693, norm: 0.2807, time(ms): 793.27, token/sec:660922.08, hellaswag_acc: 0.2955
Step: 12564, loss: 2.998773, norm: 0.2956, time(ms): 794.72, token/sec:659714.76, hellaswag_acc: 0.2955
Step: 12565, loss: 3.124482, norm: 0.2832, time(ms): 790.91, token/sec:662893.31, hellaswag_acc: 0.2955
Step: 12566, loss: 3.079906, norm: 0.2789, time(ms): 796.35, token/sec:658364.37, hellaswag_acc: 0.2955
Step: 12567, loss: 3.127641, norm: 0.2991, time(ms): 794.85, token/sec:659608.50, hellaswag_acc: 0.2955
Step: 12568, loss: 3.152796, norm: 0.2859, time(ms): 791.26, token/sec:662602.68, hellaswag_acc: 0.2955
Step: 12569, loss: 3.120479, norm: 0.2817, time(ms): 785.84, token/sec:667167.85, hellaswag_acc: 0.2955
Step: 12570, loss: 3.064107, norm: 0.2790, time(ms): 791.79, token/sec:662158.95, hellaswag_acc: 0.2955
Step: 12571, loss: 3.128472, norm: 0.2732, time(ms): 790.35, token/sec:663365.44, hellaswag_acc: 0.2955
Step: 12572, loss: 3.073940, norm: 0.2582, time(ms): 1265.01, token/sec:414452.35, hellaswag_acc: 0.2955
Step: 12573, loss: 3.130907, norm: 0.2663, time(ms): 775.70, token/sec:675892.99, hellaswag_acc: 0.2955
Step: 12574, loss: 3.151413, norm: 0.2664, time(ms): 788.79, token/sec:664672.75, hellaswag_acc: 0.2955
Step: 12575, loss: 3.102023, norm: 0.2748, time(ms): 798.86, token/sec:656298.69, hellaswag_acc: 0.2955
Step: 12576, loss: 3.095253, norm: 0.2487, time(ms): 785.49, token/sec:667463.71, hellaswag_acc: 0.2955
Step: 12577, loss: 3.084570, norm: 0.2789, time(ms): 781.04, token/sec:671266.45, hellaswag_acc: 0.2955
Step: 12578, loss: 3.085283, norm: 0.2785, time(ms): 789.82, token/sec:663808.38, hellaswag_acc: 0.2955
Step: 12579, loss: 3.076775, norm: 0.2725, time(ms): 796.20, token/sec:658485.81, hellaswag_acc: 0.2955
Step: 12580, loss: 3.106400, norm: 0.2814, time(ms): 795.11, token/sec:659389.74, hellaswag_acc: 0.2955
Step: 12581, loss: 3.094928, norm: 0.2736, time(ms): 789.95, token/sec:663695.79, hellaswag_acc: 0.2955
Step: 12582, loss: 3.074574, norm: 0.2765, time(ms): 793.73, token/sec:660536.94, hellaswag_acc: 0.2955
Step: 12583, loss: 3.089348, norm: 0.2797, time(ms): 798.35, token/sec:656714.79, hellaswag_acc: 0.2955
Step: 12584, loss: 3.107645, norm: 0.2767, time(ms): 798.19, token/sec:656844.06, hellaswag_acc: 0.2955
Step: 12585, loss: 3.081730, norm: 0.2989, time(ms): 791.90, token/sec:662063.66, hellaswag_acc: 0.2955
Step: 12586, loss: 3.008774, norm: 0.2606, time(ms): 790.40, token/sec:663316.61, hellaswag_acc: 0.2955
Step: 12587, loss: 2.977462, norm: 0.2913, time(ms): 794.14, token/sec:660193.47, hellaswag_acc: 0.2955
Step: 12588, loss: 2.931136, norm: 0.2806, time(ms): 787.07, token/sec:666125.43, hellaswag_acc: 0.2955
Step: 12589, loss: 2.961797, norm: 0.2645, time(ms): 792.15, token/sec:661855.43, hellaswag_acc: 0.2955
Step: 12590, loss: 2.964253, norm: 0.2981, time(ms): 794.93, token/sec:659543.21, hellaswag_acc: 0.2955
Step: 12591, loss: 2.942859, norm: 0.2699, time(ms): 788.62, token/sec:664817.23, hellaswag_acc: 0.2955
Step: 12592, loss: 2.940628, norm: 0.3083, time(ms): 802.05, token/sec:653682.12, hellaswag_acc: 0.2955
Step: 12593, loss: 2.979869, norm: 0.2821, time(ms): 807.60, token/sec:649196.49, hellaswag_acc: 0.2955
Step: 12594, loss: 2.965539, norm: 0.3302, time(ms): 783.51, token/sec:669150.50, hellaswag_acc: 0.2955
Step: 12595, loss: 2.889793, norm: 0.2565, time(ms): 787.81, token/sec:665500.69, hellaswag_acc: 0.2955
Step: 12596, loss: 2.958476, norm: 0.3338, time(ms): 792.83, token/sec:661285.40, hellaswag_acc: 0.2955
Step: 12597, loss: 3.027013, norm: 0.2750, time(ms): 794.42, token/sec:659965.22, hellaswag_acc: 0.2955
Step: 12598, loss: 3.111383, norm: 0.3418, time(ms): 797.07, token/sec:657770.63, hellaswag_acc: 0.2955
Step: 12599, loss: 3.178719, norm: 0.3279, time(ms): 799.84, token/sec:655493.27, hellaswag_acc: 0.2955
Step: 12600, loss: 3.090812, norm: 0.3023, time(ms): 798.94, token/sec:656225.63, hellaswag_acc: 0.2955
Step: 12601, loss: 3.092138, norm: 0.2911, time(ms): 802.75, token/sec:653113.66, hellaswag_acc: 0.2955
Step: 12602, loss: 3.201769, norm: 0.3036, time(ms): 793.79, token/sec:660485.76, hellaswag_acc: 0.2955
Step: 12603, loss: 3.204124, norm: 0.2988, time(ms): 799.89, token/sec:655452.04, hellaswag_acc: 0.2955
Step: 12604, loss: 3.191179, norm: 0.3088, time(ms): 797.96, token/sec:657034.42, hellaswag_acc: 0.2955
Step: 12605, loss: 3.099743, norm: 0.3032, time(ms): 792.81, token/sec:661305.88, hellaswag_acc: 0.2955
Step: 12606, loss: 3.123053, norm: 0.3109, time(ms): 792.00, token/sec:661980.55, hellaswag_acc: 0.2955
Step: 12607, loss: 3.128862, norm: 0.2768, time(ms): 797.87, token/sec:657109.42, hellaswag_acc: 0.2955
Step: 12608, loss: 3.180772, norm: 0.3072, time(ms): 801.50, token/sec:654129.74, hellaswag_acc: 0.2955
Step: 12609, loss: 3.199568, norm: 0.2912, time(ms): 804.30, token/sec:651858.73, hellaswag_acc: 0.2955
Step: 12610, loss: 3.118695, norm: 0.3010, time(ms): 791.28, token/sec:662578.13, hellaswag_acc: 0.2955
Step: 12611, loss: 3.060898, norm: 0.2920, time(ms): 798.21, token/sec:656832.87, hellaswag_acc: 0.2955
Step: 12612, loss: 3.152469, norm: 0.3122, time(ms): 788.66, token/sec:664781.45, hellaswag_acc: 0.2955
Step: 12613, loss: 3.174953, norm: 0.2840, time(ms): 792.46, token/sec:661592.38, hellaswag_acc: 0.2955
Step: 12614, loss: 3.169714, norm: 0.2770, time(ms): 786.33, token/sec:666754.17, hellaswag_acc: 0.2955
Step: 12615, loss: 3.112292, norm: 0.2807, time(ms): 799.26, token/sec:655965.68, hellaswag_acc: 0.2955
Step: 12616, loss: 3.120491, norm: 0.2790, time(ms): 801.99, token/sec:653734.39, hellaswag_acc: 0.2955
Step: 12617, loss: 3.145391, norm: 0.2851, time(ms): 800.91, token/sec:654613.04, hellaswag_acc: 0.2955
Step: 12618, loss: 3.113690, norm: 0.2978, time(ms): 790.94, token/sec:662871.13, hellaswag_acc: 0.2955
Step: 12619, loss: 3.172272, norm: 0.2747, time(ms): 803.43, token/sec:652561.69, hellaswag_acc: 0.2955
Step: 12620, loss: 3.094728, norm: 0.2898, time(ms): 803.73, token/sec:652319.52, hellaswag_acc: 0.2955
Step: 12621, loss: 3.071183, norm: 0.2801, time(ms): 797.53, token/sec:657393.08, hellaswag_acc: 0.2955
Step: 12622, loss: 3.127021, norm: 0.2829, time(ms): 803.59, token/sec:652433.13, hellaswag_acc: 0.2955
Step: 12623, loss: 3.126432, norm: 0.2854, time(ms): 793.02, token/sec:661130.52, hellaswag_acc: 0.2955
Step: 12624, loss: 3.148012, norm: 0.2958, time(ms): 803.50, token/sec:652501.27, hellaswag_acc: 0.2955
Step: 12625, loss: 3.145957, norm: 0.3101, time(ms): 802.78, token/sec:653087.09, hellaswag_acc: 0.2955
Step: 12626, loss: 3.114707, norm: 0.3039, time(ms): 790.19, token/sec:663498.34, hellaswag_acc: 0.2955
Step: 12627, loss: 3.092732, norm: 0.2823, time(ms): 796.30, token/sec:658402.42, hellaswag_acc: 0.2955
Step: 12628, loss: 3.112615, norm: 0.3112, time(ms): 791.92, token/sec:662049.71, hellaswag_acc: 0.2955
Step: 12629, loss: 3.124551, norm: 0.2901, time(ms): 793.76, token/sec:660515.32, hellaswag_acc: 0.2955
Step: 12630, loss: 3.092906, norm: 0.2858, time(ms): 789.91, token/sec:663731.85, hellaswag_acc: 0.2955
Step: 12631, loss: 3.129924, norm: 0.2817, time(ms): 787.09, token/sec:666113.32, hellaswag_acc: 0.2955
Step: 12632, loss: 2.940394, norm: 0.3158, time(ms): 791.93, token/sec:662041.73, hellaswag_acc: 0.2955
Step: 12633, loss: 2.906507, norm: 0.3296, time(ms): 792.45, token/sec:661605.12, hellaswag_acc: 0.2955
Step: 12634, loss: 3.000033, norm: 0.2904, time(ms): 800.10, token/sec:655282.12, hellaswag_acc: 0.2955
Step: 12635, loss: 2.965278, norm: 0.3257, time(ms): 796.48, token/sec:658259.53, hellaswag_acc: 0.2955
Step: 12636, loss: 2.991233, norm: 0.2930, time(ms): 790.84, token/sec:662954.46, hellaswag_acc: 0.2955
Step: 12637, loss: 3.005259, norm: 0.2942, time(ms): 785.91, token/sec:667105.31, hellaswag_acc: 0.2955
Step: 12638, loss: 2.949543, norm: 0.3037, time(ms): 791.56, token/sec:662347.03, hellaswag_acc: 0.2955
Step: 12639, loss: 2.925638, norm: 0.2659, time(ms): 788.78, token/sec:664682.59, hellaswag_acc: 0.2955
Step: 12640, loss: 2.948571, norm: 0.3148, time(ms): 790.69, token/sec:663073.20, hellaswag_acc: 0.2955
Step: 12641, loss: 2.988661, norm: 0.3175, time(ms): 791.90, token/sec:662060.67, hellaswag_acc: 0.2955
Step: 12642, loss: 2.918286, norm: 0.3326, time(ms): 793.33, token/sec:660868.06, hellaswag_acc: 0.2955
Step: 12643, loss: 3.020160, norm: 0.3202, time(ms): 793.44, token/sec:660781.47, hellaswag_acc: 0.2955
Step: 12644, loss: 3.127628, norm: 0.3145, time(ms): 797.17, token/sec:657688.20, hellaswag_acc: 0.2955
Step: 12645, loss: 3.112154, norm: 0.2966, time(ms): 798.35, token/sec:656718.32, hellaswag_acc: 0.2955
Step: 12646, loss: 3.144047, norm: 0.3071, time(ms): 801.24, token/sec:654348.52, hellaswag_acc: 0.2955
Step: 12647, loss: 3.141400, norm: 0.3036, time(ms): 802.37, token/sec:653424.56, hellaswag_acc: 0.2955
Step: 12648, loss: 3.149145, norm: 0.3088, time(ms): 791.35, token/sec:662521.63, hellaswag_acc: 0.2955
Step: 12649, loss: 3.129292, norm: 0.2985, time(ms): 799.17, token/sec:656039.65, hellaswag_acc: 0.2955
Step: 12650, loss: 3.086143, norm: 0.2947, time(ms): 792.82, token/sec:661291.76, hellaswag_acc: 0.2955
Step: 12651, loss: 3.147306, norm: 0.2938, time(ms): 794.64, token/sec:659776.91, hellaswag_acc: 0.2955
Step: 12652, loss: 3.112047, norm: 0.2839, time(ms): 794.78, token/sec:659660.34, hellaswag_acc: 0.2955
Step: 12653, loss: 3.186306, norm: 0.3055, time(ms): 803.28, token/sec:652680.61, hellaswag_acc: 0.2955
Step: 12654, loss: 3.154228, norm: 0.3001, time(ms): 803.38, token/sec:652600.42, hellaswag_acc: 0.2955
Step: 12655, loss: 3.110882, norm: 0.2872, time(ms): 797.72, token/sec:657232.56, hellaswag_acc: 0.2955
Step: 12656, loss: 3.073845, norm: 0.2734, time(ms): 795.42, token/sec:659129.84, hellaswag_acc: 0.2955
Step: 12657, loss: 3.121905, norm: 0.2770, time(ms): 800.04, token/sec:655325.86, hellaswag_acc: 0.2955
Step: 12658, loss: 3.152179, norm: 0.2944, time(ms): 797.40, token/sec:657498.83, hellaswag_acc: 0.2955
Step: 12659, loss: 3.121476, norm: 0.2782, time(ms): 791.94, token/sec:662033.96, hellaswag_acc: 0.2955
Step: 12660, loss: 3.119176, norm: 0.3020, time(ms): 785.45, token/sec:667496.93, hellaswag_acc: 0.2955
Step: 12661, loss: 3.141592, norm: 0.2751, time(ms): 789.84, token/sec:663789.55, hellaswag_acc: 0.2955
Step: 12662, loss: 3.160918, norm: 0.2901, time(ms): 800.68, token/sec:654801.92, hellaswag_acc: 0.2955
Step: 12663, loss: 3.118130, norm: 0.2760, time(ms): 795.78, token/sec:658832.64, hellaswag_acc: 0.2955
Step: 12664, loss: 3.156188, norm: 0.2927, time(ms): 802.98, token/sec:652925.95, hellaswag_acc: 0.2955
Step: 12665, loss: 3.153060, norm: 0.2723, time(ms): 800.54, token/sec:654920.30, hellaswag_acc: 0.2955
Step: 12666, loss: 3.151923, norm: 0.2977, time(ms): 794.81, token/sec:659636.59, hellaswag_acc: 0.2955
Step: 12667, loss: 3.078754, norm: 0.4004, time(ms): 805.53, token/sec:650857.40, hellaswag_acc: 0.2955
Step: 12668, loss: 3.110009, norm: 0.3510, time(ms): 793.77, token/sec:660500.83, hellaswag_acc: 0.2955
Step: 12669, loss: 3.062794, norm: 0.2998, time(ms): 803.78, token/sec:652279.28, hellaswag_acc: 0.2955
Step: 12670, loss: 3.120902, norm: 0.3356, time(ms): 802.46, token/sec:653351.37, hellaswag_acc: 0.2955
Step: 12671, loss: 3.130701, norm: 0.2664, time(ms): 791.25, token/sec:662608.47, hellaswag_acc: 0.2955
Step: 12672, loss: 3.095165, norm: 0.3143, time(ms): 805.34, token/sec:651017.71, hellaswag_acc: 0.2955
Step: 12673, loss: 3.043458, norm: 0.2707, time(ms): 799.67, token/sec:655633.59, hellaswag_acc: 0.2955
Step: 12674, loss: 3.117342, norm: 0.2937, time(ms): 802.93, token/sec:652966.47, hellaswag_acc: 0.2955
Step: 12675, loss: 3.134929, norm: 0.2809, time(ms): 788.47, token/sec:664946.49, hellaswag_acc: 0.2955
Step: 12676, loss: 3.116169, norm: 0.3081, time(ms): 791.20, token/sec:662645.21, hellaswag_acc: 0.2955
Step: 12677, loss: 3.036534, norm: 0.2860, time(ms): 794.87, token/sec:659586.93, hellaswag_acc: 0.2955
Step: 12678, loss: 2.978058, norm: 0.3394, time(ms): 792.10, token/sec:661896.26, hellaswag_acc: 0.2955
Step: 12679, loss: 2.938401, norm: 0.3140, time(ms): 791.54, token/sec:662366.38, hellaswag_acc: 0.2955
Step: 12680, loss: 2.943205, norm: 0.3033, time(ms): 795.46, token/sec:659102.58, hellaswag_acc: 0.2955
Step: 12681, loss: 2.955423, norm: 0.2930, time(ms): 800.77, token/sec:654729.79, hellaswag_acc: 0.2955
Step: 12682, loss: 2.896239, norm: 0.3009, time(ms): 803.01, token/sec:652907.34, hellaswag_acc: 0.2955
Step: 12683, loss: 2.942988, norm: 0.3048, time(ms): 793.48, token/sec:660748.91, hellaswag_acc: 0.2955
Step: 12684, loss: 3.025649, norm: 0.2911, time(ms): 805.98, token/sec:650494.09, hellaswag_acc: 0.2955
Step: 12685, loss: 2.982012, norm: 0.2923, time(ms): 797.25, token/sec:657622.90, hellaswag_acc: 0.2955
Step: 12686, loss: 2.958310, norm: 0.2728, time(ms): 799.50, token/sec:655767.91, hellaswag_acc: 0.2955
Step: 12687, loss: 3.035687, norm: 0.2946, time(ms): 800.56, token/sec:654903.52, hellaswag_acc: 0.2955
Step: 12688, loss: 2.949243, norm: 0.2970, time(ms): 800.34, token/sec:655080.47, hellaswag_acc: 0.2955
Step: 12689, loss: 3.097675, norm: 0.2764, time(ms): 800.43, token/sec:655009.06, hellaswag_acc: 0.2955
Step: 12690, loss: 3.147081, norm: 0.3055, time(ms): 795.24, token/sec:659284.57, hellaswag_acc: 0.2955
Step: 12691, loss: 3.228932, norm: 0.5152, time(ms): 803.34, token/sec:652631.60, hellaswag_acc: 0.2955
Step: 12692, loss: 3.162477, norm: 0.3642, time(ms): 799.50, token/sec:655769.08, hellaswag_acc: 0.2955
Step: 12693, loss: 3.128525, norm: 0.3396, time(ms): 802.68, token/sec:653168.18, hellaswag_acc: 0.2955
Step: 12694, loss: 3.309378, norm: 0.3771, time(ms): 796.58, token/sec:658175.99, hellaswag_acc: 0.2955
Step: 12695, loss: 3.105606, norm: 0.3416, time(ms): 799.52, token/sec:655755.98, hellaswag_acc: 0.2955
Step: 12696, loss: 3.094779, norm: 0.3120, time(ms): 803.28, token/sec:652686.23, hellaswag_acc: 0.2955
Step: 12697, loss: 3.123218, norm: 0.3172, time(ms): 794.06, token/sec:660260.87, hellaswag_acc: 0.2955
Step: 12698, loss: 3.137563, norm: 0.3167, time(ms): 802.69, token/sec:653161.97, hellaswag_acc: 0.2955
Step: 12699, loss: 3.098060, norm: 0.3103, time(ms): 799.35, token/sec:655895.63, hellaswag_acc: 0.2955
Step: 12700, loss: 3.148765, norm: 0.3043, time(ms): 803.77, token/sec:652287.02, hellaswag_acc: 0.2955
Step: 12701, loss: 3.174624, norm: 0.3087, time(ms): 797.35, token/sec:657541.69, hellaswag_acc: 0.2955
Step: 12702, loss: 3.265218, norm: 0.3791, time(ms): 796.72, token/sec:658059.59, hellaswag_acc: 0.2955
Step: 12703, loss: 3.141469, norm: 0.3931, time(ms): 799.17, token/sec:656037.11, hellaswag_acc: 0.2955
Step: 12704, loss: 3.174661, norm: 0.3331, time(ms): 807.84, token/sec:648999.14, hellaswag_acc: 0.2955
Step: 12705, loss: 3.146174, norm: 0.4249, time(ms): 790.56, token/sec:663185.98, hellaswag_acc: 0.2955
Step: 12706, loss: 3.170180, norm: 0.3687, time(ms): 797.84, token/sec:657133.77, hellaswag_acc: 0.2955
Step: 12707, loss: 3.168575, norm: 0.3241, time(ms): 793.11, token/sec:661054.60, hellaswag_acc: 0.2955
Step: 12708, loss: 3.208520, norm: 0.3314, time(ms): 796.38, token/sec:658335.20, hellaswag_acc: 0.2955
Step: 12709, loss: 3.176754, norm: 0.2972, time(ms): 796.36, token/sec:658356.88, hellaswag_acc: 0.2955
Step: 12710, loss: 3.150262, norm: 0.3093, time(ms): 796.33, token/sec:658377.97, hellaswag_acc: 0.2955
Step: 12711, loss: 3.166968, norm: 0.3450, time(ms): 796.60, token/sec:658160.43, hellaswag_acc: 0.2955
Step: 12712, loss: 3.142486, norm: 0.3126, time(ms): 789.95, token/sec:663695.99, hellaswag_acc: 0.2955
Step: 12713, loss: 3.145426, norm: 0.3113, time(ms): 788.99, token/sec:664506.64, hellaswag_acc: 0.2955
Step: 12714, loss: 3.113486, norm: 0.2827, time(ms): 786.28, token/sec:666792.58, hellaswag_acc: 0.2955
Step: 12715, loss: 3.099187, norm: 0.2822, time(ms): 802.77, token/sec:653101.25, hellaswag_acc: 0.2955
Step: 12716, loss: 3.077734, norm: 0.2815, time(ms): 790.87, token/sec:662927.88, hellaswag_acc: 0.2955
Step: 12717, loss: 3.123627, norm: 0.2792, time(ms): 791.93, token/sec:662035.55, hellaswag_acc: 0.2955
Step: 12718, loss: 3.105125, norm: 0.2753, time(ms): 788.46, token/sec:664952.72, hellaswag_acc: 0.2955
Step: 12719, loss: 3.116681, norm: 0.3034, time(ms): 793.53, token/sec:660706.82, hellaswag_acc: 0.2955
Step: 12720, loss: 3.139948, norm: 0.2894, time(ms): 789.23, token/sec:664303.09, hellaswag_acc: 0.2955
Step: 12721, loss: 3.068499, norm: 0.2824, time(ms): 797.05, token/sec:657782.04, hellaswag_acc: 0.2955
Step: 12722, loss: 3.136376, norm: 0.3031, time(ms): 791.26, token/sec:662602.08, hellaswag_acc: 0.2955
Step: 12723, loss: 3.124466, norm: 0.2877, time(ms): 792.20, token/sec:661812.20, hellaswag_acc: 0.2955
Step: 12724, loss: 3.031416, norm: 0.2910, time(ms): 796.90, token/sec:657912.91, hellaswag_acc: 0.2955
Step: 12725, loss: 2.995372, norm: 0.2973, time(ms): 791.03, token/sec:662787.41, hellaswag_acc: 0.2955
Step: 12726, loss: 2.919424, norm: 0.3145, time(ms): 788.39, token/sec:665009.63, hellaswag_acc: 0.2955
Step: 12727, loss: 2.934010, norm: 0.3063, time(ms): 793.14, token/sec:661025.59, hellaswag_acc: 0.2955
Step: 12728, loss: 3.015414, norm: 0.2896, time(ms): 795.92, token/sec:658717.58, hellaswag_acc: 0.2955
Step: 12729, loss: 2.974593, norm: 0.2660, time(ms): 797.88, token/sec:657100.19, hellaswag_acc: 0.2955
Step: 12730, loss: 2.909085, norm: 0.2967, time(ms): 799.15, token/sec:656056.68, hellaswag_acc: 0.2955
Step: 12731, loss: 2.989903, norm: 0.2753, time(ms): 801.95, token/sec:653768.60, hellaswag_acc: 0.2955
Step: 12732, loss: 2.960255, norm: 0.2764, time(ms): 795.99, token/sec:658658.00, hellaswag_acc: 0.2955
Step: 12733, loss: 2.957989, norm: 0.2683, time(ms): 796.67, token/sec:658096.02, hellaswag_acc: 0.2955
Step: 12734, loss: 3.049236, norm: 0.2905, time(ms): 807.07, token/sec:649618.02, hellaswag_acc: 0.2955
Step: 12735, loss: 3.023029, norm: 0.2541, time(ms): 795.92, token/sec:658719.16, hellaswag_acc: 0.2955
Step: 12736, loss: 3.019511, norm: 0.2597, time(ms): 795.61, token/sec:658975.97, hellaswag_acc: 0.2955
Step: 12737, loss: 3.144586, norm: 0.3175, time(ms): 806.06, token/sec:650436.76, hellaswag_acc: 0.2955
Step: 12738, loss: 3.233594, norm: 0.2921, time(ms): 802.71, token/sec:653144.51, hellaswag_acc: 0.2955
Step: 12739, loss: 3.125440, norm: 0.2968, time(ms): 787.92, token/sec:665411.28, hellaswag_acc: 0.2955
Step: 12740, loss: 3.163204, norm: 0.2889, time(ms): 792.94, token/sec:661198.91, hellaswag_acc: 0.2955
Step: 12741, loss: 3.133333, norm: 0.2698, time(ms): 791.22, token/sec:662636.03, hellaswag_acc: 0.2955
Step: 12742, loss: 3.154454, norm: 0.2797, time(ms): 796.72, token/sec:658060.97, hellaswag_acc: 0.2955
Step: 12743, loss: 3.117099, norm: 0.2831, time(ms): 792.89, token/sec:661237.68, hellaswag_acc: 0.2955
Step: 12744, loss: 3.242199, norm: 0.2969, time(ms): 789.22, token/sec:664309.31, hellaswag_acc: 0.2955
Step: 12745, loss: 3.123512, norm: 0.2865, time(ms): 800.21, token/sec:655191.33, hellaswag_acc: 0.2955
Step: 12746, loss: 3.103950, norm: 0.3232, time(ms): 804.20, token/sec:651936.80, hellaswag_acc: 0.2955
Step: 12747, loss: 3.118933, norm: 0.3071, time(ms): 804.11, token/sec:652011.61, hellaswag_acc: 0.2955
Step: 12748, loss: 3.147998, norm: 0.2767, time(ms): 790.54, token/sec:663203.78, hellaswag_acc: 0.2955
Step: 12749, loss: 3.126641, norm: 0.2928, time(ms): 797.87, token/sec:657108.44, hellaswag_acc: 0.2955
rank 0 sample 0: Hello, I'm a language model, and I want to make sense of some people's language of their world to see how their language actually functions, and then
rank 0 sample 1: Hello, I'm a language model, so when I do that, it should be pretty normal-sounding. We've been using "I mean, I mean
rank 0 sample 2: Hello, I'm a language model, but I did it here; when I was teaching, I just said to myself, 'You're not going to ever
rank 0 sample 3: Hello, I'm a language model, so for example, I'm not actually doing one, but I want to do two things together, because I think some
rank 1 sample 0: Hello, I'm a language model, how would you describe it?
Hi. The way I feel about it is, you know you're going to be
rank 1 sample 1: Hello, I'm a language model, not an engineering concept. I can't talk to me without understanding everything. If you come from a very humble background,
rank 1 sample 2: Hello, I'm a language model, so...
In this example, we are going to start
from our script, and then run a
$ -
rank 1 sample 3: Hello, I'm a language model, and I'm an expert model, and therefore I'm ready to model myself here. Please keep the following in mind when
Step: 12750, loss: 3.221345, norm: 0.3129, time(ms): 3818.14, token/sec:137314.86, val_loss: 3.1340, hellaswag_acc: 0.2955
Step: 12751, loss: 3.129649, norm: 0.2822, time(ms): 793.11, token/sec:661054.60, hellaswag_acc: 0.2955
Step: 12752, loss: 3.106421, norm: 0.2970, time(ms): 790.68, token/sec:663087.60, hellaswag_acc: 0.2955
Step: 12753, loss: 3.117938, norm: 0.2955, time(ms): 798.11, token/sec:656911.16, hellaswag_acc: 0.2955
Step: 12754, loss: 3.178810, norm: 0.2787, time(ms): 791.71, token/sec:662221.36, hellaswag_acc: 0.2955
Step: 12755, loss: 3.124991, norm: 0.2719, time(ms): 790.78, token/sec:662999.83, hellaswag_acc: 0.2955
Step: 12756, loss: 3.107284, norm: 0.2990, time(ms): 789.93, token/sec:663716.22, hellaswag_acc: 0.2955
Step: 12757, loss: 3.182593, norm: 0.3188, time(ms): 787.40, token/sec:665845.07, hellaswag_acc: 0.2955
Step: 12758, loss: 3.102932, norm: 0.2776, time(ms): 792.09, token/sec:661903.44, hellaswag_acc: 0.2955
Step: 12759, loss: 3.127968, norm: 0.2958, time(ms): 792.71, token/sec:661386.44, hellaswag_acc: 0.2955
Step: 12760, loss: 3.130596, norm: 0.2647, time(ms): 796.57, token/sec:658180.72, hellaswag_acc: 0.2955
Step: 12761, loss: 3.100786, norm: 0.2940, time(ms): 804.38, token/sec:651787.82, hellaswag_acc: 0.2955
Step: 12762, loss: 3.143915, norm: 0.2799, time(ms): 801.84, token/sec:653857.63, hellaswag_acc: 0.2955
Step: 12763, loss: 3.091608, norm: 0.2619, time(ms): 1302.23, token/sec:402608.68, hellaswag_acc: 0.2955
Step: 12764, loss: 3.112315, norm: 0.2990, time(ms): 798.35, token/sec:656715.18, hellaswag_acc: 0.2955
Step: 12765, loss: 3.112852, norm: 0.2771, time(ms): 789.17, token/sec:664357.88, hellaswag_acc: 0.2955
Step: 12766, loss: 3.080507, norm: 0.2878, time(ms): 780.38, token/sec:671836.58, hellaswag_acc: 0.2955
Step: 12767, loss: 3.083344, norm: 0.2703, time(ms): 800.44, token/sec:655002.03, hellaswag_acc: 0.2955
Step: 12768, loss: 3.079041, norm: 0.2712, time(ms): 792.21, token/sec:661802.64, hellaswag_acc: 0.2955
Step: 12769, loss: 3.104325, norm: 0.2797, time(ms): 785.62, token/sec:667351.89, hellaswag_acc: 0.2955
Step: 12770, loss: 3.081292, norm: 0.2552, time(ms): 791.05, token/sec:662775.23, hellaswag_acc: 0.2955
Step: 12771, loss: 3.070261, norm: 0.2625, time(ms): 789.44, token/sec:664127.14, hellaswag_acc: 0.2955
Step: 12772, loss: 3.044738, norm: 0.2632, time(ms): 792.21, token/sec:661805.83, hellaswag_acc: 0.2955
Step: 12773, loss: 3.066737, norm: 0.2814, time(ms): 789.57, token/sec:664016.84, hellaswag_acc: 0.2955
Step: 12774, loss: 3.070050, norm: 0.2810, time(ms): 788.96, token/sec:664534.55, hellaswag_acc: 0.2955
Step: 12775, loss: 3.083716, norm: 0.2924, time(ms): 792.68, token/sec:661408.91, hellaswag_acc: 0.2955
Step: 12776, loss: 3.082730, norm: 0.2645, time(ms): 804.49, token/sec:651705.34, hellaswag_acc: 0.2955
Step: 12777, loss: 3.086939, norm: 0.3197, time(ms): 800.58, token/sec:654886.16, hellaswag_acc: 0.2955
Step: 12778, loss: 3.135144, norm: 0.2967, time(ms): 789.05, token/sec:664452.43, hellaswag_acc: 0.2955
Step: 12779, loss: 3.098222, norm: 0.2965, time(ms): 790.56, token/sec:663185.38, hellaswag_acc: 0.2955
Step: 12780, loss: 3.138345, norm: 0.3039, time(ms): 794.95, token/sec:659525.01, hellaswag_acc: 0.2955
Step: 12781, loss: 3.140196, norm: 0.3219, time(ms): 791.21, token/sec:662638.22, hellaswag_acc: 0.2955
Step: 12782, loss: 3.092213, norm: 0.2949, time(ms): 790.37, token/sec:663341.22, hellaswag_acc: 0.2955
Step: 12783, loss: 3.174306, norm: 0.3013, time(ms): 800.30, token/sec:655115.99, hellaswag_acc: 0.2955
Step: 12784, loss: 3.172209, norm: 0.2875, time(ms): 797.73, token/sec:657224.51, hellaswag_acc: 0.2955
Step: 12785, loss: 3.082032, norm: 0.3131, time(ms): 803.27, token/sec:652689.33, hellaswag_acc: 0.2955
Step: 12786, loss: 3.126548, norm: 0.2945, time(ms): 795.37, token/sec:659177.46, hellaswag_acc: 0.2955
Step: 12787, loss: 3.129105, norm: 0.3073, time(ms): 802.08, token/sec:653663.27, hellaswag_acc: 0.2955
Step: 12788, loss: 3.057303, norm: 0.3084, time(ms): 799.67, token/sec:655626.94, hellaswag_acc: 0.2955
Step: 12789, loss: 3.098903, norm: 0.2980, time(ms): 802.14, token/sec:653611.01, hellaswag_acc: 0.2955
Step: 12790, loss: 3.100134, norm: 0.2892, time(ms): 800.05, token/sec:655320.20, hellaswag_acc: 0.2955
Step: 12791, loss: 3.123471, norm: 0.2737, time(ms): 798.24, token/sec:656807.17, hellaswag_acc: 0.2955
Step: 12792, loss: 3.053043, norm: 0.2757, time(ms): 799.64, token/sec:655652.75, hellaswag_acc: 0.2955
Step: 12793, loss: 3.130075, norm: 0.2839, time(ms): 801.14, token/sec:654426.99, hellaswag_acc: 0.2955
Step: 12794, loss: 3.049387, norm: 0.2779, time(ms): 797.17, token/sec:657683.09, hellaswag_acc: 0.2955
Step: 12795, loss: 3.136928, norm: 0.3298, time(ms): 800.14, token/sec:655247.56, hellaswag_acc: 0.2955
Step: 12796, loss: 3.096516, norm: 0.2721, time(ms): 800.79, token/sec:654716.34, hellaswag_acc: 0.2955
Step: 12797, loss: 3.108020, norm: 0.2966, time(ms): 793.74, token/sec:660527.42, hellaswag_acc: 0.2955
Step: 12798, loss: 3.092901, norm: 0.2715, time(ms): 792.42, token/sec:661624.83, hellaswag_acc: 0.2955
Step: 12799, loss: 3.057676, norm: 0.2763, time(ms): 786.52, token/sec:666589.65, hellaswag_acc: 0.2955
Step: 12800, loss: 3.071898, norm: 0.2823, time(ms): 792.37, token/sec:661674.20, hellaswag_acc: 0.2955
Step: 12801, loss: 3.005261, norm: 0.2713, time(ms): 790.22, token/sec:663473.92, hellaswag_acc: 0.2955
Step: 12802, loss: 3.023235, norm: 0.2792, time(ms): 790.89, token/sec:662909.69, hellaswag_acc: 0.2955
Step: 12803, loss: 3.018635, norm: 0.2802, time(ms): 792.96, token/sec:661180.02, hellaswag_acc: 0.2955
Step: 12804, loss: 3.070794, norm: 0.2916, time(ms): 801.56, token/sec:654083.43, hellaswag_acc: 0.2955
Step: 12805, loss: 3.057003, norm: 0.2780, time(ms): 800.59, token/sec:654875.63, hellaswag_acc: 0.2955
Step: 12806, loss: 3.033782, norm: 0.2778, time(ms): 795.31, token/sec:659220.74, hellaswag_acc: 0.2955
Step: 12807, loss: 3.060138, norm: 0.2906, time(ms): 803.73, token/sec:652321.26, hellaswag_acc: 0.2955
Step: 12808, loss: 2.995588, norm: 0.2585, time(ms): 801.40, token/sec:654217.31, hellaswag_acc: 0.2955
Step: 12809, loss: 3.088581, norm: 0.2687, time(ms): 794.90, token/sec:659562.40, hellaswag_acc: 0.2955
Step: 12810, loss: 3.097050, norm: 0.2614, time(ms): 803.23, token/sec:652725.94, hellaswag_acc: 0.2955
Step: 12811, loss: 3.068529, norm: 0.2885, time(ms): 799.45, token/sec:655813.87, hellaswag_acc: 0.2955
Step: 12812, loss: 3.103197, norm: 0.2848, time(ms): 797.70, token/sec:657247.10, hellaswag_acc: 0.2955
Step: 12813, loss: 3.169789, norm: 0.3069, time(ms): 801.72, token/sec:653952.72, hellaswag_acc: 0.2955
Step: 12814, loss: 3.169653, norm: 0.2811, time(ms): 799.59, token/sec:655694.00, hellaswag_acc: 0.2955
Step: 12815, loss: 3.125394, norm: 0.3308, time(ms): 799.79, token/sec:655534.89, hellaswag_acc: 0.2955
Step: 12816, loss: 3.103139, norm: 0.2868, time(ms): 801.64, token/sec:654020.01, hellaswag_acc: 0.2955
Step: 12817, loss: 3.121595, norm: 0.3177, time(ms): 796.38, token/sec:658340.53, hellaswag_acc: 0.2955
Step: 12818, loss: 3.157372, norm: 0.2899, time(ms): 799.14, token/sec:656063.72, hellaswag_acc: 0.2955
Step: 12819, loss: 3.100853, norm: 0.3016, time(ms): 804.18, token/sec:651955.36, hellaswag_acc: 0.2955
Step: 12820, loss: 3.084814, norm: 0.3018, time(ms): 798.66, token/sec:656459.34, hellaswag_acc: 0.2955
Step: 12821, loss: 3.120971, norm: 0.2923, time(ms): 792.72, token/sec:661379.08, hellaswag_acc: 0.2955
Step: 12822, loss: 3.137821, norm: 0.3039, time(ms): 808.46, token/sec:648500.18, hellaswag_acc: 0.2955
Step: 12823, loss: 3.137976, norm: 0.3380, time(ms): 800.40, token/sec:655029.93, hellaswag_acc: 0.2955
Step: 12824, loss: 3.173952, norm: 0.2784, time(ms): 785.86, token/sec:667153.48, hellaswag_acc: 0.2955
Step: 12825, loss: 3.111405, norm: 0.3130, time(ms): 789.65, token/sec:663948.68, hellaswag_acc: 0.2955
Step: 12826, loss: 3.096387, norm: 0.2741, time(ms): 795.04, token/sec:659451.44, hellaswag_acc: 0.2955
Step: 12827, loss: 3.066844, norm: 0.2784, time(ms): 792.10, token/sec:661899.85, hellaswag_acc: 0.2955
Step: 12828, loss: 3.153525, norm: 0.2948, time(ms): 788.71, token/sec:664742.07, hellaswag_acc: 0.2955
Step: 12829, loss: 3.101774, norm: 0.2841, time(ms): 798.91, token/sec:656256.58, hellaswag_acc: 0.2955
Step: 12830, loss: 3.100148, norm: 0.2731, time(ms): 806.47, token/sec:650099.10, hellaswag_acc: 0.2955
Step: 12831, loss: 3.136377, norm: 0.2925, time(ms): 800.97, token/sec:654565.11, hellaswag_acc: 0.2955
Step: 12832, loss: 3.132491, norm: 0.2675, time(ms): 787.05, token/sec:666143.19, hellaswag_acc: 0.2955
Step: 12833, loss: 3.134831, norm: 0.2912, time(ms): 791.29, token/sec:662572.34, hellaswag_acc: 0.2955
Step: 12834, loss: 3.058846, norm: 0.2663, time(ms): 799.25, token/sec:655972.33, hellaswag_acc: 0.2955
Step: 12835, loss: 3.117419, norm: 0.2735, time(ms): 798.14, token/sec:656889.77, hellaswag_acc: 0.2955
Step: 12836, loss: 3.033647, norm: 0.2714, time(ms): 792.60, token/sec:661476.76, hellaswag_acc: 0.2955
Step: 12837, loss: 3.138645, norm: 0.2823, time(ms): 788.73, token/sec:664728.20, hellaswag_acc: 0.2955
Step: 12838, loss: 3.017744, norm: 0.2774, time(ms): 791.98, token/sec:661997.29, hellaswag_acc: 0.2955
Step: 12839, loss: 3.094555, norm: 0.2717, time(ms): 790.23, token/sec:663464.91, hellaswag_acc: 0.2955
Step: 12840, loss: 3.108392, norm: 0.2866, time(ms): 798.03, token/sec:656980.05, hellaswag_acc: 0.2955
Step: 12841, loss: 3.118746, norm: 0.2829, time(ms): 793.76, token/sec:660509.17, hellaswag_acc: 0.2955
Step: 12842, loss: 3.069722, norm: 0.2712, time(ms): 805.85, token/sec:650600.91, hellaswag_acc: 0.2955
Step: 12843, loss: 3.080684, norm: 0.3069, time(ms): 801.62, token/sec:654032.07, hellaswag_acc: 0.2955
Step: 12844, loss: 3.116550, norm: 0.2796, time(ms): 790.65, token/sec:663107.59, hellaswag_acc: 0.2955
Step: 12845, loss: 3.088415, norm: 0.2832, time(ms): 808.01, token/sec:648862.22, hellaswag_acc: 0.2955
Step: 12846, loss: 3.106467, norm: 0.2712, time(ms): 798.27, token/sec:656784.22, hellaswag_acc: 0.2955
Step: 12847, loss: 3.099125, norm: 0.3005, time(ms): 801.97, token/sec:653749.55, hellaswag_acc: 0.2955
Step: 12848, loss: 3.191615, norm: 0.2797, time(ms): 794.69, token/sec:659742.47, hellaswag_acc: 0.2955
Step: 12849, loss: 3.177680, norm: 0.2926, time(ms): 802.21, token/sec:653552.15, hellaswag_acc: 0.2955
Step: 12850, loss: 3.125214, norm: 0.2910, time(ms): 801.26, token/sec:654325.93, hellaswag_acc: 0.2955
Step: 12851, loss: 3.115319, norm: 0.2808, time(ms): 797.11, token/sec:657737.38, hellaswag_acc: 0.2955
Step: 12852, loss: 3.168643, norm: 0.3063, time(ms): 803.11, token/sec:652820.89, hellaswag_acc: 0.2955
Step: 12853, loss: 3.118633, norm: 0.3090, time(ms): 799.06, token/sec:656127.34, hellaswag_acc: 0.2955
Step: 12854, loss: 3.165876, norm: 0.2779, time(ms): 799.70, token/sec:655605.83, hellaswag_acc: 0.2955
Step: 12855, loss: 3.097144, norm: 0.2599, time(ms): 797.98, token/sec:657020.88, hellaswag_acc: 0.2955
Step: 12856, loss: 3.144431, norm: 0.2836, time(ms): 802.38, token/sec:653412.33, hellaswag_acc: 0.2955
Step: 12857, loss: 3.145670, norm: 0.2973, time(ms): 800.34, token/sec:655084.96, hellaswag_acc: 0.2955
Step: 12858, loss: 3.091189, norm: 0.3019, time(ms): 800.92, token/sec:654607.78, hellaswag_acc: 0.2955
Step: 12859, loss: 3.123719, norm: 0.2869, time(ms): 787.65, token/sec:665635.66, hellaswag_acc: 0.2955
Step: 12860, loss: 3.115459, norm: 0.2811, time(ms): 789.64, token/sec:663957.10, hellaswag_acc: 0.2955
Step: 12861, loss: 3.112247, norm: 0.3048, time(ms): 792.79, token/sec:661320.80, hellaswag_acc: 0.2955
Step: 12862, loss: 3.131371, norm: 0.2760, time(ms): 792.60, token/sec:661480.94, hellaswag_acc: 0.2955
Step: 12863, loss: 3.110217, norm: 0.3732, time(ms): 789.86, token/sec:663771.31, hellaswag_acc: 0.2955
Step: 12864, loss: 3.104820, norm: 0.3451, time(ms): 799.98, token/sec:655372.34, hellaswag_acc: 0.2955
Step: 12865, loss: 3.130516, norm: 0.3024, time(ms): 806.67, token/sec:649942.88, hellaswag_acc: 0.2955
Step: 12866, loss: 3.226041, norm: 0.3463, time(ms): 792.41, token/sec:661639.16, hellaswag_acc: 0.2955
Step: 12867, loss: 3.126485, norm: 0.3269, time(ms): 798.71, token/sec:656421.13, hellaswag_acc: 0.2955
Step: 12868, loss: 3.135322, norm: 0.3036, time(ms): 803.00, token/sec:652908.11, hellaswag_acc: 0.2955
Step: 12869, loss: 3.115494, norm: 0.3322, time(ms): 803.05, token/sec:652869.73, hellaswag_acc: 0.2955
Step: 12870, loss: 3.064468, norm: 0.2913, time(ms): 792.42, token/sec:661627.62, hellaswag_acc: 0.2955
Step: 12871, loss: 3.150457, norm: 0.3170, time(ms): 798.51, token/sec:656580.08, hellaswag_acc: 0.2955
Step: 12872, loss: 3.116561, norm: 0.2925, time(ms): 792.77, token/sec:661334.72, hellaswag_acc: 0.2955
Step: 12873, loss: 3.077400, norm: 0.3019, time(ms): 788.86, token/sec:664614.89, hellaswag_acc: 0.2955
Step: 12874, loss: 3.086387, norm: 0.2780, time(ms): 792.33, token/sec:661702.87, hellaswag_acc: 0.2955
Step: 12875, loss: 3.105446, norm: 0.3018, time(ms): 788.69, token/sec:664756.94, hellaswag_acc: 0.2955
Step: 12876, loss: 3.056881, norm: 0.2916, time(ms): 795.56, token/sec:659014.09, hellaswag_acc: 0.2955
Step: 12877, loss: 3.069256, norm: 0.2839, time(ms): 792.34, token/sec:661694.51, hellaswag_acc: 0.2955
Step: 12878, loss: 3.028115, norm: 0.2657, time(ms): 788.72, token/sec:664732.82, hellaswag_acc: 0.2955
Step: 12879, loss: 3.082452, norm: 0.2743, time(ms): 794.09, token/sec:660239.86, hellaswag_acc: 0.2955
Step: 12880, loss: 3.019407, norm: 0.2733, time(ms): 790.51, token/sec:663225.99, hellaswag_acc: 0.2955
Step: 12881, loss: 3.132849, norm: 0.2794, time(ms): 791.37, token/sec:662503.67, hellaswag_acc: 0.2955
Step: 12882, loss: 3.090780, norm: 0.3054, time(ms): 791.29, token/sec:662577.13, hellaswag_acc: 0.2955
Step: 12883, loss: 3.110356, norm: 0.2612, time(ms): 796.40, token/sec:658319.83, hellaswag_acc: 0.2955
Step: 12884, loss: 3.167850, norm: 0.3383, time(ms): 805.42, token/sec:650946.02, hellaswag_acc: 0.2955
Step: 12885, loss: 3.194507, norm: 0.2643, time(ms): 799.81, token/sec:655517.69, hellaswag_acc: 0.2955
Step: 12886, loss: 3.120935, norm: 0.3232, time(ms): 790.64, token/sec:663120.39, hellaswag_acc: 0.2955
Step: 12887, loss: 3.175754, norm: 0.2894, time(ms): 805.24, token/sec:651098.67, hellaswag_acc: 0.2955
Step: 12888, loss: 3.090445, norm: 0.2938, time(ms): 802.23, token/sec:653538.16, hellaswag_acc: 0.2955
Step: 12889, loss: 3.158949, norm: 0.2742, time(ms): 794.06, token/sec:660263.05, hellaswag_acc: 0.2955
Step: 12890, loss: 3.100047, norm: 0.2919, time(ms): 800.29, token/sec:655125.94, hellaswag_acc: 0.2955
Step: 12891, loss: 3.139294, norm: 0.2828, time(ms): 803.04, token/sec:652880.78, hellaswag_acc: 0.2955
Step: 12892, loss: 3.133594, norm: 0.3295, time(ms): 798.88, token/sec:656277.14, hellaswag_acc: 0.2955
Step: 12893, loss: 3.102931, norm: 0.3032, time(ms): 799.15, token/sec:656060.98, hellaswag_acc: 0.2955
Step: 12894, loss: 3.118351, norm: 0.2983, time(ms): 802.93, token/sec:652967.05, hellaswag_acc: 0.2955
Step: 12895, loss: 3.154313, norm: 0.2987, time(ms): 798.35, token/sec:656713.22, hellaswag_acc: 0.2955
Step: 12896, loss: 3.192746, norm: 0.3036, time(ms): 795.77, token/sec:658842.31, hellaswag_acc: 0.2955
Step: 12897, loss: 3.139944, norm: 0.3253, time(ms): 804.63, token/sec:651586.19, hellaswag_acc: 0.2955
Step: 12898, loss: 3.128686, norm: 0.3001, time(ms): 799.70, token/sec:655607.40, hellaswag_acc: 0.2955
Step: 12899, loss: 3.135658, norm: 0.3368, time(ms): 796.33, token/sec:658380.14, hellaswag_acc: 0.2955
Step: 12900, loss: 3.093006, norm: 0.2933, time(ms): 800.68, token/sec:654801.73, hellaswag_acc: 0.2955
Step: 12901, loss: 3.109854, norm: 0.3214, time(ms): 802.22, token/sec:653545.55, hellaswag_acc: 0.2955
Step: 12902, loss: 3.057286, norm: 0.2894, time(ms): 797.45, token/sec:657452.83, hellaswag_acc: 0.2955
Step: 12903, loss: 3.095660, norm: 0.3184, time(ms): 798.25, token/sec:656793.83, hellaswag_acc: 0.2955
Step: 12904, loss: 3.093750, norm: 0.3065, time(ms): 798.57, token/sec:656536.37, hellaswag_acc: 0.2955
Step: 12905, loss: 3.116655, norm: 0.2992, time(ms): 803.94, token/sec:652146.38, hellaswag_acc: 0.2955
Step: 12906, loss: 3.052560, norm: 0.3052, time(ms): 794.98, token/sec:659497.32, hellaswag_acc: 0.2955
Step: 12907, loss: 3.055889, norm: 0.2925, time(ms): 793.66, token/sec:660598.26, hellaswag_acc: 0.2955
Step: 12908, loss: 2.997272, norm: 0.2920, time(ms): 794.78, token/sec:659664.10, hellaswag_acc: 0.2955
Step: 12909, loss: 3.047671, norm: 0.2830, time(ms): 796.45, token/sec:658278.64, hellaswag_acc: 0.2955
Step: 12910, loss: 3.048486, norm: 0.2668, time(ms): 799.28, token/sec:655950.02, hellaswag_acc: 0.2955
Step: 12911, loss: 3.098598, norm: 0.2844, time(ms): 801.11, token/sec:654448.81, hellaswag_acc: 0.2955
Step: 12912, loss: 3.098467, norm: 0.2713, time(ms): 799.87, token/sec:655468.46, hellaswag_acc: 0.2955
Step: 12913, loss: 3.075292, norm: 0.2854, time(ms): 792.66, token/sec:661429.40, hellaswag_acc: 0.2955
Step: 12914, loss: 3.058469, norm: 0.2665, time(ms): 789.69, token/sec:663919.01, hellaswag_acc: 0.2955
Step: 12915, loss: 3.121230, norm: 0.2737, time(ms): 788.99, token/sec:664501.22, hellaswag_acc: 0.2955
Step: 12916, loss: 3.150681, norm: 0.3154, time(ms): 788.87, token/sec:664606.66, hellaswag_acc: 0.2955
Step: 12917, loss: 3.111283, norm: 0.2679, time(ms): 799.23, token/sec:655988.57, hellaswag_acc: 0.2955
Step: 12918, loss: 3.127774, norm: 0.3115, time(ms): 796.54, token/sec:658208.30, hellaswag_acc: 0.2955
Step: 12919, loss: 3.083743, norm: 0.2764, time(ms): 807.13, token/sec:649568.32, hellaswag_acc: 0.2955
Step: 12920, loss: 3.101850, norm: 0.2823, time(ms): 797.19, token/sec:657673.25, hellaswag_acc: 0.2955
Step: 12921, loss: 3.004712, norm: 0.2760, time(ms): 791.72, token/sec:662210.60, hellaswag_acc: 0.2955
Step: 12922, loss: 3.133936, norm: 0.2847, time(ms): 803.62, token/sec:652410.87, hellaswag_acc: 0.2955
Step: 12923, loss: 3.111100, norm: 0.2662, time(ms): 806.02, token/sec:650465.42, hellaswag_acc: 0.2955
Step: 12924, loss: 3.098225, norm: 0.2799, time(ms): 789.68, token/sec:663922.02, hellaswag_acc: 0.2955
Step: 12925, loss: 3.078937, norm: 0.2670, time(ms): 795.43, token/sec:659125.10, hellaswag_acc: 0.2955
Step: 12926, loss: 3.100748, norm: 0.2578, time(ms): 790.19, token/sec:663494.74, hellaswag_acc: 0.2955
Step: 12927, loss: 3.121217, norm: 0.2583, time(ms): 794.99, token/sec:659487.43, hellaswag_acc: 0.2955
Step: 12928, loss: 3.133977, norm: 0.2649, time(ms): 791.46, token/sec:662429.03, hellaswag_acc: 0.2955
Step: 12929, loss: 3.121956, norm: 0.2643, time(ms): 793.52, token/sec:660714.37, hellaswag_acc: 0.2955
Step: 12930, loss: 3.156577, norm: 0.2617, time(ms): 795.74, token/sec:658870.54, hellaswag_acc: 0.2955
Step: 12931, loss: 3.145923, norm: 0.2691, time(ms): 805.27, token/sec:651074.19, hellaswag_acc: 0.2955
Step: 12932, loss: 3.130824, norm: 0.2789, time(ms): 790.03, token/sec:663631.49, hellaswag_acc: 0.2955
Step: 12933, loss: 3.117191, norm: 0.2617, time(ms): 793.98, token/sec:660326.89, hellaswag_acc: 0.2955
Step: 12934, loss: 3.141052, norm: 0.2679, time(ms): 790.98, token/sec:662829.97, hellaswag_acc: 0.2955
Step: 12935, loss: 3.083457, norm: 0.2778, time(ms): 802.14, token/sec:653612.95, hellaswag_acc: 0.2955
Step: 12936, loss: 3.078475, norm: 0.2792, time(ms): 802.22, token/sec:653545.35, hellaswag_acc: 0.2955
Step: 12937, loss: 3.097396, norm: 0.2622, time(ms): 794.65, token/sec:659775.13, hellaswag_acc: 0.2955
Step: 12938, loss: 3.061448, norm: 0.2898, time(ms): 800.70, token/sec:654788.47, hellaswag_acc: 0.2955
Step: 12939, loss: 3.109379, norm: 0.2866, time(ms): 801.80, token/sec:653892.05, hellaswag_acc: 0.2955
Step: 12940, loss: 3.067476, norm: 0.3393, time(ms): 803.98, token/sec:652118.15, hellaswag_acc: 0.2955
Step: 12941, loss: 3.057046, norm: 0.2549, time(ms): 794.23, token/sec:660120.54, hellaswag_acc: 0.2955
Step: 12942, loss: 3.059370, norm: 0.3402, time(ms): 799.87, token/sec:655467.67, hellaswag_acc: 0.2955
Step: 12943, loss: 3.102624, norm: 0.2907, time(ms): 799.80, token/sec:655526.49, hellaswag_acc: 0.2955
Step: 12944, loss: 3.094649, norm: 0.3527, time(ms): 795.17, token/sec:659344.27, hellaswag_acc: 0.2955
Step: 12945, loss: 3.054023, norm: 0.3168, time(ms): 790.58, token/sec:663170.78, hellaswag_acc: 0.2955
Step: 12946, loss: 3.077912, norm: 0.3311, time(ms): 787.89, token/sec:665435.85, hellaswag_acc: 0.2955
Step: 12947, loss: 3.084997, norm: 0.3346, time(ms): 791.46, token/sec:662430.23, hellaswag_acc: 0.2955
Step: 12948, loss: 3.115097, norm: 0.2917, time(ms): 796.98, token/sec:657847.37, hellaswag_acc: 0.2955
Step: 12949, loss: 3.110785, norm: 0.2939, time(ms): 801.66, token/sec:654003.67, hellaswag_acc: 0.2955
Step: 12950, loss: 3.109218, norm: 0.2940, time(ms): 798.94, token/sec:656227.00, hellaswag_acc: 0.2955
Step: 12951, loss: 3.173227, norm: 0.3315, time(ms): 799.69, token/sec:655613.65, hellaswag_acc: 0.2955
Step: 12952, loss: 3.147431, norm: 0.3132, time(ms): 799.16, token/sec:656051.39, hellaswag_acc: 0.2955
Step: 12953, loss: 3.147089, norm: 0.3138, time(ms): 1362.59, token/sec:384773.97, hellaswag_acc: 0.2955
Step: 12954, loss: 3.018618, norm: 0.3197, time(ms): 767.93, token/sec:682726.96, hellaswag_acc: 0.2955
Step: 12955, loss: 2.974859, norm: 0.2964, time(ms): 789.74, token/sec:663874.92, hellaswag_acc: 0.2955
Step: 12956, loss: 3.031502, norm: 0.3230, time(ms): 800.96, token/sec:654574.07, hellaswag_acc: 0.2955
Step: 12957, loss: 2.980995, norm: 0.2840, time(ms): 787.64, token/sec:665644.12, hellaswag_acc: 0.2955
Step: 12958, loss: 3.097383, norm: 0.3178, time(ms): 781.82, token/sec:670599.32, hellaswag_acc: 0.2955
Step: 12959, loss: 3.075575, norm: 0.2806, time(ms): 786.65, token/sec:666478.94, hellaswag_acc: 0.2955
Step: 12960, loss: 3.200497, norm: 0.3189, time(ms): 794.12, token/sec:660213.10, hellaswag_acc: 0.2955
Step: 12961, loss: 3.243870, norm: 0.2940, time(ms): 792.06, token/sec:661929.14, hellaswag_acc: 0.2955
Step: 12962, loss: 3.108716, norm: 0.3045, time(ms): 786.87, token/sec:666291.74, hellaswag_acc: 0.2955
Step: 12963, loss: 3.187651, norm: 0.3003, time(ms): 790.57, token/sec:663173.58, hellaswag_acc: 0.2955
Step: 12964, loss: 3.140304, norm: 0.3039, time(ms): 798.49, token/sec:656596.16, hellaswag_acc: 0.2955
Step: 12965, loss: 3.152283, norm: 0.2688, time(ms): 794.95, token/sec:659519.87, hellaswag_acc: 0.2955
Step: 12966, loss: 3.147969, norm: 0.3040, time(ms): 796.76, token/sec:658025.52, hellaswag_acc: 0.2955
Step: 12967, loss: 3.092008, norm: 0.2662, time(ms): 789.55, token/sec:664034.29, hellaswag_acc: 0.2955
Step: 12968, loss: 3.220018, norm: 0.2944, time(ms): 785.76, token/sec:667235.66, hellaswag_acc: 0.2955
Step: 12969, loss: 3.126507, norm: 0.2908, time(ms): 791.26, token/sec:662595.10, hellaswag_acc: 0.2955
Step: 12970, loss: 3.154556, norm: 0.3014, time(ms): 794.57, token/sec:659837.29, hellaswag_acc: 0.2955
Step: 12971, loss: 3.127506, norm: 0.2740, time(ms): 807.70, token/sec:649113.13, hellaswag_acc: 0.2955
Step: 12972, loss: 3.131189, norm: 0.2969, time(ms): 796.29, token/sec:658410.89, hellaswag_acc: 0.2955
Step: 12973, loss: 3.192420, norm: 0.3009, time(ms): 799.38, token/sec:655868.05, hellaswag_acc: 0.2955
Step: 12974, loss: 3.091197, norm: 0.2929, time(ms): 800.87, token/sec:654651.82, hellaswag_acc: 0.2955
Step: 12975, loss: 3.124676, norm: 0.2873, time(ms): 800.52, token/sec:654934.73, hellaswag_acc: 0.2955
Step: 12976, loss: 3.164928, norm: 0.2951, time(ms): 795.36, token/sec:659182.99, hellaswag_acc: 0.2955
Step: 12977, loss: 3.094920, norm: 0.2887, time(ms): 799.29, token/sec:655940.24, hellaswag_acc: 0.2955
Step: 12978, loss: 3.141042, norm: 0.3109, time(ms): 803.24, token/sec:652719.16, hellaswag_acc: 0.2955
Step: 12979, loss: 3.127841, norm: 0.2708, time(ms): 804.13, token/sec:651990.54, hellaswag_acc: 0.2955
Step: 12980, loss: 3.088477, norm: 0.2739, time(ms): 789.47, token/sec:664099.26, hellaswag_acc: 0.2955
Step: 12981, loss: 3.142182, norm: 0.2617, time(ms): 792.88, token/sec:661241.65, hellaswag_acc: 0.2955
Step: 12982, loss: 3.106644, norm: 0.2715, time(ms): 790.52, token/sec:663217.79, hellaswag_acc: 0.2955
Step: 12983, loss: 3.138658, norm: 0.2685, time(ms): 789.92, token/sec:663719.63, hellaswag_acc: 0.2955
Step: 12984, loss: 3.102610, norm: 0.2512, time(ms): 791.69, token/sec:662243.10, hellaswag_acc: 0.2955
Step: 12985, loss: 3.109561, norm: 0.2628, time(ms): 799.48, token/sec:655782.77, hellaswag_acc: 0.2955
Step: 12986, loss: 3.053297, norm: 0.2695, time(ms): 802.86, token/sec:653026.39, hellaswag_acc: 0.2955
Step: 12987, loss: 3.130608, norm: 0.2658, time(ms): 800.11, token/sec:655269.62, hellaswag_acc: 0.2955
Step: 12988, loss: 3.086147, norm: 0.2680, time(ms): 792.62, token/sec:661464.02, hellaswag_acc: 0.2955
Step: 12989, loss: 3.112990, norm: 0.2912, time(ms): 798.43, token/sec:656647.92, hellaswag_acc: 0.2955
Step: 12990, loss: 3.112450, norm: 0.2680, time(ms): 793.00, token/sec:661141.06, hellaswag_acc: 0.2955
Step: 12991, loss: 3.137825, norm: 0.2677, time(ms): 790.05, token/sec:663613.87, hellaswag_acc: 0.2955
Step: 12992, loss: 3.122385, norm: 0.2686, time(ms): 790.82, token/sec:662968.25, hellaswag_acc: 0.2955
Step: 12993, loss: 3.100050, norm: 0.2692, time(ms): 791.84, token/sec:662115.29, hellaswag_acc: 0.2955
Step: 12994, loss: 2.969671, norm: 0.2598, time(ms): 793.37, token/sec:660835.29, hellaswag_acc: 0.2955
Step: 12995, loss: 3.013573, norm: 0.2819, time(ms): 791.09, token/sec:662744.47, hellaswag_acc: 0.2955
Step: 12996, loss: 3.028155, norm: 0.2617, time(ms): 788.63, token/sec:664810.80, hellaswag_acc: 0.2955
Step: 12997, loss: 3.019145, norm: 0.2813, time(ms): 802.66, token/sec:653188.55, hellaswag_acc: 0.2955
Step: 12998, loss: 2.983024, norm: 0.2804, time(ms): 805.06, token/sec:651240.97, hellaswag_acc: 0.2955
Step: 12999, loss: 3.017323, norm: 0.2639, time(ms): 802.33, token/sec:653457.18, hellaswag_acc: 0.2955
rank 0 sample 0: Hello, I'm a language model, and I'll be talking about my background before I get to the technical term:
In languages as we'll see later
rank 0 sample 1: Hello, I'm a language model, so, because I have a computer type, it wouldn't have much problems if it was running a programming language. But
rank 0 sample 2: Hello, I'm a language model, so I had the impression that I did not, but I had some good experience with it. I wasn't able to
rank 0 sample 3: Hello, I'm a language model, so for me, I'm not only trying to understand the language but also to describe a set of skills and abilities by
rank 1 sample 0: Hello, I'm a language model, this is the way I use it within a real language.<|endoftext|>The world is changing, and this is why we need
rank 1 sample 1: Hello, I'm a language model, not an interpreter. I'm not sure exactly what is "proper" - one which stands for the language model.
rank 1 sample 2: Hello, I'm a language model, I try to model the language model in a language model that it can use. I'm just using my language model,
rank 1 sample 3: Hello, I'm a language model, and I'm an interpreter because I was my interpreter. Since I wanted to look at any number of languages, I was
Step: 13000, loss: 3.013009, norm: 0.2790, time(ms): 363733.53, token/sec:1441.41, val_loss: 3.1327, hellaswag_acc: 0.2966
Step: 13001, loss: 3.023736, norm: 0.2646, time(ms): 801.68, token/sec:653988.89, hellaswag_acc: 0.2966
Step: 13002, loss: 3.009838, norm: 0.2845, time(ms): 807.60, token/sec:649189.78, hellaswag_acc: 0.2966
Step: 13003, loss: 3.045548, norm: 0.2645, time(ms): 800.08, token/sec:655295.40, hellaswag_acc: 0.2966
Step: 13004, loss: 3.016120, norm: 0.2781, time(ms): 792.43, token/sec:661621.05, hellaswag_acc: 0.2966
Step: 13005, loss: 3.152347, norm: 0.2922, time(ms): 803.44, token/sec:652557.23, hellaswag_acc: 0.2966
Step: 13006, loss: 3.145787, norm: 0.3019, time(ms): 803.57, token/sec:652447.84, hellaswag_acc: 0.2966
Step: 13007, loss: 3.112345, norm: 0.2787, time(ms): 791.18, token/sec:662663.18, hellaswag_acc: 0.2966
Step: 13008, loss: 3.094343, norm: 0.2689, time(ms): 804.32, token/sec:651840.37, hellaswag_acc: 0.2966
Step: 13009, loss: 3.106256, norm: 0.3060, time(ms): 798.95, token/sec:656222.11, hellaswag_acc: 0.2966
Step: 13010, loss: 3.131713, norm: 0.2815, time(ms): 801.77, token/sec:653911.10, hellaswag_acc: 0.2966
Step: 13011, loss: 3.102277, norm: 0.2995, time(ms): 800.26, token/sec:655143.51, hellaswag_acc: 0.2966
Step: 13012, loss: 3.124181, norm: 0.2731, time(ms): 799.35, token/sec:655894.65, hellaswag_acc: 0.2966
Step: 13013, loss: 3.123299, norm: 0.2918, time(ms): 801.66, token/sec:654006.20, hellaswag_acc: 0.2966
Step: 13014, loss: 3.167351, norm: 0.3154, time(ms): 798.41, token/sec:656668.70, hellaswag_acc: 0.2966
Step: 13015, loss: 3.124060, norm: 0.3130, time(ms): 798.41, token/sec:656669.09, hellaswag_acc: 0.2966
Step: 13016, loss: 3.159833, norm: 0.3346, time(ms): 800.57, token/sec:654892.21, hellaswag_acc: 0.2966
Step: 13017, loss: 3.130157, norm: 0.3106, time(ms): 803.14, token/sec:652799.57, hellaswag_acc: 0.2966
Step: 13018, loss: 3.167012, norm: 0.2847, time(ms): 798.80, token/sec:656348.05, hellaswag_acc: 0.2966
Step: 13019, loss: 3.089886, norm: 0.2865, time(ms): 798.27, token/sec:656777.94, hellaswag_acc: 0.2966
Step: 13020, loss: 3.135748, norm: 0.2870, time(ms): 795.20, token/sec:659314.22, hellaswag_acc: 0.2966
Step: 13021, loss: 3.172867, norm: 0.2766, time(ms): 806.55, token/sec:650036.83, hellaswag_acc: 0.2966
Step: 13022, loss: 3.143296, norm: 0.2770, time(ms): 799.51, token/sec:655759.89, hellaswag_acc: 0.2966
Step: 13023, loss: 3.130672, norm: 0.2726, time(ms): 793.63, token/sec:660622.07, hellaswag_acc: 0.2966
Step: 13024, loss: 3.136062, norm: 0.2739, time(ms): 803.61, token/sec:652414.55, hellaswag_acc: 0.2966
Step: 13025, loss: 3.129568, norm: 0.2788, time(ms): 800.52, token/sec:654930.83, hellaswag_acc: 0.2966
Step: 13026, loss: 3.120760, norm: 0.2980, time(ms): 793.97, token/sec:660341.17, hellaswag_acc: 0.2966
Step: 13027, loss: 3.104939, norm: 0.2669, time(ms): 797.57, token/sec:657357.91, hellaswag_acc: 0.2966
Step: 13028, loss: 3.115997, norm: 0.2720, time(ms): 789.57, token/sec:664015.44, hellaswag_acc: 0.2966
Step: 13029, loss: 3.098391, norm: 0.2677, time(ms): 796.29, token/sec:658413.65, hellaswag_acc: 0.2966
Step: 13030, loss: 3.061957, norm: 0.2525, time(ms): 791.97, token/sec:662004.46, hellaswag_acc: 0.2966
Step: 13031, loss: 3.049973, norm: 0.2837, time(ms): 791.32, token/sec:662546.59, hellaswag_acc: 0.2966
Step: 13032, loss: 3.120663, norm: 0.2756, time(ms): 800.92, token/sec:654605.83, hellaswag_acc: 0.2966
Step: 13033, loss: 3.101259, norm: 0.2853, time(ms): 792.95, token/sec:661185.98, hellaswag_acc: 0.2966
Step: 13034, loss: 3.131537, norm: 0.2697, time(ms): 806.10, token/sec:650396.93, hellaswag_acc: 0.2966
Step: 13035, loss: 3.107431, norm: 0.2798, time(ms): 799.80, token/sec:655522.58, hellaswag_acc: 0.2966
Step: 13036, loss: 3.033885, norm: 0.2744, time(ms): 791.28, token/sec:662583.32, hellaswag_acc: 0.2966
Step: 13037, loss: 3.097310, norm: 0.3078, time(ms): 807.44, token/sec:649325.11, hellaswag_acc: 0.2966
Step: 13038, loss: 3.037435, norm: 0.2523, time(ms): 801.06, token/sec:654492.05, hellaswag_acc: 0.2966
Step: 13039, loss: 3.058292, norm: 0.3192, time(ms): 798.54, token/sec:656561.06, hellaswag_acc: 0.2966
Step: 13040, loss: 3.041071, norm: 0.2591, time(ms): 794.95, token/sec:659523.83, hellaswag_acc: 0.2966
Step: 13041, loss: 2.996697, norm: 0.3176, time(ms): 805.77, token/sec:650667.32, hellaswag_acc: 0.2966
Step: 13042, loss: 2.986438, norm: 0.2737, time(ms): 800.17, token/sec:655218.47, hellaswag_acc: 0.2966
Step: 13043, loss: 3.085723, norm: 0.3084, time(ms): 789.23, token/sec:664301.28, hellaswag_acc: 0.2966
Step: 13044, loss: 3.003110, norm: 0.2721, time(ms): 802.91, token/sec:652982.37, hellaswag_acc: 0.2966
Step: 13045, loss: 2.979987, norm: 0.3105, time(ms): 808.17, token/sec:648736.65, hellaswag_acc: 0.2966
Step: 13046, loss: 3.067545, norm: 0.2908, time(ms): 799.47, token/sec:655797.83, hellaswag_acc: 0.2966
Step: 13047, loss: 3.027592, norm: 0.2999, time(ms): 787.30, token/sec:665934.19, hellaswag_acc: 0.2966
Step: 13048, loss: 3.049387, norm: 0.2821, time(ms): 789.63, token/sec:663963.71, hellaswag_acc: 0.2966
Step: 13049, loss: 2.981542, norm: 0.2900, time(ms): 793.07, token/sec:661086.20, hellaswag_acc: 0.2966
Step: 13050, loss: 2.971201, norm: 0.2699, time(ms): 793.01, token/sec:661138.47, hellaswag_acc: 0.2966
Step: 13051, loss: 3.128518, norm: 0.3155, time(ms): 787.84, token/sec:665474.11, hellaswag_acc: 0.2966
Step: 13052, loss: 3.098996, norm: 0.2795, time(ms): 802.06, token/sec:653677.65, hellaswag_acc: 0.2966
Step: 13053, loss: 3.169731, norm: 0.2916, time(ms): 805.29, token/sec:651050.86, hellaswag_acc: 0.2966
Step: 13054, loss: 3.061009, norm: 0.3024, time(ms): 800.19, token/sec:655202.07, hellaswag_acc: 0.2966
Step: 13055, loss: 3.150052, norm: 0.2914, time(ms): 791.25, token/sec:662606.08, hellaswag_acc: 0.2966
Step: 13056, loss: 3.152483, norm: 0.3247, time(ms): 798.28, token/sec:656770.88, hellaswag_acc: 0.2966
Step: 13057, loss: 3.154917, norm: 0.2851, time(ms): 792.96, token/sec:661182.21, hellaswag_acc: 0.2966
Step: 13058, loss: 3.143075, norm: 0.3376, time(ms): 789.45, token/sec:664116.51, hellaswag_acc: 0.2966
Step: 13059, loss: 3.135056, norm: 0.2867, time(ms): 791.41, token/sec:662472.73, hellaswag_acc: 0.2966
Step: 13060, loss: 3.142210, norm: 0.3072, time(ms): 787.67, token/sec:665616.52, hellaswag_acc: 0.2966
Step: 13061, loss: 3.117993, norm: 0.2882, time(ms): 793.21, token/sec:660971.94, hellaswag_acc: 0.2966
Step: 13062, loss: 3.095512, norm: 0.3021, time(ms): 794.35, token/sec:660020.68, hellaswag_acc: 0.2966
Step: 13063, loss: 3.150338, norm: 0.2762, time(ms): 787.67, token/sec:665615.92, hellaswag_acc: 0.2966
Step: 13064, loss: 3.198515, norm: 0.2896, time(ms): 790.49, token/sec:663247.39, hellaswag_acc: 0.2966
Step: 13065, loss: 3.109244, norm: 0.3002, time(ms): 791.38, token/sec:662496.68, hellaswag_acc: 0.2966
Step: 13066, loss: 3.185884, norm: 0.2892, time(ms): 793.13, token/sec:661040.49, hellaswag_acc: 0.2966
Step: 13067, loss: 3.129244, norm: 0.2909, time(ms): 794.15, token/sec:660187.53, hellaswag_acc: 0.2966
Step: 13068, loss: 3.132816, norm: 0.3085, time(ms): 797.86, token/sec:657121.60, hellaswag_acc: 0.2966
Step: 13069, loss: 3.161049, norm: 0.2640, time(ms): 800.45, token/sec:654990.13, hellaswag_acc: 0.2966
Step: 13070, loss: 3.146222, norm: 0.2852, time(ms): 804.27, token/sec:651883.46, hellaswag_acc: 0.2966
Step: 13071, loss: 3.170915, norm: 0.2745, time(ms): 789.72, token/sec:663894.16, hellaswag_acc: 0.2966
Step: 13072, loss: 3.238750, norm: 0.2771, time(ms): 800.29, token/sec:655123.02, hellaswag_acc: 0.2966
Step: 13073, loss: 3.177092, norm: 0.2983, time(ms): 804.94, token/sec:651341.67, hellaswag_acc: 0.2966
Step: 13074, loss: 3.102909, norm: 0.2759, time(ms): 803.72, token/sec:652329.39, hellaswag_acc: 0.2966
Step: 13075, loss: 3.106354, norm: 0.2792, time(ms): 789.84, token/sec:663787.54, hellaswag_acc: 0.2966
Step: 13076, loss: 3.079759, norm: 0.2583, time(ms): 792.31, token/sec:661718.40, hellaswag_acc: 0.2966
Step: 13077, loss: 3.077050, norm: 0.2619, time(ms): 793.62, token/sec:660628.02, hellaswag_acc: 0.2966
Step: 13078, loss: 3.095527, norm: 0.2691, time(ms): 801.19, token/sec:654389.80, hellaswag_acc: 0.2966
Step: 13079, loss: 3.128851, norm: 0.2606, time(ms): 797.70, token/sec:657252.40, hellaswag_acc: 0.2966
Step: 13080, loss: 3.119054, norm: 0.2899, time(ms): 797.18, token/sec:657681.51, hellaswag_acc: 0.2966
Step: 13081, loss: 3.096542, norm: 0.2806, time(ms): 796.88, token/sec:657924.33, hellaswag_acc: 0.2966
Step: 13082, loss: 3.161402, norm: 0.2850, time(ms): 791.20, token/sec:662646.41, hellaswag_acc: 0.2966
Step: 13083, loss: 3.086195, norm: 0.3013, time(ms): 788.47, token/sec:664945.89, hellaswag_acc: 0.2966
Step: 13084, loss: 3.137299, norm: 0.2585, time(ms): 792.57, token/sec:661506.21, hellaswag_acc: 0.2966
Step: 13085, loss: 3.046051, norm: 0.2924, time(ms): 797.18, token/sec:657675.22, hellaswag_acc: 0.2966
Step: 13086, loss: 3.021121, norm: 0.2474, time(ms): 796.62, token/sec:658142.70, hellaswag_acc: 0.2966
Step: 13087, loss: 2.977472, norm: 0.2780, time(ms): 800.44, token/sec:655002.23, hellaswag_acc: 0.2966
Step: 13088, loss: 3.035025, norm: 0.2587, time(ms): 802.84, token/sec:653045.00, hellaswag_acc: 0.2966
Step: 13089, loss: 2.973196, norm: 0.3057, time(ms): 796.68, token/sec:658086.96, hellaswag_acc: 0.2966
Step: 13090, loss: 3.016566, norm: 0.2915, time(ms): 801.13, token/sec:654435.37, hellaswag_acc: 0.2966
Step: 13091, loss: 2.975697, norm: 0.2943, time(ms): 794.92, token/sec:659549.74, hellaswag_acc: 0.2966
Step: 13092, loss: 3.121311, norm: 0.3097, time(ms): 805.67, token/sec:650745.50, hellaswag_acc: 0.2966
Step: 13093, loss: 2.960776, norm: 0.3033, time(ms): 800.29, token/sec:655120.87, hellaswag_acc: 0.2966
Step: 13094, loss: 2.980897, norm: 0.2931, time(ms): 784.57, token/sec:668249.48, hellaswag_acc: 0.2966
Step: 13095, loss: 3.011479, norm: 0.2972, time(ms): 788.51, token/sec:664908.29, hellaswag_acc: 0.2966
Step: 13096, loss: 3.042547, norm: 0.2739, time(ms): 792.49, token/sec:661571.28, hellaswag_acc: 0.2966
Step: 13097, loss: 3.093204, norm: 0.3269, time(ms): 792.47, token/sec:661583.03, hellaswag_acc: 0.2966
Step: 13098, loss: 3.123429, norm: 0.2957, time(ms): 792.00, token/sec:661983.14, hellaswag_acc: 0.2966
Step: 13099, loss: 3.107086, norm: 0.3053, time(ms): 795.21, token/sec:659311.06, hellaswag_acc: 0.2966
Step: 13100, loss: 3.109253, norm: 0.3104, time(ms): 794.41, token/sec:659971.16, hellaswag_acc: 0.2966
Step: 13101, loss: 3.125684, norm: 0.2782, time(ms): 792.93, token/sec:661203.68, hellaswag_acc: 0.2966
Step: 13102, loss: 3.146065, norm: 0.3168, time(ms): 801.52, token/sec:654119.42, hellaswag_acc: 0.2966
Step: 13103, loss: 3.137952, norm: 0.2861, time(ms): 801.17, token/sec:654406.93, hellaswag_acc: 0.2966
Step: 13104, loss: 3.134184, norm: 0.2996, time(ms): 798.09, token/sec:656931.96, hellaswag_acc: 0.2966
Step: 13105, loss: 3.159018, norm: 0.3200, time(ms): 800.25, token/sec:655152.10, hellaswag_acc: 0.2966
Step: 13106, loss: 3.124690, norm: 0.3143, time(ms): 798.24, token/sec:656801.88, hellaswag_acc: 0.2966
Step: 13107, loss: 3.161333, norm: 0.3466, time(ms): 799.36, token/sec:655883.50, hellaswag_acc: 0.2966
Step: 13108, loss: 3.145948, norm: 0.3041, time(ms): 791.52, token/sec:662378.15, hellaswag_acc: 0.2966
Step: 13109, loss: 3.175547, norm: 0.3094, time(ms): 785.31, token/sec:667621.36, hellaswag_acc: 0.2966
Step: 13110, loss: 3.174540, norm: 0.3136, time(ms): 790.10, token/sec:663567.81, hellaswag_acc: 0.2966
Step: 13111, loss: 3.135750, norm: 0.3245, time(ms): 793.54, token/sec:660696.90, hellaswag_acc: 0.2966
Step: 13112, loss: 3.127344, norm: 0.2941, time(ms): 799.80, token/sec:655521.80, hellaswag_acc: 0.2966
Step: 13113, loss: 3.228348, norm: 0.3323, time(ms): 805.10, token/sec:651210.89, hellaswag_acc: 0.2966
Step: 13114, loss: 3.140296, norm: 0.3200, time(ms): 800.50, token/sec:654951.31, hellaswag_acc: 0.2966
Step: 13115, loss: 3.165717, norm: 0.3239, time(ms): 792.34, token/sec:661696.50, hellaswag_acc: 0.2966
Step: 13116, loss: 3.151557, norm: 0.3156, time(ms): 804.61, token/sec:651601.64, hellaswag_acc: 0.2966
Step: 13117, loss: 3.117415, norm: 0.3396, time(ms): 802.56, token/sec:653269.46, hellaswag_acc: 0.2966
Step: 13118, loss: 3.137360, norm: 0.3149, time(ms): 793.46, token/sec:660763.01, hellaswag_acc: 0.2966
Step: 13119, loss: 3.115081, norm: 0.2954, time(ms): 796.47, token/sec:658263.27, hellaswag_acc: 0.2966
Step: 13120, loss: 3.204166, norm: 0.3447, time(ms): 807.58, token/sec:649207.03, hellaswag_acc: 0.2966
Step: 13121, loss: 3.066531, norm: 0.4428, time(ms): 802.62, token/sec:653222.31, hellaswag_acc: 0.2966
Step: 13122, loss: 3.140764, norm: 0.3826, time(ms): 783.95, token/sec:668778.69, hellaswag_acc: 0.2966
Step: 13123, loss: 3.173512, norm: 0.3782, time(ms): 787.69, token/sec:665604.63, hellaswag_acc: 0.2966
Step: 13124, loss: 3.124120, norm: 0.3779, time(ms): 791.10, token/sec:662735.88, hellaswag_acc: 0.2966
Step: 13125, loss: 3.102593, norm: 0.3266, time(ms): 794.66, token/sec:659765.83, hellaswag_acc: 0.2966
Step: 13126, loss: 3.048433, norm: 0.3172, time(ms): 792.68, token/sec:661415.08, hellaswag_acc: 0.2966
Step: 13127, loss: 3.086446, norm: 0.3192, time(ms): 804.20, token/sec:651938.54, hellaswag_acc: 0.2966
Step: 13128, loss: 3.063763, norm: 0.3318, time(ms): 802.40, token/sec:653402.04, hellaswag_acc: 0.2966
Step: 13129, loss: 3.241545, norm: 0.3329, time(ms): 792.67, token/sec:661422.84, hellaswag_acc: 0.2966
Step: 13130, loss: 3.110116, norm: 0.3224, time(ms): 803.68, token/sec:652359.39, hellaswag_acc: 0.2966
Step: 13131, loss: 3.068887, norm: 0.2953, time(ms): 800.10, token/sec:655281.92, hellaswag_acc: 0.2966
Step: 13132, loss: 3.113595, norm: 0.2890, time(ms): 801.07, token/sec:654486.01, hellaswag_acc: 0.2966
Step: 13133, loss: 3.033932, norm: 0.3018, time(ms): 799.22, token/sec:656000.51, hellaswag_acc: 0.2966
Step: 13134, loss: 3.021473, norm: 0.2864, time(ms): 801.39, token/sec:654221.40, hellaswag_acc: 0.2966
Step: 13135, loss: 3.197205, norm: 0.3286, time(ms): 798.46, token/sec:656624.98, hellaswag_acc: 0.2966
Step: 13136, loss: 3.022838, norm: 0.2725, time(ms): 801.71, token/sec:653962.63, hellaswag_acc: 0.2966
Step: 13137, loss: 2.961086, norm: 0.3023, time(ms): 797.81, token/sec:657155.18, hellaswag_acc: 0.2966
Step: 13138, loss: 3.027682, norm: 0.2709, time(ms): 799.61, token/sec:655682.27, hellaswag_acc: 0.2966
Step: 13139, loss: 3.023031, norm: 0.2978, time(ms): 802.14, token/sec:653612.17, hellaswag_acc: 0.2966
Step: 13140, loss: 3.005959, norm: 0.2851, time(ms): 798.10, token/sec:656921.96, hellaswag_acc: 0.2966
Step: 13141, loss: 2.989645, norm: 0.2948, time(ms): 792.92, token/sec:661214.21, hellaswag_acc: 0.2966
Step: 13142, loss: 3.037944, norm: 0.3040, time(ms): 792.19, token/sec:661817.58, hellaswag_acc: 0.2966
Step: 13143, loss: 2.979329, norm: 0.2840, time(ms): 790.65, token/sec:663113.59, hellaswag_acc: 0.2966
Step: 13144, loss: 3.116080, norm: 0.3315, time(ms): 1313.26, token/sec:399226.33, hellaswag_acc: 0.2966
Step: 13145, loss: 3.070735, norm: 0.3040, time(ms): 788.37, token/sec:665029.54, hellaswag_acc: 0.2966
Step: 13146, loss: 3.104250, norm: 0.3026, time(ms): 791.50, token/sec:662397.90, hellaswag_acc: 0.2966
Step: 13147, loss: 3.055554, norm: 0.2978, time(ms): 786.17, token/sec:666890.25, hellaswag_acc: 0.2966
Step: 13148, loss: 3.110252, norm: 0.2970, time(ms): 790.56, token/sec:663184.78, hellaswag_acc: 0.2966
Step: 13149, loss: 3.117910, norm: 0.2933, time(ms): 796.39, token/sec:658334.22, hellaswag_acc: 0.2966
Step: 13150, loss: 3.041646, norm: 0.2693, time(ms): 789.82, token/sec:663804.38, hellaswag_acc: 0.2966
Step: 13151, loss: 3.083552, norm: 0.2730, time(ms): 803.87, token/sec:652203.63, hellaswag_acc: 0.2966
Step: 13152, loss: 3.134311, norm: 0.2992, time(ms): 806.40, token/sec:650159.45, hellaswag_acc: 0.2966
Step: 13153, loss: 3.143648, norm: 0.2788, time(ms): 797.51, token/sec:657408.61, hellaswag_acc: 0.2966
Step: 13154, loss: 3.127078, norm: 0.2835, time(ms): 787.49, token/sec:665767.86, hellaswag_acc: 0.2966
Step: 13155, loss: 3.149364, norm: 0.2822, time(ms): 790.94, token/sec:662866.53, hellaswag_acc: 0.2966
Step: 13156, loss: 3.183326, norm: 0.3168, time(ms): 792.84, token/sec:661274.66, hellaswag_acc: 0.2966
Step: 13157, loss: 3.216868, norm: 0.2941, time(ms): 791.07, token/sec:662760.85, hellaswag_acc: 0.2966
Step: 13158, loss: 3.187010, norm: 0.3287, time(ms): 788.34, token/sec:665050.66, hellaswag_acc: 0.2966
Step: 13159, loss: 3.161307, norm: 0.3194, time(ms): 791.83, token/sec:662122.66, hellaswag_acc: 0.2966
Step: 13160, loss: 3.153602, norm: 0.2899, time(ms): 791.05, token/sec:662776.63, hellaswag_acc: 0.2966
Step: 13161, loss: 3.235679, norm: 0.3050, time(ms): 802.02, token/sec:653710.49, hellaswag_acc: 0.2966
Step: 13162, loss: 3.167029, norm: 0.2758, time(ms): 795.13, token/sec:659375.11, hellaswag_acc: 0.2966
Step: 13163, loss: 3.178036, norm: 0.3061, time(ms): 791.90, token/sec:662064.85, hellaswag_acc: 0.2966
Step: 13164, loss: 3.170722, norm: 0.2797, time(ms): 791.33, token/sec:662543.19, hellaswag_acc: 0.2966
Step: 13165, loss: 3.215735, norm: 0.3042, time(ms): 789.42, token/sec:664144.59, hellaswag_acc: 0.2966
Step: 13166, loss: 3.242141, norm: 0.2877, time(ms): 794.85, token/sec:659602.96, hellaswag_acc: 0.2966
Step: 13167, loss: 3.201191, norm: 0.2878, time(ms): 790.29, token/sec:663414.47, hellaswag_acc: 0.2966
Step: 13168, loss: 3.136300, norm: 0.2964, time(ms): 791.12, token/sec:662719.30, hellaswag_acc: 0.2966
Step: 13169, loss: 3.089382, norm: 0.2704, time(ms): 789.72, token/sec:663890.95, hellaswag_acc: 0.2966
Step: 13170, loss: 3.147021, norm: 0.3206, time(ms): 793.42, token/sec:660792.99, hellaswag_acc: 0.2966
Step: 13171, loss: 3.069318, norm: 0.2687, time(ms): 796.17, token/sec:658512.04, hellaswag_acc: 0.2966
Step: 13172, loss: 3.060452, norm: 0.2869, time(ms): 789.77, token/sec:663847.86, hellaswag_acc: 0.2966
Step: 13173, loss: 3.059165, norm: 0.2669, time(ms): 788.21, token/sec:665164.52, hellaswag_acc: 0.2966
Step: 13174, loss: 3.201105, norm: 0.2630, time(ms): 796.43, token/sec:658293.82, hellaswag_acc: 0.2966
Step: 13175, loss: 3.114082, norm: 0.2927, time(ms): 796.25, token/sec:658447.76, hellaswag_acc: 0.2966
Step: 13176, loss: 3.162123, norm: 0.2596, time(ms): 791.13, token/sec:662706.52, hellaswag_acc: 0.2966
Step: 13177, loss: 3.081018, norm: 0.2932, time(ms): 788.95, token/sec:664538.77, hellaswag_acc: 0.2966
Step: 13178, loss: 3.123371, norm: 0.2755, time(ms): 788.26, token/sec:665118.25, hellaswag_acc: 0.2966
Step: 13179, loss: 3.067190, norm: 0.2688, time(ms): 799.08, token/sec:656111.88, hellaswag_acc: 0.2966
Step: 13180, loss: 3.150993, norm: 0.3022, time(ms): 794.41, token/sec:659968.98, hellaswag_acc: 0.2966
Step: 13181, loss: 3.046190, norm: 0.2723, time(ms): 805.67, token/sec:650751.85, hellaswag_acc: 0.2966
Step: 13182, loss: 3.125162, norm: 0.3085, time(ms): 796.40, token/sec:658320.23, hellaswag_acc: 0.2966
Step: 13183, loss: 3.122868, norm: 0.2756, time(ms): 796.94, token/sec:657876.30, hellaswag_acc: 0.2966
Step: 13184, loss: 3.198502, norm: 0.2911, time(ms): 801.88, token/sec:653820.89, hellaswag_acc: 0.2966
Step: 13185, loss: 3.044264, norm: 0.2755, time(ms): 803.69, token/sec:652349.32, hellaswag_acc: 0.2966
Step: 13186, loss: 3.086388, norm: 0.2713, time(ms): 794.59, token/sec:659822.64, hellaswag_acc: 0.2966
Step: 13187, loss: 3.114838, norm: 0.2772, time(ms): 802.04, token/sec:653691.06, hellaswag_acc: 0.2966
Step: 13188, loss: 3.098314, norm: 0.2823, time(ms): 802.30, token/sec:653482.81, hellaswag_acc: 0.2966
Step: 13189, loss: 3.176918, norm: 0.3318, time(ms): 790.93, token/sec:662876.12, hellaswag_acc: 0.2966
Step: 13190, loss: 3.063217, norm: 0.2797, time(ms): 796.69, token/sec:658086.77, hellaswag_acc: 0.2966
Step: 13191, loss: 3.101670, norm: 0.3095, time(ms): 791.05, token/sec:662773.63, hellaswag_acc: 0.2966
Step: 13192, loss: 3.139652, norm: 0.3016, time(ms): 799.24, token/sec:655984.07, hellaswag_acc: 0.2966
Step: 13193, loss: 3.160503, norm: 0.3233, time(ms): 790.55, token/sec:663197.98, hellaswag_acc: 0.2966
Step: 13194, loss: 3.173968, norm: 0.3005, time(ms): 786.62, token/sec:666509.44, hellaswag_acc: 0.2966
Step: 13195, loss: 3.142678, norm: 0.3238, time(ms): 800.77, token/sec:654731.54, hellaswag_acc: 0.2966
Step: 13196, loss: 3.196802, norm: 0.3108, time(ms): 802.31, token/sec:653476.99, hellaswag_acc: 0.2966
Step: 13197, loss: 3.179454, norm: 0.3187, time(ms): 797.17, token/sec:657684.47, hellaswag_acc: 0.2966
Step: 13198, loss: 3.123260, norm: 0.3072, time(ms): 798.52, token/sec:656571.85, hellaswag_acc: 0.2966
Step: 13199, loss: 3.122020, norm: 0.2840, time(ms): 800.20, token/sec:655195.43, hellaswag_acc: 0.2966
Step: 13200, loss: 3.150754, norm: 0.2979, time(ms): 804.05, token/sec:652060.91, hellaswag_acc: 0.2966
Step: 13201, loss: 3.108230, norm: 0.2987, time(ms): 794.33, token/sec:660041.09, hellaswag_acc: 0.2966
Step: 13202, loss: 3.215615, norm: 0.2940, time(ms): 801.05, token/sec:654500.23, hellaswag_acc: 0.2966
Step: 13203, loss: 3.167722, norm: 0.3192, time(ms): 799.47, token/sec:655798.22, hellaswag_acc: 0.2966
Step: 13204, loss: 3.107105, norm: 0.2970, time(ms): 804.66, token/sec:651567.27, hellaswag_acc: 0.2966
Step: 13205, loss: 3.161394, norm: 0.3060, time(ms): 790.74, token/sec:663033.82, hellaswag_acc: 0.2966
Step: 13206, loss: 3.105492, norm: 0.3003, time(ms): 795.20, token/sec:659318.97, hellaswag_acc: 0.2966
Step: 13207, loss: 3.142147, norm: 0.3081, time(ms): 793.67, token/sec:660588.33, hellaswag_acc: 0.2966
Step: 13208, loss: 3.061237, norm: 0.2803, time(ms): 798.74, token/sec:656390.56, hellaswag_acc: 0.2966
Step: 13209, loss: 3.090445, norm: 0.2722, time(ms): 799.04, token/sec:656144.96, hellaswag_acc: 0.2966
Step: 13210, loss: 3.146271, norm: 0.3000, time(ms): 798.37, token/sec:656696.55, hellaswag_acc: 0.2966
Step: 13211, loss: 3.082275, norm: 0.2813, time(ms): 800.06, token/sec:655309.26, hellaswag_acc: 0.2966
Step: 13212, loss: 3.095932, norm: 0.3053, time(ms): 799.55, token/sec:655727.04, hellaswag_acc: 0.2966
Step: 13213, loss: 3.105966, norm: 0.2946, time(ms): 802.59, token/sec:653246.95, hellaswag_acc: 0.2966
Step: 13214, loss: 3.024930, norm: 0.2713, time(ms): 795.75, token/sec:658863.43, hellaswag_acc: 0.2966
Step: 13215, loss: 3.094821, norm: 0.2949, time(ms): 800.97, token/sec:654568.22, hellaswag_acc: 0.2966
Step: 13216, loss: 3.106702, norm: 0.2912, time(ms): 800.99, token/sec:654548.55, hellaswag_acc: 0.2966
Step: 13217, loss: 3.163142, norm: 0.2595, time(ms): 798.89, token/sec:656267.35, hellaswag_acc: 0.2966
Step: 13218, loss: 3.111918, norm: 0.2916, time(ms): 798.87, token/sec:656284.98, hellaswag_acc: 0.2966
Step: 13219, loss: 3.182320, norm: 0.3103, time(ms): 797.63, token/sec:657309.96, hellaswag_acc: 0.2966
Step: 13220, loss: 3.145131, norm: 0.2914, time(ms): 802.69, token/sec:653162.74, hellaswag_acc: 0.2966
Step: 13221, loss: 3.156318, norm: 0.2968, time(ms): 803.91, token/sec:652176.55, hellaswag_acc: 0.2966
Step: 13222, loss: 3.122010, norm: 0.2969, time(ms): 794.54, token/sec:659866.80, hellaswag_acc: 0.2966
Step: 13223, loss: 3.155154, norm: 0.2934, time(ms): 800.34, token/sec:655084.76, hellaswag_acc: 0.2966
Step: 13224, loss: 3.170868, norm: 0.3191, time(ms): 802.30, token/sec:653483.40, hellaswag_acc: 0.2966
Step: 13225, loss: 3.123333, norm: 0.2769, time(ms): 793.86, token/sec:660432.40, hellaswag_acc: 0.2966
Step: 13226, loss: 3.127305, norm: 0.2813, time(ms): 795.10, token/sec:659395.87, hellaswag_acc: 0.2966
Step: 13227, loss: 3.173714, norm: 0.3300, time(ms): 787.88, token/sec:665440.08, hellaswag_acc: 0.2966
Step: 13228, loss: 3.167643, norm: 0.3070, time(ms): 790.17, token/sec:663514.96, hellaswag_acc: 0.2966
Step: 13229, loss: 3.150598, norm: 0.3466, time(ms): 791.76, token/sec:662176.70, hellaswag_acc: 0.2966
Step: 13230, loss: 3.185665, norm: 0.3102, time(ms): 793.80, token/sec:660479.01, hellaswag_acc: 0.2966
Step: 13231, loss: 3.197585, norm: 0.3203, time(ms): 806.94, token/sec:649724.93, hellaswag_acc: 0.2966
Step: 13232, loss: 3.162435, norm: 0.3093, time(ms): 802.12, token/sec:653626.74, hellaswag_acc: 0.2966
Step: 13233, loss: 3.207324, norm: 0.3113, time(ms): 793.72, token/sec:660547.06, hellaswag_acc: 0.2966
Step: 13234, loss: 3.171266, norm: 0.3071, time(ms): 798.51, token/sec:656585.76, hellaswag_acc: 0.2966
Step: 13235, loss: 3.197838, norm: 0.3029, time(ms): 804.96, token/sec:651320.64, hellaswag_acc: 0.2966
Step: 13236, loss: 3.155334, norm: 0.2964, time(ms): 791.19, token/sec:662656.39, hellaswag_acc: 0.2966
Step: 13237, loss: 3.186750, norm: 0.2771, time(ms): 793.17, token/sec:661004.93, hellaswag_acc: 0.2966
Step: 13238, loss: 3.207273, norm: 0.3268, time(ms): 790.95, token/sec:662862.73, hellaswag_acc: 0.2966
Step: 13239, loss: 3.119269, norm: 0.3081, time(ms): 795.78, token/sec:658835.21, hellaswag_acc: 0.2966
Step: 13240, loss: 3.070992, norm: 0.2753, time(ms): 791.17, token/sec:662674.97, hellaswag_acc: 0.2966
Step: 13241, loss: 3.135327, norm: 0.3031, time(ms): 790.01, token/sec:663643.51, hellaswag_acc: 0.2966
Step: 13242, loss: 3.112523, norm: 0.2840, time(ms): 798.49, token/sec:656600.47, hellaswag_acc: 0.2966
Step: 13243, loss: 3.123485, norm: 0.2898, time(ms): 793.54, token/sec:660698.29, hellaswag_acc: 0.2966
Step: 13244, loss: 3.062805, norm: 0.2827, time(ms): 795.83, token/sec:658795.34, hellaswag_acc: 0.2966
Step: 13245, loss: 3.083800, norm: 0.2646, time(ms): 789.19, token/sec:664339.21, hellaswag_acc: 0.2966
Step: 13246, loss: 3.127261, norm: 0.2699, time(ms): 790.32, token/sec:663389.25, hellaswag_acc: 0.2966
Step: 13247, loss: 3.037745, norm: 0.2917, time(ms): 791.16, token/sec:662682.15, hellaswag_acc: 0.2966
Step: 13248, loss: 3.130771, norm: 0.2803, time(ms): 793.81, token/sec:660466.71, hellaswag_acc: 0.2966
Step: 13249, loss: 3.052583, norm: 0.2860, time(ms): 793.10, token/sec:661059.17, hellaswag_acc: 0.2966
rank 0 sample 0: Hello, I'm a language model, so I need to know where you're actually on the path to be going with the project. This project involves a number
rank 0 sample 1: Hello, I'm a language model, and not a language model. But by the time those folks got the handle they were ready to do stuff with Python.
rank 0 sample 2: Hello, I'm a language model, and I see it right where I have to put in the work that you're doing, and I'm going to create
rank 0 sample 3: Hello, I'm a language model, but here's how I see the "gbo" in the sentence. The words have two different meanings. One side
rank 1 sample 0: Hello, I'm a language model, with an implementation of the Java code here and this code example of the JVM. It's pretty simple and it's
rank 1 sample 1: Hello, I'm a language model, not an object model.
What we actually do is it's easy to build two basic elements. The first is a
rank 1 sample 2: Hello, I'm a language model, but of course there are many other languages that are native and able to communicate with each other. This article is for the
rank 1 sample 3: Hello, I'm a language model, so I'm here for Python. That tells me it prints to any Python expression. My next problem is that my program
Step: 13250, loss: 3.117440, norm: 0.3067, time(ms): 3805.78, token/sec:137760.88, val_loss: 3.1274, hellaswag_acc: 0.2966
Step: 13251, loss: 3.095931, norm: 0.3125, time(ms): 785.26, token/sec:667664.33, hellaswag_acc: 0.2966
Step: 13252, loss: 3.139189, norm: 0.3096, time(ms): 785.16, token/sec:667742.59, hellaswag_acc: 0.2966
Step: 13253, loss: 3.129057, norm: 0.3250, time(ms): 795.10, token/sec:659400.22, hellaswag_acc: 0.2966
Step: 13254, loss: 3.049163, norm: 0.2825, time(ms): 794.87, token/sec:659587.53, hellaswag_acc: 0.2966
Step: 13255, loss: 3.159535, norm: 0.3103, time(ms): 791.09, token/sec:662739.67, hellaswag_acc: 0.2966
Step: 13256, loss: 3.122028, norm: 0.2733, time(ms): 792.72, token/sec:661380.67, hellaswag_acc: 0.2966
Step: 13257, loss: 3.098771, norm: 0.2944, time(ms): 796.56, token/sec:658192.54, hellaswag_acc: 0.2966
Step: 13258, loss: 3.130837, norm: 0.2855, time(ms): 792.75, token/sec:661356.40, hellaswag_acc: 0.2966
Step: 13259, loss: 3.066727, norm: 0.2748, time(ms): 796.41, token/sec:658314.71, hellaswag_acc: 0.2966
Step: 13260, loss: 3.120732, norm: 0.2848, time(ms): 794.66, token/sec:659761.67, hellaswag_acc: 0.2966
Step: 13261, loss: 3.150870, norm: 0.2861, time(ms): 789.89, token/sec:663750.28, hellaswag_acc: 0.2966
Step: 13262, loss: 3.111997, norm: 0.2908, time(ms): 791.35, token/sec:662525.43, hellaswag_acc: 0.2966
Step: 13263, loss: 3.156737, norm: 0.3101, time(ms): 789.88, token/sec:663753.68, hellaswag_acc: 0.2966
Step: 13264, loss: 3.121729, norm: 0.2871, time(ms): 788.00, token/sec:665344.24, hellaswag_acc: 0.2966
Step: 13265, loss: 3.219819, norm: 0.3109, time(ms): 804.23, token/sec:651911.68, hellaswag_acc: 0.2966
Step: 13266, loss: 3.150603, norm: 0.3217, time(ms): 806.39, token/sec:650164.26, hellaswag_acc: 0.2966
Step: 13267, loss: 3.188786, norm: 0.2890, time(ms): 792.25, token/sec:661767.39, hellaswag_acc: 0.2966
Step: 13268, loss: 3.149233, norm: 0.3214, time(ms): 803.65, token/sec:652379.52, hellaswag_acc: 0.2966
Step: 13269, loss: 3.162083, norm: 0.2777, time(ms): 799.57, token/sec:655712.77, hellaswag_acc: 0.2966
Step: 13270, loss: 3.097882, norm: 0.2862, time(ms): 795.91, token/sec:658724.88, hellaswag_acc: 0.2966
Step: 13271, loss: 3.226588, norm: 0.2884, time(ms): 801.94, token/sec:653775.79, hellaswag_acc: 0.2966
Step: 13272, loss: 3.128308, norm: 0.2705, time(ms): 802.79, token/sec:653082.43, hellaswag_acc: 0.2966
Step: 13273, loss: 3.177763, norm: 0.2662, time(ms): 795.30, token/sec:659235.56, hellaswag_acc: 0.2966
Step: 13274, loss: 3.126812, norm: 0.2965, time(ms): 805.69, token/sec:650729.70, hellaswag_acc: 0.2966
Step: 13275, loss: 3.035049, norm: 0.2755, time(ms): 794.34, token/sec:660032.97, hellaswag_acc: 0.2966
Step: 13276, loss: 3.065145, norm: 0.2776, time(ms): 804.23, token/sec:651914.38, hellaswag_acc: 0.2966
Step: 13277, loss: 3.086109, norm: 0.2900, time(ms): 800.06, token/sec:655309.26, hellaswag_acc: 0.2966
Step: 13278, loss: 3.062574, norm: 0.2695, time(ms): 795.36, token/sec:659184.57, hellaswag_acc: 0.2966
Step: 13279, loss: 3.109510, norm: 0.2636, time(ms): 803.90, token/sec:652180.62, hellaswag_acc: 0.2966
Step: 13280, loss: 3.059196, norm: 0.2825, time(ms): 799.58, token/sec:655703.58, hellaswag_acc: 0.2966
Step: 13281, loss: 3.083776, norm: 0.2573, time(ms): 795.77, token/sec:658846.85, hellaswag_acc: 0.2966
Step: 13282, loss: 3.172531, norm: 0.3020, time(ms): 796.99, token/sec:657834.39, hellaswag_acc: 0.2966
Step: 13283, loss: 3.102883, norm: 0.2715, time(ms): 805.60, token/sec:650802.31, hellaswag_acc: 0.2966
Step: 13284, loss: 3.110484, norm: 0.2768, time(ms): 803.52, token/sec:652492.95, hellaswag_acc: 0.2966
Step: 13285, loss: 3.089381, norm: 0.2721, time(ms): 789.03, token/sec:664475.32, hellaswag_acc: 0.2966
Step: 13286, loss: 3.096289, norm: 0.2714, time(ms): 801.92, token/sec:653794.65, hellaswag_acc: 0.2966
Step: 13287, loss: 3.119435, norm: 0.2822, time(ms): 807.87, token/sec:648975.39, hellaswag_acc: 0.2966
Step: 13288, loss: 3.157034, norm: 0.2836, time(ms): 788.94, token/sec:664549.42, hellaswag_acc: 0.2966
Step: 13289, loss: 3.201994, norm: 0.4084, time(ms): 789.89, token/sec:663744.27, hellaswag_acc: 0.2966
Step: 13290, loss: 3.079390, norm: 0.3069, time(ms): 796.56, token/sec:658190.37, hellaswag_acc: 0.2966
Step: 13291, loss: 3.120321, norm: 0.3073, time(ms): 790.19, token/sec:663494.34, hellaswag_acc: 0.2966
Step: 13292, loss: 3.143444, norm: 0.3122, time(ms): 791.04, token/sec:662786.41, hellaswag_acc: 0.2966
Step: 13293, loss: 3.095145, norm: 0.2888, time(ms): 794.93, token/sec:659541.23, hellaswag_acc: 0.2966
Step: 13294, loss: 3.125074, norm: 0.2728, time(ms): 803.01, token/sec:652907.14, hellaswag_acc: 0.2966
Step: 13295, loss: 3.128787, norm: 0.3341, time(ms): 804.72, token/sec:651516.70, hellaswag_acc: 0.2966
Step: 13296, loss: 3.060026, norm: 0.2949, time(ms): 798.71, token/sec:656414.66, hellaswag_acc: 0.2966
Step: 13297, loss: 3.132288, norm: 0.2917, time(ms): 791.62, token/sec:662297.95, hellaswag_acc: 0.2966
Step: 13298, loss: 3.194523, norm: 0.3645, time(ms): 798.69, token/sec:656433.87, hellaswag_acc: 0.2966
Step: 13299, loss: 3.215763, norm: 0.2964, time(ms): 792.37, token/sec:661671.01, hellaswag_acc: 0.2966
Step: 13300, loss: 3.197304, norm: 0.3209, time(ms): 790.74, token/sec:663038.81, hellaswag_acc: 0.2966
Step: 13301, loss: 3.155252, norm: 0.3308, time(ms): 789.90, token/sec:663739.86, hellaswag_acc: 0.2966
Step: 13302, loss: 3.215353, norm: 0.3022, time(ms): 800.18, token/sec:655214.17, hellaswag_acc: 0.2966
Step: 13303, loss: 3.182834, norm: 0.2955, time(ms): 792.20, token/sec:661816.58, hellaswag_acc: 0.2966
Step: 13304, loss: 3.169163, norm: 0.3030, time(ms): 787.48, token/sec:665781.16, hellaswag_acc: 0.2966
Step: 13305, loss: 3.201643, norm: 0.3055, time(ms): 787.89, token/sec:665433.63, hellaswag_acc: 0.2966
Step: 13306, loss: 3.177198, norm: 0.3016, time(ms): 807.18, token/sec:649531.10, hellaswag_acc: 0.2966
Step: 13307, loss: 3.178864, norm: 0.2813, time(ms): 800.86, token/sec:654658.64, hellaswag_acc: 0.2966
Step: 13308, loss: 3.083936, norm: 0.2833, time(ms): 793.04, token/sec:661110.45, hellaswag_acc: 0.2966
Step: 13309, loss: 3.145606, norm: 0.2793, time(ms): 800.80, token/sec:654707.17, hellaswag_acc: 0.2966
Step: 13310, loss: 3.181337, norm: 0.2883, time(ms): 805.62, token/sec:650790.95, hellaswag_acc: 0.2966
Step: 13311, loss: 3.050289, norm: 0.2725, time(ms): 791.83, token/sec:662125.66, hellaswag_acc: 0.2966
Step: 13312, loss: 3.041126, norm: 0.5379, time(ms): 801.89, token/sec:653812.14, hellaswag_acc: 0.2966
Step: 13313, loss: 3.163293, norm: 0.2981, time(ms): 805.04, token/sec:651253.32, hellaswag_acc: 0.2966
Step: 13314, loss: 3.063690, norm: 0.2723, time(ms): 796.97, token/sec:657852.88, hellaswag_acc: 0.2966
Step: 13315, loss: 3.114416, norm: 0.2920, time(ms): 795.35, token/sec:659194.26, hellaswag_acc: 0.2966
Step: 13316, loss: 3.092484, norm: 0.2770, time(ms): 804.82, token/sec:651437.18, hellaswag_acc: 0.2966
Step: 13317, loss: 3.102077, norm: 0.2869, time(ms): 802.92, token/sec:652979.46, hellaswag_acc: 0.2966
Step: 13318, loss: 3.141792, norm: 0.2709, time(ms): 793.53, token/sec:660703.65, hellaswag_acc: 0.2966
Step: 13319, loss: 3.095524, norm: 0.2998, time(ms): 793.50, token/sec:660731.84, hellaswag_acc: 0.2966
Step: 13320, loss: 3.120206, norm: 0.2780, time(ms): 790.76, token/sec:663017.42, hellaswag_acc: 0.2966
Step: 13321, loss: 3.098239, norm: 0.2899, time(ms): 796.86, token/sec:657938.70, hellaswag_acc: 0.2966
Step: 13322, loss: 3.134661, norm: 0.2988, time(ms): 791.66, token/sec:662266.84, hellaswag_acc: 0.2966
Step: 13323, loss: 3.139700, norm: 0.3086, time(ms): 788.23, token/sec:665145.00, hellaswag_acc: 0.2966
Step: 13324, loss: 3.093537, norm: 0.3209, time(ms): 796.58, token/sec:658170.67, hellaswag_acc: 0.2966
Step: 13325, loss: 3.126602, norm: 0.2758, time(ms): 807.20, token/sec:649511.15, hellaswag_acc: 0.2966
Step: 13326, loss: 3.145030, norm: 0.3001, time(ms): 796.23, token/sec:658462.75, hellaswag_acc: 0.2966
Step: 13327, loss: 3.140570, norm: 0.2866, time(ms): 795.27, token/sec:659260.06, hellaswag_acc: 0.2966
Step: 13328, loss: 3.108130, norm: 0.2933, time(ms): 803.23, token/sec:652722.45, hellaswag_acc: 0.2966
Step: 13329, loss: 3.128075, norm: 0.3049, time(ms): 804.70, token/sec:651531.56, hellaswag_acc: 0.2966
Step: 13330, loss: 3.119717, norm: 0.2818, time(ms): 790.65, token/sec:663113.39, hellaswag_acc: 0.2966
Step: 13331, loss: 3.148297, norm: 0.3140, time(ms): 791.91, token/sec:662053.09, hellaswag_acc: 0.2966
Step: 13332, loss: 3.154153, norm: 0.2979, time(ms): 792.44, token/sec:661608.11, hellaswag_acc: 0.2966
Step: 13333, loss: 3.166968, norm: 0.3183, time(ms): 798.92, token/sec:656249.33, hellaswag_acc: 0.2966
Step: 13334, loss: 3.174415, norm: 0.2974, time(ms): 1563.88, token/sec:335247.32, hellaswag_acc: 0.2966
Step: 13335, loss: 3.141377, norm: 0.3343, time(ms): 767.27, token/sec:683319.49, hellaswag_acc: 0.2966
Step: 13336, loss: 3.139749, norm: 0.3142, time(ms): 790.58, token/sec:663170.18, hellaswag_acc: 0.2966
Step: 13337, loss: 3.144925, norm: 0.2932, time(ms): 801.41, token/sec:654205.05, hellaswag_acc: 0.2966
Step: 13338, loss: 3.244407, norm: 0.3568, time(ms): 788.25, token/sec:665132.33, hellaswag_acc: 0.2966
Step: 13339, loss: 3.127291, norm: 0.3546, time(ms): 785.33, token/sec:667600.69, hellaswag_acc: 0.2966
Step: 13340, loss: 3.088913, norm: 0.3049, time(ms): 789.27, token/sec:664267.37, hellaswag_acc: 0.2966
Step: 13341, loss: 3.060820, norm: 0.3357, time(ms): 795.95, token/sec:658690.95, hellaswag_acc: 0.2966
Step: 13342, loss: 3.093502, norm: 0.2984, time(ms): 788.15, token/sec:665210.80, hellaswag_acc: 0.2966
Step: 13343, loss: 3.131001, norm: 0.2854, time(ms): 785.15, token/sec:667754.55, hellaswag_acc: 0.2966
Step: 13344, loss: 3.073957, norm: 0.3106, time(ms): 802.33, token/sec:653456.21, hellaswag_acc: 0.2966
Step: 13345, loss: 3.117829, norm: 0.2843, time(ms): 806.14, token/sec:650365.00, hellaswag_acc: 0.2966
Step: 13346, loss: 3.119560, norm: 0.2719, time(ms): 790.50, token/sec:663232.99, hellaswag_acc: 0.2966
Step: 13347, loss: 3.082332, norm: 0.2702, time(ms): 794.61, token/sec:659805.82, hellaswag_acc: 0.2966
Step: 13348, loss: 3.048794, norm: 0.2633, time(ms): 788.66, token/sec:664783.86, hellaswag_acc: 0.2966
Step: 13349, loss: 3.177530, norm: 0.2810, time(ms): 794.51, token/sec:659886.99, hellaswag_acc: 0.2966
Step: 13350, loss: 3.112766, norm: 0.2617, time(ms): 789.96, token/sec:663689.38, hellaswag_acc: 0.2966
Step: 13351, loss: 3.116856, norm: 0.2755, time(ms): 795.57, token/sec:659005.79, hellaswag_acc: 0.2966
Step: 13352, loss: 3.109123, norm: 0.2744, time(ms): 800.71, token/sec:654775.40, hellaswag_acc: 0.2966
Step: 13353, loss: 3.073121, norm: 0.2737, time(ms): 803.42, token/sec:652573.11, hellaswag_acc: 0.2966
Step: 13354, loss: 3.083245, norm: 0.2637, time(ms): 792.63, token/sec:661453.68, hellaswag_acc: 0.2966
Step: 13355, loss: 3.089543, norm: 0.2954, time(ms): 798.61, token/sec:656496.58, hellaswag_acc: 0.2966
Step: 13356, loss: 3.083784, norm: 0.2646, time(ms): 803.29, token/sec:652672.67, hellaswag_acc: 0.2966
Step: 13357, loss: 3.119049, norm: 0.2631, time(ms): 801.91, token/sec:653796.59, hellaswag_acc: 0.2966
Step: 13358, loss: 3.062539, norm: 0.2645, time(ms): 798.01, token/sec:656994.18, hellaswag_acc: 0.2966
Step: 13359, loss: 3.108095, norm: 0.2640, time(ms): 801.55, token/sec:654089.85, hellaswag_acc: 0.2966
Step: 13360, loss: 3.123155, norm: 0.2758, time(ms): 801.00, token/sec:654544.84, hellaswag_acc: 0.2966
Step: 13361, loss: 3.029677, norm: 0.2767, time(ms): 799.28, token/sec:655954.13, hellaswag_acc: 0.2966
Step: 13362, loss: 3.121339, norm: 0.2717, time(ms): 794.30, token/sec:660066.25, hellaswag_acc: 0.2966
Step: 13363, loss: 3.056999, norm: 0.2823, time(ms): 799.27, token/sec:655960.98, hellaswag_acc: 0.2966
Step: 13364, loss: 3.166925, norm: 0.3456, time(ms): 792.62, token/sec:661464.02, hellaswag_acc: 0.2966
Step: 13365, loss: 3.108305, norm: 0.3128, time(ms): 792.70, token/sec:661399.37, hellaswag_acc: 0.2966
Step: 13366, loss: 3.043751, norm: 0.3093, time(ms): 792.42, token/sec:661629.21, hellaswag_acc: 0.2966
Step: 13367, loss: 3.161023, norm: 0.3551, time(ms): 788.39, token/sec:665014.26, hellaswag_acc: 0.2966
Step: 13368, loss: 3.109037, norm: 0.4161, time(ms): 790.58, token/sec:663166.58, hellaswag_acc: 0.2966
Step: 13369, loss: 3.114556, norm: 0.3696, time(ms): 790.96, token/sec:662847.75, hellaswag_acc: 0.2966
Step: 13370, loss: 3.121412, norm: 0.3290, time(ms): 797.24, token/sec:657625.46, hellaswag_acc: 0.2966
Step: 13371, loss: 3.099546, norm: 0.3695, time(ms): 801.36, token/sec:654245.14, hellaswag_acc: 0.2966
Step: 13372, loss: 3.144680, norm: 0.3435, time(ms): 801.12, token/sec:654440.04, hellaswag_acc: 0.2966
Step: 13373, loss: 3.147893, norm: 0.3181, time(ms): 794.53, token/sec:659871.15, hellaswag_acc: 0.2966
Step: 13374, loss: 3.085089, norm: 0.3357, time(ms): 799.45, token/sec:655808.59, hellaswag_acc: 0.2966
Step: 13375, loss: 3.103689, norm: 0.3210, time(ms): 802.92, token/sec:652975.78, hellaswag_acc: 0.2966
Step: 13376, loss: 3.109758, norm: 0.3030, time(ms): 799.84, token/sec:655494.64, hellaswag_acc: 0.2966
Step: 13377, loss: 3.053381, norm: 0.3024, time(ms): 795.53, token/sec:659040.36, hellaswag_acc: 0.2966
Step: 13378, loss: 3.088267, norm: 0.2787, time(ms): 805.26, token/sec:651079.78, hellaswag_acc: 0.2966
Step: 13379, loss: 3.045658, norm: 0.2929, time(ms): 801.42, token/sec:654200.96, hellaswag_acc: 0.2966
Step: 13380, loss: 3.106507, norm: 0.2652, time(ms): 790.17, token/sec:663516.96, hellaswag_acc: 0.2966
Step: 13381, loss: 3.099622, norm: 0.2972, time(ms): 792.27, token/sec:661752.06, hellaswag_acc: 0.2966
Step: 13382, loss: 3.118922, norm: 0.3140, time(ms): 792.30, token/sec:661726.77, hellaswag_acc: 0.2966
Step: 13383, loss: 3.085302, norm: 0.2771, time(ms): 793.82, token/sec:660463.14, hellaswag_acc: 0.2966
Step: 13384, loss: 3.078618, norm: 0.3227, time(ms): 790.35, token/sec:663364.84, hellaswag_acc: 0.2966
Step: 13385, loss: 3.073012, norm: 0.2899, time(ms): 789.61, token/sec:663984.76, hellaswag_acc: 0.2966
Step: 13386, loss: 3.096772, norm: 0.2985, time(ms): 790.28, token/sec:663417.07, hellaswag_acc: 0.2966
Step: 13387, loss: 3.077842, norm: 0.2948, time(ms): 796.73, token/sec:658050.14, hellaswag_acc: 0.2966
Step: 13388, loss: 3.100509, norm: 0.2957, time(ms): 799.92, token/sec:655424.89, hellaswag_acc: 0.2966
Step: 13389, loss: 3.061070, norm: 0.2978, time(ms): 797.73, token/sec:657226.47, hellaswag_acc: 0.2966
Step: 13390, loss: 3.054542, norm: 0.2916, time(ms): 802.84, token/sec:653038.22, hellaswag_acc: 0.2966
Step: 13391, loss: 3.040359, norm: 0.2974, time(ms): 799.99, token/sec:655369.80, hellaswag_acc: 0.2966
Step: 13392, loss: 3.103108, norm: 0.2834, time(ms): 798.15, token/sec:656878.59, hellaswag_acc: 0.2966
Step: 13393, loss: 3.078134, norm: 0.3006, time(ms): 799.36, token/sec:655887.81, hellaswag_acc: 0.2966
Step: 13394, loss: 3.126464, norm: 0.2916, time(ms): 796.99, token/sec:657831.24, hellaswag_acc: 0.2966
Step: 13395, loss: 3.048325, norm: 0.3002, time(ms): 795.03, token/sec:659456.58, hellaswag_acc: 0.2966
Step: 13396, loss: 3.061934, norm: 0.2826, time(ms): 789.38, token/sec:664180.10, hellaswag_acc: 0.2966
Step: 13397, loss: 3.053070, norm: 0.2809, time(ms): 796.45, token/sec:658282.19, hellaswag_acc: 0.2966
Step: 13398, loss: 3.076414, norm: 0.2647, time(ms): 796.10, token/sec:658568.64, hellaswag_acc: 0.2966
Step: 13399, loss: 3.108005, norm: 0.2884, time(ms): 792.46, token/sec:661598.15, hellaswag_acc: 0.2966
Step: 13400, loss: 3.162407, norm: 0.2854, time(ms): 789.12, token/sec:664396.62, hellaswag_acc: 0.2966
Step: 13401, loss: 3.124297, norm: 0.2826, time(ms): 804.26, token/sec:651891.97, hellaswag_acc: 0.2966
Step: 13402, loss: 3.099156, norm: 0.2726, time(ms): 801.74, token/sec:653941.44, hellaswag_acc: 0.2966
Step: 13403, loss: 3.164863, norm: 0.3021, time(ms): 797.50, token/sec:657412.74, hellaswag_acc: 0.2966
Step: 13404, loss: 3.244877, norm: 0.3138, time(ms): 797.59, token/sec:657338.45, hellaswag_acc: 0.2966
Step: 13405, loss: 3.077130, norm: 0.3553, time(ms): 804.49, token/sec:651702.25, hellaswag_acc: 0.2966
Step: 13406, loss: 3.118473, norm: 0.3075, time(ms): 801.79, token/sec:653894.96, hellaswag_acc: 0.2966
Step: 13407, loss: 3.089394, norm: 0.3232, time(ms): 787.10, token/sec:666100.00, hellaswag_acc: 0.2966
Step: 13408, loss: 3.097653, norm: 0.2941, time(ms): 789.04, token/sec:664467.29, hellaswag_acc: 0.2966
Step: 13409, loss: 3.100453, norm: 0.3202, time(ms): 797.79, token/sec:657174.42, hellaswag_acc: 0.2966
Step: 13410, loss: 3.074006, norm: 0.2911, time(ms): 789.93, token/sec:663712.41, hellaswag_acc: 0.2966
Step: 13411, loss: 3.112139, norm: 0.2927, time(ms): 792.88, token/sec:661243.64, hellaswag_acc: 0.2966
Step: 13412, loss: 3.162682, norm: 0.2786, time(ms): 793.28, token/sec:660910.56, hellaswag_acc: 0.2966
Step: 13413, loss: 3.057798, norm: 0.2756, time(ms): 806.37, token/sec:650186.36, hellaswag_acc: 0.2966
Step: 13414, loss: 3.065087, norm: 0.2872, time(ms): 802.40, token/sec:653401.84, hellaswag_acc: 0.2966
Step: 13415, loss: 3.109290, norm: 0.2666, time(ms): 792.16, token/sec:661848.45, hellaswag_acc: 0.2966
Step: 13416, loss: 3.124055, norm: 0.2854, time(ms): 798.56, token/sec:656545.58, hellaswag_acc: 0.2966
Step: 13417, loss: 3.089031, norm: 0.2987, time(ms): 804.61, token/sec:651602.80, hellaswag_acc: 0.2966
Step: 13418, loss: 3.096066, norm: 0.3082, time(ms): 800.89, token/sec:654634.67, hellaswag_acc: 0.2966
Step: 13419, loss: 3.088781, norm: 0.3052, time(ms): 794.70, token/sec:659732.97, hellaswag_acc: 0.2966
Step: 13420, loss: 3.130746, norm: 0.2793, time(ms): 799.88, token/sec:655454.78, hellaswag_acc: 0.2966
Step: 13421, loss: 3.088093, norm: 0.2812, time(ms): 803.75, token/sec:652300.37, hellaswag_acc: 0.2966
Step: 13422, loss: 3.073779, norm: 0.2673, time(ms): 802.23, token/sec:653535.06, hellaswag_acc: 0.2966
Step: 13423, loss: 3.106128, norm: 0.2757, time(ms): 794.95, token/sec:659520.86, hellaswag_acc: 0.2966
Step: 13424, loss: 3.046086, norm: 0.2745, time(ms): 799.87, token/sec:655469.04, hellaswag_acc: 0.2966
Step: 13425, loss: 2.995877, norm: 0.3001, time(ms): 799.99, token/sec:655367.46, hellaswag_acc: 0.2966
Step: 13426, loss: 3.098971, norm: 0.2645, time(ms): 795.81, token/sec:658813.49, hellaswag_acc: 0.2966
Step: 13427, loss: 3.091266, norm: 0.2646, time(ms): 800.31, token/sec:655109.94, hellaswag_acc: 0.2966
Step: 13428, loss: 3.095612, norm: 0.2691, time(ms): 792.62, token/sec:661464.42, hellaswag_acc: 0.2966
Step: 13429, loss: 3.068884, norm: 0.2763, time(ms): 796.17, token/sec:658509.28, hellaswag_acc: 0.2966
Step: 13430, loss: 3.025901, norm: 0.2672, time(ms): 798.79, token/sec:656354.32, hellaswag_acc: 0.2966
Step: 13431, loss: 3.047404, norm: 0.2651, time(ms): 795.93, token/sec:658713.64, hellaswag_acc: 0.2966
Step: 13432, loss: 3.126706, norm: 0.2648, time(ms): 800.07, token/sec:655298.72, hellaswag_acc: 0.2966
Step: 13433, loss: 3.119874, norm: 0.2925, time(ms): 804.25, token/sec:651896.60, hellaswag_acc: 0.2966
Step: 13434, loss: 3.116605, norm: 0.2731, time(ms): 797.34, token/sec:657548.18, hellaswag_acc: 0.2966
Step: 13435, loss: 3.165165, norm: 0.3098, time(ms): 793.42, token/sec:660791.60, hellaswag_acc: 0.2966
Step: 13436, loss: 3.141185, norm: 0.2923, time(ms): 790.15, token/sec:663527.37, hellaswag_acc: 0.2966
Step: 13437, loss: 3.153124, norm: 0.2887, time(ms): 793.76, token/sec:660515.91, hellaswag_acc: 0.2966
Step: 13438, loss: 3.098908, norm: 0.3205, time(ms): 787.70, token/sec:665589.52, hellaswag_acc: 0.2966
Step: 13439, loss: 3.132299, norm: 0.2837, time(ms): 788.53, token/sec:664890.60, hellaswag_acc: 0.2966
Step: 13440, loss: 3.096164, norm: 0.2767, time(ms): 803.39, token/sec:652591.70, hellaswag_acc: 0.2966
Step: 13441, loss: 3.108230, norm: 0.2838, time(ms): 805.51, token/sec:650874.35, hellaswag_acc: 0.2966
Step: 13442, loss: 3.172171, norm: 0.3098, time(ms): 788.07, token/sec:665278.01, hellaswag_acc: 0.2966
Step: 13443, loss: 2.988127, norm: 0.3193, time(ms): 792.06, token/sec:661925.75, hellaswag_acc: 0.2966
Step: 13444, loss: 3.158628, norm: 0.3008, time(ms): 790.67, token/sec:663090.40, hellaswag_acc: 0.2966
Step: 13445, loss: 3.108626, norm: 0.2791, time(ms): 794.87, token/sec:659590.10, hellaswag_acc: 0.2966
Step: 13446, loss: 3.083860, norm: 0.3051, time(ms): 792.25, token/sec:661773.56, hellaswag_acc: 0.2966
Step: 13447, loss: 3.102992, norm: 0.2962, time(ms): 795.51, token/sec:659055.57, hellaswag_acc: 0.2966
Step: 13448, loss: 3.061627, norm: 0.2679, time(ms): 801.50, token/sec:654134.60, hellaswag_acc: 0.2966
Step: 13449, loss: 3.095802, norm: 0.2919, time(ms): 803.44, token/sec:652552.78, hellaswag_acc: 0.2966
Step: 13450, loss: 3.088320, norm: 0.2733, time(ms): 790.25, token/sec:663442.29, hellaswag_acc: 0.2966
Step: 13451, loss: 3.106892, norm: 0.2789, time(ms): 792.95, token/sec:661189.56, hellaswag_acc: 0.2966
Step: 13452, loss: 3.091649, norm: 0.2749, time(ms): 793.52, token/sec:660712.98, hellaswag_acc: 0.2966
Step: 13453, loss: 3.077181, norm: 0.2687, time(ms): 798.51, token/sec:656579.30, hellaswag_acc: 0.2966
Step: 13454, loss: 3.036175, norm: 0.2612, time(ms): 801.19, token/sec:654389.02, hellaswag_acc: 0.2966
Step: 13455, loss: 3.041186, norm: 0.2675, time(ms): 793.28, token/sec:660910.96, hellaswag_acc: 0.2966
Step: 13456, loss: 3.100105, norm: 0.2801, time(ms): 791.91, token/sec:662059.07, hellaswag_acc: 0.2966
Step: 13457, loss: 3.017529, norm: 0.2853, time(ms): 788.94, token/sec:664545.20, hellaswag_acc: 0.2966
Step: 13458, loss: 3.031661, norm: 0.2596, time(ms): 790.88, token/sec:662919.68, hellaswag_acc: 0.2966
Step: 13459, loss: 3.033286, norm: 0.2918, time(ms): 788.55, token/sec:664877.53, hellaswag_acc: 0.2966
Step: 13460, loss: 3.031954, norm: 0.2630, time(ms): 806.23, token/sec:650298.84, hellaswag_acc: 0.2966
Step: 13461, loss: 3.073802, norm: 0.2808, time(ms): 801.66, token/sec:654005.03, hellaswag_acc: 0.2966
Step: 13462, loss: 3.075027, norm: 0.3125, time(ms): 793.76, token/sec:660511.74, hellaswag_acc: 0.2966
Step: 13463, loss: 3.066593, norm: 0.2557, time(ms): 794.26, token/sec:660099.54, hellaswag_acc: 0.2966
Step: 13464, loss: 3.014189, norm: 0.3144, time(ms): 790.20, token/sec:663483.93, hellaswag_acc: 0.2966
Step: 13465, loss: 3.068077, norm: 0.2664, time(ms): 791.73, token/sec:662209.20, hellaswag_acc: 0.2966
Step: 13466, loss: 3.042251, norm: 0.2756, time(ms): 791.45, token/sec:662441.00, hellaswag_acc: 0.2966
Step: 13467, loss: 3.089813, norm: 0.2712, time(ms): 792.54, token/sec:661530.88, hellaswag_acc: 0.2966
Step: 13468, loss: 3.106818, norm: 0.2819, time(ms): 798.98, token/sec:656193.52, hellaswag_acc: 0.2966
Step: 13469, loss: 3.085869, norm: 0.3001, time(ms): 805.73, token/sec:650698.70, hellaswag_acc: 0.2966
Step: 13470, loss: 3.174087, norm: 0.2894, time(ms): 792.08, token/sec:661910.01, hellaswag_acc: 0.2966
Step: 13471, loss: 3.159622, norm: 0.3108, time(ms): 798.59, token/sec:656516.37, hellaswag_acc: 0.2966
Step: 13472, loss: 3.172952, norm: 0.2753, time(ms): 803.59, token/sec:652435.07, hellaswag_acc: 0.2966
Step: 13473, loss: 3.098862, norm: 0.2812, time(ms): 802.43, token/sec:653373.69, hellaswag_acc: 0.2966
Step: 13474, loss: 3.126322, norm: 0.3019, time(ms): 798.48, token/sec:656606.15, hellaswag_acc: 0.2966
Step: 13475, loss: 3.126295, norm: 0.2885, time(ms): 800.37, token/sec:655055.88, hellaswag_acc: 0.2966
Step: 13476, loss: 3.118669, norm: 0.2900, time(ms): 800.56, token/sec:654901.38, hellaswag_acc: 0.2966
Step: 13477, loss: 3.115267, norm: 0.2780, time(ms): 798.20, token/sec:656837.78, hellaswag_acc: 0.2966
Step: 13478, loss: 3.180663, norm: 0.3299, time(ms): 800.65, token/sec:654831.56, hellaswag_acc: 0.2966
Step: 13479, loss: 3.092375, norm: 0.2972, time(ms): 803.57, token/sec:652451.71, hellaswag_acc: 0.2966
Step: 13480, loss: 3.083255, norm: 0.2883, time(ms): 790.56, token/sec:663186.38, hellaswag_acc: 0.2966
Step: 13481, loss: 3.096786, norm: 0.3003, time(ms): 798.56, token/sec:656543.42, hellaswag_acc: 0.2966
Step: 13482, loss: 3.123071, norm: 0.2950, time(ms): 791.19, token/sec:662660.79, hellaswag_acc: 0.2966
Step: 13483, loss: 3.095288, norm: 0.2978, time(ms): 791.39, token/sec:662487.10, hellaswag_acc: 0.2966
Step: 13484, loss: 3.077640, norm: 0.2976, time(ms): 796.08, token/sec:658583.24, hellaswag_acc: 0.2966
Step: 13485, loss: 3.098030, norm: 0.2939, time(ms): 788.84, token/sec:664629.76, hellaswag_acc: 0.2966
Step: 13486, loss: 3.097009, norm: 0.2838, time(ms): 789.57, token/sec:664015.84, hellaswag_acc: 0.2966
Step: 13487, loss: 3.068127, norm: 0.2808, time(ms): 793.17, token/sec:661004.73, hellaswag_acc: 0.2966
Step: 13488, loss: 3.074521, norm: 0.2786, time(ms): 787.84, token/sec:665471.89, hellaswag_acc: 0.2966
Step: 13489, loss: 3.108282, norm: 0.2770, time(ms): 788.53, token/sec:664890.19, hellaswag_acc: 0.2966
Step: 13490, loss: 3.132421, norm: 0.2797, time(ms): 797.54, token/sec:657384.63, hellaswag_acc: 0.2966
Step: 13491, loss: 3.093324, norm: 0.2996, time(ms): 790.61, token/sec:663145.39, hellaswag_acc: 0.2966
Step: 13492, loss: 3.174530, norm: 0.3994, time(ms): 791.64, token/sec:662280.20, hellaswag_acc: 0.2966
Step: 13493, loss: 3.043786, norm: 0.3436, time(ms): 798.67, token/sec:656450.72, hellaswag_acc: 0.2966
Step: 13494, loss: 3.036495, norm: 0.2902, time(ms): 802.68, token/sec:653174.58, hellaswag_acc: 0.2966
Step: 13495, loss: 3.047004, norm: 0.3315, time(ms): 797.50, token/sec:657411.95, hellaswag_acc: 0.2966
Step: 13496, loss: 3.027668, norm: 0.2849, time(ms): 799.47, token/sec:655794.70, hellaswag_acc: 0.2966
Step: 13497, loss: 3.053351, norm: 0.3038, time(ms): 799.85, token/sec:655481.16, hellaswag_acc: 0.2966
Step: 13498, loss: 3.030945, norm: 0.2977, time(ms): 802.19, token/sec:653568.27, hellaswag_acc: 0.2966
Step: 13499, loss: 3.058138, norm: 0.3006, time(ms): 791.35, token/sec:662526.62, hellaswag_acc: 0.2966
rank 0 sample 0: Hello, I'm a language model, and I'll be able to talk to somebody!
"Hello, I want to speak to somebody!" he said in
rank 0 sample 1: Hello, I'm a language model, so a language model is a way to model how systems (or people) behave. A language model does not explain everything
rank 0 sample 2: Hello, I'm a language model, so I like that and if you know the languages, you have an opportunity to work on them.
I have three
rank 0 sample 3: Hello, I'm a language model, but one that can be used in various applications at the same time. This post about language models and APIs is intended as
rank 1 sample 0: Hello, I'm a language model,
That is, if we start without the interpreter
with and then we execute
the same, we have to

rank 1 sample 1: Hello, I'm a language model, which means I use the same grammar for my own programs I use in my mother language(s). I'm a language
rank 1 sample 2: Hello, I'm a language model, but let's try to understand it.
The input data will consist of input data, the results and output will consist
rank 1 sample 3: Hello, I'm a language model, and I'm an interpreter from Java. Anyway, I made that fun: this is another time when I'm writing a
Step: 13500, loss: 3.065489, norm: 0.2885, time(ms): 3795.71, token/sec:138126.47, val_loss: 3.1272, hellaswag_acc: 0.2966
Step: 13501, loss: 3.095543, norm: 0.2981, time(ms): 791.88, token/sec:662078.21, hellaswag_acc: 0.2966
Step: 13502, loss: 3.055831, norm: 0.2886, time(ms): 792.48, token/sec:661582.83, hellaswag_acc: 0.2966
Step: 13503, loss: 3.147193, norm: 0.3177, time(ms): 797.89, token/sec:657096.07, hellaswag_acc: 0.2966
Step: 13504, loss: 3.078163, norm: 0.3325, time(ms): 790.92, token/sec:662883.71, hellaswag_acc: 0.2966
Step: 13505, loss: 3.147425, norm: 0.3157, time(ms): 785.56, token/sec:667404.76, hellaswag_acc: 0.2966
Step: 13506, loss: 3.177995, norm: 0.3495, time(ms): 789.81, token/sec:663818.60, hellaswag_acc: 0.2966
Step: 13507, loss: 3.117044, norm: 0.3146, time(ms): 796.50, token/sec:658241.99, hellaswag_acc: 0.2966
Step: 13508, loss: 3.078528, norm: 0.3364, time(ms): 807.28, token/sec:649452.83, hellaswag_acc: 0.2966
Step: 13509, loss: 3.111660, norm: 0.3030, time(ms): 800.33, token/sec:655092.37, hellaswag_acc: 0.2966
Step: 13510, loss: 3.162807, norm: 0.3280, time(ms): 785.83, token/sec:667177.97, hellaswag_acc: 0.2966
Step: 13511, loss: 3.170364, norm: 0.2889, time(ms): 789.33, token/sec:664216.21, hellaswag_acc: 0.2966
Step: 13512, loss: 3.158609, norm: 0.3264, time(ms): 792.83, token/sec:661284.60, hellaswag_acc: 0.2966
Step: 13513, loss: 3.126970, norm: 0.2880, time(ms): 790.91, token/sec:662889.91, hellaswag_acc: 0.2966
Step: 13514, loss: 3.113861, norm: 0.2892, time(ms): 791.79, token/sec:662153.77, hellaswag_acc: 0.2966
Step: 13515, loss: 3.170162, norm: 0.3211, time(ms): 801.79, token/sec:653900.80, hellaswag_acc: 0.2966
Step: 13516, loss: 3.160708, norm: 0.3001, time(ms): 806.11, token/sec:650390.39, hellaswag_acc: 0.2966
Step: 13517, loss: 3.068316, norm: 0.3125, time(ms): 791.78, token/sec:662165.93, hellaswag_acc: 0.2966
Step: 13518, loss: 3.133050, norm: 0.2855, time(ms): 794.96, token/sec:659516.71, hellaswag_acc: 0.2966
Step: 13519, loss: 3.056941, norm: 0.2761, time(ms): 792.95, token/sec:661187.77, hellaswag_acc: 0.2966
Step: 13520, loss: 3.111283, norm: 0.2905, time(ms): 794.63, token/sec:659787.80, hellaswag_acc: 0.2966
Step: 13521, loss: 3.113640, norm: 0.2752, time(ms): 797.56, token/sec:657367.73, hellaswag_acc: 0.2966
Step: 13522, loss: 3.098516, norm: 0.2818, time(ms): 802.53, token/sec:653290.23, hellaswag_acc: 0.2966
Step: 13523, loss: 3.092517, norm: 0.2908, time(ms): 803.21, token/sec:652742.99, hellaswag_acc: 0.2966
Step: 13524, loss: 3.098595, norm: 0.3016, time(ms): 793.52, token/sec:660715.56, hellaswag_acc: 0.2966
Step: 13525, loss: 3.077864, norm: 0.2982, time(ms): 1320.38, token/sec:397072.93, hellaswag_acc: 0.2966
Step: 13526, loss: 3.107061, norm: 0.2816, time(ms): 788.63, token/sec:664807.18, hellaswag_acc: 0.2966
Step: 13527, loss: 3.098940, norm: 0.2948, time(ms): 790.44, token/sec:663284.80, hellaswag_acc: 0.2966
Step: 13528, loss: 3.106718, norm: 0.3366, time(ms): 785.30, token/sec:667624.81, hellaswag_acc: 0.2966
Step: 13529, loss: 3.128714, norm: 0.3107, time(ms): 792.72, token/sec:661376.49, hellaswag_acc: 0.2966
Step: 13530, loss: 3.096259, norm: 0.2945, time(ms): 791.85, token/sec:662104.12, hellaswag_acc: 0.2966
Step: 13531, loss: 3.204119, norm: 0.3130, time(ms): 786.87, token/sec:666295.78, hellaswag_acc: 0.2966
Step: 13532, loss: 3.159503, norm: 0.3060, time(ms): 786.64, token/sec:666491.06, hellaswag_acc: 0.2966
Step: 13533, loss: 3.152331, norm: 0.3069, time(ms): 791.93, token/sec:662036.95, hellaswag_acc: 0.2966
Step: 13534, loss: 3.089037, norm: 0.2814, time(ms): 795.24, token/sec:659282.40, hellaswag_acc: 0.2966
Step: 13535, loss: 3.113955, norm: 0.3046, time(ms): 795.00, token/sec:659482.29, hellaswag_acc: 0.2966
Step: 13536, loss: 3.124743, norm: 0.3226, time(ms): 791.27, token/sec:662589.11, hellaswag_acc: 0.2966
Step: 13537, loss: 3.109359, norm: 0.2893, time(ms): 800.73, token/sec:654758.83, hellaswag_acc: 0.2966
Step: 13538, loss: 3.144179, norm: 0.2978, time(ms): 803.95, token/sec:652141.35, hellaswag_acc: 0.2966
Step: 13539, loss: 3.107427, norm: 0.2815, time(ms): 795.64, token/sec:658952.48, hellaswag_acc: 0.2966
Step: 13540, loss: 3.176724, norm: 0.2899, time(ms): 796.28, token/sec:658423.71, hellaswag_acc: 0.2966
Step: 13541, loss: 3.095206, norm: 0.2538, time(ms): 790.98, token/sec:662833.16, hellaswag_acc: 0.2966
Step: 13542, loss: 3.064419, norm: 0.2782, time(ms): 799.73, token/sec:655578.08, hellaswag_acc: 0.2966
Step: 13543, loss: 3.128774, norm: 0.2562, time(ms): 791.38, token/sec:662495.89, hellaswag_acc: 0.2966
Step: 13544, loss: 3.111936, norm: 0.2815, time(ms): 791.82, token/sec:662126.85, hellaswag_acc: 0.2966
Step: 13545, loss: 3.087787, norm: 0.2599, time(ms): 786.24, token/sec:666832.62, hellaswag_acc: 0.2966
Step: 13546, loss: 3.071953, norm: 0.2705, time(ms): 791.96, token/sec:662012.63, hellaswag_acc: 0.2966
Step: 13547, loss: 3.116807, norm: 0.2787, time(ms): 789.52, token/sec:664060.36, hellaswag_acc: 0.2966
Step: 13548, loss: 3.109621, norm: 0.2820, time(ms): 790.04, token/sec:663623.48, hellaswag_acc: 0.2966
Step: 13549, loss: 3.147311, norm: 0.2741, time(ms): 789.68, token/sec:663923.42, hellaswag_acc: 0.2966
Step: 13550, loss: 3.103999, norm: 0.3211, time(ms): 793.75, token/sec:660518.09, hellaswag_acc: 0.2966
Step: 13551, loss: 3.099242, norm: 0.2918, time(ms): 794.96, token/sec:659515.52, hellaswag_acc: 0.2966
Step: 13552, loss: 3.186787, norm: 0.3261, time(ms): 790.02, token/sec:663642.31, hellaswag_acc: 0.2966
Step: 13553, loss: 3.047220, norm: 0.2834, time(ms): 790.69, token/sec:663077.20, hellaswag_acc: 0.2966
Step: 13554, loss: 3.063234, norm: 0.3124, time(ms): 795.85, token/sec:658776.39, hellaswag_acc: 0.2966
Step: 13555, loss: 3.080773, norm: 0.2831, time(ms): 799.07, token/sec:656124.21, hellaswag_acc: 0.2966
Step: 13556, loss: 3.081511, norm: 0.2910, time(ms): 802.74, token/sec:653120.45, hellaswag_acc: 0.2966
Step: 13557, loss: 3.060853, norm: 0.2707, time(ms): 796.65, token/sec:658119.85, hellaswag_acc: 0.2966
Step: 13558, loss: 3.135710, norm: 0.3059, time(ms): 794.08, token/sec:660243.42, hellaswag_acc: 0.2966
Step: 13559, loss: 3.047757, norm: 0.2762, time(ms): 790.33, token/sec:663379.05, hellaswag_acc: 0.2966
Step: 13560, loss: 3.049707, norm: 0.2849, time(ms): 793.67, token/sec:660589.52, hellaswag_acc: 0.2966
Step: 13561, loss: 3.065242, norm: 0.2872, time(ms): 790.33, token/sec:663376.64, hellaswag_acc: 0.2966
Step: 13562, loss: 3.048681, norm: 0.2671, time(ms): 791.42, token/sec:662465.75, hellaswag_acc: 0.2966
Step: 13563, loss: 3.034119, norm: 0.2800, time(ms): 800.70, token/sec:654787.69, hellaswag_acc: 0.2966
Step: 13564, loss: 3.133815, norm: 0.2775, time(ms): 799.88, token/sec:655454.78, hellaswag_acc: 0.2966
Step: 13565, loss: 3.196380, norm: 0.2965, time(ms): 794.95, token/sec:659521.45, hellaswag_acc: 0.2966
Step: 13566, loss: 3.084698, norm: 0.2760, time(ms): 807.28, token/sec:649451.30, hellaswag_acc: 0.2966
Step: 13567, loss: 3.064918, norm: 0.2729, time(ms): 792.76, token/sec:661348.64, hellaswag_acc: 0.2966
Step: 13568, loss: 3.062226, norm: 0.2719, time(ms): 801.95, token/sec:653763.35, hellaswag_acc: 0.2966
Step: 13569, loss: 3.101824, norm: 0.2830, time(ms): 804.76, token/sec:651483.69, hellaswag_acc: 0.2966
Step: 13570, loss: 3.148821, norm: 0.2810, time(ms): 782.44, token/sec:670071.30, hellaswag_acc: 0.2966
Step: 13571, loss: 3.056655, norm: 0.2674, time(ms): 792.83, token/sec:661289.77, hellaswag_acc: 0.2966
Step: 13572, loss: 3.139185, norm: 0.2933, time(ms): 793.56, token/sec:660674.67, hellaswag_acc: 0.2966
Step: 13573, loss: 3.172072, norm: 0.2963, time(ms): 792.75, token/sec:661356.40, hellaswag_acc: 0.2966
Step: 13574, loss: 3.049605, norm: 0.3347, time(ms): 788.24, token/sec:665137.36, hellaswag_acc: 0.2966
Step: 13575, loss: 3.131387, norm: 0.2976, time(ms): 792.49, token/sec:661568.70, hellaswag_acc: 0.2966
Step: 13576, loss: 3.134924, norm: 0.3157, time(ms): 792.65, token/sec:661437.36, hellaswag_acc: 0.2966
Step: 13577, loss: 3.119428, norm: 0.2822, time(ms): 799.80, token/sec:655522.77, hellaswag_acc: 0.2966
Step: 13578, loss: 3.172261, norm: 0.3105, time(ms): 795.18, token/sec:659331.42, hellaswag_acc: 0.2966
Step: 13579, loss: 3.067950, norm: 0.2715, time(ms): 792.40, token/sec:661648.52, hellaswag_acc: 0.2966
Step: 13580, loss: 3.174576, norm: 0.3562, time(ms): 786.65, token/sec:666479.54, hellaswag_acc: 0.2966
Step: 13581, loss: 3.117945, norm: 0.3434, time(ms): 790.65, token/sec:663113.79, hellaswag_acc: 0.2966
Step: 13582, loss: 3.144792, norm: 0.3043, time(ms): 794.31, token/sec:660057.34, hellaswag_acc: 0.2966
Step: 13583, loss: 3.106546, norm: 0.3025, time(ms): 801.80, token/sec:653889.91, hellaswag_acc: 0.2966
Step: 13584, loss: 3.140312, norm: 0.2748, time(ms): 801.57, token/sec:654077.59, hellaswag_acc: 0.2966
Step: 13585, loss: 3.079537, norm: 0.2900, time(ms): 799.72, token/sec:655593.33, hellaswag_acc: 0.2966
Step: 13586, loss: 3.154119, norm: 0.2659, time(ms): 796.03, token/sec:658626.83, hellaswag_acc: 0.2966
Step: 13587, loss: 3.118190, norm: 0.2806, time(ms): 795.39, token/sec:659161.85, hellaswag_acc: 0.2966
Step: 13588, loss: 3.067962, norm: 0.2840, time(ms): 807.66, token/sec:649147.43, hellaswag_acc: 0.2966
Step: 13589, loss: 3.027246, norm: 0.2892, time(ms): 799.59, token/sec:655699.86, hellaswag_acc: 0.2966
Step: 13590, loss: 3.091125, norm: 0.2885, time(ms): 793.44, token/sec:660780.08, hellaswag_acc: 0.2966
Step: 13591, loss: 3.013392, norm: 0.2767, time(ms): 803.36, token/sec:652615.53, hellaswag_acc: 0.2966
Step: 13592, loss: 3.141389, norm: 0.3308, time(ms): 801.98, token/sec:653743.33, hellaswag_acc: 0.2966
Step: 13593, loss: 3.147397, norm: 0.3266, time(ms): 801.65, token/sec:654013.59, hellaswag_acc: 0.2966
Step: 13594, loss: 3.110964, norm: 0.3163, time(ms): 790.97, token/sec:662840.16, hellaswag_acc: 0.2966
Step: 13595, loss: 3.001683, norm: 0.3121, time(ms): 805.55, token/sec:650843.53, hellaswag_acc: 0.2966
Step: 13596, loss: 3.132725, norm: 0.3113, time(ms): 803.26, token/sec:652701.92, hellaswag_acc: 0.2966
Step: 13597, loss: 3.106619, norm: 0.2796, time(ms): 790.95, token/sec:662856.74, hellaswag_acc: 0.2966
Step: 13598, loss: 3.091854, norm: 0.2851, time(ms): 800.37, token/sec:655053.93, hellaswag_acc: 0.2966
Step: 13599, loss: 3.073050, norm: 0.2834, time(ms): 805.63, token/sec:650782.66, hellaswag_acc: 0.2966
Step: 13600, loss: 3.164986, norm: 0.2999, time(ms): 803.65, token/sec:652379.71, hellaswag_acc: 0.2966
Step: 13601, loss: 3.157358, norm: 0.2972, time(ms): 784.44, token/sec:668360.58, hellaswag_acc: 0.2966
Step: 13602, loss: 3.129868, norm: 0.3333, time(ms): 789.76, token/sec:663855.88, hellaswag_acc: 0.2966
Step: 13603, loss: 3.094514, norm: 0.3018, time(ms): 796.44, token/sec:658286.92, hellaswag_acc: 0.2966
Step: 13604, loss: 3.160811, norm: 0.3400, time(ms): 790.76, token/sec:663016.62, hellaswag_acc: 0.2966
Step: 13605, loss: 3.025319, norm: 0.3831, time(ms): 794.56, token/sec:659850.96, hellaswag_acc: 0.2966
Step: 13606, loss: 3.119642, norm: 0.3107, time(ms): 794.45, token/sec:659941.06, hellaswag_acc: 0.2966
Step: 13607, loss: 3.191952, norm: 0.3028, time(ms): 803.02, token/sec:652892.99, hellaswag_acc: 0.2966
Step: 13608, loss: 3.098277, norm: 0.3039, time(ms): 804.04, token/sec:652069.61, hellaswag_acc: 0.2966
Step: 13609, loss: 3.145625, norm: 0.2772, time(ms): 790.81, token/sec:662978.84, hellaswag_acc: 0.2966
Step: 13610, loss: 3.117190, norm: 0.2728, time(ms): 798.39, token/sec:656681.84, hellaswag_acc: 0.2966
Step: 13611, loss: 3.120146, norm: 0.2990, time(ms): 791.62, token/sec:662299.75, hellaswag_acc: 0.2966
Step: 13612, loss: 3.099704, norm: 0.2886, time(ms): 788.90, token/sec:664582.55, hellaswag_acc: 0.2966
Step: 13613, loss: 3.107107, norm: 0.2794, time(ms): 792.66, token/sec:661428.41, hellaswag_acc: 0.2966
Step: 13614, loss: 3.152806, norm: 0.4345, time(ms): 789.29, token/sec:664252.72, hellaswag_acc: 0.2966
Step: 13615, loss: 3.086265, norm: 0.2713, time(ms): 790.66, token/sec:663099.59, hellaswag_acc: 0.2966
Step: 13616, loss: 3.186470, norm: 0.3118, time(ms): 790.50, token/sec:663237.19, hellaswag_acc: 0.2966
Step: 13617, loss: 3.095902, norm: 0.2746, time(ms): 803.07, token/sec:652858.10, hellaswag_acc: 0.2966
Step: 13618, loss: 3.116954, norm: 0.2994, time(ms): 802.13, token/sec:653621.30, hellaswag_acc: 0.2966
Step: 13619, loss: 3.146741, norm: 0.2820, time(ms): 793.70, token/sec:660564.32, hellaswag_acc: 0.2966
Step: 13620, loss: 3.063182, norm: 0.2807, time(ms): 804.44, token/sec:651745.13, hellaswag_acc: 0.2966
Step: 13621, loss: 3.061049, norm: 0.2685, time(ms): 801.20, token/sec:654377.34, hellaswag_acc: 0.2966
Step: 13622, loss: 3.101532, norm: 0.2756, time(ms): 797.36, token/sec:657526.95, hellaswag_acc: 0.2966
Step: 13623, loss: 3.085731, norm: 0.2635, time(ms): 800.74, token/sec:654757.86, hellaswag_acc: 0.2966
Step: 13624, loss: 3.034761, norm: 0.2878, time(ms): 801.12, token/sec:654441.99, hellaswag_acc: 0.2966
Step: 13625, loss: 3.069578, norm: 0.2867, time(ms): 797.17, token/sec:657689.58, hellaswag_acc: 0.2966
Step: 13626, loss: 3.056082, norm: 0.2597, time(ms): 801.35, token/sec:654253.12, hellaswag_acc: 0.2966
Step: 13627, loss: 3.049881, norm: 0.2960, time(ms): 795.77, token/sec:658842.11, hellaswag_acc: 0.2966
Step: 13628, loss: 3.048700, norm: 0.2822, time(ms): 797.72, token/sec:657232.37, hellaswag_acc: 0.2966
Step: 13629, loss: 3.130494, norm: 0.2615, time(ms): 805.93, token/sec:650540.28, hellaswag_acc: 0.2966
Step: 13630, loss: 3.054958, norm: 0.2758, time(ms): 801.82, token/sec:653875.52, hellaswag_acc: 0.2966
Step: 13631, loss: 3.061207, norm: 0.2623, time(ms): 783.99, token/sec:668742.49, hellaswag_acc: 0.2966
Step: 13632, loss: 3.116956, norm: 0.2954, time(ms): 792.04, token/sec:661948.47, hellaswag_acc: 0.2966
Step: 13633, loss: 2.993033, norm: 0.2582, time(ms): 794.35, token/sec:660020.49, hellaswag_acc: 0.2966
Step: 13634, loss: 3.065074, norm: 0.2502, time(ms): 792.79, token/sec:661323.18, hellaswag_acc: 0.2966
Step: 13635, loss: 3.098849, norm: 0.2612, time(ms): 794.13, token/sec:660202.79, hellaswag_acc: 0.2966
Step: 13636, loss: 3.102834, norm: 0.2936, time(ms): 796.89, token/sec:657914.29, hellaswag_acc: 0.2966
Step: 13637, loss: 3.135583, norm: 0.2956, time(ms): 799.50, token/sec:655768.50, hellaswag_acc: 0.2966
Step: 13638, loss: 3.140203, norm: 0.2879, time(ms): 805.00, token/sec:651290.74, hellaswag_acc: 0.2966
Step: 13639, loss: 3.115992, norm: 0.2698, time(ms): 790.02, token/sec:663635.90, hellaswag_acc: 0.2966
Step: 13640, loss: 3.095724, norm: 0.3227, time(ms): 797.62, token/sec:657315.47, hellaswag_acc: 0.2966
Step: 13641, loss: 3.103074, norm: 0.2843, time(ms): 790.61, token/sec:663140.19, hellaswag_acc: 0.2966
Step: 13642, loss: 3.113400, norm: 0.2949, time(ms): 801.80, token/sec:653890.88, hellaswag_acc: 0.2966
Step: 13643, loss: 3.085649, norm: 0.2763, time(ms): 786.25, token/sec:666825.13, hellaswag_acc: 0.2966
Step: 13644, loss: 3.115860, norm: 0.2857, time(ms): 784.33, token/sec:668449.76, hellaswag_acc: 0.2966
Step: 13645, loss: 3.140622, norm: 0.2685, time(ms): 796.57, token/sec:658184.66, hellaswag_acc: 0.2966
Step: 13646, loss: 3.099813, norm: 0.2727, time(ms): 792.29, token/sec:661739.51, hellaswag_acc: 0.2966
Step: 13647, loss: 3.117502, norm: 0.2843, time(ms): 788.24, token/sec:665138.36, hellaswag_acc: 0.2966
Step: 13648, loss: 3.126190, norm: 0.2623, time(ms): 792.63, token/sec:661451.29, hellaswag_acc: 0.2966
Step: 13649, loss: 3.110782, norm: 0.2735, time(ms): 791.96, token/sec:662011.04, hellaswag_acc: 0.2966
Step: 13650, loss: 3.089561, norm: 0.2796, time(ms): 795.45, token/sec:659106.14, hellaswag_acc: 0.2966
Step: 13651, loss: 3.128483, norm: 0.2608, time(ms): 791.71, token/sec:662220.57, hellaswag_acc: 0.2966
Step: 13652, loss: 3.114218, norm: 0.2547, time(ms): 795.76, token/sec:658850.60, hellaswag_acc: 0.2966
Step: 13653, loss: 3.090728, norm: 0.2819, time(ms): 795.47, token/sec:659088.16, hellaswag_acc: 0.2966
Step: 13654, loss: 3.077817, norm: 0.2817, time(ms): 802.08, token/sec:653659.19, hellaswag_acc: 0.2966
Step: 13655, loss: 3.102185, norm: 0.2783, time(ms): 803.36, token/sec:652621.92, hellaswag_acc: 0.2966
Step: 13656, loss: 3.102908, norm: 0.3005, time(ms): 793.96, token/sec:660346.13, hellaswag_acc: 0.2966
Step: 13657, loss: 3.061181, norm: 0.2660, time(ms): 797.12, token/sec:657731.87, hellaswag_acc: 0.2966
Step: 13658, loss: 3.110772, norm: 0.2996, time(ms): 805.77, token/sec:650670.21, hellaswag_acc: 0.2966
Step: 13659, loss: 3.039366, norm: 0.3142, time(ms): 801.68, token/sec:653989.67, hellaswag_acc: 0.2966
Step: 13660, loss: 3.088571, norm: 0.2838, time(ms): 792.47, token/sec:661586.81, hellaswag_acc: 0.2966
Step: 13661, loss: 3.091223, norm: 0.2807, time(ms): 804.35, token/sec:651811.97, hellaswag_acc: 0.2966
Step: 13662, loss: 3.076319, norm: 0.2864, time(ms): 803.92, token/sec:652165.34, hellaswag_acc: 0.2966
Step: 13663, loss: 3.034534, norm: 0.2669, time(ms): 800.70, token/sec:654790.03, hellaswag_acc: 0.2966
Step: 13664, loss: 3.116249, norm: 0.3209, time(ms): 789.71, token/sec:663895.96, hellaswag_acc: 0.2966
Step: 13665, loss: 3.059991, norm: 0.2689, time(ms): 792.92, token/sec:661211.63, hellaswag_acc: 0.2966
Step: 13666, loss: 3.072388, norm: 0.2956, time(ms): 794.57, token/sec:659836.50, hellaswag_acc: 0.2966
Step: 13667, loss: 3.098149, norm: 0.2643, time(ms): 794.48, token/sec:659912.94, hellaswag_acc: 0.2966
Step: 13668, loss: 3.101340, norm: 0.3054, time(ms): 803.03, token/sec:652889.50, hellaswag_acc: 0.2966
Step: 13669, loss: 3.078219, norm: 0.2583, time(ms): 800.91, token/sec:654616.35, hellaswag_acc: 0.2966
Step: 13670, loss: 3.136271, norm: 0.2835, time(ms): 797.52, token/sec:657394.66, hellaswag_acc: 0.2966
Step: 13671, loss: 3.182192, norm: 0.2988, time(ms): 795.47, token/sec:659088.16, hellaswag_acc: 0.2966
Step: 13672, loss: 3.166844, norm: 0.2892, time(ms): 790.52, token/sec:663221.79, hellaswag_acc: 0.2966
Step: 13673, loss: 3.169905, norm: 0.2950, time(ms): 792.85, token/sec:661269.29, hellaswag_acc: 0.2966
Step: 13674, loss: 3.183551, norm: 0.2997, time(ms): 788.89, token/sec:664590.79, hellaswag_acc: 0.2966
Step: 13675, loss: 3.156518, norm: 0.2723, time(ms): 789.29, token/sec:664255.53, hellaswag_acc: 0.2966
Step: 13676, loss: 3.129295, norm: 0.3006, time(ms): 807.59, token/sec:649203.58, hellaswag_acc: 0.2966
Step: 13677, loss: 3.092106, norm: 0.2902, time(ms): 788.94, token/sec:664543.19, hellaswag_acc: 0.2966
Step: 13678, loss: 3.120844, norm: 0.3045, time(ms): 791.89, token/sec:662074.82, hellaswag_acc: 0.2966
Step: 13679, loss: 3.095201, norm: 0.3007, time(ms): 790.51, token/sec:663231.59, hellaswag_acc: 0.2966
Step: 13680, loss: 3.171238, norm: 0.3146, time(ms): 794.58, token/sec:659826.41, hellaswag_acc: 0.2966
Step: 13681, loss: 3.040658, norm: 0.2777, time(ms): 792.49, token/sec:661571.48, hellaswag_acc: 0.2966
Step: 13682, loss: 3.094980, norm: 0.2994, time(ms): 796.34, token/sec:658368.32, hellaswag_acc: 0.2966
Step: 13683, loss: 3.131499, norm: 0.2702, time(ms): 800.30, token/sec:655115.79, hellaswag_acc: 0.2966
Step: 13684, loss: 3.100467, norm: 0.2785, time(ms): 799.45, token/sec:655808.59, hellaswag_acc: 0.2966
Step: 13685, loss: 3.119724, norm: 0.2791, time(ms): 800.02, token/sec:655345.20, hellaswag_acc: 0.2966
Step: 13686, loss: 3.147799, norm: 0.2873, time(ms): 802.17, token/sec:653590.03, hellaswag_acc: 0.2966
Step: 13687, loss: 3.114023, norm: 0.2919, time(ms): 794.99, token/sec:659489.81, hellaswag_acc: 0.2966
Step: 13688, loss: 3.109732, norm: 0.2842, time(ms): 798.56, token/sec:656538.52, hellaswag_acc: 0.2966
Step: 13689, loss: 3.115392, norm: 0.2763, time(ms): 806.70, token/sec:649916.18, hellaswag_acc: 0.2966
Step: 13690, loss: 3.113222, norm: 0.2940, time(ms): 798.57, token/sec:656534.80, hellaswag_acc: 0.2966
Step: 13691, loss: 3.069181, norm: 0.2765, time(ms): 792.73, token/sec:661367.74, hellaswag_acc: 0.2966
Step: 13692, loss: 3.103807, norm: 0.2938, time(ms): 791.94, token/sec:662027.38, hellaswag_acc: 0.2966
Step: 13693, loss: 3.122803, norm: 0.2947, time(ms): 795.68, token/sec:658917.13, hellaswag_acc: 0.2966
Step: 13694, loss: 3.075437, norm: 0.2891, time(ms): 789.47, token/sec:664102.07, hellaswag_acc: 0.2966
Step: 13695, loss: 3.034444, norm: 0.2957, time(ms): 791.18, token/sec:662668.97, hellaswag_acc: 0.2966
Step: 13696, loss: 3.055893, norm: 0.2782, time(ms): 788.70, token/sec:664750.30, hellaswag_acc: 0.2966
Step: 13697, loss: 3.132342, norm: 0.2987, time(ms): 791.01, token/sec:662810.79, hellaswag_acc: 0.2966
Step: 13698, loss: 3.052709, norm: 0.2728, time(ms): 797.49, token/sec:657422.96, hellaswag_acc: 0.2966
Step: 13699, loss: 3.077611, norm: 0.2809, time(ms): 798.45, token/sec:656628.31, hellaswag_acc: 0.2966
Step: 13700, loss: 3.010716, norm: 0.2674, time(ms): 803.34, token/sec:652632.57, hellaswag_acc: 0.2966
Step: 13701, loss: 3.079934, norm: 0.3041, time(ms): 794.09, token/sec:660241.24, hellaswag_acc: 0.2966
Step: 13702, loss: 3.071660, norm: 0.2545, time(ms): 803.57, token/sec:652447.84, hellaswag_acc: 0.2966
Step: 13703, loss: 3.078659, norm: 0.2932, time(ms): 802.24, token/sec:653527.09, hellaswag_acc: 0.2966
Step: 13704, loss: 3.118634, norm: 0.2571, time(ms): 789.84, token/sec:663787.94, hellaswag_acc: 0.2966
Step: 13705, loss: 3.140474, norm: 0.3097, time(ms): 791.28, token/sec:662586.31, hellaswag_acc: 0.2966
Step: 13706, loss: 3.066348, norm: 0.2740, time(ms): 789.24, token/sec:664294.46, hellaswag_acc: 0.2966
Step: 13707, loss: 3.114044, norm: 0.3312, time(ms): 790.84, token/sec:662952.66, hellaswag_acc: 0.2966
Step: 13708, loss: 3.158036, norm: 0.2888, time(ms): 795.89, token/sec:658745.60, hellaswag_acc: 0.2966
Step: 13709, loss: 3.090700, norm: 0.2849, time(ms): 795.04, token/sec:659450.05, hellaswag_acc: 0.2966
Step: 13710, loss: 3.137905, norm: 0.2802, time(ms): 803.56, token/sec:652454.04, hellaswag_acc: 0.2966
Step: 13711, loss: 3.146389, norm: 0.3053, time(ms): 803.85, token/sec:652223.37, hellaswag_acc: 0.2966
Step: 13712, loss: 3.122750, norm: 0.3248, time(ms): 785.37, token/sec:667564.41, hellaswag_acc: 0.2966
Step: 13713, loss: 3.145274, norm: 0.2887, time(ms): 789.43, token/sec:664132.76, hellaswag_acc: 0.2966
Step: 13714, loss: 3.103501, norm: 0.2715, time(ms): 797.88, token/sec:657102.55, hellaswag_acc: 0.2966
Step: 13715, loss: 3.125948, norm: 0.2955, time(ms): 1318.64, token/sec:397597.31, hellaswag_acc: 0.2966
Step: 13716, loss: 3.123865, norm: 0.2882, time(ms): 766.66, token/sec:683860.73, hellaswag_acc: 0.2966
Step: 13717, loss: 3.112782, norm: 0.2677, time(ms): 785.38, token/sec:667559.55, hellaswag_acc: 0.2966
Step: 13718, loss: 3.180152, norm: 0.2785, time(ms): 797.87, token/sec:657109.82, hellaswag_acc: 0.2966
Step: 13719, loss: 3.118240, norm: 0.2924, time(ms): 789.88, token/sec:663752.68, hellaswag_acc: 0.2966
Step: 13720, loss: 3.216994, norm: 0.3149, time(ms): 787.38, token/sec:665864.42, hellaswag_acc: 0.2966
Step: 13721, loss: 3.103090, norm: 0.2923, time(ms): 788.26, token/sec:665124.68, hellaswag_acc: 0.2966
Step: 13722, loss: 3.188075, norm: 0.3204, time(ms): 791.72, token/sec:662210.80, hellaswag_acc: 0.2966
Step: 13723, loss: 3.096272, norm: 0.2950, time(ms): 791.31, token/sec:662559.16, hellaswag_acc: 0.2966
Step: 13724, loss: 3.120517, norm: 0.3087, time(ms): 793.99, token/sec:660319.56, hellaswag_acc: 0.2966
Step: 13725, loss: 3.136843, norm: 0.3036, time(ms): 788.96, token/sec:664532.95, hellaswag_acc: 0.2966
Step: 13726, loss: 3.082442, norm: 0.2739, time(ms): 803.21, token/sec:652743.77, hellaswag_acc: 0.2966
Step: 13727, loss: 3.096046, norm: 0.2975, time(ms): 792.14, token/sec:661862.80, hellaswag_acc: 0.2966
Step: 13728, loss: 3.132454, norm: 0.2687, time(ms): 798.02, token/sec:656982.40, hellaswag_acc: 0.2966
Step: 13729, loss: 3.023790, norm: 0.2678, time(ms): 788.89, token/sec:664589.38, hellaswag_acc: 0.2966
Step: 13730, loss: 3.130868, norm: 0.2842, time(ms): 791.72, token/sec:662210.40, hellaswag_acc: 0.2966
Step: 13731, loss: 3.156774, norm: 0.3237, time(ms): 794.72, token/sec:659716.54, hellaswag_acc: 0.2966
Step: 13732, loss: 3.092744, norm: 0.3362, time(ms): 789.03, token/sec:664470.90, hellaswag_acc: 0.2966
Step: 13733, loss: 3.120961, norm: 0.2804, time(ms): 804.68, token/sec:651547.77, hellaswag_acc: 0.2966
Step: 13734, loss: 3.080200, norm: 0.2841, time(ms): 796.62, token/sec:658138.37, hellaswag_acc: 0.2966
Step: 13735, loss: 3.111604, norm: 0.2719, time(ms): 801.11, token/sec:654449.00, hellaswag_acc: 0.2966
Step: 13736, loss: 3.097939, norm: 0.2950, time(ms): 802.25, token/sec:653524.96, hellaswag_acc: 0.2966
Step: 13737, loss: 3.031913, norm: 0.2602, time(ms): 797.98, token/sec:657015.38, hellaswag_acc: 0.2966
Step: 13738, loss: 3.087731, norm: 0.2959, time(ms): 799.92, token/sec:655424.30, hellaswag_acc: 0.2966
Step: 13739, loss: 3.017059, norm: 0.2835, time(ms): 793.71, token/sec:660554.40, hellaswag_acc: 0.2966
Step: 13740, loss: 2.981848, norm: 0.2789, time(ms): 807.52, token/sec:649259.35, hellaswag_acc: 0.2966
Step: 13741, loss: 3.047366, norm: 0.2816, time(ms): 799.46, token/sec:655804.68, hellaswag_acc: 0.2966
Step: 13742, loss: 3.080027, norm: 0.2772, time(ms): 795.72, token/sec:658884.56, hellaswag_acc: 0.2966
Step: 13743, loss: 3.058639, norm: 0.2930, time(ms): 798.34, token/sec:656724.40, hellaswag_acc: 0.2966
Step: 13744, loss: 3.062469, norm: 0.2684, time(ms): 805.65, token/sec:650761.29, hellaswag_acc: 0.2966
Step: 13745, loss: 3.045083, norm: 0.2825, time(ms): 799.12, token/sec:656078.60, hellaswag_acc: 0.2966
Step: 13746, loss: 3.126309, norm: 0.3531, time(ms): 799.07, token/sec:656122.25, hellaswag_acc: 0.2966
Step: 13747, loss: 3.067004, norm: 0.3361, time(ms): 798.75, token/sec:656382.92, hellaswag_acc: 0.2966
Step: 13748, loss: 3.078020, norm: 0.2964, time(ms): 802.88, token/sec:653011.84, hellaswag_acc: 0.2966
Step: 13749, loss: 3.106656, norm: 0.3048, time(ms): 799.03, token/sec:656152.21, hellaswag_acc: 0.2966
rank 0 sample 0: Hello, I'm a language model, and I'll be the first, thank you.
Last night a pair of students came up at my computer lab for
rank 0 sample 1: Hello, I'm a language model, so why do I care about that?'
The big, I don't understand, I love that a few days ago
rank 0 sample 2: Hello, I'm a language model, so I haven't taken on the importance of my experience in building an app. This is the first time I have met
rank 0 sample 3: Hello, I'm a language model, which is a set of rules for constructing and reporting code. So we use it when we declare a property of an immutable
rank 1 sample 0: Hello, I'm a language model, my language model is English. I grew up reading the news regularly, and I have to be sure that the news is
rank 1 sample 1: Hello, I'm a language model, not an object model. I've just said that in principle, your model must, because the actual object model is the
rank 1 sample 2: Hello, I'm a language model, but of course there are some things that I'm not very happy with:
- I have the following: 'H
rank 1 sample 3: Hello, I'm a language model, and I'm trying to improve on how, for example, if you don't have native LST, you could use
Step: 13750, loss: 3.149658, norm: 0.2913, time(ms): 3827.07, token/sec:136994.49, val_loss: 3.1202, hellaswag_acc: 0.2966
Step: 13751, loss: 3.144488, norm: 0.2886, time(ms): 785.16, token/sec:667745.02, hellaswag_acc: 0.2966
Step: 13752, loss: 3.137164, norm: 0.2928, time(ms): 791.30, token/sec:662563.15, hellaswag_acc: 0.2966
Step: 13753, loss: 3.064961, norm: 0.2911, time(ms): 795.21, token/sec:659306.32, hellaswag_acc: 0.2966
Step: 13754, loss: 3.172767, norm: 0.2814, time(ms): 797.83, token/sec:657139.27, hellaswag_acc: 0.2966
Step: 13755, loss: 3.147265, norm: 0.2760, time(ms): 793.91, token/sec:660385.59, hellaswag_acc: 0.2966
Step: 13756, loss: 3.152570, norm: 0.2898, time(ms): 805.81, token/sec:650637.29, hellaswag_acc: 0.2966
Step: 13757, loss: 3.080328, norm: 0.2803, time(ms): 802.68, token/sec:653168.37, hellaswag_acc: 0.2966
Step: 13758, loss: 3.059055, norm: 0.2850, time(ms): 791.69, token/sec:662235.52, hellaswag_acc: 0.2966
Step: 13759, loss: 3.219247, norm: 0.3176, time(ms): 802.39, token/sec:653411.94, hellaswag_acc: 0.2966
Step: 13760, loss: 3.095556, norm: 0.3141, time(ms): 803.57, token/sec:652451.13, hellaswag_acc: 0.2966
Step: 13761, loss: 3.124724, norm: 0.3082, time(ms): 797.08, token/sec:657764.14, hellaswag_acc: 0.2966
Step: 13762, loss: 3.091563, norm: 0.2797, time(ms): 796.37, token/sec:658350.77, hellaswag_acc: 0.2966
Step: 13763, loss: 3.071486, norm: 0.2922, time(ms): 802.53, token/sec:653292.95, hellaswag_acc: 0.2966
Step: 13764, loss: 3.096729, norm: 0.2889, time(ms): 804.62, token/sec:651594.88, hellaswag_acc: 0.2966
Step: 13765, loss: 3.115513, norm: 0.2877, time(ms): 791.28, token/sec:662579.52, hellaswag_acc: 0.2966
Step: 13766, loss: 3.074757, norm: 0.2683, time(ms): 791.94, token/sec:662026.39, hellaswag_acc: 0.2966
Step: 13767, loss: 3.086359, norm: 0.2877, time(ms): 793.09, token/sec:661069.31, hellaswag_acc: 0.2966
Step: 13768, loss: 3.054740, norm: 0.2567, time(ms): 792.65, token/sec:661435.37, hellaswag_acc: 0.2966
Step: 13769, loss: 3.060206, norm: 0.2705, time(ms): 790.29, token/sec:663409.06, hellaswag_acc: 0.2966
Step: 13770, loss: 3.054981, norm: 0.2560, time(ms): 796.35, token/sec:658362.21, hellaswag_acc: 0.2966
Step: 13771, loss: 3.086469, norm: 0.2745, time(ms): 797.26, token/sec:657614.64, hellaswag_acc: 0.2966
Step: 13772, loss: 3.051988, norm: 0.2609, time(ms): 805.01, token/sec:651278.20, hellaswag_acc: 0.2966
Step: 13773, loss: 3.024433, norm: 0.2785, time(ms): 798.19, token/sec:656845.43, hellaswag_acc: 0.2966
Step: 13774, loss: 3.047293, norm: 0.2534, time(ms): 798.37, token/sec:656694.00, hellaswag_acc: 0.2966
Step: 13775, loss: 3.045718, norm: 0.2762, time(ms): 797.13, token/sec:657717.32, hellaswag_acc: 0.2966
Step: 13776, loss: 2.981919, norm: 0.2639, time(ms): 797.74, token/sec:657217.63, hellaswag_acc: 0.2966
Step: 13777, loss: 3.068078, norm: 0.2499, time(ms): 791.98, token/sec:661993.90, hellaswag_acc: 0.2966
Step: 13778, loss: 3.047746, norm: 0.2681, time(ms): 786.63, token/sec:666501.76, hellaswag_acc: 0.2966
Step: 13779, loss: 3.040279, norm: 0.2586, time(ms): 789.01, token/sec:664488.57, hellaswag_acc: 0.2966
Step: 13780, loss: 3.038473, norm: 0.2577, time(ms): 791.04, token/sec:662785.22, hellaswag_acc: 0.2966
Step: 13781, loss: 3.103937, norm: 0.2708, time(ms): 790.83, token/sec:662959.66, hellaswag_acc: 0.2966
Step: 13782, loss: 3.050805, norm: 0.2626, time(ms): 789.00, token/sec:664497.00, hellaswag_acc: 0.2966
Step: 13783, loss: 3.055629, norm: 0.2678, time(ms): 795.90, token/sec:658737.91, hellaswag_acc: 0.2966
Step: 13784, loss: 3.138628, norm: 0.2601, time(ms): 792.77, token/sec:661338.30, hellaswag_acc: 0.2966
Step: 13785, loss: 3.145726, norm: 0.2524, time(ms): 790.76, token/sec:663017.42, hellaswag_acc: 0.2966
Step: 13786, loss: 3.135801, norm: 0.2820, time(ms): 790.52, token/sec:663218.99, hellaswag_acc: 0.2966
Step: 13787, loss: 3.136424, norm: 0.2780, time(ms): 791.69, token/sec:662238.12, hellaswag_acc: 0.2966
Step: 13788, loss: 3.178312, norm: 0.2728, time(ms): 803.62, token/sec:652404.87, hellaswag_acc: 0.2966
Step: 13789, loss: 3.129163, norm: 0.2711, time(ms): 802.20, token/sec:653560.31, hellaswag_acc: 0.2966
Step: 13790, loss: 3.119152, norm: 0.2993, time(ms): 797.78, token/sec:657182.28, hellaswag_acc: 0.2966
Step: 13791, loss: 3.130501, norm: 0.2937, time(ms): 796.89, token/sec:657919.41, hellaswag_acc: 0.2966
Step: 13792, loss: 3.161822, norm: 0.2898, time(ms): 802.34, token/sec:653446.11, hellaswag_acc: 0.2966
Step: 13793, loss: 3.100075, norm: 0.3099, time(ms): 799.61, token/sec:655680.90, hellaswag_acc: 0.2966
Step: 13794, loss: 3.127711, norm: 0.2813, time(ms): 802.67, token/sec:653181.95, hellaswag_acc: 0.2966
Step: 13795, loss: 3.095125, norm: 0.3145, time(ms): 794.66, token/sec:659763.06, hellaswag_acc: 0.2966
Step: 13796, loss: 3.119160, norm: 0.2791, time(ms): 802.99, token/sec:652917.23, hellaswag_acc: 0.2966
Step: 13797, loss: 3.099167, norm: 0.2863, time(ms): 800.03, token/sec:655335.04, hellaswag_acc: 0.2966
Step: 13798, loss: 3.125988, norm: 0.2887, time(ms): 799.62, token/sec:655667.41, hellaswag_acc: 0.2966
Step: 13799, loss: 3.108634, norm: 0.3037, time(ms): 799.78, token/sec:655542.51, hellaswag_acc: 0.2966
Step: 13800, loss: 3.105256, norm: 0.3442, time(ms): 800.27, token/sec:655136.87, hellaswag_acc: 0.2966
Step: 13801, loss: 3.103041, norm: 0.2978, time(ms): 801.58, token/sec:654068.25, hellaswag_acc: 0.2966
Step: 13802, loss: 3.089170, norm: 0.2978, time(ms): 794.26, token/sec:660096.57, hellaswag_acc: 0.2966
Step: 13803, loss: 3.122352, norm: 0.3016, time(ms): 799.45, token/sec:655809.96, hellaswag_acc: 0.2966
Step: 13804, loss: 3.052683, norm: 0.2889, time(ms): 801.00, token/sec:654544.84, hellaswag_acc: 0.2966
Step: 13805, loss: 3.080710, norm: 0.2690, time(ms): 805.35, token/sec:651007.50, hellaswag_acc: 0.2966
Step: 13806, loss: 3.077158, norm: 0.3079, time(ms): 791.50, token/sec:662397.10, hellaswag_acc: 0.2966
Step: 13807, loss: 3.052467, norm: 0.2699, time(ms): 793.70, token/sec:660560.55, hellaswag_acc: 0.2966
Step: 13808, loss: 3.027165, norm: 0.2989, time(ms): 791.29, token/sec:662576.73, hellaswag_acc: 0.2966
Step: 13809, loss: 3.044930, norm: 0.2838, time(ms): 797.99, token/sec:657013.03, hellaswag_acc: 0.2966
Step: 13810, loss: 3.009679, norm: 0.2620, time(ms): 801.08, token/sec:654477.83, hellaswag_acc: 0.2966
Step: 13811, loss: 3.040356, norm: 0.2752, time(ms): 795.71, token/sec:658894.03, hellaswag_acc: 0.2966
Step: 13812, loss: 3.061903, norm: 0.2803, time(ms): 799.80, token/sec:655523.17, hellaswag_acc: 0.2966
Step: 13813, loss: 3.047871, norm: 0.2790, time(ms): 791.89, token/sec:662073.03, hellaswag_acc: 0.2966
Step: 13814, loss: 3.081308, norm: 0.3039, time(ms): 790.93, token/sec:662872.72, hellaswag_acc: 0.2966
Step: 13815, loss: 3.053042, norm: 0.3026, time(ms): 789.03, token/sec:664472.71, hellaswag_acc: 0.2966
Step: 13816, loss: 3.029339, norm: 0.3078, time(ms): 790.08, token/sec:663589.04, hellaswag_acc: 0.2966
Step: 13817, loss: 3.014842, norm: 0.3112, time(ms): 803.69, token/sec:652351.65, hellaswag_acc: 0.2966
Step: 13818, loss: 3.144655, norm: 0.3068, time(ms): 802.20, token/sec:653565.94, hellaswag_acc: 0.2966
Step: 13819, loss: 3.097330, norm: 0.3340, time(ms): 792.61, token/sec:661467.60, hellaswag_acc: 0.2966
Step: 13820, loss: 3.168752, norm: 0.3248, time(ms): 805.07, token/sec:651232.30, hellaswag_acc: 0.2966
Step: 13821, loss: 3.135426, norm: 0.2883, time(ms): 796.10, token/sec:658573.77, hellaswag_acc: 0.2966
Step: 13822, loss: 3.140600, norm: 0.2961, time(ms): 804.03, token/sec:652074.45, hellaswag_acc: 0.2966
Step: 13823, loss: 3.134815, norm: 0.3262, time(ms): 794.71, token/sec:659725.45, hellaswag_acc: 0.2966
Step: 13824, loss: 3.082857, norm: 0.3039, time(ms): 804.75, token/sec:651494.11, hellaswag_acc: 0.2966
Step: 13825, loss: 3.120075, norm: 0.3262, time(ms): 793.99, token/sec:660322.53, hellaswag_acc: 0.2966
Step: 13826, loss: 3.043057, norm: 0.2841, time(ms): 806.76, token/sec:649865.86, hellaswag_acc: 0.2966
Step: 13827, loss: 3.122848, norm: 0.3204, time(ms): 797.74, token/sec:657213.12, hellaswag_acc: 0.2966
Step: 13828, loss: 3.116856, norm: 0.3122, time(ms): 790.35, token/sec:663364.24, hellaswag_acc: 0.2966
Step: 13829, loss: 3.106097, norm: 0.3208, time(ms): 790.07, token/sec:663600.85, hellaswag_acc: 0.2966
Step: 13830, loss: 3.098595, norm: 0.2942, time(ms): 792.73, token/sec:661366.54, hellaswag_acc: 0.2966
Step: 13831, loss: 3.078975, norm: 0.3381, time(ms): 789.75, token/sec:663863.49, hellaswag_acc: 0.2966
Step: 13832, loss: 3.072370, norm: 0.3137, time(ms): 792.55, token/sec:661523.72, hellaswag_acc: 0.2966
Step: 13833, loss: 3.089450, norm: 0.2925, time(ms): 800.14, token/sec:655246.19, hellaswag_acc: 0.2966
Step: 13834, loss: 3.151670, norm: 0.3070, time(ms): 804.16, token/sec:651970.43, hellaswag_acc: 0.2966
Step: 13835, loss: 3.097728, norm: 0.3016, time(ms): 801.43, token/sec:654189.87, hellaswag_acc: 0.2966
Step: 13836, loss: 3.138294, norm: 0.3135, time(ms): 790.51, token/sec:663231.19, hellaswag_acc: 0.2966
Step: 13837, loss: 3.096148, norm: 0.2881, time(ms): 801.28, token/sec:654316.59, hellaswag_acc: 0.2966
Step: 13838, loss: 3.105470, norm: 0.2926, time(ms): 799.55, token/sec:655731.15, hellaswag_acc: 0.2966
Step: 13839, loss: 3.095563, norm: 0.2805, time(ms): 793.52, token/sec:660708.41, hellaswag_acc: 0.2966
Step: 13840, loss: 3.072863, norm: 0.2767, time(ms): 792.50, token/sec:661562.73, hellaswag_acc: 0.2966
Step: 13841, loss: 3.009722, norm: 0.2837, time(ms): 797.71, token/sec:657238.45, hellaswag_acc: 0.2966
Step: 13842, loss: 3.112835, norm: 0.2818, time(ms): 799.16, token/sec:656051.98, hellaswag_acc: 0.2966
Step: 13843, loss: 2.982435, norm: 0.2681, time(ms): 803.59, token/sec:652432.36, hellaswag_acc: 0.2966
Step: 13844, loss: 3.037794, norm: 0.2725, time(ms): 791.45, token/sec:662439.61, hellaswag_acc: 0.2966
Step: 13845, loss: 3.042732, norm: 0.2629, time(ms): 791.59, token/sec:662319.10, hellaswag_acc: 0.2966
Step: 13846, loss: 3.053096, norm: 0.2580, time(ms): 792.09, token/sec:661908.42, hellaswag_acc: 0.2966
Step: 13847, loss: 2.969686, norm: 0.2791, time(ms): 791.00, token/sec:662813.78, hellaswag_acc: 0.2966
Step: 13848, loss: 3.005399, norm: 0.3089, time(ms): 794.36, token/sec:660013.55, hellaswag_acc: 0.2966
Step: 13849, loss: 3.075295, norm: 0.2889, time(ms): 798.02, token/sec:656983.58, hellaswag_acc: 0.2966
Step: 13850, loss: 3.069313, norm: 0.3081, time(ms): 801.19, token/sec:654388.43, hellaswag_acc: 0.2966
Step: 13851, loss: 3.063495, norm: 0.2871, time(ms): 788.70, token/sec:664745.48, hellaswag_acc: 0.2966
Step: 13852, loss: 3.031826, norm: 0.3090, time(ms): 791.27, token/sec:662589.11, hellaswag_acc: 0.2966
Step: 13853, loss: 3.025816, norm: 0.3470, time(ms): 791.53, token/sec:662376.15, hellaswag_acc: 0.2966
Step: 13854, loss: 3.222253, norm: 0.3166, time(ms): 787.27, token/sec:665955.97, hellaswag_acc: 0.2966
Step: 13855, loss: 3.159478, norm: 0.3662, time(ms): 794.51, token/sec:659890.76, hellaswag_acc: 0.2966
Step: 13856, loss: 3.155712, norm: 0.3291, time(ms): 800.98, token/sec:654559.65, hellaswag_acc: 0.2966
Step: 13857, loss: 3.075891, norm: 0.3120, time(ms): 804.41, token/sec:651765.41, hellaswag_acc: 0.2966
Step: 13858, loss: 3.168522, norm: 0.3460, time(ms): 796.42, token/sec:658302.29, hellaswag_acc: 0.2966
Step: 13859, loss: 3.127661, norm: 0.4015, time(ms): 794.20, token/sec:660148.88, hellaswag_acc: 0.2966
Step: 13860, loss: 3.109982, norm: 0.3272, time(ms): 800.07, token/sec:655304.58, hellaswag_acc: 0.2966
Step: 13861, loss: 3.157350, norm: 0.3242, time(ms): 794.22, token/sec:660127.68, hellaswag_acc: 0.2966
Step: 13862, loss: 3.119949, norm: 0.3625, time(ms): 794.13, token/sec:660205.96, hellaswag_acc: 0.2966
Step: 13863, loss: 3.189669, norm: 0.3336, time(ms): 789.25, token/sec:664286.64, hellaswag_acc: 0.2966
Step: 13864, loss: 3.106806, norm: 0.3482, time(ms): 791.93, token/sec:662041.53, hellaswag_acc: 0.2966
Step: 13865, loss: 3.147484, norm: 0.3165, time(ms): 790.51, token/sec:663229.59, hellaswag_acc: 0.2966
Step: 13866, loss: 3.193086, norm: 0.3518, time(ms): 791.07, token/sec:662755.05, hellaswag_acc: 0.2966
Step: 13867, loss: 3.080810, norm: 0.3054, time(ms): 790.70, token/sec:663065.20, hellaswag_acc: 0.2966
Step: 13868, loss: 3.102780, norm: 0.3209, time(ms): 800.62, token/sec:654856.52, hellaswag_acc: 0.2966
Step: 13869, loss: 3.063095, norm: 0.2916, time(ms): 805.93, token/sec:650536.81, hellaswag_acc: 0.2966
Step: 13870, loss: 3.075273, norm: 0.2856, time(ms): 794.61, token/sec:659801.86, hellaswag_acc: 0.2966
Step: 13871, loss: 3.102872, norm: 0.2901, time(ms): 795.64, token/sec:658947.93, hellaswag_acc: 0.2966
Step: 13872, loss: 3.084352, norm: 0.2988, time(ms): 805.35, token/sec:651002.87, hellaswag_acc: 0.2966
Step: 13873, loss: 3.130385, norm: 0.2833, time(ms): 803.57, token/sec:652450.75, hellaswag_acc: 0.2966
Step: 13874, loss: 3.061347, norm: 0.2814, time(ms): 792.17, token/sec:661840.68, hellaswag_acc: 0.2966
Step: 13875, loss: 3.123123, norm: 0.2708, time(ms): 804.96, token/sec:651325.07, hellaswag_acc: 0.2966
Step: 13876, loss: 3.109426, norm: 0.2753, time(ms): 796.35, token/sec:658362.60, hellaswag_acc: 0.2966
Step: 13877, loss: 3.059494, norm: 0.2621, time(ms): 803.57, token/sec:652450.94, hellaswag_acc: 0.2966
Step: 13878, loss: 3.010463, norm: 0.2618, time(ms): 800.38, token/sec:655052.18, hellaswag_acc: 0.2966
Step: 13879, loss: 3.129827, norm: 0.3626, time(ms): 800.07, token/sec:655304.58, hellaswag_acc: 0.2966
Step: 13880, loss: 3.025896, norm: 0.2677, time(ms): 795.19, token/sec:659326.87, hellaswag_acc: 0.2966
Step: 13881, loss: 3.054654, norm: 0.2831, time(ms): 804.37, token/sec:651801.54, hellaswag_acc: 0.2966
Step: 13882, loss: 3.012183, norm: 0.2692, time(ms): 796.24, token/sec:658457.22, hellaswag_acc: 0.2966
Step: 13883, loss: 3.084909, norm: 0.3185, time(ms): 799.17, token/sec:656043.17, hellaswag_acc: 0.2966
Step: 13884, loss: 3.016806, norm: 0.2922, time(ms): 803.71, token/sec:652331.33, hellaswag_acc: 0.2966
Step: 13885, loss: 3.015275, norm: 0.3027, time(ms): 802.03, token/sec:653702.33, hellaswag_acc: 0.2966
Step: 13886, loss: 3.018793, norm: 0.2923, time(ms): 792.41, token/sec:661637.57, hellaswag_acc: 0.2966
Step: 13887, loss: 3.059548, norm: 0.2791, time(ms): 802.43, token/sec:653372.92, hellaswag_acc: 0.2966
Step: 13888, loss: 3.092040, norm: 0.2815, time(ms): 804.50, token/sec:651691.43, hellaswag_acc: 0.2966
Step: 13889, loss: 3.055687, norm: 0.2683, time(ms): 796.23, token/sec:658466.10, hellaswag_acc: 0.2966
Step: 13890, loss: 3.186782, norm: 0.2970, time(ms): 796.80, token/sec:657988.51, hellaswag_acc: 0.2966
Step: 13891, loss: 3.148035, norm: 0.2947, time(ms): 801.97, token/sec:653746.64, hellaswag_acc: 0.2966
Step: 13892, loss: 3.095111, norm: 0.2962, time(ms): 802.29, token/sec:653486.31, hellaswag_acc: 0.2966
Step: 13893, loss: 3.092962, norm: 0.2785, time(ms): 797.62, token/sec:657317.43, hellaswag_acc: 0.2966
Step: 13894, loss: 3.090846, norm: 0.2877, time(ms): 791.74, token/sec:662200.23, hellaswag_acc: 0.2966
Step: 13895, loss: 3.190347, norm: 0.3187, time(ms): 790.80, token/sec:662985.84, hellaswag_acc: 0.2966
Step: 13896, loss: 3.071692, norm: 0.2919, time(ms): 792.89, token/sec:661236.09, hellaswag_acc: 0.2966
Step: 13897, loss: 3.146042, norm: 0.2902, time(ms): 791.76, token/sec:662180.49, hellaswag_acc: 0.2966
Step: 13898, loss: 3.207789, norm: 0.3226, time(ms): 794.00, token/sec:660315.79, hellaswag_acc: 0.2966
Step: 13899, loss: 3.174154, norm: 0.2979, time(ms): 799.88, token/sec:655455.56, hellaswag_acc: 0.2966
Step: 13900, loss: 3.103507, norm: 0.2947, time(ms): 796.57, token/sec:658183.48, hellaswag_acc: 0.2966
Step: 13901, loss: 3.118177, norm: 0.2747, time(ms): 802.18, token/sec:653577.79, hellaswag_acc: 0.2966
Step: 13902, loss: 3.101290, norm: 0.2967, time(ms): 799.72, token/sec:655586.29, hellaswag_acc: 0.2966
Step: 13903, loss: 3.079246, norm: 0.2678, time(ms): 796.30, token/sec:658403.40, hellaswag_acc: 0.2966
Step: 13904, loss: 3.094831, norm: 0.2869, time(ms): 801.67, token/sec:653992.78, hellaswag_acc: 0.2966
Step: 13905, loss: 3.100857, norm: 0.2799, time(ms): 797.50, token/sec:657413.72, hellaswag_acc: 0.2966
Step: 13906, loss: 3.120265, norm: 0.2940, time(ms): 1328.42, token/sec:394671.52, hellaswag_acc: 0.2966
Step: 13907, loss: 2.967734, norm: 0.2854, time(ms): 791.53, token/sec:662370.57, hellaswag_acc: 0.2966
Step: 13908, loss: 3.091781, norm: 0.2860, time(ms): 790.72, token/sec:663051.81, hellaswag_acc: 0.2966
Step: 13909, loss: 3.094168, norm: 0.2769, time(ms): 787.31, token/sec:665924.92, hellaswag_acc: 0.2966
Step: 13910, loss: 3.145677, norm: 0.2918, time(ms): 801.11, token/sec:654452.12, hellaswag_acc: 0.2966
Step: 13911, loss: 3.120598, norm: 0.3137, time(ms): 803.73, token/sec:652316.04, hellaswag_acc: 0.2966
Step: 13912, loss: 3.111266, norm: 0.2806, time(ms): 803.42, token/sec:652572.14, hellaswag_acc: 0.2966
Step: 13913, loss: 3.102958, norm: 0.2885, time(ms): 790.00, token/sec:663659.73, hellaswag_acc: 0.2966
Step: 13914, loss: 3.118059, norm: 0.2720, time(ms): 797.84, token/sec:657135.93, hellaswag_acc: 0.2966
Step: 13915, loss: 3.001716, norm: 0.3266, time(ms): 791.74, token/sec:662198.43, hellaswag_acc: 0.2966
Step: 13916, loss: 3.103401, norm: 0.4077, time(ms): 792.91, token/sec:661218.39, hellaswag_acc: 0.2966
Step: 13917, loss: 3.164708, norm: 0.3287, time(ms): 791.26, token/sec:662596.89, hellaswag_acc: 0.2966
Step: 13918, loss: 3.071065, norm: 0.3369, time(ms): 785.91, token/sec:667107.53, hellaswag_acc: 0.2966
Step: 13919, loss: 3.094888, norm: 0.2884, time(ms): 789.37, token/sec:664184.71, hellaswag_acc: 0.2966
Step: 13920, loss: 3.110090, norm: 0.3138, time(ms): 798.26, token/sec:656789.71, hellaswag_acc: 0.2966
Step: 13921, loss: 3.058212, norm: 0.2796, time(ms): 789.55, token/sec:664031.28, hellaswag_acc: 0.2966
Step: 13922, loss: 3.079288, norm: 0.2980, time(ms): 787.67, token/sec:665621.36, hellaswag_acc: 0.2966
Step: 13923, loss: 3.094632, norm: 0.2807, time(ms): 793.65, token/sec:660603.22, hellaswag_acc: 0.2966
Step: 13924, loss: 3.063895, norm: 0.2816, time(ms): 792.28, token/sec:661749.47, hellaswag_acc: 0.2966
Step: 13925, loss: 3.076934, norm: 0.3020, time(ms): 789.49, token/sec:664082.02, hellaswag_acc: 0.2966
Step: 13926, loss: 3.061694, norm: 0.2693, time(ms): 801.20, token/sec:654382.40, hellaswag_acc: 0.2966
Step: 13927, loss: 3.092403, norm: 0.3082, time(ms): 803.16, token/sec:652785.04, hellaswag_acc: 0.2966
Step: 13928, loss: 3.086395, norm: 0.2810, time(ms): 799.17, token/sec:656039.45, hellaswag_acc: 0.2966
Step: 13929, loss: 3.059295, norm: 0.2692, time(ms): 794.33, token/sec:660035.74, hellaswag_acc: 0.2966
Step: 13930, loss: 3.088641, norm: 0.2625, time(ms): 802.31, token/sec:653470.58, hellaswag_acc: 0.2966
Step: 13931, loss: 3.052190, norm: 0.2855, time(ms): 798.49, token/sec:656600.86, hellaswag_acc: 0.2966
Step: 13932, loss: 3.073483, norm: 0.2705, time(ms): 794.41, token/sec:659967.99, hellaswag_acc: 0.2966
Step: 13933, loss: 3.029604, norm: 0.2761, time(ms): 793.36, token/sec:660845.61, hellaswag_acc: 0.2966
Step: 13934, loss: 3.042632, norm: 0.2764, time(ms): 794.78, token/sec:659667.66, hellaswag_acc: 0.2966
Step: 13935, loss: 2.956074, norm: 0.2797, time(ms): 801.21, token/sec:654371.30, hellaswag_acc: 0.2966
Step: 13936, loss: 3.036755, norm: 0.2779, time(ms): 799.73, token/sec:655581.40, hellaswag_acc: 0.2966
Step: 13937, loss: 3.011167, norm: 0.2717, time(ms): 800.64, token/sec:654834.87, hellaswag_acc: 0.2966
Step: 13938, loss: 3.035941, norm: 0.2979, time(ms): 792.94, token/sec:661197.32, hellaswag_acc: 0.2966
Step: 13939, loss: 3.054395, norm: 0.2720, time(ms): 789.58, token/sec:664008.82, hellaswag_acc: 0.2966
Step: 13940, loss: 3.076867, norm: 0.2745, time(ms): 790.04, token/sec:663618.68, hellaswag_acc: 0.2966
Step: 13941, loss: 3.048473, norm: 0.2868, time(ms): 791.63, token/sec:662291.37, hellaswag_acc: 0.2966
Step: 13942, loss: 2.981328, norm: 0.2940, time(ms): 790.99, token/sec:662827.57, hellaswag_acc: 0.2966
Step: 13943, loss: 3.008996, norm: 0.2875, time(ms): 801.64, token/sec:654016.90, hellaswag_acc: 0.2966
Step: 13944, loss: 3.150669, norm: 0.3419, time(ms): 801.97, token/sec:653750.52, hellaswag_acc: 0.2966
Step: 13945, loss: 3.189723, norm: 0.2985, time(ms): 801.92, token/sec:653788.81, hellaswag_acc: 0.2966
Step: 13946, loss: 3.130000, norm: 0.3106, time(ms): 795.00, token/sec:659484.47, hellaswag_acc: 0.2966
Step: 13947, loss: 3.117455, norm: 0.2823, time(ms): 797.68, token/sec:657262.03, hellaswag_acc: 0.2966
Step: 13948, loss: 3.080971, norm: 0.2672, time(ms): 806.19, token/sec:650325.00, hellaswag_acc: 0.2966
Step: 13949, loss: 3.102349, norm: 0.3141, time(ms): 801.04, token/sec:654513.09, hellaswag_acc: 0.2966
Step: 13950, loss: 3.106467, norm: 0.2652, time(ms): 790.95, token/sec:662857.74, hellaswag_acc: 0.2966
Step: 13951, loss: 3.111465, norm: 0.3361, time(ms): 806.21, token/sec:650308.07, hellaswag_acc: 0.2966
Step: 13952, loss: 3.144721, norm: 0.3071, time(ms): 800.78, token/sec:654723.35, hellaswag_acc: 0.2966
Step: 13953, loss: 3.082139, norm: 0.2946, time(ms): 793.00, token/sec:661144.44, hellaswag_acc: 0.2966
Step: 13954, loss: 3.112547, norm: 0.2901, time(ms): 796.98, token/sec:657839.50, hellaswag_acc: 0.2966
Step: 13955, loss: 3.090516, norm: 0.2754, time(ms): 792.26, token/sec:661762.41, hellaswag_acc: 0.2966
Step: 13956, loss: 3.106504, norm: 0.2799, time(ms): 801.21, token/sec:654374.02, hellaswag_acc: 0.2966
Step: 13957, loss: 3.049772, norm: 0.3095, time(ms): 791.03, token/sec:662787.41, hellaswag_acc: 0.2966
Step: 13958, loss: 3.073717, norm: 0.2917, time(ms): 789.42, token/sec:664147.20, hellaswag_acc: 0.2966
Step: 13959, loss: 3.073900, norm: 0.3047, time(ms): 795.87, token/sec:658758.43, hellaswag_acc: 0.2966
Step: 13960, loss: 3.064132, norm: 0.2940, time(ms): 797.78, token/sec:657186.60, hellaswag_acc: 0.2966
Step: 13961, loss: 3.059617, norm: 0.2938, time(ms): 801.73, token/sec:653945.33, hellaswag_acc: 0.2966
Step: 13962, loss: 3.097872, norm: 0.2860, time(ms): 794.21, token/sec:660139.17, hellaswag_acc: 0.2966
Step: 13963, loss: 3.158346, norm: 0.2734, time(ms): 802.23, token/sec:653534.47, hellaswag_acc: 0.2966
Step: 13964, loss: 3.125123, norm: 0.2749, time(ms): 802.88, token/sec:653011.65, hellaswag_acc: 0.2966
Step: 13965, loss: 3.115397, norm: 0.2838, time(ms): 796.31, token/sec:658396.50, hellaswag_acc: 0.2966
Step: 13966, loss: 3.115966, norm: 0.2645, time(ms): 796.25, token/sec:658448.75, hellaswag_acc: 0.2966
Step: 13967, loss: 3.041937, norm: 0.2680, time(ms): 802.71, token/sec:653151.30, hellaswag_acc: 0.2966
Step: 13968, loss: 3.007710, norm: 0.2773, time(ms): 804.94, token/sec:651341.67, hellaswag_acc: 0.2966
Step: 13969, loss: 2.998348, norm: 0.2802, time(ms): 789.96, token/sec:663686.57, hellaswag_acc: 0.2966
Step: 13970, loss: 3.058059, norm: 0.2822, time(ms): 792.49, token/sec:661573.08, hellaswag_acc: 0.2966
Step: 13971, loss: 3.001590, norm: 0.2867, time(ms): 797.00, token/sec:657829.27, hellaswag_acc: 0.2966
Step: 13972, loss: 3.008019, norm: 0.2899, time(ms): 798.07, token/sec:656941.38, hellaswag_acc: 0.2966
Step: 13973, loss: 3.020797, norm: 0.2985, time(ms): 798.67, token/sec:656455.03, hellaswag_acc: 0.2966
Step: 13974, loss: 3.037740, norm: 0.2731, time(ms): 796.15, token/sec:658529.39, hellaswag_acc: 0.2966
Step: 13975, loss: 2.989918, norm: 0.2999, time(ms): 800.14, token/sec:655243.65, hellaswag_acc: 0.2966
Step: 13976, loss: 3.051768, norm: 0.2771, time(ms): 796.39, token/sec:658333.43, hellaswag_acc: 0.2966
Step: 13977, loss: 2.933694, norm: 0.2719, time(ms): 791.74, token/sec:662199.03, hellaswag_acc: 0.2966
Step: 13978, loss: 3.013312, norm: 0.2726, time(ms): 796.92, token/sec:657889.49, hellaswag_acc: 0.2966
Step: 13979, loss: 3.008451, norm: 0.2705, time(ms): 791.08, token/sec:662752.46, hellaswag_acc: 0.2966
Step: 13980, loss: 3.135506, norm: 0.3048, time(ms): 786.17, token/sec:666887.42, hellaswag_acc: 0.2966
Step: 13981, loss: 3.072666, norm: 0.2819, time(ms): 803.05, token/sec:652874.58, hellaswag_acc: 0.2966
Step: 13982, loss: 3.084386, norm: 0.3113, time(ms): 799.11, token/sec:656089.37, hellaswag_acc: 0.2966
Step: 13983, loss: 3.042296, norm: 0.2966, time(ms): 796.87, token/sec:657932.40, hellaswag_acc: 0.2966
Step: 13984, loss: 3.143343, norm: 0.2928, time(ms): 801.63, token/sec:654027.21, hellaswag_acc: 0.2966
Step: 13985, loss: 3.084943, norm: 0.2777, time(ms): 795.33, token/sec:659208.09, hellaswag_acc: 0.2966
Step: 13986, loss: 3.091629, norm: 0.3174, time(ms): 806.23, token/sec:650298.65, hellaswag_acc: 0.2966
Step: 13987, loss: 3.081531, norm: 0.2831, time(ms): 795.47, token/sec:659096.06, hellaswag_acc: 0.2966
Step: 13988, loss: 3.034835, norm: 0.2796, time(ms): 798.21, token/sec:656827.18, hellaswag_acc: 0.2966
Step: 13989, loss: 3.136404, norm: 0.3076, time(ms): 803.74, token/sec:652311.20, hellaswag_acc: 0.2966
Step: 13990, loss: 3.058076, norm: 0.2809, time(ms): 802.32, token/sec:653465.92, hellaswag_acc: 0.2966
Step: 13991, loss: 3.066537, norm: 0.4182, time(ms): 785.93, token/sec:667088.51, hellaswag_acc: 0.2966
Step: 13992, loss: 3.045796, norm: 0.2794, time(ms): 790.22, token/sec:663472.31, hellaswag_acc: 0.2966
Step: 13993, loss: 3.109560, norm: 0.2732, time(ms): 796.63, token/sec:658132.46, hellaswag_acc: 0.2966
Step: 13994, loss: 3.077537, norm: 0.2928, time(ms): 795.09, token/sec:659407.74, hellaswag_acc: 0.2966
Step: 13995, loss: 3.099452, norm: 0.2908, time(ms): 791.22, token/sec:662634.43, hellaswag_acc: 0.2966
Step: 13996, loss: 3.066474, norm: 0.2854, time(ms): 792.22, token/sec:661792.68, hellaswag_acc: 0.2966
Step: 13997, loss: 3.118293, norm: 0.3078, time(ms): 802.20, token/sec:653561.08, hellaswag_acc: 0.2966
Step: 13998, loss: 3.093121, norm: 0.2930, time(ms): 800.85, token/sec:654667.80, hellaswag_acc: 0.2966
Step: 13999, loss: 3.133545, norm: 0.2931, time(ms): 804.82, token/sec:651438.34, hellaswag_acc: 0.2966
rank 0 sample 0: Hello, I'm a language model, and I think that it's going to save them all to a memory heap in the first place. So we're trying
rank 0 sample 1: Hello, I'm a language model, so please contact me.
This one is the real question, is the problem, the actual solution, is the real
rank 0 sample 2: Hello, I'm a language model, so I haven't a ton of examples. This is a bit tricky to understand, because you have to know what the
rank 0 sample 3: Hello, I'm a language model, a mathematical model for the way that objects in my language interact with each other and is very intuitive to be able to identify
rank 1 sample 0: Hello, I'm a language model, like an Excel spreadsheet, and I create the tables in tables
- I start with one of each of the tables,
rank 1 sample 1: Hello, I'm a language model, not an application. I'm not even good at modeling it. However, I guess you are asking yourself, "What
rank 1 sample 2: Hello, I'm a language model, I actually need to understand the language, and I need to create the code. I'm going to write the function statement
rank 1 sample 3: Hello, I'm a language model, and I'm learning to express these two entities in a fun way. If I'm wondering how to do this, I
Step: 14000, loss: 3.060413, norm: 0.3060, time(ms): 363719.47, token/sec:1441.46, val_loss: 3.1177, hellaswag_acc: 0.2999
Step: 14001, loss: 3.080733, norm: 0.3012, time(ms): 800.59, token/sec:654881.09, hellaswag_acc: 0.2999
Step: 14002, loss: 3.084342, norm: 0.2810, time(ms): 792.52, token/sec:661547.80, hellaswag_acc: 0.2999
Step: 14003, loss: 2.979583, norm: 0.3193, time(ms): 793.34, token/sec:660862.10, hellaswag_acc: 0.2999
Step: 14004, loss: 3.027235, norm: 0.2806, time(ms): 795.13, token/sec:659375.71, hellaswag_acc: 0.2999
Step: 14005, loss: 3.010051, norm: 0.2869, time(ms): 794.84, token/sec:659610.67, hellaswag_acc: 0.2999
Step: 14006, loss: 3.027772, norm: 0.2815, time(ms): 801.01, token/sec:654536.66, hellaswag_acc: 0.2999
Step: 14007, loss: 3.083508, norm: 0.2809, time(ms): 803.55, token/sec:652464.30, hellaswag_acc: 0.2999
Step: 14008, loss: 3.081778, norm: 0.2776, time(ms): 798.88, token/sec:656278.71, hellaswag_acc: 0.2999
Step: 14009, loss: 3.004569, norm: 0.3012, time(ms): 792.19, token/sec:661817.18, hellaswag_acc: 0.2999
Step: 14010, loss: 3.039369, norm: 0.2719, time(ms): 801.96, token/sec:653760.44, hellaswag_acc: 0.2999
Step: 14011, loss: 3.028802, norm: 0.2594, time(ms): 805.93, token/sec:650533.93, hellaswag_acc: 0.2999
Step: 14012, loss: 3.013684, norm: 0.2664, time(ms): 801.47, token/sec:654160.29, hellaswag_acc: 0.2999
Step: 14013, loss: 3.027355, norm: 0.2602, time(ms): 790.09, token/sec:663579.23, hellaswag_acc: 0.2999
Step: 14014, loss: 3.032913, norm: 0.2737, time(ms): 799.84, token/sec:655494.44, hellaswag_acc: 0.2999
Step: 14015, loss: 3.080815, norm: 0.3436, time(ms): 807.88, token/sec:648964.66, hellaswag_acc: 0.2999
Step: 14016, loss: 3.087313, norm: 0.2813, time(ms): 792.78, token/sec:661330.54, hellaswag_acc: 0.2999
Step: 14017, loss: 3.245852, norm: 0.4100, time(ms): 797.98, token/sec:657022.64, hellaswag_acc: 0.2999
Step: 14018, loss: 3.123206, norm: 0.3315, time(ms): 799.70, token/sec:655606.23, hellaswag_acc: 0.2999
Step: 14019, loss: 3.081529, norm: 0.3454, time(ms): 794.50, token/sec:659894.72, hellaswag_acc: 0.2999
Step: 14020, loss: 3.202865, norm: 0.3490, time(ms): 792.28, token/sec:661743.29, hellaswag_acc: 0.2999
Step: 14021, loss: 3.061218, norm: 0.3409, time(ms): 793.86, token/sec:660430.41, hellaswag_acc: 0.2999
Step: 14022, loss: 3.090820, norm: 0.2995, time(ms): 806.02, token/sec:650462.35, hellaswag_acc: 0.2999
Step: 14023, loss: 3.096921, norm: 0.3190, time(ms): 803.47, token/sec:652528.19, hellaswag_acc: 0.2999
Step: 14024, loss: 3.087455, norm: 0.3355, time(ms): 792.05, token/sec:661935.32, hellaswag_acc: 0.2999
Step: 14025, loss: 3.092312, norm: 0.3155, time(ms): 801.99, token/sec:653734.98, hellaswag_acc: 0.2999
Step: 14026, loss: 3.129371, norm: 0.3290, time(ms): 801.00, token/sec:654538.02, hellaswag_acc: 0.2999
Step: 14027, loss: 3.109873, norm: 0.3194, time(ms): 801.72, token/sec:653957.19, hellaswag_acc: 0.2999
Step: 14028, loss: 3.179426, norm: 0.3234, time(ms): 800.60, token/sec:654870.95, hellaswag_acc: 0.2999
Step: 14029, loss: 3.135607, norm: 0.5517, time(ms): 794.71, token/sec:659726.24, hellaswag_acc: 0.2999
Step: 14030, loss: 3.093199, norm: 0.3195, time(ms): 801.35, token/sec:654258.96, hellaswag_acc: 0.2999
Step: 14031, loss: 3.113028, norm: 0.2776, time(ms): 801.92, token/sec:653787.65, hellaswag_acc: 0.2999
Step: 14032, loss: 3.128091, norm: 0.2836, time(ms): 801.59, token/sec:654056.19, hellaswag_acc: 0.2999
Step: 14033, loss: 3.059946, norm: 0.3018, time(ms): 796.73, token/sec:658046.20, hellaswag_acc: 0.2999
Step: 14034, loss: 3.074246, norm: 0.3120, time(ms): 799.71, token/sec:655599.97, hellaswag_acc: 0.2999
Step: 14035, loss: 3.138528, norm: 0.3233, time(ms): 803.73, token/sec:652315.65, hellaswag_acc: 0.2999
Step: 14036, loss: 3.076754, norm: 0.2938, time(ms): 799.19, token/sec:656023.21, hellaswag_acc: 0.2999
Step: 14037, loss: 3.087327, norm: 0.2933, time(ms): 793.94, token/sec:660361.00, hellaswag_acc: 0.2999
Step: 14038, loss: 3.068369, norm: 0.2790, time(ms): 801.83, token/sec:653865.21, hellaswag_acc: 0.2999
Step: 14039, loss: 3.064486, norm: 0.3074, time(ms): 800.56, token/sec:654899.82, hellaswag_acc: 0.2999
Step: 14040, loss: 3.026393, norm: 0.2991, time(ms): 802.64, token/sec:653203.49, hellaswag_acc: 0.2999
Step: 14041, loss: 2.998502, norm: 0.2773, time(ms): 799.12, token/sec:656077.82, hellaswag_acc: 0.2999
Step: 14042, loss: 3.034563, norm: 0.3178, time(ms): 798.59, token/sec:656516.37, hellaswag_acc: 0.2999
Step: 14043, loss: 3.015541, norm: 0.2623, time(ms): 795.49, token/sec:659079.47, hellaswag_acc: 0.2999
Step: 14044, loss: 3.069676, norm: 0.2774, time(ms): 792.77, token/sec:661332.73, hellaswag_acc: 0.2999
Step: 14045, loss: 3.027433, norm: 0.2712, time(ms): 790.18, token/sec:663500.34, hellaswag_acc: 0.2999
Step: 14046, loss: 3.077370, norm: 0.2749, time(ms): 792.87, token/sec:661256.17, hellaswag_acc: 0.2999
Step: 14047, loss: 3.061318, norm: 0.2738, time(ms): 791.24, token/sec:662618.06, hellaswag_acc: 0.2999
Step: 14048, loss: 3.086898, norm: 0.2698, time(ms): 798.09, token/sec:656932.36, hellaswag_acc: 0.2999
Step: 14049, loss: 3.024216, norm: 0.2592, time(ms): 798.85, token/sec:656303.58, hellaswag_acc: 0.2999
Step: 14050, loss: 3.013651, norm: 0.2778, time(ms): 796.39, token/sec:658329.29, hellaswag_acc: 0.2999
Step: 14051, loss: 3.104270, norm: 0.2935, time(ms): 804.55, token/sec:651650.68, hellaswag_acc: 0.2999
Step: 14052, loss: 3.153263, norm: 0.2910, time(ms): 800.70, token/sec:654784.57, hellaswag_acc: 0.2999
Step: 14053, loss: 3.074934, norm: 0.2958, time(ms): 791.32, token/sec:662549.78, hellaswag_acc: 0.2999
Step: 14054, loss: 3.141889, norm: 0.2915, time(ms): 805.44, token/sec:650930.22, hellaswag_acc: 0.2999
Step: 14055, loss: 3.121812, norm: 0.2998, time(ms): 803.80, token/sec:652259.54, hellaswag_acc: 0.2999
Step: 14056, loss: 3.116420, norm: 0.2977, time(ms): 795.17, token/sec:659338.34, hellaswag_acc: 0.2999
Step: 14057, loss: 3.101272, norm: 0.2843, time(ms): 801.35, token/sec:654253.32, hellaswag_acc: 0.2999
Step: 14058, loss: 3.138438, norm: 0.2859, time(ms): 799.86, token/sec:655472.36, hellaswag_acc: 0.2999
Step: 14059, loss: 3.079739, norm: 0.2797, time(ms): 801.28, token/sec:654310.55, hellaswag_acc: 0.2999
Step: 14060, loss: 3.098881, norm: 0.2933, time(ms): 800.20, token/sec:655199.14, hellaswag_acc: 0.2999
Step: 14061, loss: 3.134037, norm: 0.2877, time(ms): 799.18, token/sec:656031.04, hellaswag_acc: 0.2999
Step: 14062, loss: 3.011367, norm: 0.2852, time(ms): 799.81, token/sec:655512.42, hellaswag_acc: 0.2999
Step: 14063, loss: 3.089691, norm: 0.2776, time(ms): 800.12, token/sec:655259.47, hellaswag_acc: 0.2999
Step: 14064, loss: 3.109416, norm: 0.2962, time(ms): 799.70, token/sec:655607.01, hellaswag_acc: 0.2999
Step: 14065, loss: 3.063640, norm: 0.2727, time(ms): 799.66, token/sec:655641.80, hellaswag_acc: 0.2999
Step: 14066, loss: 3.107570, norm: 0.3194, time(ms): 798.31, token/sec:656744.21, hellaswag_acc: 0.2999
Step: 14067, loss: 3.141373, norm: 0.2760, time(ms): 801.00, token/sec:654540.36, hellaswag_acc: 0.2999
Step: 14068, loss: 3.087160, norm: 0.2898, time(ms): 802.28, token/sec:653495.83, hellaswag_acc: 0.2999
Step: 14069, loss: 3.098394, norm: 0.2761, time(ms): 789.05, token/sec:664454.44, hellaswag_acc: 0.2999
Step: 14070, loss: 3.027296, norm: 0.2707, time(ms): 798.76, token/sec:656374.89, hellaswag_acc: 0.2999
Step: 14071, loss: 3.078001, norm: 0.3000, time(ms): 792.03, token/sec:661950.86, hellaswag_acc: 0.2999
Step: 14072, loss: 3.079839, norm: 0.2825, time(ms): 791.76, token/sec:662180.69, hellaswag_acc: 0.2999
Step: 14073, loss: 3.052718, norm: 0.2780, time(ms): 790.73, token/sec:663045.01, hellaswag_acc: 0.2999
Step: 14074, loss: 3.072631, norm: 0.2868, time(ms): 791.84, token/sec:662116.29, hellaswag_acc: 0.2999
Step: 14075, loss: 2.998596, norm: 0.2885, time(ms): 799.38, token/sec:655866.09, hellaswag_acc: 0.2999
Step: 14076, loss: 3.059591, norm: 0.2809, time(ms): 804.19, token/sec:651944.92, hellaswag_acc: 0.2999
Step: 14077, loss: 3.102052, norm: 0.2783, time(ms): 801.39, token/sec:654221.01, hellaswag_acc: 0.2999
Step: 14078, loss: 3.031269, norm: 0.2836, time(ms): 786.73, token/sec:666410.47, hellaswag_acc: 0.2999
Step: 14079, loss: 3.043997, norm: 0.2683, time(ms): 791.05, token/sec:662774.03, hellaswag_acc: 0.2999
Step: 14080, loss: 3.025382, norm: 0.2840, time(ms): 799.26, token/sec:655969.98, hellaswag_acc: 0.2999
Step: 14081, loss: 2.997640, norm: 0.2674, time(ms): 797.40, token/sec:657498.24, hellaswag_acc: 0.2999
Step: 14082, loss: 3.017715, norm: 0.2887, time(ms): 799.83, token/sec:655496.40, hellaswag_acc: 0.2999
Step: 14083, loss: 3.069609, norm: 0.2946, time(ms): 802.16, token/sec:653596.63, hellaswag_acc: 0.2999
Step: 14084, loss: 3.033272, norm: 0.2764, time(ms): 797.27, token/sec:657607.76, hellaswag_acc: 0.2999
Step: 14085, loss: 3.069514, norm: 0.3071, time(ms): 799.08, token/sec:656112.46, hellaswag_acc: 0.2999
Step: 14086, loss: 3.097069, norm: 0.2832, time(ms): 802.37, token/sec:653421.07, hellaswag_acc: 0.2999
Step: 14087, loss: 3.129528, norm: 0.3034, time(ms): 791.75, token/sec:662188.26, hellaswag_acc: 0.2999
Step: 14088, loss: 3.093244, norm: 0.2922, time(ms): 788.86, token/sec:664617.50, hellaswag_acc: 0.2999
Step: 14089, loss: 3.073037, norm: 0.2898, time(ms): 793.38, token/sec:660826.35, hellaswag_acc: 0.2999
Step: 14090, loss: 3.144830, norm: 0.2865, time(ms): 795.78, token/sec:658836.59, hellaswag_acc: 0.2999
Step: 14091, loss: 3.127454, norm: 0.3262, time(ms): 791.85, token/sec:662105.12, hellaswag_acc: 0.2999
Step: 14092, loss: 3.093563, norm: 0.2776, time(ms): 798.08, token/sec:656933.93, hellaswag_acc: 0.2999
Step: 14093, loss: 3.133610, norm: 0.2894, time(ms): 796.51, token/sec:658229.97, hellaswag_acc: 0.2999
Step: 14094, loss: 3.075720, norm: 0.2917, time(ms): 803.21, token/sec:652743.19, hellaswag_acc: 0.2999
Step: 14095, loss: 3.136565, norm: 0.3128, time(ms): 801.77, token/sec:653911.49, hellaswag_acc: 0.2999
Step: 14096, loss: 3.146224, norm: 0.3257, time(ms): 1333.58, token/sec:393142.98, hellaswag_acc: 0.2999
Step: 14097, loss: 3.200849, norm: 0.3298, time(ms): 769.00, token/sec:681779.10, hellaswag_acc: 0.2999
Step: 14098, loss: 3.138740, norm: 0.3231, time(ms): 784.52, token/sec:668294.76, hellaswag_acc: 0.2999
Step: 14099, loss: 3.106725, norm: 0.3124, time(ms): 797.56, token/sec:657363.61, hellaswag_acc: 0.2999
Step: 14100, loss: 3.174233, norm: 0.2950, time(ms): 790.94, token/sec:662866.73, hellaswag_acc: 0.2999
Step: 14101, loss: 3.047618, norm: 0.3048, time(ms): 785.40, token/sec:667542.93, hellaswag_acc: 0.2999
Step: 14102, loss: 3.175330, norm: 0.2979, time(ms): 786.50, token/sec:666611.27, hellaswag_acc: 0.2999
Step: 14103, loss: 3.098600, norm: 0.3149, time(ms): 792.53, token/sec:661539.24, hellaswag_acc: 0.2999
Step: 14104, loss: 3.098034, norm: 0.2965, time(ms): 796.63, token/sec:658128.92, hellaswag_acc: 0.2999
Step: 14105, loss: 3.126442, norm: 0.3033, time(ms): 787.41, token/sec:665837.01, hellaswag_acc: 0.2999
Step: 14106, loss: 3.208200, norm: 0.3116, time(ms): 788.36, token/sec:665032.16, hellaswag_acc: 0.2999
Step: 14107, loss: 3.136921, norm: 0.2965, time(ms): 793.33, token/sec:660871.83, hellaswag_acc: 0.2999
Step: 14108, loss: 3.081016, norm: 0.2965, time(ms): 792.25, token/sec:661768.98, hellaswag_acc: 0.2999
Step: 14109, loss: 3.060088, norm: 0.2713, time(ms): 790.13, token/sec:663547.19, hellaswag_acc: 0.2999
Step: 14110, loss: 3.068491, norm: 0.2842, time(ms): 791.27, token/sec:662594.30, hellaswag_acc: 0.2999
Step: 14111, loss: 3.076754, norm: 0.2874, time(ms): 792.25, token/sec:661772.77, hellaswag_acc: 0.2999
Step: 14112, loss: 3.116550, norm: 0.2682, time(ms): 799.45, token/sec:655810.74, hellaswag_acc: 0.2999
Step: 14113, loss: 3.074406, norm: 0.2845, time(ms): 790.60, token/sec:663148.19, hellaswag_acc: 0.2999
Step: 14114, loss: 3.077146, norm: 0.2575, time(ms): 795.32, token/sec:659213.03, hellaswag_acc: 0.2999
Step: 14115, loss: 3.094295, norm: 0.2740, time(ms): 795.86, token/sec:658770.67, hellaswag_acc: 0.2999
Step: 14116, loss: 2.963249, norm: 0.2914, time(ms): 799.85, token/sec:655484.67, hellaswag_acc: 0.2999
Step: 14117, loss: 2.994697, norm: 0.3036, time(ms): 802.91, token/sec:652983.53, hellaswag_acc: 0.2999
Step: 14118, loss: 2.952307, norm: 0.2994, time(ms): 799.34, token/sec:655901.31, hellaswag_acc: 0.2999
Step: 14119, loss: 2.884924, norm: 0.3171, time(ms): 799.28, token/sec:655947.87, hellaswag_acc: 0.2999
Step: 14120, loss: 2.904138, norm: 0.2795, time(ms): 795.34, token/sec:659199.99, hellaswag_acc: 0.2999
Step: 14121, loss: 2.980976, norm: 0.2826, time(ms): 805.46, token/sec:650921.36, hellaswag_acc: 0.2999
Step: 14122, loss: 2.946288, norm: 0.2891, time(ms): 798.64, token/sec:656477.57, hellaswag_acc: 0.2999
Step: 14123, loss: 2.974697, norm: 0.2673, time(ms): 792.80, token/sec:661311.85, hellaswag_acc: 0.2999
Step: 14124, loss: 2.974758, norm: 0.2788, time(ms): 806.11, token/sec:650392.32, hellaswag_acc: 0.2999
Step: 14125, loss: 2.935291, norm: 0.2695, time(ms): 800.58, token/sec:654886.94, hellaswag_acc: 0.2999
Step: 14126, loss: 2.946393, norm: 0.2829, time(ms): 799.11, token/sec:656093.67, hellaswag_acc: 0.2999
Step: 14127, loss: 3.052070, norm: 0.2698, time(ms): 797.14, token/sec:657715.35, hellaswag_acc: 0.2999
Step: 14128, loss: 3.128985, norm: 0.2731, time(ms): 804.27, token/sec:651882.30, hellaswag_acc: 0.2999
Step: 14129, loss: 3.174972, norm: 0.2869, time(ms): 800.72, token/sec:654770.73, hellaswag_acc: 0.2999
Step: 14130, loss: 3.085620, norm: 0.2749, time(ms): 789.49, token/sec:664083.82, hellaswag_acc: 0.2999
Step: 14131, loss: 3.110900, norm: 0.2810, time(ms): 790.24, token/sec:663452.10, hellaswag_acc: 0.2999
Step: 14132, loss: 3.162332, norm: 0.2875, time(ms): 796.45, token/sec:658279.43, hellaswag_acc: 0.2999
Step: 14133, loss: 3.122159, norm: 0.3132, time(ms): 800.67, token/sec:654812.65, hellaswag_acc: 0.2999
Step: 14134, loss: 3.108487, norm: 0.2811, time(ms): 798.01, token/sec:656994.97, hellaswag_acc: 0.2999
Step: 14135, loss: 3.067954, norm: 0.2871, time(ms): 802.56, token/sec:653269.46, hellaswag_acc: 0.2999
Step: 14136, loss: 3.163790, norm: 0.3065, time(ms): 797.02, token/sec:657807.23, hellaswag_acc: 0.2999
Step: 14137, loss: 3.085400, norm: 0.3282, time(ms): 800.19, token/sec:655201.29, hellaswag_acc: 0.2999
Step: 14138, loss: 3.087997, norm: 0.3059, time(ms): 799.91, token/sec:655436.61, hellaswag_acc: 0.2999
Step: 14139, loss: 3.139714, norm: 0.3328, time(ms): 795.10, token/sec:659396.07, hellaswag_acc: 0.2999
Step: 14140, loss: 3.091779, norm: 0.2875, time(ms): 793.63, token/sec:660621.47, hellaswag_acc: 0.2999
Step: 14141, loss: 3.084517, norm: 0.3108, time(ms): 796.68, token/sec:658094.25, hellaswag_acc: 0.2999
Step: 14142, loss: 3.135687, norm: 0.2964, time(ms): 790.18, token/sec:663506.95, hellaswag_acc: 0.2999
Step: 14143, loss: 3.098869, norm: 0.3366, time(ms): 790.86, token/sec:662929.88, hellaswag_acc: 0.2999
Step: 14144, loss: 3.098099, norm: 0.3191, time(ms): 791.90, token/sec:662066.25, hellaswag_acc: 0.2999
Step: 14145, loss: 3.154636, norm: 0.3243, time(ms): 803.53, token/sec:652479.20, hellaswag_acc: 0.2999
Step: 14146, loss: 3.113010, norm: 0.3255, time(ms): 797.83, token/sec:657145.95, hellaswag_acc: 0.2999
Step: 14147, loss: 3.156390, norm: 0.3034, time(ms): 801.77, token/sec:653913.24, hellaswag_acc: 0.2999
Step: 14148, loss: 3.123788, norm: 0.3157, time(ms): 795.31, token/sec:659226.66, hellaswag_acc: 0.2999
Step: 14149, loss: 3.118499, norm: 0.3100, time(ms): 801.45, token/sec:654174.69, hellaswag_acc: 0.2999
Step: 14150, loss: 3.149254, norm: 0.2845, time(ms): 804.09, token/sec:652029.01, hellaswag_acc: 0.2999
Step: 14151, loss: 3.118676, norm: 0.2935, time(ms): 797.98, token/sec:657019.11, hellaswag_acc: 0.2999
Step: 14152, loss: 3.078845, norm: 0.2838, time(ms): 795.26, token/sec:659262.04, hellaswag_acc: 0.2999
Step: 14153, loss: 3.119902, norm: 0.2821, time(ms): 802.87, token/sec:653017.85, hellaswag_acc: 0.2999
Step: 14154, loss: 3.161361, norm: 0.3299, time(ms): 802.70, token/sec:653159.64, hellaswag_acc: 0.2999
Step: 14155, loss: 3.090409, norm: 0.2658, time(ms): 799.30, token/sec:655933.59, hellaswag_acc: 0.2999
Step: 14156, loss: 3.053849, norm: 0.2716, time(ms): 795.33, token/sec:659208.48, hellaswag_acc: 0.2999
Step: 14157, loss: 3.088024, norm: 0.2695, time(ms): 799.31, token/sec:655924.00, hellaswag_acc: 0.2999
Step: 14158, loss: 3.064795, norm: 0.2636, time(ms): 805.72, token/sec:650708.72, hellaswag_acc: 0.2999
Step: 14159, loss: 3.094211, norm: 0.2845, time(ms): 800.83, token/sec:654682.03, hellaswag_acc: 0.2999
Step: 14160, loss: 3.094147, norm: 0.2829, time(ms): 784.00, token/sec:668735.78, hellaswag_acc: 0.2999
Step: 14161, loss: 3.080617, norm: 0.2726, time(ms): 796.41, token/sec:658314.12, hellaswag_acc: 0.2999
Step: 14162, loss: 3.148768, norm: 0.2661, time(ms): 790.97, token/sec:662842.95, hellaswag_acc: 0.2999
Step: 14163, loss: 3.076246, norm: 0.3073, time(ms): 792.85, token/sec:661270.88, hellaswag_acc: 0.2999
Step: 14164, loss: 3.013062, norm: 0.2898, time(ms): 790.10, token/sec:663572.02, hellaswag_acc: 0.2999
Step: 14165, loss: 2.928908, norm: 0.2925, time(ms): 799.71, token/sec:655601.14, hellaswag_acc: 0.2999
Step: 14166, loss: 2.957188, norm: 0.3352, time(ms): 804.16, token/sec:651970.82, hellaswag_acc: 0.2999
Step: 14167, loss: 2.912918, norm: 0.3073, time(ms): 797.94, token/sec:657052.09, hellaswag_acc: 0.2999
Step: 14168, loss: 2.978674, norm: 0.3093, time(ms): 792.14, token/sec:661862.00, hellaswag_acc: 0.2999
Step: 14169, loss: 2.925035, norm: 0.2977, time(ms): 797.93, token/sec:657057.39, hellaswag_acc: 0.2999
Step: 14170, loss: 2.911563, norm: 0.3019, time(ms): 792.40, token/sec:661642.15, hellaswag_acc: 0.2999
Step: 14171, loss: 2.962266, norm: 0.2932, time(ms): 792.43, token/sec:661622.64, hellaswag_acc: 0.2999
Step: 14172, loss: 2.988881, norm: 0.2897, time(ms): 792.31, token/sec:661718.40, hellaswag_acc: 0.2999
Step: 14173, loss: 2.958433, norm: 0.2836, time(ms): 788.67, token/sec:664772.61, hellaswag_acc: 0.2999
Step: 14174, loss: 2.966391, norm: 0.3076, time(ms): 802.02, token/sec:653710.10, hellaswag_acc: 0.2999
Step: 14175, loss: 2.941377, norm: 0.2671, time(ms): 791.96, token/sec:662010.44, hellaswag_acc: 0.2999
Step: 14176, loss: 3.164776, norm: 0.3505, time(ms): 791.57, token/sec:662343.43, hellaswag_acc: 0.2999
Step: 14177, loss: 3.117202, norm: 0.3100, time(ms): 798.18, token/sec:656855.63, hellaswag_acc: 0.2999
Step: 14178, loss: 3.161794, norm: 0.3260, time(ms): 790.84, token/sec:662951.06, hellaswag_acc: 0.2999
Step: 14179, loss: 3.093226, norm: 0.3698, time(ms): 807.22, token/sec:649497.33, hellaswag_acc: 0.2999
Step: 14180, loss: 3.092327, norm: 0.3061, time(ms): 802.29, token/sec:653488.83, hellaswag_acc: 0.2999
Step: 14181, loss: 3.125482, norm: 0.3088, time(ms): 790.62, token/sec:663137.39, hellaswag_acc: 0.2999
Step: 14182, loss: 3.272937, norm: 0.3763, time(ms): 797.05, token/sec:657784.21, hellaswag_acc: 0.2999
Step: 14183, loss: 3.128166, norm: 0.3509, time(ms): 791.13, token/sec:662704.12, hellaswag_acc: 0.2999
Step: 14184, loss: 3.218530, norm: 0.3218, time(ms): 793.19, token/sec:660990.62, hellaswag_acc: 0.2999
Step: 14185, loss: 3.144073, norm: 0.3256, time(ms): 788.05, token/sec:665294.72, hellaswag_acc: 0.2999
Step: 14186, loss: 3.103549, norm: 0.3262, time(ms): 789.75, token/sec:663864.69, hellaswag_acc: 0.2999
Step: 14187, loss: 3.147788, norm: 0.3234, time(ms): 804.24, token/sec:651902.59, hellaswag_acc: 0.2999
Step: 14188, loss: 3.093435, norm: 0.2786, time(ms): 805.03, token/sec:651269.13, hellaswag_acc: 0.2999
Step: 14189, loss: 3.101586, norm: 0.3196, time(ms): 795.20, token/sec:659318.18, hellaswag_acc: 0.2999
Step: 14190, loss: 3.132737, norm: 0.2900, time(ms): 795.94, token/sec:658704.56, hellaswag_acc: 0.2999
Step: 14191, loss: 3.149591, norm: 0.2953, time(ms): 804.01, token/sec:652091.85, hellaswag_acc: 0.2999
Step: 14192, loss: 3.110096, norm: 0.2785, time(ms): 800.60, token/sec:654867.25, hellaswag_acc: 0.2999
Step: 14193, loss: 3.048479, norm: 0.3234, time(ms): 799.21, token/sec:656011.27, hellaswag_acc: 0.2999
Step: 14194, loss: 3.147345, norm: 0.2916, time(ms): 799.66, token/sec:655636.13, hellaswag_acc: 0.2999
Step: 14195, loss: 3.110120, norm: 0.2940, time(ms): 798.12, token/sec:656905.08, hellaswag_acc: 0.2999
Step: 14196, loss: 3.053573, norm: 0.2919, time(ms): 801.61, token/sec:654045.49, hellaswag_acc: 0.2999
Step: 14197, loss: 3.104250, norm: 0.2765, time(ms): 800.09, token/sec:655288.95, hellaswag_acc: 0.2999
Step: 14198, loss: 3.146913, norm: 0.2815, time(ms): 800.17, token/sec:655218.27, hellaswag_acc: 0.2999
Step: 14199, loss: 3.151411, norm: 0.3037, time(ms): 797.68, token/sec:657264.97, hellaswag_acc: 0.2999
Step: 14200, loss: 3.141470, norm: 0.3064, time(ms): 801.57, token/sec:654078.76, hellaswag_acc: 0.2999
Step: 14201, loss: 3.050552, norm: 0.2933, time(ms): 801.94, token/sec:653773.46, hellaswag_acc: 0.2999
Step: 14202, loss: 3.073197, norm: 0.3036, time(ms): 797.69, token/sec:657257.90, hellaswag_acc: 0.2999
Step: 14203, loss: 3.093338, norm: 0.2891, time(ms): 798.05, token/sec:656960.42, hellaswag_acc: 0.2999
Step: 14204, loss: 3.030112, norm: 0.2966, time(ms): 800.88, token/sec:654637.59, hellaswag_acc: 0.2999
Step: 14205, loss: 3.077605, norm: 0.3004, time(ms): 801.24, token/sec:654344.04, hellaswag_acc: 0.2999
Step: 14206, loss: 3.122932, norm: 0.2968, time(ms): 800.39, token/sec:655040.47, hellaswag_acc: 0.2999
Step: 14207, loss: 3.098079, norm: 0.2973, time(ms): 794.85, token/sec:659609.68, hellaswag_acc: 0.2999
Step: 14208, loss: 3.126328, norm: 0.2792, time(ms): 804.16, token/sec:651972.75, hellaswag_acc: 0.2999
Step: 14209, loss: 3.082825, norm: 0.2731, time(ms): 801.57, token/sec:654075.65, hellaswag_acc: 0.2999
Step: 14210, loss: 3.105315, norm: 0.2912, time(ms): 792.82, token/sec:661296.14, hellaswag_acc: 0.2999
Step: 14211, loss: 3.025776, norm: 0.3085, time(ms): 796.85, token/sec:657952.68, hellaswag_acc: 0.2999
Step: 14212, loss: 2.966127, norm: 0.3064, time(ms): 791.84, token/sec:662114.69, hellaswag_acc: 0.2999
Step: 14213, loss: 2.983683, norm: 0.3063, time(ms): 791.04, token/sec:662783.02, hellaswag_acc: 0.2999
Step: 14214, loss: 2.970542, norm: 0.3056, time(ms): 794.26, token/sec:660095.57, hellaswag_acc: 0.2999
Step: 14215, loss: 2.946451, norm: 0.3195, time(ms): 787.43, token/sec:665825.11, hellaswag_acc: 0.2999
Step: 14216, loss: 2.928556, norm: 0.2836, time(ms): 793.39, token/sec:660819.20, hellaswag_acc: 0.2999
Step: 14217, loss: 2.923005, norm: 0.2899, time(ms): 792.87, token/sec:661250.40, hellaswag_acc: 0.2999
Step: 14218, loss: 2.978147, norm: 0.2977, time(ms): 789.81, token/sec:663816.80, hellaswag_acc: 0.2999
Step: 14219, loss: 3.045569, norm: 0.2975, time(ms): 788.46, token/sec:664951.92, hellaswag_acc: 0.2999
Step: 14220, loss: 2.974587, norm: 0.2991, time(ms): 795.42, token/sec:659131.03, hellaswag_acc: 0.2999
Step: 14221, loss: 2.946560, norm: 0.2835, time(ms): 795.84, token/sec:658786.65, hellaswag_acc: 0.2999
Step: 14222, loss: 2.911522, norm: 0.2779, time(ms): 789.59, token/sec:664003.01, hellaswag_acc: 0.2999
Step: 14223, loss: 3.025017, norm: 0.2918, time(ms): 795.95, token/sec:658696.67, hellaswag_acc: 0.2999
Step: 14224, loss: 3.122405, norm: 0.3205, time(ms): 797.30, token/sec:657579.44, hellaswag_acc: 0.2999
Step: 14225, loss: 3.053892, norm: 0.2963, time(ms): 801.80, token/sec:653888.93, hellaswag_acc: 0.2999
Step: 14226, loss: 3.158543, norm: 0.3344, time(ms): 804.50, token/sec:651693.75, hellaswag_acc: 0.2999
Step: 14227, loss: 3.143215, norm: 0.2867, time(ms): 789.65, token/sec:663946.47, hellaswag_acc: 0.2999
Step: 14228, loss: 3.165391, norm: 0.3192, time(ms): 797.20, token/sec:657662.44, hellaswag_acc: 0.2999
Step: 14229, loss: 3.115263, norm: 0.2830, time(ms): 792.61, token/sec:661468.80, hellaswag_acc: 0.2999
Step: 14230, loss: 3.121140, norm: 0.2853, time(ms): 794.66, token/sec:659767.41, hellaswag_acc: 0.2999
Step: 14231, loss: 3.112545, norm: 0.3054, time(ms): 798.05, token/sec:656958.66, hellaswag_acc: 0.2999
Step: 14232, loss: 3.194231, norm: 0.3342, time(ms): 802.37, token/sec:653423.40, hellaswag_acc: 0.2999
Step: 14233, loss: 3.231558, norm: 0.3043, time(ms): 800.48, token/sec:654966.72, hellaswag_acc: 0.2999
Step: 14234, loss: 3.145076, norm: 0.2939, time(ms): 797.91, token/sec:657078.40, hellaswag_acc: 0.2999
Step: 14235, loss: 3.109906, norm: 0.3111, time(ms): 799.36, token/sec:655884.09, hellaswag_acc: 0.2999
Step: 14236, loss: 3.124830, norm: 0.3018, time(ms): 801.42, token/sec:654199.99, hellaswag_acc: 0.2999
Step: 14237, loss: 3.112849, norm: 0.3141, time(ms): 800.12, token/sec:655260.84, hellaswag_acc: 0.2999
Step: 14238, loss: 3.108137, norm: 0.3089, time(ms): 793.94, token/sec:660364.77, hellaswag_acc: 0.2999
Step: 14239, loss: 3.064750, norm: 0.2872, time(ms): 798.65, token/sec:656470.32, hellaswag_acc: 0.2999
Step: 14240, loss: 3.037079, norm: 0.2925, time(ms): 797.70, token/sec:657245.92, hellaswag_acc: 0.2999
Step: 14241, loss: 3.165164, norm: 0.2852, time(ms): 796.64, token/sec:658124.19, hellaswag_acc: 0.2999
Step: 14242, loss: 3.087621, norm: 0.3042, time(ms): 789.88, token/sec:663754.89, hellaswag_acc: 0.2999
Step: 14243, loss: 3.151959, norm: 0.2784, time(ms): 788.96, token/sec:664532.75, hellaswag_acc: 0.2999
Step: 14244, loss: 3.109967, norm: 0.2813, time(ms): 795.28, token/sec:659253.15, hellaswag_acc: 0.2999
Step: 14245, loss: 3.119014, norm: 0.2863, time(ms): 798.80, token/sec:656346.68, hellaswag_acc: 0.2999
Step: 14246, loss: 3.060622, norm: 0.2794, time(ms): 800.30, token/sec:655113.45, hellaswag_acc: 0.2999
Step: 14247, loss: 3.130998, norm: 0.2892, time(ms): 801.79, token/sec:653899.05, hellaswag_acc: 0.2999
Step: 14248, loss: 3.080145, norm: 0.2725, time(ms): 791.61, token/sec:662308.33, hellaswag_acc: 0.2999
Step: 14249, loss: 3.045692, norm: 0.2720, time(ms): 806.06, token/sec:650436.18, hellaswag_acc: 0.2999
rank 0 sample 0: Hello, I'm a language model, and I don't understand a bunch of them very well.
My brother was a native speaker in Japan. He speaks
rank 0 sample 1: Hello, I'm a language model, so please come back.
So on the left from "The Future of Learning", you've seen two things:

rank 0 sample 2: Hello, I'm a language model, so I might need to take a break. My wife is going into the kitchen and she's going to get some groceries
rank 0 sample 3: Hello, I'm a language model, you will be the one who is talking about model.
(i) Model example - what does a model consist of
rank 1 sample 0: Hello, I'm a language model, this is the language model, this explains what an English language system is. How do we model language? What is the
rank 1 sample 1: Hello, I'm a language model, not an algorithm. I'm not. Let's get in some way to that, is there some kind of a problem
rank 1 sample 2: Hello, I'm a language model, I say I'm a language model, I'm a language model, I'm a language model, I'm a language
rank 1 sample 3: Hello, I'm a language model, and I'm an interpreter: I'm somebody who just watches my TV...or I may I might watch something and say
Step: 14250, loss: 3.108305, norm: 0.2788, time(ms): 3807.70, token/sec:137691.51, val_loss: 3.1121, hellaswag_acc: 0.2999
Step: 14251, loss: 3.102449, norm: 0.2855, time(ms): 781.09, token/sec:671228.55, hellaswag_acc: 0.2999
Step: 14252, loss: 3.116270, norm: 0.2611, time(ms): 786.06, token/sec:666980.06, hellaswag_acc: 0.2999
Step: 14253, loss: 3.097825, norm: 0.2855, time(ms): 798.24, token/sec:656804.03, hellaswag_acc: 0.2999
Step: 14254, loss: 3.090175, norm: 0.2749, time(ms): 797.75, token/sec:657205.65, hellaswag_acc: 0.2999
Step: 14255, loss: 3.086256, norm: 0.2717, time(ms): 790.80, token/sec:662981.04, hellaswag_acc: 0.2999
Step: 14256, loss: 3.067701, norm: 0.2650, time(ms): 787.69, token/sec:665602.82, hellaswag_acc: 0.2999
Step: 14257, loss: 3.053477, norm: 0.2708, time(ms): 791.58, token/sec:662328.07, hellaswag_acc: 0.2999
Step: 14258, loss: 3.083755, norm: 0.2754, time(ms): 798.47, token/sec:656617.53, hellaswag_acc: 0.2999
Step: 14259, loss: 3.026928, norm: 0.2752, time(ms): 787.64, token/sec:665645.94, hellaswag_acc: 0.2999
Step: 14260, loss: 2.930611, norm: 0.2712, time(ms): 786.80, token/sec:666358.57, hellaswag_acc: 0.2999
Step: 14261, loss: 2.901351, norm: 0.2897, time(ms): 795.56, token/sec:659017.05, hellaswag_acc: 0.2999
Step: 14262, loss: 2.947100, norm: 0.2729, time(ms): 791.00, token/sec:662817.38, hellaswag_acc: 0.2999
Step: 14263, loss: 2.898512, norm: 0.2839, time(ms): 798.55, token/sec:656554.01, hellaswag_acc: 0.2999
Step: 14264, loss: 2.952288, norm: 0.2790, time(ms): 798.29, token/sec:656766.17, hellaswag_acc: 0.2999
Step: 14265, loss: 2.984936, norm: 0.2759, time(ms): 798.11, token/sec:656915.48, hellaswag_acc: 0.2999
Step: 14266, loss: 2.926148, norm: 0.2657, time(ms): 802.66, token/sec:653191.85, hellaswag_acc: 0.2999
Step: 14267, loss: 2.945233, norm: 0.2804, time(ms): 801.89, token/sec:653815.64, hellaswag_acc: 0.2999
Step: 14268, loss: 2.926922, norm: 0.2887, time(ms): 794.14, token/sec:660199.22, hellaswag_acc: 0.2999
Step: 14269, loss: 2.900735, norm: 0.2756, time(ms): 798.73, token/sec:656400.56, hellaswag_acc: 0.2999
Step: 14270, loss: 2.896985, norm: 0.2785, time(ms): 803.76, token/sec:652293.59, hellaswag_acc: 0.2999
Step: 14271, loss: 2.962164, norm: 0.2814, time(ms): 801.94, token/sec:653773.85, hellaswag_acc: 0.2999
Step: 14272, loss: 3.139075, norm: 0.3086, time(ms): 791.90, token/sec:662063.26, hellaswag_acc: 0.2999
Step: 14273, loss: 3.111153, norm: 0.2970, time(ms): 802.74, token/sec:653120.26, hellaswag_acc: 0.2999
Step: 14274, loss: 3.152897, norm: 0.2948, time(ms): 805.55, token/sec:650841.60, hellaswag_acc: 0.2999
Step: 14275, loss: 3.112954, norm: 0.2914, time(ms): 793.72, token/sec:660546.66, hellaswag_acc: 0.2999
Step: 14276, loss: 3.074144, norm: 0.3135, time(ms): 803.34, token/sec:652634.89, hellaswag_acc: 0.2999
Step: 14277, loss: 3.168901, norm: 0.3006, time(ms): 800.77, token/sec:654732.52, hellaswag_acc: 0.2999
Step: 14278, loss: 3.103342, norm: 0.3032, time(ms): 800.27, token/sec:655138.43, hellaswag_acc: 0.2999
Step: 14279, loss: 3.087356, norm: 0.2838, time(ms): 791.81, token/sec:662142.40, hellaswag_acc: 0.2999
Step: 14280, loss: 3.117646, norm: 0.2770, time(ms): 805.93, token/sec:650540.09, hellaswag_acc: 0.2999
Step: 14281, loss: 3.127069, norm: 0.2804, time(ms): 802.13, token/sec:653619.75, hellaswag_acc: 0.2999
Step: 14282, loss: 3.083428, norm: 0.2917, time(ms): 798.58, token/sec:656523.04, hellaswag_acc: 0.2999
Step: 14283, loss: 3.129731, norm: 0.2930, time(ms): 790.21, token/sec:663482.92, hellaswag_acc: 0.2999
Step: 14284, loss: 3.116270, norm: 0.2860, time(ms): 792.52, token/sec:661547.00, hellaswag_acc: 0.2999
Step: 14285, loss: 3.134909, norm: 0.2858, time(ms): 792.08, token/sec:661914.20, hellaswag_acc: 0.2999
Step: 14286, loss: 3.131304, norm: 0.3286, time(ms): 790.09, token/sec:663579.43, hellaswag_acc: 0.2999
Step: 14287, loss: 3.103433, norm: 0.2748, time(ms): 1318.70, token/sec:397578.84, hellaswag_acc: 0.2999
Step: 14288, loss: 3.018754, norm: 0.3030, time(ms): 795.34, token/sec:659201.76, hellaswag_acc: 0.2999
Step: 14289, loss: 3.097537, norm: 0.2880, time(ms): 788.54, token/sec:664887.78, hellaswag_acc: 0.2999
Step: 14290, loss: 3.083977, norm: 0.2946, time(ms): 784.09, token/sec:668658.31, hellaswag_acc: 0.2999
Step: 14291, loss: 3.086924, norm: 0.3249, time(ms): 802.43, token/sec:653371.37, hellaswag_acc: 0.2999
Step: 14292, loss: 3.112724, norm: 0.3243, time(ms): 800.63, token/sec:654845.60, hellaswag_acc: 0.2999
Step: 14293, loss: 3.103207, norm: 0.3314, time(ms): 796.61, token/sec:658146.84, hellaswag_acc: 0.2999
Step: 14294, loss: 3.001925, norm: 0.3214, time(ms): 794.67, token/sec:659759.30, hellaswag_acc: 0.2999
Step: 14295, loss: 3.058677, norm: 0.3001, time(ms): 790.47, token/sec:663264.80, hellaswag_acc: 0.2999
Step: 14296, loss: 3.086520, norm: 0.2899, time(ms): 801.69, token/sec:653982.47, hellaswag_acc: 0.2999
Step: 14297, loss: 3.040644, norm: 0.2732, time(ms): 793.33, token/sec:660872.82, hellaswag_acc: 0.2999
Step: 14298, loss: 2.981812, norm: 0.3031, time(ms): 797.12, token/sec:657729.51, hellaswag_acc: 0.2999
Step: 14299, loss: 3.095087, norm: 0.2802, time(ms): 788.38, token/sec:665018.08, hellaswag_acc: 0.2999
Step: 14300, loss: 3.113842, norm: 0.3032, time(ms): 787.01, token/sec:666177.29, hellaswag_acc: 0.2999
Step: 14301, loss: 3.105048, norm: 0.2956, time(ms): 790.44, token/sec:663289.80, hellaswag_acc: 0.2999
Step: 14302, loss: 3.123270, norm: 0.2982, time(ms): 799.97, token/sec:655385.24, hellaswag_acc: 0.2999
Step: 14303, loss: 3.088881, norm: 0.2752, time(ms): 802.98, token/sec:652929.44, hellaswag_acc: 0.2999
Step: 14304, loss: 3.061946, norm: 0.2820, time(ms): 800.30, token/sec:655111.11, hellaswag_acc: 0.2999
Step: 14305, loss: 3.106209, norm: 0.2915, time(ms): 793.52, token/sec:660710.40, hellaswag_acc: 0.2999
Step: 14306, loss: 3.139753, norm: 0.3078, time(ms): 803.78, token/sec:652277.73, hellaswag_acc: 0.2999
Step: 14307, loss: 3.106936, norm: 0.2966, time(ms): 801.71, token/sec:653964.19, hellaswag_acc: 0.2999
Step: 14308, loss: 3.101285, norm: 0.2882, time(ms): 801.88, token/sec:653827.30, hellaswag_acc: 0.2999
Step: 14309, loss: 3.060566, norm: 0.2717, time(ms): 787.77, token/sec:665533.12, hellaswag_acc: 0.2999
Step: 14310, loss: 3.020368, norm: 0.2873, time(ms): 791.27, token/sec:662590.30, hellaswag_acc: 0.2999
Step: 14311, loss: 3.119637, norm: 0.2715, time(ms): 793.07, token/sec:661083.02, hellaswag_acc: 0.2999
Step: 14312, loss: 3.103863, norm: 0.2992, time(ms): 794.14, token/sec:660197.44, hellaswag_acc: 0.2999
Step: 14313, loss: 3.076653, norm: 0.2497, time(ms): 791.88, token/sec:662077.01, hellaswag_acc: 0.2999
Step: 14314, loss: 3.077854, norm: 0.2823, time(ms): 792.62, token/sec:661461.24, hellaswag_acc: 0.2999
Step: 14315, loss: 3.008386, norm: 0.2824, time(ms): 801.56, token/sec:654084.99, hellaswag_acc: 0.2999
Step: 14316, loss: 3.087074, norm: 0.2843, time(ms): 805.02, token/sec:651274.34, hellaswag_acc: 0.2999
Step: 14317, loss: 3.053360, norm: 0.2644, time(ms): 791.92, token/sec:662044.52, hellaswag_acc: 0.2999
Step: 14318, loss: 3.113856, norm: 0.2692, time(ms): 797.28, token/sec:657592.03, hellaswag_acc: 0.2999
Step: 14319, loss: 3.002762, norm: 0.2633, time(ms): 792.50, token/sec:661562.53, hellaswag_acc: 0.2999
Step: 14320, loss: 3.079258, norm: 0.2635, time(ms): 796.48, token/sec:658254.21, hellaswag_acc: 0.2999
Step: 14321, loss: 3.061307, norm: 0.2689, time(ms): 791.90, token/sec:662064.46, hellaswag_acc: 0.2999
Step: 14322, loss: 3.046863, norm: 0.2726, time(ms): 790.72, token/sec:663054.61, hellaswag_acc: 0.2999
Step: 14323, loss: 3.079079, norm: 0.2626, time(ms): 788.76, token/sec:664700.27, hellaswag_acc: 0.2999
Step: 14324, loss: 3.097231, norm: 0.2666, time(ms): 790.96, token/sec:662850.35, hellaswag_acc: 0.2999
Step: 14325, loss: 3.050131, norm: 0.2834, time(ms): 789.40, token/sec:664157.43, hellaswag_acc: 0.2999
Step: 14326, loss: 3.097319, norm: 0.2923, time(ms): 800.86, token/sec:654654.74, hellaswag_acc: 0.2999
Step: 14327, loss: 3.117947, norm: 0.2683, time(ms): 806.02, token/sec:650463.31, hellaswag_acc: 0.2999
Step: 14328, loss: 3.131163, norm: 0.3067, time(ms): 802.49, token/sec:653324.78, hellaswag_acc: 0.2999
Step: 14329, loss: 3.106283, norm: 0.3273, time(ms): 795.23, token/sec:659291.49, hellaswag_acc: 0.2999
Step: 14330, loss: 3.007485, norm: 0.3131, time(ms): 797.89, token/sec:657090.77, hellaswag_acc: 0.2999
Step: 14331, loss: 3.122348, norm: 0.2965, time(ms): 804.97, token/sec:651314.85, hellaswag_acc: 0.2999
Step: 14332, loss: 3.101535, norm: 0.3021, time(ms): 800.64, token/sec:654839.36, hellaswag_acc: 0.2999
Step: 14333, loss: 3.054079, norm: 0.3339, time(ms): 787.32, token/sec:665910.60, hellaswag_acc: 0.2999
Step: 14334, loss: 3.131608, norm: 0.3487, time(ms): 793.68, token/sec:660582.38, hellaswag_acc: 0.2999
Step: 14335, loss: 3.034400, norm: 0.3268, time(ms): 791.85, token/sec:662107.11, hellaswag_acc: 0.2999
Step: 14336, loss: 3.145605, norm: 0.3380, time(ms): 790.27, token/sec:663428.68, hellaswag_acc: 0.2999
Step: 14337, loss: 3.068357, norm: 0.3083, time(ms): 791.08, token/sec:662747.06, hellaswag_acc: 0.2999
Step: 14338, loss: 3.125251, norm: 0.3112, time(ms): 799.40, token/sec:655852.99, hellaswag_acc: 0.2999
Step: 14339, loss: 3.079927, norm: 0.2791, time(ms): 804.20, token/sec:651941.05, hellaswag_acc: 0.2999
Step: 14340, loss: 3.126970, norm: 0.2944, time(ms): 797.24, token/sec:657631.75, hellaswag_acc: 0.2999
Step: 14341, loss: 3.066151, norm: 0.2694, time(ms): 793.00, token/sec:661148.21, hellaswag_acc: 0.2999
Step: 14342, loss: 3.089379, norm: 0.2931, time(ms): 798.69, token/sec:656434.65, hellaswag_acc: 0.2999
Step: 14343, loss: 3.078751, norm: 0.2629, time(ms): 793.58, token/sec:660658.59, hellaswag_acc: 0.2999
Step: 14344, loss: 3.114655, norm: 0.2675, time(ms): 793.90, token/sec:660393.52, hellaswag_acc: 0.2999
Step: 14345, loss: 3.155643, norm: 0.3240, time(ms): 790.40, token/sec:663319.61, hellaswag_acc: 0.2999
Step: 14346, loss: 3.053484, norm: 0.2669, time(ms): 789.16, token/sec:664359.29, hellaswag_acc: 0.2999
Step: 14347, loss: 3.058085, norm: 0.2844, time(ms): 788.93, token/sec:664553.63, hellaswag_acc: 0.2999
Step: 14348, loss: 3.058725, norm: 0.2802, time(ms): 792.88, token/sec:661249.21, hellaswag_acc: 0.2999
Step: 14349, loss: 3.050844, norm: 0.2850, time(ms): 791.23, token/sec:662622.85, hellaswag_acc: 0.2999
Step: 14350, loss: 3.050796, norm: 0.4639, time(ms): 808.55, token/sec:648431.72, hellaswag_acc: 0.2999
Step: 14351, loss: 3.074159, norm: 0.2822, time(ms): 801.91, token/sec:653799.89, hellaswag_acc: 0.2999
Step: 14352, loss: 3.019025, norm: 0.2794, time(ms): 787.10, token/sec:666103.23, hellaswag_acc: 0.2999
Step: 14353, loss: 3.091519, norm: 0.2941, time(ms): 800.91, token/sec:654615.77, hellaswag_acc: 0.2999
Step: 14354, loss: 3.025773, norm: 0.2627, time(ms): 796.38, token/sec:658338.75, hellaswag_acc: 0.2999
Step: 14355, loss: 3.044382, norm: 0.2675, time(ms): 795.79, token/sec:658830.07, hellaswag_acc: 0.2999
Step: 14356, loss: 3.060735, norm: 0.2799, time(ms): 792.90, token/sec:661226.54, hellaswag_acc: 0.2999
Step: 14357, loss: 3.055828, norm: 0.2615, time(ms): 796.62, token/sec:658136.79, hellaswag_acc: 0.2999
Step: 14358, loss: 3.078961, norm: 0.2789, time(ms): 791.59, token/sec:662323.09, hellaswag_acc: 0.2999
Step: 14359, loss: 3.039341, norm: 0.2546, time(ms): 796.54, token/sec:658209.88, hellaswag_acc: 0.2999
Step: 14360, loss: 3.074848, norm: 0.2844, time(ms): 788.88, token/sec:664593.80, hellaswag_acc: 0.2999
Step: 14361, loss: 3.104255, norm: 0.2890, time(ms): 791.56, token/sec:662348.82, hellaswag_acc: 0.2999
Step: 14362, loss: 3.135887, norm: 0.2815, time(ms): 798.71, token/sec:656416.62, hellaswag_acc: 0.2999
Step: 14363, loss: 3.116097, norm: 0.3151, time(ms): 799.60, token/sec:655685.59, hellaswag_acc: 0.2999
Step: 14364, loss: 3.176901, norm: 0.3546, time(ms): 789.22, token/sec:664314.33, hellaswag_acc: 0.2999
Step: 14365, loss: 3.069494, norm: 0.2719, time(ms): 799.63, token/sec:655666.04, hellaswag_acc: 0.2999
Step: 14366, loss: 3.080965, norm: 0.3261, time(ms): 798.59, token/sec:656519.70, hellaswag_acc: 0.2999
Step: 14367, loss: 3.009462, norm: 0.3015, time(ms): 795.74, token/sec:658871.33, hellaswag_acc: 0.2999
Step: 14368, loss: 2.975930, norm: 0.2890, time(ms): 789.19, token/sec:664337.81, hellaswag_acc: 0.2999
Step: 14369, loss: 3.063430, norm: 0.3125, time(ms): 789.80, token/sec:663823.41, hellaswag_acc: 0.2999
Step: 14370, loss: 3.123094, norm: 0.2884, time(ms): 795.59, token/sec:658990.19, hellaswag_acc: 0.2999
Step: 14371, loss: 3.028865, norm: 0.2971, time(ms): 798.56, token/sec:656545.58, hellaswag_acc: 0.2999
Step: 14372, loss: 3.154441, norm: 0.3190, time(ms): 800.94, token/sec:654591.41, hellaswag_acc: 0.2999
Step: 14373, loss: 3.092416, norm: 0.3006, time(ms): 796.74, token/sec:658038.32, hellaswag_acc: 0.2999
Step: 14374, loss: 3.106430, norm: 0.2897, time(ms): 803.13, token/sec:652803.64, hellaswag_acc: 0.2999
Step: 14375, loss: 3.096146, norm: 0.2838, time(ms): 801.16, token/sec:654410.83, hellaswag_acc: 0.2999
Step: 14376, loss: 3.058104, norm: 0.2778, time(ms): 796.01, token/sec:658646.95, hellaswag_acc: 0.2999
Step: 14377, loss: 3.093133, norm: 0.3105, time(ms): 800.50, token/sec:654949.94, hellaswag_acc: 0.2999
Step: 14378, loss: 3.026395, norm: 0.2935, time(ms): 802.25, token/sec:653521.46, hellaswag_acc: 0.2999
Step: 14379, loss: 3.108599, norm: 0.2778, time(ms): 789.00, token/sec:664498.81, hellaswag_acc: 0.2999
Step: 14380, loss: 3.116247, norm: 0.3277, time(ms): 791.33, token/sec:662541.99, hellaswag_acc: 0.2999
Step: 14381, loss: 3.123784, norm: 0.3037, time(ms): 789.58, token/sec:664005.82, hellaswag_acc: 0.2999
Step: 14382, loss: 3.028741, norm: 0.3140, time(ms): 797.46, token/sec:657446.94, hellaswag_acc: 0.2999
Step: 14383, loss: 3.062483, norm: 0.2828, time(ms): 795.60, token/sec:658980.91, hellaswag_acc: 0.2999
Step: 14384, loss: 3.012573, norm: 0.3006, time(ms): 791.21, token/sec:662641.62, hellaswag_acc: 0.2999
Step: 14385, loss: 3.038344, norm: 0.2729, time(ms): 797.92, token/sec:657064.85, hellaswag_acc: 0.2999
Step: 14386, loss: 3.076390, norm: 0.2936, time(ms): 806.17, token/sec:650343.27, hellaswag_acc: 0.2999
Step: 14387, loss: 3.014227, norm: 0.2690, time(ms): 801.21, token/sec:654370.71, hellaswag_acc: 0.2999
Step: 14388, loss: 3.043503, norm: 0.2806, time(ms): 790.20, token/sec:663484.33, hellaswag_acc: 0.2999
Step: 14389, loss: 3.059931, norm: 0.3043, time(ms): 798.11, token/sec:656913.71, hellaswag_acc: 0.2999
Step: 14390, loss: 3.018331, norm: 0.2713, time(ms): 792.15, token/sec:661857.82, hellaswag_acc: 0.2999
Step: 14391, loss: 3.031466, norm: 0.2742, time(ms): 791.84, token/sec:662112.50, hellaswag_acc: 0.2999
Step: 14392, loss: 3.033411, norm: 0.2590, time(ms): 795.98, token/sec:658667.47, hellaswag_acc: 0.2999
Step: 14393, loss: 3.126498, norm: 0.2947, time(ms): 788.71, token/sec:664738.25, hellaswag_acc: 0.2999
Step: 14394, loss: 3.015285, norm: 0.2851, time(ms): 789.91, token/sec:663734.25, hellaswag_acc: 0.2999
Step: 14395, loss: 3.095417, norm: 0.2811, time(ms): 791.49, token/sec:662408.08, hellaswag_acc: 0.2999
Step: 14396, loss: 3.015095, norm: 0.3114, time(ms): 798.68, token/sec:656443.66, hellaswag_acc: 0.2999
Step: 14397, loss: 3.067289, norm: 0.3043, time(ms): 799.96, token/sec:655390.70, hellaswag_acc: 0.2999
Step: 14398, loss: 3.045715, norm: 0.2833, time(ms): 795.11, token/sec:659388.76, hellaswag_acc: 0.2999
Step: 14399, loss: 3.086344, norm: 0.2975, time(ms): 804.45, token/sec:651736.82, hellaswag_acc: 0.2999
Step: 14400, loss: 3.097224, norm: 0.2875, time(ms): 800.78, token/sec:654725.11, hellaswag_acc: 0.2999
Step: 14401, loss: 3.093347, norm: 0.3282, time(ms): 796.67, token/sec:658097.01, hellaswag_acc: 0.2999
Step: 14402, loss: 2.997038, norm: 0.2885, time(ms): 801.49, token/sec:654143.36, hellaswag_acc: 0.2999
Step: 14403, loss: 3.100977, norm: 0.3102, time(ms): 801.02, token/sec:654529.06, hellaswag_acc: 0.2999
Step: 14404, loss: 3.063626, norm: 0.3153, time(ms): 799.00, token/sec:656182.75, hellaswag_acc: 0.2999
Step: 14405, loss: 3.126908, norm: 0.3194, time(ms): 799.94, token/sec:655409.46, hellaswag_acc: 0.2999
Step: 14406, loss: 3.026604, norm: 0.3183, time(ms): 797.71, token/sec:657241.60, hellaswag_acc: 0.2999
Step: 14407, loss: 3.112897, norm: 0.3457, time(ms): 802.93, token/sec:652970.35, hellaswag_acc: 0.2999
Step: 14408, loss: 3.078624, norm: 0.3122, time(ms): 794.28, token/sec:660077.35, hellaswag_acc: 0.2999
Step: 14409, loss: 3.069290, norm: 0.2998, time(ms): 803.07, token/sec:652856.94, hellaswag_acc: 0.2999
Step: 14410, loss: 3.048895, norm: 0.3096, time(ms): 801.76, token/sec:653923.16, hellaswag_acc: 0.2999
Step: 14411, loss: 3.109640, norm: 0.2861, time(ms): 798.05, token/sec:656958.85, hellaswag_acc: 0.2999
Step: 14412, loss: 3.087580, norm: 0.2807, time(ms): 795.74, token/sec:658867.97, hellaswag_acc: 0.2999
Step: 14413, loss: 3.112631, norm: 0.2916, time(ms): 804.52, token/sec:651678.88, hellaswag_acc: 0.2999
Step: 14414, loss: 3.092406, norm: 0.2733, time(ms): 801.40, token/sec:654218.48, hellaswag_acc: 0.2999
Step: 14415, loss: 3.088257, norm: 0.2916, time(ms): 795.49, token/sec:659073.34, hellaswag_acc: 0.2999
Step: 14416, loss: 3.033435, norm: 0.2880, time(ms): 790.87, token/sec:662926.08, hellaswag_acc: 0.2999
Step: 14417, loss: 3.075309, norm: 0.2786, time(ms): 799.74, token/sec:655574.56, hellaswag_acc: 0.2999
Step: 14418, loss: 3.079423, norm: 0.3050, time(ms): 794.46, token/sec:659927.59, hellaswag_acc: 0.2999
Step: 14419, loss: 3.064453, norm: 0.2970, time(ms): 789.85, token/sec:663783.74, hellaswag_acc: 0.2999
Step: 14420, loss: 3.068662, norm: 0.3103, time(ms): 791.25, token/sec:662606.08, hellaswag_acc: 0.2999
Step: 14421, loss: 3.087936, norm: 0.2702, time(ms): 789.06, token/sec:664443.19, hellaswag_acc: 0.2999
Step: 14422, loss: 3.023672, norm: 0.2769, time(ms): 799.65, token/sec:655650.40, hellaswag_acc: 0.2999
Step: 14423, loss: 3.094905, norm: 0.2782, time(ms): 797.78, token/sec:657180.71, hellaswag_acc: 0.2999
Step: 14424, loss: 3.034995, norm: 0.2853, time(ms): 793.64, token/sec:660608.97, hellaswag_acc: 0.2999
Step: 14425, loss: 3.092225, norm: 0.2640, time(ms): 787.85, token/sec:665462.63, hellaswag_acc: 0.2999
Step: 14426, loss: 3.059835, norm: 0.2742, time(ms): 794.10, token/sec:660228.56, hellaswag_acc: 0.2999
Step: 14427, loss: 3.065925, norm: 0.2966, time(ms): 796.35, token/sec:658361.02, hellaswag_acc: 0.2999
Step: 14428, loss: 3.050612, norm: 0.2800, time(ms): 789.06, token/sec:664447.21, hellaswag_acc: 0.2999
Step: 14429, loss: 3.088196, norm: 0.2735, time(ms): 792.30, token/sec:661732.34, hellaswag_acc: 0.2999
Step: 14430, loss: 3.053505, norm: 0.2881, time(ms): 790.88, token/sec:662920.48, hellaswag_acc: 0.2999
Step: 14431, loss: 3.143197, norm: 0.2961, time(ms): 799.75, token/sec:655564.60, hellaswag_acc: 0.2999
Step: 14432, loss: 3.083807, norm: 0.2940, time(ms): 805.04, token/sec:651259.88, hellaswag_acc: 0.2999
Step: 14433, loss: 3.060879, norm: 0.2857, time(ms): 793.85, token/sec:660440.92, hellaswag_acc: 0.2999
Step: 14434, loss: 3.115464, norm: 0.2897, time(ms): 801.64, token/sec:654016.12, hellaswag_acc: 0.2999
Step: 14435, loss: 3.028218, norm: 0.2877, time(ms): 803.74, token/sec:652309.85, hellaswag_acc: 0.2999
Step: 14436, loss: 3.097999, norm: 0.3435, time(ms): 793.31, token/sec:660888.31, hellaswag_acc: 0.2999
Step: 14437, loss: 3.137380, norm: 0.2900, time(ms): 803.99, token/sec:652108.67, hellaswag_acc: 0.2999
Step: 14438, loss: 3.046130, norm: 0.3132, time(ms): 799.11, token/sec:656089.95, hellaswag_acc: 0.2999
Step: 14439, loss: 3.069546, norm: 0.3169, time(ms): 801.01, token/sec:654535.10, hellaswag_acc: 0.2999
Step: 14440, loss: 3.031850, norm: 0.3223, time(ms): 790.59, token/sec:663162.18, hellaswag_acc: 0.2999
Step: 14441, loss: 3.094362, norm: 0.3279, time(ms): 795.49, token/sec:659075.32, hellaswag_acc: 0.2999
Step: 14442, loss: 3.088260, norm: 0.2851, time(ms): 801.51, token/sec:654125.84, hellaswag_acc: 0.2999
Step: 14443, loss: 3.052997, norm: 0.3052, time(ms): 790.60, token/sec:663149.19, hellaswag_acc: 0.2999
Step: 14444, loss: 3.091541, norm: 0.3267, time(ms): 790.13, token/sec:663545.79, hellaswag_acc: 0.2999
Step: 14445, loss: 3.132326, norm: 0.3040, time(ms): 793.96, token/sec:660346.13, hellaswag_acc: 0.2999
Step: 14446, loss: 3.140307, norm: 0.3341, time(ms): 792.67, token/sec:661422.44, hellaswag_acc: 0.2999
Step: 14447, loss: 3.110553, norm: 0.3306, time(ms): 801.29, token/sec:654307.63, hellaswag_acc: 0.2999
Step: 14448, loss: 3.092479, norm: 0.2871, time(ms): 805.59, token/sec:650808.47, hellaswag_acc: 0.2999
Step: 14449, loss: 3.052143, norm: 0.3151, time(ms): 793.86, token/sec:660425.65, hellaswag_acc: 0.2999
Step: 14450, loss: 3.106993, norm: 0.2783, time(ms): 794.97, token/sec:659509.78, hellaswag_acc: 0.2999
Step: 14451, loss: 3.066880, norm: 0.2860, time(ms): 803.01, token/sec:652900.94, hellaswag_acc: 0.2999
Step: 14452, loss: 3.097157, norm: 0.2896, time(ms): 796.73, token/sec:658046.59, hellaswag_acc: 0.2999
Step: 14453, loss: 3.021007, norm: 0.2825, time(ms): 795.54, token/sec:659036.01, hellaswag_acc: 0.2999
Step: 14454, loss: 3.019534, norm: 0.2805, time(ms): 793.32, token/sec:660879.18, hellaswag_acc: 0.2999
Step: 14455, loss: 3.074795, norm: 0.3724, time(ms): 796.19, token/sec:658498.83, hellaswag_acc: 0.2999
Step: 14456, loss: 3.037271, norm: 0.2754, time(ms): 797.57, token/sec:657355.75, hellaswag_acc: 0.2999
Step: 14457, loss: 3.114514, norm: 0.3166, time(ms): 801.24, token/sec:654347.15, hellaswag_acc: 0.2999
Step: 14458, loss: 3.054059, norm: 0.2869, time(ms): 793.26, token/sec:660927.25, hellaswag_acc: 0.2999
Step: 14459, loss: 3.045527, norm: 0.2890, time(ms): 793.53, token/sec:660702.85, hellaswag_acc: 0.2999
Step: 14460, loss: 3.021422, norm: 0.2988, time(ms): 790.52, token/sec:663216.79, hellaswag_acc: 0.2999
Step: 14461, loss: 3.045924, norm: 0.2784, time(ms): 789.84, token/sec:663793.96, hellaswag_acc: 0.2999
Step: 14462, loss: 3.020254, norm: 0.2904, time(ms): 794.03, token/sec:660283.47, hellaswag_acc: 0.2999
Step: 14463, loss: 3.080931, norm: 0.2804, time(ms): 799.48, token/sec:655786.68, hellaswag_acc: 0.2999
Step: 14464, loss: 3.059587, norm: 0.3009, time(ms): 803.16, token/sec:652785.23, hellaswag_acc: 0.2999
Step: 14465, loss: 3.078029, norm: 0.3033, time(ms): 792.82, token/sec:661297.33, hellaswag_acc: 0.2999
Step: 14466, loss: 3.069212, norm: 0.2947, time(ms): 803.41, token/sec:652579.70, hellaswag_acc: 0.2999
Step: 14467, loss: 3.056648, norm: 0.3135, time(ms): 801.37, token/sec:654240.86, hellaswag_acc: 0.2999
Step: 14468, loss: 3.022698, norm: 0.3224, time(ms): 791.25, token/sec:662609.27, hellaswag_acc: 0.2999
Step: 14469, loss: 3.071473, norm: 0.2997, time(ms): 796.09, token/sec:658578.11, hellaswag_acc: 0.2999
Step: 14470, loss: 3.092992, norm: 0.3068, time(ms): 796.08, token/sec:658585.01, hellaswag_acc: 0.2999
Step: 14471, loss: 3.129488, norm: 0.3087, time(ms): 790.97, token/sec:662843.15, hellaswag_acc: 0.2999
Step: 14472, loss: 3.036221, norm: 0.3142, time(ms): 790.36, token/sec:663355.23, hellaswag_acc: 0.2999
Step: 14473, loss: 3.052829, norm: 0.2823, time(ms): 792.78, token/sec:661330.15, hellaswag_acc: 0.2999
Step: 14474, loss: 3.103400, norm: 0.2983, time(ms): 801.42, token/sec:654199.40, hellaswag_acc: 0.2999
Step: 14475, loss: 3.127673, norm: 0.2965, time(ms): 799.34, token/sec:655902.28, hellaswag_acc: 0.2999
Step: 14476, loss: 3.021842, norm: 0.3230, time(ms): 792.73, token/sec:661370.72, hellaswag_acc: 0.2999
Step: 14477, loss: 3.031926, norm: 0.2916, time(ms): 1342.88, token/sec:390421.42, hellaswag_acc: 0.2999
Step: 14478, loss: 3.040507, norm: 0.3112, time(ms): 771.52, token/sec:679554.03, hellaswag_acc: 0.2999
Step: 14479, loss: 3.095666, norm: 0.3047, time(ms): 786.45, token/sec:666654.31, hellaswag_acc: 0.2999
Step: 14480, loss: 3.029234, norm: 0.3306, time(ms): 802.07, token/sec:653667.16, hellaswag_acc: 0.2999
Step: 14481, loss: 3.108608, norm: 0.2935, time(ms): 792.20, token/sec:661814.19, hellaswag_acc: 0.2999
Step: 14482, loss: 3.067425, norm: 0.2899, time(ms): 794.38, token/sec:659997.51, hellaswag_acc: 0.2999
Step: 14483, loss: 3.127684, norm: 0.2939, time(ms): 785.50, token/sec:667454.18, hellaswag_acc: 0.2999
Step: 14484, loss: 3.004579, norm: 0.2900, time(ms): 793.89, token/sec:660407.01, hellaswag_acc: 0.2999
Step: 14485, loss: 3.052273, norm: 0.2819, time(ms): 790.39, token/sec:663324.42, hellaswag_acc: 0.2999
Step: 14486, loss: 3.090937, norm: 0.2952, time(ms): 790.44, token/sec:663284.80, hellaswag_acc: 0.2999
Step: 14487, loss: 3.012336, norm: 0.2738, time(ms): 788.04, token/sec:665302.97, hellaswag_acc: 0.2999
Step: 14488, loss: 3.098384, norm: 0.3307, time(ms): 802.96, token/sec:652948.05, hellaswag_acc: 0.2999
Step: 14489, loss: 3.092861, norm: 0.2898, time(ms): 804.96, token/sec:651320.64, hellaswag_acc: 0.2999
Step: 14490, loss: 3.097677, norm: 0.3060, time(ms): 792.45, token/sec:661599.95, hellaswag_acc: 0.2999
Step: 14491, loss: 3.181561, norm: 0.2952, time(ms): 796.98, token/sec:657840.49, hellaswag_acc: 0.2999
Step: 14492, loss: 3.100446, norm: 0.3066, time(ms): 790.77, token/sec:663012.43, hellaswag_acc: 0.2999
Step: 14493, loss: 3.059072, norm: 0.2870, time(ms): 788.21, token/sec:665164.32, hellaswag_acc: 0.2999
Step: 14494, loss: 3.114867, norm: 0.2993, time(ms): 798.22, token/sec:656818.36, hellaswag_acc: 0.2999
Step: 14495, loss: 3.145841, norm: 0.3535, time(ms): 794.54, token/sec:659863.43, hellaswag_acc: 0.2999
Step: 14496, loss: 3.029462, norm: 0.3590, time(ms): 789.78, token/sec:663842.65, hellaswag_acc: 0.2999
Step: 14497, loss: 3.108955, norm: 0.3252, time(ms): 804.96, token/sec:651321.02, hellaswag_acc: 0.2999
Step: 14498, loss: 3.086226, norm: 0.3026, time(ms): 802.62, token/sec:653218.82, hellaswag_acc: 0.2999
Step: 14499, loss: 3.120290, norm: 0.3229, time(ms): 791.72, token/sec:662216.78, hellaswag_acc: 0.2999
rank 0 sample 0: Hello, I'm a language model, and I need to know something new that allows me to study this field - it's very technical - so you can understand
rank 0 sample 1: Hello, I'm a language model, so when I'm learning a second language, the next thing that's changing my life and life, isn't that important
rank 0 sample 2: Hello, I'm a language model, so I might have already guessed all I'm seeing.
A good place to start is the "Noun" label
rank 0 sample 3: Hello, I'm a language model, but at the moment I'm just getting the syntax out of the way. So please use that syntax on the data from
rank 1 sample 0: Hello, I'm a language model, with my accent, the language, whether I know what I understand or not, and how I know what I'm talking
rank 1 sample 1: Hello, I'm a language model, not an interpreter. I'm not even like that. We're gonna put that together with some examples, and then we
rank 1 sample 2: Hello, I'm a language model, but...
This is a very simple example of a set rule that I'll use to write out my code to implement
rank 1 sample 3: Hello, I'm a language model, and I'm the only one in the house. I came back up this website and a book. I'm trying to
Step: 14500, loss: 3.106912, norm: 0.2822, time(ms): 3817.62, token/sec:137333.70, val_loss: 3.1080, hellaswag_acc: 0.2999
Step: 14501, loss: 3.122507, norm: 0.3166, time(ms): 795.11, token/sec:659390.73, hellaswag_acc: 0.2999
Step: 14502, loss: 3.083645, norm: 0.2823, time(ms): 783.36, token/sec:669279.00, hellaswag_acc: 0.2999
Step: 14503, loss: 3.081460, norm: 0.2795, time(ms): 792.69, token/sec:661405.13, hellaswag_acc: 0.2999
Step: 14504, loss: 3.081593, norm: 0.2985, time(ms): 798.30, token/sec:656757.35, hellaswag_acc: 0.2999
Step: 14505, loss: 3.112458, norm: 0.2679, time(ms): 797.03, token/sec:657802.70, hellaswag_acc: 0.2999
Step: 14506, loss: 3.095728, norm: 0.2798, time(ms): 794.06, token/sec:660265.63, hellaswag_acc: 0.2999
Step: 14507, loss: 3.081172, norm: 0.2896, time(ms): 791.36, token/sec:662514.45, hellaswag_acc: 0.2999
Step: 14508, loss: 3.168092, norm: 0.2700, time(ms): 788.39, token/sec:665008.83, hellaswag_acc: 0.2999
Step: 14509, loss: 3.110381, norm: 0.2911, time(ms): 792.85, token/sec:661273.67, hellaswag_acc: 0.2999
Step: 14510, loss: 3.128765, norm: 0.2690, time(ms): 791.34, token/sec:662530.42, hellaswag_acc: 0.2999
Step: 14511, loss: 3.037428, norm: 0.2820, time(ms): 802.10, token/sec:653640.15, hellaswag_acc: 0.2999
Step: 14512, loss: 3.062106, norm: 0.2688, time(ms): 801.76, token/sec:653922.96, hellaswag_acc: 0.2999
Step: 14513, loss: 3.037457, norm: 0.2743, time(ms): 791.79, token/sec:662158.15, hellaswag_acc: 0.2999
Step: 14514, loss: 3.061969, norm: 0.2834, time(ms): 799.06, token/sec:656129.30, hellaswag_acc: 0.2999
Step: 14515, loss: 3.022358, norm: 0.2620, time(ms): 807.32, token/sec:649413.90, hellaswag_acc: 0.2999
Step: 14516, loss: 3.071914, norm: 0.2666, time(ms): 799.14, token/sec:656064.90, hellaswag_acc: 0.2999
Step: 14517, loss: 3.030166, norm: 0.2699, time(ms): 794.06, token/sec:660261.27, hellaswag_acc: 0.2999
Step: 14518, loss: 3.057708, norm: 0.2702, time(ms): 805.47, token/sec:650905.56, hellaswag_acc: 0.2999
Step: 14519, loss: 3.084360, norm: 0.2737, time(ms): 802.11, token/sec:653637.04, hellaswag_acc: 0.2999
Step: 14520, loss: 3.029693, norm: 0.2730, time(ms): 797.59, token/sec:657339.63, hellaswag_acc: 0.2999
Step: 14521, loss: 3.054180, norm: 0.2722, time(ms): 794.18, token/sec:660161.56, hellaswag_acc: 0.2999
Step: 14522, loss: 3.062589, norm: 0.2933, time(ms): 807.13, token/sec:649567.36, hellaswag_acc: 0.2999
Step: 14523, loss: 3.091073, norm: 0.3165, time(ms): 799.62, token/sec:655670.73, hellaswag_acc: 0.2999
Step: 14524, loss: 3.203894, norm: 0.3399, time(ms): 794.07, token/sec:660251.16, hellaswag_acc: 0.2999
Step: 14525, loss: 3.030712, norm: 0.3291, time(ms): 796.98, token/sec:657839.70, hellaswag_acc: 0.2999
Step: 14526, loss: 3.166683, norm: 0.3333, time(ms): 800.98, token/sec:654556.73, hellaswag_acc: 0.2999
Step: 14527, loss: 3.080754, norm: 0.2878, time(ms): 798.27, token/sec:656780.89, hellaswag_acc: 0.2999
Step: 14528, loss: 2.973508, norm: 0.3585, time(ms): 789.62, token/sec:663975.54, hellaswag_acc: 0.2999
Step: 14529, loss: 3.085921, norm: 0.3434, time(ms): 788.76, token/sec:664697.86, hellaswag_acc: 0.2999
Step: 14530, loss: 3.085978, norm: 0.3392, time(ms): 790.82, token/sec:662967.65, hellaswag_acc: 0.2999
Step: 14531, loss: 2.996557, norm: 0.2949, time(ms): 795.73, token/sec:658876.07, hellaswag_acc: 0.2999
Step: 14532, loss: 3.152149, norm: 0.3181, time(ms): 800.27, token/sec:655140.39, hellaswag_acc: 0.2999
Step: 14533, loss: 3.123582, norm: 0.3077, time(ms): 803.74, token/sec:652308.88, hellaswag_acc: 0.2999
Step: 14534, loss: 3.065965, norm: 0.2970, time(ms): 797.89, token/sec:657094.89, hellaswag_acc: 0.2999
Step: 14535, loss: 3.064706, norm: 0.2993, time(ms): 792.43, token/sec:661618.66, hellaswag_acc: 0.2999
Step: 14536, loss: 3.078938, norm: 0.2918, time(ms): 801.67, token/sec:653996.09, hellaswag_acc: 0.2999
Step: 14537, loss: 3.077849, norm: 0.3015, time(ms): 801.50, token/sec:654129.74, hellaswag_acc: 0.2999
Step: 14538, loss: 3.079191, norm: 0.2958, time(ms): 797.00, token/sec:657826.12, hellaswag_acc: 0.2999
Step: 14539, loss: 3.104259, norm: 0.2941, time(ms): 799.38, token/sec:655865.31, hellaswag_acc: 0.2999
Step: 14540, loss: 3.104355, norm: 0.2796, time(ms): 798.24, token/sec:656803.64, hellaswag_acc: 0.2999
Step: 14541, loss: 3.091458, norm: 0.2957, time(ms): 790.47, token/sec:663260.99, hellaswag_acc: 0.2999
Step: 14542, loss: 3.139321, norm: 0.2844, time(ms): 793.74, token/sec:660527.81, hellaswag_acc: 0.2999
Step: 14543, loss: 3.097115, norm: 0.3800, time(ms): 795.77, token/sec:658842.31, hellaswag_acc: 0.2999
Step: 14544, loss: 3.074723, norm: 0.2769, time(ms): 789.57, token/sec:664017.25, hellaswag_acc: 0.2999
Step: 14545, loss: 3.147567, norm: 0.3206, time(ms): 789.42, token/sec:664141.18, hellaswag_acc: 0.2999
Step: 14546, loss: 3.127888, norm: 0.2783, time(ms): 790.58, token/sec:663172.38, hellaswag_acc: 0.2999
Step: 14547, loss: 3.054299, norm: 0.3022, time(ms): 794.28, token/sec:660078.93, hellaswag_acc: 0.2999
Step: 14548, loss: 3.093182, norm: 0.2741, time(ms): 803.72, token/sec:652325.52, hellaswag_acc: 0.2999
Step: 14549, loss: 3.099850, norm: 0.2790, time(ms): 795.64, token/sec:658951.09, hellaswag_acc: 0.2999
Step: 14550, loss: 3.067137, norm: 0.2739, time(ms): 803.16, token/sec:652781.16, hellaswag_acc: 0.2999
Step: 14551, loss: 3.036100, norm: 0.2840, time(ms): 801.35, token/sec:654252.73, hellaswag_acc: 0.2999
Step: 14552, loss: 3.104741, norm: 0.2918, time(ms): 795.89, token/sec:658747.97, hellaswag_acc: 0.2999
Step: 14553, loss: 3.047092, norm: 0.2767, time(ms): 800.11, token/sec:655272.75, hellaswag_acc: 0.2999
Step: 14554, loss: 3.098889, norm: 0.2942, time(ms): 803.24, token/sec:652719.16, hellaswag_acc: 0.2999
Step: 14555, loss: 3.070481, norm: 0.2847, time(ms): 799.85, token/sec:655484.48, hellaswag_acc: 0.2999
Step: 14556, loss: 3.086075, norm: 0.2927, time(ms): 792.48, token/sec:661582.63, hellaswag_acc: 0.2999
Step: 14557, loss: 3.087742, norm: 0.2857, time(ms): 805.32, token/sec:651028.70, hellaswag_acc: 0.2999
Step: 14558, loss: 3.093585, norm: 0.2741, time(ms): 803.51, token/sec:652497.98, hellaswag_acc: 0.2999
Step: 14559, loss: 3.077760, norm: 0.3170, time(ms): 789.88, token/sec:663759.49, hellaswag_acc: 0.2999
Step: 14560, loss: 3.101233, norm: 0.3240, time(ms): 798.55, token/sec:656549.89, hellaswag_acc: 0.2999
Step: 14561, loss: 3.076146, norm: 0.3187, time(ms): 794.18, token/sec:660159.78, hellaswag_acc: 0.2999
Step: 14562, loss: 3.046710, norm: 0.2986, time(ms): 791.70, token/sec:662230.14, hellaswag_acc: 0.2999
Step: 14563, loss: 3.050453, norm: 0.3072, time(ms): 789.86, token/sec:663771.11, hellaswag_acc: 0.2999
Step: 14564, loss: 3.017061, norm: 0.3202, time(ms): 794.10, token/sec:660232.13, hellaswag_acc: 0.2999
Step: 14565, loss: 3.058165, norm: 0.2955, time(ms): 794.35, token/sec:660020.09, hellaswag_acc: 0.2999
Step: 14566, loss: 3.091610, norm: 0.3336, time(ms): 804.90, token/sec:651372.92, hellaswag_acc: 0.2999
Step: 14567, loss: 3.114868, norm: 0.3248, time(ms): 799.19, token/sec:656022.82, hellaswag_acc: 0.2999
Step: 14568, loss: 3.069702, norm: 0.2993, time(ms): 791.21, token/sec:662642.42, hellaswag_acc: 0.2999
Step: 14569, loss: 3.106297, norm: 0.3030, time(ms): 792.51, token/sec:661553.97, hellaswag_acc: 0.2999
Step: 14570, loss: 3.054770, norm: 0.2747, time(ms): 794.43, token/sec:659954.92, hellaswag_acc: 0.2999
Step: 14571, loss: 3.144147, norm: 0.2987, time(ms): 796.88, token/sec:657929.05, hellaswag_acc: 0.2999
Step: 14572, loss: 3.162069, norm: 0.2769, time(ms): 796.18, token/sec:658503.17, hellaswag_acc: 0.2999
Step: 14573, loss: 3.060867, norm: 0.2870, time(ms): 792.09, token/sec:661906.43, hellaswag_acc: 0.2999
Step: 14574, loss: 3.108311, norm: 0.2854, time(ms): 788.42, token/sec:664987.91, hellaswag_acc: 0.2999
Step: 14575, loss: 3.071449, norm: 0.2675, time(ms): 791.48, token/sec:662415.06, hellaswag_acc: 0.2999
Step: 14576, loss: 3.093506, norm: 0.2791, time(ms): 793.11, token/sec:661050.43, hellaswag_acc: 0.2999
Step: 14577, loss: 3.121931, norm: 0.2763, time(ms): 797.59, token/sec:657341.80, hellaswag_acc: 0.2999
Step: 14578, loss: 3.104788, norm: 0.2932, time(ms): 805.04, token/sec:651260.84, hellaswag_acc: 0.2999
Step: 14579, loss: 3.118315, norm: 0.2886, time(ms): 800.04, token/sec:655325.08, hellaswag_acc: 0.2999
Step: 14580, loss: 3.095512, norm: 0.2792, time(ms): 792.27, token/sec:661754.44, hellaswag_acc: 0.2999
Step: 14581, loss: 3.086770, norm: 0.2688, time(ms): 806.14, token/sec:650365.39, hellaswag_acc: 0.2999
Step: 14582, loss: 3.002635, norm: 0.2828, time(ms): 797.44, token/sec:657466.00, hellaswag_acc: 0.2999
Step: 14583, loss: 3.073473, norm: 0.2791, time(ms): 798.44, token/sec:656640.07, hellaswag_acc: 0.2999
Step: 14584, loss: 3.046215, norm: 0.2961, time(ms): 798.97, token/sec:656203.31, hellaswag_acc: 0.2999
Step: 14585, loss: 3.026079, norm: 0.2796, time(ms): 801.14, token/sec:654425.44, hellaswag_acc: 0.2999
Step: 14586, loss: 3.015659, norm: 0.2962, time(ms): 803.64, token/sec:652388.42, hellaswag_acc: 0.2999
Step: 14587, loss: 3.062890, norm: 0.2963, time(ms): 799.77, token/sec:655550.33, hellaswag_acc: 0.2999
Step: 14588, loss: 3.086472, norm: 0.3002, time(ms): 792.01, token/sec:661971.18, hellaswag_acc: 0.2999
Step: 14589, loss: 3.068638, norm: 0.2883, time(ms): 805.66, token/sec:650756.09, hellaswag_acc: 0.2999
Step: 14590, loss: 3.079894, norm: 0.3064, time(ms): 803.06, token/sec:652861.20, hellaswag_acc: 0.2999
Step: 14591, loss: 3.069132, norm: 0.2631, time(ms): 794.92, token/sec:659552.11, hellaswag_acc: 0.2999
Step: 14592, loss: 3.136423, norm: 0.3299, time(ms): 798.48, token/sec:656609.88, hellaswag_acc: 0.2999
Step: 14593, loss: 3.102715, norm: 0.3068, time(ms): 805.11, token/sec:651197.39, hellaswag_acc: 0.2999
Step: 14594, loss: 3.028079, norm: 0.2992, time(ms): 798.19, token/sec:656847.98, hellaswag_acc: 0.2999
Step: 14595, loss: 3.064264, norm: 0.2915, time(ms): 792.12, token/sec:661875.35, hellaswag_acc: 0.2999
Step: 14596, loss: 3.060147, norm: 0.3000, time(ms): 799.10, token/sec:656101.31, hellaswag_acc: 0.2999
Step: 14597, loss: 3.135153, norm: 0.2954, time(ms): 797.65, token/sec:657289.73, hellaswag_acc: 0.2999
Step: 14598, loss: 3.078279, norm: 0.3139, time(ms): 790.11, token/sec:663565.61, hellaswag_acc: 0.2999
Step: 14599, loss: 3.097203, norm: 0.2951, time(ms): 792.74, token/sec:661359.38, hellaswag_acc: 0.2999
Step: 14600, loss: 3.078550, norm: 0.2968, time(ms): 792.29, token/sec:661736.52, hellaswag_acc: 0.2999
Step: 14601, loss: 3.110055, norm: 0.2922, time(ms): 793.39, token/sec:660821.39, hellaswag_acc: 0.2999
Step: 14602, loss: 2.994981, norm: 0.3037, time(ms): 800.01, token/sec:655350.86, hellaswag_acc: 0.2999
Step: 14603, loss: 3.026042, norm: 0.2891, time(ms): 800.02, token/sec:655341.48, hellaswag_acc: 0.2999
Step: 14604, loss: 3.166295, norm: 0.3329, time(ms): 798.43, token/sec:656648.90, hellaswag_acc: 0.2999
Step: 14605, loss: 3.011415, norm: 0.3011, time(ms): 801.48, token/sec:654145.89, hellaswag_acc: 0.2999
Step: 14606, loss: 3.126680, norm: 0.3365, time(ms): 799.40, token/sec:655854.36, hellaswag_acc: 0.2999
Step: 14607, loss: 3.051820, norm: 0.2786, time(ms): 802.89, token/sec:652997.88, hellaswag_acc: 0.2999
Step: 14608, loss: 3.083315, norm: 0.3130, time(ms): 799.31, token/sec:655924.78, hellaswag_acc: 0.2999
Step: 14609, loss: 3.106170, norm: 0.2992, time(ms): 793.90, token/sec:660399.27, hellaswag_acc: 0.2999
Step: 14610, loss: 3.095142, norm: 0.2929, time(ms): 802.18, token/sec:653577.79, hellaswag_acc: 0.2999
Step: 14611, loss: 3.050508, norm: 0.2933, time(ms): 804.01, token/sec:652094.56, hellaswag_acc: 0.2999
Step: 14612, loss: 3.102829, norm: 0.3195, time(ms): 798.53, token/sec:656568.91, hellaswag_acc: 0.2999
Step: 14613, loss: 3.182288, norm: 0.2800, time(ms): 793.01, token/sec:661139.07, hellaswag_acc: 0.2999
Step: 14614, loss: 3.154191, norm: 0.3139, time(ms): 803.01, token/sec:652906.18, hellaswag_acc: 0.2999
Step: 14615, loss: 3.127208, norm: 0.2842, time(ms): 803.78, token/sec:652281.60, hellaswag_acc: 0.2999
Step: 14616, loss: 3.070810, norm: 0.2775, time(ms): 801.07, token/sec:654485.62, hellaswag_acc: 0.2999
Step: 14617, loss: 3.111237, norm: 0.2887, time(ms): 790.22, token/sec:663468.31, hellaswag_acc: 0.2999
Step: 14618, loss: 3.102666, norm: 0.2747, time(ms): 793.60, token/sec:660642.12, hellaswag_acc: 0.2999
Step: 14619, loss: 3.077389, norm: 0.2670, time(ms): 793.44, token/sec:660775.12, hellaswag_acc: 0.2999
Step: 14620, loss: 3.035517, norm: 0.2830, time(ms): 791.57, token/sec:662337.45, hellaswag_acc: 0.2999
Step: 14621, loss: 3.044482, norm: 0.2825, time(ms): 789.20, token/sec:664329.38, hellaswag_acc: 0.2999
Step: 14622, loss: 3.029027, norm: 0.2598, time(ms): 786.34, token/sec:666743.45, hellaswag_acc: 0.2999
Step: 14623, loss: 3.061786, norm: 0.2698, time(ms): 790.19, token/sec:663494.74, hellaswag_acc: 0.2999
Step: 14624, loss: 3.063803, norm: 0.2828, time(ms): 802.34, token/sec:653449.22, hellaswag_acc: 0.2999
Step: 14625, loss: 3.044225, norm: 0.2706, time(ms): 801.09, token/sec:654468.48, hellaswag_acc: 0.2999
Step: 14626, loss: 3.041183, norm: 0.2758, time(ms): 790.27, token/sec:663428.88, hellaswag_acc: 0.2999
Step: 14627, loss: 3.084513, norm: 0.2752, time(ms): 790.89, token/sec:662906.10, hellaswag_acc: 0.2999
Step: 14628, loss: 3.077549, norm: 0.2827, time(ms): 791.33, token/sec:662536.60, hellaswag_acc: 0.2999
Step: 14629, loss: 3.057425, norm: 0.2824, time(ms): 791.83, token/sec:662120.47, hellaswag_acc: 0.2999
Step: 14630, loss: 3.097241, norm: 0.3372, time(ms): 792.78, token/sec:661327.36, hellaswag_acc: 0.2999
Step: 14631, loss: 3.100781, norm: 0.3099, time(ms): 795.41, token/sec:659140.12, hellaswag_acc: 0.2999
Step: 14632, loss: 3.114478, norm: 0.2995, time(ms): 804.99, token/sec:651294.21, hellaswag_acc: 0.2999
Step: 14633, loss: 3.138677, norm: 0.3016, time(ms): 797.87, token/sec:657108.24, hellaswag_acc: 0.2999
Step: 14634, loss: 3.164685, norm: 0.3372, time(ms): 798.66, token/sec:656457.38, hellaswag_acc: 0.2999
Step: 14635, loss: 3.126993, norm: 0.3403, time(ms): 795.11, token/sec:659392.51, hellaswag_acc: 0.2999
Step: 14636, loss: 3.087799, norm: 0.3800, time(ms): 791.54, token/sec:662367.57, hellaswag_acc: 0.2999
Step: 14637, loss: 3.022962, norm: 0.3314, time(ms): 791.22, token/sec:662630.24, hellaswag_acc: 0.2999
Step: 14638, loss: 2.959145, norm: 0.3302, time(ms): 795.29, token/sec:659238.52, hellaswag_acc: 0.2999
Step: 14639, loss: 3.084903, norm: 0.3108, time(ms): 789.03, token/sec:664468.49, hellaswag_acc: 0.2999
Step: 14640, loss: 3.121627, norm: 0.3202, time(ms): 791.89, token/sec:662071.43, hellaswag_acc: 0.2999
Step: 14641, loss: 3.077363, norm: 0.3375, time(ms): 792.31, token/sec:661720.00, hellaswag_acc: 0.2999
Step: 14642, loss: 3.069208, norm: 0.2985, time(ms): 795.54, token/sec:659032.85, hellaswag_acc: 0.2999
Step: 14643, loss: 3.070375, norm: 0.3040, time(ms): 795.51, token/sec:659062.68, hellaswag_acc: 0.2999
Step: 14644, loss: 3.092137, norm: 0.3073, time(ms): 803.13, token/sec:652809.46, hellaswag_acc: 0.2999
Step: 14645, loss: 3.076566, norm: 0.2843, time(ms): 802.53, token/sec:653294.31, hellaswag_acc: 0.2999
Step: 14646, loss: 3.104494, norm: 0.2871, time(ms): 796.23, token/sec:658461.96, hellaswag_acc: 0.2999
Step: 14647, loss: 3.029229, norm: 0.3257, time(ms): 797.53, token/sec:657393.28, hellaswag_acc: 0.2999
Step: 14648, loss: 3.179210, norm: 0.2894, time(ms): 805.87, token/sec:650587.05, hellaswag_acc: 0.2999
Step: 14649, loss: 3.115521, norm: 0.3113, time(ms): 794.46, token/sec:659926.80, hellaswag_acc: 0.2999
Step: 14650, loss: 3.070721, norm: 0.2944, time(ms): 801.26, token/sec:654325.54, hellaswag_acc: 0.2999
Step: 14651, loss: 3.088983, norm: 0.2860, time(ms): 797.57, token/sec:657354.76, hellaswag_acc: 0.2999
Step: 14652, loss: 3.177286, norm: 0.3005, time(ms): 802.64, token/sec:653200.96, hellaswag_acc: 0.2999
Step: 14653, loss: 3.066251, norm: 0.2793, time(ms): 803.79, token/sec:652268.25, hellaswag_acc: 0.2999
Step: 14654, loss: 3.046494, norm: 0.3066, time(ms): 789.15, token/sec:664373.54, hellaswag_acc: 0.2999
Step: 14655, loss: 3.106110, norm: 0.2884, time(ms): 804.30, token/sec:651855.64, hellaswag_acc: 0.2999
Step: 14656, loss: 3.028357, norm: 0.2826, time(ms): 802.61, token/sec:653226.19, hellaswag_acc: 0.2999
Step: 14657, loss: 3.120207, norm: 0.4029, time(ms): 793.98, token/sec:660327.09, hellaswag_acc: 0.2999
Step: 14658, loss: 3.079719, norm: 0.3048, time(ms): 798.22, token/sec:656821.30, hellaswag_acc: 0.2999
Step: 14659, loss: 3.032038, norm: 0.2909, time(ms): 791.46, token/sec:662432.42, hellaswag_acc: 0.2999
Step: 14660, loss: 3.072591, norm: 0.3062, time(ms): 788.72, token/sec:664729.41, hellaswag_acc: 0.2999
Step: 14661, loss: 3.105754, norm: 0.2876, time(ms): 792.76, token/sec:661342.48, hellaswag_acc: 0.2999
Step: 14662, loss: 3.038639, norm: 0.3000, time(ms): 788.84, token/sec:664632.57, hellaswag_acc: 0.2999
Step: 14663, loss: 3.057254, norm: 0.2734, time(ms): 798.64, token/sec:656477.17, hellaswag_acc: 0.2999
Step: 14664, loss: 3.063829, norm: 0.2827, time(ms): 799.27, token/sec:655960.20, hellaswag_acc: 0.2999
Step: 14665, loss: 3.051150, norm: 0.2946, time(ms): 793.37, token/sec:660832.71, hellaswag_acc: 0.2999
Step: 14666, loss: 3.011542, norm: 0.3655, time(ms): 787.81, token/sec:665496.46, hellaswag_acc: 0.2999
Step: 14667, loss: 3.076870, norm: 0.2850, time(ms): 796.96, token/sec:657856.23, hellaswag_acc: 0.2999
Step: 14668, loss: 3.008150, norm: 0.3651, time(ms): 1294.81, token/sec:404916.48, hellaswag_acc: 0.2999
Step: 14669, loss: 3.032300, norm: 0.3792, time(ms): 790.69, token/sec:663078.80, hellaswag_acc: 0.2999
Step: 14670, loss: 2.936643, norm: 0.3129, time(ms): 787.20, token/sec:666019.11, hellaswag_acc: 0.2999
Step: 14671, loss: 2.979290, norm: 0.3418, time(ms): 784.89, token/sec:667977.47, hellaswag_acc: 0.2999
Step: 14672, loss: 3.140193, norm: 0.4332, time(ms): 789.95, token/sec:663695.59, hellaswag_acc: 0.2999
Step: 14673, loss: 3.138233, norm: 0.3513, time(ms): 795.48, token/sec:659080.26, hellaswag_acc: 0.2999
Step: 14674, loss: 3.159654, norm: 0.3732, time(ms): 789.20, token/sec:664328.98, hellaswag_acc: 0.2999
Step: 14675, loss: 3.145966, norm: 0.3519, time(ms): 788.11, token/sec:665247.62, hellaswag_acc: 0.2999
Step: 14676, loss: 3.144165, norm: 0.3291, time(ms): 795.14, token/sec:659368.79, hellaswag_acc: 0.2999
Step: 14677, loss: 3.137115, norm: 0.3578, time(ms): 793.28, token/sec:660915.73, hellaswag_acc: 0.2999
Step: 14678, loss: 3.102540, norm: 0.3460, time(ms): 792.53, token/sec:661540.83, hellaswag_acc: 0.2999
Step: 14679, loss: 3.113887, norm: 0.3637, time(ms): 790.05, token/sec:663609.67, hellaswag_acc: 0.2999
Step: 14680, loss: 3.144691, norm: 0.3400, time(ms): 788.11, token/sec:665245.81, hellaswag_acc: 0.2999
Step: 14681, loss: 3.112834, norm: 0.3019, time(ms): 789.85, token/sec:663779.53, hellaswag_acc: 0.2999
Step: 14682, loss: 3.067428, norm: 0.3100, time(ms): 790.75, token/sec:663029.42, hellaswag_acc: 0.2999
Step: 14683, loss: 3.120364, norm: 0.3014, time(ms): 805.18, token/sec:651143.59, hellaswag_acc: 0.2999
Step: 14684, loss: 3.079890, norm: 0.3019, time(ms): 802.36, token/sec:653429.22, hellaswag_acc: 0.2999
Step: 14685, loss: 3.103819, norm: 0.2800, time(ms): 793.75, token/sec:660519.88, hellaswag_acc: 0.2999
Step: 14686, loss: 3.060967, norm: 0.2617, time(ms): 798.78, token/sec:656363.72, hellaswag_acc: 0.2999
Step: 14687, loss: 3.115586, norm: 0.2979, time(ms): 804.87, token/sec:651394.72, hellaswag_acc: 0.2999
Step: 14688, loss: 3.100754, norm: 0.2709, time(ms): 798.45, token/sec:656633.41, hellaswag_acc: 0.2999
Step: 14689, loss: 3.103980, norm: 0.2939, time(ms): 799.50, token/sec:655773.78, hellaswag_acc: 0.2999
Step: 14690, loss: 3.167426, norm: 0.2820, time(ms): 802.48, token/sec:653333.51, hellaswag_acc: 0.2999
Step: 14691, loss: 3.038155, norm: 0.3090, time(ms): 799.49, token/sec:655775.34, hellaswag_acc: 0.2999
Step: 14692, loss: 3.082119, norm: 0.3180, time(ms): 796.53, token/sec:658214.02, hellaswag_acc: 0.2999
Step: 14693, loss: 3.125744, norm: 0.3115, time(ms): 802.87, token/sec:653016.50, hellaswag_acc: 0.2999
Step: 14694, loss: 3.098221, norm: 0.2795, time(ms): 798.33, token/sec:656734.40, hellaswag_acc: 0.2999
Step: 14695, loss: 3.096446, norm: 0.2962, time(ms): 801.49, token/sec:654138.10, hellaswag_acc: 0.2999
Step: 14696, loss: 3.093055, norm: 0.2821, time(ms): 799.67, token/sec:655634.18, hellaswag_acc: 0.2999
Step: 14697, loss: 3.134808, norm: 0.2838, time(ms): 797.88, token/sec:657104.32, hellaswag_acc: 0.2999
Step: 14698, loss: 3.068365, norm: 0.2771, time(ms): 798.39, token/sec:656684.00, hellaswag_acc: 0.2999
Step: 14699, loss: 3.161028, norm: 0.2946, time(ms): 803.57, token/sec:652446.10, hellaswag_acc: 0.2999
Step: 14700, loss: 3.155784, norm: 0.2834, time(ms): 797.86, token/sec:657118.06, hellaswag_acc: 0.2999
Step: 14701, loss: 3.071085, norm: 0.2954, time(ms): 800.27, token/sec:655136.87, hellaswag_acc: 0.2999
Step: 14702, loss: 3.056147, norm: 0.2608, time(ms): 801.55, token/sec:654089.85, hellaswag_acc: 0.2999
Step: 14703, loss: 3.112144, norm: 0.2926, time(ms): 797.36, token/sec:657527.73, hellaswag_acc: 0.2999
Step: 14704, loss: 3.030745, norm: 0.2909, time(ms): 800.57, token/sec:654891.23, hellaswag_acc: 0.2999
Step: 14705, loss: 3.081599, norm: 0.2760, time(ms): 800.52, token/sec:654934.53, hellaswag_acc: 0.2999
Step: 14706, loss: 3.080517, norm: 0.2948, time(ms): 798.58, token/sec:656528.13, hellaswag_acc: 0.2999
Step: 14707, loss: 2.935288, norm: 0.3523, time(ms): 797.71, token/sec:657244.15, hellaswag_acc: 0.2999
Step: 14708, loss: 2.958298, norm: 0.3264, time(ms): 802.87, token/sec:653020.96, hellaswag_acc: 0.2999
Step: 14709, loss: 2.960119, norm: 0.3150, time(ms): 800.09, token/sec:655282.51, hellaswag_acc: 0.2999
Step: 14710, loss: 2.981209, norm: 0.3150, time(ms): 795.80, token/sec:658818.43, hellaswag_acc: 0.2999
Step: 14711, loss: 2.917448, norm: 0.2805, time(ms): 798.00, token/sec:657004.78, hellaswag_acc: 0.2999
Step: 14712, loss: 2.944034, norm: 0.3002, time(ms): 807.18, token/sec:649531.67, hellaswag_acc: 0.2999
Step: 14713, loss: 3.026336, norm: 0.2814, time(ms): 799.87, token/sec:655469.82, hellaswag_acc: 0.2999
Step: 14714, loss: 2.933108, norm: 0.3200, time(ms): 792.14, token/sec:661863.39, hellaswag_acc: 0.2999
Step: 14715, loss: 2.917424, norm: 0.2862, time(ms): 801.13, token/sec:654438.87, hellaswag_acc: 0.2999
Step: 14716, loss: 2.980931, norm: 0.3201, time(ms): 806.53, token/sec:650056.24, hellaswag_acc: 0.2999
Step: 14717, loss: 2.908217, norm: 0.2807, time(ms): 798.13, token/sec:656896.25, hellaswag_acc: 0.2999
Step: 14718, loss: 2.973267, norm: 0.2810, time(ms): 796.25, token/sec:658444.61, hellaswag_acc: 0.2999
Step: 14719, loss: 3.141423, norm: 0.3131, time(ms): 800.94, token/sec:654591.80, hellaswag_acc: 0.2999
Step: 14720, loss: 3.120538, norm: 0.2910, time(ms): 803.87, token/sec:652201.70, hellaswag_acc: 0.2999
Step: 14721, loss: 3.133081, norm: 0.3180, time(ms): 796.47, token/sec:658266.82, hellaswag_acc: 0.2999
Step: 14722, loss: 3.138856, norm: 0.3006, time(ms): 797.08, token/sec:657761.19, hellaswag_acc: 0.2999
Step: 14723, loss: 3.176326, norm: 0.2989, time(ms): 803.36, token/sec:652618.24, hellaswag_acc: 0.2999
Step: 14724, loss: 3.087750, norm: 0.2839, time(ms): 802.47, token/sec:653341.47, hellaswag_acc: 0.2999
Step: 14725, loss: 3.126295, norm: 0.2770, time(ms): 795.36, token/sec:659180.23, hellaswag_acc: 0.2999
Step: 14726, loss: 3.094721, norm: 0.4320, time(ms): 797.01, token/sec:657816.48, hellaswag_acc: 0.2999
Step: 14727, loss: 3.134604, norm: 0.3036, time(ms): 805.12, token/sec:651195.27, hellaswag_acc: 0.2999
Step: 14728, loss: 3.130620, norm: 0.2712, time(ms): 792.70, token/sec:661391.81, hellaswag_acc: 0.2999
Step: 14729, loss: 3.093627, norm: 0.3054, time(ms): 792.22, token/sec:661798.26, hellaswag_acc: 0.2999
Step: 14730, loss: 3.059588, norm: 0.2804, time(ms): 791.37, token/sec:662510.86, hellaswag_acc: 0.2999
Step: 14731, loss: 3.112976, norm: 0.2995, time(ms): 789.65, token/sec:663948.68, hellaswag_acc: 0.2999
Step: 14732, loss: 3.155703, norm: 0.2835, time(ms): 795.13, token/sec:659369.97, hellaswag_acc: 0.2999
Step: 14733, loss: 3.133652, norm: 0.2748, time(ms): 792.73, token/sec:661369.53, hellaswag_acc: 0.2999
Step: 14734, loss: 3.157370, norm: 0.2756, time(ms): 800.34, token/sec:655081.06, hellaswag_acc: 0.2999
Step: 14735, loss: 3.104076, norm: 0.2971, time(ms): 799.79, token/sec:655530.40, hellaswag_acc: 0.2999
Step: 14736, loss: 3.122218, norm: 0.2950, time(ms): 797.60, token/sec:657332.76, hellaswag_acc: 0.2999
Step: 14737, loss: 3.111792, norm: 0.2919, time(ms): 792.77, token/sec:661339.49, hellaswag_acc: 0.2999
Step: 14738, loss: 3.120759, norm: 0.2894, time(ms): 791.91, token/sec:662057.08, hellaswag_acc: 0.2999
Step: 14739, loss: 3.115441, norm: 0.2771, time(ms): 793.89, token/sec:660407.01, hellaswag_acc: 0.2999
Step: 14740, loss: 3.104184, norm: 0.2926, time(ms): 794.05, token/sec:660271.97, hellaswag_acc: 0.2999
Step: 14741, loss: 3.052646, norm: 0.2696, time(ms): 790.04, token/sec:663621.68, hellaswag_acc: 0.2999
Step: 14742, loss: 3.033319, norm: 0.2760, time(ms): 791.99, token/sec:661984.73, hellaswag_acc: 0.2999
Step: 14743, loss: 3.042273, norm: 0.2809, time(ms): 793.74, token/sec:660526.03, hellaswag_acc: 0.2999
Step: 14744, loss: 3.051562, norm: 0.2623, time(ms): 794.16, token/sec:660183.17, hellaswag_acc: 0.2999
Step: 14745, loss: 3.061458, norm: 0.2689, time(ms): 803.69, token/sec:652347.78, hellaswag_acc: 0.2999
Step: 14746, loss: 3.073435, norm: 0.2622, time(ms): 798.14, token/sec:656885.06, hellaswag_acc: 0.2999
Step: 14747, loss: 3.050905, norm: 0.2920, time(ms): 802.23, token/sec:653535.83, hellaswag_acc: 0.2999
Step: 14748, loss: 3.072865, norm: 0.2672, time(ms): 793.52, token/sec:660712.78, hellaswag_acc: 0.2999
Step: 14749, loss: 3.078988, norm: 0.2712, time(ms): 805.14, token/sec:651178.88, hellaswag_acc: 0.2999
rank 0 sample 0: Hello, I'm a language model, and I know that you could write that much different ways, and also add that to my syntax too! It's so
rank 0 sample 1: Hello, I'm a language model, I'd like to make a list of the languages one to learn to express what we want to do by our tasks.
rank 0 sample 2: Hello, I'm a language model, so I had to define things better to make myself, and make myself understand what I'm talking about.
So as
rank 0 sample 3: Hello, I'm a language model, I would like to be able to express the words in a language better. But most of the words do not come right
rank 1 sample 0: Hello, I'm a language model, this is a language model, this process, these two entities, these two entities, are going to be one entity,
rank 1 sample 1: Hello, I'm a language model, not an engineer, so I need to tell you.<|endoftext|>The new world
Cambodia has a long history
rank 1 sample 2: Hello, I'm a language model, I got my computer to do a bunch of things, so why not try doing it?
It would take some serious
rank 1 sample 3: Hello, I'm a language model, and I'm working with machine learning as these are the words in their own codes. Just read that, and you'll
Step: 14750, loss: 3.087640, norm: 0.2728, time(ms): 3809.45, token/sec:137628.11, val_loss: 3.1067, hellaswag_acc: 0.2999
Step: 14751, loss: 3.079359, norm: 0.2683, time(ms): 790.50, token/sec:663239.19, hellaswag_acc: 0.2999
Step: 14752, loss: 3.075757, norm: 0.2763, time(ms): 784.18, token/sec:668580.65, hellaswag_acc: 0.2999
Step: 14753, loss: 2.907180, norm: 0.3180, time(ms): 790.84, token/sec:662953.06, hellaswag_acc: 0.2999
Step: 14754, loss: 2.921648, norm: 0.3055, time(ms): 797.33, token/sec:657553.29, hellaswag_acc: 0.2999
Step: 14755, loss: 2.859743, norm: 0.3070, time(ms): 790.44, token/sec:663282.40, hellaswag_acc: 0.2999
Step: 14756, loss: 2.959747, norm: 0.2996, time(ms): 787.74, token/sec:665556.69, hellaswag_acc: 0.2999
Step: 14757, loss: 2.922356, norm: 0.3257, time(ms): 792.65, token/sec:661440.94, hellaswag_acc: 0.2999
Step: 14758, loss: 2.872295, norm: 0.2764, time(ms): 791.50, token/sec:662400.30, hellaswag_acc: 0.2999
Step: 14759, loss: 2.943331, norm: 0.3105, time(ms): 801.48, token/sec:654149.58, hellaswag_acc: 0.2999
Step: 14760, loss: 2.924719, norm: 0.2800, time(ms): 798.78, token/sec:656360.59, hellaswag_acc: 0.2999
Step: 14761, loss: 3.066414, norm: 0.4052, time(ms): 794.38, token/sec:659992.95, hellaswag_acc: 0.2999
Step: 14762, loss: 2.956121, norm: 0.2870, time(ms): 794.14, token/sec:660196.64, hellaswag_acc: 0.2999
Step: 14763, loss: 2.913432, norm: 0.3224, time(ms): 788.42, token/sec:664983.49, hellaswag_acc: 0.2999
Step: 14764, loss: 3.023699, norm: 0.3255, time(ms): 791.51, token/sec:662387.93, hellaswag_acc: 0.2999
Step: 14765, loss: 3.135187, norm: 0.3364, time(ms): 794.04, token/sec:660281.09, hellaswag_acc: 0.2999
Step: 14766, loss: 3.104916, norm: 0.3032, time(ms): 796.70, token/sec:658077.71, hellaswag_acc: 0.2999
Step: 14767, loss: 3.130949, norm: 0.3270, time(ms): 803.33, token/sec:652640.51, hellaswag_acc: 0.2999
Step: 14768, loss: 3.173888, norm: 0.3189, time(ms): 798.55, token/sec:656553.62, hellaswag_acc: 0.2999
Step: 14769, loss: 3.134460, norm: 0.4585, time(ms): 801.02, token/sec:654524.58, hellaswag_acc: 0.2999
Step: 14770, loss: 3.166987, norm: 0.3575, time(ms): 797.53, token/sec:657388.76, hellaswag_acc: 0.2999
Step: 14771, loss: 3.079779, norm: 0.3254, time(ms): 801.76, token/sec:653923.55, hellaswag_acc: 0.2999
Step: 14772, loss: 3.159134, norm: 0.3224, time(ms): 800.45, token/sec:654990.52, hellaswag_acc: 0.2999
Step: 14773, loss: 3.185163, norm: 0.3418, time(ms): 794.48, token/sec:659911.95, hellaswag_acc: 0.2999
Step: 14774, loss: 3.094095, norm: 0.3013, time(ms): 803.93, token/sec:652155.47, hellaswag_acc: 0.2999
Step: 14775, loss: 3.188969, norm: 0.3593, time(ms): 801.31, token/sec:654292.64, hellaswag_acc: 0.2999
Step: 14776, loss: 3.120778, norm: 0.2921, time(ms): 790.56, token/sec:663187.78, hellaswag_acc: 0.2999
Step: 14777, loss: 3.087907, norm: 0.3230, time(ms): 792.10, token/sec:661893.48, hellaswag_acc: 0.2999
Step: 14778, loss: 3.104942, norm: 0.3081, time(ms): 792.22, token/sec:661798.26, hellaswag_acc: 0.2999
Step: 14779, loss: 3.088768, norm: 0.2928, time(ms): 791.70, token/sec:662228.34, hellaswag_acc: 0.2999
Step: 14780, loss: 3.067865, norm: 0.3117, time(ms): 793.77, token/sec:660506.78, hellaswag_acc: 0.2999
Step: 14781, loss: 3.143280, norm: 0.3320, time(ms): 791.85, token/sec:662102.93, hellaswag_acc: 0.2999
Step: 14782, loss: 3.110431, norm: 0.3069, time(ms): 801.60, token/sec:654052.30, hellaswag_acc: 0.2999
Step: 14783, loss: 3.081913, norm: 0.2958, time(ms): 804.11, token/sec:652012.58, hellaswag_acc: 0.2999
Step: 14784, loss: 3.119674, norm: 0.2768, time(ms): 797.77, token/sec:657193.47, hellaswag_acc: 0.2999
Step: 14785, loss: 3.125686, norm: 0.2882, time(ms): 799.73, token/sec:655579.64, hellaswag_acc: 0.2999
Step: 14786, loss: 3.194484, norm: 0.2921, time(ms): 798.24, token/sec:656808.15, hellaswag_acc: 0.2999
Step: 14787, loss: 3.107424, norm: 0.2799, time(ms): 801.87, token/sec:653834.89, hellaswag_acc: 0.2999
Step: 14788, loss: 3.043902, norm: 0.2767, time(ms): 794.35, token/sec:660025.04, hellaswag_acc: 0.2999
Step: 14789, loss: 3.101740, norm: 0.2667, time(ms): 801.73, token/sec:653945.13, hellaswag_acc: 0.2999
Step: 14790, loss: 3.042486, norm: 0.2742, time(ms): 803.37, token/sec:652614.17, hellaswag_acc: 0.2999
Step: 14791, loss: 3.080640, norm: 0.2989, time(ms): 797.89, token/sec:657089.20, hellaswag_acc: 0.2999
Step: 14792, loss: 3.086233, norm: 0.2917, time(ms): 795.41, token/sec:659139.92, hellaswag_acc: 0.2999
Step: 14793, loss: 3.055370, norm: 0.2645, time(ms): 793.15, token/sec:661019.83, hellaswag_acc: 0.2999
Step: 14794, loss: 3.096346, norm: 0.2888, time(ms): 796.28, token/sec:658419.37, hellaswag_acc: 0.2999
Step: 14795, loss: 3.068499, norm: 0.3033, time(ms): 792.48, token/sec:661578.65, hellaswag_acc: 0.2999
Step: 14796, loss: 3.108859, norm: 0.2608, time(ms): 802.80, token/sec:653072.35, hellaswag_acc: 0.2999
Step: 14797, loss: 3.040467, norm: 0.2790, time(ms): 799.89, token/sec:655449.50, hellaswag_acc: 0.2999
Step: 14798, loss: 3.055198, norm: 0.2596, time(ms): 794.71, token/sec:659719.31, hellaswag_acc: 0.2999
Step: 14799, loss: 2.959350, norm: 0.2791, time(ms): 790.83, token/sec:662960.85, hellaswag_acc: 0.2999
Step: 14800, loss: 2.895358, norm: 0.2771, time(ms): 789.25, token/sec:664285.63, hellaswag_acc: 0.2999
Step: 14801, loss: 2.933044, norm: 0.3254, time(ms): 792.19, token/sec:661824.35, hellaswag_acc: 0.2999
Step: 14802, loss: 2.884034, norm: 0.2792, time(ms): 793.34, token/sec:660864.88, hellaswag_acc: 0.2999
Step: 14803, loss: 2.909981, norm: 0.3034, time(ms): 794.19, token/sec:660151.46, hellaswag_acc: 0.2999
Step: 14804, loss: 2.932221, norm: 0.2728, time(ms): 805.80, token/sec:650642.87, hellaswag_acc: 0.2999
Step: 14805, loss: 2.933474, norm: 0.2897, time(ms): 802.22, token/sec:653550.21, hellaswag_acc: 0.2999
Step: 14806, loss: 2.977869, norm: 0.2772, time(ms): 794.91, token/sec:659558.84, hellaswag_acc: 0.2999
Step: 14807, loss: 2.936448, norm: 0.2897, time(ms): 797.54, token/sec:657385.03, hellaswag_acc: 0.2999
Step: 14808, loss: 3.035096, norm: 0.3451, time(ms): 806.74, token/sec:649886.80, hellaswag_acc: 0.2999
Step: 14809, loss: 2.973332, norm: 0.2967, time(ms): 794.82, token/sec:659633.63, hellaswag_acc: 0.2999
Step: 14810, loss: 2.973421, norm: 0.3156, time(ms): 796.92, token/sec:657895.20, hellaswag_acc: 0.2999
Step: 14811, loss: 3.020230, norm: 0.3393, time(ms): 806.74, token/sec:649881.23, hellaswag_acc: 0.2999
Step: 14812, loss: 3.075134, norm: 0.3154, time(ms): 796.61, token/sec:658147.82, hellaswag_acc: 0.2999
Step: 14813, loss: 3.066246, norm: 0.3128, time(ms): 799.25, token/sec:655975.66, hellaswag_acc: 0.2999
Step: 14814, loss: 3.187887, norm: 0.3268, time(ms): 803.16, token/sec:652778.84, hellaswag_acc: 0.2999
Step: 14815, loss: 3.100395, norm: 0.2921, time(ms): 801.20, token/sec:654381.23, hellaswag_acc: 0.2999
Step: 14816, loss: 3.115837, norm: 0.2863, time(ms): 794.10, token/sec:660227.17, hellaswag_acc: 0.2999
Step: 14817, loss: 3.094197, norm: 0.3111, time(ms): 801.43, token/sec:654188.11, hellaswag_acc: 0.2999
Step: 14818, loss: 3.061082, norm: 0.2964, time(ms): 805.50, token/sec:650885.14, hellaswag_acc: 0.2999
Step: 14819, loss: 3.154072, norm: 0.3838, time(ms): 798.39, token/sec:656684.98, hellaswag_acc: 0.2999
Step: 14820, loss: 3.056918, norm: 0.3637, time(ms): 795.06, token/sec:659434.83, hellaswag_acc: 0.2999
Step: 14821, loss: 3.137076, norm: 0.3354, time(ms): 798.98, token/sec:656198.02, hellaswag_acc: 0.2999
Step: 14822, loss: 3.109757, norm: 0.2863, time(ms): 796.05, token/sec:658614.99, hellaswag_acc: 0.2999
Step: 14823, loss: 3.135321, norm: 0.3309, time(ms): 792.13, token/sec:661870.96, hellaswag_acc: 0.2999
Step: 14824, loss: 3.118868, norm: 0.3023, time(ms): 789.44, token/sec:664123.73, hellaswag_acc: 0.2999
Step: 14825, loss: 3.085788, norm: 0.2989, time(ms): 795.61, token/sec:658972.03, hellaswag_acc: 0.2999
Step: 14826, loss: 3.094069, norm: 0.2988, time(ms): 792.89, token/sec:661233.10, hellaswag_acc: 0.2999
Step: 14827, loss: 3.114684, norm: 0.3090, time(ms): 792.96, token/sec:661182.41, hellaswag_acc: 0.2999
Step: 14828, loss: 3.172711, norm: 0.2989, time(ms): 804.34, token/sec:651821.24, hellaswag_acc: 0.2999
Step: 14829, loss: 3.128205, norm: 0.2778, time(ms): 802.63, token/sec:653209.89, hellaswag_acc: 0.2999
Step: 14830, loss: 3.066028, norm: 0.2854, time(ms): 789.50, token/sec:664073.19, hellaswag_acc: 0.2999
Step: 14831, loss: 3.112900, norm: 0.2693, time(ms): 799.22, token/sec:656002.86, hellaswag_acc: 0.2999
Step: 14832, loss: 3.101093, norm: 0.2774, time(ms): 791.92, token/sec:662045.92, hellaswag_acc: 0.2999
Step: 14833, loss: 3.106155, norm: 0.2689, time(ms): 790.83, token/sec:662962.25, hellaswag_acc: 0.2999
Step: 14834, loss: 3.126520, norm: 0.2720, time(ms): 795.14, token/sec:659363.45, hellaswag_acc: 0.2999
Step: 14835, loss: 3.147869, norm: 0.2716, time(ms): 789.25, token/sec:664289.44, hellaswag_acc: 0.2999
Step: 14836, loss: 3.072381, norm: 0.2748, time(ms): 791.05, token/sec:662776.63, hellaswag_acc: 0.2999
Step: 14837, loss: 3.062678, norm: 0.2746, time(ms): 791.16, token/sec:662678.56, hellaswag_acc: 0.2999
Step: 14838, loss: 3.053885, norm: 0.2655, time(ms): 795.40, token/sec:659149.60, hellaswag_acc: 0.2999
Step: 14839, loss: 3.087368, norm: 0.2802, time(ms): 799.72, token/sec:655593.33, hellaswag_acc: 0.2999
Step: 14840, loss: 3.085912, norm: 0.2705, time(ms): 804.02, token/sec:652079.67, hellaswag_acc: 0.2999
Step: 14841, loss: 3.106512, norm: 0.2585, time(ms): 799.60, token/sec:655691.46, hellaswag_acc: 0.2999
Step: 14842, loss: 3.094761, norm: 0.2743, time(ms): 794.43, token/sec:659952.35, hellaswag_acc: 0.2999
Step: 14843, loss: 3.126210, norm: 0.2720, time(ms): 799.64, token/sec:655651.38, hellaswag_acc: 0.2999
Step: 14844, loss: 3.080981, norm: 0.2655, time(ms): 804.69, token/sec:651544.11, hellaswag_acc: 0.2999
Step: 14845, loss: 3.054528, norm: 0.2623, time(ms): 799.55, token/sec:655725.87, hellaswag_acc: 0.2999
Step: 14846, loss: 3.085237, norm: 0.3177, time(ms): 798.16, token/sec:656867.60, hellaswag_acc: 0.2999
Step: 14847, loss: 2.881612, norm: 0.2932, time(ms): 798.70, token/sec:656427.60, hellaswag_acc: 0.2999
Step: 14848, loss: 2.978969, norm: 0.2821, time(ms): 800.15, token/sec:655233.31, hellaswag_acc: 0.2999
Step: 14849, loss: 2.966977, norm: 0.2878, time(ms): 803.82, token/sec:652242.71, hellaswag_acc: 0.2999
Step: 14850, loss: 2.955641, norm: 0.2710, time(ms): 790.53, token/sec:663208.59, hellaswag_acc: 0.2999
Step: 14851, loss: 2.861880, norm: 0.3042, time(ms): 807.09, token/sec:649606.70, hellaswag_acc: 0.2999
Step: 14852, loss: 2.871241, norm: 0.2896, time(ms): 800.48, token/sec:654967.50, hellaswag_acc: 0.2999
Step: 14853, loss: 2.896406, norm: 0.2907, time(ms): 792.08, token/sec:661910.61, hellaswag_acc: 0.2999
Step: 14854, loss: 2.909076, norm: 0.2951, time(ms): 803.63, token/sec:652399.26, hellaswag_acc: 0.2999
Step: 14855, loss: 2.914971, norm: 0.2971, time(ms): 804.12, token/sec:652001.17, hellaswag_acc: 0.2999
Step: 14856, loss: 2.871453, norm: 0.2803, time(ms): 797.87, token/sec:657107.85, hellaswag_acc: 0.2999
Step: 14857, loss: 2.875124, norm: 0.2939, time(ms): 791.32, token/sec:662551.97, hellaswag_acc: 0.2999
Step: 14858, loss: 2.994926, norm: 0.2940, time(ms): 1329.25, token/sec:394423.40, hellaswag_acc: 0.2999
Step: 14859, loss: 3.139679, norm: 0.3190, time(ms): 764.36, token/sec:685916.82, hellaswag_acc: 0.2999
Step: 14860, loss: 3.078791, norm: 0.3629, time(ms): 789.61, token/sec:663984.76, hellaswag_acc: 0.2999
Step: 14861, loss: 3.127292, norm: 0.3116, time(ms): 803.56, token/sec:652457.13, hellaswag_acc: 0.2999
Step: 14862, loss: 3.125152, norm: 0.3293, time(ms): 788.93, token/sec:664557.45, hellaswag_acc: 0.2999
Step: 14863, loss: 3.140347, norm: 0.3232, time(ms): 783.90, token/sec:668817.14, hellaswag_acc: 0.2999
Step: 14864, loss: 3.065636, norm: 0.2940, time(ms): 791.75, token/sec:662187.86, hellaswag_acc: 0.2999
Step: 14865, loss: 3.120726, norm: 0.2758, time(ms): 794.49, token/sec:659906.40, hellaswag_acc: 0.2999
Step: 14866, loss: 3.151184, norm: 0.2999, time(ms): 801.43, token/sec:654189.28, hellaswag_acc: 0.2999
Step: 14867, loss: 3.105971, norm: 0.3605, time(ms): 794.51, token/sec:659885.01, hellaswag_acc: 0.2999
Step: 14868, loss: 3.172798, norm: 0.3694, time(ms): 796.72, token/sec:658058.01, hellaswag_acc: 0.2999
Step: 14869, loss: 3.221152, norm: 0.3288, time(ms): 788.29, token/sec:665094.31, hellaswag_acc: 0.2999
Step: 14870, loss: 3.153462, norm: 0.3033, time(ms): 789.29, token/sec:664253.53, hellaswag_acc: 0.2999
Step: 14871, loss: 3.181653, norm: 0.3447, time(ms): 790.13, token/sec:663546.19, hellaswag_acc: 0.2999
Step: 14872, loss: 3.191601, norm: 0.3109, time(ms): 799.55, token/sec:655728.61, hellaswag_acc: 0.2999
Step: 14873, loss: 3.134097, norm: 0.3048, time(ms): 801.66, token/sec:654004.06, hellaswag_acc: 0.2999
Step: 14874, loss: 3.186436, norm: 0.3118, time(ms): 796.50, token/sec:658240.22, hellaswag_acc: 0.2999
Step: 14875, loss: 3.116124, norm: 0.3008, time(ms): 793.54, token/sec:660698.69, hellaswag_acc: 0.2999
Step: 14876, loss: 3.170333, norm: 0.2971, time(ms): 798.08, token/sec:656940.21, hellaswag_acc: 0.2999
Step: 14877, loss: 3.130594, norm: 0.2865, time(ms): 789.72, token/sec:663889.15, hellaswag_acc: 0.2999
Step: 14878, loss: 3.163237, norm: 0.3086, time(ms): 787.19, token/sec:666021.93, hellaswag_acc: 0.2999
Step: 14879, loss: 3.084730, norm: 0.2896, time(ms): 787.95, token/sec:665385.31, hellaswag_acc: 0.2999
Step: 14880, loss: 3.113117, norm: 0.2660, time(ms): 804.68, token/sec:651545.65, hellaswag_acc: 0.2999
Step: 14881, loss: 3.093599, norm: 0.2767, time(ms): 793.98, token/sec:660332.64, hellaswag_acc: 0.2999
Step: 14882, loss: 3.064572, norm: 0.2944, time(ms): 797.94, token/sec:657051.70, hellaswag_acc: 0.2999
Step: 14883, loss: 3.082031, norm: 0.2836, time(ms): 793.35, token/sec:660852.17, hellaswag_acc: 0.2999
Step: 14884, loss: 3.129671, norm: 0.3069, time(ms): 796.53, token/sec:658218.35, hellaswag_acc: 0.2999
Step: 14885, loss: 3.168511, norm: 0.2978, time(ms): 796.64, token/sec:658127.54, hellaswag_acc: 0.2999
Step: 14886, loss: 3.101447, norm: 0.2984, time(ms): 797.20, token/sec:657663.03, hellaswag_acc: 0.2999
Step: 14887, loss: 3.119746, norm: 0.2872, time(ms): 799.38, token/sec:655867.46, hellaswag_acc: 0.2999
Step: 14888, loss: 3.140527, norm: 0.2620, time(ms): 791.96, token/sec:662010.64, hellaswag_acc: 0.2999
Step: 14889, loss: 3.140507, norm: 0.2874, time(ms): 797.16, token/sec:657696.46, hellaswag_acc: 0.2999
Step: 14890, loss: 3.143403, norm: 0.2780, time(ms): 788.04, token/sec:665308.01, hellaswag_acc: 0.2999
Step: 14891, loss: 3.083679, norm: 0.3058, time(ms): 787.72, token/sec:665572.80, hellaswag_acc: 0.2999
Step: 14892, loss: 3.225218, norm: 0.3259, time(ms): 796.36, token/sec:658355.70, hellaswag_acc: 0.2999
Step: 14893, loss: 3.070634, norm: 0.3127, time(ms): 801.97, token/sec:653750.14, hellaswag_acc: 0.2999
Step: 14894, loss: 3.102993, norm: 0.3000, time(ms): 798.14, token/sec:656885.06, hellaswag_acc: 0.2999
Step: 14895, loss: 3.048164, norm: 0.2973, time(ms): 801.16, token/sec:654413.36, hellaswag_acc: 0.2999
Step: 14896, loss: 3.060912, norm: 0.2785, time(ms): 800.20, token/sec:655194.85, hellaswag_acc: 0.2999
Step: 14897, loss: 3.105410, norm: 0.3029, time(ms): 799.96, token/sec:655393.24, hellaswag_acc: 0.2999
Step: 14898, loss: 3.098296, norm: 0.2824, time(ms): 799.50, token/sec:655770.84, hellaswag_acc: 0.2999
Step: 14899, loss: 3.104781, norm: 0.2930, time(ms): 796.00, token/sec:658649.51, hellaswag_acc: 0.2999
Step: 14900, loss: 3.112602, norm: 0.2917, time(ms): 804.79, token/sec:651460.53, hellaswag_acc: 0.2999
Step: 14901, loss: 3.105898, norm: 0.2889, time(ms): 798.09, token/sec:656925.49, hellaswag_acc: 0.2999
Step: 14902, loss: 3.099659, norm: 0.3094, time(ms): 802.01, token/sec:653719.04, hellaswag_acc: 0.2999
Step: 14903, loss: 3.134212, norm: 0.3074, time(ms): 792.63, token/sec:661454.67, hellaswag_acc: 0.2999
Step: 14904, loss: 3.143470, norm: 0.2895, time(ms): 796.28, token/sec:658419.57, hellaswag_acc: 0.2999
Step: 14905, loss: 3.149405, norm: 0.3222, time(ms): 797.37, token/sec:657518.49, hellaswag_acc: 0.2999
Step: 14906, loss: 3.208777, norm: 0.3073, time(ms): 792.26, token/sec:661759.22, hellaswag_acc: 0.2999
Step: 14907, loss: 3.171409, norm: 0.3318, time(ms): 784.09, token/sec:668660.75, hellaswag_acc: 0.2999
Step: 14908, loss: 3.173216, norm: 0.3098, time(ms): 790.42, token/sec:663306.01, hellaswag_acc: 0.2999
Step: 14909, loss: 3.171737, norm: 0.3325, time(ms): 804.45, token/sec:651733.92, hellaswag_acc: 0.2999
Step: 14910, loss: 3.177047, norm: 0.3281, time(ms): 792.33, token/sec:661700.68, hellaswag_acc: 0.2999
Step: 14911, loss: 3.199087, norm: 0.2900, time(ms): 792.63, token/sec:661452.28, hellaswag_acc: 0.2999
Step: 14912, loss: 3.098047, norm: 0.2798, time(ms): 793.02, token/sec:661127.34, hellaswag_acc: 0.2999
Step: 14913, loss: 3.099782, norm: 0.3061, time(ms): 798.06, token/sec:656952.57, hellaswag_acc: 0.2999
Step: 14914, loss: 3.087822, norm: 0.2637, time(ms): 798.45, token/sec:656630.66, hellaswag_acc: 0.2999
Step: 14915, loss: 3.089475, norm: 0.2822, time(ms): 791.82, token/sec:662128.05, hellaswag_acc: 0.2999
Step: 14916, loss: 3.067641, norm: 0.3056, time(ms): 788.63, token/sec:664809.59, hellaswag_acc: 0.2999
Step: 14917, loss: 3.162626, norm: 0.2896, time(ms): 794.28, token/sec:660078.14, hellaswag_acc: 0.2999
Step: 14918, loss: 3.088149, norm: 0.2772, time(ms): 791.49, token/sec:662407.48, hellaswag_acc: 0.2999
Step: 14919, loss: 3.104635, norm: 0.2843, time(ms): 790.14, token/sec:663535.78, hellaswag_acc: 0.2999
Step: 14920, loss: 3.161905, norm: 0.3141, time(ms): 806.72, token/sec:649902.93, hellaswag_acc: 0.2999
Step: 14921, loss: 3.073550, norm: 0.2793, time(ms): 801.04, token/sec:654507.83, hellaswag_acc: 0.2999
Step: 14922, loss: 3.132463, norm: 0.2956, time(ms): 796.54, token/sec:658210.27, hellaswag_acc: 0.2999
Step: 14923, loss: 3.111029, norm: 0.2729, time(ms): 798.29, token/sec:656765.39, hellaswag_acc: 0.2999
Step: 14924, loss: 3.095431, norm: 0.2771, time(ms): 804.82, token/sec:651434.09, hellaswag_acc: 0.2999
Step: 14925, loss: 3.094234, norm: 0.2914, time(ms): 800.28, token/sec:655134.14, hellaswag_acc: 0.2999
Step: 14926, loss: 3.059382, norm: 0.3352, time(ms): 795.23, token/sec:659288.13, hellaswag_acc: 0.2999
Step: 14927, loss: 3.058282, norm: 0.3140, time(ms): 798.71, token/sec:656414.47, hellaswag_acc: 0.2999
Step: 14928, loss: 3.087147, norm: 0.3156, time(ms): 805.04, token/sec:651255.25, hellaswag_acc: 0.2999
Step: 14929, loss: 3.075214, norm: 0.3084, time(ms): 800.34, token/sec:655077.54, hellaswag_acc: 0.2999
Step: 14930, loss: 3.101307, norm: 0.2946, time(ms): 791.14, token/sec:662701.33, hellaswag_acc: 0.2999
Step: 14931, loss: 3.057273, norm: 0.3182, time(ms): 805.80, token/sec:650638.83, hellaswag_acc: 0.2999
Step: 14932, loss: 3.086949, norm: 0.2907, time(ms): 802.09, token/sec:653652.00, hellaswag_acc: 0.2999
Step: 14933, loss: 3.156231, norm: 0.2838, time(ms): 791.15, token/sec:662691.74, hellaswag_acc: 0.2999
Step: 14934, loss: 3.133914, norm: 0.3522, time(ms): 798.18, token/sec:656854.06, hellaswag_acc: 0.2999
Step: 14935, loss: 3.096556, norm: 0.3140, time(ms): 792.26, token/sec:661761.41, hellaswag_acc: 0.2999
Step: 14936, loss: 3.139583, norm: 0.3091, time(ms): 791.76, token/sec:662182.08, hellaswag_acc: 0.2999
Step: 14937, loss: 3.148977, norm: 0.3059, time(ms): 791.20, token/sec:662651.60, hellaswag_acc: 0.2999
Step: 14938, loss: 3.145833, norm: 0.3099, time(ms): 788.61, token/sec:664823.06, hellaswag_acc: 0.2999
Step: 14939, loss: 3.132111, norm: 0.2949, time(ms): 804.65, token/sec:651570.36, hellaswag_acc: 0.2999
Step: 14940, loss: 3.124280, norm: 0.2795, time(ms): 802.14, token/sec:653613.53, hellaswag_acc: 0.2999
Step: 14941, loss: 3.117296, norm: 0.2890, time(ms): 789.49, token/sec:664082.82, hellaswag_acc: 0.2999
Step: 14942, loss: 3.099669, norm: 0.2919, time(ms): 799.42, token/sec:655838.71, hellaswag_acc: 0.2999
Step: 14943, loss: 3.084609, norm: 0.2847, time(ms): 797.13, token/sec:657718.10, hellaswag_acc: 0.2999
Step: 14944, loss: 3.173493, norm: 0.3100, time(ms): 792.66, token/sec:661431.39, hellaswag_acc: 0.2999
Step: 14945, loss: 3.136216, norm: 0.2790, time(ms): 790.15, token/sec:663530.37, hellaswag_acc: 0.2999
Step: 14946, loss: 3.132398, norm: 0.2645, time(ms): 790.85, token/sec:662944.47, hellaswag_acc: 0.2999
Step: 14947, loss: 3.159873, norm: 0.3052, time(ms): 785.56, token/sec:667410.83, hellaswag_acc: 0.2999
Step: 14948, loss: 3.109400, norm: 0.2819, time(ms): 792.51, token/sec:661551.38, hellaswag_acc: 0.2999
Step: 14949, loss: 3.086858, norm: 0.2845, time(ms): 795.66, token/sec:658936.68, hellaswag_acc: 0.2999
Step: 14950, loss: 3.155444, norm: 0.2792, time(ms): 803.07, token/sec:652854.03, hellaswag_acc: 0.2999
Step: 14951, loss: 3.111864, norm: 0.2737, time(ms): 798.86, token/sec:656293.01, hellaswag_acc: 0.2999
Step: 14952, loss: 3.092608, norm: 0.2550, time(ms): 802.66, token/sec:653191.26, hellaswag_acc: 0.2999
Step: 14953, loss: 3.141451, norm: 0.2769, time(ms): 791.29, token/sec:662574.33, hellaswag_acc: 0.2999
Step: 14954, loss: 3.096346, norm: 0.2771, time(ms): 799.05, token/sec:656138.70, hellaswag_acc: 0.2999
Step: 14955, loss: 3.122920, norm: 0.2609, time(ms): 805.28, token/sec:651066.67, hellaswag_acc: 0.2999
Step: 14956, loss: 3.169251, norm: 0.2664, time(ms): 803.29, token/sec:652677.12, hellaswag_acc: 0.2999
Step: 14957, loss: 3.082155, norm: 0.2666, time(ms): 788.31, token/sec:665079.62, hellaswag_acc: 0.2999
Step: 14958, loss: 3.138645, norm: 0.2806, time(ms): 792.22, token/sec:661795.07, hellaswag_acc: 0.2999
Step: 14959, loss: 3.071252, norm: 0.2696, time(ms): 795.02, token/sec:659462.32, hellaswag_acc: 0.2999
Step: 14960, loss: 3.095449, norm: 0.2695, time(ms): 793.27, token/sec:660920.10, hellaswag_acc: 0.2999
Step: 14961, loss: 3.126471, norm: 0.3002, time(ms): 791.33, token/sec:662539.60, hellaswag_acc: 0.2999
Step: 14962, loss: 3.120969, norm: 0.2891, time(ms): 788.96, token/sec:664527.73, hellaswag_acc: 0.2999
Step: 14963, loss: 3.109222, norm: 0.2860, time(ms): 798.71, token/sec:656416.82, hellaswag_acc: 0.2999
Step: 14964, loss: 3.197777, norm: 0.3012, time(ms): 790.08, token/sec:663588.24, hellaswag_acc: 0.2999
Step: 14965, loss: 3.095248, norm: 0.2927, time(ms): 799.38, token/sec:655865.90, hellaswag_acc: 0.2999
Step: 14966, loss: 3.101470, norm: 0.2912, time(ms): 787.21, token/sec:666005.19, hellaswag_acc: 0.2999
Step: 14967, loss: 3.098823, norm: 0.2879, time(ms): 790.53, token/sec:663212.19, hellaswag_acc: 0.2999
Step: 14968, loss: 3.111814, norm: 0.2693, time(ms): 796.24, token/sec:658456.44, hellaswag_acc: 0.2999
Step: 14969, loss: 3.089270, norm: 0.2760, time(ms): 791.05, token/sec:662777.83, hellaswag_acc: 0.2999
Step: 14970, loss: 3.084284, norm: 0.2968, time(ms): 795.22, token/sec:659302.76, hellaswag_acc: 0.2999
Step: 14971, loss: 3.052066, norm: 0.2665, time(ms): 793.35, token/sec:660851.57, hellaswag_acc: 0.2999
Step: 14972, loss: 3.082175, norm: 0.2939, time(ms): 802.99, token/sec:652920.71, hellaswag_acc: 0.2999
Step: 14973, loss: 3.169730, norm: 0.2706, time(ms): 801.25, token/sec:654335.08, hellaswag_acc: 0.2999
Step: 14974, loss: 3.101999, norm: 0.3009, time(ms): 801.31, token/sec:654292.44, hellaswag_acc: 0.2999
Step: 14975, loss: 3.104561, norm: 0.2933, time(ms): 789.13, token/sec:664387.79, hellaswag_acc: 0.2999
Step: 14976, loss: 3.104437, norm: 0.2818, time(ms): 792.86, token/sec:661260.34, hellaswag_acc: 0.2999
Step: 14977, loss: 3.102714, norm: 0.2865, time(ms): 794.89, token/sec:659569.92, hellaswag_acc: 0.2999
Step: 14978, loss: 3.224933, norm: 0.3118, time(ms): 792.04, token/sec:661944.08, hellaswag_acc: 0.2999
Step: 14979, loss: 3.094463, norm: 0.2943, time(ms): 790.37, token/sec:663341.62, hellaswag_acc: 0.2999
Step: 14980, loss: 3.117847, norm: 0.2904, time(ms): 791.09, token/sec:662739.87, hellaswag_acc: 0.2999
Step: 14981, loss: 3.151334, norm: 0.3131, time(ms): 798.88, token/sec:656278.71, hellaswag_acc: 0.2999
Step: 14982, loss: 3.117008, norm: 0.2752, time(ms): 793.00, token/sec:661145.83, hellaswag_acc: 0.2999
Step: 14983, loss: 3.096622, norm: 0.3089, time(ms): 796.73, token/sec:658047.58, hellaswag_acc: 0.2999
Step: 14984, loss: 3.161808, norm: 0.2833, time(ms): 790.97, token/sec:662838.96, hellaswag_acc: 0.2999
Step: 14985, loss: 3.173203, norm: 0.3172, time(ms): 794.66, token/sec:659765.04, hellaswag_acc: 0.2999
Step: 14986, loss: 3.090806, norm: 0.2789, time(ms): 789.99, token/sec:663664.94, hellaswag_acc: 0.2999
Step: 14987, loss: 3.101225, norm: 0.2869, time(ms): 792.63, token/sec:661451.49, hellaswag_acc: 0.2999
Step: 14988, loss: 3.162920, norm: 0.2722, time(ms): 790.98, token/sec:662832.56, hellaswag_acc: 0.2999
Step: 14989, loss: 3.083483, norm: 0.2992, time(ms): 799.34, token/sec:655898.57, hellaswag_acc: 0.2999
Step: 14990, loss: 3.045530, norm: 0.2952, time(ms): 785.46, token/sec:667493.89, hellaswag_acc: 0.2999
Step: 14991, loss: 3.097224, norm: 0.2651, time(ms): 801.39, token/sec:654225.48, hellaswag_acc: 0.2999
Step: 14992, loss: 3.077269, norm: 0.2700, time(ms): 794.29, token/sec:660073.58, hellaswag_acc: 0.2999
Step: 14993, loss: 3.082263, norm: 0.2894, time(ms): 791.35, token/sec:662522.43, hellaswag_acc: 0.2999
Step: 14994, loss: 3.104298, norm: 0.2918, time(ms): 790.84, token/sec:662950.66, hellaswag_acc: 0.2999
Step: 14995, loss: 3.061858, norm: 0.2815, time(ms): 790.80, token/sec:662987.24, hellaswag_acc: 0.2999
Step: 14996, loss: 3.088764, norm: 0.2885, time(ms): 801.60, token/sec:654053.47, hellaswag_acc: 0.2999
Step: 14997, loss: 3.100023, norm: 0.3158, time(ms): 802.82, token/sec:653058.77, hellaswag_acc: 0.2999
Step: 14998, loss: 3.097072, norm: 0.3047, time(ms): 790.59, token/sec:663158.18, hellaswag_acc: 0.2999
Step: 14999, loss: 3.094063, norm: 0.3265, time(ms): 803.01, token/sec:652901.91, hellaswag_acc: 0.2999
rank 0 sample 0: Hello, I'm a language model, and I think it is possible to model. Maybe. I think so. It's just just something I know. But
rank 0 sample 1: Hello, I'm a language model, so why not try this? It probably won't stop. I'd call that the 'A-level' programming language
rank 0 sample 2: Hello, I'm a language model, so I like this blog!
As a matter of fact my experience of the web has been to code, to help
rank 0 sample 3: Hello, I'm a language model, but as a person, I can't do with it. I'd like to put that aside for myself. But let
rank 1 sample 0: Hello, I'm a language model, this is the way we learn about real world and real world examples.
"The fact that it's the same as
rank 1 sample 1: Hello, I'm a language model, not an algorithm. I'm not. I'm not actually a developer. I'm very busy with code. I'm
rank 1 sample 2: Hello, I'm a language model, but on my last post, I was thinking about the more useful ones:
- The best place to learn programming languages
rank 1 sample 3: Hello, I'm a language model, and I'm working with XML. XML syntax is similar to XML syntax: <a'...</a'> <
Step: 15000, loss: 3.084147, norm: 0.2868, time(ms): 363750.99, token/sec:1441.34, val_loss: 3.1017, hellaswag_acc: 0.2999
Step: 15001, loss: 3.098764, norm: 0.3137, time(ms): 797.76, token/sec:657204.08, hellaswag_acc: 0.2999
Step: 15002, loss: 3.034331, norm: 0.3171, time(ms): 800.31, token/sec:655103.50, hellaswag_acc: 0.2999
Step: 15003, loss: 3.104879, norm: 0.2951, time(ms): 793.45, token/sec:660768.77, hellaswag_acc: 0.2999
Step: 15004, loss: 3.112618, norm: 0.2943, time(ms): 803.29, token/sec:652674.41, hellaswag_acc: 0.2999
Step: 15005, loss: 3.073843, norm: 0.3053, time(ms): 802.99, token/sec:652918.19, hellaswag_acc: 0.2999
Step: 15006, loss: 3.105666, norm: 0.2952, time(ms): 800.42, token/sec:655019.59, hellaswag_acc: 0.2999
Step: 15007, loss: 3.138991, norm: 0.2843, time(ms): 794.64, token/sec:659779.29, hellaswag_acc: 0.2999
Step: 15008, loss: 3.124661, norm: 0.2893, time(ms): 794.66, token/sec:659761.47, hellaswag_acc: 0.2999
Step: 15009, loss: 3.151296, norm: 0.3064, time(ms): 807.16, token/sec:649546.25, hellaswag_acc: 0.2999
Step: 15010, loss: 3.147135, norm: 0.2863, time(ms): 803.04, token/sec:652876.71, hellaswag_acc: 0.2999
Step: 15011, loss: 3.133861, norm: 0.2894, time(ms): 786.88, token/sec:666289.92, hellaswag_acc: 0.2999
Step: 15012, loss: 3.109627, norm: 0.2830, time(ms): 791.22, token/sec:662633.63, hellaswag_acc: 0.2999
Step: 15013, loss: 3.102021, norm: 0.2830, time(ms): 796.13, token/sec:658544.19, hellaswag_acc: 0.2999
Step: 15014, loss: 3.116913, norm: 0.2976, time(ms): 794.49, token/sec:659906.00, hellaswag_acc: 0.2999
Step: 15015, loss: 3.090754, norm: 0.2998, time(ms): 794.11, token/sec:660219.04, hellaswag_acc: 0.2999
Step: 15016, loss: 3.131321, norm: 0.2913, time(ms): 792.17, token/sec:661841.28, hellaswag_acc: 0.2999
Step: 15017, loss: 3.085151, norm: 0.2768, time(ms): 799.20, token/sec:656017.93, hellaswag_acc: 0.2999
Step: 15018, loss: 3.187639, norm: 0.2760, time(ms): 802.44, token/sec:653369.04, hellaswag_acc: 0.2999
Step: 15019, loss: 3.123825, norm: 0.3100, time(ms): 800.20, token/sec:655197.38, hellaswag_acc: 0.2999
Step: 15020, loss: 3.092241, norm: 0.2917, time(ms): 791.79, token/sec:662159.15, hellaswag_acc: 0.2999
Step: 15021, loss: 3.187531, norm: 0.2950, time(ms): 804.50, token/sec:651695.10, hellaswag_acc: 0.2999
Step: 15022, loss: 3.109890, norm: 0.2641, time(ms): 804.64, token/sec:651580.98, hellaswag_acc: 0.2999
Step: 15023, loss: 3.078750, norm: 0.2800, time(ms): 793.84, token/sec:660441.92, hellaswag_acc: 0.2999
Step: 15024, loss: 3.089243, norm: 0.2845, time(ms): 800.67, token/sec:654808.16, hellaswag_acc: 0.2999
Step: 15025, loss: 3.100260, norm: 0.2750, time(ms): 800.05, token/sec:655323.13, hellaswag_acc: 0.2999
Step: 15026, loss: 3.100672, norm: 0.2703, time(ms): 803.09, token/sec:652841.63, hellaswag_acc: 0.2999
Step: 15027, loss: 3.055697, norm: 0.2641, time(ms): 800.99, token/sec:654546.01, hellaswag_acc: 0.2999
Step: 15028, loss: 3.129760, norm: 0.2724, time(ms): 793.26, token/sec:660927.25, hellaswag_acc: 0.2999
Step: 15029, loss: 3.096889, norm: 0.2694, time(ms): 801.90, token/sec:653804.56, hellaswag_acc: 0.2999
Step: 15030, loss: 3.131985, norm: 0.2778, time(ms): 805.04, token/sec:651253.51, hellaswag_acc: 0.2999
Step: 15031, loss: 3.146263, norm: 0.2740, time(ms): 792.98, token/sec:661165.31, hellaswag_acc: 0.2999
Step: 15032, loss: 3.114287, norm: 0.2934, time(ms): 801.70, token/sec:653967.89, hellaswag_acc: 0.2999
Step: 15033, loss: 3.184313, norm: 0.3054, time(ms): 800.65, token/sec:654826.49, hellaswag_acc: 0.2999
Step: 15034, loss: 3.119963, norm: 0.2959, time(ms): 803.48, token/sec:652518.31, hellaswag_acc: 0.2999
Step: 15035, loss: 3.105071, norm: 0.3048, time(ms): 796.18, token/sec:658507.90, hellaswag_acc: 0.2999
Step: 15036, loss: 3.119575, norm: 0.2781, time(ms): 799.67, token/sec:655633.79, hellaswag_acc: 0.2999
Step: 15037, loss: 3.089044, norm: 0.3121, time(ms): 798.50, token/sec:656594.39, hellaswag_acc: 0.2999
Step: 15038, loss: 3.142198, norm: 0.2753, time(ms): 804.27, token/sec:651880.56, hellaswag_acc: 0.2999
Step: 15039, loss: 3.070579, norm: 0.2903, time(ms): 796.33, token/sec:658380.73, hellaswag_acc: 0.2999
Step: 15040, loss: 3.144438, norm: 0.3000, time(ms): 796.35, token/sec:658361.22, hellaswag_acc: 0.2999
Step: 15041, loss: 3.135592, norm: 0.2836, time(ms): 803.59, token/sec:652431.58, hellaswag_acc: 0.2999
Step: 15042, loss: 3.138448, norm: 0.2949, time(ms): 804.13, token/sec:651991.12, hellaswag_acc: 0.2999
Step: 15043, loss: 3.146189, norm: 0.2744, time(ms): 799.05, token/sec:656137.13, hellaswag_acc: 0.2999
Step: 15044, loss: 3.111383, norm: 0.2904, time(ms): 786.57, token/sec:666553.68, hellaswag_acc: 0.2999
Step: 15045, loss: 3.167337, norm: 0.2917, time(ms): 792.63, token/sec:661449.90, hellaswag_acc: 0.2999
Step: 15046, loss: 3.102950, norm: 0.2987, time(ms): 798.97, token/sec:656204.09, hellaswag_acc: 0.2999
Step: 15047, loss: 3.106140, norm: 0.2884, time(ms): 797.64, token/sec:657298.77, hellaswag_acc: 0.2999
Step: 15048, loss: 3.112949, norm: 0.2879, time(ms): 797.81, token/sec:657155.57, hellaswag_acc: 0.2999
Step: 15049, loss: 3.086107, norm: 0.2808, time(ms): 1320.78, token/sec:396954.02, hellaswag_acc: 0.2999
Step: 15050, loss: 3.110627, norm: 0.3080, time(ms): 797.30, token/sec:657577.08, hellaswag_acc: 0.2999
Step: 15051, loss: 3.036953, norm: 0.2720, time(ms): 789.62, token/sec:663974.54, hellaswag_acc: 0.2999
Step: 15052, loss: 3.090590, norm: 0.3187, time(ms): 792.96, token/sec:661179.42, hellaswag_acc: 0.2999
Step: 15053, loss: 3.114929, norm: 0.2979, time(ms): 798.15, token/sec:656876.82, hellaswag_acc: 0.2999
Step: 15054, loss: 3.105802, norm: 0.2799, time(ms): 803.12, token/sec:652810.23, hellaswag_acc: 0.2999
Step: 15055, loss: 3.124072, norm: 0.2988, time(ms): 802.66, token/sec:653190.88, hellaswag_acc: 0.2999
Step: 15056, loss: 3.120469, norm: 0.2771, time(ms): 790.17, token/sec:663514.55, hellaswag_acc: 0.2999
Step: 15057, loss: 3.134401, norm: 0.3113, time(ms): 792.90, token/sec:661232.51, hellaswag_acc: 0.2999
Step: 15058, loss: 3.080385, norm: 0.2800, time(ms): 785.40, token/sec:667538.67, hellaswag_acc: 0.2999
Step: 15059, loss: 3.095479, norm: 0.3030, time(ms): 791.49, token/sec:662408.48, hellaswag_acc: 0.2999
Step: 15060, loss: 3.136125, norm: 0.2704, time(ms): 798.37, token/sec:656700.67, hellaswag_acc: 0.2999
Step: 15061, loss: 3.119065, norm: 0.2901, time(ms): 799.56, token/sec:655721.96, hellaswag_acc: 0.2999
Step: 15062, loss: 3.122843, norm: 0.2868, time(ms): 792.72, token/sec:661379.27, hellaswag_acc: 0.2999
Step: 15063, loss: 3.051762, norm: 0.3017, time(ms): 805.29, token/sec:651053.95, hellaswag_acc: 0.2999
Step: 15064, loss: 3.038134, norm: 0.2955, time(ms): 801.20, token/sec:654378.50, hellaswag_acc: 0.2999
Step: 15065, loss: 3.130651, norm: 0.2950, time(ms): 797.75, token/sec:657205.85, hellaswag_acc: 0.2999
Step: 15066, loss: 3.096366, norm: 0.2941, time(ms): 799.54, token/sec:655740.53, hellaswag_acc: 0.2999
Step: 15067, loss: 3.089527, norm: 0.3015, time(ms): 804.37, token/sec:651800.38, hellaswag_acc: 0.2999
Step: 15068, loss: 3.069797, norm: 0.2741, time(ms): 798.58, token/sec:656525.39, hellaswag_acc: 0.2999
Step: 15069, loss: 3.064493, norm: 0.3061, time(ms): 798.14, token/sec:656890.36, hellaswag_acc: 0.2999
Step: 15070, loss: 3.066592, norm: 0.2722, time(ms): 798.12, token/sec:656899.98, hellaswag_acc: 0.2999
Step: 15071, loss: 3.025900, norm: 0.2803, time(ms): 801.43, token/sec:654190.26, hellaswag_acc: 0.2999
Step: 15072, loss: 3.099231, norm: 0.2866, time(ms): 800.65, token/sec:654829.80, hellaswag_acc: 0.2999
Step: 15073, loss: 3.101429, norm: 0.2809, time(ms): 798.41, token/sec:656668.90, hellaswag_acc: 0.2999
Step: 15074, loss: 3.065876, norm: 0.2795, time(ms): 797.60, token/sec:657333.54, hellaswag_acc: 0.2999
Step: 15075, loss: 3.146639, norm: 0.3002, time(ms): 801.14, token/sec:654425.24, hellaswag_acc: 0.2999
Step: 15076, loss: 3.115268, norm: 0.3072, time(ms): 803.25, token/sec:652704.63, hellaswag_acc: 0.2999
Step: 15077, loss: 3.105059, norm: 0.2853, time(ms): 798.67, token/sec:656450.72, hellaswag_acc: 0.2999
Step: 15078, loss: 3.110202, norm: 0.2907, time(ms): 800.14, token/sec:655242.09, hellaswag_acc: 0.2999
Step: 15079, loss: 3.093565, norm: 0.3029, time(ms): 798.76, token/sec:656381.16, hellaswag_acc: 0.2999
Step: 15080, loss: 3.142352, norm: 0.3069, time(ms): 802.12, token/sec:653630.44, hellaswag_acc: 0.2999
Step: 15081, loss: 3.210862, norm: 0.3276, time(ms): 798.88, token/sec:656278.51, hellaswag_acc: 0.2999
Step: 15082, loss: 3.074611, norm: 0.3026, time(ms): 799.57, token/sec:655714.14, hellaswag_acc: 0.2999
Step: 15083, loss: 3.062080, norm: 0.2915, time(ms): 798.99, token/sec:656185.69, hellaswag_acc: 0.2999
Step: 15084, loss: 3.114557, norm: 0.3167, time(ms): 801.86, token/sec:653841.50, hellaswag_acc: 0.2999
Step: 15085, loss: 3.123772, norm: 0.3012, time(ms): 799.49, token/sec:655776.91, hellaswag_acc: 0.2999
Step: 15086, loss: 3.176084, norm: 0.3215, time(ms): 796.98, token/sec:657845.60, hellaswag_acc: 0.2999
Step: 15087, loss: 3.096430, norm: 0.2972, time(ms): 801.26, token/sec:654329.24, hellaswag_acc: 0.2999
Step: 15088, loss: 3.077337, norm: 0.3025, time(ms): 799.08, token/sec:656112.86, hellaswag_acc: 0.2999
Step: 15089, loss: 3.160913, norm: 0.3105, time(ms): 799.14, token/sec:656067.05, hellaswag_acc: 0.2999
Step: 15090, loss: 3.116374, norm: 0.3118, time(ms): 803.29, token/sec:652675.18, hellaswag_acc: 0.2999
Step: 15091, loss: 3.099422, norm: 0.2844, time(ms): 795.80, token/sec:658822.57, hellaswag_acc: 0.2999
Step: 15092, loss: 3.122964, norm: 0.3018, time(ms): 800.93, token/sec:654601.15, hellaswag_acc: 0.2999
Step: 15093, loss: 3.069457, norm: 0.2913, time(ms): 801.48, token/sec:654148.42, hellaswag_acc: 0.2999
Step: 15094, loss: 3.048342, norm: 0.2701, time(ms): 801.09, token/sec:654469.65, hellaswag_acc: 0.2999
Step: 15095, loss: 3.244710, norm: 0.4539, time(ms): 795.97, token/sec:658680.49, hellaswag_acc: 0.2999
Step: 15096, loss: 3.075405, norm: 0.3451, time(ms): 799.77, token/sec:655550.52, hellaswag_acc: 0.2999
Step: 15097, loss: 3.048859, norm: 0.3563, time(ms): 802.62, token/sec:653221.14, hellaswag_acc: 0.2999
Step: 15098, loss: 3.136681, norm: 0.3027, time(ms): 801.99, token/sec:653734.01, hellaswag_acc: 0.2999
Step: 15099, loss: 3.151985, norm: 0.3268, time(ms): 788.56, token/sec:664867.28, hellaswag_acc: 0.2999
Step: 15100, loss: 3.053880, norm: 0.3424, time(ms): 798.83, token/sec:656317.69, hellaswag_acc: 0.2999
Step: 15101, loss: 3.123312, norm: 0.3175, time(ms): 789.67, token/sec:663934.05, hellaswag_acc: 0.2999
Step: 15102, loss: 3.062059, norm: 0.2890, time(ms): 789.14, token/sec:664380.36, hellaswag_acc: 0.2999
Step: 15103, loss: 3.057813, norm: 0.3225, time(ms): 790.41, token/sec:663312.21, hellaswag_acc: 0.2999
Step: 15104, loss: 3.111701, norm: 0.2936, time(ms): 794.09, token/sec:660240.45, hellaswag_acc: 0.2999
Step: 15105, loss: 3.045830, norm: 0.2773, time(ms): 803.96, token/sec:652133.81, hellaswag_acc: 0.2999
Step: 15106, loss: 3.104916, norm: 0.2924, time(ms): 803.15, token/sec:652789.50, hellaswag_acc: 0.2999
Step: 15107, loss: 3.121151, norm: 0.2913, time(ms): 792.49, token/sec:661574.07, hellaswag_acc: 0.2999
Step: 15108, loss: 3.058037, norm: 0.2780, time(ms): 800.13, token/sec:655255.37, hellaswag_acc: 0.2999
Step: 15109, loss: 3.086699, norm: 0.2805, time(ms): 806.69, token/sec:649927.13, hellaswag_acc: 0.2999
Step: 15110, loss: 3.031415, norm: 0.2927, time(ms): 799.48, token/sec:655789.62, hellaswag_acc: 0.2999
Step: 15111, loss: 3.051163, norm: 0.3090, time(ms): 791.92, token/sec:662046.72, hellaswag_acc: 0.2999
Step: 15112, loss: 3.146635, norm: 0.2972, time(ms): 804.60, token/sec:651614.00, hellaswag_acc: 0.2999
Step: 15113, loss: 3.093715, norm: 0.2902, time(ms): 800.63, token/sec:654847.35, hellaswag_acc: 0.2999
Step: 15114, loss: 3.116750, norm: 0.3172, time(ms): 803.51, token/sec:652494.69, hellaswag_acc: 0.2999
Step: 15115, loss: 3.071326, norm: 0.2943, time(ms): 796.54, token/sec:658207.12, hellaswag_acc: 0.2999
Step: 15116, loss: 3.232602, norm: 0.3571, time(ms): 796.67, token/sec:658096.02, hellaswag_acc: 0.2999
Step: 15117, loss: 3.118473, norm: 0.2969, time(ms): 801.27, token/sec:654323.40, hellaswag_acc: 0.2999
Step: 15118, loss: 3.098633, norm: 0.3062, time(ms): 802.67, token/sec:653181.76, hellaswag_acc: 0.2999
Step: 15119, loss: 3.096560, norm: 0.2859, time(ms): 795.05, token/sec:659438.59, hellaswag_acc: 0.2999
Step: 15120, loss: 3.097475, norm: 0.3067, time(ms): 803.51, token/sec:652493.34, hellaswag_acc: 0.2999
Step: 15121, loss: 3.118512, norm: 0.2717, time(ms): 801.65, token/sec:654011.84, hellaswag_acc: 0.2999
Step: 15122, loss: 3.114401, norm: 0.2997, time(ms): 795.45, token/sec:659111.27, hellaswag_acc: 0.2999
Step: 15123, loss: 3.129754, norm: 0.2754, time(ms): 800.25, token/sec:655155.81, hellaswag_acc: 0.2999
Step: 15124, loss: 3.146892, norm: 0.2648, time(ms): 802.99, token/sec:652922.46, hellaswag_acc: 0.2999
Step: 15125, loss: 3.091005, norm: 0.3106, time(ms): 799.48, token/sec:655785.12, hellaswag_acc: 0.2999
Step: 15126, loss: 3.096674, norm: 0.3053, time(ms): 792.13, token/sec:661875.15, hellaswag_acc: 0.2999
Step: 15127, loss: 3.133896, norm: 0.3101, time(ms): 792.70, token/sec:661396.18, hellaswag_acc: 0.2999
Step: 15128, loss: 3.079930, norm: 0.3183, time(ms): 797.10, token/sec:657743.48, hellaswag_acc: 0.2999
Step: 15129, loss: 3.090649, norm: 0.2852, time(ms): 789.64, token/sec:663962.11, hellaswag_acc: 0.2999
Step: 15130, loss: 3.057333, norm: 0.3167, time(ms): 792.40, token/sec:661641.95, hellaswag_acc: 0.2999
Step: 15131, loss: 3.086199, norm: 0.2852, time(ms): 790.56, token/sec:663188.18, hellaswag_acc: 0.2999
Step: 15132, loss: 3.092196, norm: 0.2836, time(ms): 790.45, token/sec:663275.80, hellaswag_acc: 0.2999
Step: 15133, loss: 3.184299, norm: 0.2976, time(ms): 793.40, token/sec:660815.43, hellaswag_acc: 0.2999
Step: 15134, loss: 3.064679, norm: 0.2790, time(ms): 801.38, token/sec:654232.68, hellaswag_acc: 0.2999
Step: 15135, loss: 3.068124, norm: 0.3003, time(ms): 798.18, token/sec:656850.73, hellaswag_acc: 0.2999
Step: 15136, loss: 3.077555, norm: 0.2714, time(ms): 802.00, token/sec:653726.81, hellaswag_acc: 0.2999
Step: 15137, loss: 3.075273, norm: 0.2804, time(ms): 798.61, token/sec:656499.32, hellaswag_acc: 0.2999
Step: 15138, loss: 3.033069, norm: 0.2772, time(ms): 799.61, token/sec:655676.79, hellaswag_acc: 0.2999
Step: 15139, loss: 3.102068, norm: 0.3009, time(ms): 800.92, token/sec:654609.14, hellaswag_acc: 0.2999
Step: 15140, loss: 3.060953, norm: 0.7930, time(ms): 800.12, token/sec:655258.30, hellaswag_acc: 0.2999
Step: 15141, loss: 3.092306, norm: 0.2877, time(ms): 798.65, token/sec:656467.57, hellaswag_acc: 0.2999
Step: 15142, loss: 3.087383, norm: 0.3179, time(ms): 797.18, token/sec:657681.91, hellaswag_acc: 0.2999
Step: 15143, loss: 3.028589, norm: 0.2810, time(ms): 803.68, token/sec:652363.06, hellaswag_acc: 0.2999
Step: 15144, loss: 3.085773, norm: 0.2911, time(ms): 793.98, token/sec:660325.90, hellaswag_acc: 0.2999
Step: 15145, loss: 3.068267, norm: 0.3640, time(ms): 804.98, token/sec:651308.48, hellaswag_acc: 0.2999
Step: 15146, loss: 3.124849, norm: 0.2995, time(ms): 797.87, token/sec:657105.69, hellaswag_acc: 0.2999
Step: 15147, loss: 3.134867, norm: 0.3223, time(ms): 801.11, token/sec:654453.48, hellaswag_acc: 0.2999
Step: 15148, loss: 3.173646, norm: 0.3184, time(ms): 798.26, token/sec:656787.16, hellaswag_acc: 0.2999
Step: 15149, loss: 3.082011, norm: 0.2949, time(ms): 802.07, token/sec:653665.80, hellaswag_acc: 0.2999
Step: 15150, loss: 3.163756, norm: 0.3490, time(ms): 799.51, token/sec:655758.33, hellaswag_acc: 0.2999
Step: 15151, loss: 3.118119, norm: 0.3154, time(ms): 801.14, token/sec:654427.19, hellaswag_acc: 0.2999
Step: 15152, loss: 3.099092, norm: 0.2978, time(ms): 795.82, token/sec:658805.20, hellaswag_acc: 0.2999
Step: 15153, loss: 3.144349, norm: 0.3031, time(ms): 802.47, token/sec:653344.38, hellaswag_acc: 0.2999
Step: 15154, loss: 3.136992, norm: 0.2968, time(ms): 801.76, token/sec:653917.71, hellaswag_acc: 0.2999
Step: 15155, loss: 3.122797, norm: 0.2968, time(ms): 793.23, token/sec:660957.44, hellaswag_acc: 0.2999
Step: 15156, loss: 3.118224, norm: 0.2842, time(ms): 798.87, token/sec:656284.98, hellaswag_acc: 0.2999
Step: 15157, loss: 3.090784, norm: 0.2939, time(ms): 806.54, token/sec:650042.60, hellaswag_acc: 0.2999
Step: 15158, loss: 3.113582, norm: 0.3070, time(ms): 796.81, token/sec:657982.01, hellaswag_acc: 0.2999
Step: 15159, loss: 3.135280, norm: 0.3037, time(ms): 795.17, token/sec:659342.69, hellaswag_acc: 0.2999
Step: 15160, loss: 3.135738, norm: 0.2755, time(ms): 805.46, token/sec:650914.62, hellaswag_acc: 0.2999
Step: 15161, loss: 3.073106, norm: 0.2945, time(ms): 801.50, token/sec:654134.41, hellaswag_acc: 0.2999
Step: 15162, loss: 3.069659, norm: 0.2966, time(ms): 791.11, token/sec:662720.90, hellaswag_acc: 0.2999
Step: 15163, loss: 3.097679, norm: 0.2820, time(ms): 790.75, token/sec:663024.62, hellaswag_acc: 0.2999
Step: 15164, loss: 3.121803, norm: 0.2886, time(ms): 793.71, token/sec:660557.18, hellaswag_acc: 0.2999
Step: 15165, loss: 3.176980, norm: 0.2772, time(ms): 793.78, token/sec:660496.67, hellaswag_acc: 0.2999
Step: 15166, loss: 3.095597, norm: 0.2820, time(ms): 791.28, token/sec:662578.53, hellaswag_acc: 0.2999
Step: 15167, loss: 3.130543, norm: 0.3059, time(ms): 790.04, token/sec:663620.68, hellaswag_acc: 0.2999
Step: 15168, loss: 3.152788, norm: 0.3112, time(ms): 793.46, token/sec:660759.24, hellaswag_acc: 0.2999
Step: 15169, loss: 3.069458, norm: 0.2844, time(ms): 794.12, token/sec:660211.51, hellaswag_acc: 0.2999
Step: 15170, loss: 3.079707, norm: 0.2849, time(ms): 790.44, token/sec:663290.20, hellaswag_acc: 0.2999
Step: 15171, loss: 3.084666, norm: 0.2924, time(ms): 789.41, token/sec:664154.82, hellaswag_acc: 0.2999
Step: 15172, loss: 3.011435, norm: 0.3010, time(ms): 790.48, token/sec:663250.59, hellaswag_acc: 0.2999
Step: 15173, loss: 3.135797, norm: 0.3030, time(ms): 790.80, token/sec:662980.24, hellaswag_acc: 0.2999
Step: 15174, loss: 3.044017, norm: 0.2832, time(ms): 795.40, token/sec:659153.95, hellaswag_acc: 0.2999
Step: 15175, loss: 3.080760, norm: 0.3046, time(ms): 793.41, token/sec:660802.12, hellaswag_acc: 0.2999
Step: 15176, loss: 3.101201, norm: 0.2896, time(ms): 793.16, token/sec:661010.89, hellaswag_acc: 0.2999
Step: 15177, loss: 3.036172, norm: 0.2994, time(ms): 790.73, token/sec:663042.61, hellaswag_acc: 0.2999
Step: 15178, loss: 3.038340, norm: 0.2709, time(ms): 792.20, token/sec:661814.99, hellaswag_acc: 0.2999
Step: 15179, loss: 3.097824, norm: 0.2850, time(ms): 790.13, token/sec:663544.19, hellaswag_acc: 0.2999
Step: 15180, loss: 3.078296, norm: 0.2865, time(ms): 798.85, token/sec:656299.47, hellaswag_acc: 0.2999
Step: 15181, loss: 3.090672, norm: 0.3206, time(ms): 800.15, token/sec:655240.72, hellaswag_acc: 0.2999
Step: 15182, loss: 3.144524, norm: 0.3136, time(ms): 802.73, token/sec:653134.23, hellaswag_acc: 0.2999
Step: 15183, loss: 3.100079, norm: 0.3210, time(ms): 796.36, token/sec:658356.88, hellaswag_acc: 0.2999
Step: 15184, loss: 3.141279, norm: 0.3190, time(ms): 799.01, token/sec:656172.76, hellaswag_acc: 0.2999
Step: 15185, loss: 3.112710, norm: 0.2897, time(ms): 801.28, token/sec:654309.38, hellaswag_acc: 0.2999
Step: 15186, loss: 3.139296, norm: 0.3069, time(ms): 802.84, token/sec:653041.90, hellaswag_acc: 0.2999
Step: 15187, loss: 3.062816, norm: 0.2940, time(ms): 791.66, token/sec:662266.04, hellaswag_acc: 0.2999
Step: 15188, loss: 3.081547, norm: 0.3509, time(ms): 799.87, token/sec:655464.94, hellaswag_acc: 0.2999
Step: 15189, loss: 3.169702, norm: 0.3012, time(ms): 798.70, token/sec:656427.40, hellaswag_acc: 0.2999
Step: 15190, loss: 3.178543, norm: 0.3095, time(ms): 792.55, token/sec:661522.33, hellaswag_acc: 0.2999
Step: 15191, loss: 3.076848, norm: 0.2970, time(ms): 796.89, token/sec:657918.62, hellaswag_acc: 0.2999
Step: 15192, loss: 3.161165, norm: 0.3119, time(ms): 790.38, token/sec:663334.02, hellaswag_acc: 0.2999
Step: 15193, loss: 3.091457, norm: 0.3153, time(ms): 791.57, token/sec:662336.25, hellaswag_acc: 0.2999
Step: 15194, loss: 3.083417, norm: 0.2921, time(ms): 789.41, token/sec:664150.01, hellaswag_acc: 0.2999
Step: 15195, loss: 3.132761, norm: 0.3296, time(ms): 791.09, token/sec:662743.07, hellaswag_acc: 0.2999
Step: 15196, loss: 3.059922, norm: 0.3048, time(ms): 794.94, token/sec:659532.53, hellaswag_acc: 0.2999
Step: 15197, loss: 3.092108, norm: 0.2969, time(ms): 793.62, token/sec:660627.23, hellaswag_acc: 0.2999
Step: 15198, loss: 3.078185, norm: 0.3141, time(ms): 806.12, token/sec:650386.55, hellaswag_acc: 0.2999
Step: 15199, loss: 3.069169, norm: 0.3201, time(ms): 801.41, token/sec:654204.85, hellaswag_acc: 0.2999
Step: 15200, loss: 3.058935, norm: 0.2955, time(ms): 795.93, token/sec:658712.45, hellaswag_acc: 0.2999
Step: 15201, loss: 3.141644, norm: 0.2907, time(ms): 801.56, token/sec:654084.21, hellaswag_acc: 0.2999
Step: 15202, loss: 3.109661, norm: 0.3054, time(ms): 799.58, token/sec:655701.23, hellaswag_acc: 0.2999
Step: 15203, loss: 3.087585, norm: 0.2997, time(ms): 800.56, token/sec:654900.21, hellaswag_acc: 0.2999
Step: 15204, loss: 3.117549, norm: 0.2895, time(ms): 801.67, token/sec:653998.81, hellaswag_acc: 0.2999
Step: 15205, loss: 3.090410, norm: 0.2758, time(ms): 794.74, token/sec:659701.11, hellaswag_acc: 0.2999
Step: 15206, loss: 3.068800, norm: 0.2848, time(ms): 803.64, token/sec:652389.97, hellaswag_acc: 0.2999
Step: 15207, loss: 3.060585, norm: 0.2876, time(ms): 800.23, token/sec:655169.27, hellaswag_acc: 0.2999
Step: 15208, loss: 3.071960, norm: 0.2993, time(ms): 800.35, token/sec:655075.98, hellaswag_acc: 0.2999
Step: 15209, loss: 3.176009, norm: 0.2902, time(ms): 799.41, token/sec:655844.97, hellaswag_acc: 0.2999
Step: 15210, loss: 3.108958, norm: 0.2764, time(ms): 797.24, token/sec:657631.36, hellaswag_acc: 0.2999
Step: 15211, loss: 3.047821, norm: 0.2829, time(ms): 801.45, token/sec:654170.41, hellaswag_acc: 0.2999
Step: 15212, loss: 3.080141, norm: 0.3240, time(ms): 802.45, token/sec:653355.45, hellaswag_acc: 0.2999
Step: 15213, loss: 3.068988, norm: 0.2740, time(ms): 794.16, token/sec:660175.44, hellaswag_acc: 0.2999
Step: 15214, loss: 3.090403, norm: 0.3107, time(ms): 800.24, token/sec:655160.88, hellaswag_acc: 0.2999
Step: 15215, loss: 3.028090, norm: 0.2826, time(ms): 804.57, token/sec:651634.66, hellaswag_acc: 0.2999
Step: 15216, loss: 3.070327, norm: 0.2826, time(ms): 798.50, token/sec:656589.88, hellaswag_acc: 0.2999
Step: 15217, loss: 3.054662, norm: 0.3245, time(ms): 797.65, token/sec:657292.28, hellaswag_acc: 0.2999
Step: 15218, loss: 3.102951, norm: 0.3136, time(ms): 802.34, token/sec:653446.11, hellaswag_acc: 0.2999
Step: 15219, loss: 3.112980, norm: 0.3139, time(ms): 797.63, token/sec:657306.62, hellaswag_acc: 0.2999
Step: 15220, loss: 3.012183, norm: 0.2999, time(ms): 800.39, token/sec:655039.88, hellaswag_acc: 0.2999
Step: 15221, loss: 3.182193, norm: 0.3316, time(ms): 798.49, token/sec:656596.55, hellaswag_acc: 0.2999
Step: 15222, loss: 3.080578, norm: 0.3289, time(ms): 801.46, token/sec:654167.29, hellaswag_acc: 0.2999
Step: 15223, loss: 3.137608, norm: 0.3022, time(ms): 800.72, token/sec:654770.73, hellaswag_acc: 0.2999
Step: 15224, loss: 3.247403, norm: 0.3273, time(ms): 795.57, token/sec:659006.98, hellaswag_acc: 0.2999
Step: 15225, loss: 3.108837, norm: 0.3113, time(ms): 802.12, token/sec:653626.94, hellaswag_acc: 0.2999
Step: 15226, loss: 3.123624, norm: 0.3220, time(ms): 804.02, token/sec:652079.67, hellaswag_acc: 0.2999
Step: 15227, loss: 3.074644, norm: 0.2753, time(ms): 794.25, token/sec:660103.50, hellaswag_acc: 0.2999
Step: 15228, loss: 3.098666, norm: 0.2979, time(ms): 790.66, token/sec:663100.39, hellaswag_acc: 0.2999
Step: 15229, loss: 3.105354, norm: 0.3123, time(ms): 791.20, token/sec:662653.00, hellaswag_acc: 0.2999
Step: 15230, loss: 3.077539, norm: 0.2879, time(ms): 797.31, token/sec:657569.42, hellaswag_acc: 0.2999
Step: 15231, loss: 3.122345, norm: 0.2954, time(ms): 790.77, token/sec:663006.63, hellaswag_acc: 0.2999
Step: 15232, loss: 3.106094, norm: 0.2800, time(ms): 790.14, token/sec:663542.18, hellaswag_acc: 0.2999
Step: 15233, loss: 3.102241, norm: 0.3100, time(ms): 802.54, token/sec:653287.32, hellaswag_acc: 0.2999
Step: 15234, loss: 3.126547, norm: 0.2851, time(ms): 798.58, token/sec:656523.04, hellaswag_acc: 0.2999
Step: 15235, loss: 3.094775, norm: 0.2867, time(ms): 788.91, token/sec:664573.52, hellaswag_acc: 0.2999
Step: 15236, loss: 3.112997, norm: 0.2885, time(ms): 793.39, token/sec:660817.02, hellaswag_acc: 0.2999
Step: 15237, loss: 3.074387, norm: 0.2764, time(ms): 795.26, token/sec:659266.59, hellaswag_acc: 0.2999
Step: 15238, loss: 3.060819, norm: 0.2885, time(ms): 800.74, token/sec:654756.49, hellaswag_acc: 0.2999
Step: 15239, loss: 3.081956, norm: 0.2796, time(ms): 1341.54, token/sec:390811.78, hellaswag_acc: 0.2999
Step: 15240, loss: 3.083274, norm: 0.2902, time(ms): 769.99, token/sec:680898.37, hellaswag_acc: 0.2999
Step: 15241, loss: 3.121158, norm: 0.2934, time(ms): 795.43, token/sec:659122.34, hellaswag_acc: 0.2999
Step: 15242, loss: 3.051711, norm: 0.3141, time(ms): 798.41, token/sec:656663.60, hellaswag_acc: 0.2999
Step: 15243, loss: 3.096034, norm: 0.2940, time(ms): 783.23, token/sec:669392.69, hellaswag_acc: 0.2999
Step: 15244, loss: 3.010180, norm: 0.3078, time(ms): 781.47, token/sec:670896.80, hellaswag_acc: 0.2999
Step: 15245, loss: 3.131972, norm: 0.3478, time(ms): 785.90, token/sec:667118.87, hellaswag_acc: 0.2999
Step: 15246, loss: 3.022459, norm: 0.2875, time(ms): 805.22, token/sec:651109.08, hellaswag_acc: 0.2999
Step: 15247, loss: 3.120330, norm: 0.3197, time(ms): 800.79, token/sec:654717.51, hellaswag_acc: 0.2999
Step: 15248, loss: 3.091485, norm: 0.3137, time(ms): 789.69, token/sec:663912.60, hellaswag_acc: 0.2999
Step: 15249, loss: 3.054126, norm: 0.2693, time(ms): 789.40, token/sec:664159.84, hellaswag_acc: 0.2999
rank 0 sample 0: Hello, I'm a language model, so I think it is interesting how they come up with some ideas they were thinking about when they came out.
"
rank 0 sample 1: Hello, I'm a language model, and i'm a programmer, I should be. Well, my name is Bill.
Let me break the code for
rank 0 sample 2: Hello, I'm a language model, and I really appreciate everything from grammar and syntax here. I like how we can work with other languages, and it does
rank 0 sample 3: Hello, I'm a language model, and i'm trying to explain the structure and architecture of the Web. It was about to break down how the web gets
rank 1 sample 0: Hello, I'm a language model, there is a lot of stuff like c and x in here.
And finally, we need an object.
And
rank 1 sample 1: Hello, I'm a language model, not an author. I'm writing about one of the last projects done in the recent blog series: a project in which
rank 1 sample 2: Hello, I'm a language model, I must say, I'm a language model, I have never heard a language model before and this is the most common
rank 1 sample 3: Hello, I'm a language model, so I'm interested to explain the process they use to interact with you. Is it so efficient or is it an easy
Step: 15250, loss: 3.091247, norm: 0.3057, time(ms): 3787.09, token/sec:138440.80, val_loss: 3.0990, hellaswag_acc: 0.2999
Step: 15251, loss: 3.069971, norm: 0.2848, time(ms): 782.13, token/sec:670335.21, hellaswag_acc: 0.2999
Step: 15252, loss: 3.062608, norm: 0.2901, time(ms): 788.44, token/sec:664971.02, hellaswag_acc: 0.2999
Step: 15253, loss: 3.027063, norm: 0.3013, time(ms): 798.62, token/sec:656495.21, hellaswag_acc: 0.2999
Step: 15254, loss: 2.997244, norm: 0.2949, time(ms): 801.68, token/sec:653990.25, hellaswag_acc: 0.2999
Step: 15255, loss: 3.029735, norm: 0.2841, time(ms): 793.48, token/sec:660745.54, hellaswag_acc: 0.2999
Step: 15256, loss: 3.012236, norm: 0.3093, time(ms): 790.11, token/sec:663565.21, hellaswag_acc: 0.2999
Step: 15257, loss: 3.018828, norm: 0.2905, time(ms): 790.83, token/sec:662961.05, hellaswag_acc: 0.2999
Step: 15258, loss: 3.011572, norm: 0.3423, time(ms): 790.73, token/sec:663043.01, hellaswag_acc: 0.2999
Step: 15259, loss: 2.982906, norm: 0.2752, time(ms): 791.27, token/sec:662592.10, hellaswag_acc: 0.2999
Step: 15260, loss: 3.126814, norm: 0.3103, time(ms): 803.52, token/sec:652490.24, hellaswag_acc: 0.2999
Step: 15261, loss: 2.979485, norm: 0.2786, time(ms): 802.26, token/sec:653516.02, hellaswag_acc: 0.2999
Step: 15262, loss: 3.007547, norm: 0.2731, time(ms): 788.70, token/sec:664748.50, hellaswag_acc: 0.2999
Step: 15263, loss: 3.010296, norm: 0.3011, time(ms): 800.35, token/sec:655072.27, hellaswag_acc: 0.2999
Step: 15264, loss: 3.005813, norm: 0.2757, time(ms): 791.85, token/sec:662102.13, hellaswag_acc: 0.2999
Step: 15265, loss: 3.089891, norm: 0.2907, time(ms): 788.41, token/sec:664994.35, hellaswag_acc: 0.2999
Step: 15266, loss: 3.092796, norm: 0.2971, time(ms): 792.82, token/sec:661296.93, hellaswag_acc: 0.2999
Step: 15267, loss: 3.100612, norm: 0.2842, time(ms): 790.07, token/sec:663597.85, hellaswag_acc: 0.2999
Step: 15268, loss: 3.120842, norm: 0.2835, time(ms): 797.76, token/sec:657197.60, hellaswag_acc: 0.2999
Step: 15269, loss: 3.070319, norm: 0.3039, time(ms): 807.46, token/sec:649302.68, hellaswag_acc: 0.2999
Step: 15270, loss: 3.124832, norm: 0.2833, time(ms): 796.28, token/sec:658424.10, hellaswag_acc: 0.2999
Step: 15271, loss: 3.088057, norm: 0.3256, time(ms): 790.41, token/sec:663308.01, hellaswag_acc: 0.2999
Step: 15272, loss: 3.166454, norm: 0.3402, time(ms): 792.17, token/sec:661841.48, hellaswag_acc: 0.2999
Step: 15273, loss: 3.080817, norm: 0.2848, time(ms): 794.49, token/sec:659907.19, hellaswag_acc: 0.2999
Step: 15274, loss: 3.123214, norm: 0.3080, time(ms): 795.72, token/sec:658886.93, hellaswag_acc: 0.2999
Step: 15275, loss: 3.088154, norm: 0.2879, time(ms): 789.54, token/sec:664039.50, hellaswag_acc: 0.2999
Step: 15276, loss: 3.121512, norm: 0.2933, time(ms): 786.78, token/sec:666371.90, hellaswag_acc: 0.2999
Step: 15277, loss: 3.108627, norm: 0.3047, time(ms): 788.76, token/sec:664698.87, hellaswag_acc: 0.2999
Step: 15278, loss: 3.039446, norm: 0.2656, time(ms): 800.77, token/sec:654727.64, hellaswag_acc: 0.2999
Step: 15279, loss: 3.101188, norm: 0.2888, time(ms): 803.05, token/sec:652871.48, hellaswag_acc: 0.2999
Step: 15280, loss: 3.083555, norm: 0.3052, time(ms): 796.06, token/sec:658600.59, hellaswag_acc: 0.2999
Step: 15281, loss: 3.084687, norm: 0.2799, time(ms): 796.49, token/sec:658246.13, hellaswag_acc: 0.2999
Step: 15282, loss: 3.054723, norm: 0.3091, time(ms): 805.92, token/sec:650549.13, hellaswag_acc: 0.2999
Step: 15283, loss: 3.075214, norm: 0.2781, time(ms): 792.81, token/sec:661300.51, hellaswag_acc: 0.2999
Step: 15284, loss: 3.084238, norm: 0.2741, time(ms): 797.72, token/sec:657236.29, hellaswag_acc: 0.2999
Step: 15285, loss: 3.083565, norm: 0.2712, time(ms): 790.12, token/sec:663558.40, hellaswag_acc: 0.2999
Step: 15286, loss: 3.056735, norm: 0.2661, time(ms): 790.26, token/sec:663440.29, hellaswag_acc: 0.2999
Step: 15287, loss: 3.052046, norm: 0.2739, time(ms): 791.03, token/sec:662795.40, hellaswag_acc: 0.2999
Step: 15288, loss: 3.078172, norm: 0.2853, time(ms): 789.94, token/sec:663703.80, hellaswag_acc: 0.2999
Step: 15289, loss: 3.034836, norm: 0.2599, time(ms): 797.53, token/sec:657389.94, hellaswag_acc: 0.2999
Step: 15290, loss: 3.046473, norm: 0.2864, time(ms): 790.82, token/sec:662966.85, hellaswag_acc: 0.2999
Step: 15291, loss: 3.016392, norm: 0.2814, time(ms): 790.98, token/sec:662834.96, hellaswag_acc: 0.2999
Step: 15292, loss: 2.971498, norm: 0.2742, time(ms): 791.52, token/sec:662378.15, hellaswag_acc: 0.2999
Step: 15293, loss: 3.032476, norm: 0.3085, time(ms): 787.72, token/sec:665573.41, hellaswag_acc: 0.2999
Step: 15294, loss: 3.018378, norm: 0.2887, time(ms): 790.30, token/sec:663403.26, hellaswag_acc: 0.2999
Step: 15295, loss: 3.007678, norm: 0.2821, time(ms): 793.44, token/sec:660776.51, hellaswag_acc: 0.2999
Step: 15296, loss: 2.991186, norm: 0.2863, time(ms): 801.84, token/sec:653853.35, hellaswag_acc: 0.2999
Step: 15297, loss: 3.008959, norm: 0.2840, time(ms): 802.65, token/sec:653198.64, hellaswag_acc: 0.2999
Step: 15298, loss: 3.022194, norm: 0.2838, time(ms): 800.41, token/sec:655025.25, hellaswag_acc: 0.2999
Step: 15299, loss: 3.062418, norm: 0.3525, time(ms): 794.28, token/sec:660079.72, hellaswag_acc: 0.2999
Step: 15300, loss: 3.065814, norm: 0.3125, time(ms): 802.78, token/sec:653090.58, hellaswag_acc: 0.2999
Step: 15301, loss: 3.080242, norm: 0.3004, time(ms): 802.30, token/sec:653478.93, hellaswag_acc: 0.2999
Step: 15302, loss: 3.077583, norm: 0.3081, time(ms): 788.17, token/sec:665198.72, hellaswag_acc: 0.2999
Step: 15303, loss: 3.048236, norm: 0.3105, time(ms): 790.69, token/sec:663075.00, hellaswag_acc: 0.2999
Step: 15304, loss: 3.068324, norm: 0.2937, time(ms): 792.59, token/sec:661484.12, hellaswag_acc: 0.2999
Step: 15305, loss: 3.158688, norm: 0.3100, time(ms): 794.72, token/sec:659711.59, hellaswag_acc: 0.2999
Step: 15306, loss: 3.139024, norm: 0.3000, time(ms): 794.41, token/sec:659969.18, hellaswag_acc: 0.2999
Step: 15307, loss: 3.070220, norm: 0.3018, time(ms): 788.35, token/sec:665047.64, hellaswag_acc: 0.2999
Step: 15308, loss: 3.136607, norm: 0.3004, time(ms): 792.32, token/sec:661714.22, hellaswag_acc: 0.2999
Step: 15309, loss: 3.042506, norm: 0.2859, time(ms): 797.90, token/sec:657081.15, hellaswag_acc: 0.2999
Step: 15310, loss: 3.166208, norm: 0.3265, time(ms): 795.50, token/sec:659069.00, hellaswag_acc: 0.2999
Step: 15311, loss: 3.045000, norm: 0.3101, time(ms): 800.02, token/sec:655341.68, hellaswag_acc: 0.2999
Step: 15312, loss: 3.086183, norm: 0.3058, time(ms): 801.22, token/sec:654362.15, hellaswag_acc: 0.2999
Step: 15313, loss: 3.137851, norm: 0.2842, time(ms): 793.16, token/sec:661009.10, hellaswag_acc: 0.2999
Step: 15314, loss: 3.084586, norm: 0.2920, time(ms): 790.43, token/sec:663293.80, hellaswag_acc: 0.2999
Step: 15315, loss: 3.086132, norm: 0.2885, time(ms): 787.62, token/sec:665660.24, hellaswag_acc: 0.2999
Step: 15316, loss: 3.133167, norm: 0.2974, time(ms): 789.95, token/sec:663695.79, hellaswag_acc: 0.2999
Step: 15317, loss: 3.054948, norm: 0.2668, time(ms): 798.04, token/sec:656970.43, hellaswag_acc: 0.2999
Step: 15318, loss: 3.102330, norm: 0.2975, time(ms): 796.27, token/sec:658431.59, hellaswag_acc: 0.2999
Step: 15319, loss: 3.048340, norm: 0.2785, time(ms): 802.56, token/sec:653271.02, hellaswag_acc: 0.2999
Step: 15320, loss: 3.080885, norm: 0.2708, time(ms): 802.93, token/sec:652969.77, hellaswag_acc: 0.2999
Step: 15321, loss: 3.099364, norm: 0.2653, time(ms): 798.39, token/sec:656680.47, hellaswag_acc: 0.2999
Step: 15322, loss: 3.068098, norm: 0.2826, time(ms): 793.82, token/sec:660461.55, hellaswag_acc: 0.2999
Step: 15323, loss: 2.984944, norm: 0.2872, time(ms): 804.09, token/sec:652024.76, hellaswag_acc: 0.2999
Step: 15324, loss: 3.012539, norm: 0.2609, time(ms): 802.31, token/sec:653473.49, hellaswag_acc: 0.2999
Step: 15325, loss: 3.044445, norm: 0.2696, time(ms): 796.68, token/sec:658095.04, hellaswag_acc: 0.2999
Step: 15326, loss: 2.945748, norm: 0.2849, time(ms): 795.02, token/sec:659466.86, hellaswag_acc: 0.2999
Step: 15327, loss: 3.029718, norm: 0.2780, time(ms): 803.13, token/sec:652807.71, hellaswag_acc: 0.2999
Step: 15328, loss: 2.982580, norm: 0.2990, time(ms): 804.67, token/sec:651558.59, hellaswag_acc: 0.2999
Step: 15329, loss: 3.010863, norm: 0.2754, time(ms): 798.68, token/sec:656446.41, hellaswag_acc: 0.2999
Step: 15330, loss: 3.030629, norm: 0.2791, time(ms): 798.43, token/sec:656647.13, hellaswag_acc: 0.2999
Step: 15331, loss: 3.016076, norm: 0.2809, time(ms): 799.70, token/sec:655604.86, hellaswag_acc: 0.2999
Step: 15332, loss: 3.025359, norm: 0.2831, time(ms): 801.98, token/sec:653746.05, hellaswag_acc: 0.2999
Step: 15333, loss: 3.005629, norm: 0.2769, time(ms): 798.85, token/sec:656302.80, hellaswag_acc: 0.2999
Step: 15334, loss: 3.076188, norm: 0.2946, time(ms): 797.43, token/sec:657470.92, hellaswag_acc: 0.2999
Step: 15335, loss: 3.065663, norm: 0.2894, time(ms): 799.62, token/sec:655672.49, hellaswag_acc: 0.2999
Step: 15336, loss: 3.050074, norm: 0.2820, time(ms): 801.86, token/sec:653843.25, hellaswag_acc: 0.2999
Step: 15337, loss: 3.043681, norm: 0.2721, time(ms): 799.91, token/sec:655436.81, hellaswag_acc: 0.2999
Step: 15338, loss: 3.085857, norm: 0.2667, time(ms): 800.63, token/sec:654844.04, hellaswag_acc: 0.2999
Step: 15339, loss: 3.067933, norm: 0.2847, time(ms): 797.39, token/sec:657507.68, hellaswag_acc: 0.2999
Step: 15340, loss: 3.085769, norm: 0.2709, time(ms): 801.04, token/sec:654507.63, hellaswag_acc: 0.2999
Step: 15341, loss: 3.095742, norm: 0.2905, time(ms): 800.90, token/sec:654627.27, hellaswag_acc: 0.2999
Step: 15342, loss: 3.108808, norm: 0.2792, time(ms): 796.25, token/sec:658448.55, hellaswag_acc: 0.2999
Step: 15343, loss: 3.095806, norm: 0.2773, time(ms): 798.66, token/sec:656463.06, hellaswag_acc: 0.2999
Step: 15344, loss: 3.073077, norm: 0.2825, time(ms): 800.59, token/sec:654880.31, hellaswag_acc: 0.2999
Step: 15345, loss: 3.064434, norm: 0.2808, time(ms): 805.34, token/sec:651010.97, hellaswag_acc: 0.2999
Step: 15346, loss: 3.084901, norm: 0.2807, time(ms): 792.03, token/sec:661951.46, hellaswag_acc: 0.2999
Step: 15347, loss: 3.046714, norm: 0.2678, time(ms): 803.80, token/sec:652259.54, hellaswag_acc: 0.2999
Step: 15348, loss: 3.077094, norm: 0.2917, time(ms): 804.53, token/sec:651672.51, hellaswag_acc: 0.2999
Step: 15349, loss: 3.086075, norm: 0.2649, time(ms): 798.50, token/sec:656593.41, hellaswag_acc: 0.2999
Step: 15350, loss: 3.031283, norm: 0.3058, time(ms): 795.30, token/sec:659235.95, hellaswag_acc: 0.2999
Step: 15351, loss: 3.040051, norm: 0.2811, time(ms): 802.71, token/sec:653146.25, hellaswag_acc: 0.2999
Step: 15352, loss: 3.056423, norm: 0.2829, time(ms): 801.68, token/sec:653986.95, hellaswag_acc: 0.2999
Step: 15353, loss: 3.056145, norm: 0.2875, time(ms): 797.63, token/sec:657310.36, hellaswag_acc: 0.2999
Step: 15354, loss: 3.098691, norm: 0.2779, time(ms): 796.06, token/sec:658604.14, hellaswag_acc: 0.2999
Step: 15355, loss: 3.086811, norm: 0.2821, time(ms): 806.16, token/sec:650355.19, hellaswag_acc: 0.2999
Step: 15356, loss: 3.102955, norm: 0.2963, time(ms): 800.00, token/sec:655356.33, hellaswag_acc: 0.2999
Step: 15357, loss: 3.089284, norm: 0.2890, time(ms): 794.96, token/sec:659514.53, hellaswag_acc: 0.2999
Step: 15358, loss: 3.047809, norm: 0.2996, time(ms): 799.14, token/sec:656065.68, hellaswag_acc: 0.2999
Step: 15359, loss: 2.990317, norm: 0.2751, time(ms): 801.82, token/sec:653868.71, hellaswag_acc: 0.2999
Step: 15360, loss: 3.058670, norm: 0.2624, time(ms): 803.27, token/sec:652693.01, hellaswag_acc: 0.2999
Step: 15361, loss: 3.004107, norm: 0.2645, time(ms): 791.28, token/sec:662581.52, hellaswag_acc: 0.2999
Step: 15362, loss: 3.042284, norm: 0.2818, time(ms): 799.35, token/sec:655894.26, hellaswag_acc: 0.2999
Step: 15363, loss: 3.020765, norm: 0.2580, time(ms): 808.10, token/sec:648787.37, hellaswag_acc: 0.2999
Step: 15364, loss: 3.024467, norm: 0.2669, time(ms): 801.79, token/sec:653897.68, hellaswag_acc: 0.2999
Step: 15365, loss: 3.019682, norm: 0.2718, time(ms): 794.17, token/sec:660170.68, hellaswag_acc: 0.2999
Step: 15366, loss: 2.996279, norm: 0.2600, time(ms): 795.65, token/sec:658945.96, hellaswag_acc: 0.2999
Step: 15367, loss: 3.007283, norm: 0.2673, time(ms): 805.80, token/sec:650640.37, hellaswag_acc: 0.2999
Step: 15368, loss: 2.982701, norm: 0.2801, time(ms): 803.96, token/sec:652135.75, hellaswag_acc: 0.2999
Step: 15369, loss: 3.041654, norm: 0.2927, time(ms): 795.07, token/sec:659425.34, hellaswag_acc: 0.2999
Step: 15370, loss: 3.154850, norm: 0.2861, time(ms): 799.38, token/sec:655864.72, hellaswag_acc: 0.2999
Step: 15371, loss: 3.119178, norm: 0.2910, time(ms): 798.79, token/sec:656356.08, hellaswag_acc: 0.2999
Step: 15372, loss: 3.062299, norm: 0.2993, time(ms): 804.23, token/sec:651910.52, hellaswag_acc: 0.2999
Step: 15373, loss: 3.148509, norm: 0.3502, time(ms): 795.55, token/sec:659026.33, hellaswag_acc: 0.2999
Step: 15374, loss: 3.095519, norm: 0.3040, time(ms): 800.66, token/sec:654819.27, hellaswag_acc: 0.2999
Step: 15375, loss: 3.138374, norm: 0.3164, time(ms): 804.68, token/sec:651551.06, hellaswag_acc: 0.2999
Step: 15376, loss: 3.150897, norm: 0.3176, time(ms): 799.23, token/sec:655988.18, hellaswag_acc: 0.2999
Step: 15377, loss: 3.139425, norm: 0.3297, time(ms): 794.38, token/sec:659997.51, hellaswag_acc: 0.2999
Step: 15378, loss: 3.062465, norm: 0.2996, time(ms): 800.05, token/sec:655322.35, hellaswag_acc: 0.2999
Step: 15379, loss: 3.130711, norm: 0.3224, time(ms): 802.42, token/sec:653380.88, hellaswag_acc: 0.2999
Step: 15380, loss: 3.091909, norm: 0.3180, time(ms): 801.30, token/sec:654294.59, hellaswag_acc: 0.2999
Step: 15381, loss: 3.071279, norm: 0.3177, time(ms): 799.38, token/sec:655864.33, hellaswag_acc: 0.2999
Step: 15382, loss: 3.061417, norm: 0.2952, time(ms): 796.06, token/sec:658601.19, hellaswag_acc: 0.2999
Step: 15383, loss: 3.060816, norm: 0.2942, time(ms): 802.05, token/sec:653685.81, hellaswag_acc: 0.2999
Step: 15384, loss: 3.088131, norm: 0.3214, time(ms): 802.78, token/sec:653092.52, hellaswag_acc: 0.2999
Step: 15385, loss: 3.042063, norm: 0.2843, time(ms): 796.17, token/sec:658513.62, hellaswag_acc: 0.2999
Step: 15386, loss: 3.047692, norm: 0.3004, time(ms): 790.06, token/sec:663605.26, hellaswag_acc: 0.2999
Step: 15387, loss: 3.073568, norm: 0.2886, time(ms): 792.73, token/sec:661373.51, hellaswag_acc: 0.2999
Step: 15388, loss: 3.059938, norm: 0.2920, time(ms): 791.55, token/sec:662356.60, hellaswag_acc: 0.2999
Step: 15389, loss: 3.009094, norm: 0.3018, time(ms): 793.94, token/sec:660359.02, hellaswag_acc: 0.2999
Step: 15390, loss: 3.127232, norm: 0.2796, time(ms): 789.16, token/sec:664358.68, hellaswag_acc: 0.2999
Step: 15391, loss: 3.045913, norm: 0.3145, time(ms): 795.66, token/sec:658936.28, hellaswag_acc: 0.2999
Step: 15392, loss: 3.066191, norm: 0.3182, time(ms): 790.87, token/sec:662927.08, hellaswag_acc: 0.2999
Step: 15393, loss: 3.031418, norm: 0.3205, time(ms): 797.70, token/sec:657247.29, hellaswag_acc: 0.2999
Step: 15394, loss: 3.008884, norm: 0.3040, time(ms): 797.94, token/sec:657051.70, hellaswag_acc: 0.2999
Step: 15395, loss: 3.072929, norm: 0.3338, time(ms): 800.90, token/sec:654623.76, hellaswag_acc: 0.2999
Step: 15396, loss: 3.011918, norm: 0.3068, time(ms): 800.25, token/sec:655158.93, hellaswag_acc: 0.2999
Step: 15397, loss: 3.074281, norm: 0.3288, time(ms): 797.42, token/sec:657479.17, hellaswag_acc: 0.2999
Step: 15398, loss: 3.031674, norm: 0.3394, time(ms): 799.59, token/sec:655698.89, hellaswag_acc: 0.2999
Step: 15399, loss: 3.014137, norm: 0.3009, time(ms): 799.81, token/sec:655515.74, hellaswag_acc: 0.2999
Step: 15400, loss: 2.948749, norm: 0.2951, time(ms): 799.60, token/sec:655684.61, hellaswag_acc: 0.2999
Step: 15401, loss: 3.031250, norm: 0.2934, time(ms): 800.42, token/sec:655012.96, hellaswag_acc: 0.2999
Step: 15402, loss: 3.010887, norm: 0.2962, time(ms): 797.92, token/sec:657072.12, hellaswag_acc: 0.2999
Step: 15403, loss: 3.025041, norm: 0.3002, time(ms): 795.21, token/sec:659309.48, hellaswag_acc: 0.2999
Step: 15404, loss: 3.004262, norm: 0.2816, time(ms): 790.38, token/sec:663335.22, hellaswag_acc: 0.2999
Step: 15405, loss: 2.999634, norm: 0.3080, time(ms): 789.38, token/sec:664176.89, hellaswag_acc: 0.2999
Step: 15406, loss: 3.104655, norm: 0.2978, time(ms): 790.91, token/sec:662889.11, hellaswag_acc: 0.2999
Step: 15407, loss: 3.139551, norm: 0.4326, time(ms): 798.74, token/sec:656395.66, hellaswag_acc: 0.2999
Step: 15408, loss: 3.093551, norm: 0.3128, time(ms): 791.44, token/sec:662444.40, hellaswag_acc: 0.2999
Step: 15409, loss: 3.120043, norm: 0.2795, time(ms): 805.92, token/sec:650546.82, hellaswag_acc: 0.2999
Step: 15410, loss: 3.194027, norm: 0.4179, time(ms): 801.77, token/sec:653915.38, hellaswag_acc: 0.2999
Step: 15411, loss: 3.053290, norm: 0.2980, time(ms): 794.98, token/sec:659501.48, hellaswag_acc: 0.2999
Step: 15412, loss: 2.987291, norm: 0.2998, time(ms): 797.81, token/sec:657158.32, hellaswag_acc: 0.2999
Step: 15413, loss: 3.075421, norm: 0.3231, time(ms): 806.94, token/sec:649726.85, hellaswag_acc: 0.2999
Step: 15414, loss: 3.082677, norm: 0.2791, time(ms): 801.04, token/sec:654509.00, hellaswag_acc: 0.2999
Step: 15415, loss: 3.195204, norm: 0.4185, time(ms): 787.84, token/sec:665479.34, hellaswag_acc: 0.2999
Step: 15416, loss: 3.066988, norm: 0.3360, time(ms): 795.66, token/sec:658936.68, hellaswag_acc: 0.2999
Step: 15417, loss: 3.086763, norm: 0.3104, time(ms): 793.72, token/sec:660543.69, hellaswag_acc: 0.2999
Step: 15418, loss: 3.103815, norm: 0.3135, time(ms): 792.05, token/sec:661936.31, hellaswag_acc: 0.2999
Step: 15419, loss: 3.076560, norm: 0.2922, time(ms): 792.72, token/sec:661376.29, hellaswag_acc: 0.2999
Step: 15420, loss: 3.108203, norm: 0.3020, time(ms): 792.75, token/sec:661354.61, hellaswag_acc: 0.2999
Step: 15421, loss: 3.038272, norm: 0.3041, time(ms): 798.27, token/sec:656780.49, hellaswag_acc: 0.2999
Step: 15422, loss: 3.068578, norm: 0.3766, time(ms): 803.02, token/sec:652892.02, hellaswag_acc: 0.2999
Step: 15423, loss: 3.051597, norm: 0.3006, time(ms): 792.37, token/sec:661667.23, hellaswag_acc: 0.2999
Step: 15424, loss: 3.034024, norm: 0.2911, time(ms): 792.34, token/sec:661691.72, hellaswag_acc: 0.2999
Step: 15425, loss: 3.111611, norm: 0.2870, time(ms): 790.58, token/sec:663171.98, hellaswag_acc: 0.2999
Step: 15426, loss: 3.070740, norm: 0.2965, time(ms): 794.38, token/sec:659995.92, hellaswag_acc: 0.2999
Step: 15427, loss: 3.127315, norm: 0.2576, time(ms): 789.78, token/sec:663840.85, hellaswag_acc: 0.2999
Step: 15428, loss: 3.063157, norm: 0.2727, time(ms): 791.27, token/sec:662588.31, hellaswag_acc: 0.2999
Step: 15429, loss: 3.053521, norm: 0.3000, time(ms): 790.44, token/sec:663283.40, hellaswag_acc: 0.2999
Step: 15430, loss: 3.075156, norm: 0.2666, time(ms): 1267.53, token/sec:413629.98, hellaswag_acc: 0.2999
Step: 15431, loss: 2.976299, norm: 0.3081, time(ms): 794.98, token/sec:659501.28, hellaswag_acc: 0.2999
Step: 15432, loss: 2.993738, norm: 0.2862, time(ms): 786.07, token/sec:666972.17, hellaswag_acc: 0.2999
Step: 15433, loss: 3.065594, norm: 0.2748, time(ms): 785.83, token/sec:667173.52, hellaswag_acc: 0.2999
Step: 15434, loss: 3.104948, norm: 0.2662, time(ms): 798.83, token/sec:656320.82, hellaswag_acc: 0.2999
Step: 15435, loss: 3.065898, norm: 0.2887, time(ms): 800.96, token/sec:654572.32, hellaswag_acc: 0.2999
Step: 15436, loss: 3.047870, norm: 0.2871, time(ms): 791.69, token/sec:662237.12, hellaswag_acc: 0.2999
Step: 15437, loss: 3.109712, norm: 0.2769, time(ms): 781.71, token/sec:670696.27, hellaswag_acc: 0.2999
Step: 15438, loss: 3.042190, norm: 0.2585, time(ms): 791.64, token/sec:662282.79, hellaswag_acc: 0.2999
Step: 15439, loss: 2.999105, norm: 0.2770, time(ms): 798.13, token/sec:656893.70, hellaswag_acc: 0.2999
Step: 15440, loss: 3.144943, norm: 0.3025, time(ms): 786.92, token/sec:666255.60, hellaswag_acc: 0.2999
Step: 15441, loss: 3.159959, norm: 0.3003, time(ms): 788.46, token/sec:664953.33, hellaswag_acc: 0.2999
Step: 15442, loss: 3.161300, norm: 0.3447, time(ms): 794.02, token/sec:660298.14, hellaswag_acc: 0.2999
Step: 15443, loss: 3.097754, norm: 0.2927, time(ms): 791.16, token/sec:662683.55, hellaswag_acc: 0.2999
Step: 15444, loss: 3.096718, norm: 0.2960, time(ms): 797.40, token/sec:657499.03, hellaswag_acc: 0.2999
Step: 15445, loss: 3.194714, norm: 0.3025, time(ms): 797.68, token/sec:657265.17, hellaswag_acc: 0.2999
Step: 15446, loss: 3.087718, norm: 0.3019, time(ms): 799.16, token/sec:656048.65, hellaswag_acc: 0.2999
Step: 15447, loss: 3.091618, norm: 0.3041, time(ms): 802.56, token/sec:653266.16, hellaswag_acc: 0.2999
Step: 15448, loss: 3.205542, norm: 0.3370, time(ms): 798.16, token/sec:656867.80, hellaswag_acc: 0.2999
Step: 15449, loss: 3.208438, norm: 0.3267, time(ms): 793.76, token/sec:660511.15, hellaswag_acc: 0.2999
Step: 15450, loss: 3.087595, norm: 0.3070, time(ms): 793.01, token/sec:661138.67, hellaswag_acc: 0.2999
Step: 15451, loss: 3.164824, norm: 0.3819, time(ms): 795.80, token/sec:658817.84, hellaswag_acc: 0.2999
Step: 15452, loss: 3.100192, norm: 0.2872, time(ms): 793.49, token/sec:660739.38, hellaswag_acc: 0.2999
Step: 15453, loss: 3.070154, norm: 0.3056, time(ms): 799.68, token/sec:655625.77, hellaswag_acc: 0.2999
Step: 15454, loss: 3.112683, norm: 0.3165, time(ms): 803.55, token/sec:652460.81, hellaswag_acc: 0.2999
Step: 15455, loss: 3.037055, norm: 0.2946, time(ms): 795.10, token/sec:659401.41, hellaswag_acc: 0.2999
Step: 15456, loss: 3.090796, norm: 0.3011, time(ms): 791.30, token/sec:662565.95, hellaswag_acc: 0.2999
Step: 15457, loss: 3.092608, norm: 0.2703, time(ms): 786.45, token/sec:666647.85, hellaswag_acc: 0.2999
Step: 15458, loss: 3.058611, norm: 0.2803, time(ms): 793.13, token/sec:661040.29, hellaswag_acc: 0.2999
Step: 15459, loss: 3.048571, norm: 0.2812, time(ms): 794.63, token/sec:659785.82, hellaswag_acc: 0.2999
Step: 15460, loss: 3.089332, norm: 0.3016, time(ms): 800.52, token/sec:654936.68, hellaswag_acc: 0.2999
Step: 15461, loss: 3.118692, norm: 0.2758, time(ms): 797.98, token/sec:657021.86, hellaswag_acc: 0.2999
Step: 15462, loss: 3.116616, norm: 0.3618, time(ms): 800.23, token/sec:655169.27, hellaswag_acc: 0.2999
Step: 15463, loss: 3.045695, norm: 0.3113, time(ms): 801.46, token/sec:654167.68, hellaswag_acc: 0.2999
Step: 15464, loss: 3.030319, norm: 0.2782, time(ms): 800.04, token/sec:655326.06, hellaswag_acc: 0.2999
Step: 15465, loss: 2.990745, norm: 0.2958, time(ms): 798.96, token/sec:656210.36, hellaswag_acc: 0.2999
Step: 15466, loss: 3.093671, norm: 0.3167, time(ms): 797.89, token/sec:657096.27, hellaswag_acc: 0.2999
Step: 15467, loss: 3.054189, norm: 0.2948, time(ms): 802.04, token/sec:653696.69, hellaswag_acc: 0.2999
Step: 15468, loss: 3.004342, norm: 0.2763, time(ms): 800.81, token/sec:654695.48, hellaswag_acc: 0.2999
Step: 15469, loss: 3.010998, norm: 0.2812, time(ms): 793.23, token/sec:660950.89, hellaswag_acc: 0.2999
Step: 15470, loss: 3.035044, norm: 0.2880, time(ms): 801.43, token/sec:654191.81, hellaswag_acc: 0.2999
Step: 15471, loss: 2.988623, norm: 0.2737, time(ms): 803.99, token/sec:652110.61, hellaswag_acc: 0.2999
Step: 15472, loss: 3.002405, norm: 0.2808, time(ms): 797.72, token/sec:657230.99, hellaswag_acc: 0.2999
Step: 15473, loss: 3.106565, norm: 0.2949, time(ms): 797.33, token/sec:657558.60, hellaswag_acc: 0.2999
Step: 15474, loss: 3.047319, norm: 0.2946, time(ms): 804.19, token/sec:651949.37, hellaswag_acc: 0.2999
Step: 15475, loss: 3.033243, norm: 0.2916, time(ms): 801.38, token/sec:654230.15, hellaswag_acc: 0.2999
Step: 15476, loss: 3.106771, norm: 0.3198, time(ms): 787.68, token/sec:665607.05, hellaswag_acc: 0.2999
Step: 15477, loss: 3.146791, norm: 0.2996, time(ms): 789.19, token/sec:664337.01, hellaswag_acc: 0.2999
Step: 15478, loss: 3.119585, norm: 0.3213, time(ms): 797.65, token/sec:657289.92, hellaswag_acc: 0.2999
Step: 15479, loss: 3.133675, norm: 0.3070, time(ms): 789.05, token/sec:664455.64, hellaswag_acc: 0.2999
Step: 15480, loss: 3.125875, norm: 0.3161, time(ms): 791.03, token/sec:662793.41, hellaswag_acc: 0.2999
Step: 15481, loss: 3.184449, norm: 0.3189, time(ms): 797.64, token/sec:657300.53, hellaswag_acc: 0.2999
Step: 15482, loss: 3.148585, norm: 0.3078, time(ms): 803.15, token/sec:652790.47, hellaswag_acc: 0.2999
Step: 15483, loss: 3.139609, norm: 0.3189, time(ms): 804.03, token/sec:652073.87, hellaswag_acc: 0.2999
Step: 15484, loss: 3.179813, norm: 0.3208, time(ms): 791.62, token/sec:662299.55, hellaswag_acc: 0.2999
Step: 15485, loss: 3.148330, norm: 0.3029, time(ms): 797.49, token/sec:657423.35, hellaswag_acc: 0.2999
Step: 15486, loss: 3.151569, norm: 0.3064, time(ms): 791.17, token/sec:662674.37, hellaswag_acc: 0.2999
Step: 15487, loss: 3.056013, norm: 0.2855, time(ms): 797.52, token/sec:657399.57, hellaswag_acc: 0.2999
Step: 15488, loss: 3.043415, norm: 0.2897, time(ms): 787.26, token/sec:665963.84, hellaswag_acc: 0.2999
Step: 15489, loss: 3.095391, norm: 0.2990, time(ms): 787.39, token/sec:665857.57, hellaswag_acc: 0.2999
Step: 15490, loss: 3.045426, norm: 0.2936, time(ms): 795.17, token/sec:659338.74, hellaswag_acc: 0.2999
Step: 15491, loss: 3.065692, norm: 0.3070, time(ms): 790.95, token/sec:662857.74, hellaswag_acc: 0.2999
Step: 15492, loss: 3.038963, norm: 0.3012, time(ms): 798.83, token/sec:656318.27, hellaswag_acc: 0.2999
Step: 15493, loss: 3.068512, norm: 0.2832, time(ms): 795.48, token/sec:659084.80, hellaswag_acc: 0.2999
Step: 15494, loss: 3.096352, norm: 0.3017, time(ms): 803.23, token/sec:652723.04, hellaswag_acc: 0.2999
Step: 15495, loss: 3.052862, norm: 0.2948, time(ms): 800.25, token/sec:655156.39, hellaswag_acc: 0.2999
Step: 15496, loss: 3.027464, norm: 0.2914, time(ms): 799.06, token/sec:656131.06, hellaswag_acc: 0.2999
Step: 15497, loss: 3.078258, norm: 0.2909, time(ms): 797.34, token/sec:657543.46, hellaswag_acc: 0.2999
Step: 15498, loss: 3.086416, norm: 0.2950, time(ms): 800.26, token/sec:655143.90, hellaswag_acc: 0.2999
Step: 15499, loss: 3.013475, norm: 0.3066, time(ms): 800.76, token/sec:654735.63, hellaswag_acc: 0.2999
rank 0 sample 0: Hello, I'm a language model, so I'd like you to learn something now if you want to build such a model for a game or other application or
rank 0 sample 1: Hello, I'm a language model, and when I go back to my desk, the student goes back to my office. The desk has my laptop, and
rank 0 sample 2: Hello, I'm a language model, and I wrote it just using a special syntax I gave you (see this post). I'm not sure if you actually
rank 0 sample 3: Hello, I'm a language model, and all I'm doing is creating a model graph. I'm looking at some class files to get things started and sort
rank 1 sample 0: Hello, I'm a language model, so we can use it.
Just to start the fun bit, let's say I've typed the text correctly.
rank 1 sample 1: Hello, I'm a language model, which means I want to be able to get the meaning by using these languages. I feel that the best way to learn
rank 1 sample 2: Hello, I'm a language model, I call the object model, and I call the class and all I want to do is create that model, but all
rank 1 sample 3: Hello, I'm a language model, so I'm interested to develop a theory test. I came across this problem several years ago, and I thought:

Step: 15500, loss: 3.020096, norm: 0.2934, time(ms): 3785.73, token/sec:138490.59, val_loss: 3.0967, hellaswag_acc: 0.2999
Step: 15501, loss: 3.067398, norm: 0.2803, time(ms): 782.71, token/sec:669841.07, hellaswag_acc: 0.2999
Step: 15502, loss: 3.051383, norm: 0.3093, time(ms): 786.77, token/sec:666379.37, hellaswag_acc: 0.2999
Step: 15503, loss: 2.993876, norm: 0.2636, time(ms): 802.76, token/sec:653104.74, hellaswag_acc: 0.2999
Step: 15504, loss: 2.967624, norm: 0.2768, time(ms): 802.65, token/sec:653194.37, hellaswag_acc: 0.2999
Step: 15505, loss: 2.987813, norm: 0.2893, time(ms): 790.33, token/sec:663374.44, hellaswag_acc: 0.2999
Step: 15506, loss: 2.994043, norm: 0.2729, time(ms): 790.69, token/sec:663080.00, hellaswag_acc: 0.2999
Step: 15507, loss: 3.048101, norm: 0.2640, time(ms): 798.34, token/sec:656719.69, hellaswag_acc: 0.2999
Step: 15508, loss: 3.030311, norm: 0.2729, time(ms): 797.40, token/sec:657497.46, hellaswag_acc: 0.2999
Step: 15509, loss: 3.007512, norm: 0.2663, time(ms): 797.85, token/sec:657127.10, hellaswag_acc: 0.2999
Step: 15510, loss: 2.989078, norm: 0.2568, time(ms): 797.77, token/sec:657190.33, hellaswag_acc: 0.2999
Step: 15511, loss: 3.152369, norm: 0.2980, time(ms): 790.79, token/sec:662995.43, hellaswag_acc: 0.2999
Step: 15512, loss: 3.120697, norm: 0.2894, time(ms): 787.62, token/sec:665658.23, hellaswag_acc: 0.2999
Step: 15513, loss: 3.178211, norm: 0.3113, time(ms): 792.17, token/sec:661839.69, hellaswag_acc: 0.2999
Step: 15514, loss: 3.146743, norm: 0.2738, time(ms): 791.65, token/sec:662270.23, hellaswag_acc: 0.2999
Step: 15515, loss: 3.194175, norm: 0.3429, time(ms): 804.59, token/sec:651620.95, hellaswag_acc: 0.2999
Step: 15516, loss: 3.114896, norm: 0.2966, time(ms): 797.84, token/sec:657132.20, hellaswag_acc: 0.2999
Step: 15517, loss: 3.436649, norm: 0.6025, time(ms): 792.15, token/sec:661852.04, hellaswag_acc: 0.2999
Step: 15518, loss: 3.148681, norm: 0.3803, time(ms): 790.43, token/sec:663295.60, hellaswag_acc: 0.2999
Step: 15519, loss: 3.127599, norm: 0.3881, time(ms): 788.66, token/sec:664781.25, hellaswag_acc: 0.2999
Step: 15520, loss: 3.068704, norm: 0.3067, time(ms): 791.66, token/sec:662261.45, hellaswag_acc: 0.2999
Step: 15521, loss: 3.111876, norm: 0.3218, time(ms): 790.49, token/sec:663240.19, hellaswag_acc: 0.2999
Step: 15522, loss: 3.091050, norm: 0.3182, time(ms): 796.74, token/sec:658043.44, hellaswag_acc: 0.2999
Step: 15523, loss: 3.053983, norm: 0.2974, time(ms): 790.09, token/sec:663582.43, hellaswag_acc: 0.2999
Step: 15524, loss: 3.096438, norm: 0.3435, time(ms): 793.83, token/sec:660454.81, hellaswag_acc: 0.2999
Step: 15525, loss: 3.110431, norm: 0.2834, time(ms): 798.94, token/sec:656225.63, hellaswag_acc: 0.2999
Step: 15526, loss: 3.073139, norm: 0.2963, time(ms): 800.57, token/sec:654895.91, hellaswag_acc: 0.2999
Step: 15527, loss: 3.075888, norm: 0.2903, time(ms): 804.41, token/sec:651770.24, hellaswag_acc: 0.2999
Step: 15528, loss: 3.014469, norm: 0.2736, time(ms): 793.98, token/sec:660328.68, hellaswag_acc: 0.2999
Step: 15529, loss: 3.058933, norm: 0.3020, time(ms): 795.34, token/sec:659201.37, hellaswag_acc: 0.2999
Step: 15530, loss: 3.047286, norm: 0.2781, time(ms): 790.09, token/sec:663583.23, hellaswag_acc: 0.2999
Step: 15531, loss: 3.055388, norm: 0.2888, time(ms): 791.20, token/sec:662646.81, hellaswag_acc: 0.2999
Step: 15532, loss: 3.117112, norm: 0.2809, time(ms): 791.99, token/sec:661990.11, hellaswag_acc: 0.2999
Step: 15533, loss: 3.096785, norm: 0.2837, time(ms): 799.82, token/sec:655506.95, hellaswag_acc: 0.2999
Step: 15534, loss: 3.081546, norm: 0.2751, time(ms): 782.47, token/sec:670043.74, hellaswag_acc: 0.2999
Step: 15535, loss: 3.058196, norm: 0.2767, time(ms): 790.44, token/sec:663284.60, hellaswag_acc: 0.2999
Step: 15536, loss: 3.031374, norm: 0.2881, time(ms): 794.16, token/sec:660179.80, hellaswag_acc: 0.2999
Step: 15537, loss: 3.033373, norm: 0.2734, time(ms): 792.57, token/sec:661504.22, hellaswag_acc: 0.2999
Step: 15538, loss: 3.009809, norm: 0.2898, time(ms): 791.11, token/sec:662726.29, hellaswag_acc: 0.2999
Step: 15539, loss: 2.999186, norm: 0.2722, time(ms): 797.73, token/sec:657224.70, hellaswag_acc: 0.2999
Step: 15540, loss: 3.030206, norm: 0.2663, time(ms): 792.56, token/sec:661511.18, hellaswag_acc: 0.2999
Step: 15541, loss: 3.067009, norm: 0.2752, time(ms): 797.83, token/sec:657140.06, hellaswag_acc: 0.2999
Step: 15542, loss: 3.023412, norm: 0.2782, time(ms): 788.41, token/sec:664992.13, hellaswag_acc: 0.2999
Step: 15543, loss: 3.024802, norm: 0.2690, time(ms): 789.30, token/sec:664245.70, hellaswag_acc: 0.2999
Step: 15544, loss: 3.005184, norm: 0.2815, time(ms): 790.05, token/sec:663611.47, hellaswag_acc: 0.2999
Step: 15545, loss: 3.036013, norm: 0.2919, time(ms): 790.86, token/sec:662938.07, hellaswag_acc: 0.2999
Step: 15546, loss: 3.085353, norm: 0.2716, time(ms): 791.47, token/sec:662420.25, hellaswag_acc: 0.2999
Step: 15547, loss: 3.110823, norm: 0.2889, time(ms): 805.62, token/sec:650786.13, hellaswag_acc: 0.2999
Step: 15548, loss: 3.089828, norm: 0.2826, time(ms): 802.49, token/sec:653330.41, hellaswag_acc: 0.2999
Step: 15549, loss: 3.090743, norm: 0.2936, time(ms): 789.33, token/sec:664219.22, hellaswag_acc: 0.2999
Step: 15550, loss: 3.121782, norm: 0.2949, time(ms): 796.52, token/sec:658219.53, hellaswag_acc: 0.2999
Step: 15551, loss: 3.096550, norm: 0.2803, time(ms): 792.90, token/sec:661231.51, hellaswag_acc: 0.2999
Step: 15552, loss: 3.130040, norm: 0.2869, time(ms): 789.78, token/sec:663843.65, hellaswag_acc: 0.2999
Step: 15553, loss: 3.127361, norm: 0.2885, time(ms): 790.36, token/sec:663352.83, hellaswag_acc: 0.2999
Step: 15554, loss: 3.131517, norm: 0.2987, time(ms): 795.65, token/sec:658946.55, hellaswag_acc: 0.2999
Step: 15555, loss: 3.092182, norm: 0.2681, time(ms): 798.23, token/sec:656815.22, hellaswag_acc: 0.2999
Step: 15556, loss: 3.100625, norm: 0.2983, time(ms): 804.25, token/sec:651893.70, hellaswag_acc: 0.2999
Step: 15557, loss: 3.131452, norm: 0.2780, time(ms): 800.56, token/sec:654903.52, hellaswag_acc: 0.2999
Step: 15558, loss: 3.051462, norm: 0.2635, time(ms): 788.87, token/sec:664610.07, hellaswag_acc: 0.2999
Step: 15559, loss: 3.073538, norm: 0.2834, time(ms): 790.22, token/sec:663467.91, hellaswag_acc: 0.2999
Step: 15560, loss: 3.086791, norm: 0.2875, time(ms): 800.32, token/sec:655096.28, hellaswag_acc: 0.2999
Step: 15561, loss: 3.031800, norm: 0.2802, time(ms): 797.82, token/sec:657151.05, hellaswag_acc: 0.2999
Step: 15562, loss: 3.010320, norm: 0.2865, time(ms): 798.68, token/sec:656441.12, hellaswag_acc: 0.2999
Step: 15563, loss: 3.068729, norm: 0.2755, time(ms): 798.00, token/sec:657005.17, hellaswag_acc: 0.2999
Step: 15564, loss: 3.152639, norm: 0.3906, time(ms): 798.93, token/sec:656236.01, hellaswag_acc: 0.2999
Step: 15565, loss: 3.123552, norm: 0.2897, time(ms): 795.96, token/sec:658687.39, hellaswag_acc: 0.2999
Step: 15566, loss: 3.094593, norm: 0.2858, time(ms): 789.73, token/sec:663883.13, hellaswag_acc: 0.2999
Step: 15567, loss: 3.132867, norm: 0.3277, time(ms): 790.91, token/sec:662895.30, hellaswag_acc: 0.2999
Step: 15568, loss: 3.088349, norm: 0.2697, time(ms): 791.56, token/sec:662347.42, hellaswag_acc: 0.2999
Step: 15569, loss: 3.010368, norm: 0.3053, time(ms): 794.36, token/sec:660010.78, hellaswag_acc: 0.2999
Step: 15570, loss: 3.010427, norm: 0.3054, time(ms): 792.87, token/sec:661250.80, hellaswag_acc: 0.2999
Step: 15571, loss: 3.018562, norm: 0.2957, time(ms): 796.32, token/sec:658385.07, hellaswag_acc: 0.2999
Step: 15572, loss: 3.065992, norm: 0.3236, time(ms): 792.05, token/sec:661941.69, hellaswag_acc: 0.2999
Step: 15573, loss: 3.020630, norm: 0.2964, time(ms): 791.26, token/sec:662598.89, hellaswag_acc: 0.2999
Step: 15574, loss: 2.985287, norm: 0.2789, time(ms): 790.94, token/sec:662863.33, hellaswag_acc: 0.2999
Step: 15575, loss: 3.031518, norm: 0.3044, time(ms): 795.90, token/sec:658733.37, hellaswag_acc: 0.2999
Step: 15576, loss: 3.002694, norm: 0.3015, time(ms): 798.84, token/sec:656310.83, hellaswag_acc: 0.2999
Step: 15577, loss: 2.994769, norm: 0.2730, time(ms): 801.28, token/sec:654309.19, hellaswag_acc: 0.2999
Step: 15578, loss: 3.050826, norm: 0.2960, time(ms): 802.75, token/sec:653117.74, hellaswag_acc: 0.2999
Step: 15579, loss: 3.042820, norm: 0.2968, time(ms): 792.48, token/sec:661579.05, hellaswag_acc: 0.2999
Step: 15580, loss: 3.171266, norm: 0.3732, time(ms): 802.75, token/sec:653116.57, hellaswag_acc: 0.2999
Step: 15581, loss: 3.079919, norm: 0.3304, time(ms): 800.13, token/sec:655256.34, hellaswag_acc: 0.2999
Step: 15582, loss: 3.082611, norm: 0.2880, time(ms): 800.44, token/sec:655002.81, hellaswag_acc: 0.2999
Step: 15583, loss: 3.150380, norm: 0.3093, time(ms): 799.59, token/sec:655694.58, hellaswag_acc: 0.2999
Step: 15584, loss: 3.210698, norm: 0.3150, time(ms): 800.01, token/sec:655349.88, hellaswag_acc: 0.2999
Step: 15585, loss: 3.165860, norm: 0.3078, time(ms): 799.23, token/sec:655992.29, hellaswag_acc: 0.2999
Step: 15586, loss: 3.079207, norm: 0.2987, time(ms): 800.25, token/sec:655156.59, hellaswag_acc: 0.2999
Step: 15587, loss: 3.109176, norm: 0.3236, time(ms): 799.67, token/sec:655629.88, hellaswag_acc: 0.2999
Step: 15588, loss: 3.111708, norm: 0.3061, time(ms): 800.25, token/sec:655155.61, hellaswag_acc: 0.2999
Step: 15589, loss: 3.131365, norm: 0.3362, time(ms): 800.93, token/sec:654596.48, hellaswag_acc: 0.2999
Step: 15590, loss: 3.107383, norm: 0.3153, time(ms): 798.76, token/sec:656380.18, hellaswag_acc: 0.2999
Step: 15591, loss: 3.075017, norm: 0.2758, time(ms): 794.52, token/sec:659884.22, hellaswag_acc: 0.2999
Step: 15592, loss: 3.085443, norm: 0.2941, time(ms): 804.66, token/sec:651561.09, hellaswag_acc: 0.2999
Step: 15593, loss: 3.091240, norm: 0.2950, time(ms): 803.17, token/sec:652776.13, hellaswag_acc: 0.2999
Step: 15594, loss: 3.049834, norm: 0.2770, time(ms): 789.98, token/sec:663674.96, hellaswag_acc: 0.2999
Step: 15595, loss: 3.066601, norm: 0.2711, time(ms): 791.27, token/sec:662589.91, hellaswag_acc: 0.2999
Step: 15596, loss: 3.112278, norm: 0.3005, time(ms): 794.58, token/sec:659833.14, hellaswag_acc: 0.2999
Step: 15597, loss: 2.999061, norm: 0.2684, time(ms): 797.59, token/sec:657342.78, hellaswag_acc: 0.2999
Step: 15598, loss: 3.057084, norm: 0.3005, time(ms): 802.54, token/sec:653288.09, hellaswag_acc: 0.2999
Step: 15599, loss: 3.067212, norm: 0.2947, time(ms): 801.74, token/sec:653941.44, hellaswag_acc: 0.2999
Step: 15600, loss: 3.035263, norm: 0.2727, time(ms): 795.62, token/sec:658966.50, hellaswag_acc: 0.2999
Step: 15601, loss: 3.039361, norm: 0.2781, time(ms): 795.19, token/sec:659325.89, hellaswag_acc: 0.2999
Step: 15602, loss: 3.101026, norm: 0.2725, time(ms): 789.93, token/sec:663715.02, hellaswag_acc: 0.2999
Step: 15603, loss: 3.051699, norm: 0.2774, time(ms): 790.45, token/sec:663274.40, hellaswag_acc: 0.2999
Step: 15604, loss: 3.037080, norm: 0.2597, time(ms): 790.71, token/sec:663061.20, hellaswag_acc: 0.2999
Step: 15605, loss: 3.029809, norm: 0.2725, time(ms): 796.32, token/sec:658390.98, hellaswag_acc: 0.2999
Step: 15606, loss: 3.008815, norm: 0.2611, time(ms): 799.25, token/sec:655973.31, hellaswag_acc: 0.2999
Step: 15607, loss: 3.058991, norm: 0.2795, time(ms): 803.06, token/sec:652865.47, hellaswag_acc: 0.2999
Step: 15608, loss: 3.075310, norm: 0.2513, time(ms): 793.26, token/sec:660928.24, hellaswag_acc: 0.2999
Step: 15609, loss: 3.003144, norm: 0.2769, time(ms): 803.47, token/sec:652531.67, hellaswag_acc: 0.2999
Step: 15610, loss: 2.946878, norm: 0.2786, time(ms): 802.63, token/sec:653215.90, hellaswag_acc: 0.2999
Step: 15611, loss: 3.028241, norm: 0.2761, time(ms): 793.94, token/sec:660361.99, hellaswag_acc: 0.2999
Step: 15612, loss: 3.045630, norm: 0.2838, time(ms): 798.37, token/sec:656697.14, hellaswag_acc: 0.2999
Step: 15613, loss: 2.926732, norm: 0.3417, time(ms): 806.28, token/sec:650251.73, hellaswag_acc: 0.2999
Step: 15614, loss: 2.993231, norm: 0.2970, time(ms): 801.21, token/sec:654369.35, hellaswag_acc: 0.2999
Step: 15615, loss: 2.998534, norm: 0.2679, time(ms): 786.89, token/sec:666277.00, hellaswag_acc: 0.2999
Step: 15616, loss: 3.043512, norm: 0.2962, time(ms): 789.58, token/sec:664008.82, hellaswag_acc: 0.2999
Step: 15617, loss: 3.115578, norm: 0.3038, time(ms): 797.83, token/sec:657144.18, hellaswag_acc: 0.2999
Step: 15618, loss: 3.172339, norm: 0.2929, time(ms): 790.87, token/sec:662923.68, hellaswag_acc: 0.2999
Step: 15619, loss: 3.071024, norm: 0.3524, time(ms): 791.83, token/sec:662119.28, hellaswag_acc: 0.2999
Step: 15620, loss: 3.180166, norm: 0.2991, time(ms): 1338.73, token/sec:391630.99, hellaswag_acc: 0.2999
Step: 15621, loss: 3.115927, norm: 0.3074, time(ms): 769.22, token/sec:681580.25, hellaswag_acc: 0.2999
Step: 15622, loss: 3.166358, norm: 0.3147, time(ms): 790.24, token/sec:663455.50, hellaswag_acc: 0.2999
Step: 15623, loss: 3.056740, norm: 0.3158, time(ms): 801.69, token/sec:653977.42, hellaswag_acc: 0.2999
Step: 15624, loss: 3.118540, norm: 0.3198, time(ms): 789.52, token/sec:664056.35, hellaswag_acc: 0.2999
Step: 15625, loss: 3.102416, norm: 0.2952, time(ms): 782.52, token/sec:669999.44, hellaswag_acc: 0.2999
Step: 15626, loss: 3.032701, norm: 0.3218, time(ms): 799.56, token/sec:655717.66, hellaswag_acc: 0.2999
Step: 15627, loss: 3.082747, norm: 0.3240, time(ms): 797.95, token/sec:657041.88, hellaswag_acc: 0.2999
Step: 15628, loss: 3.136213, norm: 0.3322, time(ms): 790.78, token/sec:663005.03, hellaswag_acc: 0.2999
Step: 15629, loss: 3.090677, norm: 0.3353, time(ms): 788.61, token/sec:664824.66, hellaswag_acc: 0.2999
Step: 15630, loss: 3.092983, norm: 0.3160, time(ms): 789.06, token/sec:664449.42, hellaswag_acc: 0.2999
Step: 15631, loss: 3.077294, norm: 0.3072, time(ms): 799.64, token/sec:655650.99, hellaswag_acc: 0.2999
Step: 15632, loss: 3.093234, norm: 0.3116, time(ms): 797.28, token/sec:657597.73, hellaswag_acc: 0.2999
Step: 15633, loss: 3.118786, norm: 0.3088, time(ms): 801.42, token/sec:654199.01, hellaswag_acc: 0.2999
Step: 15634, loss: 3.073341, norm: 0.3614, time(ms): 802.67, token/sec:653180.59, hellaswag_acc: 0.2999
Step: 15635, loss: 3.068669, norm: 0.3364, time(ms): 796.46, token/sec:658272.53, hellaswag_acc: 0.2999
Step: 15636, loss: 3.055293, norm: 0.3002, time(ms): 798.22, token/sec:656820.12, hellaswag_acc: 0.2999
Step: 15637, loss: 3.146579, norm: 0.3384, time(ms): 804.70, token/sec:651534.07, hellaswag_acc: 0.2999
Step: 15638, loss: 3.110984, norm: 0.3004, time(ms): 793.46, token/sec:660763.21, hellaswag_acc: 0.2999
Step: 15639, loss: 3.113303, norm: 0.2925, time(ms): 800.96, token/sec:654572.32, hellaswag_acc: 0.2999
Step: 15640, loss: 3.067225, norm: 0.2820, time(ms): 804.32, token/sec:651836.51, hellaswag_acc: 0.2999
Step: 15641, loss: 3.135112, norm: 0.3146, time(ms): 800.12, token/sec:655263.57, hellaswag_acc: 0.2999
Step: 15642, loss: 3.030309, norm: 0.2821, time(ms): 795.96, token/sec:658687.20, hellaswag_acc: 0.2999
Step: 15643, loss: 3.111291, norm: 0.2904, time(ms): 795.66, token/sec:658934.11, hellaswag_acc: 0.2999
Step: 15644, loss: 3.099316, norm: 0.3030, time(ms): 806.54, token/sec:650042.02, hellaswag_acc: 0.2999
Step: 15645, loss: 3.076814, norm: 0.2712, time(ms): 801.38, token/sec:654231.91, hellaswag_acc: 0.2999
Step: 15646, loss: 3.046512, norm: 0.2913, time(ms): 790.48, token/sec:663252.79, hellaswag_acc: 0.2999
Step: 15647, loss: 3.109891, norm: 0.3003, time(ms): 791.83, token/sec:662121.07, hellaswag_acc: 0.2999
Step: 15648, loss: 3.120067, norm: 0.2699, time(ms): 786.59, token/sec:666535.30, hellaswag_acc: 0.2999
Step: 15649, loss: 3.049098, norm: 0.2852, time(ms): 790.84, token/sec:662951.86, hellaswag_acc: 0.2999
Step: 15650, loss: 3.087203, norm: 0.2686, time(ms): 797.73, token/sec:657223.13, hellaswag_acc: 0.2999
Step: 15651, loss: 3.162516, norm: 0.2783, time(ms): 792.75, token/sec:661350.23, hellaswag_acc: 0.2999
Step: 15652, loss: 3.124218, norm: 0.2711, time(ms): 792.28, token/sec:661746.08, hellaswag_acc: 0.2999
Step: 15653, loss: 3.084205, norm: 0.2740, time(ms): 794.56, token/sec:659843.23, hellaswag_acc: 0.2999
Step: 15654, loss: 3.047596, norm: 0.2704, time(ms): 797.29, token/sec:657589.67, hellaswag_acc: 0.2999
Step: 15655, loss: 3.078992, norm: 0.2857, time(ms): 799.34, token/sec:655900.91, hellaswag_acc: 0.2999
Step: 15656, loss: 3.126764, norm: 0.2891, time(ms): 800.01, token/sec:655351.45, hellaswag_acc: 0.2999
Step: 15657, loss: 3.225764, norm: 0.2868, time(ms): 797.46, token/sec:657444.77, hellaswag_acc: 0.2999
Step: 15658, loss: 3.109224, norm: 0.2947, time(ms): 793.41, token/sec:660807.29, hellaswag_acc: 0.2999
Step: 15659, loss: 3.140974, norm: 0.2785, time(ms): 792.08, token/sec:661914.99, hellaswag_acc: 0.2999
Step: 15660, loss: 3.096164, norm: 0.3191, time(ms): 790.04, token/sec:663620.88, hellaswag_acc: 0.2999
Step: 15661, loss: 3.107309, norm: 0.3105, time(ms): 791.75, token/sec:662187.46, hellaswag_acc: 0.2999
Step: 15662, loss: 3.036862, norm: 0.3123, time(ms): 796.61, token/sec:658144.87, hellaswag_acc: 0.2999
Step: 15663, loss: 3.060156, norm: 0.3171, time(ms): 795.75, token/sec:658857.51, hellaswag_acc: 0.2999
Step: 15664, loss: 3.220750, norm: 0.3434, time(ms): 806.00, token/sec:650482.36, hellaswag_acc: 0.2999
Step: 15665, loss: 3.079967, norm: 0.3400, time(ms): 800.21, token/sec:655187.43, hellaswag_acc: 0.2999
Step: 15666, loss: 3.160364, norm: 0.3071, time(ms): 793.02, token/sec:661126.55, hellaswag_acc: 0.2999
Step: 15667, loss: 3.079569, norm: 0.2998, time(ms): 797.71, token/sec:657239.04, hellaswag_acc: 0.2999
Step: 15668, loss: 3.073028, norm: 0.3183, time(ms): 808.74, token/sec:648280.71, hellaswag_acc: 0.2999
Step: 15669, loss: 3.093024, norm: 0.2967, time(ms): 790.50, token/sec:663236.99, hellaswag_acc: 0.2999
Step: 15670, loss: 3.078544, norm: 0.2939, time(ms): 792.47, token/sec:661586.01, hellaswag_acc: 0.2999
Step: 15671, loss: 3.134380, norm: 0.3144, time(ms): 792.07, token/sec:661918.58, hellaswag_acc: 0.2999
Step: 15672, loss: 3.092407, norm: 0.2990, time(ms): 794.91, token/sec:659558.05, hellaswag_acc: 0.2999
Step: 15673, loss: 3.073015, norm: 0.3246, time(ms): 792.19, token/sec:661819.97, hellaswag_acc: 0.2999
Step: 15674, loss: 3.105024, norm: 0.2975, time(ms): 788.83, token/sec:664636.99, hellaswag_acc: 0.2999
Step: 15675, loss: 3.172885, norm: 0.3040, time(ms): 792.88, token/sec:661247.82, hellaswag_acc: 0.2999
Step: 15676, loss: 3.150170, norm: 0.3155, time(ms): 794.28, token/sec:660079.92, hellaswag_acc: 0.2999
Step: 15677, loss: 3.091322, norm: 0.2925, time(ms): 795.13, token/sec:659374.72, hellaswag_acc: 0.2999
Step: 15678, loss: 3.040215, norm: 0.2947, time(ms): 796.43, token/sec:658299.93, hellaswag_acc: 0.2999
Step: 15679, loss: 3.113887, norm: 0.2923, time(ms): 791.51, token/sec:662388.52, hellaswag_acc: 0.2999
Step: 15680, loss: 3.115613, norm: 0.3390, time(ms): 789.13, token/sec:664390.00, hellaswag_acc: 0.2999
Step: 15681, loss: 3.079238, norm: 0.2774, time(ms): 794.80, token/sec:659647.08, hellaswag_acc: 0.2999
Step: 15682, loss: 3.119385, norm: 0.2820, time(ms): 792.11, token/sec:661885.71, hellaswag_acc: 0.2999
Step: 15683, loss: 3.043610, norm: 0.2895, time(ms): 799.11, token/sec:656092.69, hellaswag_acc: 0.2999
Step: 15684, loss: 3.148620, norm: 0.2778, time(ms): 801.34, token/sec:654263.83, hellaswag_acc: 0.2999
Step: 15685, loss: 3.070608, norm: 0.2672, time(ms): 793.80, token/sec:660476.03, hellaswag_acc: 0.2999
Step: 15686, loss: 3.103154, norm: 0.2911, time(ms): 800.47, token/sec:654972.96, hellaswag_acc: 0.2999
Step: 15687, loss: 3.159263, norm: 0.2779, time(ms): 805.30, token/sec:651047.78, hellaswag_acc: 0.2999
Step: 15688, loss: 3.077793, norm: 0.2641, time(ms): 800.02, token/sec:655340.31, hellaswag_acc: 0.2999
Step: 15689, loss: 3.089934, norm: 0.2978, time(ms): 791.10, token/sec:662733.68, hellaswag_acc: 0.2999
Step: 15690, loss: 3.138110, norm: 0.2843, time(ms): 800.96, token/sec:654575.63, hellaswag_acc: 0.2999
Step: 15691, loss: 3.063847, norm: 0.2742, time(ms): 804.53, token/sec:651671.73, hellaswag_acc: 0.2999
Step: 15692, loss: 3.133213, norm: 0.2972, time(ms): 803.38, token/sec:652604.10, hellaswag_acc: 0.2999
Step: 15693, loss: 3.053009, norm: 0.2661, time(ms): 791.55, token/sec:662356.60, hellaswag_acc: 0.2999
Step: 15694, loss: 3.057933, norm: 0.3103, time(ms): 805.41, token/sec:650958.93, hellaswag_acc: 0.2999
Step: 15695, loss: 3.110813, norm: 0.2916, time(ms): 793.93, token/sec:660369.72, hellaswag_acc: 0.2999
Step: 15696, loss: 3.097675, norm: 0.3015, time(ms): 806.00, token/sec:650480.43, hellaswag_acc: 0.2999
Step: 15697, loss: 3.075193, norm: 0.2989, time(ms): 800.94, token/sec:654587.32, hellaswag_acc: 0.2999
Step: 15698, loss: 3.151191, norm: 0.3040, time(ms): 793.62, token/sec:660630.80, hellaswag_acc: 0.2999
Step: 15699, loss: 3.019145, norm: 0.3145, time(ms): 802.70, token/sec:653158.67, hellaswag_acc: 0.2999
Step: 15700, loss: 3.087828, norm: 0.2991, time(ms): 802.99, token/sec:652917.61, hellaswag_acc: 0.2999
Step: 15701, loss: 3.080758, norm: 0.2943, time(ms): 799.48, token/sec:655785.12, hellaswag_acc: 0.2999
Step: 15702, loss: 3.171128, norm: 0.3080, time(ms): 798.12, token/sec:656906.45, hellaswag_acc: 0.2999
Step: 15703, loss: 3.093157, norm: 0.3114, time(ms): 800.68, token/sec:654802.51, hellaswag_acc: 0.2999
Step: 15704, loss: 3.055686, norm: 0.3180, time(ms): 795.57, token/sec:659008.56, hellaswag_acc: 0.2999
Step: 15705, loss: 3.089506, norm: 0.3532, time(ms): 803.35, token/sec:652628.70, hellaswag_acc: 0.2999
Step: 15706, loss: 3.075872, norm: 0.2912, time(ms): 802.43, token/sec:653371.95, hellaswag_acc: 0.2999
Step: 15707, loss: 3.131484, norm: 0.3480, time(ms): 794.98, token/sec:659501.87, hellaswag_acc: 0.2999
Step: 15708, loss: 3.147699, norm: 0.2852, time(ms): 797.24, token/sec:657632.93, hellaswag_acc: 0.2999
Step: 15709, loss: 3.129889, norm: 0.3133, time(ms): 806.82, token/sec:649823.04, hellaswag_acc: 0.2999
Step: 15710, loss: 3.116045, norm: 0.2999, time(ms): 801.30, token/sec:654296.92, hellaswag_acc: 0.2999
Step: 15711, loss: 3.112162, norm: 0.2832, time(ms): 785.73, token/sec:667265.83, hellaswag_acc: 0.2999
Step: 15712, loss: 3.123258, norm: 0.3082, time(ms): 790.70, token/sec:663064.20, hellaswag_acc: 0.2999
Step: 15713, loss: 3.118290, norm: 0.2808, time(ms): 796.42, token/sec:658309.39, hellaswag_acc: 0.2999
Step: 15714, loss: 3.085935, norm: 0.2995, time(ms): 791.01, token/sec:662805.19, hellaswag_acc: 0.2999
Step: 15715, loss: 3.167501, norm: 0.3204, time(ms): 793.41, token/sec:660805.70, hellaswag_acc: 0.2999
Step: 15716, loss: 3.060488, norm: 0.3254, time(ms): 795.40, token/sec:659148.81, hellaswag_acc: 0.2999
Step: 15717, loss: 3.065245, norm: 0.3436, time(ms): 802.17, token/sec:653587.11, hellaswag_acc: 0.2999
Step: 15718, loss: 3.081940, norm: 0.2912, time(ms): 801.34, token/sec:654265.00, hellaswag_acc: 0.2999
Step: 15719, loss: 3.090983, norm: 0.3298, time(ms): 793.51, token/sec:660720.12, hellaswag_acc: 0.2999
Step: 15720, loss: 3.088754, norm: 0.2916, time(ms): 799.14, token/sec:656064.51, hellaswag_acc: 0.2999
Step: 15721, loss: 3.056385, norm: 0.3057, time(ms): 798.14, token/sec:656890.36, hellaswag_acc: 0.2999
Step: 15722, loss: 3.094144, norm: 0.2977, time(ms): 791.82, token/sec:662132.83, hellaswag_acc: 0.2999
Step: 15723, loss: 3.120498, norm: 0.2993, time(ms): 789.73, token/sec:663879.93, hellaswag_acc: 0.2999
Step: 15724, loss: 3.048833, norm: 0.3081, time(ms): 797.56, token/sec:657360.86, hellaswag_acc: 0.2999
Step: 15725, loss: 3.081856, norm: 0.2784, time(ms): 789.28, token/sec:664260.15, hellaswag_acc: 0.2999
Step: 15726, loss: 3.068104, norm: 0.2628, time(ms): 792.27, token/sec:661754.84, hellaswag_acc: 0.2999
Step: 15727, loss: 3.122771, norm: 0.2926, time(ms): 792.11, token/sec:661889.09, hellaswag_acc: 0.2999
Step: 15728, loss: 3.097814, norm: 0.2946, time(ms): 796.15, token/sec:658530.97, hellaswag_acc: 0.2999
Step: 15729, loss: 3.120800, norm: 0.2854, time(ms): 797.10, token/sec:657747.61, hellaswag_acc: 0.2999
Step: 15730, loss: 3.080691, norm: 0.2858, time(ms): 800.76, token/sec:654736.41, hellaswag_acc: 0.2999
Step: 15731, loss: 3.075768, norm: 0.3016, time(ms): 794.98, token/sec:659494.95, hellaswag_acc: 0.2999
Step: 15732, loss: 3.125523, norm: 0.2956, time(ms): 804.13, token/sec:651991.31, hellaswag_acc: 0.2999
Step: 15733, loss: 3.134932, norm: 0.4063, time(ms): 803.01, token/sec:652905.59, hellaswag_acc: 0.2999
Step: 15734, loss: 3.082870, norm: 0.2843, time(ms): 790.12, token/sec:663556.00, hellaswag_acc: 0.2999
Step: 15735, loss: 3.121345, norm: 0.3289, time(ms): 797.61, token/sec:657321.56, hellaswag_acc: 0.2999
Step: 15736, loss: 3.049047, norm: 0.3020, time(ms): 790.44, token/sec:663289.00, hellaswag_acc: 0.2999
Step: 15737, loss: 3.065923, norm: 0.3050, time(ms): 791.37, token/sec:662503.47, hellaswag_acc: 0.2999
Step: 15738, loss: 3.170276, norm: 0.2910, time(ms): 791.24, token/sec:662612.27, hellaswag_acc: 0.2999
Step: 15739, loss: 3.109451, norm: 0.3485, time(ms): 790.22, token/sec:663469.11, hellaswag_acc: 0.2999
Step: 15740, loss: 3.110363, norm: 0.2905, time(ms): 803.27, token/sec:652694.17, hellaswag_acc: 0.2999
Step: 15741, loss: 3.099632, norm: 0.2868, time(ms): 803.49, token/sec:652515.21, hellaswag_acc: 0.2999
Step: 15742, loss: 3.075469, norm: 0.3101, time(ms): 792.42, token/sec:661628.41, hellaswag_acc: 0.2999
Step: 15743, loss: 3.076022, norm: 0.2736, time(ms): 798.00, token/sec:657000.66, hellaswag_acc: 0.2999
Step: 15744, loss: 3.091894, norm: 0.2957, time(ms): 798.80, token/sec:656347.27, hellaswag_acc: 0.2999
Step: 15745, loss: 3.191875, norm: 0.3464, time(ms): 791.49, token/sec:662407.48, hellaswag_acc: 0.2999
Step: 15746, loss: 3.107657, norm: 0.3269, time(ms): 793.25, token/sec:660935.59, hellaswag_acc: 0.2999
Step: 15747, loss: 3.096025, norm: 0.3094, time(ms): 792.53, token/sec:661533.07, hellaswag_acc: 0.2999
Step: 15748, loss: 3.128076, norm: 0.2849, time(ms): 790.70, token/sec:663068.60, hellaswag_acc: 0.2999
Step: 15749, loss: 3.089176, norm: 0.3166, time(ms): 793.30, token/sec:660894.87, hellaswag_acc: 0.2999
rank 0 sample 0: Hello, I'm a language model, so I'd like you to have that look into how your computer performs this sort of problem. But you need to make
rank 0 sample 1: Hello, I'm a language model, and like learning a language, there's a certain process behind learning and working that I need to understand if I want to
rank 0 sample 2: Hello, I'm a language model, and I wrote the module named SaaS:
SaaS is a module of the SaaS library,
rank 0 sample 3: Hello, I'm a language model, you probably know the basics of Java and I see this as a little bit confusing when you learn it.
How long
rank 1 sample 0: Hello, I'm a language model, or more precisely, a language model like Python! This is so because we cannot use any programming language in order to create
rank 1 sample 1: Hello, I'm a language model, not an algorithm. I'm not even getting into the "language" of my new students, if I can't figure
rank 1 sample 2: Hello, I'm a language model, I must say "I'm a language model, I can express the meaning of the language." In my opinion that is
rank 1 sample 3: Hello, I'm a language model, so I'm working with machine learning with code.
Why use GIM:
Here's what I'm working with
Step: 15750, loss: 3.116756, norm: 0.2924, time(ms): 3840.16, token/sec:136527.63, val_loss: 3.0936, hellaswag_acc: 0.2999
Step: 15751, loss: 3.102883, norm: 0.2906, time(ms): 795.26, token/sec:659266.59, hellaswag_acc: 0.2999
Step: 15752, loss: 3.062521, norm: 0.2794, time(ms): 788.51, token/sec:664912.11, hellaswag_acc: 0.2999
Step: 15753, loss: 3.098810, norm: 0.2728, time(ms): 795.20, token/sec:659316.60, hellaswag_acc: 0.2999
Step: 15754, loss: 3.085097, norm: 0.2889, time(ms): 794.39, token/sec:659989.98, hellaswag_acc: 0.2999
Step: 15755, loss: 3.098712, norm: 0.2651, time(ms): 790.38, token/sec:663340.42, hellaswag_acc: 0.2999
Step: 15756, loss: 3.088460, norm: 0.2720, time(ms): 789.07, token/sec:664433.96, hellaswag_acc: 0.2999
Step: 15757, loss: 3.107722, norm: 0.2873, time(ms): 790.01, token/sec:663647.52, hellaswag_acc: 0.2999
Step: 15758, loss: 3.155500, norm: 0.2692, time(ms): 803.19, token/sec:652761.01, hellaswag_acc: 0.2999
Step: 15759, loss: 3.092260, norm: 0.2678, time(ms): 793.73, token/sec:660534.56, hellaswag_acc: 0.2999
Step: 15760, loss: 3.111876, norm: 0.2741, time(ms): 804.58, token/sec:651625.39, hellaswag_acc: 0.2999
Step: 15761, loss: 3.070553, norm: 0.2710, time(ms): 801.14, token/sec:654426.80, hellaswag_acc: 0.2999
Step: 15762, loss: 3.064291, norm: 0.2647, time(ms): 790.46, token/sec:663267.00, hellaswag_acc: 0.2999
Step: 15763, loss: 3.116966, norm: 0.3162, time(ms): 798.07, token/sec:656940.99, hellaswag_acc: 0.2999
Step: 15764, loss: 3.089788, norm: 0.2859, time(ms): 790.30, token/sec:663405.06, hellaswag_acc: 0.2999
Step: 15765, loss: 3.008746, norm: 0.3116, time(ms): 790.61, token/sec:663144.79, hellaswag_acc: 0.2999
Step: 15766, loss: 3.151077, norm: 0.3497, time(ms): 789.79, token/sec:663830.43, hellaswag_acc: 0.2999
Step: 15767, loss: 3.150794, norm: 0.3108, time(ms): 793.90, token/sec:660398.88, hellaswag_acc: 0.2999
Step: 15768, loss: 3.103243, norm: 0.3347, time(ms): 802.20, token/sec:653560.31, hellaswag_acc: 0.2999
Step: 15769, loss: 3.110466, norm: 0.4334, time(ms): 802.46, token/sec:653347.88, hellaswag_acc: 0.2999
Step: 15770, loss: 3.088652, norm: 0.3293, time(ms): 798.67, token/sec:656449.54, hellaswag_acc: 0.2999
Step: 15771, loss: 3.150053, norm: 0.3706, time(ms): 798.19, token/sec:656845.04, hellaswag_acc: 0.2999
Step: 15772, loss: 3.111842, norm: 0.3126, time(ms): 800.05, token/sec:655315.51, hellaswag_acc: 0.2999
Step: 15773, loss: 3.059219, norm: 0.3049, time(ms): 802.66, token/sec:653184.08, hellaswag_acc: 0.2999
Step: 15774, loss: 3.113729, norm: 0.3208, time(ms): 794.28, token/sec:660081.71, hellaswag_acc: 0.2999
Step: 15775, loss: 3.148887, norm: 0.3382, time(ms): 797.23, token/sec:657635.69, hellaswag_acc: 0.2999
Step: 15776, loss: 3.193069, norm: 0.3259, time(ms): 791.79, token/sec:662158.75, hellaswag_acc: 0.2999
Step: 15777, loss: 3.047482, norm: 0.2964, time(ms): 793.19, token/sec:660987.44, hellaswag_acc: 0.2999
Step: 15778, loss: 3.061245, norm: 0.3032, time(ms): 796.30, token/sec:658404.98, hellaswag_acc: 0.2999
Step: 15779, loss: 3.112755, norm: 0.2992, time(ms): 792.37, token/sec:661669.02, hellaswag_acc: 0.2999
Step: 15780, loss: 3.110871, norm: 0.3066, time(ms): 790.65, token/sec:663107.39, hellaswag_acc: 0.2999
Step: 15781, loss: 3.071704, norm: 0.3209, time(ms): 793.80, token/sec:660479.21, hellaswag_acc: 0.2999
Step: 15782, loss: 3.092802, norm: 0.3044, time(ms): 790.52, token/sec:663222.39, hellaswag_acc: 0.2999
Step: 15783, loss: 3.075240, norm: 0.2930, time(ms): 796.43, token/sec:658297.56, hellaswag_acc: 0.2999
Step: 15784, loss: 3.104225, norm: 0.2901, time(ms): 795.27, token/sec:659254.93, hellaswag_acc: 0.2999
Step: 15785, loss: 3.022061, norm: 0.3003, time(ms): 806.26, token/sec:650272.11, hellaswag_acc: 0.2999
Step: 15786, loss: 3.024729, norm: 0.2937, time(ms): 798.35, token/sec:656712.43, hellaswag_acc: 0.2999
Step: 15787, loss: 3.031381, norm: 0.2738, time(ms): 791.74, token/sec:662194.24, hellaswag_acc: 0.2999
Step: 15788, loss: 3.057297, norm: 0.2823, time(ms): 791.18, token/sec:662668.38, hellaswag_acc: 0.2999
Step: 15789, loss: 3.099113, norm: 0.2884, time(ms): 790.48, token/sec:663250.59, hellaswag_acc: 0.2999
Step: 15790, loss: 3.005157, norm: 0.2875, time(ms): 790.28, token/sec:663421.47, hellaswag_acc: 0.2999
Step: 15791, loss: 3.094402, norm: 0.2669, time(ms): 791.20, token/sec:662648.81, hellaswag_acc: 0.2999
Step: 15792, loss: 3.081758, norm: 0.2685, time(ms): 800.31, token/sec:655104.86, hellaswag_acc: 0.2999
Step: 15793, loss: 3.072821, norm: 0.2591, time(ms): 805.33, token/sec:651025.23, hellaswag_acc: 0.2999
Step: 15794, loss: 3.018968, norm: 0.2714, time(ms): 795.75, token/sec:658857.12, hellaswag_acc: 0.2999
Step: 15795, loss: 3.061543, norm: 0.3029, time(ms): 795.27, token/sec:659256.11, hellaswag_acc: 0.2999
Step: 15796, loss: 3.079698, norm: 0.2688, time(ms): 793.06, token/sec:661092.36, hellaswag_acc: 0.2999
Step: 15797, loss: 3.129000, norm: 0.3174, time(ms): 796.01, token/sec:658641.03, hellaswag_acc: 0.2999
Step: 15798, loss: 3.092423, norm: 0.3011, time(ms): 795.06, token/sec:659431.07, hellaswag_acc: 0.2999
Step: 15799, loss: 3.100786, norm: 0.2966, time(ms): 802.30, token/sec:653484.76, hellaswag_acc: 0.2999
Step: 15800, loss: 3.096313, norm: 0.2962, time(ms): 799.13, token/sec:656074.68, hellaswag_acc: 0.2999
Step: 15801, loss: 3.106440, norm: 0.3082, time(ms): 797.36, token/sec:657531.07, hellaswag_acc: 0.2999
Step: 15802, loss: 3.105423, norm: 0.2672, time(ms): 798.66, token/sec:656461.10, hellaswag_acc: 0.2999
Step: 15803, loss: 3.069726, norm: 0.2938, time(ms): 797.17, token/sec:657684.86, hellaswag_acc: 0.2999
Step: 15804, loss: 3.187263, norm: 0.2791, time(ms): 789.86, token/sec:663773.52, hellaswag_acc: 0.2999
Step: 15805, loss: 3.123956, norm: 0.2903, time(ms): 785.27, token/sec:667651.77, hellaswag_acc: 0.2999
Step: 15806, loss: 3.050482, norm: 0.2787, time(ms): 791.07, token/sec:662758.65, hellaswag_acc: 0.2999
Step: 15807, loss: 3.058219, norm: 0.2709, time(ms): 801.24, token/sec:654345.60, hellaswag_acc: 0.2999
Step: 15808, loss: 3.093718, norm: 0.2932, time(ms): 796.49, token/sec:658251.25, hellaswag_acc: 0.2999
Step: 15809, loss: 3.104489, norm: 0.2922, time(ms): 801.95, token/sec:653763.74, hellaswag_acc: 0.2999
Step: 15810, loss: 3.092761, norm: 0.3016, time(ms): 801.59, token/sec:654063.20, hellaswag_acc: 0.2999
Step: 15811, loss: 3.134983, norm: 0.2734, time(ms): 1301.08, token/sec:402964.80, hellaswag_acc: 0.2999
Step: 15812, loss: 3.113682, norm: 0.2957, time(ms): 788.23, token/sec:665142.39, hellaswag_acc: 0.2999
Step: 15813, loss: 3.055284, norm: 0.2964, time(ms): 786.01, token/sec:667021.33, hellaswag_acc: 0.2999
Step: 15814, loss: 2.956333, norm: 0.2759, time(ms): 789.91, token/sec:663733.05, hellaswag_acc: 0.2999
Step: 15815, loss: 3.031605, norm: 0.2916, time(ms): 786.45, token/sec:666654.11, hellaswag_acc: 0.2999
Step: 15816, loss: 2.994324, norm: 0.2772, time(ms): 806.49, token/sec:650086.22, hellaswag_acc: 0.2999
Step: 15817, loss: 2.952224, norm: 0.2805, time(ms): 792.61, token/sec:661472.18, hellaswag_acc: 0.2999
Step: 15818, loss: 3.031969, norm: 0.2794, time(ms): 790.88, token/sec:662916.89, hellaswag_acc: 0.2999
Step: 15819, loss: 2.974187, norm: 0.2952, time(ms): 789.56, token/sec:664024.86, hellaswag_acc: 0.2999
Step: 15820, loss: 2.965932, norm: 0.2899, time(ms): 803.22, token/sec:652734.66, hellaswag_acc: 0.2999
Step: 15821, loss: 3.014632, norm: 0.2727, time(ms): 804.10, token/sec:652021.86, hellaswag_acc: 0.2999
Step: 15822, loss: 2.974642, norm: 0.2852, time(ms): 791.59, token/sec:662318.90, hellaswag_acc: 0.2999
Step: 15823, loss: 2.960489, norm: 0.2631, time(ms): 791.58, token/sec:662326.88, hellaswag_acc: 0.2999
Step: 15824, loss: 3.035323, norm: 0.3059, time(ms): 785.54, token/sec:667419.75, hellaswag_acc: 0.2999
Step: 15825, loss: 3.064159, norm: 0.3337, time(ms): 792.49, token/sec:661567.30, hellaswag_acc: 0.2999
Step: 15826, loss: 3.042917, norm: 0.2785, time(ms): 797.71, token/sec:657242.38, hellaswag_acc: 0.2999
Step: 15827, loss: 3.073400, norm: 0.3034, time(ms): 790.01, token/sec:663650.32, hellaswag_acc: 0.2999
Step: 15828, loss: 3.129044, norm: 0.3070, time(ms): 791.56, token/sec:662346.43, hellaswag_acc: 0.2999
Step: 15829, loss: 3.061873, norm: 0.3013, time(ms): 795.73, token/sec:658880.02, hellaswag_acc: 0.2999
Step: 15830, loss: 3.112110, norm: 0.2939, time(ms): 790.60, token/sec:663149.99, hellaswag_acc: 0.2999
Step: 15831, loss: 3.084814, norm: 0.2797, time(ms): 789.00, token/sec:664496.40, hellaswag_acc: 0.2999
Step: 15832, loss: 3.068627, norm: 0.2924, time(ms): 800.04, token/sec:655330.74, hellaswag_acc: 0.2999
Step: 15833, loss: 3.057149, norm: 0.2802, time(ms): 801.22, token/sec:654364.48, hellaswag_acc: 0.2999
Step: 15834, loss: 3.091166, norm: 0.2835, time(ms): 791.61, token/sec:662305.53, hellaswag_acc: 0.2999
Step: 15835, loss: 3.078751, norm: 0.2881, time(ms): 790.62, token/sec:663132.79, hellaswag_acc: 0.2999
Step: 15836, loss: 3.152032, norm: 0.2963, time(ms): 795.11, token/sec:659391.33, hellaswag_acc: 0.2999
Step: 15837, loss: 3.157551, norm: 0.2855, time(ms): 799.74, token/sec:655572.22, hellaswag_acc: 0.2999
Step: 15838, loss: 3.113893, norm: 0.3081, time(ms): 797.77, token/sec:657187.98, hellaswag_acc: 0.2999
Step: 15839, loss: 3.052272, norm: 0.2854, time(ms): 797.88, token/sec:657100.98, hellaswag_acc: 0.2999
Step: 15840, loss: 3.142348, norm: 0.2832, time(ms): 797.59, token/sec:657338.06, hellaswag_acc: 0.2999
Step: 15841, loss: 3.072837, norm: 0.2748, time(ms): 789.52, token/sec:664062.36, hellaswag_acc: 0.2999
Step: 15842, loss: 3.106236, norm: 0.2873, time(ms): 791.20, token/sec:662650.40, hellaswag_acc: 0.2999
Step: 15843, loss: 3.104435, norm: 0.2850, time(ms): 795.23, token/sec:659289.71, hellaswag_acc: 0.2999
Step: 15844, loss: 3.114897, norm: 0.3186, time(ms): 792.46, token/sec:661591.79, hellaswag_acc: 0.2999
Step: 15845, loss: 3.114403, norm: 0.2775, time(ms): 795.12, token/sec:659378.67, hellaswag_acc: 0.2999
Step: 15846, loss: 3.108903, norm: 0.2841, time(ms): 804.26, token/sec:651892.35, hellaswag_acc: 0.2999
Step: 15847, loss: 3.074146, norm: 0.2796, time(ms): 800.46, token/sec:654984.67, hellaswag_acc: 0.2999
Step: 15848, loss: 3.060710, norm: 0.2713, time(ms): 792.94, token/sec:661198.91, hellaswag_acc: 0.2999
Step: 15849, loss: 3.125348, norm: 0.2744, time(ms): 804.72, token/sec:651514.19, hellaswag_acc: 0.2999
Step: 15850, loss: 3.076226, norm: 0.2903, time(ms): 802.59, token/sec:653243.27, hellaswag_acc: 0.2999
Step: 15851, loss: 3.065780, norm: 0.2743, time(ms): 788.79, token/sec:664673.35, hellaswag_acc: 0.2999
Step: 15852, loss: 3.107413, norm: 0.2899, time(ms): 790.50, token/sec:663233.19, hellaswag_acc: 0.2999
Step: 15853, loss: 3.134386, norm: 0.3105, time(ms): 792.31, token/sec:661724.77, hellaswag_acc: 0.2999
Step: 15854, loss: 3.085055, norm: 0.2868, time(ms): 796.17, token/sec:658510.27, hellaswag_acc: 0.2999
Step: 15855, loss: 3.048839, norm: 0.2858, time(ms): 791.60, token/sec:662315.71, hellaswag_acc: 0.2999
Step: 15856, loss: 3.033728, norm: 0.2692, time(ms): 793.23, token/sec:660954.66, hellaswag_acc: 0.2999
Step: 15857, loss: 3.066986, norm: 0.2737, time(ms): 802.52, token/sec:653302.07, hellaswag_acc: 0.2999
Step: 15858, loss: 3.112570, norm: 0.2745, time(ms): 803.05, token/sec:652870.90, hellaswag_acc: 0.2999
Step: 15859, loss: 3.027972, norm: 0.2713, time(ms): 799.74, token/sec:655575.74, hellaswag_acc: 0.2999
Step: 15860, loss: 2.995023, norm: 0.2853, time(ms): 789.64, token/sec:663961.11, hellaswag_acc: 0.2999
Step: 15861, loss: 2.932321, norm: 0.2863, time(ms): 792.96, token/sec:661182.01, hellaswag_acc: 0.2999
Step: 15862, loss: 2.975266, norm: 0.2906, time(ms): 796.13, token/sec:658547.34, hellaswag_acc: 0.2999
Step: 15863, loss: 3.036186, norm: 0.3061, time(ms): 797.33, token/sec:657557.42, hellaswag_acc: 0.2999
Step: 15864, loss: 2.987999, norm: 0.2790, time(ms): 797.42, token/sec:657484.29, hellaswag_acc: 0.2999
Step: 15865, loss: 2.983849, norm: 0.2882, time(ms): 797.90, token/sec:657082.33, hellaswag_acc: 0.2999
Step: 15866, loss: 2.998297, norm: 0.2846, time(ms): 796.39, token/sec:658327.91, hellaswag_acc: 0.2999
Step: 15867, loss: 2.937445, norm: 0.2910, time(ms): 791.55, token/sec:662352.21, hellaswag_acc: 0.2999
Step: 15868, loss: 3.025953, norm: 0.2930, time(ms): 789.47, token/sec:664102.47, hellaswag_acc: 0.2999
Step: 15869, loss: 3.011779, norm: 0.2792, time(ms): 791.22, token/sec:662628.24, hellaswag_acc: 0.2999
Step: 15870, loss: 3.014207, norm: 0.2826, time(ms): 796.53, token/sec:658213.23, hellaswag_acc: 0.2999
Step: 15871, loss: 2.958556, norm: 0.2784, time(ms): 797.54, token/sec:657378.74, hellaswag_acc: 0.2999
Step: 15872, loss: 3.008121, norm: 0.2949, time(ms): 801.21, token/sec:654369.55, hellaswag_acc: 0.2999
Step: 15873, loss: 3.117762, norm: 0.3080, time(ms): 801.91, token/sec:653796.78, hellaswag_acc: 0.2999
Step: 15874, loss: 3.121537, norm: 0.2914, time(ms): 795.59, token/sec:658993.35, hellaswag_acc: 0.2999
Step: 15875, loss: 3.122518, norm: 0.2973, time(ms): 796.29, token/sec:658414.05, hellaswag_acc: 0.2999
Step: 15876, loss: 3.049839, norm: 0.2984, time(ms): 806.53, token/sec:650055.28, hellaswag_acc: 0.2999
Step: 15877, loss: 3.115536, norm: 0.3001, time(ms): 802.10, token/sec:653645.59, hellaswag_acc: 0.2999
Step: 15878, loss: 3.079435, norm: 0.3067, time(ms): 791.57, token/sec:662335.85, hellaswag_acc: 0.2999
Step: 15879, loss: 3.169741, norm: 0.3351, time(ms): 801.81, token/sec:653879.41, hellaswag_acc: 0.2999
Step: 15880, loss: 3.037773, norm: 0.3032, time(ms): 806.32, token/sec:650220.58, hellaswag_acc: 0.2999
Step: 15881, loss: 3.111719, norm: 0.3162, time(ms): 795.22, token/sec:659302.96, hellaswag_acc: 0.2999
Step: 15882, loss: 3.083444, norm: 0.2947, time(ms): 800.17, token/sec:655218.27, hellaswag_acc: 0.2999
Step: 15883, loss: 3.107240, norm: 0.3054, time(ms): 796.74, token/sec:658044.03, hellaswag_acc: 0.2999
Step: 15884, loss: 3.066501, norm: 0.3305, time(ms): 804.05, token/sec:652057.24, hellaswag_acc: 0.2999
Step: 15885, loss: 3.085670, norm: 0.3037, time(ms): 803.06, token/sec:652860.04, hellaswag_acc: 0.2999
Step: 15886, loss: 3.098404, norm: 0.3046, time(ms): 790.60, token/sec:663150.59, hellaswag_acc: 0.2999
Step: 15887, loss: 3.133582, norm: 0.3037, time(ms): 804.75, token/sec:651494.50, hellaswag_acc: 0.2999
Step: 15888, loss: 3.117754, norm: 0.3041, time(ms): 802.75, token/sec:653118.90, hellaswag_acc: 0.2999
Step: 15889, loss: 3.098990, norm: 0.3013, time(ms): 799.13, token/sec:656075.86, hellaswag_acc: 0.2999
Step: 15890, loss: 3.103328, norm: 0.2867, time(ms): 793.07, token/sec:661083.22, hellaswag_acc: 0.2999
Step: 15891, loss: 3.139390, norm: 0.2972, time(ms): 806.31, token/sec:650229.04, hellaswag_acc: 0.2999
Step: 15892, loss: 3.050576, norm: 0.2937, time(ms): 800.72, token/sec:654771.31, hellaswag_acc: 0.2999
Step: 15893, loss: 3.090154, norm: 0.2866, time(ms): 800.30, token/sec:655111.70, hellaswag_acc: 0.2999
Step: 15894, loss: 3.028941, norm: 0.3048, time(ms): 794.20, token/sec:660145.11, hellaswag_acc: 0.2999
Step: 15895, loss: 3.081303, norm: 0.3050, time(ms): 800.97, token/sec:654565.89, hellaswag_acc: 0.2999
Step: 15896, loss: 3.025734, norm: 0.2867, time(ms): 804.86, token/sec:651402.64, hellaswag_acc: 0.2999
Step: 15897, loss: 3.044215, norm: 0.2683, time(ms): 795.60, token/sec:658981.70, hellaswag_acc: 0.2999
Step: 15898, loss: 3.086363, norm: 0.2845, time(ms): 793.65, token/sec:660601.43, hellaswag_acc: 0.2999
Step: 15899, loss: 3.020934, norm: 0.2676, time(ms): 793.12, token/sec:661044.07, hellaswag_acc: 0.2999
Step: 15900, loss: 3.090271, norm: 0.2663, time(ms): 794.23, token/sec:660125.10, hellaswag_acc: 0.2999
Step: 15901, loss: 3.088646, norm: 0.2659, time(ms): 786.81, token/sec:666344.03, hellaswag_acc: 0.2999
Step: 15902, loss: 3.074313, norm: 0.2808, time(ms): 793.22, token/sec:660958.83, hellaswag_acc: 0.2999
Step: 15903, loss: 3.045582, norm: 0.2712, time(ms): 797.03, token/sec:657804.08, hellaswag_acc: 0.2999
Step: 15904, loss: 3.033155, norm: 0.2761, time(ms): 803.28, token/sec:652682.93, hellaswag_acc: 0.2999
Step: 15905, loss: 3.023199, norm: 0.2937, time(ms): 799.67, token/sec:655633.98, hellaswag_acc: 0.2999
Step: 15906, loss: 3.077898, norm: 0.2650, time(ms): 792.19, token/sec:661819.57, hellaswag_acc: 0.2999
Step: 15907, loss: 3.048274, norm: 0.2571, time(ms): 800.96, token/sec:654572.90, hellaswag_acc: 0.2999
Step: 15908, loss: 2.966485, norm: 0.2673, time(ms): 795.42, token/sec:659136.96, hellaswag_acc: 0.2999
Step: 15909, loss: 3.018247, norm: 0.2721, time(ms): 793.34, token/sec:660857.73, hellaswag_acc: 0.2999
Step: 15910, loss: 2.980142, norm: 0.2775, time(ms): 794.10, token/sec:660229.35, hellaswag_acc: 0.2999
Step: 15911, loss: 3.005286, norm: 0.2618, time(ms): 798.24, token/sec:656803.45, hellaswag_acc: 0.2999
Step: 15912, loss: 3.008782, norm: 0.2577, time(ms): 802.71, token/sec:653148.00, hellaswag_acc: 0.2999
Step: 15913, loss: 3.002433, norm: 0.2748, time(ms): 796.32, token/sec:658386.25, hellaswag_acc: 0.2999
Step: 15914, loss: 2.994287, norm: 0.2671, time(ms): 796.12, token/sec:658551.88, hellaswag_acc: 0.2999
Step: 15915, loss: 2.997078, norm: 0.2739, time(ms): 789.14, token/sec:664380.76, hellaswag_acc: 0.2999
Step: 15916, loss: 2.999646, norm: 0.2765, time(ms): 793.99, token/sec:660317.97, hellaswag_acc: 0.2999
Step: 15917, loss: 2.963157, norm: 0.2734, time(ms): 792.38, token/sec:661663.85, hellaswag_acc: 0.2999
Step: 15918, loss: 3.002128, norm: 0.2869, time(ms): 789.99, token/sec:663663.14, hellaswag_acc: 0.2999
Step: 15919, loss: 2.987592, norm: 0.2757, time(ms): 803.47, token/sec:652528.19, hellaswag_acc: 0.2999
Step: 15920, loss: 3.064594, norm: 0.3265, time(ms): 796.15, token/sec:658530.77, hellaswag_acc: 0.2999
Step: 15921, loss: 3.083510, norm: 0.3096, time(ms): 802.30, token/sec:653484.56, hellaswag_acc: 0.2999
Step: 15922, loss: 3.085479, norm: 0.3133, time(ms): 802.48, token/sec:653335.26, hellaswag_acc: 0.2999
Step: 15923, loss: 3.112204, norm: 0.2958, time(ms): 794.00, token/sec:660314.99, hellaswag_acc: 0.2999
Step: 15924, loss: 3.062371, norm: 0.2837, time(ms): 802.83, token/sec:653048.11, hellaswag_acc: 0.2999
Step: 15925, loss: 3.090943, norm: 0.3038, time(ms): 799.85, token/sec:655482.52, hellaswag_acc: 0.2999
Step: 15926, loss: 3.072957, norm: 0.3014, time(ms): 795.65, token/sec:658943.39, hellaswag_acc: 0.2999
Step: 15927, loss: 3.152611, norm: 0.2902, time(ms): 803.38, token/sec:652599.26, hellaswag_acc: 0.2999
Step: 15928, loss: 3.052515, norm: 0.3053, time(ms): 803.00, token/sec:652914.90, hellaswag_acc: 0.2999
Step: 15929, loss: 3.088296, norm: 0.2829, time(ms): 789.30, token/sec:664244.70, hellaswag_acc: 0.2999
Step: 15930, loss: 3.108027, norm: 0.3106, time(ms): 793.19, token/sec:660984.06, hellaswag_acc: 0.2999
Step: 15931, loss: 3.100830, norm: 0.2951, time(ms): 791.19, token/sec:662657.79, hellaswag_acc: 0.2999
Step: 15932, loss: 3.088104, norm: 0.2972, time(ms): 790.63, token/sec:663123.59, hellaswag_acc: 0.2999
Step: 15933, loss: 3.117769, norm: 0.2929, time(ms): 790.89, token/sec:662910.09, hellaswag_acc: 0.2999
Step: 15934, loss: 3.099352, norm: 0.2841, time(ms): 797.14, token/sec:657707.87, hellaswag_acc: 0.2999
Step: 15935, loss: 3.064391, norm: 0.2771, time(ms): 803.43, token/sec:652564.01, hellaswag_acc: 0.2999
Step: 15936, loss: 3.103488, norm: 0.3081, time(ms): 799.76, token/sec:655554.43, hellaswag_acc: 0.2999
Step: 15937, loss: 3.053732, norm: 0.2882, time(ms): 800.79, token/sec:654709.51, hellaswag_acc: 0.2999
Step: 15938, loss: 3.127090, norm: 0.2879, time(ms): 800.97, token/sec:654566.66, hellaswag_acc: 0.2999
Step: 15939, loss: 3.087025, norm: 0.2961, time(ms): 796.48, token/sec:658256.97, hellaswag_acc: 0.2999
Step: 15940, loss: 3.106738, norm: 0.2669, time(ms): 798.36, token/sec:656703.80, hellaswag_acc: 0.2999
Step: 15941, loss: 3.074587, norm: 0.2756, time(ms): 801.79, token/sec:653896.91, hellaswag_acc: 0.2999
Step: 15942, loss: 3.065386, norm: 0.2670, time(ms): 802.97, token/sec:652934.48, hellaswag_acc: 0.2999
Step: 15943, loss: 3.100250, norm: 0.2745, time(ms): 793.35, token/sec:660854.95, hellaswag_acc: 0.2999
Step: 15944, loss: 3.055100, norm: 0.2783, time(ms): 802.31, token/sec:653475.43, hellaswag_acc: 0.2999
Step: 15945, loss: 3.015768, norm: 0.2648, time(ms): 802.68, token/sec:653175.74, hellaswag_acc: 0.2999
Step: 15946, loss: 3.053184, norm: 0.2705, time(ms): 797.28, token/sec:657592.23, hellaswag_acc: 0.2999
Step: 15947, loss: 3.024554, norm: 0.2631, time(ms): 797.95, token/sec:657041.69, hellaswag_acc: 0.2999
Step: 15948, loss: 3.109361, norm: 0.2786, time(ms): 799.64, token/sec:655652.36, hellaswag_acc: 0.2999
Step: 15949, loss: 3.066262, norm: 0.2838, time(ms): 796.69, token/sec:658084.21, hellaswag_acc: 0.2999
Step: 15950, loss: 3.041530, norm: 0.2900, time(ms): 793.38, token/sec:660831.32, hellaswag_acc: 0.2999
Step: 15951, loss: 3.061880, norm: 0.2904, time(ms): 791.63, token/sec:662290.37, hellaswag_acc: 0.2999
Step: 15952, loss: 3.085210, norm: 0.2926, time(ms): 798.49, token/sec:656598.51, hellaswag_acc: 0.2999
Step: 15953, loss: 3.070520, norm: 0.2694, time(ms): 800.94, token/sec:654593.94, hellaswag_acc: 0.2999
Step: 15954, loss: 3.034843, norm: 0.2933, time(ms): 798.44, token/sec:656638.50, hellaswag_acc: 0.2999
Step: 15955, loss: 3.113430, norm: 0.2819, time(ms): 794.48, token/sec:659912.54, hellaswag_acc: 0.2999
Step: 15956, loss: 2.994562, norm: 0.2770, time(ms): 790.06, token/sec:663601.86, hellaswag_acc: 0.2999
Step: 15957, loss: 3.015018, norm: 0.2881, time(ms): 792.04, token/sec:661946.08, hellaswag_acc: 0.2999
Step: 15958, loss: 2.948747, norm: 0.2629, time(ms): 792.36, token/sec:661677.98, hellaswag_acc: 0.2999
Step: 15959, loss: 2.984259, norm: 0.2839, time(ms): 795.87, token/sec:658763.17, hellaswag_acc: 0.2999
Step: 15960, loss: 3.009606, norm: 0.2971, time(ms): 797.48, token/sec:657428.26, hellaswag_acc: 0.2999
Step: 15961, loss: 2.984125, norm: 0.2767, time(ms): 801.74, token/sec:653939.69, hellaswag_acc: 0.2999
Step: 15962, loss: 2.969470, norm: 0.2971, time(ms): 799.88, token/sec:655456.54, hellaswag_acc: 0.2999
Step: 15963, loss: 2.970665, norm: 0.2785, time(ms): 799.91, token/sec:655432.51, hellaswag_acc: 0.2999
Step: 15964, loss: 2.947658, norm: 0.2649, time(ms): 791.58, token/sec:662334.86, hellaswag_acc: 0.2999
Step: 15965, loss: 3.020554, norm: 0.2854, time(ms): 807.99, token/sec:648879.45, hellaswag_acc: 0.2999
Step: 15966, loss: 3.000654, norm: 0.2798, time(ms): 799.78, token/sec:655536.45, hellaswag_acc: 0.2999
Step: 15967, loss: 2.982378, norm: 0.3010, time(ms): 800.04, token/sec:655325.67, hellaswag_acc: 0.2999
Step: 15968, loss: 3.076861, norm: 0.3264, time(ms): 793.33, token/sec:660866.67, hellaswag_acc: 0.2999
Step: 15969, loss: 3.114164, norm: 0.3066, time(ms): 799.15, token/sec:656053.74, hellaswag_acc: 0.2999
Step: 15970, loss: 3.089746, norm: 0.3031, time(ms): 806.82, token/sec:649821.89, hellaswag_acc: 0.2999
Step: 15971, loss: 3.091023, norm: 0.2831, time(ms): 798.43, token/sec:656646.74, hellaswag_acc: 0.2999
Step: 15972, loss: 3.126544, norm: 0.2895, time(ms): 790.53, token/sec:663210.59, hellaswag_acc: 0.2999
Step: 15973, loss: 3.061623, norm: 0.3386, time(ms): 792.49, token/sec:661573.87, hellaswag_acc: 0.2999
Step: 15974, loss: 3.073427, norm: 0.2820, time(ms): 792.69, token/sec:661406.73, hellaswag_acc: 0.2999
Step: 15975, loss: 3.114215, norm: 0.3019, time(ms): 795.82, token/sec:658798.69, hellaswag_acc: 0.2999
Step: 15976, loss: 3.131565, norm: 0.2947, time(ms): 790.44, token/sec:663288.60, hellaswag_acc: 0.2999
Step: 15977, loss: 3.159634, norm: 0.3037, time(ms): 790.52, token/sec:663221.19, hellaswag_acc: 0.2999
Step: 15978, loss: 3.052720, norm: 0.2759, time(ms): 803.50, token/sec:652503.60, hellaswag_acc: 0.2999
Step: 15979, loss: 3.064224, norm: 0.3050, time(ms): 804.00, token/sec:652099.20, hellaswag_acc: 0.2999
Step: 15980, loss: 3.100126, norm: 0.3273, time(ms): 798.57, token/sec:656532.05, hellaswag_acc: 0.2999
Step: 15981, loss: 3.073916, norm: 0.2885, time(ms): 792.14, token/sec:661866.18, hellaswag_acc: 0.2999
Step: 15982, loss: 3.098102, norm: 0.2940, time(ms): 805.56, token/sec:650837.75, hellaswag_acc: 0.2999
Step: 15983, loss: 3.106550, norm: 0.2816, time(ms): 802.60, token/sec:653235.89, hellaswag_acc: 0.2999
Step: 15984, loss: 3.140384, norm: 0.2827, time(ms): 791.00, token/sec:662815.18, hellaswag_acc: 0.2999
Step: 15985, loss: 3.118443, norm: 0.2994, time(ms): 792.84, token/sec:661281.22, hellaswag_acc: 0.2999
Step: 15986, loss: 3.098027, norm: 0.2753, time(ms): 792.45, token/sec:661602.73, hellaswag_acc: 0.2999
Step: 15987, loss: 3.130771, norm: 0.2895, time(ms): 802.70, token/sec:653151.88, hellaswag_acc: 0.2999
Step: 15988, loss: 3.047419, norm: 0.2950, time(ms): 793.47, token/sec:660756.85, hellaswag_acc: 0.2999
Step: 15989, loss: 3.035913, norm: 0.2856, time(ms): 801.37, token/sec:654236.97, hellaswag_acc: 0.2999
Step: 15990, loss: 3.088164, norm: 0.2742, time(ms): 801.23, token/sec:654355.14, hellaswag_acc: 0.2999
Step: 15991, loss: 3.055396, norm: 0.2793, time(ms): 798.03, token/sec:656975.34, hellaswag_acc: 0.2999
Step: 15992, loss: 3.040851, norm: 0.2862, time(ms): 795.22, token/sec:659297.03, hellaswag_acc: 0.2999
Step: 15993, loss: 3.032638, norm: 0.2646, time(ms): 789.74, token/sec:663878.32, hellaswag_acc: 0.2999
Step: 15994, loss: 3.100870, norm: 0.2768, time(ms): 789.82, token/sec:663804.18, hellaswag_acc: 0.2999
Step: 15995, loss: 3.048042, norm: 0.2985, time(ms): 791.00, token/sec:662814.18, hellaswag_acc: 0.2999
Step: 15996, loss: 3.067352, norm: 0.2811, time(ms): 799.46, token/sec:655799.98, hellaswag_acc: 0.2999
Step: 15997, loss: 3.060109, norm: 0.2766, time(ms): 796.24, token/sec:658457.03, hellaswag_acc: 0.2999
Step: 15998, loss: 3.031533, norm: 0.2749, time(ms): 800.45, token/sec:654994.81, hellaswag_acc: 0.2999
Step: 15999, loss: 3.047923, norm: 0.2906, time(ms): 799.47, token/sec:655790.40, hellaswag_acc: 0.2999
rank 0 sample 0: Hello, I'm a language model, and I understand that it's the one who wants to translate it so that people can communicate with other language, and the
rank 0 sample 1: Hello, I'm a language model, so here's a simple example, showing how the object code works. But it's also possible that something in the program
rank 0 sample 2: Hello, I'm a language model, so I won't want to explain what I'd like to teach to students. I am not a language model. For
rank 0 sample 3: Hello, I'm a language model, so please add some of these in a separate write-up.
You'll get your message here via email:email
rank 1 sample 0: Hello, I'm a language model, an assistant at the company, and currently a project at the center of the business. In addition, I've been working
rank 1 sample 1: Hello, I'm a language model, not an application; I'm a software writer. I just wrote out a simple one thing that says "Hello, I
rank 1 sample 2: Hello, I'm a language model, I actually know this, but I'm not sure how. My first thought is, "what would I say in the
rank 1 sample 3: Hello, I'm a language model, and I'm working with another language model—I'm modeling C++. Since I like math, I'm doing it
Step: 16000, loss: 3.017244, norm: 0.2639, time(ms): 363911.37, token/sec:1440.70, val_loss: 3.0895, hellaswag_acc: 0.3013
Step: 16001, loss: 3.050249, norm: 0.2840, time(ms): 1419.89, token/sec:369244.90, hellaswag_acc: 0.3013
Step: 16002, loss: 2.979108, norm: 0.3027, time(ms): 771.22, token/sec:679814.11, hellaswag_acc: 0.3013
Step: 16003, loss: 2.895412, norm: 0.2964, time(ms): 787.20, token/sec:666014.26, hellaswag_acc: 0.3013
Step: 16004, loss: 2.951388, norm: 0.3120, time(ms): 795.36, token/sec:659183.39, hellaswag_acc: 0.3013
Step: 16005, loss: 2.895724, norm: 0.2819, time(ms): 787.95, token/sec:665384.91, hellaswag_acc: 0.3013
Step: 16006, loss: 2.901613, norm: 0.2904, time(ms): 781.10, token/sec:671215.23, hellaswag_acc: 0.3013
Step: 16007, loss: 2.892649, norm: 0.2724, time(ms): 787.58, token/sec:665697.12, hellaswag_acc: 0.3013
Step: 16008, loss: 2.965520, norm: 0.2786, time(ms): 801.54, token/sec:654098.41, hellaswag_acc: 0.3013
Step: 16009, loss: 2.906554, norm: 0.2778, time(ms): 798.71, token/sec:656420.35, hellaswag_acc: 0.3013
Step: 16010, loss: 2.940377, norm: 0.2701, time(ms): 792.56, token/sec:661515.96, hellaswag_acc: 0.3013
Step: 16011, loss: 2.880784, norm: 0.2674, time(ms): 788.87, token/sec:664608.66, hellaswag_acc: 0.3013
Step: 16012, loss: 2.915700, norm: 0.2813, time(ms): 791.71, token/sec:662219.37, hellaswag_acc: 0.3013
Step: 16013, loss: 2.923464, norm: 0.2589, time(ms): 791.16, token/sec:662684.15, hellaswag_acc: 0.3013
Step: 16014, loss: 3.039660, norm: 0.3091, time(ms): 787.35, token/sec:665890.44, hellaswag_acc: 0.3013
Step: 16015, loss: 3.065631, norm: 0.2874, time(ms): 791.64, token/sec:662278.01, hellaswag_acc: 0.3013
Step: 16016, loss: 3.044800, norm: 0.2862, time(ms): 791.64, token/sec:662284.99, hellaswag_acc: 0.3013
Step: 16017, loss: 3.078325, norm: 0.2989, time(ms): 792.07, token/sec:661925.15, hellaswag_acc: 0.3013
Step: 16018, loss: 3.081035, norm: 0.2795, time(ms): 792.62, token/sec:661460.64, hellaswag_acc: 0.3013
Step: 16019, loss: 3.111671, norm: 0.2979, time(ms): 796.78, token/sec:658011.94, hellaswag_acc: 0.3013
Step: 16020, loss: 3.112708, norm: 0.3000, time(ms): 804.15, token/sec:651981.65, hellaswag_acc: 0.3013
Step: 16021, loss: 3.070369, norm: 0.2989, time(ms): 797.02, token/sec:657810.57, hellaswag_acc: 0.3013
Step: 16022, loss: 3.065722, norm: 0.3214, time(ms): 799.40, token/sec:655851.81, hellaswag_acc: 0.3013
Step: 16023, loss: 3.059302, norm: 0.2787, time(ms): 799.66, token/sec:655639.65, hellaswag_acc: 0.3013
Step: 16024, loss: 3.074755, norm: 0.2916, time(ms): 802.00, token/sec:653724.48, hellaswag_acc: 0.3013
Step: 16025, loss: 3.060007, norm: 0.3090, time(ms): 793.18, token/sec:660997.77, hellaswag_acc: 0.3013
Step: 16026, loss: 3.061309, norm: 0.2850, time(ms): 799.48, token/sec:655785.12, hellaswag_acc: 0.3013
Step: 16027, loss: 3.165950, norm: 0.3048, time(ms): 802.03, token/sec:653701.55, hellaswag_acc: 0.3013
Step: 16028, loss: 2.985886, norm: 0.3646, time(ms): 804.91, token/sec:651363.85, hellaswag_acc: 0.3013
Step: 16029, loss: 3.117813, norm: 0.3182, time(ms): 794.49, token/sec:659904.42, hellaswag_acc: 0.3013
Step: 16030, loss: 3.122748, norm: 0.3443, time(ms): 803.64, token/sec:652390.55, hellaswag_acc: 0.3013
Step: 16031, loss: 3.135428, norm: 0.3218, time(ms): 799.25, token/sec:655974.29, hellaswag_acc: 0.3013
Step: 16032, loss: 3.102385, norm: 0.2894, time(ms): 803.01, token/sec:652903.46, hellaswag_acc: 0.3013
Step: 16033, loss: 3.095221, norm: 0.3107, time(ms): 799.58, token/sec:655705.53, hellaswag_acc: 0.3013
Step: 16034, loss: 3.034805, norm: 0.3056, time(ms): 790.38, token/sec:663336.42, hellaswag_acc: 0.3013
Step: 16035, loss: 3.120950, norm: 0.3125, time(ms): 793.14, token/sec:661024.40, hellaswag_acc: 0.3013
Step: 16036, loss: 3.094582, norm: 0.2861, time(ms): 793.56, token/sec:660675.66, hellaswag_acc: 0.3013
Step: 16037, loss: 3.029839, norm: 0.2897, time(ms): 792.69, token/sec:661399.56, hellaswag_acc: 0.3013
Step: 16038, loss: 3.060627, norm: 0.3017, time(ms): 788.33, token/sec:665058.30, hellaswag_acc: 0.3013
Step: 16039, loss: 3.065343, norm: 0.2912, time(ms): 792.03, token/sec:661956.24, hellaswag_acc: 0.3013
Step: 16040, loss: 3.023742, norm: 0.2740, time(ms): 791.05, token/sec:662774.43, hellaswag_acc: 0.3013
Step: 16041, loss: 3.072622, norm: 0.3049, time(ms): 791.97, token/sec:662007.25, hellaswag_acc: 0.3013
Step: 16042, loss: 3.108556, norm: 0.2769, time(ms): 802.46, token/sec:653350.40, hellaswag_acc: 0.3013
Step: 16043, loss: 3.056742, norm: 0.2878, time(ms): 802.35, token/sec:653440.68, hellaswag_acc: 0.3013
Step: 16044, loss: 2.970608, norm: 0.2986, time(ms): 800.43, token/sec:655006.71, hellaswag_acc: 0.3013
Step: 16045, loss: 3.241125, norm: 0.3719, time(ms): 800.31, token/sec:655105.06, hellaswag_acc: 0.3013
Step: 16046, loss: 3.041779, norm: 0.2920, time(ms): 797.18, token/sec:657676.20, hellaswag_acc: 0.3013
Step: 16047, loss: 3.065845, norm: 0.2957, time(ms): 800.60, token/sec:654867.64, hellaswag_acc: 0.3013
Step: 16048, loss: 3.005813, norm: 0.2873, time(ms): 800.85, token/sec:654664.10, hellaswag_acc: 0.3013
Step: 16049, loss: 2.968596, norm: 0.3070, time(ms): 798.95, token/sec:656217.61, hellaswag_acc: 0.3013
Step: 16050, loss: 2.843352, norm: 0.2937, time(ms): 800.23, token/sec:655175.52, hellaswag_acc: 0.3013
Step: 16051, loss: 2.965190, norm: 0.3143, time(ms): 798.98, token/sec:656199.98, hellaswag_acc: 0.3013
Step: 16052, loss: 2.961733, norm: 0.3043, time(ms): 801.62, token/sec:654039.27, hellaswag_acc: 0.3013
Step: 16053, loss: 2.927095, norm: 0.3292, time(ms): 796.42, token/sec:658304.66, hellaswag_acc: 0.3013
Step: 16054, loss: 2.944552, norm: 0.2826, time(ms): 801.27, token/sec:654324.37, hellaswag_acc: 0.3013
Step: 16055, loss: 2.973863, norm: 0.3722, time(ms): 802.33, token/sec:653455.24, hellaswag_acc: 0.3013
Step: 16056, loss: 2.946717, norm: 0.3455, time(ms): 797.55, token/sec:657375.79, hellaswag_acc: 0.3013
Step: 16057, loss: 2.935880, norm: 0.2898, time(ms): 797.08, token/sec:657763.94, hellaswag_acc: 0.3013
Step: 16058, loss: 2.932291, norm: 0.3276, time(ms): 800.50, token/sec:654949.55, hellaswag_acc: 0.3013
Step: 16059, loss: 2.961615, norm: 0.2874, time(ms): 803.68, token/sec:652356.10, hellaswag_acc: 0.3013
Step: 16060, loss: 2.866321, norm: 0.2920, time(ms): 801.17, token/sec:654399.53, hellaswag_acc: 0.3013
Step: 16061, loss: 3.038784, norm: 0.3144, time(ms): 789.09, token/sec:664423.12, hellaswag_acc: 0.3013
Step: 16062, loss: 3.055189, norm: 0.3070, time(ms): 806.92, token/sec:649737.21, hellaswag_acc: 0.3013
Step: 16063, loss: 3.107099, norm: 0.3265, time(ms): 803.00, token/sec:652908.89, hellaswag_acc: 0.3013
Step: 16064, loss: 3.092169, norm: 0.3334, time(ms): 798.88, token/sec:656277.53, hellaswag_acc: 0.3013
Step: 16065, loss: 3.010454, norm: 0.3197, time(ms): 789.59, token/sec:663997.80, hellaswag_acc: 0.3013
Step: 16066, loss: 3.079853, norm: 0.3063, time(ms): 790.65, token/sec:663106.99, hellaswag_acc: 0.3013
Step: 16067, loss: 3.120542, norm: 0.3191, time(ms): 795.13, token/sec:659370.76, hellaswag_acc: 0.3013
Step: 16068, loss: 3.079769, norm: 0.2971, time(ms): 790.97, token/sec:662841.55, hellaswag_acc: 0.3013
Step: 16069, loss: 3.027922, norm: 0.2953, time(ms): 787.88, token/sec:665439.47, hellaswag_acc: 0.3013
Step: 16070, loss: 3.127929, norm: 0.2907, time(ms): 803.66, token/sec:652372.93, hellaswag_acc: 0.3013
Step: 16071, loss: 3.101650, norm: 0.2932, time(ms): 800.81, token/sec:654694.31, hellaswag_acc: 0.3013
Step: 16072, loss: 3.074246, norm: 0.2835, time(ms): 793.20, token/sec:660977.31, hellaswag_acc: 0.3013
Step: 16073, loss: 3.024080, norm: 0.3009, time(ms): 801.40, token/sec:654214.39, hellaswag_acc: 0.3013
Step: 16074, loss: 3.117642, norm: 0.3071, time(ms): 796.84, token/sec:657957.80, hellaswag_acc: 0.3013
Step: 16075, loss: 3.116167, norm: 0.2945, time(ms): 799.36, token/sec:655887.42, hellaswag_acc: 0.3013
Step: 16076, loss: 3.108987, norm: 0.2796, time(ms): 792.79, token/sec:661322.79, hellaswag_acc: 0.3013
Step: 16077, loss: 3.081676, norm: 0.2957, time(ms): 794.56, token/sec:659846.40, hellaswag_acc: 0.3013
Step: 16078, loss: 3.040703, norm: 0.2932, time(ms): 797.66, token/sec:657279.90, hellaswag_acc: 0.3013
Step: 16079, loss: 3.033162, norm: 0.3090, time(ms): 797.26, token/sec:657613.46, hellaswag_acc: 0.3013
Step: 16080, loss: 3.095620, norm: 0.2757, time(ms): 802.27, token/sec:653506.31, hellaswag_acc: 0.3013
Step: 16081, loss: 3.103053, norm: 0.2980, time(ms): 794.81, token/sec:659638.97, hellaswag_acc: 0.3013
Step: 16082, loss: 3.054056, norm: 0.3468, time(ms): 789.82, token/sec:663807.58, hellaswag_acc: 0.3013
Step: 16083, loss: 3.123498, norm: 0.2743, time(ms): 789.50, token/sec:664074.19, hellaswag_acc: 0.3013
Step: 16084, loss: 3.088804, norm: 0.2973, time(ms): 789.70, token/sec:663911.80, hellaswag_acc: 0.3013
Step: 16085, loss: 3.053949, norm: 0.2748, time(ms): 799.72, token/sec:655585.70, hellaswag_acc: 0.3013
Step: 16086, loss: 3.064516, norm: 0.2946, time(ms): 798.13, token/sec:656898.21, hellaswag_acc: 0.3013
Step: 16087, loss: 3.029377, norm: 0.2808, time(ms): 798.20, token/sec:656836.21, hellaswag_acc: 0.3013
Step: 16088, loss: 3.091961, norm: 0.2879, time(ms): 800.34, token/sec:655083.40, hellaswag_acc: 0.3013
Step: 16089, loss: 3.046907, norm: 0.3086, time(ms): 801.44, token/sec:654181.89, hellaswag_acc: 0.3013
Step: 16090, loss: 3.072273, norm: 0.2857, time(ms): 800.60, token/sec:654868.42, hellaswag_acc: 0.3013
Step: 16091, loss: 3.104430, norm: 0.3373, time(ms): 797.62, token/sec:657314.48, hellaswag_acc: 0.3013
Step: 16092, loss: 3.061160, norm: 0.2647, time(ms): 795.32, token/sec:659212.63, hellaswag_acc: 0.3013
Step: 16093, loss: 3.023572, norm: 0.3045, time(ms): 801.22, token/sec:654362.54, hellaswag_acc: 0.3013
Step: 16094, loss: 3.020407, norm: 0.2842, time(ms): 803.82, token/sec:652246.97, hellaswag_acc: 0.3013
Step: 16095, loss: 3.140180, norm: 0.3052, time(ms): 800.00, token/sec:655358.28, hellaswag_acc: 0.3013
Step: 16096, loss: 3.039788, norm: 0.3292, time(ms): 794.85, token/sec:659603.75, hellaswag_acc: 0.3013
Step: 16097, loss: 2.891554, norm: 0.3356, time(ms): 805.25, token/sec:651085.18, hellaswag_acc: 0.3013
Step: 16098, loss: 2.971394, norm: 0.3647, time(ms): 797.80, token/sec:657170.50, hellaswag_acc: 0.3013
Step: 16099, loss: 2.972190, norm: 0.3745, time(ms): 794.27, token/sec:660090.82, hellaswag_acc: 0.3013
Step: 16100, loss: 2.918968, norm: 0.3051, time(ms): 808.25, token/sec:648669.67, hellaswag_acc: 0.3013
Step: 16101, loss: 2.917654, norm: 0.3359, time(ms): 796.71, token/sec:658068.65, hellaswag_acc: 0.3013
Step: 16102, loss: 2.913271, norm: 0.2847, time(ms): 801.62, token/sec:654034.79, hellaswag_acc: 0.3013
Step: 16103, loss: 2.931344, norm: 0.3138, time(ms): 798.57, token/sec:656535.97, hellaswag_acc: 0.3013
Step: 16104, loss: 2.909134, norm: 0.2985, time(ms): 800.98, token/sec:654555.17, hellaswag_acc: 0.3013
Step: 16105, loss: 2.935870, norm: 0.2930, time(ms): 799.66, token/sec:655638.67, hellaswag_acc: 0.3013
Step: 16106, loss: 2.915668, norm: 0.3333, time(ms): 797.27, token/sec:657603.04, hellaswag_acc: 0.3013
Step: 16107, loss: 2.903393, norm: 0.2797, time(ms): 800.99, token/sec:654553.81, hellaswag_acc: 0.3013
Step: 16108, loss: 2.945011, norm: 0.2950, time(ms): 800.59, token/sec:654878.36, hellaswag_acc: 0.3013
Step: 16109, loss: 3.056921, norm: 0.3098, time(ms): 799.88, token/sec:655460.05, hellaswag_acc: 0.3013
Step: 16110, loss: 3.067457, norm: 0.2923, time(ms): 799.65, token/sec:655643.56, hellaswag_acc: 0.3013
Step: 16111, loss: 3.075379, norm: 0.3230, time(ms): 796.72, token/sec:658054.08, hellaswag_acc: 0.3013
Step: 16112, loss: 3.100694, norm: 0.3119, time(ms): 802.14, token/sec:653611.01, hellaswag_acc: 0.3013
Step: 16113, loss: 3.072049, norm: 0.2872, time(ms): 801.03, token/sec:654517.18, hellaswag_acc: 0.3013
Step: 16114, loss: 3.079137, norm: 0.3146, time(ms): 801.60, token/sec:654055.03, hellaswag_acc: 0.3013
Step: 16115, loss: 3.100776, norm: 0.2784, time(ms): 792.60, token/sec:661479.15, hellaswag_acc: 0.3013
Step: 16116, loss: 3.080271, norm: 0.3191, time(ms): 803.16, token/sec:652784.85, hellaswag_acc: 0.3013
Step: 16117, loss: 3.084511, norm: 0.2945, time(ms): 802.55, token/sec:653280.53, hellaswag_acc: 0.3013
Step: 16118, loss: 3.050761, norm: 0.3138, time(ms): 796.88, token/sec:657923.94, hellaswag_acc: 0.3013
Step: 16119, loss: 3.019730, norm: 0.3141, time(ms): 800.57, token/sec:654889.67, hellaswag_acc: 0.3013
Step: 16120, loss: 3.146418, norm: 0.3513, time(ms): 800.59, token/sec:654879.73, hellaswag_acc: 0.3013
Step: 16121, loss: 3.123146, norm: 0.2958, time(ms): 799.24, token/sec:655982.11, hellaswag_acc: 0.3013
Step: 16122, loss: 3.090294, norm: 0.3316, time(ms): 800.80, token/sec:654702.89, hellaswag_acc: 0.3013
Step: 16123, loss: 3.053596, norm: 0.3081, time(ms): 798.80, token/sec:656344.13, hellaswag_acc: 0.3013
Step: 16124, loss: 3.037241, norm: 0.2898, time(ms): 800.45, token/sec:654993.64, hellaswag_acc: 0.3013
Step: 16125, loss: 3.077602, norm: 0.3010, time(ms): 800.48, token/sec:654964.77, hellaswag_acc: 0.3013
Step: 16126, loss: 3.053109, norm: 0.2974, time(ms): 798.82, token/sec:656324.74, hellaswag_acc: 0.3013
Step: 16127, loss: 3.067649, norm: 0.2969, time(ms): 802.26, token/sec:653516.61, hellaswag_acc: 0.3013
Step: 16128, loss: 3.144536, norm: 0.2858, time(ms): 790.85, token/sec:662942.07, hellaswag_acc: 0.3013
Step: 16129, loss: 3.111911, norm: 0.2833, time(ms): 791.78, token/sec:662166.13, hellaswag_acc: 0.3013
Step: 16130, loss: 3.102936, norm: 0.2807, time(ms): 790.21, token/sec:663479.52, hellaswag_acc: 0.3013
Step: 16131, loss: 3.031927, norm: 0.2973, time(ms): 792.35, token/sec:661688.73, hellaswag_acc: 0.3013
Step: 16132, loss: 3.067934, norm: 0.2896, time(ms): 791.13, token/sec:662711.91, hellaswag_acc: 0.3013
Step: 16133, loss: 3.024573, norm: 0.2819, time(ms): 797.41, token/sec:657488.81, hellaswag_acc: 0.3013
Step: 16134, loss: 3.031756, norm: 0.2701, time(ms): 803.50, token/sec:652507.08, hellaswag_acc: 0.3013
Step: 16135, loss: 3.046542, norm: 0.2908, time(ms): 801.42, token/sec:654201.74, hellaswag_acc: 0.3013
Step: 16136, loss: 3.053563, norm: 0.2638, time(ms): 790.34, token/sec:663371.04, hellaswag_acc: 0.3013
Step: 16137, loss: 3.074800, norm: 0.2717, time(ms): 791.75, token/sec:662191.45, hellaswag_acc: 0.3013
Step: 16138, loss: 3.054911, norm: 0.2676, time(ms): 797.59, token/sec:657341.01, hellaswag_acc: 0.3013
Step: 16139, loss: 3.079175, norm: 0.2547, time(ms): 799.63, token/sec:655661.94, hellaswag_acc: 0.3013
Step: 16140, loss: 3.100260, norm: 0.3577, time(ms): 799.02, token/sec:656164.74, hellaswag_acc: 0.3013
Step: 16141, loss: 3.059761, norm: 0.2767, time(ms): 797.87, token/sec:657105.50, hellaswag_acc: 0.3013
Step: 16142, loss: 3.046356, norm: 0.3268, time(ms): 802.19, token/sec:653567.69, hellaswag_acc: 0.3013
Step: 16143, loss: 3.056239, norm: 0.2655, time(ms): 798.93, token/sec:656241.69, hellaswag_acc: 0.3013
Step: 16144, loss: 2.974532, norm: 0.3279, time(ms): 801.66, token/sec:654002.51, hellaswag_acc: 0.3013
Step: 16145, loss: 2.933344, norm: 0.2878, time(ms): 793.02, token/sec:661124.96, hellaswag_acc: 0.3013
Step: 16146, loss: 2.947001, norm: 0.2792, time(ms): 800.37, token/sec:655058.22, hellaswag_acc: 0.3013
Step: 16147, loss: 2.872765, norm: 0.2952, time(ms): 804.97, token/sec:651313.69, hellaswag_acc: 0.3013
Step: 16148, loss: 2.876369, norm: 0.2876, time(ms): 799.19, token/sec:656024.78, hellaswag_acc: 0.3013
Step: 16149, loss: 2.951730, norm: 0.2833, time(ms): 796.16, token/sec:658522.30, hellaswag_acc: 0.3013
Step: 16150, loss: 2.886702, norm: 0.2809, time(ms): 796.22, token/sec:658467.48, hellaswag_acc: 0.3013
Step: 16151, loss: 2.918221, norm: 0.2807, time(ms): 789.42, token/sec:664140.98, hellaswag_acc: 0.3013
Step: 16152, loss: 2.931925, norm: 0.3194, time(ms): 786.13, token/sec:666921.20, hellaswag_acc: 0.3013
Step: 16153, loss: 2.940587, norm: 0.2750, time(ms): 791.89, token/sec:662067.65, hellaswag_acc: 0.3013
Step: 16154, loss: 2.871618, norm: 0.2785, time(ms): 795.38, token/sec:659165.01, hellaswag_acc: 0.3013
Step: 16155, loss: 3.008518, norm: 0.3083, time(ms): 803.32, token/sec:652653.88, hellaswag_acc: 0.3013
Step: 16156, loss: 3.073945, norm: 0.3254, time(ms): 803.38, token/sec:652601.77, hellaswag_acc: 0.3013
Step: 16157, loss: 3.090086, norm: 0.2833, time(ms): 786.31, token/sec:666769.74, hellaswag_acc: 0.3013
Step: 16158, loss: 3.098678, norm: 0.3147, time(ms): 790.34, token/sec:663367.64, hellaswag_acc: 0.3013
Step: 16159, loss: 3.079352, norm: 0.3003, time(ms): 800.19, token/sec:655200.90, hellaswag_acc: 0.3013
Step: 16160, loss: 3.096254, norm: 0.2884, time(ms): 796.35, token/sec:658362.60, hellaswag_acc: 0.3013
Step: 16161, loss: 3.106802, norm: 0.2984, time(ms): 790.53, token/sec:663214.39, hellaswag_acc: 0.3013
Step: 16162, loss: 3.048009, norm: 0.2678, time(ms): 790.51, token/sec:663227.59, hellaswag_acc: 0.3013
Step: 16163, loss: 3.090695, norm: 0.2868, time(ms): 802.26, token/sec:653512.72, hellaswag_acc: 0.3013
Step: 16164, loss: 3.069601, norm: 0.2922, time(ms): 800.29, token/sec:655123.99, hellaswag_acc: 0.3013
Step: 16165, loss: 3.002381, norm: 0.3494, time(ms): 791.08, token/sec:662752.26, hellaswag_acc: 0.3013
Step: 16166, loss: 3.069455, norm: 0.2950, time(ms): 792.17, token/sec:661840.68, hellaswag_acc: 0.3013
Step: 16167, loss: 3.112238, norm: 0.3481, time(ms): 795.32, token/sec:659220.34, hellaswag_acc: 0.3013
Step: 16168, loss: 3.089350, norm: 0.3034, time(ms): 797.32, token/sec:657560.17, hellaswag_acc: 0.3013
Step: 16169, loss: 3.109906, norm: 0.3050, time(ms): 799.60, token/sec:655685.98, hellaswag_acc: 0.3013
Step: 16170, loss: 3.083270, norm: 0.3157, time(ms): 802.74, token/sec:653123.75, hellaswag_acc: 0.3013
Step: 16171, loss: 3.013649, norm: 0.3055, time(ms): 797.71, token/sec:657243.76, hellaswag_acc: 0.3013
Step: 16172, loss: 3.139823, norm: 0.2815, time(ms): 796.50, token/sec:658242.98, hellaswag_acc: 0.3013
Step: 16173, loss: 3.175051, norm: 0.3692, time(ms): 798.53, token/sec:656570.08, hellaswag_acc: 0.3013
Step: 16174, loss: 3.107521, norm: 0.3319, time(ms): 790.31, token/sec:663397.66, hellaswag_acc: 0.3013
Step: 16175, loss: 3.147006, norm: 0.3406, time(ms): 787.27, token/sec:665958.39, hellaswag_acc: 0.3013
Step: 16176, loss: 3.084775, norm: 0.2953, time(ms): 790.75, token/sec:663025.22, hellaswag_acc: 0.3013
Step: 16177, loss: 3.028466, norm: 0.3322, time(ms): 796.19, token/sec:658497.65, hellaswag_acc: 0.3013
Step: 16178, loss: 3.063166, norm: 0.2930, time(ms): 803.15, token/sec:652787.75, hellaswag_acc: 0.3013
Step: 16179, loss: 3.046933, norm: 0.3069, time(ms): 793.85, token/sec:660435.37, hellaswag_acc: 0.3013
Step: 16180, loss: 3.096516, norm: 0.3390, time(ms): 801.20, token/sec:654382.01, hellaswag_acc: 0.3013
Step: 16181, loss: 3.118547, norm: 0.2834, time(ms): 804.32, token/sec:651839.99, hellaswag_acc: 0.3013
Step: 16182, loss: 3.065794, norm: 0.2922, time(ms): 797.93, token/sec:657059.94, hellaswag_acc: 0.3013
Step: 16183, loss: 3.018951, norm: 0.3160, time(ms): 795.04, token/sec:659450.85, hellaswag_acc: 0.3013
Step: 16184, loss: 3.097617, norm: 0.2898, time(ms): 806.53, token/sec:650053.36, hellaswag_acc: 0.3013
Step: 16185, loss: 3.086002, norm: 0.3012, time(ms): 799.21, token/sec:656005.40, hellaswag_acc: 0.3013
Step: 16186, loss: 3.082761, norm: 0.2878, time(ms): 795.53, token/sec:659045.89, hellaswag_acc: 0.3013
Step: 16187, loss: 3.030941, norm: 0.2749, time(ms): 799.84, token/sec:655487.60, hellaswag_acc: 0.3013
Step: 16188, loss: 3.026671, norm: 0.2986, time(ms): 804.99, token/sec:651296.91, hellaswag_acc: 0.3013
Step: 16189, loss: 3.068775, norm: 0.2846, time(ms): 789.34, token/sec:664211.19, hellaswag_acc: 0.3013
Step: 16190, loss: 2.988592, norm: 0.2775, time(ms): 791.78, token/sec:662161.54, hellaswag_acc: 0.3013
Step: 16191, loss: 2.920709, norm: 0.2961, time(ms): 792.77, token/sec:661338.90, hellaswag_acc: 0.3013
Step: 16192, loss: 2.956704, norm: 0.3324, time(ms): 1295.98, token/sec:404549.91, hellaswag_acc: 0.3013
Step: 16193, loss: 3.070920, norm: 0.3222, time(ms): 798.25, token/sec:656793.83, hellaswag_acc: 0.3013
Step: 16194, loss: 3.090762, norm: 0.3070, time(ms): 787.65, token/sec:665635.46, hellaswag_acc: 0.3013
Step: 16195, loss: 3.092183, norm: 0.3288, time(ms): 793.87, token/sec:660421.69, hellaswag_acc: 0.3013
Step: 16196, loss: 3.128482, norm: 0.3007, time(ms): 803.44, token/sec:652553.17, hellaswag_acc: 0.3013
Step: 16197, loss: 3.046108, norm: 0.2938, time(ms): 804.14, token/sec:651983.97, hellaswag_acc: 0.3013
Step: 16198, loss: 3.103531, norm: 0.3040, time(ms): 796.10, token/sec:658572.39, hellaswag_acc: 0.3013
Step: 16199, loss: 3.042617, norm: 0.2874, time(ms): 797.48, token/sec:657434.16, hellaswag_acc: 0.3013
Step: 16200, loss: 3.067997, norm: 0.2685, time(ms): 806.85, token/sec:649797.69, hellaswag_acc: 0.3013
Step: 16201, loss: 3.048550, norm: 0.2995, time(ms): 791.80, token/sec:662150.58, hellaswag_acc: 0.3013
Step: 16202, loss: 3.109429, norm: 0.2941, time(ms): 793.85, token/sec:660437.55, hellaswag_acc: 0.3013
Step: 16203, loss: 3.125045, norm: 0.2970, time(ms): 792.07, token/sec:661917.38, hellaswag_acc: 0.3013
Step: 16204, loss: 3.051481, norm: 0.2892, time(ms): 795.32, token/sec:659220.14, hellaswag_acc: 0.3013
Step: 16205, loss: 3.084513, norm: 0.2880, time(ms): 795.48, token/sec:659081.24, hellaswag_acc: 0.3013
Step: 16206, loss: 3.065943, norm: 0.2827, time(ms): 786.34, token/sec:666745.07, hellaswag_acc: 0.3013
Step: 16207, loss: 3.046989, norm: 0.2775, time(ms): 789.56, token/sec:664021.66, hellaswag_acc: 0.3013
Step: 16208, loss: 3.042123, norm: 0.2687, time(ms): 793.45, token/sec:660773.33, hellaswag_acc: 0.3013
Step: 16209, loss: 3.103170, norm: 0.2885, time(ms): 793.21, token/sec:660969.96, hellaswag_acc: 0.3013
Step: 16210, loss: 3.110478, norm: 0.2790, time(ms): 803.45, token/sec:652549.29, hellaswag_acc: 0.3013
Step: 16211, loss: 3.079334, norm: 0.3014, time(ms): 801.21, token/sec:654371.49, hellaswag_acc: 0.3013
Step: 16212, loss: 3.046585, norm: 0.2927, time(ms): 802.40, token/sec:653396.99, hellaswag_acc: 0.3013
Step: 16213, loss: 3.082610, norm: 0.3045, time(ms): 793.28, token/sec:660909.37, hellaswag_acc: 0.3013
Step: 16214, loss: 3.104342, norm: 0.2744, time(ms): 801.11, token/sec:654449.59, hellaswag_acc: 0.3013
Step: 16215, loss: 3.052207, norm: 0.2777, time(ms): 803.00, token/sec:652907.73, hellaswag_acc: 0.3013
Step: 16216, loss: 3.052630, norm: 0.2640, time(ms): 794.21, token/sec:660137.58, hellaswag_acc: 0.3013
Step: 16217, loss: 3.060414, norm: 0.2627, time(ms): 796.76, token/sec:658024.93, hellaswag_acc: 0.3013
Step: 16218, loss: 3.030925, norm: 0.2792, time(ms): 791.21, token/sec:662641.22, hellaswag_acc: 0.3013
Step: 16219, loss: 3.028490, norm: 0.2669, time(ms): 791.25, token/sec:662608.47, hellaswag_acc: 0.3013
Step: 16220, loss: 3.063065, norm: 0.2691, time(ms): 789.81, token/sec:663818.40, hellaswag_acc: 0.3013
Step: 16221, loss: 3.011784, norm: 0.2847, time(ms): 793.45, token/sec:660770.95, hellaswag_acc: 0.3013
Step: 16222, loss: 3.049272, norm: 0.2667, time(ms): 799.26, token/sec:655968.02, hellaswag_acc: 0.3013
Step: 16223, loss: 3.092564, norm: 0.3069, time(ms): 803.72, token/sec:652330.17, hellaswag_acc: 0.3013
Step: 16224, loss: 3.065872, norm: 0.2826, time(ms): 790.92, token/sec:662887.31, hellaswag_acc: 0.3013
Step: 16225, loss: 2.997745, norm: 0.2775, time(ms): 790.71, token/sec:663057.61, hellaswag_acc: 0.3013
Step: 16226, loss: 3.061061, norm: 0.3182, time(ms): 791.44, token/sec:662451.58, hellaswag_acc: 0.3013
Step: 16227, loss: 3.080884, norm: 0.2832, time(ms): 791.46, token/sec:662429.63, hellaswag_acc: 0.3013
Step: 16228, loss: 3.095517, norm: 0.3065, time(ms): 788.84, token/sec:664631.36, hellaswag_acc: 0.3013
Step: 16229, loss: 3.048254, norm: 0.3063, time(ms): 791.34, token/sec:662527.82, hellaswag_acc: 0.3013
Step: 16230, loss: 3.095221, norm: 0.2977, time(ms): 793.41, token/sec:660800.93, hellaswag_acc: 0.3013
Step: 16231, loss: 3.103898, norm: 0.3637, time(ms): 792.81, token/sec:661300.11, hellaswag_acc: 0.3013
Step: 16232, loss: 3.085748, norm: 0.3053, time(ms): 797.10, token/sec:657743.87, hellaswag_acc: 0.3013
Step: 16233, loss: 3.052973, norm: 0.3106, time(ms): 793.10, token/sec:661065.33, hellaswag_acc: 0.3013
Step: 16234, loss: 3.123183, norm: 0.3032, time(ms): 788.41, token/sec:664991.53, hellaswag_acc: 0.3013
Step: 16235, loss: 3.065344, norm: 0.3570, time(ms): 790.94, token/sec:662864.73, hellaswag_acc: 0.3013
Step: 16236, loss: 3.082706, norm: 0.2962, time(ms): 793.58, token/sec:660664.35, hellaswag_acc: 0.3013
Step: 16237, loss: 3.133876, norm: 0.3088, time(ms): 792.81, token/sec:661306.88, hellaswag_acc: 0.3013
Step: 16238, loss: 3.056407, norm: 0.3303, time(ms): 791.85, token/sec:662101.73, hellaswag_acc: 0.3013
Step: 16239, loss: 3.087359, norm: 0.2693, time(ms): 793.70, token/sec:660557.97, hellaswag_acc: 0.3013
Step: 16240, loss: 3.102063, norm: 0.3343, time(ms): 794.23, token/sec:660120.94, hellaswag_acc: 0.3013
Step: 16241, loss: 3.147234, norm: 0.3245, time(ms): 788.89, token/sec:664593.40, hellaswag_acc: 0.3013
Step: 16242, loss: 3.059078, norm: 0.2927, time(ms): 792.14, token/sec:661863.00, hellaswag_acc: 0.3013
Step: 16243, loss: 3.114125, norm: 0.3080, time(ms): 790.18, token/sec:663503.74, hellaswag_acc: 0.3013
Step: 16244, loss: 3.144483, norm: 0.2921, time(ms): 794.23, token/sec:660120.15, hellaswag_acc: 0.3013
Step: 16245, loss: 3.123029, norm: 0.2813, time(ms): 796.89, token/sec:657919.61, hellaswag_acc: 0.3013
Step: 16246, loss: 3.119393, norm: 0.2919, time(ms): 803.54, token/sec:652472.43, hellaswag_acc: 0.3013
Step: 16247, loss: 3.110284, norm: 0.3147, time(ms): 800.94, token/sec:654587.51, hellaswag_acc: 0.3013
Step: 16248, loss: 3.170196, norm: 0.2875, time(ms): 801.99, token/sec:653737.31, hellaswag_acc: 0.3013
Step: 16249, loss: 3.079389, norm: 0.3084, time(ms): 795.32, token/sec:659218.76, hellaswag_acc: 0.3013
rank 0 sample 0: Hello, I'm a language model, so I am a computer program for teaching beginners at all levels. There are no rules and I don't really know where
rank 0 sample 1: Hello, I'm a language model, and what I'm talking about in question is that those ideas that were built by people, by the likes of Larry Page
rank 0 sample 2: Hello, I'm a language model, and I feel it's like I was a child. I know it's a pretty awful language, but I feel it
rank 0 sample 3: Hello, I'm a language model, and here's my definition: "To do action, you must get in touch with somebody else. When you're using
rank 1 sample 0: Hello, I'm a language model, an interface for modeling and representing real code in programming, rather than a language model. In fact, I can't even
rank 1 sample 1: Hello, I'm a language model, not an engineer. I'm a professional English speaker, like you, and I could only finish for the first time.
rank 1 sample 2: Hello, I'm a language model, I assume I've been watching the video, and I have used a few articles to explain it. But, how can
rank 1 sample 3: Hello, I'm a language model, so I'm pretty good at coding. Since I'm always thinking about code you're modeling so, I'm also pretty
Step: 16250, loss: 3.095371, norm: 0.2848, time(ms): 3834.23, token/sec:136738.84, val_loss: 3.0853, hellaswag_acc: 0.3013
Step: 16251, loss: 3.030595, norm: 0.2832, time(ms): 790.07, token/sec:663596.45, hellaswag_acc: 0.3013
Step: 16252, loss: 3.115091, norm: 0.3075, time(ms): 784.56, token/sec:668256.18, hellaswag_acc: 0.3013
Step: 16253, loss: 3.025537, norm: 0.2755, time(ms): 791.49, token/sec:662405.48, hellaswag_acc: 0.3013
Step: 16254, loss: 3.075704, norm: 0.2774, time(ms): 806.10, token/sec:650400.78, hellaswag_acc: 0.3013
Step: 16255, loss: 3.096169, norm: 0.2754, time(ms): 794.49, token/sec:659903.43, hellaswag_acc: 0.3013
Step: 16256, loss: 3.066321, norm: 0.3003, time(ms): 795.34, token/sec:659199.99, hellaswag_acc: 0.3013
Step: 16257, loss: 3.080842, norm: 0.2857, time(ms): 803.42, token/sec:652573.31, hellaswag_acc: 0.3013
Step: 16258, loss: 3.044021, norm: 0.2850, time(ms): 804.57, token/sec:651637.94, hellaswag_acc: 0.3013
Step: 16259, loss: 3.076735, norm: 0.3271, time(ms): 789.85, token/sec:663785.74, hellaswag_acc: 0.3013
Step: 16260, loss: 3.048520, norm: 0.2723, time(ms): 792.05, token/sec:661941.69, hellaswag_acc: 0.3013
Step: 16261, loss: 3.122460, norm: 0.3461, time(ms): 790.70, token/sec:663067.40, hellaswag_acc: 0.3013
Step: 16262, loss: 3.110691, norm: 0.2888, time(ms): 792.85, token/sec:661272.08, hellaswag_acc: 0.3013
Step: 16263, loss: 3.080210, norm: 0.2929, time(ms): 789.41, token/sec:664151.41, hellaswag_acc: 0.3013
Step: 16264, loss: 3.082047, norm: 0.3113, time(ms): 797.96, token/sec:657038.55, hellaswag_acc: 0.3013
Step: 16265, loss: 3.100806, norm: 0.2873, time(ms): 796.75, token/sec:658035.17, hellaswag_acc: 0.3013
Step: 16266, loss: 3.052656, norm: 0.2986, time(ms): 792.94, token/sec:661197.32, hellaswag_acc: 0.3013
Step: 16267, loss: 3.093492, norm: 0.2950, time(ms): 787.42, token/sec:665827.53, hellaswag_acc: 0.3013
Step: 16268, loss: 3.056848, norm: 0.2617, time(ms): 791.69, token/sec:662237.52, hellaswag_acc: 0.3013
Step: 16269, loss: 3.037071, norm: 0.2938, time(ms): 786.10, token/sec:666949.92, hellaswag_acc: 0.3013
Step: 16270, loss: 3.074585, norm: 0.2754, time(ms): 789.55, token/sec:664029.88, hellaswag_acc: 0.3013
Step: 16271, loss: 3.054099, norm: 0.3049, time(ms): 800.53, token/sec:654926.54, hellaswag_acc: 0.3013
Step: 16272, loss: 3.106190, norm: 0.3484, time(ms): 789.42, token/sec:664143.79, hellaswag_acc: 0.3013
Step: 16273, loss: 3.159425, norm: 0.2832, time(ms): 790.97, token/sec:662838.76, hellaswag_acc: 0.3013
Step: 16274, loss: 3.086703, norm: 0.3068, time(ms): 794.04, token/sec:660277.92, hellaswag_acc: 0.3013
Step: 16275, loss: 3.074910, norm: 0.2840, time(ms): 795.97, token/sec:658676.35, hellaswag_acc: 0.3013
Step: 16276, loss: 3.045318, norm: 0.3003, time(ms): 787.72, token/sec:665575.42, hellaswag_acc: 0.3013
Step: 16277, loss: 3.076937, norm: 0.2986, time(ms): 793.69, token/sec:660569.68, hellaswag_acc: 0.3013
Step: 16278, loss: 3.084044, norm: 0.2699, time(ms): 798.81, token/sec:656340.21, hellaswag_acc: 0.3013
Step: 16279, loss: 3.074864, norm: 0.2867, time(ms): 798.53, token/sec:656569.89, hellaswag_acc: 0.3013
Step: 16280, loss: 3.115138, norm: 0.3038, time(ms): 793.20, token/sec:660982.08, hellaswag_acc: 0.3013
Step: 16281, loss: 3.069000, norm: 0.2835, time(ms): 785.73, token/sec:667263.20, hellaswag_acc: 0.3013
Step: 16282, loss: 3.040061, norm: 0.2942, time(ms): 788.39, token/sec:665008.22, hellaswag_acc: 0.3013
Step: 16283, loss: 3.063652, norm: 0.2699, time(ms): 792.28, token/sec:661745.09, hellaswag_acc: 0.3013
Step: 16284, loss: 3.058525, norm: 0.2999, time(ms): 790.08, token/sec:663585.43, hellaswag_acc: 0.3013
Step: 16285, loss: 3.027175, norm: 0.2806, time(ms): 788.80, token/sec:664665.11, hellaswag_acc: 0.3013
Step: 16286, loss: 2.982277, norm: 0.3008, time(ms): 791.34, token/sec:662535.41, hellaswag_acc: 0.3013
Step: 16287, loss: 3.063740, norm: 0.2900, time(ms): 795.36, token/sec:659185.36, hellaswag_acc: 0.3013
Step: 16288, loss: 3.050596, norm: 0.3058, time(ms): 792.40, token/sec:661642.15, hellaswag_acc: 0.3013
Step: 16289, loss: 3.039178, norm: 0.2806, time(ms): 790.82, token/sec:662971.05, hellaswag_acc: 0.3013
Step: 16290, loss: 3.043808, norm: 0.2817, time(ms): 790.78, token/sec:662999.83, hellaswag_acc: 0.3013
Step: 16291, loss: 3.046294, norm: 0.2666, time(ms): 804.29, token/sec:651868.20, hellaswag_acc: 0.3013
Step: 16292, loss: 3.051416, norm: 0.2744, time(ms): 801.38, token/sec:654229.96, hellaswag_acc: 0.3013
Step: 16293, loss: 3.057254, norm: 0.3417, time(ms): 800.79, token/sec:654710.10, hellaswag_acc: 0.3013
Step: 16294, loss: 3.064490, norm: 0.2651, time(ms): 796.61, token/sec:658147.23, hellaswag_acc: 0.3013
Step: 16295, loss: 3.087950, norm: 0.3276, time(ms): 798.73, token/sec:656400.36, hellaswag_acc: 0.3013
Step: 16296, loss: 3.138546, norm: 0.3221, time(ms): 805.26, token/sec:651080.16, hellaswag_acc: 0.3013
Step: 16297, loss: 3.109795, norm: 0.2949, time(ms): 796.51, token/sec:658230.17, hellaswag_acc: 0.3013
Step: 16298, loss: 3.148334, norm: 0.3015, time(ms): 802.07, token/sec:653664.83, hellaswag_acc: 0.3013
Step: 16299, loss: 3.132259, norm: 0.3334, time(ms): 797.29, token/sec:657590.26, hellaswag_acc: 0.3013
Step: 16300, loss: 3.077155, norm: 0.3017, time(ms): 799.60, token/sec:655685.40, hellaswag_acc: 0.3013
Step: 16301, loss: 3.072458, norm: 0.2856, time(ms): 799.25, token/sec:655974.29, hellaswag_acc: 0.3013
Step: 16302, loss: 3.162342, norm: 0.3328, time(ms): 800.22, token/sec:655175.91, hellaswag_acc: 0.3013
Step: 16303, loss: 3.077752, norm: 0.2883, time(ms): 800.88, token/sec:654637.40, hellaswag_acc: 0.3013
Step: 16304, loss: 3.079165, norm: 0.2828, time(ms): 799.34, token/sec:655898.18, hellaswag_acc: 0.3013
Step: 16305, loss: 3.055887, norm: 0.3243, time(ms): 801.01, token/sec:654532.37, hellaswag_acc: 0.3013
Step: 16306, loss: 3.093533, norm: 0.2840, time(ms): 798.63, token/sec:656482.27, hellaswag_acc: 0.3013
Step: 16307, loss: 3.153192, norm: 0.3064, time(ms): 801.94, token/sec:653772.49, hellaswag_acc: 0.3013
Step: 16308, loss: 3.131064, norm: 0.2968, time(ms): 796.44, token/sec:658286.53, hellaswag_acc: 0.3013
Step: 16309, loss: 3.074083, norm: 0.2862, time(ms): 802.05, token/sec:653681.15, hellaswag_acc: 0.3013
Step: 16310, loss: 3.112298, norm: 0.2830, time(ms): 801.40, token/sec:654218.28, hellaswag_acc: 0.3013
Step: 16311, loss: 3.105362, norm: 0.2804, time(ms): 791.57, token/sec:662338.45, hellaswag_acc: 0.3013
Step: 16312, loss: 3.084720, norm: 0.2774, time(ms): 798.94, token/sec:656227.20, hellaswag_acc: 0.3013
Step: 16313, loss: 3.049967, norm: 0.2877, time(ms): 793.46, token/sec:660762.81, hellaswag_acc: 0.3013
Step: 16314, loss: 3.042703, norm: 0.2971, time(ms): 793.51, token/sec:660719.73, hellaswag_acc: 0.3013
Step: 16315, loss: 3.075446, norm: 0.3082, time(ms): 791.56, token/sec:662350.02, hellaswag_acc: 0.3013
Step: 16316, loss: 3.078411, norm: 0.2910, time(ms): 787.30, token/sec:665931.98, hellaswag_acc: 0.3013
Step: 16317, loss: 3.067723, norm: 0.2749, time(ms): 797.42, token/sec:657476.42, hellaswag_acc: 0.3013
Step: 16318, loss: 3.096491, norm: 0.2944, time(ms): 791.93, token/sec:662039.94, hellaswag_acc: 0.3013
Step: 16319, loss: 3.095867, norm: 0.2850, time(ms): 784.85, token/sec:668011.16, hellaswag_acc: 0.3013
Step: 16320, loss: 3.070641, norm: 0.2733, time(ms): 806.65, token/sec:649955.95, hellaswag_acc: 0.3013
Step: 16321, loss: 3.010823, norm: 0.2824, time(ms): 799.86, token/sec:655472.17, hellaswag_acc: 0.3013
Step: 16322, loss: 3.082694, norm: 0.2731, time(ms): 790.71, token/sec:663059.60, hellaswag_acc: 0.3013
Step: 16323, loss: 3.060559, norm: 0.2781, time(ms): 790.90, token/sec:662899.90, hellaswag_acc: 0.3013
Step: 16324, loss: 3.073906, norm: 0.2766, time(ms): 794.73, token/sec:659709.22, hellaswag_acc: 0.3013
Step: 16325, loss: 3.101916, norm: 0.2956, time(ms): 792.67, token/sec:661420.25, hellaswag_acc: 0.3013
Step: 16326, loss: 3.071597, norm: 0.2813, time(ms): 786.92, token/sec:666251.57, hellaswag_acc: 0.3013
Step: 16327, loss: 3.088088, norm: 0.2814, time(ms): 798.97, token/sec:656206.25, hellaswag_acc: 0.3013
Step: 16328, loss: 3.091156, norm: 0.3038, time(ms): 803.83, token/sec:652239.42, hellaswag_acc: 0.3013
Step: 16329, loss: 3.077019, norm: 0.2785, time(ms): 797.88, token/sec:657097.25, hellaswag_acc: 0.3013
Step: 16330, loss: 3.136435, norm: 0.2971, time(ms): 796.11, token/sec:658565.49, hellaswag_acc: 0.3013
Step: 16331, loss: 3.053246, norm: 0.3142, time(ms): 799.07, token/sec:656119.12, hellaswag_acc: 0.3013
Step: 16332, loss: 3.125715, norm: 0.2742, time(ms): 792.73, token/sec:661369.53, hellaswag_acc: 0.3013
Step: 16333, loss: 3.074953, norm: 0.3213, time(ms): 794.73, token/sec:659705.26, hellaswag_acc: 0.3013
Step: 16334, loss: 3.096828, norm: 0.3239, time(ms): 790.78, token/sec:662997.83, hellaswag_acc: 0.3013
Step: 16335, loss: 3.051620, norm: 0.2790, time(ms): 789.08, token/sec:664433.16, hellaswag_acc: 0.3013
Step: 16336, loss: 3.145478, norm: 0.3110, time(ms): 790.64, token/sec:663116.39, hellaswag_acc: 0.3013
Step: 16337, loss: 3.057443, norm: 0.3117, time(ms): 791.27, token/sec:662592.10, hellaswag_acc: 0.3013
Step: 16338, loss: 3.082909, norm: 0.2851, time(ms): 796.55, token/sec:658202.59, hellaswag_acc: 0.3013
Step: 16339, loss: 3.109421, norm: 0.3179, time(ms): 796.24, token/sec:658457.22, hellaswag_acc: 0.3013
Step: 16340, loss: 3.051160, norm: 0.3179, time(ms): 804.63, token/sec:651590.63, hellaswag_acc: 0.3013
Step: 16341, loss: 3.072686, norm: 0.3012, time(ms): 799.78, token/sec:655542.32, hellaswag_acc: 0.3013
Step: 16342, loss: 3.073970, norm: 0.3087, time(ms): 797.62, token/sec:657315.66, hellaswag_acc: 0.3013
Step: 16343, loss: 3.071867, norm: 0.2979, time(ms): 793.42, token/sec:660794.58, hellaswag_acc: 0.3013
Step: 16344, loss: 3.083864, norm: 0.3114, time(ms): 801.07, token/sec:654483.87, hellaswag_acc: 0.3013
Step: 16345, loss: 3.110123, norm: 0.2794, time(ms): 795.30, token/sec:659232.79, hellaswag_acc: 0.3013
Step: 16346, loss: 3.114169, norm: 0.3018, time(ms): 790.70, token/sec:663066.60, hellaswag_acc: 0.3013
Step: 16347, loss: 3.053040, norm: 0.2785, time(ms): 792.55, token/sec:661519.74, hellaswag_acc: 0.3013
Step: 16348, loss: 3.068413, norm: 0.3103, time(ms): 789.87, token/sec:663767.91, hellaswag_acc: 0.3013
Step: 16349, loss: 3.057900, norm: 0.2749, time(ms): 793.55, token/sec:660683.40, hellaswag_acc: 0.3013
Step: 16350, loss: 3.027954, norm: 0.2980, time(ms): 800.51, token/sec:654939.80, hellaswag_acc: 0.3013
Step: 16351, loss: 3.107031, norm: 0.3103, time(ms): 803.34, token/sec:652633.54, hellaswag_acc: 0.3013
Step: 16352, loss: 3.153369, norm: 0.3683, time(ms): 801.30, token/sec:654299.26, hellaswag_acc: 0.3013
Step: 16353, loss: 3.092521, norm: 0.2991, time(ms): 790.98, token/sec:662831.56, hellaswag_acc: 0.3013
Step: 16354, loss: 3.059793, norm: 0.3278, time(ms): 803.68, token/sec:652355.90, hellaswag_acc: 0.3013
Step: 16355, loss: 2.964436, norm: 0.3369, time(ms): 803.73, token/sec:652318.17, hellaswag_acc: 0.3013
Step: 16356, loss: 3.051646, norm: 0.3103, time(ms): 797.26, token/sec:657616.22, hellaswag_acc: 0.3013
Step: 16357, loss: 3.116088, norm: 0.3225, time(ms): 800.61, token/sec:654864.71, hellaswag_acc: 0.3013
Step: 16358, loss: 3.109066, norm: 0.2950, time(ms): 799.11, token/sec:656088.97, hellaswag_acc: 0.3013
Step: 16359, loss: 3.055120, norm: 0.3081, time(ms): 797.71, token/sec:657242.19, hellaswag_acc: 0.3013
Step: 16360, loss: 3.075740, norm: 0.2902, time(ms): 802.83, token/sec:653053.15, hellaswag_acc: 0.3013
Step: 16361, loss: 3.120004, norm: 0.2933, time(ms): 802.02, token/sec:653705.63, hellaswag_acc: 0.3013
Step: 16362, loss: 3.075707, norm: 0.3125, time(ms): 795.57, token/sec:659006.58, hellaswag_acc: 0.3013
Step: 16363, loss: 3.031539, norm: 0.2862, time(ms): 796.50, token/sec:658242.58, hellaswag_acc: 0.3013
Step: 16364, loss: 3.079026, norm: 0.2776, time(ms): 806.22, token/sec:650303.27, hellaswag_acc: 0.3013
Step: 16365, loss: 3.069798, norm: 0.2910, time(ms): 798.50, token/sec:656594.59, hellaswag_acc: 0.3013
Step: 16366, loss: 3.034412, norm: 0.2828, time(ms): 793.74, token/sec:660530.20, hellaswag_acc: 0.3013
Step: 16367, loss: 3.105433, norm: 0.2989, time(ms): 800.35, token/sec:655073.45, hellaswag_acc: 0.3013
Step: 16368, loss: 3.087494, norm: 0.2802, time(ms): 793.86, token/sec:660431.60, hellaswag_acc: 0.3013
Step: 16369, loss: 3.113183, norm: 0.2791, time(ms): 794.29, token/sec:660067.24, hellaswag_acc: 0.3013
Step: 16370, loss: 3.127821, norm: 0.2869, time(ms): 793.29, token/sec:660902.81, hellaswag_acc: 0.3013
Step: 16371, loss: 3.083171, norm: 0.2898, time(ms): 804.73, token/sec:651510.13, hellaswag_acc: 0.3013
Step: 16372, loss: 3.073442, norm: 0.2915, time(ms): 799.64, token/sec:655653.33, hellaswag_acc: 0.3013
Step: 16373, loss: 3.060110, norm: 0.3170, time(ms): 792.81, token/sec:661305.29, hellaswag_acc: 0.3013
Step: 16374, loss: 3.126732, norm: 0.3050, time(ms): 792.24, token/sec:661775.16, hellaswag_acc: 0.3013
Step: 16375, loss: 3.047147, norm: 0.2814, time(ms): 788.42, token/sec:664986.91, hellaswag_acc: 0.3013
Step: 16376, loss: 3.157394, norm: 0.3045, time(ms): 791.56, token/sec:662351.41, hellaswag_acc: 0.3013
Step: 16377, loss: 3.055903, norm: 0.2997, time(ms): 796.64, token/sec:658124.98, hellaswag_acc: 0.3013
Step: 16378, loss: 3.088892, norm: 0.2788, time(ms): 790.67, token/sec:663096.19, hellaswag_acc: 0.3013
Step: 16379, loss: 3.112942, norm: 0.3080, time(ms): 805.35, token/sec:651006.34, hellaswag_acc: 0.3013
Step: 16380, loss: 3.125398, norm: 0.2916, time(ms): 802.89, token/sec:653004.28, hellaswag_acc: 0.3013
Step: 16381, loss: 3.128522, norm: 0.2961, time(ms): 794.82, token/sec:659635.01, hellaswag_acc: 0.3013
Step: 16382, loss: 3.086293, norm: 0.2793, time(ms): 1064.77, token/sec:492393.56, hellaswag_acc: 0.3013
Step: 16383, loss: 3.043893, norm: 0.2842, time(ms): 769.11, token/sec:681679.77, hellaswag_acc: 0.3013
Step: 16384, loss: 3.112210, norm: 0.2698, time(ms): 790.09, token/sec:663581.63, hellaswag_acc: 0.3013
Step: 16385, loss: 3.070814, norm: 0.3160, time(ms): 799.50, token/sec:655773.78, hellaswag_acc: 0.3013
Step: 16386, loss: 3.080724, norm: 0.2825, time(ms): 787.50, token/sec:665764.64, hellaswag_acc: 0.3013
Step: 16387, loss: 3.064225, norm: 0.2804, time(ms): 782.36, token/sec:670139.92, hellaswag_acc: 0.3013
Step: 16388, loss: 3.081774, norm: 0.2825, time(ms): 790.80, token/sec:662988.44, hellaswag_acc: 0.3013
Step: 16389, loss: 3.097362, norm: 0.2989, time(ms): 793.04, token/sec:661111.64, hellaswag_acc: 0.3013
Step: 16390, loss: 3.004184, norm: 0.2959, time(ms): 795.76, token/sec:658853.56, hellaswag_acc: 0.3013
Step: 16391, loss: 3.049382, norm: 0.2645, time(ms): 791.31, token/sec:662559.56, hellaswag_acc: 0.3013
Step: 16392, loss: 3.030030, norm: 0.2978, time(ms): 785.56, token/sec:667408.20, hellaswag_acc: 0.3013
Step: 16393, loss: 3.067259, norm: 0.2941, time(ms): 792.25, token/sec:661767.19, hellaswag_acc: 0.3013
Step: 16394, loss: 3.070825, norm: 0.3157, time(ms): 799.08, token/sec:656117.75, hellaswag_acc: 0.3013
Step: 16395, loss: 3.069259, norm: 0.2785, time(ms): 800.25, token/sec:655155.22, hellaswag_acc: 0.3013
Step: 16396, loss: 3.076047, norm: 0.3098, time(ms): 797.30, token/sec:657576.69, hellaswag_acc: 0.3013
Step: 16397, loss: 3.044199, norm: 0.2832, time(ms): 796.06, token/sec:658600.59, hellaswag_acc: 0.3013
Step: 16398, loss: 3.065202, norm: 0.3393, time(ms): 794.69, token/sec:659738.71, hellaswag_acc: 0.3013
Step: 16399, loss: 3.156154, norm: 0.3439, time(ms): 790.11, token/sec:663566.01, hellaswag_acc: 0.3013
Step: 16400, loss: 3.054302, norm: 0.3106, time(ms): 793.71, token/sec:660552.02, hellaswag_acc: 0.3013
Step: 16401, loss: 3.095801, norm: 0.3186, time(ms): 791.27, token/sec:662590.30, hellaswag_acc: 0.3013
Step: 16402, loss: 3.093413, norm: 0.3107, time(ms): 792.26, token/sec:661758.43, hellaswag_acc: 0.3013
Step: 16403, loss: 3.027623, norm: 0.2803, time(ms): 800.70, token/sec:654787.10, hellaswag_acc: 0.3013
Step: 16404, loss: 2.967466, norm: 0.3068, time(ms): 800.25, token/sec:655153.07, hellaswag_acc: 0.3013
Step: 16405, loss: 2.976447, norm: 0.2799, time(ms): 803.30, token/sec:652663.95, hellaswag_acc: 0.3013
Step: 16406, loss: 2.945865, norm: 0.3000, time(ms): 790.32, token/sec:663383.05, hellaswag_acc: 0.3013
Step: 16407, loss: 2.969143, norm: 0.2980, time(ms): 803.73, token/sec:652318.94, hellaswag_acc: 0.3013
Step: 16408, loss: 3.046906, norm: 0.2823, time(ms): 804.36, token/sec:651805.01, hellaswag_acc: 0.3013
Step: 16409, loss: 2.965336, norm: 0.3000, time(ms): 795.56, token/sec:659018.63, hellaswag_acc: 0.3013
Step: 16410, loss: 3.006960, norm: 0.2739, time(ms): 803.14, token/sec:652796.28, hellaswag_acc: 0.3013
Step: 16411, loss: 2.973206, norm: 0.2735, time(ms): 800.37, token/sec:655058.81, hellaswag_acc: 0.3013
Step: 16412, loss: 2.994341, norm: 0.2959, time(ms): 795.72, token/sec:658886.14, hellaswag_acc: 0.3013
Step: 16413, loss: 3.007176, norm: 0.2784, time(ms): 798.71, token/sec:656417.21, hellaswag_acc: 0.3013
Step: 16414, loss: 2.978037, norm: 0.2869, time(ms): 803.73, token/sec:652315.85, hellaswag_acc: 0.3013
Step: 16415, loss: 3.134803, norm: 0.3274, time(ms): 802.10, token/sec:653646.76, hellaswag_acc: 0.3013
Step: 16416, loss: 3.125648, norm: 0.2998, time(ms): 797.67, token/sec:657270.48, hellaswag_acc: 0.3013
Step: 16417, loss: 3.113223, norm: 0.3073, time(ms): 791.14, token/sec:662701.13, hellaswag_acc: 0.3013
Step: 16418, loss: 3.039468, norm: 0.3362, time(ms): 791.19, token/sec:662657.59, hellaswag_acc: 0.3013
Step: 16419, loss: 3.080592, norm: 0.2948, time(ms): 800.19, token/sec:655205.58, hellaswag_acc: 0.3013
Step: 16420, loss: 3.132640, norm: 0.2852, time(ms): 788.82, token/sec:664652.05, hellaswag_acc: 0.3013
Step: 16421, loss: 3.063944, norm: 0.3024, time(ms): 784.78, token/sec:668071.23, hellaswag_acc: 0.3013
Step: 16422, loss: 3.052088, norm: 0.3061, time(ms): 797.09, token/sec:657750.56, hellaswag_acc: 0.3013
Step: 16423, loss: 3.068200, norm: 0.2841, time(ms): 801.29, token/sec:654302.18, hellaswag_acc: 0.3013
Step: 16424, loss: 3.074751, norm: 0.2999, time(ms): 794.30, token/sec:660062.09, hellaswag_acc: 0.3013
Step: 16425, loss: 3.116597, norm: 0.3178, time(ms): 789.15, token/sec:664371.53, hellaswag_acc: 0.3013
Step: 16426, loss: 3.065350, norm: 0.2915, time(ms): 796.52, token/sec:658225.84, hellaswag_acc: 0.3013
Step: 16427, loss: 3.064390, norm: 0.2780, time(ms): 803.96, token/sec:652135.55, hellaswag_acc: 0.3013
Step: 16428, loss: 2.985877, norm: 0.2836, time(ms): 792.85, token/sec:661273.67, hellaswag_acc: 0.3013
Step: 16429, loss: 3.051373, norm: 0.2967, time(ms): 792.63, token/sec:661454.67, hellaswag_acc: 0.3013
Step: 16430, loss: 3.046335, norm: 0.2747, time(ms): 787.06, token/sec:666138.95, hellaswag_acc: 0.3013
Step: 16431, loss: 3.005928, norm: 0.2614, time(ms): 793.64, token/sec:660614.13, hellaswag_acc: 0.3013
Step: 16432, loss: 3.053150, norm: 0.2847, time(ms): 795.23, token/sec:659286.94, hellaswag_acc: 0.3013
Step: 16433, loss: 3.226478, norm: 0.2933, time(ms): 791.06, token/sec:662763.44, hellaswag_acc: 0.3013
Step: 16434, loss: 3.109742, norm: 0.2998, time(ms): 806.42, token/sec:650138.88, hellaswag_acc: 0.3013
Step: 16435, loss: 3.071502, norm: 0.2779, time(ms): 802.17, token/sec:653586.92, hellaswag_acc: 0.3013
Step: 16436, loss: 3.054349, norm: 0.3059, time(ms): 787.86, token/sec:665454.98, hellaswag_acc: 0.3013
Step: 16437, loss: 3.090132, norm: 0.2962, time(ms): 790.13, token/sec:663545.19, hellaswag_acc: 0.3013
Step: 16438, loss: 3.121336, norm: 0.2760, time(ms): 798.98, token/sec:656199.20, hellaswag_acc: 0.3013
Step: 16439, loss: 2.966736, norm: 0.3172, time(ms): 795.76, token/sec:658853.37, hellaswag_acc: 0.3013
Step: 16440, loss: 2.991616, norm: 0.3110, time(ms): 791.39, token/sec:662490.90, hellaswag_acc: 0.3013
Step: 16441, loss: 2.983761, norm: 0.2991, time(ms): 791.71, token/sec:662226.35, hellaswag_acc: 0.3013
Step: 16442, loss: 3.018442, norm: 0.2930, time(ms): 796.45, token/sec:658278.25, hellaswag_acc: 0.3013
Step: 16443, loss: 2.992770, norm: 0.3132, time(ms): 805.03, token/sec:651265.66, hellaswag_acc: 0.3013
Step: 16444, loss: 2.964421, norm: 0.2830, time(ms): 796.42, token/sec:658303.67, hellaswag_acc: 0.3013
Step: 16445, loss: 2.990430, norm: 0.2717, time(ms): 793.43, token/sec:660786.64, hellaswag_acc: 0.3013
Step: 16446, loss: 2.996818, norm: 0.2858, time(ms): 788.79, token/sec:664676.16, hellaswag_acc: 0.3013
Step: 16447, loss: 3.021496, norm: 0.2738, time(ms): 799.90, token/sec:655443.06, hellaswag_acc: 0.3013
Step: 16448, loss: 2.981653, norm: 0.2779, time(ms): 798.14, token/sec:656885.06, hellaswag_acc: 0.3013
Step: 16449, loss: 2.979780, norm: 0.2929, time(ms): 797.70, token/sec:657250.44, hellaswag_acc: 0.3013
Step: 16450, loss: 3.009536, norm: 0.3259, time(ms): 795.95, token/sec:658697.06, hellaswag_acc: 0.3013
Step: 16451, loss: 3.132945, norm: 0.3230, time(ms): 792.39, token/sec:661658.07, hellaswag_acc: 0.3013
Step: 16452, loss: 3.089375, norm: 0.3256, time(ms): 786.68, token/sec:666459.75, hellaswag_acc: 0.3013
Step: 16453, loss: 3.076284, norm: 0.3278, time(ms): 792.03, token/sec:661957.23, hellaswag_acc: 0.3013
Step: 16454, loss: 3.143618, norm: 0.3109, time(ms): 797.35, token/sec:657540.71, hellaswag_acc: 0.3013
Step: 16455, loss: 3.071404, norm: 0.2980, time(ms): 790.98, token/sec:662829.37, hellaswag_acc: 0.3013
Step: 16456, loss: 3.154168, norm: 0.3199, time(ms): 799.77, token/sec:655549.74, hellaswag_acc: 0.3013
Step: 16457, loss: 3.077457, norm: 0.3034, time(ms): 794.48, token/sec:659912.74, hellaswag_acc: 0.3013
Step: 16458, loss: 3.080975, norm: 0.3166, time(ms): 792.06, token/sec:661926.95, hellaswag_acc: 0.3013
Step: 16459, loss: 3.002869, norm: 0.3089, time(ms): 793.99, token/sec:660324.31, hellaswag_acc: 0.3013
Step: 16460, loss: 3.103671, norm: 0.3024, time(ms): 793.86, token/sec:660429.62, hellaswag_acc: 0.3013
Step: 16461, loss: 3.067715, norm: 0.3247, time(ms): 793.63, token/sec:660620.68, hellaswag_acc: 0.3013
Step: 16462, loss: 3.081701, norm: 0.2875, time(ms): 794.26, token/sec:660097.95, hellaswag_acc: 0.3013
Step: 16463, loss: 3.017512, norm: 0.3164, time(ms): 799.63, token/sec:655662.72, hellaswag_acc: 0.3013
Step: 16464, loss: 3.013306, norm: 0.2896, time(ms): 801.91, token/sec:653802.81, hellaswag_acc: 0.3013
Step: 16465, loss: 3.039361, norm: 0.2754, time(ms): 798.15, token/sec:656880.55, hellaswag_acc: 0.3013
Step: 16466, loss: 3.062472, norm: 0.2903, time(ms): 796.18, token/sec:658507.31, hellaswag_acc: 0.3013
Step: 16467, loss: 3.004898, norm: 0.2985, time(ms): 801.37, token/sec:654239.89, hellaswag_acc: 0.3013
Step: 16468, loss: 3.054182, norm: 0.2828, time(ms): 798.90, token/sec:656261.47, hellaswag_acc: 0.3013
Step: 16469, loss: 3.050093, norm: 0.2972, time(ms): 794.18, token/sec:660159.38, hellaswag_acc: 0.3013
Step: 16470, loss: 3.029679, norm: 0.2691, time(ms): 791.46, token/sec:662433.42, hellaswag_acc: 0.3013
Step: 16471, loss: 3.077897, norm: 0.2981, time(ms): 794.80, token/sec:659645.70, hellaswag_acc: 0.3013
Step: 16472, loss: 3.060036, norm: 0.2940, time(ms): 804.21, token/sec:651932.16, hellaswag_acc: 0.3013
Step: 16473, loss: 3.067101, norm: 0.2761, time(ms): 793.94, token/sec:660362.78, hellaswag_acc: 0.3013
Step: 16474, loss: 3.025222, norm: 0.3007, time(ms): 799.59, token/sec:655695.76, hellaswag_acc: 0.3013
Step: 16475, loss: 3.002827, norm: 0.2986, time(ms): 792.59, token/sec:661484.12, hellaswag_acc: 0.3013
Step: 16476, loss: 3.002722, norm: 0.2756, time(ms): 787.35, token/sec:665893.46, hellaswag_acc: 0.3013
Step: 16477, loss: 3.016254, norm: 0.3063, time(ms): 791.56, token/sec:662351.02, hellaswag_acc: 0.3013
Step: 16478, loss: 2.971040, norm: 0.2790, time(ms): 795.46, token/sec:659098.23, hellaswag_acc: 0.3013
Step: 16479, loss: 2.971160, norm: 0.2765, time(ms): 798.90, token/sec:656262.26, hellaswag_acc: 0.3013
Step: 16480, loss: 3.049726, norm: 0.3189, time(ms): 799.32, token/sec:655920.67, hellaswag_acc: 0.3013
Step: 16481, loss: 2.972317, norm: 0.2811, time(ms): 803.44, token/sec:652556.65, hellaswag_acc: 0.3013
Step: 16482, loss: 3.027970, norm: 0.2869, time(ms): 788.58, token/sec:664851.20, hellaswag_acc: 0.3013
Step: 16483, loss: 2.981025, norm: 0.2814, time(ms): 790.85, token/sec:662940.87, hellaswag_acc: 0.3013
Step: 16484, loss: 2.982272, norm: 0.2816, time(ms): 797.17, token/sec:657689.78, hellaswag_acc: 0.3013
Step: 16485, loss: 3.023255, norm: 0.2713, time(ms): 1228.21, token/sec:426872.80, hellaswag_acc: 0.3013
Step: 16486, loss: 3.103451, norm: 0.3059, time(ms): 786.86, token/sec:666305.87, hellaswag_acc: 0.3013
Step: 16487, loss: 3.073313, norm: 0.2896, time(ms): 780.55, token/sec:671694.17, hellaswag_acc: 0.3013
Step: 16488, loss: 3.040878, norm: 0.2765, time(ms): 794.90, token/sec:659563.79, hellaswag_acc: 0.3013
Step: 16489, loss: 3.082626, norm: 0.3033, time(ms): 792.72, token/sec:661377.48, hellaswag_acc: 0.3013
Step: 16490, loss: 3.102712, norm: 0.3064, time(ms): 785.34, token/sec:667592.78, hellaswag_acc: 0.3013
Step: 16491, loss: 3.142429, norm: 0.2880, time(ms): 783.41, token/sec:669239.08, hellaswag_acc: 0.3013
Step: 16492, loss: 3.149548, norm: 0.3123, time(ms): 798.45, token/sec:656634.00, hellaswag_acc: 0.3013
Step: 16493, loss: 3.033693, norm: 0.2865, time(ms): 790.60, token/sec:663155.58, hellaswag_acc: 0.3013
Step: 16494, loss: 3.096121, norm: 0.3037, time(ms): 787.53, token/sec:665735.41, hellaswag_acc: 0.3013
Step: 16495, loss: 2.974065, norm: 0.4066, time(ms): 792.76, token/sec:661343.87, hellaswag_acc: 0.3013
Step: 16496, loss: 3.030873, norm: 0.3083, time(ms): 793.76, token/sec:660509.96, hellaswag_acc: 0.3013
Step: 16497, loss: 3.088899, norm: 0.3040, time(ms): 798.90, token/sec:656259.51, hellaswag_acc: 0.3013
Step: 16498, loss: 3.058416, norm: 0.2824, time(ms): 805.92, token/sec:650543.94, hellaswag_acc: 0.3013
Step: 16499, loss: 3.056413, norm: 0.2851, time(ms): 789.38, token/sec:664177.29, hellaswag_acc: 0.3013
rank 0 sample 0: Hello, I'm a language model, and I need to be able to make mistakes about grammar.
There are three things that I would need to do if
rank 0 sample 1: Hello, I'm a language model, so for me, the "global":
The default local variables are stored inside a local variable, that is, you
rank 0 sample 2: Hello, I'm a language model, so I didn't ask this question before. This is a simple problem to solve. I'm not sure how I can
rank 0 sample 3: Hello, I'm a language model, so for me I'm a model of a data model.
You are probably trying to find the model that you wish
rank 1 sample 0: Hello, I'm a language model, and so
I'm not interested yet with all this info, but I still have the
data to look at.
rank 1 sample 1: Hello, I'm a language model, not an interpreter. I'm not even my native speaker yet. Let's go to Bjarne, and I'll
rank 1 sample 2: Hello, I'm a language model, I read it every day. I have a lot of time I can spend with my students and with their parents so that
rank 1 sample 3: Hello, I'm a language model, and I'm working with another language model or language model? Which one am I? One-off, one-off
Step: 16500, loss: 3.078471, norm: 0.2778, time(ms): 3795.15, token/sec:138146.98, val_loss: 3.0850, hellaswag_acc: 0.3013
Step: 16501, loss: 3.089523, norm: 0.2864, time(ms): 783.06, token/sec:669533.72, hellaswag_acc: 0.3013
Step: 16502, loss: 3.107788, norm: 0.3087, time(ms): 791.31, token/sec:662559.76, hellaswag_acc: 0.3013
Step: 16503, loss: 3.113518, norm: 0.2771, time(ms): 792.70, token/sec:661393.20, hellaswag_acc: 0.3013
Step: 16504, loss: 3.082905, norm: 0.3110, time(ms): 805.08, token/sec:651221.11, hellaswag_acc: 0.3013
Step: 16505, loss: 3.005008, norm: 0.2806, time(ms): 796.85, token/sec:657949.72, hellaswag_acc: 0.3013
Step: 16506, loss: 2.941932, norm: 0.2966, time(ms): 795.34, token/sec:659201.37, hellaswag_acc: 0.3013
Step: 16507, loss: 3.003207, norm: 0.2899, time(ms): 801.39, token/sec:654224.12, hellaswag_acc: 0.3013
Step: 16508, loss: 2.970943, norm: 0.3113, time(ms): 801.42, token/sec:654194.93, hellaswag_acc: 0.3013
Step: 16509, loss: 2.975991, norm: 0.2738, time(ms): 797.05, token/sec:657784.40, hellaswag_acc: 0.3013
Step: 16510, loss: 2.997352, norm: 0.2690, time(ms): 791.55, token/sec:662355.40, hellaswag_acc: 0.3013
Step: 16511, loss: 3.019546, norm: 0.2802, time(ms): 793.81, token/sec:660467.11, hellaswag_acc: 0.3013
Step: 16512, loss: 2.977639, norm: 0.2768, time(ms): 795.08, token/sec:659412.29, hellaswag_acc: 0.3013
Step: 16513, loss: 2.996598, norm: 0.2659, time(ms): 791.03, token/sec:662791.01, hellaswag_acc: 0.3013
Step: 16514, loss: 2.950381, norm: 0.2563, time(ms): 786.20, token/sec:666860.73, hellaswag_acc: 0.3013
Step: 16515, loss: 2.966228, norm: 0.2813, time(ms): 787.36, token/sec:665880.76, hellaswag_acc: 0.3013
Step: 16516, loss: 3.019012, norm: 0.2748, time(ms): 799.15, token/sec:656058.44, hellaswag_acc: 0.3013
Step: 16517, loss: 3.042393, norm: 0.3062, time(ms): 799.83, token/sec:655502.06, hellaswag_acc: 0.3013
Step: 16518, loss: 3.060028, norm: 0.3056, time(ms): 791.61, token/sec:662307.13, hellaswag_acc: 0.3013
Step: 16519, loss: 3.103786, norm: 0.2991, time(ms): 790.53, token/sec:663212.19, hellaswag_acc: 0.3013
Step: 16520, loss: 3.088671, norm: 0.2930, time(ms): 794.76, token/sec:659678.94, hellaswag_acc: 0.3013
Step: 16521, loss: 3.062847, norm: 0.2769, time(ms): 791.39, token/sec:662487.70, hellaswag_acc: 0.3013
Step: 16522, loss: 3.098355, norm: 0.2827, time(ms): 790.45, token/sec:663279.60, hellaswag_acc: 0.3013
Step: 16523, loss: 3.049211, norm: 0.3397, time(ms): 795.05, token/sec:659442.14, hellaswag_acc: 0.3013
Step: 16524, loss: 3.060869, norm: 0.2719, time(ms): 796.39, token/sec:658333.04, hellaswag_acc: 0.3013
Step: 16525, loss: 3.128360, norm: 0.2856, time(ms): 793.80, token/sec:660478.42, hellaswag_acc: 0.3013
Step: 16526, loss: 3.030655, norm: 0.2847, time(ms): 788.63, token/sec:664809.19, hellaswag_acc: 0.3013
Step: 16527, loss: 3.106536, norm: 0.2972, time(ms): 791.51, token/sec:662390.92, hellaswag_acc: 0.3013
Step: 16528, loss: 3.057357, norm: 0.2802, time(ms): 788.46, token/sec:664953.73, hellaswag_acc: 0.3013
Step: 16529, loss: 3.136469, norm: 0.2956, time(ms): 789.91, token/sec:663729.64, hellaswag_acc: 0.3013
Step: 16530, loss: 3.159349, norm: 0.2833, time(ms): 788.77, token/sec:664694.24, hellaswag_acc: 0.3013
Step: 16531, loss: 3.068337, norm: 0.2764, time(ms): 791.09, token/sec:662743.67, hellaswag_acc: 0.3013
Step: 16532, loss: 3.051838, norm: 0.2946, time(ms): 795.45, token/sec:659109.69, hellaswag_acc: 0.3013
Step: 16533, loss: 3.044616, norm: 0.2871, time(ms): 793.17, token/sec:661002.34, hellaswag_acc: 0.3013
Step: 16534, loss: 3.112190, norm: 0.3241, time(ms): 790.72, token/sec:663054.81, hellaswag_acc: 0.3013
Step: 16535, loss: 3.053470, norm: 0.2880, time(ms): 790.55, token/sec:663191.98, hellaswag_acc: 0.3013
Step: 16536, loss: 3.110273, norm: 0.3190, time(ms): 800.08, token/sec:655290.52, hellaswag_acc: 0.3013
Step: 16537, loss: 3.066749, norm: 0.2971, time(ms): 799.80, token/sec:655522.38, hellaswag_acc: 0.3013
Step: 16538, loss: 3.032380, norm: 0.3058, time(ms): 800.03, token/sec:655332.89, hellaswag_acc: 0.3013
Step: 16539, loss: 3.077210, norm: 0.3129, time(ms): 797.92, token/sec:657065.05, hellaswag_acc: 0.3013
Step: 16540, loss: 3.058435, norm: 0.3000, time(ms): 793.72, token/sec:660544.68, hellaswag_acc: 0.3013
Step: 16541, loss: 3.082019, norm: 0.3139, time(ms): 795.31, token/sec:659225.68, hellaswag_acc: 0.3013
Step: 16542, loss: 3.063187, norm: 0.3022, time(ms): 792.98, token/sec:661157.76, hellaswag_acc: 0.3013
Step: 16543, loss: 3.056876, norm: 0.3101, time(ms): 801.64, token/sec:654018.07, hellaswag_acc: 0.3013
Step: 16544, loss: 3.062941, norm: 0.3109, time(ms): 791.00, token/sec:662819.98, hellaswag_acc: 0.3013
Step: 16545, loss: 3.112960, norm: 0.2892, time(ms): 789.65, token/sec:663952.09, hellaswag_acc: 0.3013
Step: 16546, loss: 3.030866, norm: 0.2845, time(ms): 789.41, token/sec:664148.00, hellaswag_acc: 0.3013
Step: 16547, loss: 3.084923, norm: 0.2957, time(ms): 794.04, token/sec:660279.90, hellaswag_acc: 0.3013
Step: 16548, loss: 3.117083, norm: 0.2874, time(ms): 791.10, token/sec:662732.28, hellaswag_acc: 0.3013
Step: 16549, loss: 3.076330, norm: 0.3095, time(ms): 803.47, token/sec:652526.06, hellaswag_acc: 0.3013
Step: 16550, loss: 3.112275, norm: 0.3150, time(ms): 805.27, token/sec:651071.30, hellaswag_acc: 0.3013
Step: 16551, loss: 3.207592, norm: 0.3915, time(ms): 799.68, token/sec:655624.01, hellaswag_acc: 0.3013
Step: 16552, loss: 2.977054, norm: 0.3233, time(ms): 792.75, token/sec:661356.60, hellaswag_acc: 0.3013
Step: 16553, loss: 2.990624, norm: 0.3035, time(ms): 802.96, token/sec:652945.34, hellaswag_acc: 0.3013
Step: 16554, loss: 3.022224, norm: 0.3813, time(ms): 804.21, token/sec:651931.00, hellaswag_acc: 0.3013
Step: 16555, loss: 3.020042, norm: 0.2981, time(ms): 798.06, token/sec:656955.12, hellaswag_acc: 0.3013
Step: 16556, loss: 3.008125, norm: 0.3275, time(ms): 790.58, token/sec:663171.18, hellaswag_acc: 0.3013
Step: 16557, loss: 3.018277, norm: 0.3032, time(ms): 795.04, token/sec:659450.85, hellaswag_acc: 0.3013
Step: 16558, loss: 2.987556, norm: 0.2943, time(ms): 794.97, token/sec:659507.81, hellaswag_acc: 0.3013
Step: 16559, loss: 2.978463, norm: 0.2992, time(ms): 792.85, token/sec:661268.69, hellaswag_acc: 0.3013
Step: 16560, loss: 3.024462, norm: 0.3041, time(ms): 789.53, token/sec:664048.73, hellaswag_acc: 0.3013
Step: 16561, loss: 3.014382, norm: 0.2914, time(ms): 794.79, token/sec:659655.99, hellaswag_acc: 0.3013
Step: 16562, loss: 3.028747, norm: 0.2883, time(ms): 799.14, token/sec:656061.18, hellaswag_acc: 0.3013
Step: 16563, loss: 2.973817, norm: 0.2835, time(ms): 800.42, token/sec:655014.52, hellaswag_acc: 0.3013
Step: 16564, loss: 3.117134, norm: 0.3148, time(ms): 802.17, token/sec:653587.11, hellaswag_acc: 0.3013
Step: 16565, loss: 3.153473, norm: 0.3039, time(ms): 796.30, token/sec:658405.57, hellaswag_acc: 0.3013
Step: 16566, loss: 3.133853, norm: 0.2985, time(ms): 799.17, token/sec:656039.65, hellaswag_acc: 0.3013
Step: 16567, loss: 3.125266, norm: 0.2992, time(ms): 800.23, token/sec:655169.86, hellaswag_acc: 0.3013
Step: 16568, loss: 3.035569, norm: 0.2881, time(ms): 801.94, token/sec:653777.74, hellaswag_acc: 0.3013
Step: 16569, loss: 3.150110, norm: 0.2788, time(ms): 800.27, token/sec:655139.41, hellaswag_acc: 0.3013
Step: 16570, loss: 3.069146, norm: 0.2849, time(ms): 794.05, token/sec:660268.40, hellaswag_acc: 0.3013
Step: 16571, loss: 3.105253, norm: 0.2966, time(ms): 803.61, token/sec:652413.39, hellaswag_acc: 0.3013
Step: 16572, loss: 3.085942, norm: 0.2672, time(ms): 802.69, token/sec:653162.36, hellaswag_acc: 0.3013
Step: 16573, loss: 3.123286, norm: 0.2852, time(ms): 791.55, token/sec:662358.60, hellaswag_acc: 0.3013
Step: 16574, loss: 3.067599, norm: 0.2866, time(ms): 792.04, token/sec:661949.46, hellaswag_acc: 0.3013
Step: 16575, loss: 3.105386, norm: 0.2850, time(ms): 792.19, token/sec:661825.15, hellaswag_acc: 0.3013
Step: 16576, loss: 3.064465, norm: 0.2726, time(ms): 796.47, token/sec:658263.27, hellaswag_acc: 0.3013
Step: 16577, loss: 3.087206, norm: 0.2772, time(ms): 790.48, token/sec:663254.19, hellaswag_acc: 0.3013
Step: 16578, loss: 3.028540, norm: 0.2987, time(ms): 783.46, token/sec:669199.57, hellaswag_acc: 0.3013
Step: 16579, loss: 3.038900, norm: 0.2855, time(ms): 786.33, token/sec:666753.76, hellaswag_acc: 0.3013
Step: 16580, loss: 3.137463, norm: 0.3109, time(ms): 805.62, token/sec:650784.78, hellaswag_acc: 0.3013
Step: 16581, loss: 3.065626, norm: 0.3035, time(ms): 800.94, token/sec:654590.24, hellaswag_acc: 0.3013
Step: 16582, loss: 3.094124, norm: 0.3083, time(ms): 796.98, token/sec:657839.90, hellaswag_acc: 0.3013
Step: 16583, loss: 3.087194, norm: 0.3066, time(ms): 793.44, token/sec:660780.48, hellaswag_acc: 0.3013
Step: 16584, loss: 3.104424, norm: 0.2784, time(ms): 804.93, token/sec:651345.91, hellaswag_acc: 0.3013
Step: 16585, loss: 3.097565, norm: 0.2972, time(ms): 805.76, token/sec:650678.29, hellaswag_acc: 0.3013
Step: 16586, loss: 3.051373, norm: 0.2991, time(ms): 793.51, token/sec:660716.35, hellaswag_acc: 0.3013
Step: 16587, loss: 3.060634, norm: 0.3148, time(ms): 802.20, token/sec:653559.92, hellaswag_acc: 0.3013
Step: 16588, loss: 3.070754, norm: 0.3092, time(ms): 801.30, token/sec:654297.90, hellaswag_acc: 0.3013
Step: 16589, loss: 3.110318, norm: 0.2733, time(ms): 800.75, token/sec:654744.21, hellaswag_acc: 0.3013
Step: 16590, loss: 3.029365, norm: 0.2996, time(ms): 788.77, token/sec:664689.62, hellaswag_acc: 0.3013
Step: 16591, loss: 3.135267, norm: 0.3095, time(ms): 792.32, token/sec:661708.84, hellaswag_acc: 0.3013
Step: 16592, loss: 3.078859, norm: 0.3094, time(ms): 793.12, token/sec:661047.05, hellaswag_acc: 0.3013
Step: 16593, loss: 3.066219, norm: 0.2810, time(ms): 797.35, token/sec:657540.91, hellaswag_acc: 0.3013
Step: 16594, loss: 3.101189, norm: 0.2947, time(ms): 788.56, token/sec:664864.87, hellaswag_acc: 0.3013
Step: 16595, loss: 3.090874, norm: 0.2740, time(ms): 793.31, token/sec:660882.55, hellaswag_acc: 0.3013
Step: 16596, loss: 3.095853, norm: 0.2843, time(ms): 798.99, token/sec:656185.30, hellaswag_acc: 0.3013
Step: 16597, loss: 3.067681, norm: 0.2716, time(ms): 805.71, token/sec:650713.72, hellaswag_acc: 0.3013
Step: 16598, loss: 2.980803, norm: 0.2887, time(ms): 794.38, token/sec:659999.09, hellaswag_acc: 0.3013
Step: 16599, loss: 2.951585, norm: 0.2920, time(ms): 792.51, token/sec:661551.98, hellaswag_acc: 0.3013
Step: 16600, loss: 3.001690, norm: 0.2927, time(ms): 792.34, token/sec:661692.32, hellaswag_acc: 0.3013
Step: 16601, loss: 3.002633, norm: 0.3062, time(ms): 798.45, token/sec:656630.66, hellaswag_acc: 0.3013
Step: 16602, loss: 2.979459, norm: 0.2678, time(ms): 797.41, token/sec:657487.63, hellaswag_acc: 0.3013
Step: 16603, loss: 3.008275, norm: 0.2657, time(ms): 792.92, token/sec:661215.61, hellaswag_acc: 0.3013
Step: 16604, loss: 2.984754, norm: 0.2979, time(ms): 785.64, token/sec:667336.91, hellaswag_acc: 0.3013
Step: 16605, loss: 3.026792, norm: 0.2798, time(ms): 792.58, token/sec:661496.66, hellaswag_acc: 0.3013
Step: 16606, loss: 3.022031, norm: 0.2866, time(ms): 792.90, token/sec:661228.53, hellaswag_acc: 0.3013
Step: 16607, loss: 2.998084, norm: 0.2761, time(ms): 793.47, token/sec:660755.86, hellaswag_acc: 0.3013
Step: 16608, loss: 2.967161, norm: 0.2811, time(ms): 797.85, token/sec:657128.27, hellaswag_acc: 0.3013
Step: 16609, loss: 3.042417, norm: 0.2815, time(ms): 802.43, token/sec:653371.75, hellaswag_acc: 0.3013
Step: 16610, loss: 3.085279, norm: 0.2986, time(ms): 803.44, token/sec:652556.85, hellaswag_acc: 0.3013
Step: 16611, loss: 3.249585, norm: 0.3389, time(ms): 795.82, token/sec:658803.43, hellaswag_acc: 0.3013
Step: 16612, loss: 3.087460, norm: 0.2918, time(ms): 802.45, token/sec:653357.00, hellaswag_acc: 0.3013
Step: 16613, loss: 3.112718, norm: 0.3453, time(ms): 803.18, token/sec:652765.27, hellaswag_acc: 0.3013
Step: 16614, loss: 3.060494, norm: 0.2992, time(ms): 794.64, token/sec:659778.89, hellaswag_acc: 0.3013
Step: 16615, loss: 3.070329, norm: 0.3022, time(ms): 796.36, token/sec:658354.12, hellaswag_acc: 0.3013
Step: 16616, loss: 3.080927, norm: 0.2995, time(ms): 805.44, token/sec:650933.11, hellaswag_acc: 0.3013
Step: 16617, loss: 3.098206, norm: 0.3230, time(ms): 802.65, token/sec:653200.19, hellaswag_acc: 0.3013
Step: 16618, loss: 3.091993, norm: 0.2943, time(ms): 790.01, token/sec:663649.52, hellaswag_acc: 0.3013
Step: 16619, loss: 3.064500, norm: 0.2986, time(ms): 798.91, token/sec:656257.75, hellaswag_acc: 0.3013
Step: 16620, loss: 3.109894, norm: 0.3007, time(ms): 791.82, token/sec:662131.64, hellaswag_acc: 0.3013
Step: 16621, loss: 3.108533, norm: 0.2920, time(ms): 788.71, token/sec:664737.24, hellaswag_acc: 0.3013
Step: 16622, loss: 3.122604, norm: 0.3262, time(ms): 791.57, token/sec:662338.05, hellaswag_acc: 0.3013
Step: 16623, loss: 3.124793, norm: 0.3168, time(ms): 787.77, token/sec:665537.75, hellaswag_acc: 0.3013
Step: 16624, loss: 3.076239, norm: 0.3066, time(ms): 793.55, token/sec:660683.80, hellaswag_acc: 0.3013
Step: 16625, loss: 3.142536, norm: 0.2923, time(ms): 794.01, token/sec:660305.08, hellaswag_acc: 0.3013
Step: 16626, loss: 3.047687, norm: 0.2760, time(ms): 791.74, token/sec:662200.23, hellaswag_acc: 0.3013
Step: 16627, loss: 3.053331, norm: 0.3145, time(ms): 788.80, token/sec:664664.11, hellaswag_acc: 0.3013
Step: 16628, loss: 3.087518, norm: 0.3670, time(ms): 791.33, token/sec:662539.00, hellaswag_acc: 0.3013
Step: 16629, loss: 3.123488, norm: 0.2827, time(ms): 790.82, token/sec:662969.05, hellaswag_acc: 0.3013
Step: 16630, loss: 3.157856, norm: 0.3172, time(ms): 792.83, token/sec:661290.17, hellaswag_acc: 0.3013
Step: 16631, loss: 3.110533, norm: 0.3179, time(ms): 803.33, token/sec:652645.35, hellaswag_acc: 0.3013
Step: 16632, loss: 3.116027, norm: 0.3093, time(ms): 802.12, token/sec:653624.41, hellaswag_acc: 0.3013
Step: 16633, loss: 3.101187, norm: 0.2765, time(ms): 791.03, token/sec:662788.21, hellaswag_acc: 0.3013
Step: 16634, loss: 3.071369, norm: 0.2831, time(ms): 806.83, token/sec:649811.90, hellaswag_acc: 0.3013
Step: 16635, loss: 3.052338, norm: 0.2828, time(ms): 801.81, token/sec:653876.69, hellaswag_acc: 0.3013
Step: 16636, loss: 3.053343, norm: 0.2683, time(ms): 789.75, token/sec:663869.91, hellaswag_acc: 0.3013
Step: 16637, loss: 3.084394, norm: 0.2849, time(ms): 801.23, token/sec:654350.66, hellaswag_acc: 0.3013
Step: 16638, loss: 3.079145, norm: 0.2907, time(ms): 806.10, token/sec:650399.24, hellaswag_acc: 0.3013
Step: 16639, loss: 3.136795, norm: 0.3131, time(ms): 802.82, token/sec:653058.19, hellaswag_acc: 0.3013
Step: 16640, loss: 3.068689, norm: 0.2984, time(ms): 785.97, token/sec:667057.96, hellaswag_acc: 0.3013
Step: 16641, loss: 3.087379, norm: 0.3292, time(ms): 789.00, token/sec:664496.20, hellaswag_acc: 0.3013
Step: 16642, loss: 3.001820, norm: 0.2803, time(ms): 798.37, token/sec:656696.94, hellaswag_acc: 0.3013
Step: 16643, loss: 3.081742, norm: 0.2870, time(ms): 793.89, token/sec:660401.26, hellaswag_acc: 0.3013
Step: 16644, loss: 3.078938, norm: 0.2888, time(ms): 790.44, token/sec:663289.60, hellaswag_acc: 0.3013
Step: 16645, loss: 3.057568, norm: 0.2791, time(ms): 798.24, token/sec:656807.76, hellaswag_acc: 0.3013
Step: 16646, loss: 2.968206, norm: 0.3015, time(ms): 799.66, token/sec:655642.19, hellaswag_acc: 0.3013
Step: 16647, loss: 2.990314, norm: 0.2802, time(ms): 800.93, token/sec:654596.28, hellaswag_acc: 0.3013
Step: 16648, loss: 2.982464, norm: 0.3019, time(ms): 798.52, token/sec:656576.75, hellaswag_acc: 0.3013
Step: 16649, loss: 3.014002, norm: 0.2959, time(ms): 797.91, token/sec:657072.90, hellaswag_acc: 0.3013
Step: 16650, loss: 2.964600, norm: 0.2851, time(ms): 799.98, token/sec:655377.81, hellaswag_acc: 0.3013
Step: 16651, loss: 3.000822, norm: 0.3130, time(ms): 800.10, token/sec:655277.04, hellaswag_acc: 0.3013
Step: 16652, loss: 3.003268, norm: 0.3117, time(ms): 802.31, token/sec:653471.94, hellaswag_acc: 0.3013
Step: 16653, loss: 3.014323, norm: 0.2942, time(ms): 798.99, token/sec:656192.15, hellaswag_acc: 0.3013
Step: 16654, loss: 2.989581, norm: 0.2930, time(ms): 797.52, token/sec:657397.80, hellaswag_acc: 0.3013
Step: 16655, loss: 2.957158, norm: 0.2819, time(ms): 799.48, token/sec:655788.84, hellaswag_acc: 0.3013
Step: 16656, loss: 2.960816, norm: 0.2712, time(ms): 802.23, token/sec:653536.03, hellaswag_acc: 0.3013
Step: 16657, loss: 3.023249, norm: 0.2790, time(ms): 799.48, token/sec:655783.55, hellaswag_acc: 0.3013
Step: 16658, loss: 3.060050, norm: 0.3156, time(ms): 798.69, token/sec:656438.76, hellaswag_acc: 0.3013
Step: 16659, loss: 3.126723, norm: 0.2889, time(ms): 801.23, token/sec:654353.00, hellaswag_acc: 0.3013
Step: 16660, loss: 3.118498, norm: 0.2856, time(ms): 800.41, token/sec:655022.32, hellaswag_acc: 0.3013
Step: 16661, loss: 3.110084, norm: 0.2956, time(ms): 801.32, token/sec:654277.26, hellaswag_acc: 0.3013
Step: 16662, loss: 3.101145, norm: 0.2907, time(ms): 793.19, token/sec:660989.03, hellaswag_acc: 0.3013
Step: 16663, loss: 3.103360, norm: 0.3036, time(ms): 799.90, token/sec:655442.67, hellaswag_acc: 0.3013
Step: 16664, loss: 3.112008, norm: 0.3180, time(ms): 806.55, token/sec:650036.83, hellaswag_acc: 0.3013
Step: 16665, loss: 3.170307, norm: 0.2945, time(ms): 791.74, token/sec:662197.63, hellaswag_acc: 0.3013
Step: 16666, loss: 3.155421, norm: 0.3059, time(ms): 798.10, token/sec:656918.62, hellaswag_acc: 0.3013
Step: 16667, loss: 3.071518, norm: 0.3120, time(ms): 791.79, token/sec:662157.75, hellaswag_acc: 0.3013
Step: 16668, loss: 3.120614, norm: 0.3081, time(ms): 795.71, token/sec:658891.07, hellaswag_acc: 0.3013
Step: 16669, loss: 3.120749, norm: 0.3165, time(ms): 798.65, token/sec:656466.00, hellaswag_acc: 0.3013
Step: 16670, loss: 3.102463, norm: 0.2995, time(ms): 795.91, token/sec:658730.01, hellaswag_acc: 0.3013
Step: 16671, loss: 3.075171, norm: 0.2993, time(ms): 798.90, token/sec:656265.98, hellaswag_acc: 0.3013
Step: 16672, loss: 3.146648, norm: 0.3131, time(ms): 790.45, token/sec:663279.60, hellaswag_acc: 0.3013
Step: 16673, loss: 3.161938, norm: 0.3217, time(ms): 787.03, token/sec:666159.53, hellaswag_acc: 0.3013
Step: 16674, loss: 3.154845, norm: 0.3129, time(ms): 792.49, token/sec:661569.69, hellaswag_acc: 0.3013
Step: 16675, loss: 3.117103, norm: 0.3363, time(ms): 788.89, token/sec:664592.19, hellaswag_acc: 0.3013
Step: 16676, loss: 3.053249, norm: 0.3310, time(ms): 1450.18, token/sec:361532.74, hellaswag_acc: 0.3013
Step: 16677, loss: 3.083390, norm: 0.3060, time(ms): 799.46, token/sec:655800.37, hellaswag_acc: 0.3013
Step: 16678, loss: 3.006240, norm: 0.3074, time(ms): 789.59, token/sec:663996.39, hellaswag_acc: 0.3013
Step: 16679, loss: 3.002893, norm: 0.2962, time(ms): 788.19, token/sec:665177.19, hellaswag_acc: 0.3013
Step: 16680, loss: 3.029388, norm: 0.2925, time(ms): 783.84, token/sec:668873.28, hellaswag_acc: 0.3013
Step: 16681, loss: 3.013603, norm: 0.2862, time(ms): 793.10, token/sec:661059.17, hellaswag_acc: 0.3013
Step: 16682, loss: 3.057356, norm: 0.2920, time(ms): 802.60, token/sec:653234.34, hellaswag_acc: 0.3013
Step: 16683, loss: 3.039288, norm: 0.2954, time(ms): 791.72, token/sec:662210.00, hellaswag_acc: 0.3013
Step: 16684, loss: 3.103216, norm: 0.3002, time(ms): 804.92, token/sec:651355.36, hellaswag_acc: 0.3013
Step: 16685, loss: 3.113759, norm: 0.3235, time(ms): 797.28, token/sec:657599.11, hellaswag_acc: 0.3013
Step: 16686, loss: 3.060030, norm: 0.3111, time(ms): 804.17, token/sec:651964.64, hellaswag_acc: 0.3013
Step: 16687, loss: 3.058017, norm: 0.3041, time(ms): 801.50, token/sec:654129.54, hellaswag_acc: 0.3013
Step: 16688, loss: 3.033406, norm: 0.3154, time(ms): 793.47, token/sec:660752.68, hellaswag_acc: 0.3013
Step: 16689, loss: 3.092097, norm: 0.2864, time(ms): 799.58, token/sec:655701.43, hellaswag_acc: 0.3013
Step: 16690, loss: 3.036309, norm: 0.3229, time(ms): 806.46, token/sec:650108.90, hellaswag_acc: 0.3013
Step: 16691, loss: 3.048250, norm: 0.3006, time(ms): 787.44, token/sec:665814.02, hellaswag_acc: 0.3013
Step: 16692, loss: 3.081114, norm: 0.2794, time(ms): 788.10, token/sec:665258.49, hellaswag_acc: 0.3013
Step: 16693, loss: 3.043979, norm: 0.2910, time(ms): 798.18, token/sec:656854.85, hellaswag_acc: 0.3013
Step: 16694, loss: 3.073357, norm: 0.2813, time(ms): 790.43, token/sec:663298.61, hellaswag_acc: 0.3013
Step: 16695, loss: 3.104594, norm: 0.2825, time(ms): 788.37, token/sec:665028.33, hellaswag_acc: 0.3013
Step: 16696, loss: 3.059394, norm: 0.3093, time(ms): 797.90, token/sec:657086.06, hellaswag_acc: 0.3013
Step: 16697, loss: 3.029969, norm: 0.2825, time(ms): 801.45, token/sec:654171.57, hellaswag_acc: 0.3013
Step: 16698, loss: 3.131090, norm: 0.4215, time(ms): 798.60, token/sec:656509.32, hellaswag_acc: 0.3013
Step: 16699, loss: 3.051517, norm: 0.3141, time(ms): 794.21, token/sec:660135.80, hellaswag_acc: 0.3013
Step: 16700, loss: 3.049177, norm: 0.2989, time(ms): 788.34, token/sec:665049.85, hellaswag_acc: 0.3013
Step: 16701, loss: 3.033742, norm: 0.2878, time(ms): 804.56, token/sec:651643.35, hellaswag_acc: 0.3013
Step: 16702, loss: 3.059177, norm: 0.2933, time(ms): 795.61, token/sec:658976.37, hellaswag_acc: 0.3013
Step: 16703, loss: 3.107241, norm: 0.2928, time(ms): 794.18, token/sec:660158.79, hellaswag_acc: 0.3013
Step: 16704, loss: 3.062573, norm: 0.2899, time(ms): 790.54, token/sec:663199.78, hellaswag_acc: 0.3013
Step: 16705, loss: 3.139168, norm: 0.3135, time(ms): 787.86, token/sec:665459.00, hellaswag_acc: 0.3013
Step: 16706, loss: 3.082472, norm: 0.2875, time(ms): 791.27, token/sec:662592.70, hellaswag_acc: 0.3013
Step: 16707, loss: 3.065161, norm: 0.2888, time(ms): 794.77, token/sec:659672.01, hellaswag_acc: 0.3013
Step: 16708, loss: 3.016493, norm: 0.2780, time(ms): 801.38, token/sec:654228.79, hellaswag_acc: 0.3013
Step: 16709, loss: 3.036810, norm: 0.2955, time(ms): 803.68, token/sec:652362.10, hellaswag_acc: 0.3013
Step: 16710, loss: 3.032320, norm: 0.2836, time(ms): 795.85, token/sec:658780.34, hellaswag_acc: 0.3013
Step: 16711, loss: 3.068185, norm: 0.2583, time(ms): 798.93, token/sec:656236.60, hellaswag_acc: 0.3013
Step: 16712, loss: 3.065658, norm: 0.2779, time(ms): 803.38, token/sec:652605.26, hellaswag_acc: 0.3013
Step: 16713, loss: 3.060127, norm: 0.3058, time(ms): 801.00, token/sec:654539.39, hellaswag_acc: 0.3013
Step: 16714, loss: 3.046696, norm: 0.2884, time(ms): 791.64, token/sec:662276.81, hellaswag_acc: 0.3013
Step: 16715, loss: 3.046981, norm: 0.3001, time(ms): 806.12, token/sec:650384.82, hellaswag_acc: 0.3013
Step: 16716, loss: 3.060315, norm: 0.2822, time(ms): 802.08, token/sec:653660.16, hellaswag_acc: 0.3013
Step: 16717, loss: 3.016497, norm: 0.2953, time(ms): 797.89, token/sec:657096.66, hellaswag_acc: 0.3013
Step: 16718, loss: 2.982442, norm: 0.2850, time(ms): 793.15, token/sec:661019.43, hellaswag_acc: 0.3013
Step: 16719, loss: 3.080027, norm: 0.2831, time(ms): 802.97, token/sec:652932.93, hellaswag_acc: 0.3013
Step: 16720, loss: 3.055010, norm: 0.3061, time(ms): 804.00, token/sec:652097.65, hellaswag_acc: 0.3013
Step: 16721, loss: 3.073147, norm: 0.2904, time(ms): 796.01, token/sec:658647.34, hellaswag_acc: 0.3013
Step: 16722, loss: 3.102156, norm: 0.3081, time(ms): 805.60, token/sec:650804.24, hellaswag_acc: 0.3013
Step: 16723, loss: 3.109738, norm: 0.3024, time(ms): 794.70, token/sec:659728.22, hellaswag_acc: 0.3013
Step: 16724, loss: 3.032930, norm: 0.2864, time(ms): 803.33, token/sec:652646.32, hellaswag_acc: 0.3013
Step: 16725, loss: 3.188479, norm: 0.4086, time(ms): 795.65, token/sec:658940.23, hellaswag_acc: 0.3013
Step: 16726, loss: 3.077339, norm: 0.2894, time(ms): 803.39, token/sec:652594.22, hellaswag_acc: 0.3013
Step: 16727, loss: 3.059657, norm: 0.3040, time(ms): 800.58, token/sec:654886.16, hellaswag_acc: 0.3013
Step: 16728, loss: 3.059362, norm: 0.3036, time(ms): 799.68, token/sec:655622.64, hellaswag_acc: 0.3013
Step: 16729, loss: 3.107081, norm: 0.2948, time(ms): 791.81, token/sec:662135.23, hellaswag_acc: 0.3013
Step: 16730, loss: 3.224571, norm: 0.3560, time(ms): 802.36, token/sec:653434.66, hellaswag_acc: 0.3013
Step: 16731, loss: 3.099537, norm: 0.3311, time(ms): 804.21, token/sec:651932.16, hellaswag_acc: 0.3013
Step: 16732, loss: 3.075859, norm: 0.3220, time(ms): 802.16, token/sec:653592.36, hellaswag_acc: 0.3013
Step: 16733, loss: 3.057764, norm: 0.2935, time(ms): 793.90, token/sec:660398.48, hellaswag_acc: 0.3013
Step: 16734, loss: 3.062340, norm: 0.3242, time(ms): 800.40, token/sec:655035.98, hellaswag_acc: 0.3013
Step: 16735, loss: 3.077983, norm: 0.2938, time(ms): 805.28, token/sec:651063.39, hellaswag_acc: 0.3013
Step: 16736, loss: 3.083788, norm: 0.2919, time(ms): 796.76, token/sec:658025.52, hellaswag_acc: 0.3013
Step: 16737, loss: 3.147046, norm: 0.3295, time(ms): 790.13, token/sec:663544.79, hellaswag_acc: 0.3013
Step: 16738, loss: 3.079314, norm: 0.3336, time(ms): 790.07, token/sec:663600.05, hellaswag_acc: 0.3013
Step: 16739, loss: 3.048265, norm: 0.2919, time(ms): 797.17, token/sec:657684.47, hellaswag_acc: 0.3013
Step: 16740, loss: 3.016384, norm: 0.3067, time(ms): 791.87, token/sec:662091.76, hellaswag_acc: 0.3013
Step: 16741, loss: 3.068285, norm: 0.3419, time(ms): 788.55, token/sec:664878.94, hellaswag_acc: 0.3013
Step: 16742, loss: 3.049418, norm: 0.2844, time(ms): 799.45, token/sec:655810.74, hellaswag_acc: 0.3013
Step: 16743, loss: 3.064171, norm: 0.3115, time(ms): 799.27, token/sec:655961.18, hellaswag_acc: 0.3013
Step: 16744, loss: 3.008375, norm: 0.3438, time(ms): 801.30, token/sec:654296.14, hellaswag_acc: 0.3013
Step: 16745, loss: 3.072105, norm: 0.2895, time(ms): 799.44, token/sec:655818.76, hellaswag_acc: 0.3013
Step: 16746, loss: 3.053164, norm: 0.3069, time(ms): 795.22, token/sec:659297.03, hellaswag_acc: 0.3013
Step: 16747, loss: 3.028199, norm: 0.3578, time(ms): 803.12, token/sec:652813.33, hellaswag_acc: 0.3013
Step: 16748, loss: 3.114327, norm: 0.3150, time(ms): 801.70, token/sec:653967.50, hellaswag_acc: 0.3013
Step: 16749, loss: 3.031614, norm: 0.3089, time(ms): 799.06, token/sec:656134.98, hellaswag_acc: 0.3013
rank 0 sample 0: Hello, I'm a language model, so I want to know, and do math right?
The language model can be very efficient when we need to model
rank 0 sample 1: Hello, I'm a language model, and now I'm learning more about you. So then as you start coming over, let's start on your own.
rank 0 sample 2: Hello, I'm a language model, and I really need to teach grammar because I was having a difficult day with my classes, and I was having trouble using
rank 0 sample 3: Hello, I'm a language model, which we're trying to do. Let me test your language model so that we can find how many strings you have (
rank 1 sample 0: Hello, I'm a language model, this is the language model, this approach, these models are built on top of the other model which is the language model
rank 1 sample 1: Hello, I'm a language model, not an interpreter. I'm using it in my classroom!
To illustrate that I already know what a language model is
rank 1 sample 2: Hello, I'm a language model, I won't talk about it, but I'll keep talking what the model is.
The basic thing to keep in
rank 1 sample 3: Hello, I'm a language model, so I'm interested to discover more about something.
Last Updated: 12
- Learn in Spanish
- Learn in
Step: 16750, loss: 3.000757, norm: 0.2983, time(ms): 3791.04, token/sec:138296.51, val_loss: 3.0830, hellaswag_acc: 0.3013
Step: 16751, loss: 3.026757, norm: 0.3012, time(ms): 791.42, token/sec:662467.94, hellaswag_acc: 0.3013
Step: 16752, loss: 3.056119, norm: 0.3197, time(ms): 788.65, token/sec:664791.90, hellaswag_acc: 0.3013
Step: 16753, loss: 3.016258, norm: 0.2837, time(ms): 789.39, token/sec:664164.85, hellaswag_acc: 0.3013
Step: 16754, loss: 3.008471, norm: 0.3003, time(ms): 791.26, token/sec:662600.89, hellaswag_acc: 0.3013
Step: 16755, loss: 3.050602, norm: 0.3214, time(ms): 788.57, token/sec:664860.84, hellaswag_acc: 0.3013
Step: 16756, loss: 3.068267, norm: 0.2951, time(ms): 795.94, token/sec:658705.94, hellaswag_acc: 0.3013
Step: 16757, loss: 3.040877, norm: 0.3029, time(ms): 803.27, token/sec:652689.52, hellaswag_acc: 0.3013
Step: 16758, loss: 3.090901, norm: 0.3059, time(ms): 803.12, token/sec:652812.36, hellaswag_acc: 0.3013
Step: 16759, loss: 3.101095, norm: 0.3233, time(ms): 797.02, token/sec:657807.03, hellaswag_acc: 0.3013
Step: 16760, loss: 3.054906, norm: 0.3033, time(ms): 790.56, token/sec:663187.78, hellaswag_acc: 0.3013
Step: 16761, loss: 3.071024, norm: 0.2893, time(ms): 790.01, token/sec:663648.32, hellaswag_acc: 0.3013
Step: 16762, loss: 3.081685, norm: 0.2961, time(ms): 798.36, token/sec:656706.35, hellaswag_acc: 0.3013
Step: 16763, loss: 3.049857, norm: 0.3257, time(ms): 794.60, token/sec:659811.75, hellaswag_acc: 0.3013
Step: 16764, loss: 3.085309, norm: 0.2784, time(ms): 786.91, token/sec:666258.83, hellaswag_acc: 0.3013
Step: 16765, loss: 3.080562, norm: 0.3587, time(ms): 793.14, token/sec:661030.36, hellaswag_acc: 0.3013
Step: 16766, loss: 3.039663, norm: 0.3285, time(ms): 803.49, token/sec:652517.15, hellaswag_acc: 0.3013
Step: 16767, loss: 3.051108, norm: 0.3081, time(ms): 803.44, token/sec:652556.85, hellaswag_acc: 0.3013
Step: 16768, loss: 3.009593, norm: 0.2941, time(ms): 790.79, token/sec:662993.44, hellaswag_acc: 0.3013
Step: 16769, loss: 3.058668, norm: 0.3438, time(ms): 793.41, token/sec:660804.71, hellaswag_acc: 0.3013
Step: 16770, loss: 3.083899, norm: 0.3012, time(ms): 794.85, token/sec:659608.69, hellaswag_acc: 0.3013
Step: 16771, loss: 3.039475, norm: 0.2912, time(ms): 800.70, token/sec:654786.91, hellaswag_acc: 0.3013
Step: 16772, loss: 3.039903, norm: 0.2779, time(ms): 802.73, token/sec:653134.61, hellaswag_acc: 0.3013
Step: 16773, loss: 3.072819, norm: 0.2987, time(ms): 784.62, token/sec:668203.18, hellaswag_acc: 0.3013
Step: 16774, loss: 3.062375, norm: 0.3000, time(ms): 792.14, token/sec:661860.41, hellaswag_acc: 0.3013
Step: 16775, loss: 3.096332, norm: 0.2807, time(ms): 787.80, token/sec:665512.58, hellaswag_acc: 0.3013
Step: 16776, loss: 3.096599, norm: 0.2878, time(ms): 790.32, token/sec:663387.05, hellaswag_acc: 0.3013
Step: 16777, loss: 3.022993, norm: 0.2850, time(ms): 801.02, token/sec:654525.95, hellaswag_acc: 0.3013
Step: 16778, loss: 3.043141, norm: 0.2776, time(ms): 793.56, token/sec:660682.61, hellaswag_acc: 0.3013
Step: 16779, loss: 3.021375, norm: 0.2950, time(ms): 802.96, token/sec:652943.59, hellaswag_acc: 0.3013
Step: 16780, loss: 3.079008, norm: 0.2766, time(ms): 801.40, token/sec:654212.64, hellaswag_acc: 0.3013
Step: 16781, loss: 3.014543, norm: 0.2729, time(ms): 799.15, token/sec:656060.59, hellaswag_acc: 0.3013
Step: 16782, loss: 3.030187, norm: 0.2723, time(ms): 791.33, token/sec:662536.21, hellaswag_acc: 0.3013
Step: 16783, loss: 3.091980, norm: 0.2751, time(ms): 791.20, token/sec:662651.20, hellaswag_acc: 0.3013
Step: 16784, loss: 3.060801, norm: 0.2954, time(ms): 800.81, token/sec:654693.34, hellaswag_acc: 0.3013
Step: 16785, loss: 3.049896, norm: 0.2607, time(ms): 792.26, token/sec:661763.61, hellaswag_acc: 0.3013
Step: 16786, loss: 2.988260, norm: 0.2672, time(ms): 790.19, token/sec:663492.33, hellaswag_acc: 0.3013
Step: 16787, loss: 3.100183, norm: 0.2978, time(ms): 790.47, token/sec:663261.79, hellaswag_acc: 0.3013
Step: 16788, loss: 3.028383, norm: 0.2684, time(ms): 798.91, token/sec:656251.09, hellaswag_acc: 0.3013
Step: 16789, loss: 3.007509, norm: 0.2873, time(ms): 805.47, token/sec:650911.53, hellaswag_acc: 0.3013
Step: 16790, loss: 3.052040, norm: 0.3071, time(ms): 793.22, token/sec:660958.63, hellaswag_acc: 0.3013
Step: 16791, loss: 3.007152, norm: 0.3002, time(ms): 795.77, token/sec:658847.44, hellaswag_acc: 0.3013
Step: 16792, loss: 3.066243, norm: 0.3000, time(ms): 792.89, token/sec:661237.48, hellaswag_acc: 0.3013
Step: 16793, loss: 3.105206, norm: 0.3391, time(ms): 796.28, token/sec:658425.68, hellaswag_acc: 0.3013
Step: 16794, loss: 3.064021, norm: 0.3138, time(ms): 795.24, token/sec:659282.40, hellaswag_acc: 0.3013
Step: 16795, loss: 3.073153, norm: 0.2932, time(ms): 797.25, token/sec:657622.31, hellaswag_acc: 0.3013
Step: 16796, loss: 3.040741, norm: 0.3342, time(ms): 791.08, token/sec:662746.86, hellaswag_acc: 0.3013
Step: 16797, loss: 3.009574, norm: 0.2943, time(ms): 788.46, token/sec:664951.92, hellaswag_acc: 0.3013
Step: 16798, loss: 3.109524, norm: 0.2961, time(ms): 790.18, token/sec:663500.54, hellaswag_acc: 0.3013
Step: 16799, loss: 3.042743, norm: 0.2787, time(ms): 794.59, token/sec:659824.23, hellaswag_acc: 0.3013
Step: 16800, loss: 3.037441, norm: 0.2903, time(ms): 798.72, token/sec:656414.27, hellaswag_acc: 0.3013
Step: 16801, loss: 3.010834, norm: 0.2894, time(ms): 804.38, token/sec:651787.43, hellaswag_acc: 0.3013
Step: 16802, loss: 3.031073, norm: 0.2825, time(ms): 795.21, token/sec:659309.48, hellaswag_acc: 0.3013
Step: 16803, loss: 3.071214, norm: 0.2743, time(ms): 802.39, token/sec:653410.97, hellaswag_acc: 0.3013
Step: 16804, loss: 3.063618, norm: 0.3106, time(ms): 799.23, token/sec:655988.18, hellaswag_acc: 0.3013
Step: 16805, loss: 3.070730, norm: 0.2869, time(ms): 800.55, token/sec:654910.35, hellaswag_acc: 0.3013
Step: 16806, loss: 3.048999, norm: 0.2772, time(ms): 799.23, token/sec:655992.48, hellaswag_acc: 0.3013
Step: 16807, loss: 3.056221, norm: 0.2919, time(ms): 797.15, token/sec:657699.02, hellaswag_acc: 0.3013
Step: 16808, loss: 3.192050, norm: 0.3814, time(ms): 802.48, token/sec:653336.42, hellaswag_acc: 0.3013
Step: 16809, loss: 3.096179, norm: 0.2999, time(ms): 799.79, token/sec:655530.20, hellaswag_acc: 0.3013
Step: 16810, loss: 3.078430, norm: 0.3170, time(ms): 800.66, token/sec:654819.47, hellaswag_acc: 0.3013
Step: 16811, loss: 3.069784, norm: 0.2949, time(ms): 792.84, token/sec:661281.42, hellaswag_acc: 0.3013
Step: 16812, loss: 3.064768, norm: 0.2775, time(ms): 806.21, token/sec:650309.23, hellaswag_acc: 0.3013
Step: 16813, loss: 2.998815, norm: 0.2981, time(ms): 800.45, token/sec:654989.16, hellaswag_acc: 0.3013
Step: 16814, loss: 3.046778, norm: 0.2994, time(ms): 793.77, token/sec:660499.84, hellaswag_acc: 0.3013
Step: 16815, loss: 3.040966, norm: 0.2891, time(ms): 802.54, token/sec:653284.41, hellaswag_acc: 0.3013
Step: 16816, loss: 3.137942, norm: 0.3502, time(ms): 804.63, token/sec:651590.63, hellaswag_acc: 0.3013
Step: 16817, loss: 3.041549, norm: 0.2735, time(ms): 799.82, token/sec:655509.10, hellaswag_acc: 0.3013
Step: 16818, loss: 3.046460, norm: 0.2933, time(ms): 794.97, token/sec:659510.77, hellaswag_acc: 0.3013
Step: 16819, loss: 3.010405, norm: 0.2864, time(ms): 795.38, token/sec:659164.81, hellaswag_acc: 0.3013
Step: 16820, loss: 3.017360, norm: 0.2837, time(ms): 791.87, token/sec:662088.18, hellaswag_acc: 0.3013
Step: 16821, loss: 3.024579, norm: 0.3026, time(ms): 789.24, token/sec:664295.46, hellaswag_acc: 0.3013
Step: 16822, loss: 3.123787, norm: 0.3149, time(ms): 790.66, token/sec:663102.99, hellaswag_acc: 0.3013
Step: 16823, loss: 3.047198, norm: 0.2799, time(ms): 789.74, token/sec:663875.12, hellaswag_acc: 0.3013
Step: 16824, loss: 3.045075, norm: 0.2755, time(ms): 800.13, token/sec:655254.98, hellaswag_acc: 0.3013
Step: 16825, loss: 3.045409, norm: 0.3025, time(ms): 805.70, token/sec:650721.23, hellaswag_acc: 0.3013
Step: 16826, loss: 3.130066, norm: 0.3221, time(ms): 795.89, token/sec:658745.21, hellaswag_acc: 0.3013
Step: 16827, loss: 3.059628, norm: 0.2993, time(ms): 800.12, token/sec:655258.69, hellaswag_acc: 0.3013
Step: 16828, loss: 3.138143, norm: 0.3209, time(ms): 801.08, token/sec:654476.08, hellaswag_acc: 0.3013
Step: 16829, loss: 3.116585, norm: 0.2904, time(ms): 799.33, token/sec:655905.41, hellaswag_acc: 0.3013
Step: 16830, loss: 3.099942, norm: 0.2909, time(ms): 799.70, token/sec:655601.93, hellaswag_acc: 0.3013
Step: 16831, loss: 3.095532, norm: 0.3018, time(ms): 801.35, token/sec:654258.38, hellaswag_acc: 0.3013
Step: 16832, loss: 3.108015, norm: 0.2940, time(ms): 801.66, token/sec:654003.09, hellaswag_acc: 0.3013
Step: 16833, loss: 3.135106, norm: 0.2987, time(ms): 791.03, token/sec:662788.41, hellaswag_acc: 0.3013
Step: 16834, loss: 3.088151, norm: 0.2907, time(ms): 792.86, token/sec:661258.75, hellaswag_acc: 0.3013
Step: 16835, loss: 3.117717, norm: 0.3012, time(ms): 793.86, token/sec:660430.02, hellaswag_acc: 0.3013
Step: 16836, loss: 3.036259, norm: 0.2972, time(ms): 797.40, token/sec:657493.72, hellaswag_acc: 0.3013
Step: 16837, loss: 3.020641, norm: 0.3219, time(ms): 802.37, token/sec:653426.50, hellaswag_acc: 0.3013
Step: 16838, loss: 3.029655, norm: 0.2867, time(ms): 798.83, token/sec:656318.86, hellaswag_acc: 0.3013
Step: 16839, loss: 3.081814, norm: 0.2895, time(ms): 793.06, token/sec:661095.14, hellaswag_acc: 0.3013
Step: 16840, loss: 3.053752, norm: 0.2815, time(ms): 790.30, token/sec:663404.06, hellaswag_acc: 0.3013
Step: 16841, loss: 3.097949, norm: 0.2921, time(ms): 793.17, token/sec:661002.94, hellaswag_acc: 0.3013
Step: 16842, loss: 3.063417, norm: 0.2939, time(ms): 791.19, token/sec:662659.19, hellaswag_acc: 0.3013
Step: 16843, loss: 3.067506, norm: 0.2900, time(ms): 789.46, token/sec:664107.89, hellaswag_acc: 0.3013
Step: 16844, loss: 3.053780, norm: 0.2649, time(ms): 799.82, token/sec:655508.31, hellaswag_acc: 0.3013
Step: 16845, loss: 3.086167, norm: 0.2869, time(ms): 805.64, token/sec:650774.00, hellaswag_acc: 0.3013
Step: 16846, loss: 3.064688, norm: 0.2832, time(ms): 791.06, token/sec:662763.64, hellaswag_acc: 0.3013
Step: 16847, loss: 3.022216, norm: 0.2713, time(ms): 800.46, token/sec:654982.72, hellaswag_acc: 0.3013
Step: 16848, loss: 3.028135, norm: 0.2633, time(ms): 804.55, token/sec:651650.30, hellaswag_acc: 0.3013
Step: 16849, loss: 2.995403, norm: 0.2710, time(ms): 802.89, token/sec:653004.86, hellaswag_acc: 0.3013
Step: 16850, loss: 3.141243, norm: 0.2972, time(ms): 791.90, token/sec:662063.06, hellaswag_acc: 0.3013
Step: 16851, loss: 3.116822, norm: 0.3058, time(ms): 796.03, token/sec:658630.18, hellaswag_acc: 0.3013
Step: 16852, loss: 3.075419, norm: 0.2987, time(ms): 792.28, token/sec:661747.08, hellaswag_acc: 0.3013
Step: 16853, loss: 3.040708, norm: 0.3242, time(ms): 797.32, token/sec:657560.76, hellaswag_acc: 0.3013
Step: 16854, loss: 3.023672, norm: 0.2749, time(ms): 793.87, token/sec:660421.09, hellaswag_acc: 0.3013
Step: 16855, loss: 3.094524, norm: 0.2725, time(ms): 787.42, token/sec:665831.36, hellaswag_acc: 0.3013
Step: 16856, loss: 3.003908, norm: 0.2926, time(ms): 793.67, token/sec:660588.33, hellaswag_acc: 0.3013
Step: 16857, loss: 3.058391, norm: 0.2837, time(ms): 804.59, token/sec:651619.40, hellaswag_acc: 0.3013
Step: 16858, loss: 3.004564, norm: 0.2712, time(ms): 802.00, token/sec:653727.59, hellaswag_acc: 0.3013
Step: 16859, loss: 2.991433, norm: 0.2989, time(ms): 790.55, token/sec:663197.98, hellaswag_acc: 0.3013
Step: 16860, loss: 2.991437, norm: 0.2863, time(ms): 793.38, token/sec:660826.35, hellaswag_acc: 0.3013
Step: 16861, loss: 3.098720, norm: 0.3232, time(ms): 794.48, token/sec:659915.51, hellaswag_acc: 0.3013
Step: 16862, loss: 3.068527, norm: 0.2990, time(ms): 799.16, token/sec:656044.93, hellaswag_acc: 0.3013
Step: 16863, loss: 3.111604, norm: 0.3091, time(ms): 799.90, token/sec:655441.69, hellaswag_acc: 0.3013
Step: 16864, loss: 3.083494, norm: 0.3020, time(ms): 796.05, token/sec:658615.98, hellaswag_acc: 0.3013
Step: 16865, loss: 3.162972, norm: 0.3084, time(ms): 801.71, token/sec:653960.30, hellaswag_acc: 0.3013
Step: 16866, loss: 3.071375, norm: 0.3457, time(ms): 1306.77, token/sec:401209.35, hellaswag_acc: 0.3013
Step: 16867, loss: 3.073187, norm: 0.3190, time(ms): 783.52, token/sec:669146.42, hellaswag_acc: 0.3013
Step: 16868, loss: 3.070864, norm: 0.2837, time(ms): 778.91, token/sec:673107.47, hellaswag_acc: 0.3013
Step: 16869, loss: 3.051319, norm: 0.3225, time(ms): 789.17, token/sec:664353.46, hellaswag_acc: 0.3013
Step: 16870, loss: 3.142592, norm: 0.3049, time(ms): 802.89, token/sec:653004.47, hellaswag_acc: 0.3013
Step: 16871, loss: 3.104606, norm: 0.3195, time(ms): 791.90, token/sec:662064.06, hellaswag_acc: 0.3013
Step: 16872, loss: 3.145916, norm: 0.3354, time(ms): 794.73, token/sec:659707.44, hellaswag_acc: 0.3013
Step: 16873, loss: 3.103035, norm: 0.2857, time(ms): 790.33, token/sec:663376.24, hellaswag_acc: 0.3013
Step: 16874, loss: 3.103084, norm: 0.3201, time(ms): 797.00, token/sec:657825.73, hellaswag_acc: 0.3013
Step: 16875, loss: 3.027817, norm: 0.3167, time(ms): 791.38, token/sec:662497.48, hellaswag_acc: 0.3013
Step: 16876, loss: 3.076999, norm: 0.3335, time(ms): 791.84, token/sec:662116.29, hellaswag_acc: 0.3013
Step: 16877, loss: 3.066279, norm: 0.3154, time(ms): 796.99, token/sec:657838.32, hellaswag_acc: 0.3013
Step: 16878, loss: 3.041696, norm: 0.3209, time(ms): 802.03, token/sec:653701.75, hellaswag_acc: 0.3013
Step: 16879, loss: 3.065451, norm: 0.2942, time(ms): 800.47, token/sec:654974.33, hellaswag_acc: 0.3013
Step: 16880, loss: 3.103216, norm: 0.3114, time(ms): 799.74, token/sec:655575.34, hellaswag_acc: 0.3013
Step: 16881, loss: 3.077304, norm: 0.3032, time(ms): 793.77, token/sec:660507.58, hellaswag_acc: 0.3013
Step: 16882, loss: 3.128788, norm: 0.3348, time(ms): 791.59, token/sec:662322.09, hellaswag_acc: 0.3013
Step: 16883, loss: 3.106292, norm: 0.3188, time(ms): 796.06, token/sec:658607.50, hellaswag_acc: 0.3013
Step: 16884, loss: 3.078653, norm: 0.3401, time(ms): 793.12, token/sec:661046.46, hellaswag_acc: 0.3013
Step: 16885, loss: 3.065059, norm: 0.2840, time(ms): 803.90, token/sec:652182.74, hellaswag_acc: 0.3013
Step: 16886, loss: 3.077763, norm: 0.2906, time(ms): 800.15, token/sec:655237.21, hellaswag_acc: 0.3013
Step: 16887, loss: 3.073843, norm: 0.3093, time(ms): 796.58, token/sec:658172.45, hellaswag_acc: 0.3013
Step: 16888, loss: 3.070049, norm: 0.3013, time(ms): 798.49, token/sec:656596.35, hellaswag_acc: 0.3013
Step: 16889, loss: 3.039717, norm: 0.2885, time(ms): 790.76, token/sec:663020.82, hellaswag_acc: 0.3013
Step: 16890, loss: 3.061908, norm: 0.2929, time(ms): 788.13, token/sec:665227.90, hellaswag_acc: 0.3013
Step: 16891, loss: 3.051934, norm: 0.2814, time(ms): 790.55, token/sec:663194.38, hellaswag_acc: 0.3013
Step: 16892, loss: 3.046846, norm: 0.2830, time(ms): 793.59, token/sec:660650.05, hellaswag_acc: 0.3013
Step: 16893, loss: 3.094528, norm: 0.2875, time(ms): 800.75, token/sec:654744.80, hellaswag_acc: 0.3013
Step: 16894, loss: 3.061030, norm: 0.2983, time(ms): 795.79, token/sec:658825.93, hellaswag_acc: 0.3013
Step: 16895, loss: 3.057745, norm: 0.2923, time(ms): 806.96, token/sec:649711.49, hellaswag_acc: 0.3013
Step: 16896, loss: 3.054081, norm: 0.2827, time(ms): 798.72, token/sec:656411.92, hellaswag_acc: 0.3013
Step: 16897, loss: 3.102642, norm: 0.2869, time(ms): 791.02, token/sec:662800.20, hellaswag_acc: 0.3013
Step: 16898, loss: 3.080543, norm: 0.2870, time(ms): 807.70, token/sec:649110.83, hellaswag_acc: 0.3013
Step: 16899, loss: 3.067116, norm: 0.3074, time(ms): 798.75, token/sec:656387.43, hellaswag_acc: 0.3013
Step: 16900, loss: 3.024050, norm: 0.2720, time(ms): 801.10, token/sec:654463.03, hellaswag_acc: 0.3013
Step: 16901, loss: 3.016412, norm: 0.3034, time(ms): 795.78, token/sec:658835.80, hellaswag_acc: 0.3013
Step: 16902, loss: 2.961533, norm: 0.3015, time(ms): 802.02, token/sec:653709.91, hellaswag_acc: 0.3013
Step: 16903, loss: 3.002937, norm: 0.2617, time(ms): 799.69, token/sec:655611.89, hellaswag_acc: 0.3013
Step: 16904, loss: 2.961143, norm: 0.3345, time(ms): 801.85, token/sec:653851.80, hellaswag_acc: 0.3013
Step: 16905, loss: 2.984100, norm: 0.2915, time(ms): 799.98, token/sec:655377.62, hellaswag_acc: 0.3013
Step: 16906, loss: 2.997704, norm: 0.3077, time(ms): 798.35, token/sec:656717.53, hellaswag_acc: 0.3013
Step: 16907, loss: 2.973063, norm: 0.2858, time(ms): 799.86, token/sec:655476.47, hellaswag_acc: 0.3013
Step: 16908, loss: 2.971806, norm: 0.2903, time(ms): 800.52, token/sec:654933.36, hellaswag_acc: 0.3013
Step: 16909, loss: 2.968605, norm: 0.2692, time(ms): 793.78, token/sec:660496.67, hellaswag_acc: 0.3013
Step: 16910, loss: 2.959495, norm: 0.2928, time(ms): 798.24, token/sec:656802.86, hellaswag_acc: 0.3013
Step: 16911, loss: 2.905854, norm: 0.2830, time(ms): 791.94, token/sec:662026.78, hellaswag_acc: 0.3013
Step: 16912, loss: 2.947989, norm: 0.2787, time(ms): 794.01, token/sec:660306.27, hellaswag_acc: 0.3013
Step: 16913, loss: 3.040360, norm: 0.2866, time(ms): 796.08, token/sec:658586.39, hellaswag_acc: 0.3013
Step: 16914, loss: 3.099048, norm: 0.2884, time(ms): 791.68, token/sec:662246.29, hellaswag_acc: 0.3013
Step: 16915, loss: 3.115965, norm: 0.2957, time(ms): 793.52, token/sec:660715.76, hellaswag_acc: 0.3013
Step: 16916, loss: 3.063738, norm: 0.2845, time(ms): 798.71, token/sec:656420.54, hellaswag_acc: 0.3013
Step: 16917, loss: 3.087285, norm: 0.2823, time(ms): 797.86, token/sec:657115.90, hellaswag_acc: 0.3013
Step: 16918, loss: 3.121805, norm: 0.2785, time(ms): 801.48, token/sec:654151.53, hellaswag_acc: 0.3013
Step: 16919, loss: 3.076789, norm: 0.2790, time(ms): 795.51, token/sec:659058.13, hellaswag_acc: 0.3013
Step: 16920, loss: 3.054979, norm: 0.2801, time(ms): 799.45, token/sec:655813.87, hellaswag_acc: 0.3013
Step: 16921, loss: 3.077404, norm: 0.2758, time(ms): 804.55, token/sec:651652.62, hellaswag_acc: 0.3013
Step: 16922, loss: 3.120062, norm: 0.2899, time(ms): 800.90, token/sec:654619.67, hellaswag_acc: 0.3013
Step: 16923, loss: 3.171350, norm: 0.2947, time(ms): 801.36, token/sec:654244.17, hellaswag_acc: 0.3013
Step: 16924, loss: 3.110287, norm: 0.3025, time(ms): 796.29, token/sec:658409.71, hellaswag_acc: 0.3013
Step: 16925, loss: 3.086757, norm: 0.3172, time(ms): 799.94, token/sec:655412.78, hellaswag_acc: 0.3013
Step: 16926, loss: 3.085994, norm: 0.2886, time(ms): 804.14, token/sec:651988.61, hellaswag_acc: 0.3013
Step: 16927, loss: 3.087507, norm: 0.3007, time(ms): 790.12, token/sec:663550.99, hellaswag_acc: 0.3013
Step: 16928, loss: 3.084823, norm: 0.3130, time(ms): 794.15, token/sec:660190.50, hellaswag_acc: 0.3013
Step: 16929, loss: 3.177003, norm: 0.2982, time(ms): 794.90, token/sec:659562.00, hellaswag_acc: 0.3013
Step: 16930, loss: 3.117084, norm: 0.2964, time(ms): 795.39, token/sec:659162.05, hellaswag_acc: 0.3013
Step: 16931, loss: 3.058832, norm: 0.3114, time(ms): 793.33, token/sec:660866.47, hellaswag_acc: 0.3013
Step: 16932, loss: 3.070116, norm: 0.2911, time(ms): 789.07, token/sec:664434.76, hellaswag_acc: 0.3013
Step: 16933, loss: 3.083888, norm: 0.3036, time(ms): 792.98, token/sec:661162.72, hellaswag_acc: 0.3013
Step: 16934, loss: 3.009360, norm: 0.2865, time(ms): 792.64, token/sec:661447.31, hellaswag_acc: 0.3013
Step: 16935, loss: 3.115716, norm: 0.2922, time(ms): 792.05, token/sec:661933.92, hellaswag_acc: 0.3013
Step: 16936, loss: 3.130097, norm: 0.3019, time(ms): 799.28, token/sec:655954.33, hellaswag_acc: 0.3013
Step: 16937, loss: 3.038569, norm: 0.2892, time(ms): 799.03, token/sec:656154.16, hellaswag_acc: 0.3013
Step: 16938, loss: 3.125925, norm: 0.3186, time(ms): 804.61, token/sec:651607.04, hellaswag_acc: 0.3013
Step: 16939, loss: 3.091600, norm: 0.3220, time(ms): 795.75, token/sec:658860.87, hellaswag_acc: 0.3013
Step: 16940, loss: 3.035688, norm: 0.2946, time(ms): 795.30, token/sec:659236.55, hellaswag_acc: 0.3013
Step: 16941, loss: 3.025247, norm: 0.2672, time(ms): 806.58, token/sec:650010.89, hellaswag_acc: 0.3013
Step: 16942, loss: 3.029114, norm: 0.2906, time(ms): 801.25, token/sec:654338.59, hellaswag_acc: 0.3013
Step: 16943, loss: 3.059024, norm: 0.2708, time(ms): 792.40, token/sec:661646.73, hellaswag_acc: 0.3013
Step: 16944, loss: 3.085072, norm: 0.2789, time(ms): 806.16, token/sec:650351.54, hellaswag_acc: 0.3013
Step: 16945, loss: 3.030842, norm: 0.2686, time(ms): 801.59, token/sec:654059.11, hellaswag_acc: 0.3013
Step: 16946, loss: 3.067440, norm: 0.2666, time(ms): 799.46, token/sec:655800.76, hellaswag_acc: 0.3013
Step: 16947, loss: 3.032289, norm: 0.2611, time(ms): 793.96, token/sec:660342.36, hellaswag_acc: 0.3013
Step: 16948, loss: 2.951854, norm: 0.2860, time(ms): 801.24, token/sec:654345.21, hellaswag_acc: 0.3013
Step: 16949, loss: 2.957363, norm: 0.2656, time(ms): 804.71, token/sec:651524.42, hellaswag_acc: 0.3013
Step: 16950, loss: 3.099702, norm: 0.3173, time(ms): 794.51, token/sec:659886.99, hellaswag_acc: 0.3013
Step: 16951, loss: 2.955301, norm: 0.2720, time(ms): 803.41, token/sec:652579.50, hellaswag_acc: 0.3013
Step: 16952, loss: 2.984488, norm: 0.2895, time(ms): 796.42, token/sec:658302.09, hellaswag_acc: 0.3013
Step: 16953, loss: 2.928667, norm: 0.2679, time(ms): 803.96, token/sec:652134.78, hellaswag_acc: 0.3013
Step: 16954, loss: 3.020932, norm: 0.2955, time(ms): 800.39, token/sec:655042.03, hellaswag_acc: 0.3013
Step: 16955, loss: 2.963480, norm: 0.2531, time(ms): 792.56, token/sec:661508.60, hellaswag_acc: 0.3013
Step: 16956, loss: 3.031972, norm: 0.2906, time(ms): 805.02, token/sec:651272.22, hellaswag_acc: 0.3013
Step: 16957, loss: 2.959779, norm: 0.2579, time(ms): 802.18, token/sec:653576.62, hellaswag_acc: 0.3013
Step: 16958, loss: 2.956028, norm: 0.2624, time(ms): 795.00, token/sec:659481.30, hellaswag_acc: 0.3013
Step: 16959, loss: 3.112801, norm: 0.3729, time(ms): 796.10, token/sec:658568.84, hellaswag_acc: 0.3013
Step: 16960, loss: 3.104301, norm: 0.2827, time(ms): 805.37, token/sec:650992.47, hellaswag_acc: 0.3013
Step: 16961, loss: 3.078162, norm: 0.2964, time(ms): 801.54, token/sec:654100.94, hellaswag_acc: 0.3013
Step: 16962, loss: 3.135486, norm: 0.3095, time(ms): 794.91, token/sec:659559.83, hellaswag_acc: 0.3013
Step: 16963, loss: 3.115786, norm: 0.2943, time(ms): 801.57, token/sec:654073.70, hellaswag_acc: 0.3013
Step: 16964, loss: 3.145383, norm: 0.3048, time(ms): 803.70, token/sec:652340.62, hellaswag_acc: 0.3013
Step: 16965, loss: 3.096976, norm: 0.3234, time(ms): 801.34, token/sec:654265.97, hellaswag_acc: 0.3013
Step: 16966, loss: 3.082283, norm: 0.2863, time(ms): 786.23, token/sec:666837.67, hellaswag_acc: 0.3013
Step: 16967, loss: 3.081601, norm: 0.3221, time(ms): 789.71, token/sec:663895.56, hellaswag_acc: 0.3013
Step: 16968, loss: 3.078527, norm: 0.3220, time(ms): 799.57, token/sec:655710.62, hellaswag_acc: 0.3013
Step: 16969, loss: 3.068528, norm: 0.2844, time(ms): 788.67, token/sec:664776.83, hellaswag_acc: 0.3013
Step: 16970, loss: 2.995181, norm: 0.2753, time(ms): 790.31, token/sec:663395.46, hellaswag_acc: 0.3013
Step: 16971, loss: 3.104875, norm: 0.2948, time(ms): 795.64, token/sec:658948.53, hellaswag_acc: 0.3013
Step: 16972, loss: 3.043587, norm: 0.2720, time(ms): 804.18, token/sec:651949.56, hellaswag_acc: 0.3013
Step: 16973, loss: 3.104350, norm: 0.3133, time(ms): 803.88, token/sec:652197.25, hellaswag_acc: 0.3013
Step: 16974, loss: 3.060117, norm: 0.3273, time(ms): 789.69, token/sec:663919.81, hellaswag_acc: 0.3013
Step: 16975, loss: 3.035859, norm: 0.2755, time(ms): 794.70, token/sec:659727.63, hellaswag_acc: 0.3013
Step: 16976, loss: 3.127220, norm: 0.3115, time(ms): 792.26, token/sec:661765.80, hellaswag_acc: 0.3013
Step: 16977, loss: 3.125175, norm: 0.2977, time(ms): 802.02, token/sec:653705.44, hellaswag_acc: 0.3013
Step: 16978, loss: 3.058497, norm: 0.2836, time(ms): 802.47, token/sec:653346.71, hellaswag_acc: 0.3013
Step: 16979, loss: 3.038103, norm: 0.2994, time(ms): 786.20, token/sec:666861.74, hellaswag_acc: 0.3013
Step: 16980, loss: 3.035216, norm: 0.2969, time(ms): 791.11, token/sec:662721.90, hellaswag_acc: 0.3013
Step: 16981, loss: 3.115807, norm: 0.2969, time(ms): 790.08, token/sec:663587.44, hellaswag_acc: 0.3013
Step: 16982, loss: 3.077703, norm: 0.2880, time(ms): 790.18, token/sec:663503.34, hellaswag_acc: 0.3013
Step: 16983, loss: 3.075419, norm: 0.2935, time(ms): 792.64, token/sec:661444.33, hellaswag_acc: 0.3013
Step: 16984, loss: 3.084466, norm: 0.3497, time(ms): 803.41, token/sec:652582.21, hellaswag_acc: 0.3013
Step: 16985, loss: 3.053907, norm: 0.2656, time(ms): 802.64, token/sec:653207.17, hellaswag_acc: 0.3013
Step: 16986, loss: 3.043869, norm: 0.3020, time(ms): 796.00, token/sec:658654.84, hellaswag_acc: 0.3013
Step: 16987, loss: 3.054781, norm: 0.2772, time(ms): 795.57, token/sec:659008.56, hellaswag_acc: 0.3013
Step: 16988, loss: 3.086792, norm: 0.2807, time(ms): 807.53, token/sec:649251.30, hellaswag_acc: 0.3013
Step: 16989, loss: 3.036362, norm: 0.2729, time(ms): 795.28, token/sec:659253.34, hellaswag_acc: 0.3013
Step: 16990, loss: 3.080539, norm: 0.2619, time(ms): 796.25, token/sec:658449.54, hellaswag_acc: 0.3013
Step: 16991, loss: 3.066654, norm: 0.2874, time(ms): 806.69, token/sec:649926.36, hellaswag_acc: 0.3013
Step: 16992, loss: 3.052428, norm: 0.3049, time(ms): 801.84, token/sec:653855.69, hellaswag_acc: 0.3013
Step: 16993, loss: 3.074796, norm: 0.2713, time(ms): 789.68, token/sec:663923.22, hellaswag_acc: 0.3013
Step: 16994, loss: 2.969309, norm: 0.2829, time(ms): 791.60, token/sec:662310.32, hellaswag_acc: 0.3013
Step: 16995, loss: 3.004181, norm: 0.2833, time(ms): 792.50, token/sec:661560.94, hellaswag_acc: 0.3013
Step: 16996, loss: 3.005937, norm: 0.2890, time(ms): 790.27, token/sec:663427.08, hellaswag_acc: 0.3013
Step: 16997, loss: 2.998991, norm: 0.2755, time(ms): 792.09, token/sec:661905.63, hellaswag_acc: 0.3013
Step: 16998, loss: 2.963465, norm: 0.2871, time(ms): 795.85, token/sec:658775.40, hellaswag_acc: 0.3013
Step: 16999, loss: 2.982307, norm: 0.2998, time(ms): 800.85, token/sec:654661.57, hellaswag_acc: 0.3013
rank 0 sample 0: Hello, I'm a language model, and I'll be able to speak. As someone who is fluent in and is fluent in Latin can be said to speak
rank 0 sample 1: Hello, I'm a language model, so i'm not sure what it means. It used to mean the same thing, so the same with it. So
rank 0 sample 2: Hello, I'm a language model, so I use Python that comes with an interpreter:
import pyxl import pyxl.py
PyX
rank 0 sample 3: Hello, I'm a language model, but one that you can use in the future was to build a set of basic compilers to parse English. So there
rank 1 sample 0: Hello, I'm a language model, this is the first language I think
to write, there's a lot of things you could have done in the past
rank 1 sample 1: Hello, I'm a language model, not an author. I'm a student in a foreign academic environment. I know more how to pronounce the words than I
rank 1 sample 2: Hello, I'm a language model, but ...
What is the difference between a language model and a language learning model?
Language models are a subset of
rank 1 sample 3: Hello, I'm a language model, and I'm an interpreter
A programming language is a written language with which its users build hardware
A programming language is
Step: 17000, loss: 2.906383, norm: 0.2760, time(ms): 363697.90, token/sec:1441.55, val_loss: 3.0811, hellaswag_acc: 0.3031
Step: 17001, loss: 2.996931, norm: 0.2863, time(ms): 794.47, token/sec:659917.69, hellaswag_acc: 0.3031
Step: 17002, loss: 2.963161, norm: 0.3133, time(ms): 795.47, token/sec:659094.88, hellaswag_acc: 0.3031
Step: 17003, loss: 2.973028, norm: 0.2938, time(ms): 801.31, token/sec:654286.22, hellaswag_acc: 0.3031
Step: 17004, loss: 2.965654, norm: 0.3194, time(ms): 789.48, token/sec:664092.24, hellaswag_acc: 0.3031
Step: 17005, loss: 2.963842, norm: 0.3122, time(ms): 794.95, token/sec:659524.22, hellaswag_acc: 0.3031
Step: 17006, loss: 3.127516, norm: 0.3247, time(ms): 790.95, token/sec:662859.54, hellaswag_acc: 0.3031
Step: 17007, loss: 3.105123, norm: 0.3225, time(ms): 792.61, token/sec:661471.19, hellaswag_acc: 0.3031
Step: 17008, loss: 3.145728, norm: 0.2963, time(ms): 791.05, token/sec:662773.03, hellaswag_acc: 0.3031
Step: 17009, loss: 3.016148, norm: 0.3026, time(ms): 796.29, token/sec:658410.30, hellaswag_acc: 0.3031
Step: 17010, loss: 3.098452, norm: 0.3446, time(ms): 796.82, token/sec:657979.25, hellaswag_acc: 0.3031
Step: 17011, loss: 3.077991, norm: 0.2916, time(ms): 802.51, token/sec:653314.30, hellaswag_acc: 0.3031
Step: 17012, loss: 3.077626, norm: 0.2998, time(ms): 804.13, token/sec:651996.53, hellaswag_acc: 0.3031
Step: 17013, loss: 3.088613, norm: 0.3011, time(ms): 785.22, token/sec:667695.96, hellaswag_acc: 0.3031
Step: 17014, loss: 3.090619, norm: 0.3047, time(ms): 788.56, token/sec:664865.07, hellaswag_acc: 0.3031
Step: 17015, loss: 3.170385, norm: 0.3014, time(ms): 794.54, token/sec:659860.06, hellaswag_acc: 0.3031
Step: 17016, loss: 3.096961, norm: 0.3042, time(ms): 792.04, token/sec:661948.07, hellaswag_acc: 0.3031
Step: 17017, loss: 3.098068, norm: 0.3190, time(ms): 791.48, token/sec:662414.26, hellaswag_acc: 0.3031
Step: 17018, loss: 3.073417, norm: 0.2933, time(ms): 800.00, token/sec:655361.99, hellaswag_acc: 0.3031
Step: 17019, loss: 3.096729, norm: 0.2890, time(ms): 802.53, token/sec:653293.14, hellaswag_acc: 0.3031
Step: 17020, loss: 3.095480, norm: 0.2855, time(ms): 802.51, token/sec:653310.03, hellaswag_acc: 0.3031
Step: 17021, loss: 3.089195, norm: 0.2843, time(ms): 792.89, token/sec:661240.06, hellaswag_acc: 0.3031
Step: 17022, loss: 3.106636, norm: 0.3681, time(ms): 804.24, token/sec:651906.07, hellaswag_acc: 0.3031
Step: 17023, loss: 3.090579, norm: 0.3042, time(ms): 802.22, token/sec:653547.29, hellaswag_acc: 0.3031
Step: 17024, loss: 3.076279, norm: 0.3062, time(ms): 799.68, token/sec:655625.19, hellaswag_acc: 0.3031
Step: 17025, loss: 3.144480, norm: 0.2987, time(ms): 793.42, token/sec:660791.00, hellaswag_acc: 0.3031
Step: 17026, loss: 3.109499, norm: 0.3054, time(ms): 804.32, token/sec:651837.09, hellaswag_acc: 0.3031
Step: 17027, loss: 3.054523, norm: 0.2945, time(ms): 801.92, token/sec:653792.31, hellaswag_acc: 0.3031
Step: 17028, loss: 3.100808, norm: 0.2823, time(ms): 794.26, token/sec:660094.98, hellaswag_acc: 0.3031
Step: 17029, loss: 3.012678, norm: 0.2833, time(ms): 801.84, token/sec:653858.41, hellaswag_acc: 0.3031
Step: 17030, loss: 3.112371, norm: 0.3795, time(ms): 803.48, token/sec:652521.99, hellaswag_acc: 0.3031
Step: 17031, loss: 3.100269, norm: 0.3077, time(ms): 799.92, token/sec:655429.38, hellaswag_acc: 0.3031
Step: 17032, loss: 3.040818, norm: 0.2718, time(ms): 790.52, token/sec:663222.79, hellaswag_acc: 0.3031
Step: 17033, loss: 3.056221, norm: 0.2849, time(ms): 793.65, token/sec:660601.43, hellaswag_acc: 0.3031
Step: 17034, loss: 3.093717, norm: 0.3107, time(ms): 795.00, token/sec:659482.49, hellaswag_acc: 0.3031
Step: 17035, loss: 3.041586, norm: 0.2843, time(ms): 800.95, token/sec:654582.64, hellaswag_acc: 0.3031
Step: 17036, loss: 3.035039, norm: 0.2749, time(ms): 793.60, token/sec:660641.12, hellaswag_acc: 0.3031
Step: 17037, loss: 3.053790, norm: 0.2804, time(ms): 801.59, token/sec:654059.11, hellaswag_acc: 0.3031
Step: 17038, loss: 3.047030, norm: 0.2637, time(ms): 801.37, token/sec:654239.11, hellaswag_acc: 0.3031
Step: 17039, loss: 3.070230, norm: 0.2696, time(ms): 802.86, token/sec:653026.77, hellaswag_acc: 0.3031
Step: 17040, loss: 3.148291, norm: 0.4005, time(ms): 788.20, token/sec:665168.94, hellaswag_acc: 0.3031
Step: 17041, loss: 3.019875, norm: 0.3134, time(ms): 788.78, token/sec:664680.18, hellaswag_acc: 0.3031
Step: 17042, loss: 2.992788, norm: 0.2709, time(ms): 798.36, token/sec:656707.73, hellaswag_acc: 0.3031
Step: 17043, loss: 2.928899, norm: 0.3044, time(ms): 790.92, token/sec:662887.91, hellaswag_acc: 0.3031
Step: 17044, loss: 3.016217, norm: 0.3086, time(ms): 788.21, token/sec:665164.32, hellaswag_acc: 0.3031
Step: 17045, loss: 2.960376, norm: 0.2752, time(ms): 803.67, token/sec:652363.84, hellaswag_acc: 0.3031
Step: 17046, loss: 2.970712, norm: 0.3073, time(ms): 795.41, token/sec:659139.33, hellaswag_acc: 0.3031
Step: 17047, loss: 2.932627, norm: 0.2914, time(ms): 804.20, token/sec:651940.09, hellaswag_acc: 0.3031
Step: 17048, loss: 2.961881, norm: 0.2731, time(ms): 798.25, token/sec:656792.85, hellaswag_acc: 0.3031
Step: 17049, loss: 2.972389, norm: 0.3096, time(ms): 800.80, token/sec:654702.89, hellaswag_acc: 0.3031
Step: 17050, loss: 2.967085, norm: 0.2812, time(ms): 793.22, token/sec:660959.83, hellaswag_acc: 0.3031
Step: 17051, loss: 3.026484, norm: 0.2682, time(ms): 802.58, token/sec:653254.71, hellaswag_acc: 0.3031
Step: 17052, loss: 3.128436, norm: 0.3073, time(ms): 804.90, token/sec:651368.48, hellaswag_acc: 0.3031
Step: 17053, loss: 3.168944, norm: 0.3167, time(ms): 798.60, token/sec:656512.84, hellaswag_acc: 0.3031
Step: 17054, loss: 3.165904, norm: 0.2993, time(ms): 791.12, token/sec:662717.70, hellaswag_acc: 0.3031
Step: 17055, loss: 3.139854, norm: 0.3244, time(ms): 808.47, token/sec:648492.53, hellaswag_acc: 0.3031
Step: 17056, loss: 3.097177, norm: 0.3429, time(ms): 796.44, token/sec:658293.03, hellaswag_acc: 0.3031
Step: 17057, loss: 3.068709, norm: 0.3123, time(ms): 1508.16, token/sec:347633.35, hellaswag_acc: 0.3031
Step: 17058, loss: 3.097517, norm: 0.3074, time(ms): 797.01, token/sec:657822.18, hellaswag_acc: 0.3031
Step: 17059, loss: 3.121726, norm: 0.3445, time(ms): 790.20, token/sec:663484.53, hellaswag_acc: 0.3031
Step: 17060, loss: 3.115146, norm: 0.3398, time(ms): 783.04, token/sec:669558.80, hellaswag_acc: 0.3031
Step: 17061, loss: 3.175506, norm: 0.3241, time(ms): 787.96, token/sec:665376.65, hellaswag_acc: 0.3031
Step: 17062, loss: 3.129415, norm: 0.3475, time(ms): 793.94, token/sec:660363.58, hellaswag_acc: 0.3031
Step: 17063, loss: 3.147038, norm: 0.3502, time(ms): 804.58, token/sec:651625.39, hellaswag_acc: 0.3031
Step: 17064, loss: 3.118136, norm: 0.3272, time(ms): 786.79, token/sec:666359.78, hellaswag_acc: 0.3031
Step: 17065, loss: 3.150296, norm: 0.3239, time(ms): 791.22, token/sec:662636.23, hellaswag_acc: 0.3031
Step: 17066, loss: 3.176516, norm: 0.3088, time(ms): 793.54, token/sec:660691.14, hellaswag_acc: 0.3031
Step: 17067, loss: 3.130369, norm: 0.3223, time(ms): 803.48, token/sec:652523.54, hellaswag_acc: 0.3031
Step: 17068, loss: 3.110699, norm: 0.3130, time(ms): 792.86, token/sec:661261.14, hellaswag_acc: 0.3031
Step: 17069, loss: 3.230140, norm: 0.3037, time(ms): 790.97, token/sec:662839.36, hellaswag_acc: 0.3031
Step: 17070, loss: 3.112539, norm: 0.2978, time(ms): 786.29, token/sec:666783.89, hellaswag_acc: 0.3031
Step: 17071, loss: 2.992744, norm: 0.2892, time(ms): 789.19, token/sec:664337.61, hellaswag_acc: 0.3031
Step: 17072, loss: 3.064384, norm: 0.2917, time(ms): 800.13, token/sec:655254.00, hellaswag_acc: 0.3031
Step: 17073, loss: 3.060873, norm: 0.2736, time(ms): 799.73, token/sec:655583.55, hellaswag_acc: 0.3031
Step: 17074, loss: 3.004257, norm: 0.2753, time(ms): 797.94, token/sec:657053.66, hellaswag_acc: 0.3031
Step: 17075, loss: 3.096955, norm: 0.2882, time(ms): 803.21, token/sec:652740.28, hellaswag_acc: 0.3031
Step: 17076, loss: 3.056699, norm: 0.3015, time(ms): 791.49, token/sec:662409.47, hellaswag_acc: 0.3031
Step: 17077, loss: 3.110021, norm: 0.3117, time(ms): 806.67, token/sec:649942.12, hellaswag_acc: 0.3031
Step: 17078, loss: 3.064409, norm: 0.3196, time(ms): 792.77, token/sec:661335.71, hellaswag_acc: 0.3031
Step: 17079, loss: 3.043997, norm: 0.3088, time(ms): 791.73, token/sec:662204.61, hellaswag_acc: 0.3031
Step: 17080, loss: 3.055718, norm: 0.2959, time(ms): 794.48, token/sec:659910.96, hellaswag_acc: 0.3031
Step: 17081, loss: 3.050770, norm: 0.2975, time(ms): 792.61, token/sec:661467.80, hellaswag_acc: 0.3031
Step: 17082, loss: 3.052617, norm: 0.3074, time(ms): 788.82, token/sec:664650.45, hellaswag_acc: 0.3031
Step: 17083, loss: 3.101439, norm: 0.3401, time(ms): 797.92, token/sec:657072.12, hellaswag_acc: 0.3031
Step: 17084, loss: 3.092368, norm: 0.2989, time(ms): 797.53, token/sec:657385.81, hellaswag_acc: 0.3031
Step: 17085, loss: 3.073889, norm: 0.3148, time(ms): 803.43, token/sec:652565.75, hellaswag_acc: 0.3031
Step: 17086, loss: 3.171202, norm: 0.3888, time(ms): 800.42, token/sec:655015.30, hellaswag_acc: 0.3031
Step: 17087, loss: 3.106190, norm: 0.3230, time(ms): 794.02, token/sec:660297.15, hellaswag_acc: 0.3031
Step: 17088, loss: 3.107018, norm: 0.3170, time(ms): 801.75, token/sec:653930.94, hellaswag_acc: 0.3031
Step: 17089, loss: 3.099450, norm: 0.3709, time(ms): 804.28, token/sec:651868.97, hellaswag_acc: 0.3031
Step: 17090, loss: 3.163870, norm: 0.3552, time(ms): 793.52, token/sec:660714.96, hellaswag_acc: 0.3031
Step: 17091, loss: 3.046073, norm: 0.3267, time(ms): 800.68, token/sec:654801.14, hellaswag_acc: 0.3031
Step: 17092, loss: 3.139556, norm: 0.3350, time(ms): 802.47, token/sec:653344.96, hellaswag_acc: 0.3031
Step: 17093, loss: 3.115441, norm: 0.3011, time(ms): 801.64, token/sec:654015.54, hellaswag_acc: 0.3031
Step: 17094, loss: 3.111321, norm: 0.3305, time(ms): 796.95, token/sec:657866.46, hellaswag_acc: 0.3031
Step: 17095, loss: 3.122242, norm: 0.3669, time(ms): 802.66, token/sec:653184.08, hellaswag_acc: 0.3031
Step: 17096, loss: 3.135630, norm: 0.3201, time(ms): 798.00, token/sec:656999.68, hellaswag_acc: 0.3031
Step: 17097, loss: 3.124357, norm: 0.3447, time(ms): 798.58, token/sec:656528.13, hellaswag_acc: 0.3031
Step: 17098, loss: 3.167466, norm: 0.3331, time(ms): 801.58, token/sec:654070.39, hellaswag_acc: 0.3031
Step: 17099, loss: 3.130042, norm: 0.3355, time(ms): 800.58, token/sec:654887.53, hellaswag_acc: 0.3031
Step: 17100, loss: 3.160030, norm: 0.2948, time(ms): 793.67, token/sec:660582.78, hellaswag_acc: 0.3031
Step: 17101, loss: 3.108062, norm: 0.3331, time(ms): 798.86, token/sec:656295.94, hellaswag_acc: 0.3031
Step: 17102, loss: 3.117975, norm: 0.3207, time(ms): 792.37, token/sec:661673.01, hellaswag_acc: 0.3031
Step: 17103, loss: 3.149900, norm: 0.2917, time(ms): 794.66, token/sec:659762.26, hellaswag_acc: 0.3031
Step: 17104, loss: 3.142412, norm: 0.3230, time(ms): 794.35, token/sec:660017.91, hellaswag_acc: 0.3031
Step: 17105, loss: 3.121967, norm: 0.3331, time(ms): 802.42, token/sec:653382.43, hellaswag_acc: 0.3031
Step: 17106, loss: 3.061510, norm: 0.3254, time(ms): 805.67, token/sec:650744.92, hellaswag_acc: 0.3031
Step: 17107, loss: 3.084941, norm: 0.3353, time(ms): 794.97, token/sec:659510.38, hellaswag_acc: 0.3031
Step: 17108, loss: 3.043605, norm: 0.3002, time(ms): 793.05, token/sec:661101.50, hellaswag_acc: 0.3031
Step: 17109, loss: 3.054874, norm: 0.3214, time(ms): 789.40, token/sec:664159.64, hellaswag_acc: 0.3031
Step: 17110, loss: 3.010532, norm: 0.3173, time(ms): 792.15, token/sec:661851.04, hellaswag_acc: 0.3031
Step: 17111, loss: 3.074069, norm: 0.3116, time(ms): 794.26, token/sec:660095.97, hellaswag_acc: 0.3031
Step: 17112, loss: 3.045449, norm: 0.3162, time(ms): 791.96, token/sec:662016.02, hellaswag_acc: 0.3031
Step: 17113, loss: 3.059467, norm: 0.2838, time(ms): 796.41, token/sec:658312.93, hellaswag_acc: 0.3031
Step: 17114, loss: 3.042676, norm: 0.3100, time(ms): 804.99, token/sec:651297.30, hellaswag_acc: 0.3031
Step: 17115, loss: 3.048929, norm: 0.2815, time(ms): 798.40, token/sec:656676.74, hellaswag_acc: 0.3031
Step: 17116, loss: 3.105294, norm: 0.3059, time(ms): 795.53, token/sec:659042.33, hellaswag_acc: 0.3031
Step: 17117, loss: 3.014612, norm: 0.2932, time(ms): 802.65, token/sec:653193.01, hellaswag_acc: 0.3031
Step: 17118, loss: 3.076691, norm: 0.3307, time(ms): 803.05, token/sec:652873.61, hellaswag_acc: 0.3031
Step: 17119, loss: 3.121614, norm: 0.3151, time(ms): 791.46, token/sec:662427.83, hellaswag_acc: 0.3031
Step: 17120, loss: 3.076190, norm: 0.2803, time(ms): 806.83, token/sec:649812.86, hellaswag_acc: 0.3031
Step: 17121, loss: 3.079605, norm: 0.3268, time(ms): 798.69, token/sec:656433.87, hellaswag_acc: 0.3031
Step: 17122, loss: 3.074967, norm: 0.2922, time(ms): 800.76, token/sec:654740.90, hellaswag_acc: 0.3031
Step: 17123, loss: 3.103960, norm: 0.3136, time(ms): 800.96, token/sec:654574.26, hellaswag_acc: 0.3031
Step: 17124, loss: 3.070970, norm: 0.2921, time(ms): 788.15, token/sec:665213.21, hellaswag_acc: 0.3031
Step: 17125, loss: 3.096296, norm: 0.2834, time(ms): 789.53, token/sec:664052.54, hellaswag_acc: 0.3031
Step: 17126, loss: 3.092789, norm: 0.3116, time(ms): 794.45, token/sec:659939.87, hellaswag_acc: 0.3031
Step: 17127, loss: 3.111055, norm: 0.3017, time(ms): 793.03, token/sec:661120.39, hellaswag_acc: 0.3031
Step: 17128, loss: 3.035750, norm: 0.2860, time(ms): 788.94, token/sec:664549.82, hellaswag_acc: 0.3031
Step: 17129, loss: 3.088841, norm: 0.3253, time(ms): 800.50, token/sec:654951.70, hellaswag_acc: 0.3031
Step: 17130, loss: 3.088225, norm: 0.3176, time(ms): 803.89, token/sec:652189.71, hellaswag_acc: 0.3031
Step: 17131, loss: 3.071443, norm: 0.2836, time(ms): 801.25, token/sec:654340.73, hellaswag_acc: 0.3031
Step: 17132, loss: 3.133532, norm: 0.3031, time(ms): 789.68, token/sec:663923.62, hellaswag_acc: 0.3031
Step: 17133, loss: 3.078003, norm: 0.3121, time(ms): 798.91, token/sec:656256.77, hellaswag_acc: 0.3031
Step: 17134, loss: 3.094015, norm: 0.2881, time(ms): 791.47, token/sec:662422.84, hellaswag_acc: 0.3031
Step: 17135, loss: 3.070228, norm: 0.2863, time(ms): 796.82, token/sec:657978.66, hellaswag_acc: 0.3031
Step: 17136, loss: 3.101758, norm: 0.3322, time(ms): 791.08, token/sec:662747.46, hellaswag_acc: 0.3031
Step: 17137, loss: 3.106458, norm: 0.3092, time(ms): 787.25, token/sec:665974.53, hellaswag_acc: 0.3031
Step: 17138, loss: 3.086274, norm: 0.3219, time(ms): 794.73, token/sec:659702.69, hellaswag_acc: 0.3031
Step: 17139, loss: 3.062243, norm: 0.3069, time(ms): 791.38, token/sec:662494.69, hellaswag_acc: 0.3031
Step: 17140, loss: 3.075455, norm: 0.3181, time(ms): 795.72, token/sec:658883.77, hellaswag_acc: 0.3031
Step: 17141, loss: 3.162863, norm: 0.3080, time(ms): 798.69, token/sec:656431.91, hellaswag_acc: 0.3031
Step: 17142, loss: 3.014425, norm: 0.3132, time(ms): 799.83, token/sec:655497.18, hellaswag_acc: 0.3031
Step: 17143, loss: 3.050077, norm: 0.2950, time(ms): 801.39, token/sec:654226.07, hellaswag_acc: 0.3031
Step: 17144, loss: 3.019382, norm: 0.2835, time(ms): 796.79, token/sec:658000.32, hellaswag_acc: 0.3031
Step: 17145, loss: 3.047370, norm: 0.3033, time(ms): 800.13, token/sec:655249.51, hellaswag_acc: 0.3031
Step: 17146, loss: 3.020309, norm: 0.2792, time(ms): 799.95, token/sec:655402.23, hellaswag_acc: 0.3031
Step: 17147, loss: 3.036402, norm: 0.3105, time(ms): 802.91, token/sec:652982.95, hellaswag_acc: 0.3031
Step: 17148, loss: 3.050638, norm: 0.2951, time(ms): 798.62, token/sec:656492.85, hellaswag_acc: 0.3031
Step: 17149, loss: 3.059178, norm: 0.2726, time(ms): 797.67, token/sec:657275.19, hellaswag_acc: 0.3031
Step: 17150, loss: 3.014117, norm: 0.2830, time(ms): 797.87, token/sec:657106.87, hellaswag_acc: 0.3031
Step: 17151, loss: 3.032729, norm: 0.2890, time(ms): 804.74, token/sec:651496.04, hellaswag_acc: 0.3031
Step: 17152, loss: 3.042840, norm: 0.2858, time(ms): 794.30, token/sec:660067.04, hellaswag_acc: 0.3031
Step: 17153, loss: 3.004100, norm: 0.2828, time(ms): 799.59, token/sec:655699.47, hellaswag_acc: 0.3031
Step: 17154, loss: 3.153732, norm: 0.3039, time(ms): 803.89, token/sec:652192.22, hellaswag_acc: 0.3031
Step: 17155, loss: 3.042464, norm: 0.3020, time(ms): 801.39, token/sec:654227.23, hellaswag_acc: 0.3031
Step: 17156, loss: 3.108412, norm: 0.3173, time(ms): 791.45, token/sec:662442.00, hellaswag_acc: 0.3031
Step: 17157, loss: 3.054867, norm: 0.3127, time(ms): 803.16, token/sec:652778.06, hellaswag_acc: 0.3031
Step: 17158, loss: 3.103014, norm: 0.3061, time(ms): 804.98, token/sec:651303.85, hellaswag_acc: 0.3031
Step: 17159, loss: 3.115105, norm: 0.2866, time(ms): 795.26, token/sec:659267.77, hellaswag_acc: 0.3031
Step: 17160, loss: 3.101540, norm: 0.3236, time(ms): 803.20, token/sec:652746.48, hellaswag_acc: 0.3031
Step: 17161, loss: 3.055265, norm: 0.2948, time(ms): 797.25, token/sec:657619.36, hellaswag_acc: 0.3031
Step: 17162, loss: 3.088347, norm: 0.3056, time(ms): 803.72, token/sec:652328.42, hellaswag_acc: 0.3031
Step: 17163, loss: 3.095182, norm: 0.2985, time(ms): 793.83, token/sec:660454.81, hellaswag_acc: 0.3031
Step: 17164, loss: 3.094866, norm: 0.3171, time(ms): 801.61, token/sec:654047.05, hellaswag_acc: 0.3031
Step: 17165, loss: 3.067996, norm: 0.3065, time(ms): 804.53, token/sec:651667.10, hellaswag_acc: 0.3031
Step: 17166, loss: 3.065973, norm: 0.3196, time(ms): 794.30, token/sec:660064.86, hellaswag_acc: 0.3031
Step: 17167, loss: 3.096673, norm: 0.2915, time(ms): 793.76, token/sec:660512.34, hellaswag_acc: 0.3031
Step: 17168, loss: 3.172173, norm: 0.3409, time(ms): 791.08, token/sec:662751.26, hellaswag_acc: 0.3031
Step: 17169, loss: 3.079955, norm: 0.2914, time(ms): 800.36, token/sec:655067.59, hellaswag_acc: 0.3031
Step: 17170, loss: 3.097414, norm: 0.3050, time(ms): 791.27, token/sec:662587.11, hellaswag_acc: 0.3031
Step: 17171, loss: 3.048787, norm: 0.2797, time(ms): 788.66, token/sec:664779.24, hellaswag_acc: 0.3031
Step: 17172, loss: 3.051455, norm: 0.2894, time(ms): 797.80, token/sec:657168.53, hellaswag_acc: 0.3031
Step: 17173, loss: 3.054328, norm: 0.3036, time(ms): 793.48, token/sec:660741.76, hellaswag_acc: 0.3031
Step: 17174, loss: 3.069076, norm: 0.2788, time(ms): 805.96, token/sec:650512.57, hellaswag_acc: 0.3031
Step: 17175, loss: 3.091949, norm: 0.2844, time(ms): 796.13, token/sec:658547.93, hellaswag_acc: 0.3031
Step: 17176, loss: 3.045200, norm: 0.2785, time(ms): 794.71, token/sec:659724.66, hellaswag_acc: 0.3031
Step: 17177, loss: 3.120406, norm: 0.2895, time(ms): 793.47, token/sec:660749.31, hellaswag_acc: 0.3031
Step: 17178, loss: 3.171955, norm: 0.3783, time(ms): 796.19, token/sec:658492.72, hellaswag_acc: 0.3031
Step: 17179, loss: 3.019999, norm: 0.3015, time(ms): 797.12, token/sec:657731.68, hellaswag_acc: 0.3031
Step: 17180, loss: 3.016116, norm: 0.2915, time(ms): 796.39, token/sec:658331.46, hellaswag_acc: 0.3031
Step: 17181, loss: 3.070647, norm: 0.2635, time(ms): 799.72, token/sec:655586.29, hellaswag_acc: 0.3031
Step: 17182, loss: 3.058388, norm: 0.2884, time(ms): 799.95, token/sec:655403.99, hellaswag_acc: 0.3031
Step: 17183, loss: 3.092652, norm: 0.3124, time(ms): 797.40, token/sec:657499.82, hellaswag_acc: 0.3031
Step: 17184, loss: 3.120310, norm: 0.3307, time(ms): 790.83, token/sec:662961.25, hellaswag_acc: 0.3031
Step: 17185, loss: 3.034156, norm: 0.3300, time(ms): 789.04, token/sec:664465.68, hellaswag_acc: 0.3031
Step: 17186, loss: 3.082766, norm: 0.2968, time(ms): 792.11, token/sec:661888.30, hellaswag_acc: 0.3031
Step: 17187, loss: 3.087666, norm: 0.2987, time(ms): 792.93, token/sec:661205.86, hellaswag_acc: 0.3031
Step: 17188, loss: 3.108876, norm: 0.2974, time(ms): 800.14, token/sec:655244.24, hellaswag_acc: 0.3031
Step: 17189, loss: 3.140586, norm: 0.3453, time(ms): 802.00, token/sec:653727.98, hellaswag_acc: 0.3031
Step: 17190, loss: 3.027686, norm: 0.3098, time(ms): 796.96, token/sec:657857.80, hellaswag_acc: 0.3031
Step: 17191, loss: 3.152277, norm: 0.3161, time(ms): 800.56, token/sec:654900.79, hellaswag_acc: 0.3031
Step: 17192, loss: 3.104302, norm: 0.3228, time(ms): 801.79, token/sec:653895.16, hellaswag_acc: 0.3031
Step: 17193, loss: 3.104616, norm: 0.3007, time(ms): 797.73, token/sec:657222.74, hellaswag_acc: 0.3031
Step: 17194, loss: 3.140694, norm: 0.3139, time(ms): 800.50, token/sec:654948.58, hellaswag_acc: 0.3031
Step: 17195, loss: 3.059475, norm: 0.2893, time(ms): 801.21, token/sec:654366.82, hellaswag_acc: 0.3031
Step: 17196, loss: 3.112108, norm: 0.3295, time(ms): 790.77, token/sec:663009.03, hellaswag_acc: 0.3031
Step: 17197, loss: 3.137177, norm: 0.2830, time(ms): 805.00, token/sec:651292.28, hellaswag_acc: 0.3031
Step: 17198, loss: 3.059861, norm: 0.3054, time(ms): 804.90, token/sec:651367.13, hellaswag_acc: 0.3031
Step: 17199, loss: 3.126395, norm: 0.3208, time(ms): 790.69, token/sec:663080.40, hellaswag_acc: 0.3031
Step: 17200, loss: 3.145321, norm: 0.2860, time(ms): 797.30, token/sec:657578.66, hellaswag_acc: 0.3031
Step: 17201, loss: 3.177642, norm: 0.3472, time(ms): 791.03, token/sec:662793.21, hellaswag_acc: 0.3031
Step: 17202, loss: 3.149130, norm: 0.2957, time(ms): 800.57, token/sec:654890.26, hellaswag_acc: 0.3031
Step: 17203, loss: 3.103576, norm: 0.3164, time(ms): 793.44, token/sec:660777.70, hellaswag_acc: 0.3031
Step: 17204, loss: 3.133862, norm: 0.3208, time(ms): 788.87, token/sec:664610.07, hellaswag_acc: 0.3031
Step: 17205, loss: 3.132841, norm: 0.3200, time(ms): 789.84, token/sec:663789.95, hellaswag_acc: 0.3031
Step: 17206, loss: 3.150209, norm: 0.3081, time(ms): 802.38, token/sec:653414.27, hellaswag_acc: 0.3031
Step: 17207, loss: 3.115200, norm: 0.2954, time(ms): 804.88, token/sec:651388.74, hellaswag_acc: 0.3031
Step: 17208, loss: 3.119371, norm: 0.3068, time(ms): 789.04, token/sec:664467.09, hellaswag_acc: 0.3031
Step: 17209, loss: 3.098736, norm: 0.3218, time(ms): 796.40, token/sec:658323.18, hellaswag_acc: 0.3031
Step: 17210, loss: 3.082586, norm: 0.2694, time(ms): 791.85, token/sec:662107.11, hellaswag_acc: 0.3031
Step: 17211, loss: 3.087766, norm: 0.3119, time(ms): 800.94, token/sec:654588.68, hellaswag_acc: 0.3031
Step: 17212, loss: 3.082963, norm: 0.2933, time(ms): 790.56, token/sec:663183.98, hellaswag_acc: 0.3031
Step: 17213, loss: 3.095328, norm: 0.2877, time(ms): 787.94, token/sec:665386.72, hellaswag_acc: 0.3031
Step: 17214, loss: 3.090174, norm: 0.2799, time(ms): 789.36, token/sec:664192.53, hellaswag_acc: 0.3031
Step: 17215, loss: 3.067640, norm: 0.2931, time(ms): 791.90, token/sec:662061.47, hellaswag_acc: 0.3031
Step: 17216, loss: 3.089183, norm: 0.2885, time(ms): 798.38, token/sec:656693.21, hellaswag_acc: 0.3031
Step: 17217, loss: 3.066501, norm: 0.3195, time(ms): 802.06, token/sec:653674.74, hellaswag_acc: 0.3031
Step: 17218, loss: 3.063462, norm: 0.2881, time(ms): 795.48, token/sec:659087.57, hellaswag_acc: 0.3031
Step: 17219, loss: 3.076707, norm: 0.2830, time(ms): 801.45, token/sec:654177.02, hellaswag_acc: 0.3031
Step: 17220, loss: 3.002133, norm: 0.2811, time(ms): 795.48, token/sec:659086.38, hellaswag_acc: 0.3031
Step: 17221, loss: 3.075734, norm: 0.2765, time(ms): 801.97, token/sec:653750.33, hellaswag_acc: 0.3031
Step: 17222, loss: 3.051056, norm: 0.2932, time(ms): 802.45, token/sec:653355.25, hellaswag_acc: 0.3031
Step: 17223, loss: 3.026865, norm: 0.2771, time(ms): 800.00, token/sec:655362.38, hellaswag_acc: 0.3031
Step: 17224, loss: 3.017076, norm: 0.2762, time(ms): 791.37, token/sec:662510.26, hellaswag_acc: 0.3031
Step: 17225, loss: 3.092740, norm: 0.2796, time(ms): 806.83, token/sec:649809.79, hellaswag_acc: 0.3031
Step: 17226, loss: 3.057264, norm: 0.2980, time(ms): 798.82, token/sec:656331.01, hellaswag_acc: 0.3031
Step: 17227, loss: 3.072824, norm: 0.2997, time(ms): 796.92, token/sec:657891.26, hellaswag_acc: 0.3031
Step: 17228, loss: 3.127475, norm: 0.2846, time(ms): 803.50, token/sec:652501.66, hellaswag_acc: 0.3031
Step: 17229, loss: 3.101686, norm: 0.2812, time(ms): 802.44, token/sec:653364.96, hellaswag_acc: 0.3031
Step: 17230, loss: 3.097100, norm: 0.3135, time(ms): 790.15, token/sec:663527.57, hellaswag_acc: 0.3031
Step: 17231, loss: 3.125379, norm: 0.2957, time(ms): 807.09, token/sec:649600.75, hellaswag_acc: 0.3031
Step: 17232, loss: 3.058399, norm: 0.2832, time(ms): 802.37, token/sec:653425.53, hellaswag_acc: 0.3031
Step: 17233, loss: 3.084394, norm: 0.2971, time(ms): 794.53, token/sec:659869.96, hellaswag_acc: 0.3031
Step: 17234, loss: 3.076424, norm: 0.2847, time(ms): 802.58, token/sec:653253.55, hellaswag_acc: 0.3031
Step: 17235, loss: 3.115782, norm: 0.2902, time(ms): 800.92, token/sec:654609.53, hellaswag_acc: 0.3031
Step: 17236, loss: 3.126266, norm: 0.2857, time(ms): 797.55, token/sec:657369.90, hellaswag_acc: 0.3031
Step: 17237, loss: 3.038890, norm: 0.2960, time(ms): 801.93, token/sec:653783.96, hellaswag_acc: 0.3031
Step: 17238, loss: 3.062310, norm: 0.2843, time(ms): 798.97, token/sec:656203.90, hellaswag_acc: 0.3031
Step: 17239, loss: 3.111505, norm: 0.2734, time(ms): 802.48, token/sec:653332.74, hellaswag_acc: 0.3031
Step: 17240, loss: 3.105117, norm: 0.2936, time(ms): 797.51, token/sec:657406.84, hellaswag_acc: 0.3031
Step: 17241, loss: 3.120297, norm: 0.2842, time(ms): 797.51, token/sec:657409.59, hellaswag_acc: 0.3031
Step: 17242, loss: 3.118294, norm: 0.2936, time(ms): 802.50, token/sec:653316.63, hellaswag_acc: 0.3031
Step: 17243, loss: 3.151546, norm: 0.2909, time(ms): 798.54, token/sec:656556.75, hellaswag_acc: 0.3031
Step: 17244, loss: 3.072051, norm: 0.2846, time(ms): 795.23, token/sec:659289.71, hellaswag_acc: 0.3031
Step: 17245, loss: 3.073841, norm: 0.2771, time(ms): 806.09, token/sec:650411.36, hellaswag_acc: 0.3031
Step: 17246, loss: 3.108796, norm: 0.2845, time(ms): 794.31, token/sec:660056.54, hellaswag_acc: 0.3031
Step: 17247, loss: 3.106886, norm: 0.2872, time(ms): 1297.73, token/sec:404002.51, hellaswag_acc: 0.3031
Step: 17248, loss: 3.174875, norm: 0.3058, time(ms): 787.08, token/sec:666115.54, hellaswag_acc: 0.3031
Step: 17249, loss: 3.170051, norm: 0.3242, time(ms): 786.78, token/sec:666375.93, hellaswag_acc: 0.3031
rank 0 sample 0: Hello, I'm a language model, and I'll be doing things, as there's a lot of software people use to write on top, but I can
rank 0 sample 1: Hello, I'm a language model, so when I say that, "Why do I tell other languages not to teach?" "Why don't they teach the
rank 0 sample 2: Hello, I'm a language model, so I might as well go to my native language, and start working on the grammar, and then I'll be sure
rank 0 sample 3: Hello, I'm a language model, so for me this is the language that we as a society would expect to have...it's not very efficient to develop
rank 1 sample 0: Hello, I'm a language model, as far as I'm concerned, "
You have to add a few bits to each bit and you'll have to
rank 1 sample 1: Hello, I'm a language model, not an author. I'm a little bored, but am able to teach,
[nondisc.com]
rank 1 sample 2: Hello, I'm a language model, but
- It's a language model, but it's like
a language model. The reason why I have a
rank 1 sample 3: Hello, I'm a language model, and I'm working with
it (So, we only have input
data, with .so, and , and
Step: 17250, loss: 3.172634, norm: 0.3171, time(ms): 3812.60, token/sec:137514.53, val_loss: 3.0767, hellaswag_acc: 0.3031
Step: 17251, loss: 3.199963, norm: 0.3952, time(ms): 787.69, token/sec:665601.81, hellaswag_acc: 0.3031
Step: 17252, loss: 3.093752, norm: 0.3300, time(ms): 788.51, token/sec:664908.69, hellaswag_acc: 0.3031
Step: 17253, loss: 3.078278, norm: 0.3085, time(ms): 802.22, token/sec:653545.35, hellaswag_acc: 0.3031
Step: 17254, loss: 3.149629, norm: 0.3288, time(ms): 802.73, token/sec:653127.44, hellaswag_acc: 0.3031
Step: 17255, loss: 3.096914, norm: 0.3195, time(ms): 791.55, token/sec:662358.00, hellaswag_acc: 0.3031
Step: 17256, loss: 3.123497, norm: 0.3258, time(ms): 802.13, token/sec:653621.11, hellaswag_acc: 0.3031
Step: 17257, loss: 3.123559, norm: 0.3056, time(ms): 789.67, token/sec:663932.84, hellaswag_acc: 0.3031
Step: 17258, loss: 3.154670, norm: 0.3029, time(ms): 793.97, token/sec:660335.02, hellaswag_acc: 0.3031
Step: 17259, loss: 3.132541, norm: 0.2934, time(ms): 793.36, token/sec:660844.82, hellaswag_acc: 0.3031
Step: 17260, loss: 3.087584, norm: 0.2961, time(ms): 793.45, token/sec:660771.94, hellaswag_acc: 0.3031
Step: 17261, loss: 3.005336, norm: 0.2830, time(ms): 791.05, token/sec:662776.03, hellaswag_acc: 0.3031
Step: 17262, loss: 3.066904, norm: 0.2953, time(ms): 792.30, token/sec:661724.97, hellaswag_acc: 0.3031
Step: 17263, loss: 3.053237, norm: 0.2901, time(ms): 791.22, token/sec:662629.84, hellaswag_acc: 0.3031
Step: 17264, loss: 3.072803, norm: 0.2950, time(ms): 798.21, token/sec:656826.99, hellaswag_acc: 0.3031
Step: 17265, loss: 3.085529, norm: 0.2896, time(ms): 794.02, token/sec:660298.54, hellaswag_acc: 0.3031
Step: 17266, loss: 3.141480, norm: 0.3109, time(ms): 801.28, token/sec:654317.17, hellaswag_acc: 0.3031
Step: 17267, loss: 3.039733, norm: 0.3064, time(ms): 803.31, token/sec:652662.59, hellaswag_acc: 0.3031
Step: 17268, loss: 3.128974, norm: 0.3582, time(ms): 802.47, token/sec:653344.38, hellaswag_acc: 0.3031
Step: 17269, loss: 3.071449, norm: 0.3018, time(ms): 794.65, token/sec:659773.15, hellaswag_acc: 0.3031
Step: 17270, loss: 3.113089, norm: 0.3017, time(ms): 796.40, token/sec:658326.33, hellaswag_acc: 0.3031
Step: 17271, loss: 3.105814, norm: 0.2814, time(ms): 807.90, token/sec:648948.39, hellaswag_acc: 0.3031
Step: 17272, loss: 3.016760, norm: 0.2951, time(ms): 798.79, token/sec:656352.95, hellaswag_acc: 0.3031
Step: 17273, loss: 3.045077, norm: 0.3384, time(ms): 792.51, token/sec:661551.58, hellaswag_acc: 0.3031
Step: 17274, loss: 3.047344, norm: 0.2802, time(ms): 806.24, token/sec:650285.38, hellaswag_acc: 0.3031
Step: 17275, loss: 3.078946, norm: 0.3279, time(ms): 795.10, token/sec:659402.60, hellaswag_acc: 0.3031
Step: 17276, loss: 3.035716, norm: 0.2984, time(ms): 804.04, token/sec:652068.64, hellaswag_acc: 0.3031
Step: 17277, loss: 3.095826, norm: 0.2921, time(ms): 798.12, token/sec:656902.53, hellaswag_acc: 0.3031
Step: 17278, loss: 3.054100, norm: 0.2847, time(ms): 795.41, token/sec:659139.13, hellaswag_acc: 0.3031
Step: 17279, loss: 3.134157, norm: 0.3323, time(ms): 805.78, token/sec:650656.73, hellaswag_acc: 0.3031
Step: 17280, loss: 3.131435, norm: 0.3189, time(ms): 802.36, token/sec:653433.10, hellaswag_acc: 0.3031
Step: 17281, loss: 3.139542, norm: 0.3063, time(ms): 787.51, token/sec:665752.74, hellaswag_acc: 0.3031
Step: 17282, loss: 3.023814, norm: 0.3112, time(ms): 785.06, token/sec:667831.01, hellaswag_acc: 0.3031
Step: 17283, loss: 3.087873, norm: 0.3136, time(ms): 799.32, token/sec:655915.00, hellaswag_acc: 0.3031
Step: 17284, loss: 3.148385, norm: 0.3323, time(ms): 791.36, token/sec:662514.45, hellaswag_acc: 0.3031
Step: 17285, loss: 3.142517, norm: 0.3174, time(ms): 789.86, token/sec:663772.32, hellaswag_acc: 0.3031
Step: 17286, loss: 3.087256, norm: 0.3111, time(ms): 798.14, token/sec:656886.05, hellaswag_acc: 0.3031
Step: 17287, loss: 3.056290, norm: 0.2876, time(ms): 806.00, token/sec:650481.59, hellaswag_acc: 0.3031
Step: 17288, loss: 3.102612, norm: 0.3202, time(ms): 799.27, token/sec:655962.15, hellaswag_acc: 0.3031
Step: 17289, loss: 3.101454, norm: 0.2905, time(ms): 792.20, token/sec:661809.21, hellaswag_acc: 0.3031
Step: 17290, loss: 3.129759, norm: 0.2860, time(ms): 792.27, token/sec:661757.43, hellaswag_acc: 0.3031
Step: 17291, loss: 3.114497, norm: 0.2761, time(ms): 794.43, token/sec:659950.96, hellaswag_acc: 0.3031
Step: 17292, loss: 3.042138, norm: 0.2940, time(ms): 796.61, token/sec:658147.63, hellaswag_acc: 0.3031
Step: 17293, loss: 3.070155, norm: 0.2965, time(ms): 800.60, token/sec:654865.88, hellaswag_acc: 0.3031
Step: 17294, loss: 3.096519, norm: 0.2777, time(ms): 803.98, token/sec:652115.25, hellaswag_acc: 0.3031
Step: 17295, loss: 3.095371, norm: 0.2762, time(ms): 791.30, token/sec:662566.35, hellaswag_acc: 0.3031
Step: 17296, loss: 3.139203, norm: 0.2980, time(ms): 789.45, token/sec:664120.32, hellaswag_acc: 0.3031
Step: 17297, loss: 3.052398, norm: 0.2774, time(ms): 789.48, token/sec:664096.86, hellaswag_acc: 0.3031
Step: 17298, loss: 3.062301, norm: 0.2585, time(ms): 793.45, token/sec:660772.34, hellaswag_acc: 0.3031
Step: 17299, loss: 3.016571, norm: 0.2924, time(ms): 791.52, token/sec:662380.94, hellaswag_acc: 0.3031
Step: 17300, loss: 3.034221, norm: 0.2727, time(ms): 798.49, token/sec:656597.14, hellaswag_acc: 0.3031
Step: 17301, loss: 3.122605, norm: 0.2874, time(ms): 803.44, token/sec:652553.36, hellaswag_acc: 0.3031
Step: 17302, loss: 3.053952, norm: 0.2926, time(ms): 801.05, token/sec:654496.92, hellaswag_acc: 0.3031
Step: 17303, loss: 3.063577, norm: 0.2725, time(ms): 795.04, token/sec:659449.46, hellaswag_acc: 0.3031
Step: 17304, loss: 3.109255, norm: 0.2826, time(ms): 802.61, token/sec:653229.68, hellaswag_acc: 0.3031
Step: 17305, loss: 3.087161, norm: 0.2861, time(ms): 803.64, token/sec:652390.93, hellaswag_acc: 0.3031
Step: 17306, loss: 3.097245, norm: 0.2588, time(ms): 788.04, token/sec:665306.80, hellaswag_acc: 0.3031
Step: 17307, loss: 3.137921, norm: 0.3223, time(ms): 790.50, token/sec:663232.59, hellaswag_acc: 0.3031
Step: 17308, loss: 3.116220, norm: 0.3458, time(ms): 796.08, token/sec:658589.55, hellaswag_acc: 0.3031
Step: 17309, loss: 3.098799, norm: 0.3110, time(ms): 790.09, token/sec:663578.03, hellaswag_acc: 0.3031
Step: 17310, loss: 3.076543, norm: 0.3524, time(ms): 792.51, token/sec:661552.78, hellaswag_acc: 0.3031
Step: 17311, loss: 3.156391, norm: 0.3089, time(ms): 795.08, token/sec:659412.48, hellaswag_acc: 0.3031
Step: 17312, loss: 3.113909, norm: 0.3283, time(ms): 804.73, token/sec:651509.94, hellaswag_acc: 0.3031
Step: 17313, loss: 3.094790, norm: 0.3227, time(ms): 797.45, token/sec:657456.18, hellaswag_acc: 0.3031
Step: 17314, loss: 3.060521, norm: 0.3137, time(ms): 795.20, token/sec:659315.01, hellaswag_acc: 0.3031
Step: 17315, loss: 3.113865, norm: 0.2900, time(ms): 801.07, token/sec:654483.48, hellaswag_acc: 0.3031
Step: 17316, loss: 3.135402, norm: 0.2895, time(ms): 804.20, token/sec:651936.61, hellaswag_acc: 0.3031
Step: 17317, loss: 3.107616, norm: 0.3694, time(ms): 796.08, token/sec:658589.94, hellaswag_acc: 0.3031
Step: 17318, loss: 3.142945, norm: 0.3433, time(ms): 795.18, token/sec:659329.25, hellaswag_acc: 0.3031
Step: 17319, loss: 3.111383, norm: 0.3011, time(ms): 791.87, token/sec:662086.18, hellaswag_acc: 0.3031
Step: 17320, loss: 3.051883, norm: 0.2976, time(ms): 795.45, token/sec:659108.70, hellaswag_acc: 0.3031
Step: 17321, loss: 3.071542, norm: 0.3152, time(ms): 797.71, token/sec:657244.54, hellaswag_acc: 0.3031
Step: 17322, loss: 3.073955, norm: 0.2975, time(ms): 798.37, token/sec:656694.78, hellaswag_acc: 0.3031
Step: 17323, loss: 3.105215, norm: 0.2995, time(ms): 802.63, token/sec:653213.19, hellaswag_acc: 0.3031
Step: 17324, loss: 3.151989, norm: 0.2959, time(ms): 795.27, token/sec:659257.69, hellaswag_acc: 0.3031
Step: 17325, loss: 3.088528, norm: 0.2829, time(ms): 793.52, token/sec:660714.37, hellaswag_acc: 0.3031
Step: 17326, loss: 3.069925, norm: 0.3128, time(ms): 790.42, token/sec:663307.01, hellaswag_acc: 0.3031
Step: 17327, loss: 3.110382, norm: 0.2882, time(ms): 792.57, token/sec:661501.23, hellaswag_acc: 0.3031
Step: 17328, loss: 3.075223, norm: 0.2844, time(ms): 789.74, token/sec:663873.51, hellaswag_acc: 0.3031
Step: 17329, loss: 3.022304, norm: 0.2807, time(ms): 800.51, token/sec:654940.39, hellaswag_acc: 0.3031
Step: 17330, loss: 3.073395, norm: 0.2774, time(ms): 790.90, token/sec:662898.30, hellaswag_acc: 0.3031
Step: 17331, loss: 3.099855, norm: 0.2960, time(ms): 804.74, token/sec:651497.01, hellaswag_acc: 0.3031
Step: 17332, loss: 3.057447, norm: 0.2770, time(ms): 804.68, token/sec:651544.88, hellaswag_acc: 0.3031
Step: 17333, loss: 3.034534, norm: 0.2840, time(ms): 789.84, token/sec:663790.55, hellaswag_acc: 0.3031
Step: 17334, loss: 3.038360, norm: 0.2872, time(ms): 796.61, token/sec:658148.81, hellaswag_acc: 0.3031
Step: 17335, loss: 3.081724, norm: 0.2631, time(ms): 794.33, token/sec:660038.91, hellaswag_acc: 0.3031
Step: 17336, loss: 3.087422, norm: 0.2966, time(ms): 794.65, token/sec:659768.40, hellaswag_acc: 0.3031
Step: 17337, loss: 3.043491, norm: 0.2788, time(ms): 789.33, token/sec:664221.02, hellaswag_acc: 0.3031
Step: 17338, loss: 3.068874, norm: 0.2801, time(ms): 790.71, token/sec:663060.60, hellaswag_acc: 0.3031
Step: 17339, loss: 3.080387, norm: 0.2814, time(ms): 801.58, token/sec:654067.67, hellaswag_acc: 0.3031
Step: 17340, loss: 3.080219, norm: 0.2784, time(ms): 798.46, token/sec:656622.62, hellaswag_acc: 0.3031
Step: 17341, loss: 3.089869, norm: 0.2638, time(ms): 797.19, token/sec:657669.12, hellaswag_acc: 0.3031
Step: 17342, loss: 3.066848, norm: 0.3394, time(ms): 798.65, token/sec:656465.02, hellaswag_acc: 0.3031
Step: 17343, loss: 3.113349, norm: 0.3007, time(ms): 802.95, token/sec:652951.54, hellaswag_acc: 0.3031
Step: 17344, loss: 3.094247, norm: 0.3024, time(ms): 794.25, token/sec:660106.87, hellaswag_acc: 0.3031
Step: 17345, loss: 3.099705, norm: 0.3234, time(ms): 797.51, token/sec:657407.43, hellaswag_acc: 0.3031
Step: 17346, loss: 3.112736, norm: 0.3084, time(ms): 791.82, token/sec:662134.23, hellaswag_acc: 0.3031
Step: 17347, loss: 3.084938, norm: 0.2797, time(ms): 795.34, token/sec:659199.99, hellaswag_acc: 0.3031
Step: 17348, loss: 3.067221, norm: 0.3078, time(ms): 795.32, token/sec:659215.79, hellaswag_acc: 0.3031
Step: 17349, loss: 3.220496, norm: 0.3217, time(ms): 802.13, token/sec:653621.69, hellaswag_acc: 0.3031
Step: 17350, loss: 3.071610, norm: 0.2825, time(ms): 795.20, token/sec:659318.57, hellaswag_acc: 0.3031
Step: 17351, loss: 3.135057, norm: 0.2796, time(ms): 791.30, token/sec:662563.15, hellaswag_acc: 0.3031
Step: 17352, loss: 3.094480, norm: 0.2827, time(ms): 787.11, token/sec:666089.51, hellaswag_acc: 0.3031
Step: 17353, loss: 3.086342, norm: 0.3239, time(ms): 791.68, token/sec:662250.88, hellaswag_acc: 0.3031
Step: 17354, loss: 3.144768, norm: 0.3148, time(ms): 793.10, token/sec:661061.96, hellaswag_acc: 0.3031
Step: 17355, loss: 3.160813, norm: 0.3240, time(ms): 805.25, token/sec:651089.42, hellaswag_acc: 0.3031
Step: 17356, loss: 3.110689, norm: 0.3048, time(ms): 799.91, token/sec:655435.44, hellaswag_acc: 0.3031
Step: 17357, loss: 3.129875, norm: 0.3389, time(ms): 795.91, token/sec:658728.44, hellaswag_acc: 0.3031
Step: 17358, loss: 3.103333, norm: 0.3400, time(ms): 799.15, token/sec:656057.66, hellaswag_acc: 0.3031
Step: 17359, loss: 3.056633, norm: 0.3083, time(ms): 805.31, token/sec:651035.44, hellaswag_acc: 0.3031
Step: 17360, loss: 3.049229, norm: 0.2949, time(ms): 794.73, token/sec:659706.45, hellaswag_acc: 0.3031
Step: 17361, loss: 3.134119, norm: 0.3029, time(ms): 803.91, token/sec:652168.62, hellaswag_acc: 0.3031
Step: 17362, loss: 3.116457, norm: 0.3090, time(ms): 799.00, token/sec:656179.42, hellaswag_acc: 0.3031
Step: 17363, loss: 3.106486, norm: 0.3037, time(ms): 798.58, token/sec:656528.53, hellaswag_acc: 0.3031
Step: 17364, loss: 3.089769, norm: 0.3337, time(ms): 791.20, token/sec:662647.81, hellaswag_acc: 0.3031
Step: 17365, loss: 3.076284, norm: 0.3124, time(ms): 790.95, token/sec:662859.94, hellaswag_acc: 0.3031
Step: 17366, loss: 3.095315, norm: 0.3171, time(ms): 795.36, token/sec:659182.40, hellaswag_acc: 0.3031
Step: 17367, loss: 3.041441, norm: 0.3026, time(ms): 790.14, token/sec:663538.18, hellaswag_acc: 0.3031
Step: 17368, loss: 3.185308, norm: 0.3145, time(ms): 789.47, token/sec:664103.88, hellaswag_acc: 0.3031
Step: 17369, loss: 3.106168, norm: 0.2822, time(ms): 798.17, token/sec:656863.48, hellaswag_acc: 0.3031
Step: 17370, loss: 3.207989, norm: 0.3185, time(ms): 805.94, token/sec:650530.85, hellaswag_acc: 0.3031
Step: 17371, loss: 3.072503, norm: 0.2973, time(ms): 790.72, token/sec:663047.61, hellaswag_acc: 0.3031
Step: 17372, loss: 3.030958, norm: 0.2736, time(ms): 792.62, token/sec:661460.04, hellaswag_acc: 0.3031
Step: 17373, loss: 3.105517, norm: 0.2979, time(ms): 792.50, token/sec:661559.34, hellaswag_acc: 0.3031
Step: 17374, loss: 3.016013, norm: 0.2739, time(ms): 800.24, token/sec:655159.71, hellaswag_acc: 0.3031
Step: 17375, loss: 3.066196, norm: 0.2651, time(ms): 803.20, token/sec:652745.51, hellaswag_acc: 0.3031
Step: 17376, loss: 3.057661, norm: 0.2696, time(ms): 793.94, token/sec:660359.21, hellaswag_acc: 0.3031
Step: 17377, loss: 3.096872, norm: 0.2851, time(ms): 794.59, token/sec:659821.26, hellaswag_acc: 0.3031
Step: 17378, loss: 3.133630, norm: 0.3163, time(ms): 787.22, token/sec:665996.11, hellaswag_acc: 0.3031
Step: 17379, loss: 3.064458, norm: 0.3078, time(ms): 789.54, token/sec:664043.71, hellaswag_acc: 0.3031
Step: 17380, loss: 3.072982, norm: 0.3083, time(ms): 787.53, token/sec:665737.43, hellaswag_acc: 0.3031
Step: 17381, loss: 3.127154, norm: 0.3302, time(ms): 795.95, token/sec:658695.88, hellaswag_acc: 0.3031
Step: 17382, loss: 3.160907, norm: 0.3086, time(ms): 790.86, token/sec:662936.67, hellaswag_acc: 0.3031
Step: 17383, loss: 3.131038, norm: 0.3031, time(ms): 793.08, token/sec:661078.85, hellaswag_acc: 0.3031
Step: 17384, loss: 3.046667, norm: 0.3120, time(ms): 791.42, token/sec:662465.95, hellaswag_acc: 0.3031
Step: 17385, loss: 3.092185, norm: 0.3267, time(ms): 789.17, token/sec:664353.46, hellaswag_acc: 0.3031
Step: 17386, loss: 3.108549, norm: 0.3111, time(ms): 799.46, token/sec:655799.00, hellaswag_acc: 0.3031
Step: 17387, loss: 3.084327, norm: 0.2937, time(ms): 805.63, token/sec:650778.81, hellaswag_acc: 0.3031
Step: 17388, loss: 3.104951, norm: 0.3286, time(ms): 792.87, token/sec:661255.97, hellaswag_acc: 0.3031
Step: 17389, loss: 3.176379, norm: 0.3426, time(ms): 795.13, token/sec:659373.93, hellaswag_acc: 0.3031
Step: 17390, loss: 3.135685, norm: 0.3107, time(ms): 790.82, token/sec:662970.65, hellaswag_acc: 0.3031
Step: 17391, loss: 3.061023, norm: 0.3147, time(ms): 801.86, token/sec:653837.22, hellaswag_acc: 0.3031
Step: 17392, loss: 3.085588, norm: 0.2893, time(ms): 787.72, token/sec:665573.21, hellaswag_acc: 0.3031
Step: 17393, loss: 3.102462, norm: 0.2916, time(ms): 789.92, token/sec:663721.03, hellaswag_acc: 0.3031
Step: 17394, loss: 3.216040, norm: 0.3549, time(ms): 792.05, token/sec:661937.31, hellaswag_acc: 0.3031
Step: 17395, loss: 3.076356, norm: 0.3201, time(ms): 792.96, token/sec:661178.43, hellaswag_acc: 0.3031
Step: 17396, loss: 3.096925, norm: 0.3060, time(ms): 788.87, token/sec:664606.46, hellaswag_acc: 0.3031
Step: 17397, loss: 3.127665, norm: 0.3117, time(ms): 803.33, token/sec:652639.35, hellaswag_acc: 0.3031
Step: 17398, loss: 3.081448, norm: 0.2894, time(ms): 799.50, token/sec:655766.15, hellaswag_acc: 0.3031
Step: 17399, loss: 3.053084, norm: 0.2823, time(ms): 802.09, token/sec:653654.72, hellaswag_acc: 0.3031
Step: 17400, loss: 3.123123, norm: 0.4111, time(ms): 794.54, token/sec:659866.80, hellaswag_acc: 0.3031
Step: 17401, loss: 3.077729, norm: 0.2794, time(ms): 802.34, token/sec:653452.52, hellaswag_acc: 0.3031
Step: 17402, loss: 3.092667, norm: 0.2842, time(ms): 800.65, token/sec:654824.15, hellaswag_acc: 0.3031
Step: 17403, loss: 3.041769, norm: 0.2808, time(ms): 803.14, token/sec:652797.44, hellaswag_acc: 0.3031
Step: 17404, loss: 3.045979, norm: 0.2918, time(ms): 788.52, token/sec:664897.63, hellaswag_acc: 0.3031
Step: 17405, loss: 3.026281, norm: 0.3122, time(ms): 790.26, token/sec:663434.88, hellaswag_acc: 0.3031
Step: 17406, loss: 3.083955, norm: 0.2782, time(ms): 796.49, token/sec:658250.07, hellaswag_acc: 0.3031
Step: 17407, loss: 3.110999, norm: 0.2777, time(ms): 789.20, token/sec:664332.59, hellaswag_acc: 0.3031
Step: 17408, loss: 3.085111, norm: 0.3398, time(ms): 790.90, token/sec:662902.90, hellaswag_acc: 0.3031
Step: 17409, loss: 3.072578, norm: 0.2928, time(ms): 799.14, token/sec:656062.16, hellaswag_acc: 0.3031
Step: 17410, loss: 3.086700, norm: 0.2793, time(ms): 799.25, token/sec:655976.24, hellaswag_acc: 0.3031
Step: 17411, loss: 3.083125, norm: 0.2892, time(ms): 803.34, token/sec:652637.61, hellaswag_acc: 0.3031
Step: 17412, loss: 3.119492, norm: 0.3050, time(ms): 799.78, token/sec:655536.45, hellaswag_acc: 0.3031
Step: 17413, loss: 3.024802, norm: 0.2759, time(ms): 791.98, token/sec:661996.89, hellaswag_acc: 0.3031
Step: 17414, loss: 3.080550, norm: 0.3060, time(ms): 791.12, token/sec:662715.51, hellaswag_acc: 0.3031
Step: 17415, loss: 3.099718, norm: 0.3072, time(ms): 796.73, token/sec:658048.56, hellaswag_acc: 0.3031
Step: 17416, loss: 3.206860, norm: 0.3157, time(ms): 793.71, token/sec:660552.22, hellaswag_acc: 0.3031
Step: 17417, loss: 3.126717, norm: 0.2956, time(ms): 805.99, token/sec:650488.51, hellaswag_acc: 0.3031
Step: 17418, loss: 3.045686, norm: 0.2956, time(ms): 798.32, token/sec:656741.46, hellaswag_acc: 0.3031
Step: 17419, loss: 3.080431, norm: 0.2668, time(ms): 798.37, token/sec:656697.92, hellaswag_acc: 0.3031
Step: 17420, loss: 3.085094, norm: 0.3054, time(ms): 801.29, token/sec:654308.41, hellaswag_acc: 0.3031
Step: 17421, loss: 3.101329, norm: 0.3272, time(ms): 798.85, token/sec:656306.52, hellaswag_acc: 0.3031
Step: 17422, loss: 3.088532, norm: 0.3393, time(ms): 798.13, token/sec:656894.68, hellaswag_acc: 0.3031
Step: 17423, loss: 3.096321, norm: 0.3453, time(ms): 804.21, token/sec:651927.91, hellaswag_acc: 0.3031
Step: 17424, loss: 3.163289, norm: 0.3064, time(ms): 797.93, token/sec:657062.69, hellaswag_acc: 0.3031
Step: 17425, loss: 3.074470, norm: 0.3241, time(ms): 798.25, token/sec:656800.31, hellaswag_acc: 0.3031
Step: 17426, loss: 3.098366, norm: 0.3173, time(ms): 799.82, token/sec:655511.25, hellaswag_acc: 0.3031
Step: 17427, loss: 3.042977, norm: 0.2905, time(ms): 800.36, token/sec:655067.79, hellaswag_acc: 0.3031
Step: 17428, loss: 3.068542, norm: 0.3091, time(ms): 799.79, token/sec:655529.81, hellaswag_acc: 0.3031
Step: 17429, loss: 3.118720, norm: 0.3201, time(ms): 799.56, token/sec:655721.57, hellaswag_acc: 0.3031
Step: 17430, loss: 3.093236, norm: 0.2934, time(ms): 799.85, token/sec:655481.35, hellaswag_acc: 0.3031
Step: 17431, loss: 3.086076, norm: 0.2935, time(ms): 800.54, token/sec:654918.34, hellaswag_acc: 0.3031
Step: 17432, loss: 3.115216, norm: 0.2945, time(ms): 794.53, token/sec:659875.31, hellaswag_acc: 0.3031
Step: 17433, loss: 3.109494, norm: 0.3174, time(ms): 806.99, token/sec:649685.00, hellaswag_acc: 0.3031
Step: 17434, loss: 3.115725, norm: 0.2887, time(ms): 794.97, token/sec:659507.01, hellaswag_acc: 0.3031
Step: 17435, loss: 3.070847, norm: 0.2774, time(ms): 796.05, token/sec:658615.78, hellaswag_acc: 0.3031
Step: 17436, loss: 3.107625, norm: 0.2944, time(ms): 789.41, token/sec:664148.60, hellaswag_acc: 0.3031
Step: 17437, loss: 3.095790, norm: 0.2884, time(ms): 790.57, token/sec:663180.58, hellaswag_acc: 0.3031
Step: 17438, loss: 3.060164, norm: 0.2937, time(ms): 1511.91, token/sec:346772.96, hellaswag_acc: 0.3031
Step: 17439, loss: 3.123259, norm: 0.3001, time(ms): 796.65, token/sec:658114.93, hellaswag_acc: 0.3031
Step: 17440, loss: 3.085860, norm: 0.2785, time(ms): 795.55, token/sec:659027.52, hellaswag_acc: 0.3031
Step: 17441, loss: 3.089343, norm: 0.2946, time(ms): 788.50, token/sec:664914.52, hellaswag_acc: 0.3031
Step: 17442, loss: 3.089488, norm: 0.2686, time(ms): 785.61, token/sec:667362.63, hellaswag_acc: 0.3031
Step: 17443, loss: 3.086657, norm: 0.2779, time(ms): 787.66, token/sec:665631.43, hellaswag_acc: 0.3031
Step: 17444, loss: 3.054427, norm: 0.2886, time(ms): 794.14, token/sec:660193.08, hellaswag_acc: 0.3031
Step: 17445, loss: 3.046253, norm: 0.2986, time(ms): 792.73, token/sec:661368.73, hellaswag_acc: 0.3031
Step: 17446, loss: 3.059214, norm: 0.2896, time(ms): 788.69, token/sec:664755.33, hellaswag_acc: 0.3031
Step: 17447, loss: 3.040397, norm: 0.3095, time(ms): 799.60, token/sec:655686.57, hellaswag_acc: 0.3031
Step: 17448, loss: 3.083829, norm: 0.2879, time(ms): 803.42, token/sec:652573.50, hellaswag_acc: 0.3031
Step: 17449, loss: 3.049688, norm: 0.2979, time(ms): 801.40, token/sec:654211.47, hellaswag_acc: 0.3031
Step: 17450, loss: 3.024050, norm: 0.2776, time(ms): 790.70, token/sec:663070.80, hellaswag_acc: 0.3031
Step: 17451, loss: 3.026814, norm: 0.2933, time(ms): 792.89, token/sec:661236.28, hellaswag_acc: 0.3031
Step: 17452, loss: 3.029883, norm: 0.2934, time(ms): 794.19, token/sec:660153.64, hellaswag_acc: 0.3031
Step: 17453, loss: 3.045349, norm: 0.2716, time(ms): 797.41, token/sec:657490.77, hellaswag_acc: 0.3031
Step: 17454, loss: 3.000461, norm: 0.2801, time(ms): 804.44, token/sec:651742.62, hellaswag_acc: 0.3031
Step: 17455, loss: 3.000791, norm: 0.2641, time(ms): 789.40, token/sec:664156.63, hellaswag_acc: 0.3031
Step: 17456, loss: 3.066794, norm: 0.2916, time(ms): 785.76, token/sec:667237.28, hellaswag_acc: 0.3031
Step: 17457, loss: 3.027682, norm: 0.2989, time(ms): 791.03, token/sec:662789.61, hellaswag_acc: 0.3031
Step: 17458, loss: 3.021011, norm: 0.2930, time(ms): 794.06, token/sec:660259.28, hellaswag_acc: 0.3031
Step: 17459, loss: 3.020401, norm: 0.2844, time(ms): 792.17, token/sec:661834.51, hellaswag_acc: 0.3031
Step: 17460, loss: 3.091509, norm: 0.2792, time(ms): 802.13, token/sec:653617.61, hellaswag_acc: 0.3031
Step: 17461, loss: 3.060956, norm: 0.2979, time(ms): 805.33, token/sec:651021.95, hellaswag_acc: 0.3031
Step: 17462, loss: 3.130857, norm: 0.3242, time(ms): 800.12, token/sec:655265.13, hellaswag_acc: 0.3031
Step: 17463, loss: 3.058126, norm: 0.3242, time(ms): 790.20, token/sec:663490.93, hellaswag_acc: 0.3031
Step: 17464, loss: 3.253252, norm: 0.3687, time(ms): 806.67, token/sec:649944.81, hellaswag_acc: 0.3031
Step: 17465, loss: 3.136943, norm: 0.3093, time(ms): 802.35, token/sec:653440.68, hellaswag_acc: 0.3031
Step: 17466, loss: 3.136091, norm: 0.3062, time(ms): 794.72, token/sec:659714.37, hellaswag_acc: 0.3031
Step: 17467, loss: 3.057628, norm: 0.2941, time(ms): 799.51, token/sec:655757.74, hellaswag_acc: 0.3031
Step: 17468, loss: 3.097810, norm: 0.3151, time(ms): 802.09, token/sec:653655.89, hellaswag_acc: 0.3031
Step: 17469, loss: 3.095938, norm: 0.2825, time(ms): 802.41, token/sec:653391.75, hellaswag_acc: 0.3031
Step: 17470, loss: 3.119324, norm: 0.3077, time(ms): 796.10, token/sec:658570.22, hellaswag_acc: 0.3031
Step: 17471, loss: 3.102776, norm: 0.3170, time(ms): 798.05, token/sec:656964.35, hellaswag_acc: 0.3031
Step: 17472, loss: 3.066410, norm: 0.2843, time(ms): 802.53, token/sec:653290.81, hellaswag_acc: 0.3031
Step: 17473, loss: 3.068609, norm: 0.3250, time(ms): 797.55, token/sec:657371.47, hellaswag_acc: 0.3031
Step: 17474, loss: 3.056054, norm: 0.3015, time(ms): 798.42, token/sec:656654.19, hellaswag_acc: 0.3031
Step: 17475, loss: 3.058795, norm: 0.2946, time(ms): 804.20, token/sec:651933.90, hellaswag_acc: 0.3031
Step: 17476, loss: 3.098142, norm: 0.3303, time(ms): 802.70, token/sec:653154.60, hellaswag_acc: 0.3031
Step: 17477, loss: 3.087628, norm: 0.2962, time(ms): 784.53, token/sec:668286.23, hellaswag_acc: 0.3031
Step: 17478, loss: 3.064321, norm: 0.2867, time(ms): 792.52, token/sec:661542.03, hellaswag_acc: 0.3031
Step: 17479, loss: 3.051630, norm: 0.2859, time(ms): 790.11, token/sec:663561.01, hellaswag_acc: 0.3031
Step: 17480, loss: 3.132778, norm: 0.2808, time(ms): 790.32, token/sec:663390.65, hellaswag_acc: 0.3031
Step: 17481, loss: 3.096408, norm: 0.2855, time(ms): 797.52, token/sec:657398.98, hellaswag_acc: 0.3031
Step: 17482, loss: 3.092831, norm: 0.2897, time(ms): 794.98, token/sec:659495.94, hellaswag_acc: 0.3031
Step: 17483, loss: 3.100939, norm: 0.2917, time(ms): 798.08, token/sec:656937.26, hellaswag_acc: 0.3031
Step: 17484, loss: 3.084772, norm: 0.2954, time(ms): 791.94, token/sec:662030.17, hellaswag_acc: 0.3031
Step: 17485, loss: 2.968096, norm: 0.2708, time(ms): 791.91, token/sec:662053.89, hellaswag_acc: 0.3031
Step: 17486, loss: 3.054994, norm: 0.2787, time(ms): 789.62, token/sec:663971.73, hellaswag_acc: 0.3031
Step: 17487, loss: 3.052513, norm: 0.2648, time(ms): 786.77, token/sec:666380.98, hellaswag_acc: 0.3031
Step: 17488, loss: 3.024617, norm: 0.2818, time(ms): 789.59, token/sec:663999.40, hellaswag_acc: 0.3031
Step: 17489, loss: 3.071867, norm: 0.2763, time(ms): 794.21, token/sec:660141.15, hellaswag_acc: 0.3031
Step: 17490, loss: 3.029161, norm: 0.2732, time(ms): 801.88, token/sec:653824.97, hellaswag_acc: 0.3031
Step: 17491, loss: 3.015189, norm: 0.2756, time(ms): 797.53, token/sec:657391.51, hellaswag_acc: 0.3031
Step: 17492, loss: 2.968292, norm: 0.2692, time(ms): 805.07, token/sec:651233.07, hellaswag_acc: 0.3031
Step: 17493, loss: 3.036396, norm: 0.2824, time(ms): 789.81, token/sec:663817.80, hellaswag_acc: 0.3031
Step: 17494, loss: 3.040492, norm: 0.2653, time(ms): 799.65, token/sec:655649.62, hellaswag_acc: 0.3031
Step: 17495, loss: 3.029282, norm: 0.2697, time(ms): 790.87, token/sec:662928.88, hellaswag_acc: 0.3031
Step: 17496, loss: 3.071379, norm: 0.2805, time(ms): 795.90, token/sec:658733.57, hellaswag_acc: 0.3031
Step: 17497, loss: 3.075783, norm: 0.3022, time(ms): 789.17, token/sec:664353.67, hellaswag_acc: 0.3031
Step: 17498, loss: 3.076244, norm: 0.2789, time(ms): 792.86, token/sec:661261.93, hellaswag_acc: 0.3031
Step: 17499, loss: 3.071288, norm: 0.2771, time(ms): 797.48, token/sec:657434.36, hellaswag_acc: 0.3031
rank 0 sample 0: Hello, I'm a language model, and I think that it's the biggest source of my life's interest. So I thought, how would I use language
rank 0 sample 1: Hello, I'm a language model, so to speak. But my first year of school when I started teaching first taught in English, and after that, I
rank 0 sample 2: Hello, I'm a language model, so I use this idea a lot of times now.
What are the advantages of this?
- It is straightforward
rank 0 sample 3: Hello, I'm a language model, but, most of the time I was not there. I grew up in an authoritarian system that always meant that the English
rank 1 sample 0: Hello, I'm a language model, how are you?
I'm sure I will get better when I get to the beginning of what I'm going to
rank 1 sample 1: Hello, I'm a language model, not an interpreter. I'm not sure of the type you're getting, but it'd be interesting if you could figure
rank 1 sample 2: Hello, I'm a language model, but because the grammar is so complex, I'm not a teacher and so I'm not really sure I can make a
rank 1 sample 3: Hello, I'm a language model, and I'm the one working in the new language. Every time I have to write myself over there, I just have
Step: 17500, loss: 3.062642, norm: 0.2822, time(ms): 3810.84, token/sec:137577.89, val_loss: 3.0754, hellaswag_acc: 0.3031
Step: 17501, loss: 3.064344, norm: 0.2781, time(ms): 793.81, token/sec:660470.48, hellaswag_acc: 0.3031
Step: 17502, loss: 3.106565, norm: 0.2862, time(ms): 788.67, token/sec:664775.83, hellaswag_acc: 0.3031
Step: 17503, loss: 3.054496, norm: 0.3060, time(ms): 804.23, token/sec:651913.42, hellaswag_acc: 0.3031
Step: 17504, loss: 3.120077, norm: 0.3041, time(ms): 803.44, token/sec:652558.01, hellaswag_acc: 0.3031
Step: 17505, loss: 3.088481, norm: 0.2795, time(ms): 791.16, token/sec:662682.55, hellaswag_acc: 0.3031
Step: 17506, loss: 3.139859, norm: 0.3156, time(ms): 790.45, token/sec:663277.40, hellaswag_acc: 0.3031
Step: 17507, loss: 3.068213, norm: 0.3281, time(ms): 796.44, token/sec:658293.42, hellaswag_acc: 0.3031
Step: 17508, loss: 3.079012, norm: 0.2843, time(ms): 792.89, token/sec:661235.09, hellaswag_acc: 0.3031
Step: 17509, loss: 3.018878, norm: 0.2858, time(ms): 790.21, token/sec:663479.72, hellaswag_acc: 0.3031
Step: 17510, loss: 3.070776, norm: 0.2785, time(ms): 789.29, token/sec:664253.53, hellaswag_acc: 0.3031
Step: 17511, loss: 3.106867, norm: 0.2866, time(ms): 783.80, token/sec:668903.19, hellaswag_acc: 0.3031
Step: 17512, loss: 3.045865, norm: 0.2793, time(ms): 802.37, token/sec:653427.08, hellaswag_acc: 0.3031
Step: 17513, loss: 3.061699, norm: 0.2681, time(ms): 802.36, token/sec:653434.07, hellaswag_acc: 0.3031
Step: 17514, loss: 3.038279, norm: 0.2800, time(ms): 799.97, token/sec:655386.21, hellaswag_acc: 0.3031
Step: 17515, loss: 3.079778, norm: 0.2898, time(ms): 791.06, token/sec:662767.04, hellaswag_acc: 0.3031
Step: 17516, loss: 3.087370, norm: 0.2656, time(ms): 798.43, token/sec:656648.70, hellaswag_acc: 0.3031
Step: 17517, loss: 3.059914, norm: 0.2597, time(ms): 794.54, token/sec:659862.64, hellaswag_acc: 0.3031
Step: 17518, loss: 3.060591, norm: 0.3015, time(ms): 792.76, token/sec:661346.06, hellaswag_acc: 0.3031
Step: 17519, loss: 3.066058, norm: 0.2631, time(ms): 787.45, token/sec:665805.56, hellaswag_acc: 0.3031
Step: 17520, loss: 3.000518, norm: 0.2848, time(ms): 791.12, token/sec:662717.10, hellaswag_acc: 0.3031
Step: 17521, loss: 2.995677, norm: 0.2630, time(ms): 801.12, token/sec:654442.19, hellaswag_acc: 0.3031
Step: 17522, loss: 2.968998, norm: 0.2824, time(ms): 801.97, token/sec:653746.44, hellaswag_acc: 0.3031
Step: 17523, loss: 3.033026, norm: 0.2710, time(ms): 790.68, token/sec:663087.60, hellaswag_acc: 0.3031
Step: 17524, loss: 3.053426, norm: 0.2714, time(ms): 791.73, token/sec:662207.61, hellaswag_acc: 0.3031
Step: 17525, loss: 3.058052, norm: 0.2755, time(ms): 793.43, token/sec:660783.66, hellaswag_acc: 0.3031
Step: 17526, loss: 3.042798, norm: 0.2774, time(ms): 799.93, token/sec:655418.25, hellaswag_acc: 0.3031
Step: 17527, loss: 2.993382, norm: 0.2585, time(ms): 803.10, token/sec:652832.71, hellaswag_acc: 0.3031
Step: 17528, loss: 3.069175, norm: 0.2689, time(ms): 797.78, token/sec:657180.90, hellaswag_acc: 0.3031
Step: 17529, loss: 3.027858, norm: 0.2730, time(ms): 798.08, token/sec:656936.28, hellaswag_acc: 0.3031
Step: 17530, loss: 2.991962, norm: 0.2746, time(ms): 795.21, token/sec:659308.10, hellaswag_acc: 0.3031
Step: 17531, loss: 2.981210, norm: 0.3029, time(ms): 789.57, token/sec:664013.03, hellaswag_acc: 0.3031
Step: 17532, loss: 3.005155, norm: 0.3134, time(ms): 787.65, token/sec:665633.85, hellaswag_acc: 0.3031
Step: 17533, loss: 3.106150, norm: 0.3247, time(ms): 785.54, token/sec:667426.43, hellaswag_acc: 0.3031
Step: 17534, loss: 2.993899, norm: 0.2877, time(ms): 802.09, token/sec:653651.22, hellaswag_acc: 0.3031
Step: 17535, loss: 3.079211, norm: 0.2952, time(ms): 805.14, token/sec:651176.18, hellaswag_acc: 0.3031
Step: 17536, loss: 3.028289, norm: 0.3018, time(ms): 787.21, token/sec:666009.02, hellaswag_acc: 0.3031
Step: 17537, loss: 3.078747, norm: 0.3040, time(ms): 787.29, token/sec:665940.85, hellaswag_acc: 0.3031
Step: 17538, loss: 3.000818, norm: 0.3019, time(ms): 795.48, token/sec:659080.65, hellaswag_acc: 0.3031
Step: 17539, loss: 3.018292, norm: 0.3242, time(ms): 793.59, token/sec:660651.44, hellaswag_acc: 0.3031
Step: 17540, loss: 3.032091, norm: 0.3169, time(ms): 790.60, token/sec:663147.99, hellaswag_acc: 0.3031
Step: 17541, loss: 3.110937, norm: 0.3130, time(ms): 797.02, token/sec:657806.25, hellaswag_acc: 0.3031
Step: 17542, loss: 3.071956, norm: 0.3292, time(ms): 801.86, token/sec:653837.22, hellaswag_acc: 0.3031
Step: 17543, loss: 3.062826, norm: 0.2869, time(ms): 805.28, token/sec:651063.59, hellaswag_acc: 0.3031
Step: 17544, loss: 3.009037, norm: 0.3206, time(ms): 789.72, token/sec:663893.76, hellaswag_acc: 0.3031
Step: 17545, loss: 3.079736, norm: 0.2871, time(ms): 796.64, token/sec:658120.64, hellaswag_acc: 0.3031
Step: 17546, loss: 3.079577, norm: 0.3013, time(ms): 791.82, token/sec:662132.63, hellaswag_acc: 0.3031
Step: 17547, loss: 3.053045, norm: 0.2960, time(ms): 793.45, token/sec:660771.15, hellaswag_acc: 0.3031
Step: 17548, loss: 3.065982, norm: 0.2993, time(ms): 801.86, token/sec:653842.47, hellaswag_acc: 0.3031
Step: 17549, loss: 3.117993, norm: 0.3001, time(ms): 804.28, token/sec:651873.99, hellaswag_acc: 0.3031
Step: 17550, loss: 3.071898, norm: 0.2749, time(ms): 800.54, token/sec:654921.47, hellaswag_acc: 0.3031
Step: 17551, loss: 3.137114, norm: 0.3129, time(ms): 792.03, token/sec:661950.66, hellaswag_acc: 0.3031
Step: 17552, loss: 3.076960, norm: 0.3006, time(ms): 797.26, token/sec:657614.64, hellaswag_acc: 0.3031
Step: 17553, loss: 3.065156, norm: 0.2844, time(ms): 789.68, token/sec:663920.62, hellaswag_acc: 0.3031
Step: 17554, loss: 3.074832, norm: 0.2878, time(ms): 790.05, token/sec:663609.87, hellaswag_acc: 0.3031
Step: 17555, loss: 3.021816, norm: 0.3016, time(ms): 789.35, token/sec:664202.16, hellaswag_acc: 0.3031
Step: 17556, loss: 3.028553, norm: 0.2738, time(ms): 788.99, token/sec:664507.04, hellaswag_acc: 0.3031
Step: 17557, loss: 2.996665, norm: 0.2944, time(ms): 790.25, token/sec:663449.09, hellaswag_acc: 0.3031
Step: 17558, loss: 3.021671, norm: 0.2711, time(ms): 791.24, token/sec:662619.25, hellaswag_acc: 0.3031
Step: 17559, loss: 3.025179, norm: 0.2800, time(ms): 791.90, token/sec:662066.45, hellaswag_acc: 0.3031
Step: 17560, loss: 3.022547, norm: 0.2809, time(ms): 791.52, token/sec:662383.34, hellaswag_acc: 0.3031
Step: 17561, loss: 3.067558, norm: 0.2991, time(ms): 800.20, token/sec:655194.85, hellaswag_acc: 0.3031
Step: 17562, loss: 3.016143, norm: 0.2898, time(ms): 803.24, token/sec:652716.84, hellaswag_acc: 0.3031
Step: 17563, loss: 3.055066, norm: 0.2935, time(ms): 800.59, token/sec:654879.92, hellaswag_acc: 0.3031
Step: 17564, loss: 3.019731, norm: 0.3354, time(ms): 791.46, token/sec:662431.62, hellaswag_acc: 0.3031
Step: 17565, loss: 2.973629, norm: 0.2888, time(ms): 803.89, token/sec:652186.61, hellaswag_acc: 0.3031
Step: 17566, loss: 3.044744, norm: 0.3128, time(ms): 804.17, token/sec:651962.12, hellaswag_acc: 0.3031
Step: 17567, loss: 2.968810, norm: 0.3100, time(ms): 799.63, token/sec:655660.57, hellaswag_acc: 0.3031
Step: 17568, loss: 3.015392, norm: 0.3270, time(ms): 791.78, token/sec:662161.94, hellaswag_acc: 0.3031
Step: 17569, loss: 3.077583, norm: 0.2914, time(ms): 807.01, token/sec:649664.08, hellaswag_acc: 0.3031
Step: 17570, loss: 3.144707, norm: 0.3388, time(ms): 801.67, token/sec:653993.17, hellaswag_acc: 0.3031
Step: 17571, loss: 3.140406, norm: 0.3557, time(ms): 791.19, token/sec:662657.39, hellaswag_acc: 0.3031
Step: 17572, loss: 3.020475, norm: 0.2914, time(ms): 797.99, token/sec:657011.26, hellaswag_acc: 0.3031
Step: 17573, loss: 2.940644, norm: 0.3174, time(ms): 792.68, token/sec:661411.10, hellaswag_acc: 0.3031
Step: 17574, loss: 3.033207, norm: 0.3431, time(ms): 796.24, token/sec:658456.44, hellaswag_acc: 0.3031
Step: 17575, loss: 3.039631, norm: 0.3065, time(ms): 795.36, token/sec:659186.15, hellaswag_acc: 0.3031
Step: 17576, loss: 3.086300, norm: 0.3217, time(ms): 801.03, token/sec:654517.96, hellaswag_acc: 0.3031
Step: 17577, loss: 3.024231, norm: 0.3213, time(ms): 804.13, token/sec:651994.98, hellaswag_acc: 0.3031
Step: 17578, loss: 3.097740, norm: 0.3029, time(ms): 791.25, token/sec:662610.07, hellaswag_acc: 0.3031
Step: 17579, loss: 3.081220, norm: 0.2985, time(ms): 792.21, token/sec:661802.84, hellaswag_acc: 0.3031
Step: 17580, loss: 3.053783, norm: 0.2966, time(ms): 791.63, token/sec:662285.98, hellaswag_acc: 0.3031
Step: 17581, loss: 3.088364, norm: 0.3149, time(ms): 792.88, token/sec:661248.81, hellaswag_acc: 0.3031
Step: 17582, loss: 3.037103, norm: 0.2914, time(ms): 787.97, token/sec:665363.57, hellaswag_acc: 0.3031
Step: 17583, loss: 3.093416, norm: 0.3036, time(ms): 803.07, token/sec:652857.13, hellaswag_acc: 0.3031
Step: 17584, loss: 3.096733, norm: 0.3007, time(ms): 797.00, token/sec:657828.09, hellaswag_acc: 0.3031
Step: 17585, loss: 3.037649, norm: 0.2993, time(ms): 800.43, token/sec:655004.57, hellaswag_acc: 0.3031
Step: 17586, loss: 3.075664, norm: 0.2982, time(ms): 798.97, token/sec:656200.96, hellaswag_acc: 0.3031
Step: 17587, loss: 3.065747, norm: 0.2888, time(ms): 801.19, token/sec:654386.29, hellaswag_acc: 0.3031
Step: 17588, loss: 3.088487, norm: 0.2849, time(ms): 799.07, token/sec:656124.80, hellaswag_acc: 0.3031
Step: 17589, loss: 3.031794, norm: 0.2824, time(ms): 795.90, token/sec:658733.57, hellaswag_acc: 0.3031
Step: 17590, loss: 3.057073, norm: 0.2869, time(ms): 803.51, token/sec:652498.56, hellaswag_acc: 0.3031
Step: 17591, loss: 3.076042, norm: 0.2984, time(ms): 797.89, token/sec:657089.40, hellaswag_acc: 0.3031
Step: 17592, loss: 3.078282, norm: 0.2885, time(ms): 802.36, token/sec:653436.40, hellaswag_acc: 0.3031
Step: 17593, loss: 3.073921, norm: 0.2843, time(ms): 801.68, token/sec:653990.25, hellaswag_acc: 0.3031
Step: 17594, loss: 3.018206, norm: 0.3003, time(ms): 795.30, token/sec:659229.23, hellaswag_acc: 0.3031
Step: 17595, loss: 3.050082, norm: 0.2776, time(ms): 802.68, token/sec:653171.47, hellaswag_acc: 0.3031
Step: 17596, loss: 3.014992, norm: 0.2938, time(ms): 796.56, token/sec:658189.39, hellaswag_acc: 0.3031
Step: 17597, loss: 3.076793, norm: 0.3608, time(ms): 801.82, token/sec:653873.77, hellaswag_acc: 0.3031
Step: 17598, loss: 3.061271, norm: 0.2811, time(ms): 801.14, token/sec:654428.55, hellaswag_acc: 0.3031
Step: 17599, loss: 2.992653, norm: 0.3550, time(ms): 798.14, token/sec:656885.46, hellaswag_acc: 0.3031
Step: 17600, loss: 3.026769, norm: 0.2854, time(ms): 799.57, token/sec:655709.84, hellaswag_acc: 0.3031
Step: 17601, loss: 3.034979, norm: 0.3140, time(ms): 795.08, token/sec:659414.46, hellaswag_acc: 0.3031
Step: 17602, loss: 2.982291, norm: 0.3292, time(ms): 807.61, token/sec:649181.15, hellaswag_acc: 0.3031
Step: 17603, loss: 3.000565, norm: 0.3816, time(ms): 798.29, token/sec:656767.94, hellaswag_acc: 0.3031
Step: 17604, loss: 3.066345, norm: 0.3214, time(ms): 791.26, token/sec:662601.88, hellaswag_acc: 0.3031
Step: 17605, loss: 3.083772, norm: 0.3752, time(ms): 792.35, token/sec:661684.95, hellaswag_acc: 0.3031
Step: 17606, loss: 3.054676, norm: 0.3980, time(ms): 796.25, token/sec:658443.23, hellaswag_acc: 0.3031
Step: 17607, loss: 3.005451, norm: 0.3199, time(ms): 789.33, token/sec:664222.03, hellaswag_acc: 0.3031
Step: 17608, loss: 2.981493, norm: 0.3545, time(ms): 787.50, token/sec:665766.25, hellaswag_acc: 0.3031
Step: 17609, loss: 3.076920, norm: 0.3283, time(ms): 800.09, token/sec:655284.66, hellaswag_acc: 0.3031
Step: 17610, loss: 3.113699, norm: 0.3251, time(ms): 803.07, token/sec:652858.10, hellaswag_acc: 0.3031
Step: 17611, loss: 3.033705, norm: 0.3093, time(ms): 795.20, token/sec:659312.64, hellaswag_acc: 0.3031
Step: 17612, loss: 3.022295, norm: 0.3098, time(ms): 795.24, token/sec:659281.81, hellaswag_acc: 0.3031
Step: 17613, loss: 3.080462, norm: 0.3049, time(ms): 791.31, token/sec:662553.57, hellaswag_acc: 0.3031
Step: 17614, loss: 3.160840, norm: 0.3460, time(ms): 796.56, token/sec:658188.60, hellaswag_acc: 0.3031
Step: 17615, loss: 3.072023, norm: 0.3223, time(ms): 791.36, token/sec:662514.05, hellaswag_acc: 0.3031
Step: 17616, loss: 3.166348, norm: 0.3759, time(ms): 789.76, token/sec:663854.87, hellaswag_acc: 0.3031
Step: 17617, loss: 3.087599, norm: 0.3073, time(ms): 790.38, token/sec:663333.42, hellaswag_acc: 0.3031
Step: 17618, loss: 3.080971, norm: 0.3159, time(ms): 794.17, token/sec:660173.46, hellaswag_acc: 0.3031
Step: 17619, loss: 3.121497, norm: 0.3170, time(ms): 791.80, token/sec:662144.60, hellaswag_acc: 0.3031
Step: 17620, loss: 3.072672, norm: 0.3245, time(ms): 797.28, token/sec:657598.32, hellaswag_acc: 0.3031
Step: 17621, loss: 3.062255, norm: 0.3213, time(ms): 805.24, token/sec:651099.06, hellaswag_acc: 0.3031
Step: 17622, loss: 3.075905, norm: 0.3093, time(ms): 799.37, token/sec:655876.27, hellaswag_acc: 0.3031
Step: 17623, loss: 3.001025, norm: 0.2850, time(ms): 799.05, token/sec:656142.42, hellaswag_acc: 0.3031
Step: 17624, loss: 3.109240, norm: 0.2941, time(ms): 796.03, token/sec:658629.98, hellaswag_acc: 0.3031
Step: 17625, loss: 3.070504, norm: 0.3312, time(ms): 800.56, token/sec:654905.47, hellaswag_acc: 0.3031
Step: 17626, loss: 3.032776, norm: 0.3041, time(ms): 803.24, token/sec:652714.90, hellaswag_acc: 0.3031
Step: 17627, loss: 3.126125, norm: 0.3481, time(ms): 799.55, token/sec:655725.09, hellaswag_acc: 0.3031
Step: 17628, loss: 3.077865, norm: 0.2812, time(ms): 1293.62, token/sec:405287.01, hellaswag_acc: 0.3031
Step: 17629, loss: 2.897837, norm: 0.3443, time(ms): 788.28, token/sec:665101.35, hellaswag_acc: 0.3031
Step: 17630, loss: 2.811866, norm: 0.3173, time(ms): 784.68, token/sec:668151.61, hellaswag_acc: 0.3031
Step: 17631, loss: 2.908748, norm: 0.3644, time(ms): 785.22, token/sec:667696.36, hellaswag_acc: 0.3031
Step: 17632, loss: 2.900822, norm: 0.3954, time(ms): 809.24, token/sec:647876.94, hellaswag_acc: 0.3031
Step: 17633, loss: 2.876079, norm: 0.3409, time(ms): 788.26, token/sec:665122.67, hellaswag_acc: 0.3031
Step: 17634, loss: 2.839238, norm: 0.3472, time(ms): 785.87, token/sec:667143.56, hellaswag_acc: 0.3031
Step: 17635, loss: 2.856943, norm: 0.3040, time(ms): 797.28, token/sec:657598.13, hellaswag_acc: 0.3031
Step: 17636, loss: 2.874049, norm: 0.3372, time(ms): 806.07, token/sec:650422.52, hellaswag_acc: 0.3031
Step: 17637, loss: 2.856954, norm: 0.3085, time(ms): 794.56, token/sec:659844.03, hellaswag_acc: 0.3031
Step: 17638, loss: 2.945790, norm: 0.3155, time(ms): 794.36, token/sec:660017.12, hellaswag_acc: 0.3031
Step: 17639, loss: 2.892635, norm: 0.3254, time(ms): 785.57, token/sec:667395.84, hellaswag_acc: 0.3031
Step: 17640, loss: 2.834006, norm: 0.2921, time(ms): 789.90, token/sec:663741.06, hellaswag_acc: 0.3031
Step: 17641, loss: 3.076353, norm: 0.3693, time(ms): 797.59, token/sec:657337.67, hellaswag_acc: 0.3031
Step: 17642, loss: 3.128661, norm: 0.3182, time(ms): 792.18, token/sec:661830.13, hellaswag_acc: 0.3031
Step: 17643, loss: 3.096102, norm: 0.3092, time(ms): 798.67, token/sec:656448.56, hellaswag_acc: 0.3031
Step: 17644, loss: 3.103395, norm: 0.3226, time(ms): 805.89, token/sec:650571.65, hellaswag_acc: 0.3031
Step: 17645, loss: 3.112830, norm: 0.3236, time(ms): 793.63, token/sec:660618.10, hellaswag_acc: 0.3031
Step: 17646, loss: 3.143206, norm: 0.3088, time(ms): 801.11, token/sec:654450.37, hellaswag_acc: 0.3031
Step: 17647, loss: 3.080060, norm: 0.3398, time(ms): 802.76, token/sec:653108.81, hellaswag_acc: 0.3031
Step: 17648, loss: 3.117298, norm: 0.3186, time(ms): 800.34, token/sec:655084.76, hellaswag_acc: 0.3031
Step: 17649, loss: 3.097149, norm: 0.3261, time(ms): 796.71, token/sec:658065.70, hellaswag_acc: 0.3031
Step: 17650, loss: 3.087341, norm: 0.3027, time(ms): 802.33, token/sec:653456.60, hellaswag_acc: 0.3031
Step: 17651, loss: 3.088993, norm: 0.2968, time(ms): 801.59, token/sec:654063.59, hellaswag_acc: 0.3031
Step: 17652, loss: 3.045641, norm: 0.3033, time(ms): 792.91, token/sec:661221.57, hellaswag_acc: 0.3031
Step: 17653, loss: 3.191161, norm: 0.3153, time(ms): 794.40, token/sec:659977.11, hellaswag_acc: 0.3031
Step: 17654, loss: 3.092059, norm: 0.3247, time(ms): 794.04, token/sec:660277.72, hellaswag_acc: 0.3031
Step: 17655, loss: 3.086271, norm: 0.3450, time(ms): 795.04, token/sec:659448.08, hellaswag_acc: 0.3031
Step: 17656, loss: 3.114242, norm: 0.3053, time(ms): 789.23, token/sec:664303.09, hellaswag_acc: 0.3031
Step: 17657, loss: 3.129764, norm: 0.2996, time(ms): 788.66, token/sec:664781.05, hellaswag_acc: 0.3031
Step: 17658, loss: 3.066171, norm: 0.2826, time(ms): 800.57, token/sec:654895.13, hellaswag_acc: 0.3031
Step: 17659, loss: 3.125554, norm: 0.3294, time(ms): 804.52, token/sec:651677.72, hellaswag_acc: 0.3031
Step: 17660, loss: 3.103002, norm: 0.2980, time(ms): 801.60, token/sec:654051.52, hellaswag_acc: 0.3031
Step: 17661, loss: 3.065659, norm: 0.2935, time(ms): 785.87, token/sec:667147.00, hellaswag_acc: 0.3031
Step: 17662, loss: 3.077497, norm: 0.2827, time(ms): 791.32, token/sec:662552.77, hellaswag_acc: 0.3031
Step: 17663, loss: 3.110241, norm: 0.3136, time(ms): 801.14, token/sec:654428.94, hellaswag_acc: 0.3031
Step: 17664, loss: 3.029889, norm: 0.3291, time(ms): 788.90, token/sec:664580.14, hellaswag_acc: 0.3031
Step: 17665, loss: 3.048459, norm: 0.2882, time(ms): 785.95, token/sec:667071.72, hellaswag_acc: 0.3031
Step: 17666, loss: 3.066086, norm: 0.2928, time(ms): 794.25, token/sec:660106.27, hellaswag_acc: 0.3031
Step: 17667, loss: 3.014037, norm: 0.3074, time(ms): 791.29, token/sec:662569.94, hellaswag_acc: 0.3031
Step: 17668, loss: 3.044074, norm: 0.2883, time(ms): 796.37, token/sec:658344.66, hellaswag_acc: 0.3031
Step: 17669, loss: 3.018889, norm: 0.3134, time(ms): 793.82, token/sec:660462.55, hellaswag_acc: 0.3031
Step: 17670, loss: 3.051199, norm: 0.3032, time(ms): 803.31, token/sec:652661.43, hellaswag_acc: 0.3031
Step: 17671, loss: 2.997986, norm: 0.2864, time(ms): 806.01, token/sec:650472.16, hellaswag_acc: 0.3031
Step: 17672, loss: 3.086757, norm: 0.3099, time(ms): 783.85, token/sec:668860.47, hellaswag_acc: 0.3031
Step: 17673, loss: 3.062634, norm: 0.2972, time(ms): 791.75, token/sec:662191.85, hellaswag_acc: 0.3031
Step: 17674, loss: 3.014378, norm: 0.2886, time(ms): 793.06, token/sec:661097.33, hellaswag_acc: 0.3031
Step: 17675, loss: 2.853673, norm: 0.3195, time(ms): 792.96, token/sec:661182.01, hellaswag_acc: 0.3031
Step: 17676, loss: 2.801561, norm: 0.3290, time(ms): 794.28, token/sec:660081.51, hellaswag_acc: 0.3031
Step: 17677, loss: 2.900818, norm: 0.3738, time(ms): 792.55, token/sec:661518.55, hellaswag_acc: 0.3031
Step: 17678, loss: 2.845658, norm: 0.3214, time(ms): 801.12, token/sec:654442.96, hellaswag_acc: 0.3031
Step: 17679, loss: 2.854536, norm: 0.3376, time(ms): 803.21, token/sec:652740.86, hellaswag_acc: 0.3031
Step: 17680, loss: 2.846166, norm: 0.3256, time(ms): 789.93, token/sec:663717.62, hellaswag_acc: 0.3031
Step: 17681, loss: 2.848093, norm: 0.3354, time(ms): 791.66, token/sec:662260.65, hellaswag_acc: 0.3031
Step: 17682, loss: 2.826640, norm: 0.3060, time(ms): 797.54, token/sec:657380.31, hellaswag_acc: 0.3031
Step: 17683, loss: 2.861219, norm: 0.3153, time(ms): 800.00, token/sec:655357.30, hellaswag_acc: 0.3031
Step: 17684, loss: 2.844710, norm: 0.3123, time(ms): 800.50, token/sec:654951.70, hellaswag_acc: 0.3031
Step: 17685, loss: 2.866294, norm: 0.3276, time(ms): 794.86, token/sec:659601.57, hellaswag_acc: 0.3031
Step: 17686, loss: 2.953713, norm: 0.3093, time(ms): 797.77, token/sec:657192.30, hellaswag_acc: 0.3031
Step: 17687, loss: 3.036386, norm: 0.3034, time(ms): 790.48, token/sec:663249.79, hellaswag_acc: 0.3031
Step: 17688, loss: 3.058635, norm: 0.3250, time(ms): 786.83, token/sec:666325.66, hellaswag_acc: 0.3031
Step: 17689, loss: 3.053971, norm: 0.3199, time(ms): 791.26, token/sec:662595.89, hellaswag_acc: 0.3031
Step: 17690, loss: 3.041479, norm: 0.2935, time(ms): 790.99, token/sec:662826.37, hellaswag_acc: 0.3031
Step: 17691, loss: 2.993154, norm: 0.3010, time(ms): 792.09, token/sec:661908.02, hellaswag_acc: 0.3031
Step: 17692, loss: 3.083678, norm: 0.3171, time(ms): 792.14, token/sec:661863.19, hellaswag_acc: 0.3031
Step: 17693, loss: 3.006009, norm: 0.2929, time(ms): 790.43, token/sec:663296.01, hellaswag_acc: 0.3031
Step: 17694, loss: 3.051585, norm: 0.3061, time(ms): 793.81, token/sec:660473.06, hellaswag_acc: 0.3031
Step: 17695, loss: 3.122070, norm: 0.3025, time(ms): 799.58, token/sec:655706.32, hellaswag_acc: 0.3031
Step: 17696, loss: 3.020233, norm: 0.3195, time(ms): 801.29, token/sec:654301.98, hellaswag_acc: 0.3031
Step: 17697, loss: 3.063892, norm: 0.3162, time(ms): 795.81, token/sec:658811.13, hellaswag_acc: 0.3031
Step: 17698, loss: 3.071737, norm: 0.3049, time(ms): 799.01, token/sec:656170.61, hellaswag_acc: 0.3031
Step: 17699, loss: 3.067508, norm: 0.2903, time(ms): 804.62, token/sec:651600.87, hellaswag_acc: 0.3031
Step: 17700, loss: 3.070903, norm: 0.2888, time(ms): 791.70, token/sec:662228.34, hellaswag_acc: 0.3031
Step: 17701, loss: 3.028045, norm: 0.2947, time(ms): 800.36, token/sec:655062.32, hellaswag_acc: 0.3031
Step: 17702, loss: 3.080127, norm: 0.2907, time(ms): 798.90, token/sec:656262.26, hellaswag_acc: 0.3031
Step: 17703, loss: 3.069755, norm: 0.2905, time(ms): 793.67, token/sec:660583.17, hellaswag_acc: 0.3031
Step: 17704, loss: 3.036273, norm: 0.2979, time(ms): 793.34, token/sec:660860.51, hellaswag_acc: 0.3031
Step: 17705, loss: 3.083767, norm: 0.2904, time(ms): 794.77, token/sec:659675.38, hellaswag_acc: 0.3031
Step: 17706, loss: 3.110626, norm: 0.3005, time(ms): 795.12, token/sec:659379.07, hellaswag_acc: 0.3031
Step: 17707, loss: 3.082951, norm: 0.2779, time(ms): 790.28, token/sec:663424.68, hellaswag_acc: 0.3031
Step: 17708, loss: 3.079504, norm: 0.2905, time(ms): 786.77, token/sec:666379.57, hellaswag_acc: 0.3031
Step: 17709, loss: 3.071687, norm: 0.2928, time(ms): 790.62, token/sec:663137.39, hellaswag_acc: 0.3031
Step: 17710, loss: 3.051541, norm: 0.2815, time(ms): 796.79, token/sec:658004.26, hellaswag_acc: 0.3031
Step: 17711, loss: 3.114346, norm: 0.2764, time(ms): 803.27, token/sec:652694.17, hellaswag_acc: 0.3031
Step: 17712, loss: 3.064121, norm: 0.2868, time(ms): 801.57, token/sec:654074.29, hellaswag_acc: 0.3031
Step: 17713, loss: 3.082408, norm: 0.2911, time(ms): 790.33, token/sec:663377.44, hellaswag_acc: 0.3031
Step: 17714, loss: 3.026505, norm: 0.2840, time(ms): 802.27, token/sec:653505.34, hellaswag_acc: 0.3031
Step: 17715, loss: 3.083829, norm: 0.2904, time(ms): 806.35, token/sec:650201.74, hellaswag_acc: 0.3031
Step: 17716, loss: 3.071526, norm: 0.2755, time(ms): 786.99, token/sec:666197.07, hellaswag_acc: 0.3031
Step: 17717, loss: 3.029949, norm: 0.2617, time(ms): 792.83, token/sec:661289.38, hellaswag_acc: 0.3031
Step: 17718, loss: 3.043121, norm: 0.3101, time(ms): 790.24, token/sec:663454.50, hellaswag_acc: 0.3031
Step: 17719, loss: 3.041972, norm: 0.3019, time(ms): 790.28, token/sec:663421.67, hellaswag_acc: 0.3031
Step: 17720, loss: 2.891684, norm: 0.3422, time(ms): 791.28, token/sec:662579.72, hellaswag_acc: 0.3031
Step: 17721, loss: 2.809577, norm: 0.3012, time(ms): 792.93, token/sec:661205.27, hellaswag_acc: 0.3031
Step: 17722, loss: 2.909146, norm: 0.3528, time(ms): 793.51, token/sec:660718.54, hellaswag_acc: 0.3031
Step: 17723, loss: 2.838006, norm: 0.3859, time(ms): 795.34, token/sec:659199.99, hellaswag_acc: 0.3031
Step: 17724, loss: 2.853847, norm: 0.3372, time(ms): 797.11, token/sec:657736.60, hellaswag_acc: 0.3031
Step: 17725, loss: 2.914757, norm: 0.3280, time(ms): 791.77, token/sec:662173.51, hellaswag_acc: 0.3031
Step: 17726, loss: 2.840437, norm: 0.3300, time(ms): 787.47, token/sec:665792.05, hellaswag_acc: 0.3031
Step: 17727, loss: 2.885905, norm: 0.3330, time(ms): 789.10, token/sec:664414.89, hellaswag_acc: 0.3031
Step: 17728, loss: 2.857210, norm: 0.3014, time(ms): 796.22, token/sec:658473.98, hellaswag_acc: 0.3031
Step: 17729, loss: 2.876865, norm: 0.2948, time(ms): 800.25, token/sec:655156.59, hellaswag_acc: 0.3031
Step: 17730, loss: 2.851973, norm: 0.3427, time(ms): 801.07, token/sec:654487.18, hellaswag_acc: 0.3031
Step: 17731, loss: 2.958464, norm: 0.2747, time(ms): 801.34, token/sec:654262.27, hellaswag_acc: 0.3031
Step: 17732, loss: 3.039414, norm: 0.3459, time(ms): 795.09, token/sec:659407.54, hellaswag_acc: 0.3031
Step: 17733, loss: 3.069064, norm: 0.3196, time(ms): 802.00, token/sec:653721.76, hellaswag_acc: 0.3031
Step: 17734, loss: 3.101159, norm: 0.3250, time(ms): 796.93, token/sec:657884.37, hellaswag_acc: 0.3031
Step: 17735, loss: 3.087888, norm: 0.3141, time(ms): 802.31, token/sec:653473.30, hellaswag_acc: 0.3031
Step: 17736, loss: 3.035946, norm: 0.3019, time(ms): 798.15, token/sec:656875.65, hellaswag_acc: 0.3031
Step: 17737, loss: 3.077287, norm: 0.3027, time(ms): 802.94, token/sec:652957.74, hellaswag_acc: 0.3031
Step: 17738, loss: 3.039532, norm: 0.2951, time(ms): 797.56, token/sec:657365.77, hellaswag_acc: 0.3031
Step: 17739, loss: 3.073385, norm: 0.3034, time(ms): 799.70, token/sec:655608.38, hellaswag_acc: 0.3031
Step: 17740, loss: 3.033689, norm: 0.2849, time(ms): 802.04, token/sec:653693.00, hellaswag_acc: 0.3031
Step: 17741, loss: 3.074755, norm: 0.2846, time(ms): 799.56, token/sec:655717.07, hellaswag_acc: 0.3031
Step: 17742, loss: 3.073945, norm: 0.3073, time(ms): 802.21, token/sec:653558.56, hellaswag_acc: 0.3031
Step: 17743, loss: 3.065419, norm: 0.3017, time(ms): 798.72, token/sec:656412.90, hellaswag_acc: 0.3031
Step: 17744, loss: 3.083462, norm: 0.2928, time(ms): 791.96, token/sec:662015.03, hellaswag_acc: 0.3031
Step: 17745, loss: 3.116195, norm: 0.3016, time(ms): 805.97, token/sec:650504.48, hellaswag_acc: 0.3031
Step: 17746, loss: 3.084615, norm: 0.3255, time(ms): 803.14, token/sec:652799.19, hellaswag_acc: 0.3031
Step: 17747, loss: 3.066701, norm: 0.2815, time(ms): 786.38, token/sec:666712.73, hellaswag_acc: 0.3031
Step: 17748, loss: 3.080805, norm: 0.2868, time(ms): 792.42, token/sec:661626.02, hellaswag_acc: 0.3031
Step: 17749, loss: 3.037312, norm: 0.2712, time(ms): 791.05, token/sec:662778.22, hellaswag_acc: 0.3031
rank 0 sample 0: Hello, I'm a language model, and I am a computer scientist! The biggest things I learn are in modeling software, programming languages, computer systems, data
rank 0 sample 1: Hello, I'm a language model, so i'm not sure if this class is the source of all these functions? I can't say with a very small
rank 0 sample 2: Hello, I'm a language model, so I see this everywhere
because, I guess, it was pretty interesting.
In my opinion, the most interesting
rank 0 sample 3: Hello, I'm a language model, I believe that I'm a computer programmer, all of my tools are for programming . And you know, I have 3
rank 1 sample 0: Hello, I'm a language model, how are you?
I'm A.T.K...
I'm a.T.K...
I
rank 1 sample 1: Hello, I'm a language model, not an interpreter. I'm a model I'm trying with a Python interpreter.
First of all I'm going to
rank 1 sample 2: Hello, I'm a language model, I speak the language of the world, and I'm learning from it."
"I am in an environment. No
rank 1 sample 3: Hello, I'm a language model, and I'm the one and only thing if I ever wanted to try the test. Just use "test" here.
Step: 17750, loss: 3.063345, norm: 0.2900, time(ms): 3850.92, token/sec:136146.28, val_loss: 3.0734, hellaswag_acc: 0.3031
Step: 17751, loss: 2.980948, norm: 0.2865, time(ms): 792.86, token/sec:661262.53, hellaswag_acc: 0.3031
Step: 17752, loss: 3.056048, norm: 0.2675, time(ms): 793.53, token/sec:660700.67, hellaswag_acc: 0.3031
Step: 17753, loss: 3.085839, norm: 0.2791, time(ms): 794.25, token/sec:660106.47, hellaswag_acc: 0.3031
Step: 17754, loss: 3.089610, norm: 0.2858, time(ms): 793.52, token/sec:660713.18, hellaswag_acc: 0.3031
Step: 17755, loss: 3.026867, norm: 0.2794, time(ms): 797.41, token/sec:657486.05, hellaswag_acc: 0.3031
Step: 17756, loss: 3.078669, norm: 0.2760, time(ms): 801.14, token/sec:654430.50, hellaswag_acc: 0.3031
Step: 17757, loss: 3.061363, norm: 0.2568, time(ms): 804.77, token/sec:651475.58, hellaswag_acc: 0.3031
Step: 17758, loss: 2.973937, norm: 0.2683, time(ms): 792.56, token/sec:661514.17, hellaswag_acc: 0.3031
Step: 17759, loss: 3.089544, norm: 0.2788, time(ms): 794.84, token/sec:659614.63, hellaswag_acc: 0.3031
Step: 17760, loss: 3.087168, norm: 0.2717, time(ms): 791.04, token/sec:662781.02, hellaswag_acc: 0.3031
Step: 17761, loss: 3.079056, norm: 0.2816, time(ms): 792.20, token/sec:661808.62, hellaswag_acc: 0.3031
Step: 17762, loss: 3.066489, norm: 0.2983, time(ms): 792.06, token/sec:661927.35, hellaswag_acc: 0.3031
Step: 17763, loss: 2.961686, norm: 0.4754, time(ms): 792.54, token/sec:661528.10, hellaswag_acc: 0.3031
Step: 17764, loss: 3.076597, norm: 0.3055, time(ms): 799.54, token/sec:655736.23, hellaswag_acc: 0.3031
Step: 17765, loss: 3.007037, norm: 0.3107, time(ms): 798.63, token/sec:656486.78, hellaswag_acc: 0.3031
Step: 17766, loss: 2.869849, norm: 0.3249, time(ms): 794.12, token/sec:660209.53, hellaswag_acc: 0.3031
Step: 17767, loss: 2.873215, norm: 0.3016, time(ms): 791.73, token/sec:662203.02, hellaswag_acc: 0.3031
Step: 17768, loss: 2.901106, norm: 0.3028, time(ms): 794.86, token/sec:659599.59, hellaswag_acc: 0.3031
Step: 17769, loss: 2.833338, norm: 0.2993, time(ms): 797.42, token/sec:657482.12, hellaswag_acc: 0.3031
Step: 17770, loss: 2.847357, norm: 0.2923, time(ms): 801.64, token/sec:654016.51, hellaswag_acc: 0.3031
Step: 17771, loss: 2.921848, norm: 0.2916, time(ms): 800.63, token/sec:654842.09, hellaswag_acc: 0.3031
Step: 17772, loss: 2.806868, norm: 0.2821, time(ms): 793.41, token/sec:660804.31, hellaswag_acc: 0.3031
Step: 17773, loss: 2.879403, norm: 0.3219, time(ms): 792.09, token/sec:661905.23, hellaswag_acc: 0.3031
Step: 17774, loss: 2.903639, norm: 0.3019, time(ms): 791.18, token/sec:662665.78, hellaswag_acc: 0.3031
Step: 17775, loss: 2.817860, norm: 0.3016, time(ms): 792.27, token/sec:661750.26, hellaswag_acc: 0.3031
Step: 17776, loss: 2.799325, norm: 0.2585, time(ms): 786.04, token/sec:666999.08, hellaswag_acc: 0.3031
Step: 17777, loss: 2.935394, norm: 0.2796, time(ms): 805.16, token/sec:651158.05, hellaswag_acc: 0.3031
Step: 17778, loss: 3.102867, norm: 0.3171, time(ms): 798.24, token/sec:656808.55, hellaswag_acc: 0.3031
Step: 17779, loss: 3.034557, norm: 0.3049, time(ms): 800.65, token/sec:654823.95, hellaswag_acc: 0.3031
Step: 17780, loss: 3.053074, norm: 0.2958, time(ms): 796.26, token/sec:658437.31, hellaswag_acc: 0.3031
Step: 17781, loss: 3.070242, norm: 0.3693, time(ms): 803.67, token/sec:652370.42, hellaswag_acc: 0.3031
Step: 17782, loss: 3.113514, norm: 0.2930, time(ms): 799.58, token/sec:655702.99, hellaswag_acc: 0.3031
Step: 17783, loss: 3.079482, norm: 0.2868, time(ms): 802.59, token/sec:653243.85, hellaswag_acc: 0.3031
Step: 17784, loss: 3.091570, norm: 0.3035, time(ms): 791.07, token/sec:662757.85, hellaswag_acc: 0.3031
Step: 17785, loss: 3.055778, norm: 0.2756, time(ms): 805.51, token/sec:650878.40, hellaswag_acc: 0.3031
Step: 17786, loss: 3.133974, norm: 0.2996, time(ms): 800.20, token/sec:655193.28, hellaswag_acc: 0.3031
Step: 17787, loss: 3.106153, norm: 0.2883, time(ms): 796.53, token/sec:658215.99, hellaswag_acc: 0.3031
Step: 17788, loss: 3.108518, norm: 0.2826, time(ms): 799.81, token/sec:655514.76, hellaswag_acc: 0.3031
Step: 17789, loss: 3.069933, norm: 0.3179, time(ms): 799.97, token/sec:655383.48, hellaswag_acc: 0.3031
Step: 17790, loss: 3.127336, norm: 0.3087, time(ms): 804.81, token/sec:651443.74, hellaswag_acc: 0.3031
Step: 17791, loss: 3.117104, norm: 0.2874, time(ms): 796.88, token/sec:657926.69, hellaswag_acc: 0.3031
Step: 17792, loss: 3.093680, norm: 0.2938, time(ms): 798.90, token/sec:656263.82, hellaswag_acc: 0.3031
Step: 17793, loss: 3.102026, norm: 0.3190, time(ms): 801.50, token/sec:654135.57, hellaswag_acc: 0.3031
Step: 17794, loss: 3.103800, norm: 0.2677, time(ms): 801.65, token/sec:654010.67, hellaswag_acc: 0.3031
Step: 17795, loss: 3.079880, norm: 0.2807, time(ms): 796.66, token/sec:658105.48, hellaswag_acc: 0.3031
Step: 17796, loss: 3.117493, norm: 0.2869, time(ms): 796.12, token/sec:658557.20, hellaswag_acc: 0.3031
Step: 17797, loss: 3.072078, norm: 0.2791, time(ms): 805.90, token/sec:650565.68, hellaswag_acc: 0.3031
Step: 17798, loss: 3.071455, norm: 0.2822, time(ms): 801.46, token/sec:654168.85, hellaswag_acc: 0.3031
Step: 17799, loss: 3.076468, norm: 0.2651, time(ms): 790.71, token/sec:663057.81, hellaswag_acc: 0.3031
Step: 17800, loss: 3.007084, norm: 0.2771, time(ms): 807.53, token/sec:649252.26, hellaswag_acc: 0.3031
Step: 17801, loss: 3.050550, norm: 0.2678, time(ms): 799.96, token/sec:655389.34, hellaswag_acc: 0.3031
Step: 17802, loss: 2.973650, norm: 0.2697, time(ms): 791.20, token/sec:662649.60, hellaswag_acc: 0.3031
Step: 17803, loss: 3.056861, norm: 0.2761, time(ms): 799.57, token/sec:655709.64, hellaswag_acc: 0.3031
Step: 17804, loss: 3.054937, norm: 0.2779, time(ms): 793.74, token/sec:660526.43, hellaswag_acc: 0.3031
Step: 17805, loss: 3.113786, norm: 0.2688, time(ms): 794.18, token/sec:660158.59, hellaswag_acc: 0.3031
Step: 17806, loss: 3.037841, norm: 0.2685, time(ms): 791.52, token/sec:662379.15, hellaswag_acc: 0.3031
Step: 17807, loss: 3.065002, norm: 0.2682, time(ms): 791.94, token/sec:662032.56, hellaswag_acc: 0.3031
Step: 17808, loss: 3.031585, norm: 0.2821, time(ms): 792.61, token/sec:661467.01, hellaswag_acc: 0.3031
Step: 17809, loss: 3.048535, norm: 0.3158, time(ms): 802.57, token/sec:653262.87, hellaswag_acc: 0.3031
Step: 17810, loss: 3.033193, norm: 0.2793, time(ms): 798.28, token/sec:656773.82, hellaswag_acc: 0.3031
Step: 17811, loss: 3.025362, norm: 0.2881, time(ms): 798.88, token/sec:656280.08, hellaswag_acc: 0.3031
Step: 17812, loss: 3.088450, norm: 0.3381, time(ms): 801.34, token/sec:654263.44, hellaswag_acc: 0.3031
Step: 17813, loss: 3.104294, norm: 0.2948, time(ms): 800.46, token/sec:654986.03, hellaswag_acc: 0.3031
Step: 17814, loss: 3.069861, norm: 0.2951, time(ms): 801.09, token/sec:654468.29, hellaswag_acc: 0.3031
Step: 17815, loss: 3.104715, norm: 0.3004, time(ms): 796.69, token/sec:658083.03, hellaswag_acc: 0.3031
Step: 17816, loss: 3.036867, norm: 0.2985, time(ms): 795.39, token/sec:659161.85, hellaswag_acc: 0.3031
Step: 17817, loss: 3.078204, norm: 0.2864, time(ms): 797.38, token/sec:657511.22, hellaswag_acc: 0.3031
Step: 17818, loss: 3.091981, norm: 0.3179, time(ms): 792.35, token/sec:661690.33, hellaswag_acc: 0.3031
Step: 17819, loss: 3.080929, norm: 0.3148, time(ms): 1444.41, token/sec:362978.03, hellaswag_acc: 0.3031
Step: 17820, loss: 3.071670, norm: 0.3095, time(ms): 810.49, token/sec:646879.42, hellaswag_acc: 0.3031
Step: 17821, loss: 3.117743, norm: 0.2919, time(ms): 787.80, token/sec:665505.73, hellaswag_acc: 0.3031
Step: 17822, loss: 3.078563, norm: 0.3234, time(ms): 788.09, token/sec:665263.12, hellaswag_acc: 0.3031
Step: 17823, loss: 3.074321, norm: 0.3221, time(ms): 790.92, token/sec:662880.92, hellaswag_acc: 0.3031
Step: 17824, loss: 3.207935, norm: 0.3240, time(ms): 792.31, token/sec:661717.80, hellaswag_acc: 0.3031
Step: 17825, loss: 3.058129, norm: 0.2961, time(ms): 802.41, token/sec:653390.58, hellaswag_acc: 0.3031
Step: 17826, loss: 3.147522, norm: 0.2973, time(ms): 798.94, token/sec:656228.77, hellaswag_acc: 0.3031
Step: 17827, loss: 3.128256, norm: 0.3080, time(ms): 793.66, token/sec:660598.85, hellaswag_acc: 0.3031
Step: 17828, loss: 3.030251, norm: 0.2808, time(ms): 804.17, token/sec:651958.84, hellaswag_acc: 0.3031
Step: 17829, loss: 3.063096, norm: 0.2841, time(ms): 803.46, token/sec:652537.09, hellaswag_acc: 0.3031
Step: 17830, loss: 3.072900, norm: 0.2791, time(ms): 797.12, token/sec:657731.48, hellaswag_acc: 0.3031
Step: 17831, loss: 3.048945, norm: 0.2771, time(ms): 796.66, token/sec:658111.19, hellaswag_acc: 0.3031
Step: 17832, loss: 3.050509, norm: 0.2704, time(ms): 797.05, token/sec:657784.21, hellaswag_acc: 0.3031
Step: 17833, loss: 3.025395, norm: 0.2593, time(ms): 792.88, token/sec:661244.63, hellaswag_acc: 0.3031
Step: 17834, loss: 3.087503, norm: 0.2680, time(ms): 794.01, token/sec:660306.27, hellaswag_acc: 0.3031
Step: 17835, loss: 3.055731, norm: 0.2653, time(ms): 788.70, token/sec:664750.51, hellaswag_acc: 0.3031
Step: 17836, loss: 3.085057, norm: 0.2563, time(ms): 784.83, token/sec:668029.01, hellaswag_acc: 0.3031
Step: 17837, loss: 3.053519, norm: 0.2600, time(ms): 795.53, token/sec:659044.11, hellaswag_acc: 0.3031
Step: 17838, loss: 3.064635, norm: 0.2692, time(ms): 792.79, token/sec:661323.38, hellaswag_acc: 0.3031
Step: 17839, loss: 3.084475, norm: 0.2687, time(ms): 792.61, token/sec:661469.79, hellaswag_acc: 0.3031
Step: 17840, loss: 3.036751, norm: 0.2738, time(ms): 793.48, token/sec:660742.16, hellaswag_acc: 0.3031
Step: 17841, loss: 3.076595, norm: 0.2635, time(ms): 791.04, token/sec:662783.42, hellaswag_acc: 0.3031
Step: 17842, loss: 3.035285, norm: 0.2696, time(ms): 792.77, token/sec:661338.90, hellaswag_acc: 0.3031
Step: 17843, loss: 3.024019, norm: 0.2809, time(ms): 791.87, token/sec:662088.97, hellaswag_acc: 0.3031
Step: 17844, loss: 2.948788, norm: 0.2631, time(ms): 790.33, token/sec:663376.44, hellaswag_acc: 0.3031
Step: 17845, loss: 2.974218, norm: 0.2708, time(ms): 796.04, token/sec:658623.48, hellaswag_acc: 0.3031
Step: 17846, loss: 2.971010, norm: 0.2500, time(ms): 791.41, token/sec:662477.12, hellaswag_acc: 0.3031
Step: 17847, loss: 2.992780, norm: 0.2764, time(ms): 796.86, token/sec:657942.24, hellaswag_acc: 0.3031
Step: 17848, loss: 3.009168, norm: 0.2632, time(ms): 789.25, token/sec:664290.45, hellaswag_acc: 0.3031
Step: 17849, loss: 2.943521, norm: 0.2719, time(ms): 788.83, token/sec:664643.22, hellaswag_acc: 0.3031
Step: 17850, loss: 3.047009, norm: 0.3058, time(ms): 791.35, token/sec:662521.83, hellaswag_acc: 0.3031
Step: 17851, loss: 2.966141, norm: 0.2782, time(ms): 791.90, token/sec:662064.66, hellaswag_acc: 0.3031
Step: 17852, loss: 2.970719, norm: 0.2863, time(ms): 796.87, token/sec:657931.42, hellaswag_acc: 0.3031
Step: 17853, loss: 3.013911, norm: 0.2773, time(ms): 800.03, token/sec:655337.19, hellaswag_acc: 0.3031
Step: 17854, loss: 3.062708, norm: 0.3082, time(ms): 798.78, token/sec:656363.13, hellaswag_acc: 0.3031
Step: 17855, loss: 3.170675, norm: 0.3350, time(ms): 800.97, token/sec:654568.22, hellaswag_acc: 0.3031
Step: 17856, loss: 3.179816, norm: 0.3015, time(ms): 795.95, token/sec:658698.25, hellaswag_acc: 0.3031
Step: 17857, loss: 3.137102, norm: 0.2878, time(ms): 800.15, token/sec:655239.75, hellaswag_acc: 0.3031
Step: 17858, loss: 3.114516, norm: 0.3016, time(ms): 804.16, token/sec:651967.54, hellaswag_acc: 0.3031
Step: 17859, loss: 3.173587, norm: 0.3023, time(ms): 798.21, token/sec:656828.95, hellaswag_acc: 0.3031
Step: 17860, loss: 3.109778, norm: 0.2943, time(ms): 795.29, token/sec:659237.53, hellaswag_acc: 0.3031
Step: 17861, loss: 3.219118, norm: 0.3698, time(ms): 802.33, token/sec:653457.57, hellaswag_acc: 0.3031
Step: 17862, loss: 3.113497, norm: 0.3061, time(ms): 804.21, token/sec:651928.69, hellaswag_acc: 0.3031
Step: 17863, loss: 3.136199, norm: 0.2922, time(ms): 793.91, token/sec:660383.80, hellaswag_acc: 0.3031
Step: 17864, loss: 3.057463, norm: 0.3650, time(ms): 794.82, token/sec:659629.27, hellaswag_acc: 0.3031
Step: 17865, loss: 3.095450, norm: 0.2988, time(ms): 791.57, token/sec:662336.65, hellaswag_acc: 0.3031
Step: 17866, loss: 3.067474, norm: 0.3171, time(ms): 789.43, token/sec:664132.76, hellaswag_acc: 0.3031
Step: 17867, loss: 3.144555, norm: 0.3653, time(ms): 789.41, token/sec:664149.00, hellaswag_acc: 0.3031
Step: 17868, loss: 3.114297, norm: 0.3016, time(ms): 795.69, token/sec:658906.08, hellaswag_acc: 0.3031
Step: 17869, loss: 3.113460, norm: 0.3060, time(ms): 799.67, token/sec:655630.27, hellaswag_acc: 0.3031
Step: 17870, loss: 3.143192, norm: 0.3275, time(ms): 801.57, token/sec:654072.92, hellaswag_acc: 0.3031
Step: 17871, loss: 3.218828, norm: 0.3316, time(ms): 793.68, token/sec:660581.39, hellaswag_acc: 0.3031
Step: 17872, loss: 3.058469, norm: 0.3126, time(ms): 791.98, token/sec:662000.68, hellaswag_acc: 0.3031
Step: 17873, loss: 3.153020, norm: 0.3043, time(ms): 790.90, token/sec:662900.30, hellaswag_acc: 0.3031
Step: 17874, loss: 3.067549, norm: 0.3059, time(ms): 795.30, token/sec:659236.55, hellaswag_acc: 0.3031
Step: 17875, loss: 3.190032, norm: 0.3582, time(ms): 789.21, token/sec:664316.34, hellaswag_acc: 0.3031
Step: 17876, loss: 3.087379, norm: 0.3116, time(ms): 788.35, token/sec:665044.83, hellaswag_acc: 0.3031
Step: 17877, loss: 3.159821, norm: 0.3407, time(ms): 791.87, token/sec:662090.37, hellaswag_acc: 0.3031
Step: 17878, loss: 3.012833, norm: 0.3112, time(ms): 794.25, token/sec:660102.91, hellaswag_acc: 0.3031
Step: 17879, loss: 3.047544, norm: 0.3036, time(ms): 799.74, token/sec:655572.22, hellaswag_acc: 0.3031
Step: 17880, loss: 3.019849, norm: 0.2877, time(ms): 804.89, token/sec:651376.97, hellaswag_acc: 0.3031
Step: 17881, loss: 3.059150, norm: 0.2906, time(ms): 799.63, token/sec:655661.74, hellaswag_acc: 0.3031
Step: 17882, loss: 3.069878, norm: 0.3007, time(ms): 799.04, token/sec:656150.44, hellaswag_acc: 0.3031
Step: 17883, loss: 3.075396, norm: 0.2757, time(ms): 799.29, token/sec:655945.72, hellaswag_acc: 0.3031
Step: 17884, loss: 3.064162, norm: 0.2759, time(ms): 802.06, token/sec:653679.59, hellaswag_acc: 0.3031
Step: 17885, loss: 3.074422, norm: 0.3063, time(ms): 793.69, token/sec:660570.87, hellaswag_acc: 0.3031
Step: 17886, loss: 3.124596, norm: 0.3118, time(ms): 803.54, token/sec:652472.43, hellaswag_acc: 0.3031
Step: 17887, loss: 3.057479, norm: 0.3039, time(ms): 801.66, token/sec:654004.06, hellaswag_acc: 0.3031
Step: 17888, loss: 3.106288, norm: 0.2916, time(ms): 795.10, token/sec:659397.65, hellaswag_acc: 0.3031
Step: 17889, loss: 3.059653, norm: 0.3223, time(ms): 794.29, token/sec:660067.84, hellaswag_acc: 0.3031
Step: 17890, loss: 2.967104, norm: 0.3059, time(ms): 792.19, token/sec:661821.16, hellaswag_acc: 0.3031
Step: 17891, loss: 2.992708, norm: 0.2809, time(ms): 793.11, token/sec:661050.63, hellaswag_acc: 0.3031
Step: 17892, loss: 3.004036, norm: 0.3037, time(ms): 787.55, token/sec:665722.51, hellaswag_acc: 0.3031
Step: 17893, loss: 2.944796, norm: 0.2668, time(ms): 789.33, token/sec:664222.03, hellaswag_acc: 0.3031
Step: 17894, loss: 2.998425, norm: 0.3062, time(ms): 798.13, token/sec:656897.23, hellaswag_acc: 0.3031
Step: 17895, loss: 2.987994, norm: 0.2999, time(ms): 792.17, token/sec:661841.68, hellaswag_acc: 0.3031
Step: 17896, loss: 3.014710, norm: 0.2797, time(ms): 796.31, token/sec:658399.07, hellaswag_acc: 0.3031
Step: 17897, loss: 3.018105, norm: 0.3124, time(ms): 787.55, token/sec:665717.47, hellaswag_acc: 0.3031
Step: 17898, loss: 3.006125, norm: 0.2801, time(ms): 786.50, token/sec:666610.66, hellaswag_acc: 0.3031
Step: 17899, loss: 2.949199, norm: 0.2748, time(ms): 791.66, token/sec:662261.65, hellaswag_acc: 0.3031
Step: 17900, loss: 2.954483, norm: 0.2920, time(ms): 795.03, token/sec:659453.81, hellaswag_acc: 0.3031
Step: 17901, loss: 2.981443, norm: 0.3272, time(ms): 792.24, token/sec:661782.72, hellaswag_acc: 0.3031
Step: 17902, loss: 3.078316, norm: 0.3379, time(ms): 801.50, token/sec:654136.35, hellaswag_acc: 0.3031
Step: 17903, loss: 3.050846, norm: 0.2934, time(ms): 805.60, token/sec:650806.74, hellaswag_acc: 0.3031
Step: 17904, loss: 3.141464, norm: 0.3632, time(ms): 796.64, token/sec:658126.35, hellaswag_acc: 0.3031
Step: 17905, loss: 3.056914, norm: 0.3145, time(ms): 794.63, token/sec:659791.17, hellaswag_acc: 0.3031
Step: 17906, loss: 3.089968, norm: 0.3239, time(ms): 800.55, token/sec:654913.47, hellaswag_acc: 0.3031
Step: 17907, loss: 3.056480, norm: 0.3100, time(ms): 806.62, token/sec:649984.19, hellaswag_acc: 0.3031
Step: 17908, loss: 3.061070, norm: 0.2875, time(ms): 797.45, token/sec:657452.24, hellaswag_acc: 0.3031
Step: 17909, loss: 3.048333, norm: 0.3103, time(ms): 793.55, token/sec:660684.59, hellaswag_acc: 0.3031
Step: 17910, loss: 3.058146, norm: 0.3113, time(ms): 806.43, token/sec:650132.92, hellaswag_acc: 0.3031
Step: 17911, loss: 3.112326, norm: 0.2917, time(ms): 802.86, token/sec:653025.42, hellaswag_acc: 0.3031
Step: 17912, loss: 3.099670, norm: 0.3089, time(ms): 788.50, token/sec:664919.35, hellaswag_acc: 0.3031
Step: 17913, loss: 3.092758, norm: 0.3222, time(ms): 791.30, token/sec:662562.95, hellaswag_acc: 0.3031
Step: 17914, loss: 3.104155, norm: 0.2933, time(ms): 791.44, token/sec:662450.58, hellaswag_acc: 0.3031
Step: 17915, loss: 3.219846, norm: 0.3369, time(ms): 792.88, token/sec:661245.23, hellaswag_acc: 0.3031
Step: 17916, loss: 3.101302, norm: 0.3108, time(ms): 788.68, token/sec:664770.40, hellaswag_acc: 0.3031
Step: 17917, loss: 3.135191, norm: 0.3742, time(ms): 795.25, token/sec:659276.67, hellaswag_acc: 0.3031
Step: 17918, loss: 3.056110, norm: 0.2912, time(ms): 792.08, token/sec:661912.80, hellaswag_acc: 0.3031
Step: 17919, loss: 3.104408, norm: 0.2992, time(ms): 801.85, token/sec:653850.44, hellaswag_acc: 0.3031
Step: 17920, loss: 3.147911, norm: 0.2995, time(ms): 787.59, token/sec:665684.62, hellaswag_acc: 0.3031
Step: 17921, loss: 3.105425, norm: 0.3046, time(ms): 803.29, token/sec:652672.86, hellaswag_acc: 0.3031
Step: 17922, loss: 3.098371, norm: 0.2946, time(ms): 804.06, token/sec:652047.57, hellaswag_acc: 0.3031
Step: 17923, loss: 3.144254, norm: 0.2835, time(ms): 791.72, token/sec:662214.98, hellaswag_acc: 0.3031
Step: 17924, loss: 3.100875, norm: 0.3024, time(ms): 792.59, token/sec:661489.09, hellaswag_acc: 0.3031
Step: 17925, loss: 3.094202, norm: 0.2779, time(ms): 788.78, token/sec:664680.98, hellaswag_acc: 0.3031
Step: 17926, loss: 3.064258, norm: 0.2778, time(ms): 795.50, token/sec:659071.37, hellaswag_acc: 0.3031
Step: 17927, loss: 3.047648, norm: 0.2798, time(ms): 791.70, token/sec:662226.75, hellaswag_acc: 0.3031
Step: 17928, loss: 3.063776, norm: 0.2826, time(ms): 790.02, token/sec:663640.91, hellaswag_acc: 0.3031
Step: 17929, loss: 3.073205, norm: 0.2890, time(ms): 787.65, token/sec:665631.63, hellaswag_acc: 0.3031
Step: 17930, loss: 3.094070, norm: 0.2918, time(ms): 795.18, token/sec:659328.46, hellaswag_acc: 0.3031
Step: 17931, loss: 3.024373, norm: 0.2676, time(ms): 796.04, token/sec:658623.87, hellaswag_acc: 0.3031
Step: 17932, loss: 3.052368, norm: 0.2871, time(ms): 792.28, token/sec:661747.28, hellaswag_acc: 0.3031
Step: 17933, loss: 3.088609, norm: 0.2824, time(ms): 794.56, token/sec:659844.42, hellaswag_acc: 0.3031
Step: 17934, loss: 3.086316, norm: 0.2603, time(ms): 792.73, token/sec:661366.54, hellaswag_acc: 0.3031
Step: 17935, loss: 3.074123, norm: 0.2657, time(ms): 792.07, token/sec:661924.56, hellaswag_acc: 0.3031
Step: 17936, loss: 3.019048, norm: 0.2784, time(ms): 796.34, token/sec:658369.70, hellaswag_acc: 0.3031
Step: 17937, loss: 2.966327, norm: 0.2582, time(ms): 797.60, token/sec:657334.33, hellaswag_acc: 0.3031
Step: 17938, loss: 3.017627, norm: 0.2789, time(ms): 798.95, token/sec:656222.11, hellaswag_acc: 0.3031
Step: 17939, loss: 2.982064, norm: 0.2747, time(ms): 804.11, token/sec:652010.45, hellaswag_acc: 0.3031
Step: 17940, loss: 2.953260, norm: 0.2604, time(ms): 795.53, token/sec:659039.17, hellaswag_acc: 0.3031
Step: 17941, loss: 2.990203, norm: 0.2720, time(ms): 798.84, token/sec:656310.83, hellaswag_acc: 0.3031
Step: 17942, loss: 3.015911, norm: 0.2850, time(ms): 794.71, token/sec:659719.91, hellaswag_acc: 0.3031
Step: 17943, loss: 3.005427, norm: 0.2610, time(ms): 789.41, token/sec:664148.40, hellaswag_acc: 0.3031
Step: 17944, loss: 3.096033, norm: 0.2705, time(ms): 791.39, token/sec:662492.29, hellaswag_acc: 0.3031
Step: 17945, loss: 2.907507, norm: 0.2817, time(ms): 789.12, token/sec:664391.60, hellaswag_acc: 0.3031
Step: 17946, loss: 2.951030, norm: 0.2737, time(ms): 795.45, token/sec:659105.74, hellaswag_acc: 0.3031
Step: 17947, loss: 2.978607, norm: 0.2812, time(ms): 798.56, token/sec:656541.27, hellaswag_acc: 0.3031
Step: 17948, loss: 3.086674, norm: 0.3354, time(ms): 805.50, token/sec:650888.03, hellaswag_acc: 0.3031
Step: 17949, loss: 3.071297, norm: 0.2936, time(ms): 794.67, token/sec:659754.94, hellaswag_acc: 0.3031
Step: 17950, loss: 3.067456, norm: 0.2979, time(ms): 799.06, token/sec:656133.61, hellaswag_acc: 0.3031
Step: 17951, loss: 3.084997, norm: 0.3078, time(ms): 804.31, token/sec:651845.20, hellaswag_acc: 0.3031
Step: 17952, loss: 3.107962, norm: 0.3048, time(ms): 801.18, token/sec:654392.33, hellaswag_acc: 0.3031
Step: 17953, loss: 3.084224, norm: 0.2849, time(ms): 789.80, token/sec:663826.02, hellaswag_acc: 0.3031
Step: 17954, loss: 3.318640, norm: 0.3913, time(ms): 800.24, token/sec:655163.61, hellaswag_acc: 0.3031
Step: 17955, loss: 3.092674, norm: 0.3945, time(ms): 799.79, token/sec:655528.83, hellaswag_acc: 0.3031
Step: 17956, loss: 3.067027, norm: 0.3021, time(ms): 792.30, token/sec:661729.95, hellaswag_acc: 0.3031
Step: 17957, loss: 3.199528, norm: 0.4012, time(ms): 793.74, token/sec:660524.64, hellaswag_acc: 0.3031
Step: 17958, loss: 3.135965, norm: 0.3357, time(ms): 790.05, token/sec:663612.47, hellaswag_acc: 0.3031
Step: 17959, loss: 3.054173, norm: 0.3138, time(ms): 791.77, token/sec:662171.71, hellaswag_acc: 0.3031
Step: 17960, loss: 3.065384, norm: 0.3228, time(ms): 796.70, token/sec:658076.53, hellaswag_acc: 0.3031
Step: 17961, loss: 3.098429, norm: 0.3074, time(ms): 802.45, token/sec:653359.72, hellaswag_acc: 0.3031
Step: 17962, loss: 3.095861, norm: 0.2879, time(ms): 793.28, token/sec:660908.77, hellaswag_acc: 0.3031
Step: 17963, loss: 3.102753, norm: 0.3016, time(ms): 803.02, token/sec:652893.58, hellaswag_acc: 0.3031
Step: 17964, loss: 3.086167, norm: 0.2935, time(ms): 805.52, token/sec:650867.22, hellaswag_acc: 0.3031
Step: 17965, loss: 3.071002, norm: 0.2933, time(ms): 792.37, token/sec:661667.43, hellaswag_acc: 0.3031
Step: 17966, loss: 3.094686, norm: 0.2950, time(ms): 799.98, token/sec:655374.10, hellaswag_acc: 0.3031
Step: 17967, loss: 3.042600, norm: 0.2998, time(ms): 801.40, token/sec:654216.72, hellaswag_acc: 0.3031
Step: 17968, loss: 3.057714, norm: 0.2850, time(ms): 799.34, token/sec:655897.78, hellaswag_acc: 0.3031
Step: 17969, loss: 3.113396, norm: 0.3014, time(ms): 801.62, token/sec:654034.21, hellaswag_acc: 0.3031
Step: 17970, loss: 3.085388, norm: 0.2886, time(ms): 799.31, token/sec:655923.80, hellaswag_acc: 0.3031
Step: 17971, loss: 3.085294, norm: 0.2891, time(ms): 800.12, token/sec:655262.59, hellaswag_acc: 0.3031
Step: 17972, loss: 3.053006, norm: 0.2878, time(ms): 800.67, token/sec:654809.14, hellaswag_acc: 0.3031
Step: 17973, loss: 3.041886, norm: 0.2705, time(ms): 799.88, token/sec:655457.12, hellaswag_acc: 0.3031
Step: 17974, loss: 3.090168, norm: 0.3017, time(ms): 799.79, token/sec:655534.89, hellaswag_acc: 0.3031
Step: 17975, loss: 3.082919, norm: 0.2799, time(ms): 799.37, token/sec:655874.11, hellaswag_acc: 0.3031
Step: 17976, loss: 3.066566, norm: 0.2819, time(ms): 798.73, token/sec:656398.01, hellaswag_acc: 0.3031
Step: 17977, loss: 3.065252, norm: 0.2875, time(ms): 801.61, token/sec:654044.13, hellaswag_acc: 0.3031
Step: 17978, loss: 2.997032, norm: 0.2946, time(ms): 797.13, token/sec:657721.45, hellaswag_acc: 0.3031
Step: 17979, loss: 3.058840, norm: 0.2772, time(ms): 801.65, token/sec:654007.37, hellaswag_acc: 0.3031
Step: 17980, loss: 3.095715, norm: 0.2764, time(ms): 800.26, token/sec:655148.97, hellaswag_acc: 0.3031
Step: 17981, loss: 3.055471, norm: 0.2914, time(ms): 800.04, token/sec:655328.60, hellaswag_acc: 0.3031
Step: 17982, loss: 3.067492, norm: 0.2883, time(ms): 798.38, token/sec:656692.43, hellaswag_acc: 0.3031
Step: 17983, loss: 2.933053, norm: 0.2802, time(ms): 801.26, token/sec:654329.44, hellaswag_acc: 0.3031
Step: 17984, loss: 2.984399, norm: 0.3008, time(ms): 799.70, token/sec:655605.44, hellaswag_acc: 0.3031
Step: 17985, loss: 2.957629, norm: 0.3310, time(ms): 797.57, token/sec:657359.48, hellaswag_acc: 0.3031
Step: 17986, loss: 3.006104, norm: 0.2961, time(ms): 797.38, token/sec:657515.15, hellaswag_acc: 0.3031
Step: 17987, loss: 2.966316, norm: 0.2900, time(ms): 803.71, token/sec:652337.52, hellaswag_acc: 0.3031
Step: 17988, loss: 3.006890, norm: 0.2698, time(ms): 802.84, token/sec:653041.71, hellaswag_acc: 0.3031
Step: 17989, loss: 2.955363, norm: 0.2768, time(ms): 789.85, token/sec:663781.73, hellaswag_acc: 0.3031
Step: 17990, loss: 2.931443, norm: 0.2882, time(ms): 790.22, token/sec:663468.91, hellaswag_acc: 0.3031
Step: 17991, loss: 3.034050, norm: 0.3004, time(ms): 799.73, token/sec:655584.73, hellaswag_acc: 0.3031
Step: 17992, loss: 3.022290, norm: 0.2663, time(ms): 791.24, token/sec:662612.27, hellaswag_acc: 0.3031
Step: 17993, loss: 2.951959, norm: 0.3039, time(ms): 791.32, token/sec:662550.78, hellaswag_acc: 0.3031
Step: 17994, loss: 3.005223, norm: 0.2947, time(ms): 787.93, token/sec:665399.80, hellaswag_acc: 0.3031
Step: 17995, loss: 3.089334, norm: 0.3383, time(ms): 791.34, token/sec:662533.21, hellaswag_acc: 0.3031
Step: 17996, loss: 3.025141, norm: 0.3132, time(ms): 793.72, token/sec:660546.66, hellaswag_acc: 0.3031
Step: 17997, loss: 3.041766, norm: 0.3059, time(ms): 800.51, token/sec:654942.92, hellaswag_acc: 0.3031
Step: 17998, loss: 3.092772, norm: 0.3223, time(ms): 800.92, token/sec:654605.83, hellaswag_acc: 0.3031
Step: 17999, loss: 3.057306, norm: 0.2928, time(ms): 798.33, token/sec:656733.62, hellaswag_acc: 0.3031
rank 0 sample 0: Hello, I'm a language model, and I think it is possible to learn Spanish much more easily. However, as I understand it myself I would like to
rank 0 sample 1: Hello, I'm a language model, so in this post we'll talk about the language classes from a particular part of the course. So what I'm saying
rank 0 sample 2: Hello, I'm a language model, so I get it on Google. The language model is a great place to start and it's a great place for any
rank 0 sample 3: Hello, I'm a language model, a lot of people are learning to code and most of them are getting really excited at the new machine learning world that can
rank 1 sample 0: Hello, I'm a language model, i guess i'm a language model can't even think of myself as a language model in this language model.
I
rank 1 sample 1: Hello, I'm a language model, not an expert in the field. If you're thinking back to before you went into computer science, you might have a
rank 1 sample 2: Hello, I'm a language model, I used it and I'm a language model. I think when we say "I'm a language model," there are
rank 1 sample 3: Hello, I'm a language model, and I'm learning to run some commands every day. ...You might even hear me sing me the song I am singing
Step: 18000, loss: 3.067457, norm: 0.3182, time(ms): 363450.88, token/sec:1442.53, val_loss: 3.0709, hellaswag_acc: 0.3044
Step: 18001, loss: 3.087147, norm: 0.3200, time(ms): 797.13, token/sec:657721.05, hellaswag_acc: 0.3044
Step: 18002, loss: 3.079564, norm: 0.2993, time(ms): 794.19, token/sec:660155.42, hellaswag_acc: 0.3044
Step: 18003, loss: 3.060375, norm: 0.3020, time(ms): 800.71, token/sec:654779.30, hellaswag_acc: 0.3044
Step: 18004, loss: 3.028692, norm: 0.2940, time(ms): 800.08, token/sec:655294.62, hellaswag_acc: 0.3044
Step: 18005, loss: 3.074829, norm: 0.3120, time(ms): 801.16, token/sec:654409.66, hellaswag_acc: 0.3044
Step: 18006, loss: 3.099995, norm: 0.3025, time(ms): 798.74, token/sec:656393.11, hellaswag_acc: 0.3044
Step: 18007, loss: 3.087776, norm: 0.3042, time(ms): 799.82, token/sec:655508.12, hellaswag_acc: 0.3044
Step: 18008, loss: 3.076945, norm: 0.3170, time(ms): 799.70, token/sec:655607.59, hellaswag_acc: 0.3044
Step: 18009, loss: 3.170645, norm: 0.3372, time(ms): 1299.53, token/sec:403443.50, hellaswag_acc: 0.3044
Step: 18010, loss: 3.054060, norm: 0.3040, time(ms): 790.29, token/sec:663415.47, hellaswag_acc: 0.3044
Step: 18011, loss: 3.135198, norm: 0.3175, time(ms): 778.75, token/sec:673241.21, hellaswag_acc: 0.3044
Step: 18012, loss: 3.102747, norm: 0.2936, time(ms): 788.04, token/sec:665304.58, hellaswag_acc: 0.3044
Step: 18013, loss: 3.080948, norm: 0.2851, time(ms): 804.21, token/sec:651932.55, hellaswag_acc: 0.3044
Step: 18014, loss: 3.151798, norm: 0.2934, time(ms): 786.72, token/sec:666422.79, hellaswag_acc: 0.3044
Step: 18015, loss: 3.059657, norm: 0.2980, time(ms): 785.16, token/sec:667749.28, hellaswag_acc: 0.3044
Step: 18016, loss: 3.061073, norm: 0.3107, time(ms): 792.24, token/sec:661778.74, hellaswag_acc: 0.3044
Step: 18017, loss: 3.042360, norm: 0.2650, time(ms): 795.72, token/sec:658883.77, hellaswag_acc: 0.3044
Step: 18018, loss: 3.010633, norm: 0.2745, time(ms): 795.25, token/sec:659274.29, hellaswag_acc: 0.3044
Step: 18019, loss: 3.009627, norm: 0.3157, time(ms): 801.79, token/sec:653897.49, hellaswag_acc: 0.3044
Step: 18020, loss: 3.054820, norm: 0.2912, time(ms): 801.99, token/sec:653730.12, hellaswag_acc: 0.3044
Step: 18021, loss: 3.039692, norm: 0.2608, time(ms): 800.70, token/sec:654791.00, hellaswag_acc: 0.3044
Step: 18022, loss: 3.034245, norm: 0.2659, time(ms): 790.81, token/sec:662976.45, hellaswag_acc: 0.3044
Step: 18023, loss: 3.000215, norm: 0.2759, time(ms): 797.20, token/sec:657663.22, hellaswag_acc: 0.3044
Step: 18024, loss: 3.061042, norm: 0.2680, time(ms): 792.46, token/sec:661599.55, hellaswag_acc: 0.3044
Step: 18025, loss: 3.078187, norm: 0.2647, time(ms): 790.50, token/sec:663234.79, hellaswag_acc: 0.3044
Step: 18026, loss: 3.052991, norm: 0.2737, time(ms): 790.54, token/sec:663202.58, hellaswag_acc: 0.3044
Step: 18027, loss: 3.094348, norm: 0.2889, time(ms): 784.24, token/sec:668529.63, hellaswag_acc: 0.3044
Step: 18028, loss: 3.086768, norm: 0.3242, time(ms): 789.17, token/sec:664356.88, hellaswag_acc: 0.3044
Step: 18029, loss: 3.062542, norm: 0.2792, time(ms): 801.87, token/sec:653834.69, hellaswag_acc: 0.3044
Step: 18030, loss: 3.054338, norm: 0.2933, time(ms): 801.14, token/sec:654424.85, hellaswag_acc: 0.3044
Step: 18031, loss: 3.147779, norm: 0.2980, time(ms): 795.97, token/sec:658677.13, hellaswag_acc: 0.3044
Step: 18032, loss: 3.079673, norm: 0.2981, time(ms): 802.48, token/sec:653334.29, hellaswag_acc: 0.3044
Step: 18033, loss: 3.141762, norm: 0.2965, time(ms): 801.87, token/sec:653833.14, hellaswag_acc: 0.3044
Step: 18034, loss: 3.130883, norm: 0.3144, time(ms): 795.00, token/sec:659481.50, hellaswag_acc: 0.3044
Step: 18035, loss: 3.091885, norm: 0.3100, time(ms): 795.80, token/sec:658821.98, hellaswag_acc: 0.3044
Step: 18036, loss: 3.053800, norm: 0.2919, time(ms): 801.54, token/sec:654098.99, hellaswag_acc: 0.3044
Step: 18037, loss: 3.061581, norm: 0.3089, time(ms): 805.27, token/sec:651068.41, hellaswag_acc: 0.3044
Step: 18038, loss: 3.082306, norm: 0.3100, time(ms): 801.34, token/sec:654261.69, hellaswag_acc: 0.3044
Step: 18039, loss: 3.012085, norm: 0.2858, time(ms): 794.50, token/sec:659894.72, hellaswag_acc: 0.3044
Step: 18040, loss: 3.100597, norm: 0.3190, time(ms): 802.74, token/sec:653119.68, hellaswag_acc: 0.3044
Step: 18041, loss: 3.054233, norm: 0.3048, time(ms): 801.89, token/sec:653817.39, hellaswag_acc: 0.3044
Step: 18042, loss: 3.061378, norm: 0.3070, time(ms): 800.00, token/sec:655356.52, hellaswag_acc: 0.3044
Step: 18043, loss: 3.060720, norm: 0.2727, time(ms): 788.53, token/sec:664895.22, hellaswag_acc: 0.3044
Step: 18044, loss: 3.237743, norm: 0.3515, time(ms): 790.86, token/sec:662934.87, hellaswag_acc: 0.3044
Step: 18045, loss: 3.103404, norm: 0.2981, time(ms): 791.75, token/sec:662185.27, hellaswag_acc: 0.3044
Step: 18046, loss: 3.097988, norm: 0.2902, time(ms): 792.04, token/sec:661943.29, hellaswag_acc: 0.3044
Step: 18047, loss: 3.117327, norm: 0.3053, time(ms): 794.31, token/sec:660056.54, hellaswag_acc: 0.3044
Step: 18048, loss: 3.080501, norm: 0.3069, time(ms): 796.59, token/sec:658166.34, hellaswag_acc: 0.3044
Step: 18049, loss: 3.077607, norm: 0.2870, time(ms): 800.88, token/sec:654637.20, hellaswag_acc: 0.3044
Step: 18050, loss: 3.069658, norm: 0.2850, time(ms): 801.47, token/sec:654162.04, hellaswag_acc: 0.3044
Step: 18051, loss: 3.019691, norm: 0.2918, time(ms): 798.53, token/sec:656564.98, hellaswag_acc: 0.3044
Step: 18052, loss: 3.058644, norm: 0.2817, time(ms): 796.73, token/sec:658049.55, hellaswag_acc: 0.3044
Step: 18053, loss: 3.108175, norm: 0.3143, time(ms): 806.00, token/sec:650482.93, hellaswag_acc: 0.3044
Step: 18054, loss: 3.047311, norm: 0.2719, time(ms): 798.30, token/sec:656751.66, hellaswag_acc: 0.3044
Step: 18055, loss: 3.070771, norm: 0.2962, time(ms): 792.93, token/sec:661202.09, hellaswag_acc: 0.3044
Step: 18056, loss: 3.012565, norm: 0.2902, time(ms): 795.75, token/sec:658860.08, hellaswag_acc: 0.3044
Step: 18057, loss: 3.037478, norm: 0.2839, time(ms): 796.68, token/sec:658087.36, hellaswag_acc: 0.3044
Step: 18058, loss: 3.070302, norm: 0.2741, time(ms): 788.01, token/sec:665333.37, hellaswag_acc: 0.3044
Step: 18059, loss: 3.052930, norm: 0.2828, time(ms): 788.55, token/sec:664877.33, hellaswag_acc: 0.3044
Step: 18060, loss: 3.085136, norm: 0.2981, time(ms): 787.75, token/sec:665554.47, hellaswag_acc: 0.3044
Step: 18061, loss: 3.099913, norm: 0.2896, time(ms): 792.16, token/sec:661849.05, hellaswag_acc: 0.3044
Step: 18062, loss: 3.068178, norm: 0.3049, time(ms): 798.29, token/sec:656766.17, hellaswag_acc: 0.3044
Step: 18063, loss: 3.062496, norm: 0.3031, time(ms): 790.85, token/sec:662942.47, hellaswag_acc: 0.3044
Step: 18064, loss: 3.142122, norm: 0.3101, time(ms): 800.94, token/sec:654592.97, hellaswag_acc: 0.3044
Step: 18065, loss: 3.105984, norm: 0.3355, time(ms): 798.09, token/sec:656926.08, hellaswag_acc: 0.3044
Step: 18066, loss: 3.067100, norm: 0.3061, time(ms): 792.37, token/sec:661671.81, hellaswag_acc: 0.3044
Step: 18067, loss: 3.124672, norm: 0.2841, time(ms): 794.75, token/sec:659687.25, hellaswag_acc: 0.3044
Step: 18068, loss: 3.137512, norm: 0.3112, time(ms): 787.19, token/sec:666020.92, hellaswag_acc: 0.3044
Step: 18069, loss: 3.062438, norm: 0.2945, time(ms): 791.03, token/sec:662793.61, hellaswag_acc: 0.3044
Step: 18070, loss: 3.061540, norm: 0.2851, time(ms): 800.35, token/sec:655077.35, hellaswag_acc: 0.3044
Step: 18071, loss: 3.142237, norm: 0.2982, time(ms): 803.62, token/sec:652408.16, hellaswag_acc: 0.3044
Step: 18072, loss: 3.071615, norm: 0.3131, time(ms): 796.36, token/sec:658352.55, hellaswag_acc: 0.3044
Step: 18073, loss: 3.080174, norm: 0.3111, time(ms): 793.62, token/sec:660629.22, hellaswag_acc: 0.3044
Step: 18074, loss: 3.012305, norm: 0.3000, time(ms): 797.68, token/sec:657269.89, hellaswag_acc: 0.3044
Step: 18075, loss: 3.149083, norm: 0.3548, time(ms): 792.58, token/sec:661498.84, hellaswag_acc: 0.3044
Step: 18076, loss: 3.078967, norm: 0.3012, time(ms): 796.97, token/sec:657848.95, hellaswag_acc: 0.3044
Step: 18077, loss: 3.031315, norm: 0.2984, time(ms): 791.35, token/sec:662522.63, hellaswag_acc: 0.3044
Step: 18078, loss: 3.065129, norm: 0.2978, time(ms): 788.83, token/sec:664636.79, hellaswag_acc: 0.3044
Step: 18079, loss: 3.080625, norm: 0.2793, time(ms): 791.95, token/sec:662022.80, hellaswag_acc: 0.3044
Step: 18080, loss: 3.039811, norm: 0.2780, time(ms): 789.99, token/sec:663666.34, hellaswag_acc: 0.3044
Step: 18081, loss: 3.045412, norm: 0.2789, time(ms): 788.51, token/sec:664913.11, hellaswag_acc: 0.3044
Step: 18082, loss: 3.065015, norm: 0.3012, time(ms): 790.96, token/sec:662849.55, hellaswag_acc: 0.3044
Step: 18083, loss: 3.116521, norm: 0.2744, time(ms): 792.41, token/sec:661634.98, hellaswag_acc: 0.3044
Step: 18084, loss: 3.055449, norm: 0.2898, time(ms): 792.30, token/sec:661730.35, hellaswag_acc: 0.3044
Step: 18085, loss: 3.059364, norm: 0.2823, time(ms): 794.30, token/sec:660062.68, hellaswag_acc: 0.3044
Step: 18086, loss: 3.098274, norm: 0.2709, time(ms): 794.09, token/sec:660233.91, hellaswag_acc: 0.3044
Step: 18087, loss: 3.041833, norm: 0.2913, time(ms): 800.80, token/sec:654703.28, hellaswag_acc: 0.3044
Step: 18088, loss: 3.054313, norm: 0.2700, time(ms): 802.41, token/sec:653395.24, hellaswag_acc: 0.3044
Step: 18089, loss: 3.105301, norm: 0.3018, time(ms): 798.73, token/sec:656400.56, hellaswag_acc: 0.3044
Step: 18090, loss: 3.041915, norm: 0.2807, time(ms): 797.02, token/sec:657813.92, hellaswag_acc: 0.3044
Step: 18091, loss: 3.053000, norm: 0.2627, time(ms): 801.26, token/sec:654331.38, hellaswag_acc: 0.3044
Step: 18092, loss: 3.076844, norm: 0.2880, time(ms): 803.78, token/sec:652279.47, hellaswag_acc: 0.3044
Step: 18093, loss: 3.026329, norm: 0.2944, time(ms): 791.46, token/sec:662428.63, hellaswag_acc: 0.3044
Step: 18094, loss: 3.048134, norm: 0.2724, time(ms): 792.12, token/sec:661882.12, hellaswag_acc: 0.3044
Step: 18095, loss: 3.087398, norm: 0.3213, time(ms): 793.73, token/sec:660534.16, hellaswag_acc: 0.3044
Step: 18096, loss: 3.014163, norm: 0.3148, time(ms): 798.02, token/sec:656984.56, hellaswag_acc: 0.3044
Step: 18097, loss: 3.130526, norm: 0.3031, time(ms): 804.11, token/sec:652013.16, hellaswag_acc: 0.3044
Step: 18098, loss: 3.072922, norm: 0.3073, time(ms): 797.64, token/sec:657295.23, hellaswag_acc: 0.3044
Step: 18099, loss: 3.111763, norm: 0.3260, time(ms): 791.28, token/sec:662579.12, hellaswag_acc: 0.3044
Step: 18100, loss: 3.079763, norm: 0.3122, time(ms): 788.63, token/sec:664807.18, hellaswag_acc: 0.3044
Step: 18101, loss: 3.100532, norm: 0.2941, time(ms): 790.40, token/sec:663317.81, hellaswag_acc: 0.3044
Step: 18102, loss: 3.087095, norm: 0.3151, time(ms): 790.49, token/sec:663247.59, hellaswag_acc: 0.3044
Step: 18103, loss: 3.058733, norm: 0.2915, time(ms): 798.09, token/sec:656929.02, hellaswag_acc: 0.3044
Step: 18104, loss: 3.077169, norm: 0.3271, time(ms): 799.65, token/sec:655650.21, hellaswag_acc: 0.3044
Step: 18105, loss: 3.117424, norm: 0.5747, time(ms): 800.27, token/sec:655137.46, hellaswag_acc: 0.3044
Step: 18106, loss: 3.065504, norm: 0.3413, time(ms): 791.30, token/sec:662568.74, hellaswag_acc: 0.3044
Step: 18107, loss: 3.084497, norm: 0.3670, time(ms): 793.00, token/sec:661145.43, hellaswag_acc: 0.3044
Step: 18108, loss: 3.081965, norm: 0.3392, time(ms): 792.82, token/sec:661291.96, hellaswag_acc: 0.3044
Step: 18109, loss: 3.087389, norm: 0.3199, time(ms): 791.77, token/sec:662169.52, hellaswag_acc: 0.3044
Step: 18110, loss: 3.100943, norm: 0.3350, time(ms): 792.98, token/sec:661163.12, hellaswag_acc: 0.3044
Step: 18111, loss: 3.099865, norm: 0.3629, time(ms): 793.83, token/sec:660453.62, hellaswag_acc: 0.3044
Step: 18112, loss: 3.156344, norm: 0.3298, time(ms): 801.15, token/sec:654417.65, hellaswag_acc: 0.3044
Step: 18113, loss: 3.027654, norm: 0.3056, time(ms): 800.51, token/sec:654941.56, hellaswag_acc: 0.3044
Step: 18114, loss: 3.083240, norm: 0.3174, time(ms): 800.84, token/sec:654674.62, hellaswag_acc: 0.3044
Step: 18115, loss: 3.076137, norm: 0.3173, time(ms): 799.45, token/sec:655809.57, hellaswag_acc: 0.3044
Step: 18116, loss: 3.099231, norm: 0.2910, time(ms): 802.48, token/sec:653332.93, hellaswag_acc: 0.3044
Step: 18117, loss: 3.083253, norm: 0.2905, time(ms): 793.51, token/sec:660721.91, hellaswag_acc: 0.3044
Step: 18118, loss: 3.049754, norm: 0.2922, time(ms): 801.36, token/sec:654251.18, hellaswag_acc: 0.3044
Step: 18119, loss: 3.050383, norm: 0.2831, time(ms): 803.32, token/sec:652655.43, hellaswag_acc: 0.3044
Step: 18120, loss: 3.057570, norm: 0.2963, time(ms): 800.67, token/sec:654809.72, hellaswag_acc: 0.3044
Step: 18121, loss: 3.023886, norm: 0.2841, time(ms): 789.99, token/sec:663667.55, hellaswag_acc: 0.3044
Step: 18122, loss: 3.017877, norm: 0.2972, time(ms): 790.57, token/sec:663179.78, hellaswag_acc: 0.3044
Step: 18123, loss: 3.014849, norm: 0.2769, time(ms): 799.10, token/sec:656095.63, hellaswag_acc: 0.3044
Step: 18124, loss: 3.058488, norm: 0.2928, time(ms): 791.68, token/sec:662247.69, hellaswag_acc: 0.3044
Step: 18125, loss: 3.002883, norm: 0.2993, time(ms): 792.18, token/sec:661828.34, hellaswag_acc: 0.3044
Step: 18126, loss: 2.963607, norm: 0.3063, time(ms): 792.28, token/sec:661747.87, hellaswag_acc: 0.3044
Step: 18127, loss: 3.029001, norm: 0.2758, time(ms): 787.86, token/sec:665461.22, hellaswag_acc: 0.3044
Step: 18128, loss: 3.059561, norm: 0.2957, time(ms): 795.16, token/sec:659349.21, hellaswag_acc: 0.3044
Step: 18129, loss: 3.036392, norm: 0.2871, time(ms): 797.23, token/sec:657633.13, hellaswag_acc: 0.3044
Step: 18130, loss: 3.065553, norm: 0.3053, time(ms): 800.89, token/sec:654631.55, hellaswag_acc: 0.3044
Step: 18131, loss: 3.104490, norm: 0.3440, time(ms): 800.86, token/sec:654660.20, hellaswag_acc: 0.3044
Step: 18132, loss: 3.069717, norm: 0.3263, time(ms): 792.45, token/sec:661603.93, hellaswag_acc: 0.3044
Step: 18133, loss: 3.090860, norm: 0.3186, time(ms): 805.13, token/sec:651187.56, hellaswag_acc: 0.3044
Step: 18134, loss: 3.059993, norm: 0.3194, time(ms): 800.46, token/sec:654983.30, hellaswag_acc: 0.3044
Step: 18135, loss: 3.119647, norm: 0.3297, time(ms): 798.65, token/sec:656468.55, hellaswag_acc: 0.3044
Step: 18136, loss: 3.104088, norm: 0.3431, time(ms): 798.54, token/sec:656561.65, hellaswag_acc: 0.3044
Step: 18137, loss: 3.086642, norm: 0.3208, time(ms): 799.55, token/sec:655729.58, hellaswag_acc: 0.3044
Step: 18138, loss: 3.062134, norm: 0.3280, time(ms): 804.13, token/sec:651993.82, hellaswag_acc: 0.3044
Step: 18139, loss: 3.092434, norm: 0.3211, time(ms): 797.78, token/sec:657182.28, hellaswag_acc: 0.3044
Step: 18140, loss: 3.129149, norm: 0.2989, time(ms): 794.02, token/sec:660298.93, hellaswag_acc: 0.3044
Step: 18141, loss: 3.099977, norm: 0.3061, time(ms): 806.10, token/sec:650403.67, hellaswag_acc: 0.3044
Step: 18142, loss: 3.083671, norm: 0.3146, time(ms): 802.07, token/sec:653669.49, hellaswag_acc: 0.3044
Step: 18143, loss: 3.127948, norm: 0.2981, time(ms): 794.57, token/sec:659842.64, hellaswag_acc: 0.3044
Step: 18144, loss: 3.050807, norm: 0.3062, time(ms): 799.91, token/sec:655430.16, hellaswag_acc: 0.3044
Step: 18145, loss: 3.089402, norm: 0.2983, time(ms): 805.29, token/sec:651053.95, hellaswag_acc: 0.3044
Step: 18146, loss: 3.113869, norm: 0.3086, time(ms): 796.18, token/sec:658501.20, hellaswag_acc: 0.3044
Step: 18147, loss: 3.071987, norm: 0.2878, time(ms): 800.91, token/sec:654616.74, hellaswag_acc: 0.3044
Step: 18148, loss: 3.109766, norm: 0.2870, time(ms): 798.33, token/sec:656727.54, hellaswag_acc: 0.3044
Step: 18149, loss: 3.192966, norm: 0.3397, time(ms): 801.08, token/sec:654477.63, hellaswag_acc: 0.3044
Step: 18150, loss: 3.109729, norm: 0.3026, time(ms): 799.12, token/sec:656082.32, hellaswag_acc: 0.3044
Step: 18151, loss: 3.090945, norm: 0.3028, time(ms): 796.64, token/sec:658123.99, hellaswag_acc: 0.3044
Step: 18152, loss: 3.079451, norm: 0.2936, time(ms): 803.61, token/sec:652419.77, hellaswag_acc: 0.3044
Step: 18153, loss: 3.076869, norm: 0.3061, time(ms): 802.90, token/sec:652994.39, hellaswag_acc: 0.3044
Step: 18154, loss: 3.048196, norm: 0.2848, time(ms): 793.02, token/sec:661132.51, hellaswag_acc: 0.3044
Step: 18155, loss: 3.025869, norm: 0.2804, time(ms): 800.62, token/sec:654854.37, hellaswag_acc: 0.3044
Step: 18156, loss: 3.036693, norm: 0.2620, time(ms): 803.59, token/sec:652430.23, hellaswag_acc: 0.3044
Step: 18157, loss: 3.034762, norm: 0.2858, time(ms): 801.64, token/sec:654016.90, hellaswag_acc: 0.3044
Step: 18158, loss: 3.035602, norm: 0.2805, time(ms): 794.48, token/sec:659910.56, hellaswag_acc: 0.3044
Step: 18159, loss: 3.077645, norm: 0.2699, time(ms): 796.66, token/sec:658106.07, hellaswag_acc: 0.3044
Step: 18160, loss: 3.066466, norm: 0.2890, time(ms): 805.13, token/sec:651184.28, hellaswag_acc: 0.3044
Step: 18161, loss: 3.008798, norm: 0.2658, time(ms): 801.77, token/sec:653911.68, hellaswag_acc: 0.3044
Step: 18162, loss: 3.027386, norm: 0.2695, time(ms): 789.16, token/sec:664360.29, hellaswag_acc: 0.3044
Step: 18163, loss: 3.018973, norm: 0.2802, time(ms): 790.76, token/sec:663018.22, hellaswag_acc: 0.3044
Step: 18164, loss: 3.117781, norm: 0.2933, time(ms): 791.34, token/sec:662534.01, hellaswag_acc: 0.3044
Step: 18165, loss: 3.086351, norm: 0.3295, time(ms): 790.81, token/sec:662973.65, hellaswag_acc: 0.3044
Step: 18166, loss: 3.229875, norm: 0.3283, time(ms): 793.53, token/sec:660703.45, hellaswag_acc: 0.3044
Step: 18167, loss: 3.093892, norm: 0.3197, time(ms): 797.62, token/sec:657317.82, hellaswag_acc: 0.3044
Step: 18168, loss: 3.109257, norm: 0.2997, time(ms): 805.82, token/sec:650629.20, hellaswag_acc: 0.3044
Step: 18169, loss: 3.135765, norm: 0.3010, time(ms): 797.96, token/sec:657036.19, hellaswag_acc: 0.3044
Step: 18170, loss: 3.068573, norm: 0.3154, time(ms): 795.81, token/sec:658810.53, hellaswag_acc: 0.3044
Step: 18171, loss: 3.042825, norm: 0.2858, time(ms): 801.25, token/sec:654339.75, hellaswag_acc: 0.3044
Step: 18172, loss: 3.122044, norm: 0.3020, time(ms): 801.74, token/sec:653938.33, hellaswag_acc: 0.3044
Step: 18173, loss: 3.126736, norm: 0.3080, time(ms): 796.60, token/sec:658156.89, hellaswag_acc: 0.3044
Step: 18174, loss: 3.083175, norm: 0.3284, time(ms): 800.86, token/sec:654660.01, hellaswag_acc: 0.3044
Step: 18175, loss: 3.139295, norm: 0.3315, time(ms): 802.74, token/sec:653124.72, hellaswag_acc: 0.3044
Step: 18176, loss: 3.096050, norm: 0.3113, time(ms): 801.55, token/sec:654093.35, hellaswag_acc: 0.3044
Step: 18177, loss: 3.080423, norm: 0.3312, time(ms): 787.05, token/sec:666142.78, hellaswag_acc: 0.3044
Step: 18178, loss: 3.076290, norm: 0.3015, time(ms): 792.62, token/sec:661460.44, hellaswag_acc: 0.3044
Step: 18179, loss: 3.105397, norm: 0.3120, time(ms): 798.08, token/sec:656932.75, hellaswag_acc: 0.3044
Step: 18180, loss: 3.079296, norm: 0.3062, time(ms): 797.80, token/sec:657169.71, hellaswag_acc: 0.3044
Step: 18181, loss: 3.069691, norm: 0.3030, time(ms): 799.69, token/sec:655613.26, hellaswag_acc: 0.3044
Step: 18182, loss: 3.130409, norm: 0.3068, time(ms): 801.74, token/sec:653941.63, hellaswag_acc: 0.3044
Step: 18183, loss: 3.037203, norm: 0.3092, time(ms): 799.73, token/sec:655580.23, hellaswag_acc: 0.3044
Step: 18184, loss: 3.179920, norm: 0.3186, time(ms): 794.14, token/sec:660192.88, hellaswag_acc: 0.3044
Step: 18185, loss: 3.095519, norm: 0.2907, time(ms): 790.33, token/sec:663381.65, hellaswag_acc: 0.3044
Step: 18186, loss: 3.096792, norm: 0.2823, time(ms): 785.01, token/sec:667878.27, hellaswag_acc: 0.3044
Step: 18187, loss: 3.097576, norm: 0.2906, time(ms): 789.97, token/sec:663681.97, hellaswag_acc: 0.3044
Step: 18188, loss: 3.063888, norm: 0.2826, time(ms): 801.55, token/sec:654090.82, hellaswag_acc: 0.3044
Step: 18189, loss: 2.989549, norm: 0.2747, time(ms): 799.30, token/sec:655933.00, hellaswag_acc: 0.3044
Step: 18190, loss: 3.070278, norm: 0.2779, time(ms): 791.11, token/sec:662721.10, hellaswag_acc: 0.3044
Step: 18191, loss: 3.066393, norm: 0.3207, time(ms): 790.97, token/sec:662845.95, hellaswag_acc: 0.3044
Step: 18192, loss: 3.072783, norm: 0.2823, time(ms): 789.63, token/sec:663970.73, hellaswag_acc: 0.3044
Step: 18193, loss: 3.031190, norm: 0.3083, time(ms): 790.99, token/sec:662824.57, hellaswag_acc: 0.3044
Step: 18194, loss: 3.052838, norm: 0.2807, time(ms): 796.31, token/sec:658393.35, hellaswag_acc: 0.3044
Step: 18195, loss: 3.043601, norm: 0.2785, time(ms): 791.99, token/sec:661991.51, hellaswag_acc: 0.3044
Step: 18196, loss: 3.037017, norm: 0.2831, time(ms): 791.29, token/sec:662574.73, hellaswag_acc: 0.3044
Step: 18197, loss: 3.015738, norm: 0.2918, time(ms): 797.74, token/sec:657220.58, hellaswag_acc: 0.3044
Step: 18198, loss: 3.094217, norm: 0.3130, time(ms): 793.98, token/sec:660327.88, hellaswag_acc: 0.3044
Step: 18199, loss: 3.136763, norm: 0.3093, time(ms): 796.64, token/sec:658126.95, hellaswag_acc: 0.3044
Step: 18200, loss: 3.091967, norm: 0.2929, time(ms): 1454.88, token/sec:360364.70, hellaswag_acc: 0.3044
Step: 18201, loss: 3.056408, norm: 0.3214, time(ms): 802.62, token/sec:653224.44, hellaswag_acc: 0.3044
Step: 18202, loss: 3.122581, norm: 0.2889, time(ms): 795.79, token/sec:658822.97, hellaswag_acc: 0.3044
Step: 18203, loss: 3.024467, norm: 0.2895, time(ms): 783.72, token/sec:668976.45, hellaswag_acc: 0.3044
Step: 18204, loss: 3.107724, norm: 0.3040, time(ms): 791.45, token/sec:662438.21, hellaswag_acc: 0.3044
Step: 18205, loss: 3.024095, norm: 0.2785, time(ms): 796.32, token/sec:658386.25, hellaswag_acc: 0.3044
Step: 18206, loss: 3.063592, norm: 0.2984, time(ms): 804.18, token/sec:651950.14, hellaswag_acc: 0.3044
Step: 18207, loss: 3.030323, norm: 0.2904, time(ms): 797.33, token/sec:657555.46, hellaswag_acc: 0.3044
Step: 18208, loss: 3.041378, norm: 0.2867, time(ms): 797.91, token/sec:657079.97, hellaswag_acc: 0.3044
Step: 18209, loss: 2.978450, norm: 0.2880, time(ms): 800.63, token/sec:654842.87, hellaswag_acc: 0.3044
Step: 18210, loss: 2.988723, norm: 0.2736, time(ms): 803.57, token/sec:652445.71, hellaswag_acc: 0.3044
Step: 18211, loss: 3.049341, norm: 0.2867, time(ms): 794.02, token/sec:660297.75, hellaswag_acc: 0.3044
Step: 18212, loss: 3.090218, norm: 0.3042, time(ms): 793.18, token/sec:660993.60, hellaswag_acc: 0.3044
Step: 18213, loss: 3.075576, norm: 0.2804, time(ms): 790.21, token/sec:663483.52, hellaswag_acc: 0.3044
Step: 18214, loss: 3.080669, norm: 0.2859, time(ms): 797.73, token/sec:657223.92, hellaswag_acc: 0.3044
Step: 18215, loss: 3.067034, norm: 0.3263, time(ms): 793.47, token/sec:660751.89, hellaswag_acc: 0.3044
Step: 18216, loss: 2.898132, norm: 0.3486, time(ms): 789.13, token/sec:664390.00, hellaswag_acc: 0.3044
Step: 18217, loss: 2.844755, norm: 0.2971, time(ms): 785.26, token/sec:667660.89, hellaswag_acc: 0.3044
Step: 18218, loss: 2.853266, norm: 0.3420, time(ms): 794.72, token/sec:659715.95, hellaswag_acc: 0.3044
Step: 18219, loss: 2.913805, norm: 0.3830, time(ms): 796.09, token/sec:658576.14, hellaswag_acc: 0.3044
Step: 18220, loss: 2.829846, norm: 0.2844, time(ms): 804.12, token/sec:652002.72, hellaswag_acc: 0.3044
Step: 18221, loss: 2.904441, norm: 0.3318, time(ms): 798.00, token/sec:656999.87, hellaswag_acc: 0.3044
Step: 18222, loss: 2.855381, norm: 0.3176, time(ms): 794.39, token/sec:659989.98, hellaswag_acc: 0.3044
Step: 18223, loss: 2.858384, norm: 0.2870, time(ms): 804.02, token/sec:652081.41, hellaswag_acc: 0.3044
Step: 18224, loss: 2.843927, norm: 0.3091, time(ms): 800.11, token/sec:655273.33, hellaswag_acc: 0.3044
Step: 18225, loss: 2.903781, norm: 0.3165, time(ms): 799.03, token/sec:656157.30, hellaswag_acc: 0.3044
Step: 18226, loss: 2.879401, norm: 0.2892, time(ms): 801.89, token/sec:653819.33, hellaswag_acc: 0.3044
Step: 18227, loss: 2.892992, norm: 0.3012, time(ms): 797.82, token/sec:657149.88, hellaswag_acc: 0.3044
Step: 18228, loss: 3.101442, norm: 0.3369, time(ms): 801.35, token/sec:654253.32, hellaswag_acc: 0.3044
Step: 18229, loss: 3.205875, norm: 0.3677, time(ms): 794.73, token/sec:659705.06, hellaswag_acc: 0.3044
Step: 18230, loss: 3.110254, norm: 0.3454, time(ms): 804.99, token/sec:651297.10, hellaswag_acc: 0.3044
Step: 18231, loss: 3.054385, norm: 0.3336, time(ms): 798.17, token/sec:656862.30, hellaswag_acc: 0.3044
Step: 18232, loss: 3.129970, norm: 0.3339, time(ms): 800.46, token/sec:654985.06, hellaswag_acc: 0.3044
Step: 18233, loss: 3.108394, norm: 0.2905, time(ms): 797.40, token/sec:657498.05, hellaswag_acc: 0.3044
Step: 18234, loss: 3.070969, norm: 0.3159, time(ms): 801.66, token/sec:654003.87, hellaswag_acc: 0.3044
Step: 18235, loss: 3.069287, norm: 0.3094, time(ms): 795.11, token/sec:659394.29, hellaswag_acc: 0.3044
Step: 18236, loss: 3.056324, norm: 0.3003, time(ms): 803.69, token/sec:652353.97, hellaswag_acc: 0.3044
Step: 18237, loss: 3.052624, norm: 0.2999, time(ms): 802.66, token/sec:653190.10, hellaswag_acc: 0.3044
Step: 18238, loss: 3.033688, norm: 0.2914, time(ms): 797.90, token/sec:657084.29, hellaswag_acc: 0.3044
Step: 18239, loss: 3.020943, norm: 0.4564, time(ms): 796.86, token/sec:657941.65, hellaswag_acc: 0.3044
Step: 18240, loss: 3.051372, norm: 0.2971, time(ms): 800.78, token/sec:654717.70, hellaswag_acc: 0.3044
Step: 18241, loss: 3.106009, norm: 0.2956, time(ms): 804.83, token/sec:651426.18, hellaswag_acc: 0.3044
Step: 18242, loss: 3.070951, norm: 0.3021, time(ms): 789.38, token/sec:664172.88, hellaswag_acc: 0.3044
Step: 18243, loss: 3.093663, norm: 0.2874, time(ms): 789.72, token/sec:663893.76, hellaswag_acc: 0.3044
Step: 18244, loss: 3.058577, norm: 0.2893, time(ms): 794.03, token/sec:660290.41, hellaswag_acc: 0.3044
Step: 18245, loss: 3.091517, norm: 0.3162, time(ms): 791.89, token/sec:662072.03, hellaswag_acc: 0.3044
Step: 18246, loss: 3.114345, norm: 0.3012, time(ms): 790.96, token/sec:662846.95, hellaswag_acc: 0.3044
Step: 18247, loss: 3.110998, norm: 0.2948, time(ms): 797.76, token/sec:657202.31, hellaswag_acc: 0.3044
Step: 18248, loss: 3.126926, norm: 0.3032, time(ms): 802.13, token/sec:653623.05, hellaswag_acc: 0.3044
Step: 18249, loss: 3.115546, norm: 0.3017, time(ms): 802.56, token/sec:653267.52, hellaswag_acc: 0.3044
rank 0 sample 0: Hello, I'm a language model, and I need to understand my native language at least one hour a day. So, how do I learn that language?"
rank 0 sample 1: Hello, I'm a language model, so please go ahead and type this sentence. It tells me what it's supposed to say. I was just trying to
rank 0 sample 2: Hello, I'm a language model, so I really need to teach everything about it as a language so you can understand it better.
I'm not sure
rank 0 sample 3: Hello, I'm a language model, but i'm not a language modeling, i simply a language model. It has certain rules to be true, i say
rank 1 sample 0: Hello, I'm a language model, as well. I'm not a coder... but maybe maybe I could build a robot with me. Maybe I could
rank 1 sample 1: Hello, I'm a language model, not an artist. I'm a software engineer, not that I'm a painter, i'm just an artist. I
rank 1 sample 2: Hello, I'm a language model, but
the real world is a collection of languages. It could have a
language model. In fact it can have
rank 1 sample 3: Hello, I'm a language model, and I'm learning to get it wrong just like everyone when I write software
- Make no mistake, I'll be
Step: 18250, loss: 3.117570, norm: 0.2879, time(ms): 3844.95, token/sec:136357.59, val_loss: 3.0699, hellaswag_acc: 0.3044
Step: 18251, loss: 3.032894, norm: 0.2833, time(ms): 793.23, token/sec:660956.45, hellaswag_acc: 0.3044
Step: 18252, loss: 3.069790, norm: 0.3020, time(ms): 797.30, token/sec:657580.03, hellaswag_acc: 0.3044
Step: 18253, loss: 3.021771, norm: 0.2667, time(ms): 797.71, token/sec:657244.15, hellaswag_acc: 0.3044
Step: 18254, loss: 2.982085, norm: 0.3147, time(ms): 806.61, token/sec:649991.30, hellaswag_acc: 0.3044
Step: 18255, loss: 3.029781, norm: 0.2793, time(ms): 788.14, token/sec:665219.85, hellaswag_acc: 0.3044
Step: 18256, loss: 3.050204, norm: 0.2891, time(ms): 786.10, token/sec:666948.91, hellaswag_acc: 0.3044
Step: 18257, loss: 3.004728, norm: 0.2711, time(ms): 795.62, token/sec:658967.29, hellaswag_acc: 0.3044
Step: 18258, loss: 3.130305, norm: 0.3291, time(ms): 791.39, token/sec:662491.30, hellaswag_acc: 0.3044
Step: 18259, loss: 3.078885, norm: 0.2795, time(ms): 789.80, token/sec:663822.81, hellaswag_acc: 0.3044
Step: 18260, loss: 3.076777, norm: 0.3230, time(ms): 795.88, token/sec:658750.14, hellaswag_acc: 0.3044
Step: 18261, loss: 3.055500, norm: 0.2753, time(ms): 790.89, token/sec:662912.89, hellaswag_acc: 0.3044
Step: 18262, loss: 2.980231, norm: 0.3146, time(ms): 799.43, token/sec:655825.60, hellaswag_acc: 0.3044
Step: 18263, loss: 2.835814, norm: 0.3092, time(ms): 787.58, token/sec:665691.88, hellaswag_acc: 0.3044
Step: 18264, loss: 2.859785, norm: 0.3208, time(ms): 789.29, token/sec:664252.32, hellaswag_acc: 0.3044
Step: 18265, loss: 2.857611, norm: 0.3606, time(ms): 792.72, token/sec:661374.90, hellaswag_acc: 0.3044
Step: 18266, loss: 2.820903, norm: 0.3114, time(ms): 790.49, token/sec:663241.19, hellaswag_acc: 0.3044
Step: 18267, loss: 2.861486, norm: 0.2952, time(ms): 798.69, token/sec:656436.41, hellaswag_acc: 0.3044
Step: 18268, loss: 2.875515, norm: 0.3262, time(ms): 795.71, token/sec:658894.43, hellaswag_acc: 0.3044
Step: 18269, loss: 2.861339, norm: 0.3163, time(ms): 793.01, token/sec:661135.49, hellaswag_acc: 0.3044
Step: 18270, loss: 2.904016, norm: 0.2717, time(ms): 790.24, token/sec:663456.50, hellaswag_acc: 0.3044
Step: 18271, loss: 2.829803, norm: 0.2950, time(ms): 792.50, token/sec:661561.93, hellaswag_acc: 0.3044
Step: 18272, loss: 2.797153, norm: 0.2966, time(ms): 790.51, token/sec:663226.19, hellaswag_acc: 0.3044
Step: 18273, loss: 2.895855, norm: 0.2664, time(ms): 789.11, token/sec:664407.86, hellaswag_acc: 0.3044
Step: 18274, loss: 3.014072, norm: 0.3417, time(ms): 791.70, token/sec:662230.14, hellaswag_acc: 0.3044
Step: 18275, loss: 3.098102, norm: 0.3031, time(ms): 797.29, token/sec:657591.64, hellaswag_acc: 0.3044
Step: 18276, loss: 3.016308, norm: 0.3072, time(ms): 794.06, token/sec:660262.06, hellaswag_acc: 0.3044
Step: 18277, loss: 3.137709, norm: 0.3442, time(ms): 799.72, token/sec:655591.76, hellaswag_acc: 0.3044
Step: 18278, loss: 3.090282, norm: 0.3082, time(ms): 796.56, token/sec:658193.53, hellaswag_acc: 0.3044
Step: 18279, loss: 2.994244, norm: 0.3577, time(ms): 790.59, token/sec:663158.98, hellaswag_acc: 0.3044
Step: 18280, loss: 3.046989, norm: 0.3210, time(ms): 788.01, token/sec:665335.78, hellaswag_acc: 0.3044
Step: 18281, loss: 3.062026, norm: 0.3232, time(ms): 790.41, token/sec:663313.61, hellaswag_acc: 0.3044
Step: 18282, loss: 3.134771, norm: 0.3003, time(ms): 793.29, token/sec:660906.99, hellaswag_acc: 0.3044
Step: 18283, loss: 3.039697, norm: 0.3120, time(ms): 802.13, token/sec:653620.92, hellaswag_acc: 0.3044
Step: 18284, loss: 3.141449, norm: 0.3230, time(ms): 799.35, token/sec:655889.37, hellaswag_acc: 0.3044
Step: 18285, loss: 3.070725, norm: 0.3095, time(ms): 803.53, token/sec:652479.20, hellaswag_acc: 0.3044
Step: 18286, loss: 3.129795, norm: 0.2890, time(ms): 797.75, token/sec:657207.42, hellaswag_acc: 0.3044
Step: 18287, loss: 3.081919, norm: 0.3066, time(ms): 798.00, token/sec:657000.27, hellaswag_acc: 0.3044
Step: 18288, loss: 3.076519, norm: 0.3031, time(ms): 801.82, token/sec:653870.46, hellaswag_acc: 0.3044
Step: 18289, loss: 3.090139, norm: 0.2924, time(ms): 800.38, token/sec:655044.76, hellaswag_acc: 0.3044
Step: 18290, loss: 3.053706, norm: 0.3289, time(ms): 801.65, token/sec:654009.51, hellaswag_acc: 0.3044
Step: 18291, loss: 3.156481, norm: 0.2924, time(ms): 784.04, token/sec:668699.38, hellaswag_acc: 0.3044
Step: 18292, loss: 3.047090, norm: 0.2768, time(ms): 797.15, token/sec:657699.41, hellaswag_acc: 0.3044
Step: 18293, loss: 3.083426, norm: 0.2761, time(ms): 788.72, token/sec:664732.82, hellaswag_acc: 0.3044
Step: 18294, loss: 3.120891, norm: 0.2741, time(ms): 793.49, token/sec:660739.58, hellaswag_acc: 0.3044
Step: 18295, loss: 3.119582, norm: 0.2777, time(ms): 791.51, token/sec:662387.93, hellaswag_acc: 0.3044
Step: 18296, loss: 3.068911, norm: 0.2923, time(ms): 800.30, token/sec:655111.31, hellaswag_acc: 0.3044
Step: 18297, loss: 3.074166, norm: 0.2785, time(ms): 800.07, token/sec:655304.97, hellaswag_acc: 0.3044
Step: 18298, loss: 3.022399, norm: 0.3009, time(ms): 800.52, token/sec:654931.61, hellaswag_acc: 0.3044
Step: 18299, loss: 3.054881, norm: 0.2943, time(ms): 798.92, token/sec:656245.61, hellaswag_acc: 0.3044
Step: 18300, loss: 3.047426, norm: 0.2973, time(ms): 802.20, token/sec:653566.72, hellaswag_acc: 0.3044
Step: 18301, loss: 3.083445, norm: 0.2742, time(ms): 797.88, token/sec:657100.98, hellaswag_acc: 0.3044
Step: 18302, loss: 3.020931, norm: 0.2853, time(ms): 794.66, token/sec:659761.47, hellaswag_acc: 0.3044
Step: 18303, loss: 3.078132, norm: 0.3012, time(ms): 800.89, token/sec:654633.50, hellaswag_acc: 0.3044
Step: 18304, loss: 3.090129, norm: 0.2695, time(ms): 798.04, token/sec:656972.20, hellaswag_acc: 0.3044
Step: 18305, loss: 3.028381, norm: 0.2848, time(ms): 795.31, token/sec:659225.68, hellaswag_acc: 0.3044
Step: 18306, loss: 2.988919, norm: 0.2798, time(ms): 792.59, token/sec:661483.92, hellaswag_acc: 0.3044
Step: 18307, loss: 3.060739, norm: 0.2911, time(ms): 794.91, token/sec:659553.30, hellaswag_acc: 0.3044
Step: 18308, loss: 3.002851, norm: 0.2852, time(ms): 800.71, token/sec:654776.18, hellaswag_acc: 0.3044
Step: 18309, loss: 2.825565, norm: 0.3580, time(ms): 798.70, token/sec:656429.16, hellaswag_acc: 0.3044
Step: 18310, loss: 2.834951, norm: 0.2982, time(ms): 795.92, token/sec:658721.33, hellaswag_acc: 0.3044
Step: 18311, loss: 2.910161, norm: 0.3901, time(ms): 788.73, token/sec:664727.80, hellaswag_acc: 0.3044
Step: 18312, loss: 2.866762, norm: 0.3183, time(ms): 789.94, token/sec:663709.21, hellaswag_acc: 0.3044
Step: 18313, loss: 2.827772, norm: 0.2915, time(ms): 794.57, token/sec:659838.88, hellaswag_acc: 0.3044
Step: 18314, loss: 2.896740, norm: 0.3355, time(ms): 792.16, token/sec:661849.65, hellaswag_acc: 0.3044
Step: 18315, loss: 2.848740, norm: 0.3047, time(ms): 796.56, token/sec:658186.83, hellaswag_acc: 0.3044
Step: 18316, loss: 2.834975, norm: 0.2960, time(ms): 806.71, token/sec:649911.00, hellaswag_acc: 0.3044
Step: 18317, loss: 2.848294, norm: 0.3114, time(ms): 800.45, token/sec:654988.96, hellaswag_acc: 0.3044
Step: 18318, loss: 2.920655, norm: 0.3005, time(ms): 791.32, token/sec:662552.57, hellaswag_acc: 0.3044
Step: 18319, loss: 2.826158, norm: 0.2808, time(ms): 802.35, token/sec:653441.84, hellaswag_acc: 0.3044
Step: 18320, loss: 3.026223, norm: 0.3083, time(ms): 805.31, token/sec:651039.49, hellaswag_acc: 0.3044
Step: 18321, loss: 3.045393, norm: 0.3245, time(ms): 799.57, token/sec:655715.90, hellaswag_acc: 0.3044
Step: 18322, loss: 3.155991, norm: 0.3411, time(ms): 790.11, token/sec:663562.21, hellaswag_acc: 0.3044
Step: 18323, loss: 3.063026, norm: 0.3381, time(ms): 791.09, token/sec:662743.47, hellaswag_acc: 0.3044
Step: 18324, loss: 3.151462, norm: 0.3489, time(ms): 787.65, token/sec:665633.85, hellaswag_acc: 0.3044
Step: 18325, loss: 3.054204, norm: 0.3158, time(ms): 791.62, token/sec:662300.94, hellaswag_acc: 0.3044
Step: 18326, loss: 3.054590, norm: 0.3002, time(ms): 798.20, token/sec:656834.83, hellaswag_acc: 0.3044
Step: 18327, loss: 3.045855, norm: 0.3033, time(ms): 794.00, token/sec:660316.38, hellaswag_acc: 0.3044
Step: 18328, loss: 3.116810, norm: 0.3300, time(ms): 800.25, token/sec:655157.56, hellaswag_acc: 0.3044
Step: 18329, loss: 3.159928, norm: 0.3175, time(ms): 802.23, token/sec:653537.58, hellaswag_acc: 0.3044
Step: 18330, loss: 3.071235, norm: 0.3166, time(ms): 794.70, token/sec:659729.01, hellaswag_acc: 0.3044
Step: 18331, loss: 3.083534, norm: 0.3090, time(ms): 792.65, token/sec:661439.95, hellaswag_acc: 0.3044
Step: 18332, loss: 3.052571, norm: 0.3161, time(ms): 794.13, token/sec:660203.58, hellaswag_acc: 0.3044
Step: 18333, loss: 3.101019, norm: 0.3066, time(ms): 798.40, token/sec:656672.23, hellaswag_acc: 0.3044
Step: 18334, loss: 3.089019, norm: 0.3008, time(ms): 799.97, token/sec:655383.09, hellaswag_acc: 0.3044
Step: 18335, loss: 3.096721, norm: 0.3268, time(ms): 794.62, token/sec:659794.14, hellaswag_acc: 0.3044
Step: 18336, loss: 3.113813, norm: 0.3009, time(ms): 791.99, token/sec:661992.11, hellaswag_acc: 0.3044
Step: 18337, loss: 3.117134, norm: 0.2851, time(ms): 787.82, token/sec:665490.22, hellaswag_acc: 0.3044
Step: 18338, loss: 3.095598, norm: 0.3120, time(ms): 794.79, token/sec:659652.62, hellaswag_acc: 0.3044
Step: 18339, loss: 3.129128, norm: 0.2991, time(ms): 792.11, token/sec:661886.70, hellaswag_acc: 0.3044
Step: 18340, loss: 3.155944, norm: 0.3080, time(ms): 795.05, token/sec:659438.19, hellaswag_acc: 0.3044
Step: 18341, loss: 3.096312, norm: 0.2846, time(ms): 804.54, token/sec:651661.50, hellaswag_acc: 0.3044
Step: 18342, loss: 3.126386, norm: 0.2953, time(ms): 797.51, token/sec:657403.89, hellaswag_acc: 0.3044
Step: 18343, loss: 3.099903, norm: 0.3353, time(ms): 798.70, token/sec:656428.58, hellaswag_acc: 0.3044
Step: 18344, loss: 3.017991, norm: 0.3189, time(ms): 802.37, token/sec:653421.84, hellaswag_acc: 0.3044
Step: 18345, loss: 3.061506, norm: 0.2972, time(ms): 800.96, token/sec:654576.41, hellaswag_acc: 0.3044
Step: 18346, loss: 3.021824, norm: 0.2951, time(ms): 795.62, token/sec:658965.11, hellaswag_acc: 0.3044
Step: 18347, loss: 3.080343, norm: 0.2837, time(ms): 801.19, token/sec:654389.41, hellaswag_acc: 0.3044
Step: 18348, loss: 2.996091, norm: 0.3000, time(ms): 802.37, token/sec:653425.92, hellaswag_acc: 0.3044
Step: 18349, loss: 3.087610, norm: 0.2942, time(ms): 797.09, token/sec:657751.35, hellaswag_acc: 0.3044
Step: 18350, loss: 3.049861, norm: 0.2703, time(ms): 801.08, token/sec:654473.74, hellaswag_acc: 0.3044
Step: 18351, loss: 3.045218, norm: 0.3038, time(ms): 801.90, token/sec:653807.28, hellaswag_acc: 0.3044
Step: 18352, loss: 3.011930, norm: 0.3590, time(ms): 794.71, token/sec:659722.48, hellaswag_acc: 0.3044
Step: 18353, loss: 3.038812, norm: 0.2812, time(ms): 800.42, token/sec:655013.54, hellaswag_acc: 0.3044
Step: 18354, loss: 3.046107, norm: 0.3022, time(ms): 802.83, token/sec:653048.88, hellaswag_acc: 0.3044
Step: 18355, loss: 2.886686, norm: 0.3377, time(ms): 800.12, token/sec:655264.94, hellaswag_acc: 0.3044
Step: 18356, loss: 2.890257, norm: 0.3004, time(ms): 785.92, token/sec:667098.63, hellaswag_acc: 0.3044
Step: 18357, loss: 2.886984, norm: 0.3262, time(ms): 807.05, token/sec:649632.99, hellaswag_acc: 0.3044
Step: 18358, loss: 2.859261, norm: 0.3264, time(ms): 789.39, token/sec:664166.05, hellaswag_acc: 0.3044
Step: 18359, loss: 2.865360, norm: 0.3208, time(ms): 790.06, token/sec:663602.46, hellaswag_acc: 0.3044
Step: 18360, loss: 2.871093, norm: 0.2822, time(ms): 794.35, token/sec:660018.11, hellaswag_acc: 0.3044
Step: 18361, loss: 2.876717, norm: 0.2956, time(ms): 793.82, token/sec:660463.14, hellaswag_acc: 0.3044
Step: 18362, loss: 2.855754, norm: 0.3037, time(ms): 793.04, token/sec:661115.22, hellaswag_acc: 0.3044
Step: 18363, loss: 2.885001, norm: 0.2737, time(ms): 806.43, token/sec:650132.92, hellaswag_acc: 0.3044
Step: 18364, loss: 2.885609, norm: 0.2955, time(ms): 797.29, token/sec:657584.36, hellaswag_acc: 0.3044
Step: 18365, loss: 2.836246, norm: 0.2946, time(ms): 792.34, token/sec:661698.69, hellaswag_acc: 0.3044
Step: 18366, loss: 2.920468, norm: 0.2878, time(ms): 793.64, token/sec:660612.74, hellaswag_acc: 0.3044
Step: 18367, loss: 3.080661, norm: 0.3593, time(ms): 795.15, token/sec:659360.09, hellaswag_acc: 0.3044
Step: 18368, loss: 3.081303, norm: 0.2910, time(ms): 794.74, token/sec:659698.93, hellaswag_acc: 0.3044
Step: 18369, loss: 3.113705, norm: 0.3303, time(ms): 801.30, token/sec:654294.59, hellaswag_acc: 0.3044
Step: 18370, loss: 3.093060, norm: 0.3304, time(ms): 805.49, token/sec:650890.34, hellaswag_acc: 0.3044
Step: 18371, loss: 3.093625, norm: 0.3289, time(ms): 790.10, token/sec:663570.02, hellaswag_acc: 0.3044
Step: 18372, loss: 3.070111, norm: 0.2766, time(ms): 792.43, token/sec:661624.03, hellaswag_acc: 0.3044
Step: 18373, loss: 3.109636, norm: 0.3011, time(ms): 789.92, token/sec:663720.03, hellaswag_acc: 0.3044
Step: 18374, loss: 3.123627, norm: 0.3085, time(ms): 796.23, token/sec:658461.56, hellaswag_acc: 0.3044
Step: 18375, loss: 3.109180, norm: 0.2945, time(ms): 790.66, token/sec:663099.19, hellaswag_acc: 0.3044
Step: 18376, loss: 3.049800, norm: 0.3015, time(ms): 788.74, token/sec:664716.95, hellaswag_acc: 0.3044
Step: 18377, loss: 3.097140, norm: 0.2853, time(ms): 795.63, token/sec:658960.97, hellaswag_acc: 0.3044
Step: 18378, loss: 3.095138, norm: 0.3096, time(ms): 795.18, token/sec:659331.03, hellaswag_acc: 0.3044
Step: 18379, loss: 3.079851, norm: 0.3134, time(ms): 789.30, token/sec:664240.48, hellaswag_acc: 0.3044
Step: 18380, loss: 3.091348, norm: 0.2984, time(ms): 793.45, token/sec:660773.73, hellaswag_acc: 0.3044
Step: 18381, loss: 3.098478, norm: 0.2923, time(ms): 790.21, token/sec:663476.12, hellaswag_acc: 0.3044
Step: 18382, loss: 3.062634, norm: 0.2855, time(ms): 801.52, token/sec:654118.45, hellaswag_acc: 0.3044
Step: 18383, loss: 3.042403, norm: 0.2869, time(ms): 801.24, token/sec:654346.76, hellaswag_acc: 0.3044
Step: 18384, loss: 3.116970, norm: 0.2890, time(ms): 798.03, token/sec:656978.09, hellaswag_acc: 0.3044
Step: 18385, loss: 3.124783, norm: 0.2774, time(ms): 796.22, token/sec:658475.17, hellaswag_acc: 0.3044
Step: 18386, loss: 3.085929, norm: 0.2818, time(ms): 803.74, token/sec:652312.36, hellaswag_acc: 0.3044
Step: 18387, loss: 3.090404, norm: 0.2867, time(ms): 800.44, token/sec:655003.79, hellaswag_acc: 0.3044
Step: 18388, loss: 3.060857, norm: 0.2694, time(ms): 796.82, token/sec:657978.07, hellaswag_acc: 0.3044
Step: 18389, loss: 3.057093, norm: 0.2805, time(ms): 801.04, token/sec:654508.41, hellaswag_acc: 0.3044
Step: 18390, loss: 3.019886, norm: 0.2798, time(ms): 1293.38, token/sec:405361.49, hellaswag_acc: 0.3044
Step: 18391, loss: 3.060756, norm: 0.2878, time(ms): 789.57, token/sec:664017.85, hellaswag_acc: 0.3044
Step: 18392, loss: 3.075584, norm: 0.2851, time(ms): 789.06, token/sec:664444.00, hellaswag_acc: 0.3044
Step: 18393, loss: 3.097907, norm: 0.2951, time(ms): 803.84, token/sec:652230.52, hellaswag_acc: 0.3044
Step: 18394, loss: 3.089078, norm: 0.2878, time(ms): 809.76, token/sec:647461.85, hellaswag_acc: 0.3044
Step: 18395, loss: 3.106801, norm: 0.2847, time(ms): 784.71, token/sec:668125.63, hellaswag_acc: 0.3044
Step: 18396, loss: 3.077366, norm: 0.2833, time(ms): 787.54, token/sec:665731.18, hellaswag_acc: 0.3044
Step: 18397, loss: 3.036190, norm: 0.2794, time(ms): 788.78, token/sec:664677.97, hellaswag_acc: 0.3044
Step: 18398, loss: 3.009361, norm: 0.3149, time(ms): 791.62, token/sec:662295.16, hellaswag_acc: 0.3044
Step: 18399, loss: 3.041022, norm: 0.2800, time(ms): 802.40, token/sec:653403.79, hellaswag_acc: 0.3044
Step: 18400, loss: 3.062185, norm: 0.2874, time(ms): 799.27, token/sec:655961.96, hellaswag_acc: 0.3044
Step: 18401, loss: 3.068631, norm: 0.3026, time(ms): 798.99, token/sec:656186.86, hellaswag_acc: 0.3044
Step: 18402, loss: 3.041634, norm: 0.2749, time(ms): 795.23, token/sec:659288.92, hellaswag_acc: 0.3044
Step: 18403, loss: 3.032598, norm: 0.2832, time(ms): 805.76, token/sec:650676.56, hellaswag_acc: 0.3044
Step: 18404, loss: 3.078899, norm: 0.3167, time(ms): 801.72, token/sec:653950.77, hellaswag_acc: 0.3044
Step: 18405, loss: 3.045362, norm: 0.2829, time(ms): 793.68, token/sec:660582.38, hellaswag_acc: 0.3044
Step: 18406, loss: 3.054511, norm: 0.2951, time(ms): 802.33, token/sec:653457.38, hellaswag_acc: 0.3044
Step: 18407, loss: 3.044086, norm: 0.2935, time(ms): 802.06, token/sec:653675.90, hellaswag_acc: 0.3044
Step: 18408, loss: 3.057932, norm: 0.3035, time(ms): 799.68, token/sec:655623.62, hellaswag_acc: 0.3044
Step: 18409, loss: 2.995926, norm: 0.2802, time(ms): 788.67, token/sec:664773.01, hellaswag_acc: 0.3044
Step: 18410, loss: 2.936480, norm: 0.3107, time(ms): 793.11, token/sec:661055.79, hellaswag_acc: 0.3044
Step: 18411, loss: 2.900822, norm: 0.3038, time(ms): 790.21, token/sec:663477.52, hellaswag_acc: 0.3044
Step: 18412, loss: 2.869404, norm: 0.2897, time(ms): 791.38, token/sec:662501.67, hellaswag_acc: 0.3044
Step: 18413, loss: 2.880147, norm: 0.3358, time(ms): 787.08, token/sec:666119.98, hellaswag_acc: 0.3044
Step: 18414, loss: 2.894884, norm: 0.3256, time(ms): 791.86, token/sec:662095.55, hellaswag_acc: 0.3044
Step: 18415, loss: 2.889878, norm: 0.3362, time(ms): 797.24, token/sec:657632.34, hellaswag_acc: 0.3044
Step: 18416, loss: 2.930162, norm: 0.3233, time(ms): 791.82, token/sec:662134.03, hellaswag_acc: 0.3044
Step: 18417, loss: 2.920686, norm: 0.2945, time(ms): 791.83, token/sec:662125.06, hellaswag_acc: 0.3044
Step: 18418, loss: 2.900397, norm: 0.3200, time(ms): 787.10, token/sec:666101.42, hellaswag_acc: 0.3044
Step: 18419, loss: 2.996053, norm: 0.2849, time(ms): 790.02, token/sec:663639.51, hellaswag_acc: 0.3044
Step: 18420, loss: 2.921625, norm: 0.3165, time(ms): 793.95, token/sec:660356.44, hellaswag_acc: 0.3044
Step: 18421, loss: 2.946697, norm: 0.2950, time(ms): 799.61, token/sec:655680.90, hellaswag_acc: 0.3044
Step: 18422, loss: 3.052305, norm: 0.3336, time(ms): 804.27, token/sec:651877.47, hellaswag_acc: 0.3044
Step: 18423, loss: 3.081414, norm: 0.3453, time(ms): 802.21, token/sec:653552.54, hellaswag_acc: 0.3044
Step: 18424, loss: 3.099943, norm: 0.3148, time(ms): 794.70, token/sec:659728.42, hellaswag_acc: 0.3044
Step: 18425, loss: 3.086702, norm: 0.3200, time(ms): 796.98, token/sec:657843.04, hellaswag_acc: 0.3044
Step: 18426, loss: 3.062555, norm: 0.3082, time(ms): 804.56, token/sec:651648.56, hellaswag_acc: 0.3044
Step: 18427, loss: 3.080103, norm: 0.2996, time(ms): 798.82, token/sec:656330.22, hellaswag_acc: 0.3044
Step: 18428, loss: 3.126724, norm: 0.3013, time(ms): 801.96, token/sec:653760.24, hellaswag_acc: 0.3044
Step: 18429, loss: 3.023577, norm: 0.2941, time(ms): 792.47, token/sec:661584.02, hellaswag_acc: 0.3044
Step: 18430, loss: 3.085014, norm: 0.2891, time(ms): 805.76, token/sec:650676.95, hellaswag_acc: 0.3044
Step: 18431, loss: 3.119537, norm: 0.3029, time(ms): 802.14, token/sec:653608.48, hellaswag_acc: 0.3044
Step: 18432, loss: 3.107607, norm: 0.3288, time(ms): 789.87, token/sec:663766.51, hellaswag_acc: 0.3044
Step: 18433, loss: 3.116322, norm: 0.2936, time(ms): 792.04, token/sec:661945.08, hellaswag_acc: 0.3044
Step: 18434, loss: 3.048510, norm: 0.3133, time(ms): 787.27, token/sec:665956.58, hellaswag_acc: 0.3044
Step: 18435, loss: 3.104634, norm: 0.3252, time(ms): 790.83, token/sec:662958.66, hellaswag_acc: 0.3044
Step: 18436, loss: 3.077985, norm: 0.3156, time(ms): 794.10, token/sec:660226.18, hellaswag_acc: 0.3044
Step: 18437, loss: 3.124379, norm: 0.2866, time(ms): 794.47, token/sec:659921.25, hellaswag_acc: 0.3044
Step: 18438, loss: 3.106763, norm: 0.3230, time(ms): 791.95, token/sec:662018.81, hellaswag_acc: 0.3044
Step: 18439, loss: 3.113524, norm: 0.3424, time(ms): 791.66, token/sec:662264.24, hellaswag_acc: 0.3044
Step: 18440, loss: 3.117326, norm: 0.3030, time(ms): 795.20, token/sec:659316.60, hellaswag_acc: 0.3044
Step: 18441, loss: 3.083950, norm: 0.3106, time(ms): 787.33, token/sec:665907.37, hellaswag_acc: 0.3044
Step: 18442, loss: 3.054394, norm: 0.3011, time(ms): 793.80, token/sec:660478.61, hellaswag_acc: 0.3044
Step: 18443, loss: 3.041454, norm: 0.2933, time(ms): 792.47, token/sec:661590.99, hellaswag_acc: 0.3044
Step: 18444, loss: 3.090829, norm: 0.2946, time(ms): 793.13, token/sec:661032.55, hellaswag_acc: 0.3044
Step: 18445, loss: 3.061354, norm: 0.2979, time(ms): 795.96, token/sec:658685.22, hellaswag_acc: 0.3044
Step: 18446, loss: 2.978221, norm: 0.2956, time(ms): 805.15, token/sec:651171.74, hellaswag_acc: 0.3044
Step: 18447, loss: 3.052280, norm: 0.3250, time(ms): 803.26, token/sec:652703.86, hellaswag_acc: 0.3044
Step: 18448, loss: 3.031019, norm: 0.3015, time(ms): 795.40, token/sec:659147.03, hellaswag_acc: 0.3044
Step: 18449, loss: 3.037444, norm: 0.2888, time(ms): 792.30, token/sec:661728.76, hellaswag_acc: 0.3044
Step: 18450, loss: 3.049147, norm: 0.2961, time(ms): 793.15, token/sec:661021.22, hellaswag_acc: 0.3044
Step: 18451, loss: 3.101561, norm: 0.3201, time(ms): 790.50, token/sec:663239.19, hellaswag_acc: 0.3044
Step: 18452, loss: 3.084913, norm: 0.2765, time(ms): 792.12, token/sec:661879.93, hellaswag_acc: 0.3044
Step: 18453, loss: 3.028676, norm: 0.2856, time(ms): 789.95, token/sec:663700.20, hellaswag_acc: 0.3044
Step: 18454, loss: 3.048891, norm: 0.3223, time(ms): 800.52, token/sec:654932.58, hellaswag_acc: 0.3044
Step: 18455, loss: 2.948018, norm: 0.2847, time(ms): 803.41, token/sec:652576.02, hellaswag_acc: 0.3044
Step: 18456, loss: 3.075064, norm: 0.3136, time(ms): 790.40, token/sec:663318.41, hellaswag_acc: 0.3044
Step: 18457, loss: 3.005410, norm: 0.3014, time(ms): 793.62, token/sec:660628.42, hellaswag_acc: 0.3044
Step: 18458, loss: 2.937096, norm: 0.3038, time(ms): 794.74, token/sec:659697.94, hellaswag_acc: 0.3044
Step: 18459, loss: 2.947950, norm: 0.3269, time(ms): 799.78, token/sec:655543.68, hellaswag_acc: 0.3044
Step: 18460, loss: 2.886973, norm: 0.3146, time(ms): 794.54, token/sec:659866.20, hellaswag_acc: 0.3044
Step: 18461, loss: 2.865955, norm: 0.2994, time(ms): 802.59, token/sec:653244.24, hellaswag_acc: 0.3044
Step: 18462, loss: 2.878815, norm: 0.3003, time(ms): 800.11, token/sec:655267.28, hellaswag_acc: 0.3044
Step: 18463, loss: 2.930566, norm: 0.3353, time(ms): 799.52, token/sec:655753.83, hellaswag_acc: 0.3044
Step: 18464, loss: 2.897478, norm: 0.2876, time(ms): 800.97, token/sec:654569.59, hellaswag_acc: 0.3044
Step: 18465, loss: 2.941005, norm: 0.3544, time(ms): 796.58, token/sec:658170.28, hellaswag_acc: 0.3044
Step: 18466, loss: 2.909229, norm: 0.3032, time(ms): 799.15, token/sec:656053.35, hellaswag_acc: 0.3044
Step: 18467, loss: 2.864641, norm: 0.3161, time(ms): 799.08, token/sec:656113.64, hellaswag_acc: 0.3044
Step: 18468, loss: 2.957039, norm: 0.2992, time(ms): 795.11, token/sec:659390.34, hellaswag_acc: 0.3044
Step: 18469, loss: 2.983435, norm: 0.3356, time(ms): 789.91, token/sec:663734.05, hellaswag_acc: 0.3044
Step: 18470, loss: 3.130774, norm: 0.3494, time(ms): 787.10, token/sec:666097.79, hellaswag_acc: 0.3044
Step: 18471, loss: 3.092039, norm: 0.3062, time(ms): 798.63, token/sec:656484.43, hellaswag_acc: 0.3044
Step: 18472, loss: 3.058327, norm: 0.3209, time(ms): 792.14, token/sec:661862.80, hellaswag_acc: 0.3044
Step: 18473, loss: 3.045732, norm: 0.3092, time(ms): 800.51, token/sec:654941.56, hellaswag_acc: 0.3044
Step: 18474, loss: 3.152544, norm: 0.3535, time(ms): 802.90, token/sec:652994.20, hellaswag_acc: 0.3044
Step: 18475, loss: 3.082837, norm: 0.2895, time(ms): 795.36, token/sec:659182.40, hellaswag_acc: 0.3044
Step: 18476, loss: 3.119300, norm: 0.3406, time(ms): 794.72, token/sec:659714.76, hellaswag_acc: 0.3044
Step: 18477, loss: 3.068202, norm: 0.3135, time(ms): 804.90, token/sec:651370.22, hellaswag_acc: 0.3044
Step: 18478, loss: 3.080816, norm: 0.3166, time(ms): 803.43, token/sec:652561.69, hellaswag_acc: 0.3044
Step: 18479, loss: 3.094270, norm: 0.3207, time(ms): 793.14, token/sec:661031.75, hellaswag_acc: 0.3044
Step: 18480, loss: 3.103074, norm: 0.3361, time(ms): 795.91, token/sec:658725.28, hellaswag_acc: 0.3044
Step: 18481, loss: 3.077816, norm: 0.3271, time(ms): 790.69, token/sec:663078.80, hellaswag_acc: 0.3044
Step: 18482, loss: 3.077894, norm: 0.3155, time(ms): 789.28, token/sec:664264.16, hellaswag_acc: 0.3044
Step: 18483, loss: 3.049168, norm: 0.3012, time(ms): 792.53, token/sec:661536.65, hellaswag_acc: 0.3044
Step: 18484, loss: 3.071624, norm: 0.3109, time(ms): 788.57, token/sec:664858.23, hellaswag_acc: 0.3044
Step: 18485, loss: 3.087310, norm: 0.3061, time(ms): 798.84, token/sec:656310.24, hellaswag_acc: 0.3044
Step: 18486, loss: 3.013957, norm: 0.2894, time(ms): 791.25, token/sec:662607.67, hellaswag_acc: 0.3044
Step: 18487, loss: 3.084336, norm: 0.2959, time(ms): 794.47, token/sec:659924.82, hellaswag_acc: 0.3044
Step: 18488, loss: 3.076563, norm: 0.3090, time(ms): 799.27, token/sec:655956.87, hellaswag_acc: 0.3044
Step: 18489, loss: 3.099012, norm: 0.2835, time(ms): 801.15, token/sec:654415.89, hellaswag_acc: 0.3044
Step: 18490, loss: 3.075498, norm: 0.2912, time(ms): 799.88, token/sec:655459.86, hellaswag_acc: 0.3044
Step: 18491, loss: 3.113262, norm: 0.3753, time(ms): 799.53, token/sec:655748.16, hellaswag_acc: 0.3044
Step: 18492, loss: 3.135316, norm: 0.2981, time(ms): 803.48, token/sec:652517.54, hellaswag_acc: 0.3044
Step: 18493, loss: 3.003820, norm: 0.3087, time(ms): 792.19, token/sec:661822.56, hellaswag_acc: 0.3044
Step: 18494, loss: 3.009643, norm: 0.3283, time(ms): 802.64, token/sec:653203.29, hellaswag_acc: 0.3044
Step: 18495, loss: 3.027611, norm: 0.3029, time(ms): 794.74, token/sec:659693.78, hellaswag_acc: 0.3044
Step: 18496, loss: 3.023555, norm: 0.3035, time(ms): 790.40, token/sec:663322.22, hellaswag_acc: 0.3044
Step: 18497, loss: 3.017204, norm: 0.2817, time(ms): 789.14, token/sec:664382.17, hellaswag_acc: 0.3044
Step: 18498, loss: 3.078376, norm: 0.2924, time(ms): 790.53, token/sec:663209.79, hellaswag_acc: 0.3044
Step: 18499, loss: 3.019902, norm: 0.3113, time(ms): 791.69, token/sec:662241.11, hellaswag_acc: 0.3044
rank 0 sample 0: Hello, I'm a language model, so I just need a basic introduction to get out of it. First, a little history of what it means to "
rank 0 sample 1: Hello, I'm a language model, I like to understand and I love trying to make good software, because for that, it's important to learn the language
rank 0 sample 2: Hello, I'm a language model, and I feel it's nice to be able to give you feedback about how well you are doing.
I think it
rank 0 sample 3: Hello, I'm a language model, I'd like to know what I understand, etc.
Hi, I have two friends that I wish I had some
rank 1 sample 0: Hello, I'm a language model, or model. I'm not a very advanced level person, what I'm telling you is that this is an appropriate language
rank 1 sample 1: Hello, I'm a language model, not an algorithm. I'm a mathematician, not a developer. I'm a futurist, not a computer scientist
rank 1 sample 2: Hello, I'm a language model, I always say: "I'm a language model, I speak it". What I'm doing is a model in a
rank 1 sample 3: Hello, I'm a language model, so I'm here for real-time prototyping. (Okay, it comes from GDI.)
Okay, so
Step: 18500, loss: 3.068836, norm: 0.2761, time(ms): 3829.61, token/sec:136903.75, val_loss: 3.0697, hellaswag_acc: 0.3044
Step: 18501, loss: 3.017465, norm: 0.2794, time(ms): 788.44, token/sec:664967.00, hellaswag_acc: 0.3044
Step: 18502, loss: 3.026282, norm: 0.2997, time(ms): 796.90, token/sec:657907.40, hellaswag_acc: 0.3044
Step: 18503, loss: 3.024706, norm: 0.2968, time(ms): 793.56, token/sec:660679.43, hellaswag_acc: 0.3044
Step: 18504, loss: 3.058760, norm: 0.3368, time(ms): 798.52, token/sec:656574.98, hellaswag_acc: 0.3044
Step: 18505, loss: 2.895317, norm: 0.3064, time(ms): 793.89, token/sec:660407.21, hellaswag_acc: 0.3044
Step: 18506, loss: 2.909320, norm: 0.2902, time(ms): 804.34, token/sec:651825.49, hellaswag_acc: 0.3044
Step: 18507, loss: 2.917376, norm: 0.3197, time(ms): 800.74, token/sec:654753.37, hellaswag_acc: 0.3044
Step: 18508, loss: 2.859957, norm: 0.2928, time(ms): 800.48, token/sec:654970.43, hellaswag_acc: 0.3044
Step: 18509, loss: 2.939934, norm: 0.2982, time(ms): 785.55, token/sec:667414.07, hellaswag_acc: 0.3044
Step: 18510, loss: 2.963706, norm: 0.3249, time(ms): 800.15, token/sec:655240.92, hellaswag_acc: 0.3044
Step: 18511, loss: 2.961554, norm: 0.2836, time(ms): 790.52, token/sec:663215.99, hellaswag_acc: 0.3044
Step: 18512, loss: 2.899254, norm: 0.3176, time(ms): 791.10, token/sec:662731.88, hellaswag_acc: 0.3044
Step: 18513, loss: 2.894725, norm: 0.3007, time(ms): 791.45, token/sec:662437.61, hellaswag_acc: 0.3044
Step: 18514, loss: 2.880356, norm: 0.2794, time(ms): 791.40, token/sec:662483.71, hellaswag_acc: 0.3044
Step: 18515, loss: 2.918916, norm: 0.2857, time(ms): 797.59, token/sec:657342.97, hellaswag_acc: 0.3044
Step: 18516, loss: 3.053226, norm: 0.3079, time(ms): 797.89, token/sec:657089.40, hellaswag_acc: 0.3044
Step: 18517, loss: 3.181892, norm: 0.3651, time(ms): 794.32, token/sec:660050.20, hellaswag_acc: 0.3044
Step: 18518, loss: 3.057909, norm: 0.3077, time(ms): 791.81, token/sec:662138.81, hellaswag_acc: 0.3044
Step: 18519, loss: 3.051381, norm: 0.3275, time(ms): 796.59, token/sec:658165.16, hellaswag_acc: 0.3044
Step: 18520, loss: 3.071514, norm: 0.3352, time(ms): 791.43, token/sec:662455.17, hellaswag_acc: 0.3044
Step: 18521, loss: 3.101959, norm: 0.3080, time(ms): 788.54, token/sec:664881.15, hellaswag_acc: 0.3044
Step: 18522, loss: 3.066510, norm: 0.3304, time(ms): 790.87, token/sec:662921.88, hellaswag_acc: 0.3044
Step: 18523, loss: 3.101892, norm: 0.3098, time(ms): 793.42, token/sec:660797.36, hellaswag_acc: 0.3044
Step: 18524, loss: 3.072974, norm: 0.3185, time(ms): 798.42, token/sec:656655.76, hellaswag_acc: 0.3044
Step: 18525, loss: 3.059127, norm: 0.3026, time(ms): 805.56, token/sec:650832.93, hellaswag_acc: 0.3044
Step: 18526, loss: 3.074250, norm: 0.2888, time(ms): 796.89, token/sec:657913.70, hellaswag_acc: 0.3044
Step: 18527, loss: 3.056042, norm: 0.3096, time(ms): 794.02, token/sec:660296.75, hellaswag_acc: 0.3044
Step: 18528, loss: 3.072245, norm: 0.2938, time(ms): 807.45, token/sec:649317.25, hellaswag_acc: 0.3044
Step: 18529, loss: 3.043477, norm: 0.2735, time(ms): 798.12, token/sec:656902.14, hellaswag_acc: 0.3044
Step: 18530, loss: 3.072918, norm: 0.2816, time(ms): 792.41, token/sec:661636.37, hellaswag_acc: 0.3044
Step: 18531, loss: 3.102548, norm: 0.2858, time(ms): 807.43, token/sec:649326.45, hellaswag_acc: 0.3044
Step: 18532, loss: 3.083903, norm: 0.3098, time(ms): 800.80, token/sec:654706.00, hellaswag_acc: 0.3044
Step: 18533, loss: 3.069959, norm: 0.3044, time(ms): 794.60, token/sec:659816.51, hellaswag_acc: 0.3044
Step: 18534, loss: 3.086336, norm: 0.3037, time(ms): 803.14, token/sec:652801.12, hellaswag_acc: 0.3044
Step: 18535, loss: 3.091045, norm: 0.2943, time(ms): 800.25, token/sec:655151.51, hellaswag_acc: 0.3044
Step: 18536, loss: 3.105417, norm: 0.2902, time(ms): 802.63, token/sec:653213.19, hellaswag_acc: 0.3044
Step: 18537, loss: 3.077741, norm: 0.2796, time(ms): 790.55, token/sec:663196.38, hellaswag_acc: 0.3044
Step: 18538, loss: 3.143546, norm: 0.3415, time(ms): 795.85, token/sec:658773.63, hellaswag_acc: 0.3044
Step: 18539, loss: 3.123918, norm: 0.3899, time(ms): 797.34, token/sec:657549.56, hellaswag_acc: 0.3044
Step: 18540, loss: 3.050002, norm: 0.3099, time(ms): 792.72, token/sec:661376.89, hellaswag_acc: 0.3044
Step: 18541, loss: 3.035670, norm: 0.3040, time(ms): 788.95, token/sec:664534.96, hellaswag_acc: 0.3044
Step: 18542, loss: 3.110729, norm: 0.3190, time(ms): 792.31, token/sec:661719.00, hellaswag_acc: 0.3044
Step: 18543, loss: 3.080482, norm: 0.2905, time(ms): 797.27, token/sec:657603.83, hellaswag_acc: 0.3044
Step: 18544, loss: 3.030520, norm: 0.2848, time(ms): 799.85, token/sec:655480.18, hellaswag_acc: 0.3044
Step: 18545, loss: 3.008959, norm: 0.2911, time(ms): 801.29, token/sec:654304.13, hellaswag_acc: 0.3044
Step: 18546, loss: 2.978815, norm: 0.2939, time(ms): 799.38, token/sec:655871.77, hellaswag_acc: 0.3044
Step: 18547, loss: 3.069673, norm: 0.2804, time(ms): 796.13, token/sec:658547.54, hellaswag_acc: 0.3044
Step: 18548, loss: 3.045202, norm: 0.2900, time(ms): 800.49, token/sec:654955.60, hellaswag_acc: 0.3044
Step: 18549, loss: 3.044526, norm: 0.2889, time(ms): 799.39, token/sec:655859.05, hellaswag_acc: 0.3044
Step: 18550, loss: 2.988132, norm: 0.2682, time(ms): 798.20, token/sec:656839.74, hellaswag_acc: 0.3044
Step: 18551, loss: 3.021627, norm: 0.2812, time(ms): 801.78, token/sec:653905.27, hellaswag_acc: 0.3044
Step: 18552, loss: 2.922791, norm: 0.3183, time(ms): 798.15, token/sec:656875.45, hellaswag_acc: 0.3044
Step: 18553, loss: 2.859846, norm: 0.2885, time(ms): 802.91, token/sec:652982.95, hellaswag_acc: 0.3044
Step: 18554, loss: 2.925932, norm: 0.2784, time(ms): 800.63, token/sec:654840.92, hellaswag_acc: 0.3044
Step: 18555, loss: 2.875916, norm: 0.3128, time(ms): 798.98, token/sec:656200.57, hellaswag_acc: 0.3044
Step: 18556, loss: 2.888325, norm: 0.2881, time(ms): 796.59, token/sec:658169.49, hellaswag_acc: 0.3044
Step: 18557, loss: 2.944034, norm: 0.2842, time(ms): 804.37, token/sec:651803.47, hellaswag_acc: 0.3044
Step: 18558, loss: 2.861984, norm: 0.2970, time(ms): 802.95, token/sec:652949.41, hellaswag_acc: 0.3044
Step: 18559, loss: 2.881110, norm: 0.2821, time(ms): 792.05, token/sec:661937.71, hellaswag_acc: 0.3044
Step: 18560, loss: 2.908577, norm: 0.2637, time(ms): 796.92, token/sec:657892.25, hellaswag_acc: 0.3044
Step: 18561, loss: 2.853782, norm: 0.2962, time(ms): 794.07, token/sec:660252.35, hellaswag_acc: 0.3044
Step: 18562, loss: 2.890615, norm: 0.2863, time(ms): 796.56, token/sec:658186.43, hellaswag_acc: 0.3044
Step: 18563, loss: 2.877334, norm: 0.2853, time(ms): 787.73, token/sec:665567.36, hellaswag_acc: 0.3044
Step: 18564, loss: 3.133404, norm: 0.3402, time(ms): 788.51, token/sec:664908.89, hellaswag_acc: 0.3044
Step: 18565, loss: 3.075592, norm: 0.3136, time(ms): 791.62, token/sec:662294.96, hellaswag_acc: 0.3044
Step: 18566, loss: 3.042696, norm: 0.3117, time(ms): 792.69, token/sec:661404.54, hellaswag_acc: 0.3044
Step: 18567, loss: 3.083371, norm: 0.3198, time(ms): 795.57, token/sec:659012.31, hellaswag_acc: 0.3044
Step: 18568, loss: 3.125652, norm: 0.3309, time(ms): 795.99, token/sec:658657.41, hellaswag_acc: 0.3044
Step: 18569, loss: 3.083388, norm: 0.2964, time(ms): 800.52, token/sec:654933.95, hellaswag_acc: 0.3044
Step: 18570, loss: 3.080004, norm: 0.3155, time(ms): 805.71, token/sec:650714.88, hellaswag_acc: 0.3044
Step: 18571, loss: 3.054116, norm: 0.3026, time(ms): 790.26, token/sec:663438.69, hellaswag_acc: 0.3044
Step: 18572, loss: 3.119773, norm: 0.3051, time(ms): 803.16, token/sec:652785.43, hellaswag_acc: 0.3044
Step: 18573, loss: 3.109261, norm: 0.2934, time(ms): 803.52, token/sec:652489.27, hellaswag_acc: 0.3044
Step: 18574, loss: 3.164052, norm: 0.3097, time(ms): 798.48, token/sec:656607.92, hellaswag_acc: 0.3044
Step: 18575, loss: 3.055786, norm: 0.3155, time(ms): 796.77, token/sec:658016.27, hellaswag_acc: 0.3044
Step: 18576, loss: 3.132419, norm: 0.3031, time(ms): 803.77, token/sec:652282.37, hellaswag_acc: 0.3044
Step: 18577, loss: 3.068838, norm: 0.2933, time(ms): 802.50, token/sec:653315.27, hellaswag_acc: 0.3044
Step: 18578, loss: 3.025335, norm: 0.2987, time(ms): 792.86, token/sec:661264.72, hellaswag_acc: 0.3044
Step: 18579, loss: 3.077158, norm: 0.3002, time(ms): 803.16, token/sec:652780.78, hellaswag_acc: 0.3044
Step: 18580, loss: 3.108072, norm: 0.2951, time(ms): 802.80, token/sec:653075.45, hellaswag_acc: 0.3044
Step: 18581, loss: 3.115367, norm: 0.2871, time(ms): 1440.48, token/sec:363966.85, hellaswag_acc: 0.3044
Step: 18582, loss: 3.065930, norm: 0.3000, time(ms): 798.34, token/sec:656724.00, hellaswag_acc: 0.3044
Step: 18583, loss: 3.077973, norm: 0.3052, time(ms): 794.87, token/sec:659593.26, hellaswag_acc: 0.3044
Step: 18584, loss: 3.080070, norm: 0.3150, time(ms): 787.95, token/sec:665380.48, hellaswag_acc: 0.3044
Step: 18585, loss: 3.042503, norm: 0.2840, time(ms): 785.53, token/sec:667431.50, hellaswag_acc: 0.3044
Step: 18586, loss: 3.042696, norm: 0.2845, time(ms): 794.20, token/sec:660147.49, hellaswag_acc: 0.3044
Step: 18587, loss: 3.221835, norm: 0.3588, time(ms): 795.95, token/sec:658697.26, hellaswag_acc: 0.3044
Step: 18588, loss: 3.018138, norm: 0.2936, time(ms): 791.91, token/sec:662052.89, hellaswag_acc: 0.3044
Step: 18589, loss: 3.048099, norm: 0.3114, time(ms): 795.78, token/sec:658833.43, hellaswag_acc: 0.3044
Step: 18590, loss: 3.027110, norm: 0.2915, time(ms): 792.90, token/sec:661232.31, hellaswag_acc: 0.3044
Step: 18591, loss: 3.071393, norm: 0.2882, time(ms): 791.62, token/sec:662297.55, hellaswag_acc: 0.3044
Step: 18592, loss: 3.028365, norm: 0.2986, time(ms): 792.00, token/sec:661977.96, hellaswag_acc: 0.3044
Step: 18593, loss: 3.026467, norm: 0.3160, time(ms): 790.94, token/sec:662868.73, hellaswag_acc: 0.3044
Step: 18594, loss: 3.111601, norm: 0.3644, time(ms): 802.24, token/sec:653529.62, hellaswag_acc: 0.3044
Step: 18595, loss: 3.073781, norm: 0.3274, time(ms): 800.23, token/sec:655169.47, hellaswag_acc: 0.3044
Step: 18596, loss: 2.996025, norm: 0.3094, time(ms): 793.72, token/sec:660541.70, hellaswag_acc: 0.3044
Step: 18597, loss: 3.100777, norm: 0.3027, time(ms): 793.83, token/sec:660449.85, hellaswag_acc: 0.3044
Step: 18598, loss: 3.069572, norm: 0.3036, time(ms): 802.50, token/sec:653318.76, hellaswag_acc: 0.3044
Step: 18599, loss: 3.073590, norm: 0.3108, time(ms): 787.12, token/sec:666082.65, hellaswag_acc: 0.3044
Step: 18600, loss: 3.070796, norm: 0.3162, time(ms): 801.57, token/sec:654079.15, hellaswag_acc: 0.3044
Step: 18601, loss: 3.059318, norm: 0.3034, time(ms): 800.27, token/sec:655142.14, hellaswag_acc: 0.3044
Step: 18602, loss: 3.044496, norm: 0.2977, time(ms): 799.89, token/sec:655450.68, hellaswag_acc: 0.3044
Step: 18603, loss: 3.064267, norm: 0.2888, time(ms): 792.86, token/sec:661260.34, hellaswag_acc: 0.3044
Step: 18604, loss: 3.101019, norm: 0.3086, time(ms): 789.45, token/sec:664117.51, hellaswag_acc: 0.3044
Step: 18605, loss: 3.110061, norm: 0.3159, time(ms): 791.24, token/sec:662615.86, hellaswag_acc: 0.3044
Step: 18606, loss: 3.110299, norm: 0.2963, time(ms): 788.32, token/sec:665067.76, hellaswag_acc: 0.3044
Step: 18607, loss: 3.195375, norm: 0.3414, time(ms): 788.94, token/sec:664544.39, hellaswag_acc: 0.3044
Step: 18608, loss: 3.088944, norm: 0.3102, time(ms): 790.95, token/sec:662854.74, hellaswag_acc: 0.3044
Step: 18609, loss: 3.123431, norm: 0.3063, time(ms): 789.26, token/sec:664276.80, hellaswag_acc: 0.3044
Step: 18610, loss: 3.089467, norm: 0.3169, time(ms): 791.79, token/sec:662151.37, hellaswag_acc: 0.3044
Step: 18611, loss: 3.197371, norm: 0.3493, time(ms): 790.58, token/sec:663170.78, hellaswag_acc: 0.3044
Step: 18612, loss: 3.079148, norm: 0.3089, time(ms): 802.26, token/sec:653510.97, hellaswag_acc: 0.3044
Step: 18613, loss: 3.122445, norm: 0.3043, time(ms): 801.39, token/sec:654221.01, hellaswag_acc: 0.3044
Step: 18614, loss: 3.129275, norm: 0.3134, time(ms): 803.47, token/sec:652531.09, hellaswag_acc: 0.3044
Step: 18615, loss: 3.157279, norm: 0.3212, time(ms): 790.72, token/sec:663053.41, hellaswag_acc: 0.3044
Step: 18616, loss: 3.091609, norm: 0.2850, time(ms): 797.74, token/sec:657220.19, hellaswag_acc: 0.3044
Step: 18617, loss: 3.114974, norm: 0.3191, time(ms): 801.20, token/sec:654378.11, hellaswag_acc: 0.3044
Step: 18618, loss: 3.024912, norm: 0.2888, time(ms): 791.76, token/sec:662181.28, hellaswag_acc: 0.3044
Step: 18619, loss: 3.015618, norm: 0.3197, time(ms): 788.03, token/sec:665313.64, hellaswag_acc: 0.3044
Step: 18620, loss: 3.067787, norm: 0.2989, time(ms): 799.21, token/sec:656011.47, hellaswag_acc: 0.3044
Step: 18621, loss: 3.117420, norm: 0.2926, time(ms): 789.99, token/sec:663663.94, hellaswag_acc: 0.3044
Step: 18622, loss: 3.081719, norm: 0.2904, time(ms): 790.71, token/sec:663058.21, hellaswag_acc: 0.3044
Step: 18623, loss: 3.059401, norm: 0.2882, time(ms): 791.58, token/sec:662327.08, hellaswag_acc: 0.3044
Step: 18624, loss: 3.054235, norm: 0.2786, time(ms): 791.77, token/sec:662175.30, hellaswag_acc: 0.3044
Step: 18625, loss: 3.112908, norm: 0.2819, time(ms): 802.15, token/sec:653599.74, hellaswag_acc: 0.3044
Step: 18626, loss: 3.080884, norm: 0.2939, time(ms): 801.84, token/sec:653856.47, hellaswag_acc: 0.3044
Step: 18627, loss: 3.054212, norm: 0.2868, time(ms): 793.60, token/sec:660645.49, hellaswag_acc: 0.3044
Step: 18628, loss: 3.135601, norm: 0.3098, time(ms): 798.77, token/sec:656367.64, hellaswag_acc: 0.3044
Step: 18629, loss: 3.078269, norm: 0.3083, time(ms): 805.52, token/sec:650872.23, hellaswag_acc: 0.3044
Step: 18630, loss: 3.022300, norm: 0.3026, time(ms): 802.97, token/sec:652938.36, hellaswag_acc: 0.3044
Step: 18631, loss: 3.037870, norm: 0.3251, time(ms): 788.71, token/sec:664743.47, hellaswag_acc: 0.3044
Step: 18632, loss: 3.090630, norm: 0.3219, time(ms): 792.41, token/sec:661640.36, hellaswag_acc: 0.3044
Step: 18633, loss: 3.152436, norm: 0.3185, time(ms): 788.18, token/sec:665190.88, hellaswag_acc: 0.3044
Step: 18634, loss: 3.060108, norm: 0.3118, time(ms): 790.31, token/sec:663391.85, hellaswag_acc: 0.3044
Step: 18635, loss: 3.007735, norm: 0.3155, time(ms): 796.36, token/sec:658353.34, hellaswag_acc: 0.3044
Step: 18636, loss: 3.066150, norm: 0.3170, time(ms): 798.91, token/sec:656255.60, hellaswag_acc: 0.3044
Step: 18637, loss: 3.074624, norm: 0.3103, time(ms): 797.14, token/sec:657712.00, hellaswag_acc: 0.3044
Step: 18638, loss: 3.054227, norm: 0.3071, time(ms): 804.25, token/sec:651894.67, hellaswag_acc: 0.3044
Step: 18639, loss: 3.076421, norm: 0.3254, time(ms): 797.93, token/sec:657057.39, hellaswag_acc: 0.3044
Step: 18640, loss: 3.082334, norm: 0.3128, time(ms): 794.32, token/sec:660048.82, hellaswag_acc: 0.3044
Step: 18641, loss: 3.155730, norm: 0.3122, time(ms): 802.62, token/sec:653224.25, hellaswag_acc: 0.3044
Step: 18642, loss: 3.056192, norm: 0.3024, time(ms): 803.27, token/sec:652695.91, hellaswag_acc: 0.3044
Step: 18643, loss: 3.141181, norm: 0.3013, time(ms): 797.28, token/sec:657593.60, hellaswag_acc: 0.3044
Step: 18644, loss: 3.157853, norm: 0.3074, time(ms): 801.82, token/sec:653868.52, hellaswag_acc: 0.3044
Step: 18645, loss: 3.160624, norm: 0.3146, time(ms): 801.57, token/sec:654077.79, hellaswag_acc: 0.3044
Step: 18646, loss: 3.102631, norm: 0.3123, time(ms): 800.90, token/sec:654620.06, hellaswag_acc: 0.3044
Step: 18647, loss: 3.109397, norm: 0.3042, time(ms): 793.41, token/sec:660803.91, hellaswag_acc: 0.3044
Step: 18648, loss: 3.097666, norm: 0.3009, time(ms): 803.88, token/sec:652195.12, hellaswag_acc: 0.3044
Step: 18649, loss: 3.181186, norm: 0.3125, time(ms): 801.39, token/sec:654221.01, hellaswag_acc: 0.3044
Step: 18650, loss: 3.081595, norm: 0.2963, time(ms): 792.20, token/sec:661812.60, hellaswag_acc: 0.3044
Step: 18651, loss: 3.070515, norm: 0.3127, time(ms): 792.37, token/sec:661673.01, hellaswag_acc: 0.3044
Step: 18652, loss: 3.069613, norm: 0.2774, time(ms): 794.08, token/sec:660245.21, hellaswag_acc: 0.3044
Step: 18653, loss: 3.060318, norm: 0.2981, time(ms): 801.81, token/sec:653876.69, hellaswag_acc: 0.3044
Step: 18654, loss: 3.082741, norm: 0.2973, time(ms): 791.27, token/sec:662594.10, hellaswag_acc: 0.3044
Step: 18655, loss: 3.065741, norm: 0.2849, time(ms): 792.34, token/sec:661698.69, hellaswag_acc: 0.3044
Step: 18656, loss: 3.114152, norm: 0.2866, time(ms): 784.71, token/sec:668132.12, hellaswag_acc: 0.3044
Step: 18657, loss: 3.046271, norm: 0.3017, time(ms): 794.12, token/sec:660213.49, hellaswag_acc: 0.3044
Step: 18658, loss: 3.078515, norm: 0.3081, time(ms): 795.89, token/sec:658747.18, hellaswag_acc: 0.3044
Step: 18659, loss: 3.092783, norm: 0.2993, time(ms): 792.73, token/sec:661367.94, hellaswag_acc: 0.3044
Step: 18660, loss: 2.963132, norm: 0.2838, time(ms): 805.44, token/sec:650933.89, hellaswag_acc: 0.3044
Step: 18661, loss: 3.091297, norm: 0.2830, time(ms): 800.72, token/sec:654771.70, hellaswag_acc: 0.3044
Step: 18662, loss: 3.061957, norm: 0.3647, time(ms): 800.57, token/sec:654893.96, hellaswag_acc: 0.3044
Step: 18663, loss: 3.047887, norm: 0.2927, time(ms): 791.16, token/sec:662682.75, hellaswag_acc: 0.3044
Step: 18664, loss: 3.074049, norm: 0.3164, time(ms): 804.83, token/sec:651429.26, hellaswag_acc: 0.3044
Step: 18665, loss: 3.114403, norm: 0.2909, time(ms): 802.30, token/sec:653482.04, hellaswag_acc: 0.3044
Step: 18666, loss: 3.100023, norm: 0.3000, time(ms): 803.44, token/sec:652550.46, hellaswag_acc: 0.3044
Step: 18667, loss: 3.070153, norm: 0.3199, time(ms): 782.06, token/sec:670391.41, hellaswag_acc: 0.3044
Step: 18668, loss: 3.033635, norm: 0.2802, time(ms): 793.74, token/sec:660531.58, hellaswag_acc: 0.3044
Step: 18669, loss: 3.052719, norm: 0.2898, time(ms): 792.64, token/sec:661447.11, hellaswag_acc: 0.3044
Step: 18670, loss: 3.111864, norm: 0.2995, time(ms): 792.18, token/sec:661827.14, hellaswag_acc: 0.3044
Step: 18671, loss: 3.080787, norm: 0.2879, time(ms): 788.18, token/sec:665192.08, hellaswag_acc: 0.3044
Step: 18672, loss: 3.109706, norm: 0.3054, time(ms): 800.12, token/sec:655259.27, hellaswag_acc: 0.3044
Step: 18673, loss: 3.093588, norm: 0.2919, time(ms): 800.21, token/sec:655188.99, hellaswag_acc: 0.3044
Step: 18674, loss: 3.094193, norm: 0.3663, time(ms): 792.50, token/sec:661561.93, hellaswag_acc: 0.3044
Step: 18675, loss: 3.032361, norm: 0.3002, time(ms): 790.57, token/sec:663173.38, hellaswag_acc: 0.3044
Step: 18676, loss: 3.063071, norm: 0.3002, time(ms): 798.50, token/sec:656593.02, hellaswag_acc: 0.3044
Step: 18677, loss: 3.102860, norm: 0.2903, time(ms): 803.44, token/sec:652557.04, hellaswag_acc: 0.3044
Step: 18678, loss: 3.128374, norm: 0.3122, time(ms): 800.51, token/sec:654941.36, hellaswag_acc: 0.3044
Step: 18679, loss: 3.123817, norm: 0.2913, time(ms): 792.32, token/sec:661713.03, hellaswag_acc: 0.3044
Step: 18680, loss: 3.072983, norm: 0.2854, time(ms): 798.50, token/sec:656592.43, hellaswag_acc: 0.3044
Step: 18681, loss: 3.122751, norm: 0.2906, time(ms): 787.37, token/sec:665871.68, hellaswag_acc: 0.3044
Step: 18682, loss: 3.125453, norm: 0.3061, time(ms): 790.57, token/sec:663176.38, hellaswag_acc: 0.3044
Step: 18683, loss: 3.321171, norm: 0.3750, time(ms): 795.23, token/sec:659289.51, hellaswag_acc: 0.3044
Step: 18684, loss: 3.070084, norm: 0.3171, time(ms): 791.00, token/sec:662813.38, hellaswag_acc: 0.3044
Step: 18685, loss: 3.182090, norm: 0.3180, time(ms): 803.49, token/sec:652512.31, hellaswag_acc: 0.3044
Step: 18686, loss: 3.082591, norm: 0.3030, time(ms): 802.50, token/sec:653319.93, hellaswag_acc: 0.3044
Step: 18687, loss: 3.016661, norm: 0.2798, time(ms): 792.86, token/sec:661259.35, hellaswag_acc: 0.3044
Step: 18688, loss: 3.051624, norm: 0.3178, time(ms): 799.94, token/sec:655409.46, hellaswag_acc: 0.3044
Step: 18689, loss: 3.040357, norm: 0.2793, time(ms): 802.90, token/sec:652992.45, hellaswag_acc: 0.3044
Step: 18690, loss: 3.082775, norm: 0.2915, time(ms): 804.00, token/sec:652098.81, hellaswag_acc: 0.3044
Step: 18691, loss: 3.049535, norm: 0.2775, time(ms): 789.54, token/sec:664043.11, hellaswag_acc: 0.3044
Step: 18692, loss: 3.043436, norm: 0.2828, time(ms): 800.10, token/sec:655279.38, hellaswag_acc: 0.3044
Step: 18693, loss: 3.048525, norm: 0.2764, time(ms): 807.92, token/sec:648937.09, hellaswag_acc: 0.3044
Step: 18694, loss: 3.041565, norm: 0.2891, time(ms): 799.39, token/sec:655861.99, hellaswag_acc: 0.3044
Step: 18695, loss: 3.046368, norm: 0.2860, time(ms): 790.67, token/sec:663094.99, hellaswag_acc: 0.3044
Step: 18696, loss: 3.089953, norm: 0.2784, time(ms): 791.83, token/sec:662119.87, hellaswag_acc: 0.3044
Step: 18697, loss: 3.059324, norm: 0.3223, time(ms): 793.48, token/sec:660746.53, hellaswag_acc: 0.3044
Step: 18698, loss: 3.119136, norm: 0.3232, time(ms): 794.62, token/sec:659796.12, hellaswag_acc: 0.3044
Step: 18699, loss: 3.133487, norm: 0.3135, time(ms): 789.83, token/sec:663798.56, hellaswag_acc: 0.3044
Step: 18700, loss: 3.057156, norm: 0.3076, time(ms): 790.85, token/sec:662940.87, hellaswag_acc: 0.3044
Step: 18701, loss: 3.083288, norm: 0.3000, time(ms): 797.36, token/sec:657528.91, hellaswag_acc: 0.3044
Step: 18702, loss: 3.145733, norm: 0.3089, time(ms): 796.44, token/sec:658293.03, hellaswag_acc: 0.3044
Step: 18703, loss: 3.125428, norm: 0.3181, time(ms): 790.51, token/sec:663226.59, hellaswag_acc: 0.3044
Step: 18704, loss: 3.032961, norm: 0.2887, time(ms): 798.15, token/sec:656878.79, hellaswag_acc: 0.3044
Step: 18705, loss: 3.066394, norm: 0.3009, time(ms): 802.10, token/sec:653643.45, hellaswag_acc: 0.3044
Step: 18706, loss: 3.021314, norm: 0.2906, time(ms): 803.48, token/sec:652522.19, hellaswag_acc: 0.3044
Step: 18707, loss: 3.064762, norm: 0.3053, time(ms): 797.04, token/sec:657791.88, hellaswag_acc: 0.3044
Step: 18708, loss: 3.071603, norm: 0.3116, time(ms): 799.58, token/sec:655705.53, hellaswag_acc: 0.3044
Step: 18709, loss: 3.154390, norm: 0.3249, time(ms): 799.00, token/sec:656182.16, hellaswag_acc: 0.3044
Step: 18710, loss: 3.088717, norm: 0.2817, time(ms): 801.65, token/sec:654013.20, hellaswag_acc: 0.3044
Step: 18711, loss: 3.074215, norm: 0.3304, time(ms): 798.48, token/sec:656611.64, hellaswag_acc: 0.3044
Step: 18712, loss: 3.111735, norm: 0.2912, time(ms): 799.32, token/sec:655915.39, hellaswag_acc: 0.3044
Step: 18713, loss: 3.078115, norm: 0.2808, time(ms): 801.68, token/sec:653985.97, hellaswag_acc: 0.3044
Step: 18714, loss: 3.147077, norm: 0.3006, time(ms): 799.35, token/sec:655890.55, hellaswag_acc: 0.3044
Step: 18715, loss: 3.101295, norm: 0.2878, time(ms): 793.00, token/sec:661141.85, hellaswag_acc: 0.3044
Step: 18716, loss: 3.109521, norm: 0.2945, time(ms): 790.93, token/sec:662871.73, hellaswag_acc: 0.3044
Step: 18717, loss: 3.089453, norm: 0.2838, time(ms): 788.10, token/sec:665256.08, hellaswag_acc: 0.3044
Step: 18718, loss: 3.207095, norm: 0.3142, time(ms): 794.11, token/sec:660220.63, hellaswag_acc: 0.3044
Step: 18719, loss: 3.092190, norm: 0.2907, time(ms): 791.42, token/sec:662463.95, hellaswag_acc: 0.3044
Step: 18720, loss: 3.057529, norm: 0.2964, time(ms): 798.26, token/sec:656784.42, hellaswag_acc: 0.3044
Step: 18721, loss: 3.049691, norm: 0.3152, time(ms): 803.27, token/sec:652690.29, hellaswag_acc: 0.3044
Step: 18722, loss: 3.049363, norm: 0.2778, time(ms): 802.50, token/sec:653318.18, hellaswag_acc: 0.3044
Step: 18723, loss: 3.033036, norm: 0.2920, time(ms): 787.30, token/sec:665932.18, hellaswag_acc: 0.3044
Step: 18724, loss: 3.014304, norm: 0.5034, time(ms): 795.02, token/sec:659462.32, hellaswag_acc: 0.3044
Step: 18725, loss: 3.124664, norm: 0.3304, time(ms): 788.96, token/sec:664528.93, hellaswag_acc: 0.3044
Step: 18726, loss: 3.027997, norm: 0.3313, time(ms): 792.41, token/sec:661638.37, hellaswag_acc: 0.3044
Step: 18727, loss: 3.081599, norm: 0.2905, time(ms): 790.41, token/sec:663308.21, hellaswag_acc: 0.3044
Step: 18728, loss: 3.047004, norm: 0.2972, time(ms): 796.14, token/sec:658539.45, hellaswag_acc: 0.3044
Step: 18729, loss: 3.110402, norm: 0.3251, time(ms): 802.76, token/sec:653107.07, hellaswag_acc: 0.3044
Step: 18730, loss: 3.042479, norm: 0.3130, time(ms): 801.16, token/sec:654411.80, hellaswag_acc: 0.3044
Step: 18731, loss: 3.134228, norm: 0.3307, time(ms): 798.11, token/sec:656912.54, hellaswag_acc: 0.3044
Step: 18732, loss: 3.081992, norm: 0.3688, time(ms): 797.61, token/sec:657324.50, hellaswag_acc: 0.3044
Step: 18733, loss: 3.061575, norm: 0.3230, time(ms): 803.39, token/sec:652594.22, hellaswag_acc: 0.3044
Step: 18734, loss: 3.038213, norm: 0.3404, time(ms): 802.40, token/sec:653401.07, hellaswag_acc: 0.3044
Step: 18735, loss: 3.039290, norm: 0.3290, time(ms): 800.01, token/sec:655353.01, hellaswag_acc: 0.3044
Step: 18736, loss: 3.107889, norm: 0.3104, time(ms): 791.45, token/sec:662437.01, hellaswag_acc: 0.3044
Step: 18737, loss: 3.060899, norm: 0.2915, time(ms): 793.50, token/sec:660732.04, hellaswag_acc: 0.3044
Step: 18738, loss: 3.039299, norm: 0.3122, time(ms): 795.89, token/sec:658743.83, hellaswag_acc: 0.3044
Step: 18739, loss: 3.084091, norm: 0.3159, time(ms): 792.33, token/sec:661708.25, hellaswag_acc: 0.3044
Step: 18740, loss: 3.083493, norm: 0.3131, time(ms): 802.20, token/sec:653561.86, hellaswag_acc: 0.3044
Step: 18741, loss: 3.119731, norm: 0.3269, time(ms): 802.30, token/sec:653481.26, hellaswag_acc: 0.3044
Step: 18742, loss: 3.069542, norm: 0.3031, time(ms): 800.14, token/sec:655243.65, hellaswag_acc: 0.3044
Step: 18743, loss: 3.108300, norm: 0.3185, time(ms): 798.90, token/sec:656263.24, hellaswag_acc: 0.3044
Step: 18744, loss: 3.207437, norm: 0.3081, time(ms): 798.77, token/sec:656371.36, hellaswag_acc: 0.3044
Step: 18745, loss: 3.085172, norm: 0.3114, time(ms): 800.75, token/sec:654743.63, hellaswag_acc: 0.3044
Step: 18746, loss: 3.108593, norm: 0.2882, time(ms): 801.34, token/sec:654264.61, hellaswag_acc: 0.3044
Step: 18747, loss: 3.133830, norm: 0.2950, time(ms): 797.91, token/sec:657072.51, hellaswag_acc: 0.3044
Step: 18748, loss: 3.127713, norm: 0.2814, time(ms): 802.62, token/sec:653224.64, hellaswag_acc: 0.3044
Step: 18749, loss: 3.160812, norm: 0.2932, time(ms): 795.46, token/sec:659102.97, hellaswag_acc: 0.3044
rank 0 sample 0: Hello, I'm a language model, so I just need a set of objects! :)
Thank you... if it's my project we can have a great
rank 0 sample 1: Hello, I'm a language model, and when I go out and talk, I get it from a very distant country, but if you've never heard of
rank 0 sample 2: Hello, I'm a language model, and I would be doing math a year later for the same class that I'm studying for.
I'm not familiar
rank 0 sample 3: Hello, I'm a language model, and how do I get a good start in reading Spanish?
How do we define an open sentence?
The closed
rank 1 sample 0: Hello, I'm a language model, as well. I'm not a social psychologist I've met before, but I'm an education and social psychology professor at
rank 1 sample 1: Hello, I'm a language model, not an expert in the field. If you're new let me know.
Terence Wright died in 2010.

rank 1 sample 2: Hello, I'm a language model, I did it myself, and I'm a language model myself now! :)
I'm an IT guy and the project
rank 1 sample 3: Hello, I'm a language model, so I'm interested to develop a program how to learn java language java - part 1(the) java language tutorial -
Step: 18750, loss: 3.118193, norm: 0.3096, time(ms): 3831.48, token/sec:136837.08, val_loss: 3.0682, hellaswag_acc: 0.3044
Step: 18751, loss: 3.085310, norm: 0.2951, time(ms): 798.16, token/sec:656874.86, hellaswag_acc: 0.3044
Step: 18752, loss: 3.090398, norm: 0.2811, time(ms): 788.83, token/sec:664641.21, hellaswag_acc: 0.3044
Step: 18753, loss: 3.125168, norm: 0.3046, time(ms): 803.64, token/sec:652388.61, hellaswag_acc: 0.3044
Step: 18754, loss: 3.082631, norm: 0.2838, time(ms): 802.56, token/sec:653268.49, hellaswag_acc: 0.3044
Step: 18755, loss: 3.053222, norm: 0.2931, time(ms): 794.31, token/sec:660056.34, hellaswag_acc: 0.3044
Step: 18756, loss: 3.072507, norm: 0.2704, time(ms): 800.24, token/sec:655164.59, hellaswag_acc: 0.3044
Step: 18757, loss: 3.129133, norm: 0.2963, time(ms): 803.67, token/sec:652366.74, hellaswag_acc: 0.3044
Step: 18758, loss: 3.041450, norm: 0.2944, time(ms): 799.15, token/sec:656056.29, hellaswag_acc: 0.3044
Step: 18759, loss: 3.083952, norm: 0.2793, time(ms): 798.10, token/sec:656922.74, hellaswag_acc: 0.3044
Step: 18760, loss: 3.117260, norm: 0.3233, time(ms): 794.06, token/sec:660259.28, hellaswag_acc: 0.3044
Step: 18761, loss: 3.099996, norm: 0.2810, time(ms): 801.70, token/sec:653970.80, hellaswag_acc: 0.3044
Step: 18762, loss: 3.021394, norm: 0.3007, time(ms): 803.98, token/sec:652113.51, hellaswag_acc: 0.3044
Step: 18763, loss: 3.018970, norm: 0.2863, time(ms): 801.26, token/sec:654329.24, hellaswag_acc: 0.3044
Step: 18764, loss: 3.001135, norm: 0.2778, time(ms): 791.17, token/sec:662673.37, hellaswag_acc: 0.3044
Step: 18765, loss: 3.068366, norm: 0.2763, time(ms): 791.52, token/sec:662378.75, hellaswag_acc: 0.3044
Step: 18766, loss: 3.047502, norm: 0.2946, time(ms): 796.95, token/sec:657865.87, hellaswag_acc: 0.3044
Step: 18767, loss: 3.101010, norm: 0.2912, time(ms): 793.93, token/sec:660368.93, hellaswag_acc: 0.3044
Step: 18768, loss: 3.095356, norm: 0.2804, time(ms): 801.53, token/sec:654109.89, hellaswag_acc: 0.3044
Step: 18769, loss: 3.116373, norm: 0.2911, time(ms): 793.36, token/sec:660842.44, hellaswag_acc: 0.3044
Step: 18770, loss: 3.038117, norm: 0.2826, time(ms): 787.28, token/sec:665946.50, hellaswag_acc: 0.3044
Step: 18771, loss: 3.129391, norm: 0.2854, time(ms): 1042.27, token/sec:503027.11, hellaswag_acc: 0.3044
Step: 18772, loss: 3.106226, norm: 0.2951, time(ms): 784.54, token/sec:668273.85, hellaswag_acc: 0.3044
Step: 18773, loss: 3.035901, norm: 0.2741, time(ms): 782.11, token/sec:670346.86, hellaswag_acc: 0.3044
Step: 18774, loss: 3.039581, norm: 0.2828, time(ms): 791.74, token/sec:662197.43, hellaswag_acc: 0.3044
Step: 18775, loss: 3.071287, norm: 0.2912, time(ms): 793.78, token/sec:660497.86, hellaswag_acc: 0.3044
Step: 18776, loss: 2.980381, norm: 0.2995, time(ms): 790.09, token/sec:663583.83, hellaswag_acc: 0.3044
Step: 18777, loss: 3.039609, norm: 0.2926, time(ms): 783.09, token/sec:669510.48, hellaswag_acc: 0.3044
Step: 18778, loss: 3.091846, norm: 0.2882, time(ms): 789.96, token/sec:663690.18, hellaswag_acc: 0.3044
Step: 18779, loss: 3.103536, norm: 0.3099, time(ms): 795.61, token/sec:658976.17, hellaswag_acc: 0.3044
Step: 18780, loss: 3.022226, norm: 0.2840, time(ms): 793.87, token/sec:660423.67, hellaswag_acc: 0.3044
Step: 18781, loss: 3.080881, norm: 0.2977, time(ms): 790.87, token/sec:662929.68, hellaswag_acc: 0.3044
Step: 18782, loss: 3.025996, norm: 0.2873, time(ms): 796.76, token/sec:658024.93, hellaswag_acc: 0.3044
Step: 18783, loss: 3.018585, norm: 0.2989, time(ms): 801.16, token/sec:654408.88, hellaswag_acc: 0.3044
Step: 18784, loss: 3.134079, norm: 0.3057, time(ms): 798.29, token/sec:656763.04, hellaswag_acc: 0.3044
Step: 18785, loss: 3.058251, norm: 0.2932, time(ms): 793.42, token/sec:660792.00, hellaswag_acc: 0.3044
Step: 18786, loss: 3.053248, norm: 0.2990, time(ms): 793.77, token/sec:660506.19, hellaswag_acc: 0.3044
Step: 18787, loss: 3.073672, norm: 0.2857, time(ms): 799.70, token/sec:655608.38, hellaswag_acc: 0.3044
Step: 18788, loss: 3.046903, norm: 0.2960, time(ms): 797.01, token/sec:657819.23, hellaswag_acc: 0.3044
Step: 18789, loss: 3.045612, norm: 0.2966, time(ms): 798.66, token/sec:656458.75, hellaswag_acc: 0.3044
Step: 18790, loss: 3.108550, norm: 0.2961, time(ms): 799.36, token/sec:655881.16, hellaswag_acc: 0.3044
Step: 18791, loss: 3.054441, norm: 0.2865, time(ms): 804.01, token/sec:652089.72, hellaswag_acc: 0.3044
Step: 18792, loss: 3.124318, norm: 0.3003, time(ms): 797.35, token/sec:657536.58, hellaswag_acc: 0.3044
Step: 18793, loss: 3.045014, norm: 0.2972, time(ms): 797.51, token/sec:657404.68, hellaswag_acc: 0.3044
Step: 18794, loss: 3.180790, norm: 0.3202, time(ms): 797.42, token/sec:657483.50, hellaswag_acc: 0.3044
Step: 18795, loss: 3.024297, norm: 0.3118, time(ms): 791.61, token/sec:662305.13, hellaswag_acc: 0.3044
Step: 18796, loss: 3.010730, norm: 0.2861, time(ms): 785.52, token/sec:667439.19, hellaswag_acc: 0.3044
Step: 18797, loss: 3.030711, norm: 0.2812, time(ms): 792.51, token/sec:661551.18, hellaswag_acc: 0.3044
Step: 18798, loss: 3.040154, norm: 0.3165, time(ms): 794.82, token/sec:659635.21, hellaswag_acc: 0.3044
Step: 18799, loss: 3.029689, norm: 0.2820, time(ms): 802.34, token/sec:653450.58, hellaswag_acc: 0.3044
Step: 18800, loss: 3.030898, norm: 0.2945, time(ms): 798.23, token/sec:656809.72, hellaswag_acc: 0.3044
Step: 18801, loss: 3.063219, norm: 0.2991, time(ms): 790.50, token/sec:663232.79, hellaswag_acc: 0.3044
Step: 18802, loss: 3.065831, norm: 0.2772, time(ms): 795.39, token/sec:659162.05, hellaswag_acc: 0.3044
Step: 18803, loss: 3.030164, norm: 0.2737, time(ms): 788.11, token/sec:665243.40, hellaswag_acc: 0.3044
Step: 18804, loss: 3.069442, norm: 0.2933, time(ms): 788.93, token/sec:664554.44, hellaswag_acc: 0.3044
Step: 18805, loss: 3.138198, norm: 0.3269, time(ms): 787.56, token/sec:665711.02, hellaswag_acc: 0.3044
Step: 18806, loss: 3.026991, norm: 0.2848, time(ms): 790.95, token/sec:662859.34, hellaswag_acc: 0.3044
Step: 18807, loss: 3.068445, norm: 0.3230, time(ms): 798.81, token/sec:656332.97, hellaswag_acc: 0.3044
Step: 18808, loss: 3.052191, norm: 0.3126, time(ms): 786.32, token/sec:666762.46, hellaswag_acc: 0.3044
Step: 18809, loss: 3.056438, norm: 0.3142, time(ms): 790.46, token/sec:663266.00, hellaswag_acc: 0.3044
Step: 18810, loss: 2.977191, norm: 0.3947, time(ms): 793.17, token/sec:660999.16, hellaswag_acc: 0.3044
Step: 18811, loss: 3.157531, norm: 0.3515, time(ms): 791.87, token/sec:662088.77, hellaswag_acc: 0.3044
Step: 18812, loss: 3.047013, norm: 0.3703, time(ms): 791.89, token/sec:662075.42, hellaswag_acc: 0.3044
Step: 18813, loss: 3.025213, norm: 0.3306, time(ms): 796.38, token/sec:658342.69, hellaswag_acc: 0.3044
Step: 18814, loss: 3.038607, norm: 0.3438, time(ms): 798.31, token/sec:656746.17, hellaswag_acc: 0.3044
Step: 18815, loss: 3.066554, norm: 0.3239, time(ms): 791.70, token/sec:662234.53, hellaswag_acc: 0.3044
Step: 18816, loss: 3.077889, norm: 0.3242, time(ms): 788.97, token/sec:664518.09, hellaswag_acc: 0.3044
Step: 18817, loss: 3.126601, norm: 0.3236, time(ms): 796.88, token/sec:657925.71, hellaswag_acc: 0.3044
Step: 18818, loss: 3.042912, norm: 0.2755, time(ms): 792.11, token/sec:661886.90, hellaswag_acc: 0.3044
Step: 18819, loss: 3.083765, norm: 0.3256, time(ms): 791.26, token/sec:662600.49, hellaswag_acc: 0.3044
Step: 18820, loss: 3.102004, norm: 0.3060, time(ms): 795.98, token/sec:658671.81, hellaswag_acc: 0.3044
Step: 18821, loss: 3.066797, norm: 0.3057, time(ms): 793.56, token/sec:660677.45, hellaswag_acc: 0.3044
Step: 18822, loss: 3.078882, norm: 0.2764, time(ms): 791.36, token/sec:662516.64, hellaswag_acc: 0.3044
Step: 18823, loss: 3.103497, norm: 0.2906, time(ms): 794.89, token/sec:659576.05, hellaswag_acc: 0.3044
Step: 18824, loss: 3.072959, norm: 0.2835, time(ms): 789.68, token/sec:663927.03, hellaswag_acc: 0.3044
Step: 18825, loss: 3.114258, norm: 0.3028, time(ms): 792.96, token/sec:661179.22, hellaswag_acc: 0.3044
Step: 18826, loss: 3.016370, norm: 0.3035, time(ms): 791.03, token/sec:662790.21, hellaswag_acc: 0.3044
Step: 18827, loss: 3.047883, norm: 0.2844, time(ms): 791.79, token/sec:662154.76, hellaswag_acc: 0.3044
Step: 18828, loss: 3.069462, norm: 0.2905, time(ms): 801.40, token/sec:654214.78, hellaswag_acc: 0.3044
Step: 18829, loss: 3.120718, norm: 0.3027, time(ms): 804.84, token/sec:651416.53, hellaswag_acc: 0.3044
Step: 18830, loss: 3.035354, norm: 0.2902, time(ms): 798.58, token/sec:656529.11, hellaswag_acc: 0.3044
Step: 18831, loss: 3.035130, norm: 0.2694, time(ms): 793.62, token/sec:660625.25, hellaswag_acc: 0.3044
Step: 18832, loss: 3.030372, norm: 0.2909, time(ms): 801.14, token/sec:654428.36, hellaswag_acc: 0.3044
Step: 18833, loss: 3.023169, norm: 0.2851, time(ms): 805.71, token/sec:650716.42, hellaswag_acc: 0.3044
Step: 18834, loss: 3.026992, norm: 0.2617, time(ms): 796.50, token/sec:658239.83, hellaswag_acc: 0.3044
Step: 18835, loss: 3.012586, norm: 0.2768, time(ms): 797.52, token/sec:657395.64, hellaswag_acc: 0.3044
Step: 18836, loss: 3.025748, norm: 0.2763, time(ms): 804.55, token/sec:651657.64, hellaswag_acc: 0.3044
Step: 18837, loss: 3.040236, norm: 0.2742, time(ms): 794.52, token/sec:659881.25, hellaswag_acc: 0.3044
Step: 18838, loss: 3.075046, norm: 0.2711, time(ms): 798.68, token/sec:656441.90, hellaswag_acc: 0.3044
Step: 18839, loss: 3.045598, norm: 0.2713, time(ms): 804.76, token/sec:651482.53, hellaswag_acc: 0.3044
Step: 18840, loss: 3.065428, norm: 0.2810, time(ms): 803.19, token/sec:652757.91, hellaswag_acc: 0.3044
Step: 18841, loss: 3.031534, norm: 0.2853, time(ms): 783.25, token/sec:669373.33, hellaswag_acc: 0.3044
Step: 18842, loss: 3.029869, norm: 0.2992, time(ms): 790.88, token/sec:662918.29, hellaswag_acc: 0.3044
Step: 18843, loss: 3.061862, norm: 0.3319, time(ms): 792.52, token/sec:661547.40, hellaswag_acc: 0.3044
Step: 18844, loss: 3.197887, norm: 0.3315, time(ms): 791.60, token/sec:662312.12, hellaswag_acc: 0.3044
Step: 18845, loss: 3.090128, norm: 0.3239, time(ms): 796.18, token/sec:658508.29, hellaswag_acc: 0.3044
Step: 18846, loss: 3.065412, norm: 0.3309, time(ms): 794.10, token/sec:660229.55, hellaswag_acc: 0.3044
Step: 18847, loss: 3.064877, norm: 0.3162, time(ms): 794.85, token/sec:659602.96, hellaswag_acc: 0.3044
Step: 18848, loss: 3.084844, norm: 0.3091, time(ms): 796.27, token/sec:658430.61, hellaswag_acc: 0.3044
Step: 18849, loss: 3.067902, norm: 0.2899, time(ms): 795.46, token/sec:659101.00, hellaswag_acc: 0.3044
Step: 18850, loss: 3.092370, norm: 0.2878, time(ms): 795.54, token/sec:659036.21, hellaswag_acc: 0.3044
Step: 18851, loss: 3.025600, norm: 0.3014, time(ms): 804.23, token/sec:651916.51, hellaswag_acc: 0.3044
Step: 18852, loss: 3.111000, norm: 0.3242, time(ms): 803.01, token/sec:652904.04, hellaswag_acc: 0.3044
Step: 18853, loss: 3.076290, norm: 0.3239, time(ms): 790.62, token/sec:663135.79, hellaswag_acc: 0.3044
Step: 18854, loss: 3.075215, norm: 0.3046, time(ms): 794.30, token/sec:660061.30, hellaswag_acc: 0.3044
Step: 18855, loss: 3.012352, norm: 0.3170, time(ms): 790.35, token/sec:663358.23, hellaswag_acc: 0.3044
Step: 18856, loss: 3.064404, norm: 0.3007, time(ms): 793.25, token/sec:660935.99, hellaswag_acc: 0.3044
Step: 18857, loss: 3.067719, norm: 0.3047, time(ms): 791.22, token/sec:662631.03, hellaswag_acc: 0.3044
Step: 18858, loss: 3.074527, norm: 0.2977, time(ms): 789.90, token/sec:663743.67, hellaswag_acc: 0.3044
Step: 18859, loss: 3.067517, norm: 0.2832, time(ms): 800.83, token/sec:654683.39, hellaswag_acc: 0.3044
Step: 18860, loss: 3.062906, norm: 0.2857, time(ms): 806.55, token/sec:650034.91, hellaswag_acc: 0.3044
Step: 18861, loss: 3.057852, norm: 0.2961, time(ms): 801.99, token/sec:653734.78, hellaswag_acc: 0.3044
Step: 18862, loss: 3.074268, norm: 0.3029, time(ms): 785.95, token/sec:667071.92, hellaswag_acc: 0.3044
Step: 18863, loss: 3.042174, norm: 0.2859, time(ms): 795.01, token/sec:659471.61, hellaswag_acc: 0.3044
Step: 18864, loss: 3.161326, norm: 0.3074, time(ms): 790.19, token/sec:663492.93, hellaswag_acc: 0.3044
Step: 18865, loss: 3.082801, norm: 0.2835, time(ms): 792.31, token/sec:661721.79, hellaswag_acc: 0.3044
Step: 18866, loss: 3.079690, norm: 0.2723, time(ms): 794.82, token/sec:659631.25, hellaswag_acc: 0.3044
Step: 18867, loss: 2.979098, norm: 0.2895, time(ms): 796.51, token/sec:658233.72, hellaswag_acc: 0.3044
Step: 18868, loss: 2.974833, norm: 0.2846, time(ms): 800.92, token/sec:654603.49, hellaswag_acc: 0.3044
Step: 18869, loss: 3.091181, norm: 0.2913, time(ms): 793.64, token/sec:660612.35, hellaswag_acc: 0.3044
Step: 18870, loss: 3.037804, norm: 0.2892, time(ms): 798.98, token/sec:656195.67, hellaswag_acc: 0.3044
Step: 18871, loss: 3.047312, norm: 0.3012, time(ms): 792.27, token/sec:661752.85, hellaswag_acc: 0.3044
Step: 18872, loss: 2.963609, norm: 0.2878, time(ms): 795.93, token/sec:658714.43, hellaswag_acc: 0.3044
Step: 18873, loss: 3.009325, norm: 0.2892, time(ms): 792.14, token/sec:661866.58, hellaswag_acc: 0.3044
Step: 18874, loss: 3.069705, norm: 0.3033, time(ms): 803.16, token/sec:652785.43, hellaswag_acc: 0.3044
Step: 18875, loss: 3.072374, norm: 0.2868, time(ms): 796.98, token/sec:657840.29, hellaswag_acc: 0.3044
Step: 18876, loss: 3.020052, norm: 0.2881, time(ms): 798.31, token/sec:656744.99, hellaswag_acc: 0.3044
Step: 18877, loss: 3.015679, norm: 0.2846, time(ms): 790.82, token/sec:662968.25, hellaswag_acc: 0.3044
Step: 18878, loss: 3.069124, norm: 0.3285, time(ms): 790.28, token/sec:663417.47, hellaswag_acc: 0.3044
Step: 18879, loss: 3.080642, norm: 0.2867, time(ms): 792.71, token/sec:661391.01, hellaswag_acc: 0.3044
Step: 18880, loss: 3.057079, norm: 0.2971, time(ms): 795.75, token/sec:658863.63, hellaswag_acc: 0.3044
Step: 18881, loss: 3.126514, norm: 0.3834, time(ms): 791.97, token/sec:662003.07, hellaswag_acc: 0.3044
Step: 18882, loss: 3.050557, norm: 0.2924, time(ms): 804.68, token/sec:651546.42, hellaswag_acc: 0.3044
Step: 18883, loss: 3.146046, norm: 0.3136, time(ms): 801.19, token/sec:654384.35, hellaswag_acc: 0.3044
Step: 18884, loss: 3.086962, norm: 0.3311, time(ms): 796.05, token/sec:658609.67, hellaswag_acc: 0.3044
Step: 18885, loss: 3.038244, norm: 0.3022, time(ms): 798.63, token/sec:656485.21, hellaswag_acc: 0.3044
Step: 18886, loss: 3.076016, norm: 0.3022, time(ms): 802.38, token/sec:653420.10, hellaswag_acc: 0.3044
Step: 18887, loss: 3.026245, norm: 0.3146, time(ms): 800.02, token/sec:655346.76, hellaswag_acc: 0.3044
Step: 18888, loss: 3.126358, norm: 0.3186, time(ms): 792.64, token/sec:661448.90, hellaswag_acc: 0.3044
Step: 18889, loss: 3.111244, norm: 0.3165, time(ms): 793.76, token/sec:660508.37, hellaswag_acc: 0.3044
Step: 18890, loss: 3.011949, norm: 0.3448, time(ms): 792.07, token/sec:661917.78, hellaswag_acc: 0.3044
Step: 18891, loss: 3.084542, norm: 0.3212, time(ms): 794.09, token/sec:660239.26, hellaswag_acc: 0.3044
Step: 18892, loss: 3.077106, norm: 0.3092, time(ms): 792.36, token/sec:661680.77, hellaswag_acc: 0.3044
Step: 18893, loss: 3.140249, norm: 0.3403, time(ms): 788.22, token/sec:665151.84, hellaswag_acc: 0.3044
Step: 18894, loss: 3.095368, norm: 0.3128, time(ms): 797.46, token/sec:657451.46, hellaswag_acc: 0.3044
Step: 18895, loss: 3.035346, norm: 0.3021, time(ms): 792.18, token/sec:661829.53, hellaswag_acc: 0.3044
Step: 18896, loss: 3.095165, norm: 0.3338, time(ms): 790.78, token/sec:662997.03, hellaswag_acc: 0.3044
Step: 18897, loss: 3.047833, norm: 0.3208, time(ms): 792.23, token/sec:661791.09, hellaswag_acc: 0.3044
Step: 18898, loss: 3.072679, norm: 0.2948, time(ms): 788.77, token/sec:664693.64, hellaswag_acc: 0.3044
Step: 18899, loss: 3.032604, norm: 0.3056, time(ms): 794.24, token/sec:660111.43, hellaswag_acc: 0.3044
Step: 18900, loss: 3.111451, norm: 0.3127, time(ms): 792.55, token/sec:661523.12, hellaswag_acc: 0.3044
Step: 18901, loss: 3.101385, norm: 0.2922, time(ms): 793.25, token/sec:660939.36, hellaswag_acc: 0.3044
Step: 18902, loss: 3.088488, norm: 0.2949, time(ms): 794.97, token/sec:659510.18, hellaswag_acc: 0.3044
Step: 18903, loss: 3.079607, norm: 0.3539, time(ms): 791.26, token/sec:662602.68, hellaswag_acc: 0.3044
Step: 18904, loss: 3.132514, norm: 0.3088, time(ms): 788.28, token/sec:665106.38, hellaswag_acc: 0.3044
Step: 18905, loss: 3.021106, norm: 0.3009, time(ms): 792.16, token/sec:661847.66, hellaswag_acc: 0.3044
Step: 18906, loss: 3.033769, norm: 0.2867, time(ms): 791.99, token/sec:661986.93, hellaswag_acc: 0.3044
Step: 18907, loss: 3.058987, norm: 0.3094, time(ms): 798.68, token/sec:656440.72, hellaswag_acc: 0.3044
Step: 18908, loss: 2.994141, norm: 0.2939, time(ms): 806.76, token/sec:649867.59, hellaswag_acc: 0.3044
Step: 18909, loss: 3.033223, norm: 0.2985, time(ms): 796.24, token/sec:658458.21, hellaswag_acc: 0.3044
Step: 18910, loss: 2.951900, norm: 0.3061, time(ms): 794.00, token/sec:660313.21, hellaswag_acc: 0.3044
Step: 18911, loss: 3.034477, norm: 0.2887, time(ms): 795.08, token/sec:659418.02, hellaswag_acc: 0.3044
Step: 18912, loss: 3.046966, norm: 0.3227, time(ms): 794.11, token/sec:660222.41, hellaswag_acc: 0.3044
Step: 18913, loss: 3.044447, norm: 0.3082, time(ms): 797.16, token/sec:657696.86, hellaswag_acc: 0.3044
Step: 18914, loss: 3.068256, norm: 0.3311, time(ms): 799.48, token/sec:655784.34, hellaswag_acc: 0.3044
Step: 18915, loss: 3.127307, norm: 0.3342, time(ms): 799.05, token/sec:656138.70, hellaswag_acc: 0.3044
Step: 18916, loss: 3.101850, norm: 0.3334, time(ms): 801.19, token/sec:654387.46, hellaswag_acc: 0.3044
Step: 18917, loss: 3.080032, norm: 0.2971, time(ms): 800.56, token/sec:654898.45, hellaswag_acc: 0.3044
Step: 18918, loss: 3.047652, norm: 0.3105, time(ms): 800.19, token/sec:655204.02, hellaswag_acc: 0.3044
Step: 18919, loss: 3.057825, norm: 0.3329, time(ms): 797.37, token/sec:657524.98, hellaswag_acc: 0.3044
Step: 18920, loss: 3.208039, norm: 0.3164, time(ms): 799.59, token/sec:655696.54, hellaswag_acc: 0.3044
Step: 18921, loss: 3.107771, norm: 0.2889, time(ms): 800.53, token/sec:654929.27, hellaswag_acc: 0.3044
Step: 18922, loss: 3.089001, norm: 0.3312, time(ms): 794.88, token/sec:659584.76, hellaswag_acc: 0.3044
Step: 18923, loss: 3.105820, norm: 0.3287, time(ms): 791.84, token/sec:662109.91, hellaswag_acc: 0.3044
Step: 18924, loss: 3.096414, norm: 0.2880, time(ms): 787.41, token/sec:665837.41, hellaswag_acc: 0.3044
Step: 18925, loss: 3.095623, norm: 0.3252, time(ms): 793.48, token/sec:660745.54, hellaswag_acc: 0.3044
Step: 18926, loss: 3.070419, norm: 0.3196, time(ms): 789.72, token/sec:663894.76, hellaswag_acc: 0.3044
Step: 18927, loss: 3.060579, norm: 0.2983, time(ms): 804.14, token/sec:651982.42, hellaswag_acc: 0.3044
Step: 18928, loss: 3.053077, norm: 0.2955, time(ms): 797.65, token/sec:657294.64, hellaswag_acc: 0.3044
Step: 18929, loss: 3.061082, norm: 0.3032, time(ms): 798.92, token/sec:656243.65, hellaswag_acc: 0.3044
Step: 18930, loss: 3.071835, norm: 0.2958, time(ms): 801.85, token/sec:653846.16, hellaswag_acc: 0.3044
Step: 18931, loss: 3.048735, norm: 0.2887, time(ms): 803.18, token/sec:652767.60, hellaswag_acc: 0.3044
Step: 18932, loss: 3.047433, norm: 0.2856, time(ms): 783.49, token/sec:669170.86, hellaswag_acc: 0.3044
Step: 18933, loss: 3.077179, norm: 0.2948, time(ms): 796.21, token/sec:658479.90, hellaswag_acc: 0.3044
Step: 18934, loss: 3.078609, norm: 0.2872, time(ms): 792.65, token/sec:661434.78, hellaswag_acc: 0.3044
Step: 18935, loss: 3.042974, norm: 0.2867, time(ms): 795.95, token/sec:658691.34, hellaswag_acc: 0.3044
Step: 18936, loss: 3.012085, norm: 0.2924, time(ms): 791.29, token/sec:662571.74, hellaswag_acc: 0.3044
Step: 18937, loss: 3.017451, norm: 0.3069, time(ms): 793.32, token/sec:660881.96, hellaswag_acc: 0.3044
Step: 18938, loss: 2.974868, norm: 0.2851, time(ms): 799.57, token/sec:655709.64, hellaswag_acc: 0.3044
Step: 18939, loss: 3.031016, norm: 0.2794, time(ms): 802.21, token/sec:653558.56, hellaswag_acc: 0.3044
Step: 18940, loss: 3.053230, norm: 0.2809, time(ms): 797.29, token/sec:657586.72, hellaswag_acc: 0.3044
Step: 18941, loss: 3.075856, norm: 0.3417, time(ms): 795.96, token/sec:658688.97, hellaswag_acc: 0.3044
Step: 18942, loss: 3.043854, norm: 0.3027, time(ms): 798.85, token/sec:656306.52, hellaswag_acc: 0.3044
Step: 18943, loss: 2.981651, norm: 0.2901, time(ms): 794.76, token/sec:659677.56, hellaswag_acc: 0.3044
Step: 18944, loss: 3.022795, norm: 0.2820, time(ms): 796.81, token/sec:657981.22, hellaswag_acc: 0.3044
Step: 18945, loss: 3.035417, norm: 0.2809, time(ms): 790.12, token/sec:663555.20, hellaswag_acc: 0.3044
Step: 18946, loss: 3.050677, norm: 0.2877, time(ms): 800.58, token/sec:654886.94, hellaswag_acc: 0.3044
Step: 18947, loss: 3.079885, norm: 0.2893, time(ms): 803.09, token/sec:652840.27, hellaswag_acc: 0.3044
Step: 18948, loss: 3.073384, norm: 0.2747, time(ms): 794.31, token/sec:660054.56, hellaswag_acc: 0.3044
Step: 18949, loss: 3.065963, norm: 0.2830, time(ms): 792.63, token/sec:661451.09, hellaswag_acc: 0.3044
Step: 18950, loss: 3.065294, norm: 0.3152, time(ms): 791.06, token/sec:662770.03, hellaswag_acc: 0.3044
Step: 18951, loss: 3.090579, norm: 0.3342, time(ms): 795.52, token/sec:659050.23, hellaswag_acc: 0.3044
Step: 18952, loss: 3.117469, norm: 0.3201, time(ms): 791.84, token/sec:662114.69, hellaswag_acc: 0.3044
Step: 18953, loss: 3.099267, norm: 0.3370, time(ms): 788.42, token/sec:664984.29, hellaswag_acc: 0.3044
Step: 18954, loss: 3.040971, norm: 0.3087, time(ms): 799.30, token/sec:655931.83, hellaswag_acc: 0.3044
Step: 18955, loss: 3.082462, norm: 0.3064, time(ms): 806.00, token/sec:650483.32, hellaswag_acc: 0.3044
Step: 18956, loss: 3.087283, norm: 0.3530, time(ms): 802.85, token/sec:653030.85, hellaswag_acc: 0.3044
Step: 18957, loss: 3.084126, norm: 0.3160, time(ms): 787.73, token/sec:665570.39, hellaswag_acc: 0.3044
Step: 18958, loss: 3.095959, norm: 0.3213, time(ms): 792.26, token/sec:661763.41, hellaswag_acc: 0.3044
Step: 18959, loss: 3.099645, norm: 0.3299, time(ms): 790.86, token/sec:662938.07, hellaswag_acc: 0.3044
Step: 18960, loss: 3.084600, norm: 0.3247, time(ms): 791.24, token/sec:662615.46, hellaswag_acc: 0.3044
Step: 18961, loss: 3.119527, norm: 0.3382, time(ms): 794.86, token/sec:659600.39, hellaswag_acc: 0.3044
Step: 18962, loss: 3.039640, norm: 0.3105, time(ms): 1192.40, token/sec:439691.56, hellaswag_acc: 0.3044
Step: 18963, loss: 3.082257, norm: 0.3186, time(ms): 805.86, token/sec:650597.83, hellaswag_acc: 0.3044
Step: 18964, loss: 3.075804, norm: 0.3118, time(ms): 794.14, token/sec:660198.43, hellaswag_acc: 0.3044
Step: 18965, loss: 3.043263, norm: 0.3168, time(ms): 784.61, token/sec:668216.78, hellaswag_acc: 0.3044
Step: 18966, loss: 3.067733, norm: 0.2896, time(ms): 791.26, token/sec:662602.88, hellaswag_acc: 0.3044
Step: 18967, loss: 3.015037, norm: 0.3142, time(ms): 789.85, token/sec:663784.54, hellaswag_acc: 0.3044
Step: 18968, loss: 3.007485, norm: 0.3107, time(ms): 792.51, token/sec:661550.98, hellaswag_acc: 0.3044
Step: 18969, loss: 2.975894, norm: 0.3109, time(ms): 791.58, token/sec:662333.06, hellaswag_acc: 0.3044
Step: 18970, loss: 3.035571, norm: 0.2879, time(ms): 788.02, token/sec:665322.10, hellaswag_acc: 0.3044
Step: 18971, loss: 3.024585, norm: 0.3192, time(ms): 793.07, token/sec:661090.18, hellaswag_acc: 0.3044
Step: 18972, loss: 2.940413, norm: 0.3406, time(ms): 786.23, token/sec:666835.65, hellaswag_acc: 0.3044
Step: 18973, loss: 3.024297, norm: 0.2784, time(ms): 791.15, token/sec:662692.94, hellaswag_acc: 0.3044
Step: 18974, loss: 3.071546, norm: 0.3268, time(ms): 792.88, token/sec:661242.65, hellaswag_acc: 0.3044
Step: 18975, loss: 2.976258, norm: 0.2997, time(ms): 801.74, token/sec:653937.16, hellaswag_acc: 0.3044
Step: 18976, loss: 2.962109, norm: 0.2893, time(ms): 801.90, token/sec:653808.84, hellaswag_acc: 0.3044
Step: 18977, loss: 3.007571, norm: 0.2775, time(ms): 797.92, token/sec:657072.31, hellaswag_acc: 0.3044
Step: 18978, loss: 3.020269, norm: 0.2965, time(ms): 796.64, token/sec:658121.43, hellaswag_acc: 0.3044
Step: 18979, loss: 3.067419, norm: 0.4032, time(ms): 797.91, token/sec:657077.81, hellaswag_acc: 0.3044
Step: 18980, loss: 3.105491, norm: 0.3305, time(ms): 792.61, token/sec:661468.00, hellaswag_acc: 0.3044
Step: 18981, loss: 3.027856, norm: 0.3104, time(ms): 789.56, token/sec:664026.07, hellaswag_acc: 0.3044
Step: 18982, loss: 3.025953, norm: 0.3534, time(ms): 796.26, token/sec:658436.33, hellaswag_acc: 0.3044
Step: 18983, loss: 3.030755, norm: 0.3506, time(ms): 788.57, token/sec:664862.05, hellaswag_acc: 0.3044
Step: 18984, loss: 3.044718, norm: 0.3234, time(ms): 787.54, token/sec:665725.53, hellaswag_acc: 0.3044
Step: 18985, loss: 3.001213, norm: 0.3256, time(ms): 794.62, token/sec:659793.34, hellaswag_acc: 0.3044
Step: 18986, loss: 2.996603, norm: 0.3335, time(ms): 792.41, token/sec:661635.78, hellaswag_acc: 0.3044
Step: 18987, loss: 2.977347, norm: 0.3200, time(ms): 802.03, token/sec:653699.61, hellaswag_acc: 0.3044
Step: 18988, loss: 3.016753, norm: 0.2995, time(ms): 805.24, token/sec:651093.85, hellaswag_acc: 0.3044
Step: 18989, loss: 3.057422, norm: 0.3305, time(ms): 798.71, token/sec:656419.17, hellaswag_acc: 0.3044
Step: 18990, loss: 3.083374, norm: 0.3236, time(ms): 789.64, token/sec:663957.90, hellaswag_acc: 0.3044
Step: 18991, loss: 3.065707, norm: 0.2960, time(ms): 795.16, token/sec:659346.84, hellaswag_acc: 0.3044
Step: 18992, loss: 3.070088, norm: 0.3278, time(ms): 794.26, token/sec:660094.98, hellaswag_acc: 0.3044
Step: 18993, loss: 3.094161, norm: 0.3082, time(ms): 786.71, token/sec:666430.06, hellaswag_acc: 0.3044
Step: 18994, loss: 3.084184, norm: 0.2871, time(ms): 788.81, token/sec:664655.07, hellaswag_acc: 0.3044
Step: 18995, loss: 3.023937, norm: 0.2889, time(ms): 802.63, token/sec:653209.31, hellaswag_acc: 0.3044
Step: 18996, loss: 3.094816, norm: 0.2982, time(ms): 801.02, token/sec:654528.87, hellaswag_acc: 0.3044
Step: 18997, loss: 3.127588, norm: 0.3083, time(ms): 791.32, token/sec:662545.79, hellaswag_acc: 0.3044
Step: 18998, loss: 3.074523, norm: 0.2933, time(ms): 797.24, token/sec:657627.43, hellaswag_acc: 0.3044
Step: 18999, loss: 3.069901, norm: 0.2896, time(ms): 791.42, token/sec:662467.74, hellaswag_acc: 0.3044
rank 0 sample 0: Hello, I'm a language model, so I want to make things like an e-mail program that takes me around the world and creates e-mail,
rank 0 sample 1: Hello, I'm a language model, and when I use the language, "I" tells me what my students will do in the next half of the year
rank 0 sample 2: Hello, I'm a language model, and I would be pleased to introduce my students to the language they're learning. My goal is to help them learn something
rank 0 sample 3: Hello, I'm a language model, I love it. I want a great model."
"I would like the data from one server to be analysed across
rank 1 sample 0: Hello, I'm a language model, or what you call a model, all you see here is model. You go to one of our languages, and you
rank 1 sample 1: Hello, I'm a language model, not an algorithm. I'm a person, not a teacher. I'm a physicist now, so my job is to
rank 1 sample 2: Hello, I'm a language model, I learn languages by heart. I'm a language model, just by understanding the language. The other language is that of
rank 1 sample 3: Hello, I'm a language model, so I'm trying to put this information really in the very tight time scale right now.... This is a very basic thing
Step: 19000, loss: 3.091312, norm: 0.3094, time(ms): 363594.52, token/sec:1441.96, val_loss: 3.0678, hellaswag_acc: 0.3036
Step: 19001, loss: 3.033850, norm: 0.2965, time(ms): 798.68, token/sec:656439.94, hellaswag_acc: 0.3036
Step: 19002, loss: 3.020753, norm: 0.2982, time(ms): 788.63, token/sec:664810.80, hellaswag_acc: 0.3036
Step: 19003, loss: 3.011285, norm: 0.2773, time(ms): 794.41, token/sec:659975.32, hellaswag_acc: 0.3036
Step: 19004, loss: 3.002601, norm: 0.2754, time(ms): 790.74, token/sec:663035.01, hellaswag_acc: 0.3036
Step: 19005, loss: 3.007905, norm: 0.2785, time(ms): 790.31, token/sec:663399.46, hellaswag_acc: 0.3036
Step: 19006, loss: 3.038855, norm: 0.3015, time(ms): 804.24, token/sec:651902.79, hellaswag_acc: 0.3036
Step: 19007, loss: 3.032366, norm: 0.2834, time(ms): 800.08, token/sec:655292.08, hellaswag_acc: 0.3036
Step: 19008, loss: 3.041057, norm: 0.2818, time(ms): 800.53, token/sec:654927.51, hellaswag_acc: 0.3036
Step: 19009, loss: 3.001995, norm: 0.3074, time(ms): 792.99, token/sec:661154.97, hellaswag_acc: 0.3036
Step: 19010, loss: 2.991886, norm: 0.2831, time(ms): 802.74, token/sec:653125.30, hellaswag_acc: 0.3036
Step: 19011, loss: 3.005052, norm: 0.2787, time(ms): 803.24, token/sec:652712.57, hellaswag_acc: 0.3036
Step: 19012, loss: 3.016148, norm: 0.2796, time(ms): 794.24, token/sec:660110.83, hellaswag_acc: 0.3036
Step: 19013, loss: 2.984039, norm: 0.2783, time(ms): 795.27, token/sec:659261.45, hellaswag_acc: 0.3036
Step: 19014, loss: 3.038276, norm: 0.3386, time(ms): 792.24, token/sec:661779.34, hellaswag_acc: 0.3036
Step: 19015, loss: 3.046760, norm: 0.3185, time(ms): 789.11, token/sec:664401.04, hellaswag_acc: 0.3036
Step: 19016, loss: 3.050926, norm: 0.3060, time(ms): 792.69, token/sec:661401.35, hellaswag_acc: 0.3036
Step: 19017, loss: 3.050888, norm: 0.3086, time(ms): 792.61, token/sec:661471.58, hellaswag_acc: 0.3036
Step: 19018, loss: 3.030755, norm: 0.3915, time(ms): 799.59, token/sec:655698.30, hellaswag_acc: 0.3036
Step: 19019, loss: 3.142185, norm: 0.3316, time(ms): 803.01, token/sec:652903.27, hellaswag_acc: 0.3036
Step: 19020, loss: 2.963599, norm: 0.3158, time(ms): 801.47, token/sec:654160.09, hellaswag_acc: 0.3036
Step: 19021, loss: 3.028120, norm: 0.3103, time(ms): 782.99, token/sec:669600.80, hellaswag_acc: 0.3036
Step: 19022, loss: 3.028442, norm: 0.3075, time(ms): 793.47, token/sec:660756.85, hellaswag_acc: 0.3036
Step: 19023, loss: 3.172642, norm: 0.3531, time(ms): 800.71, token/sec:654779.50, hellaswag_acc: 0.3036
Step: 19024, loss: 3.054822, norm: 0.3064, time(ms): 798.44, token/sec:656636.54, hellaswag_acc: 0.3036
Step: 19025, loss: 3.023177, norm: 0.3239, time(ms): 795.13, token/sec:659371.55, hellaswag_acc: 0.3036
Step: 19026, loss: 3.137442, norm: 0.3277, time(ms): 802.85, token/sec:653034.14, hellaswag_acc: 0.3036
Step: 19027, loss: 3.003659, norm: 0.3272, time(ms): 803.76, token/sec:652291.47, hellaswag_acc: 0.3036
Step: 19028, loss: 3.057378, norm: 0.3046, time(ms): 797.11, token/sec:657736.99, hellaswag_acc: 0.3036
Step: 19029, loss: 3.144966, norm: 0.3515, time(ms): 796.83, token/sec:657966.46, hellaswag_acc: 0.3036
Step: 19030, loss: 3.051300, norm: 0.3129, time(ms): 805.68, token/sec:650741.64, hellaswag_acc: 0.3036
Step: 19031, loss: 3.100711, norm: 0.3017, time(ms): 799.68, token/sec:655625.38, hellaswag_acc: 0.3036
Step: 19032, loss: 3.048816, norm: 0.2869, time(ms): 799.90, token/sec:655438.95, hellaswag_acc: 0.3036
Step: 19033, loss: 3.074378, norm: 0.2783, time(ms): 796.67, token/sec:658098.98, hellaswag_acc: 0.3036
Step: 19034, loss: 3.093524, norm: 0.3107, time(ms): 799.50, token/sec:655768.11, hellaswag_acc: 0.3036
Step: 19035, loss: 3.023785, norm: 0.2699, time(ms): 801.06, token/sec:654492.83, hellaswag_acc: 0.3036
Step: 19036, loss: 3.029787, norm: 0.2864, time(ms): 801.04, token/sec:654506.66, hellaswag_acc: 0.3036
Step: 19037, loss: 3.059070, norm: 0.2944, time(ms): 799.70, token/sec:655609.55, hellaswag_acc: 0.3036
Step: 19038, loss: 2.986944, norm: 0.2949, time(ms): 796.42, token/sec:658304.26, hellaswag_acc: 0.3036
Step: 19039, loss: 2.983951, norm: 0.3085, time(ms): 802.65, token/sec:653195.53, hellaswag_acc: 0.3036
Step: 19040, loss: 3.055348, norm: 0.2874, time(ms): 797.77, token/sec:657195.05, hellaswag_acc: 0.3036
Step: 19041, loss: 2.970085, norm: 0.2751, time(ms): 797.60, token/sec:657331.58, hellaswag_acc: 0.3036
Step: 19042, loss: 3.017788, norm: 0.2871, time(ms): 805.38, token/sec:650984.18, hellaswag_acc: 0.3036
Step: 19043, loss: 2.979877, norm: 0.2718, time(ms): 798.27, token/sec:656776.18, hellaswag_acc: 0.3036
Step: 19044, loss: 3.049747, norm: 0.2773, time(ms): 792.63, token/sec:661449.50, hellaswag_acc: 0.3036
Step: 19045, loss: 3.001358, norm: 0.2831, time(ms): 796.22, token/sec:658470.63, hellaswag_acc: 0.3036
Step: 19046, loss: 3.031879, norm: 0.2766, time(ms): 791.81, token/sec:662142.00, hellaswag_acc: 0.3036
Step: 19047, loss: 3.060030, norm: 0.2652, time(ms): 790.01, token/sec:663648.92, hellaswag_acc: 0.3036
Step: 19048, loss: 3.026168, norm: 0.2821, time(ms): 790.80, token/sec:662981.84, hellaswag_acc: 0.3036
Step: 19049, loss: 3.023980, norm: 0.3988, time(ms): 796.54, token/sec:658207.32, hellaswag_acc: 0.3036
Step: 19050, loss: 3.055296, norm: 0.2907, time(ms): 802.15, token/sec:653604.79, hellaswag_acc: 0.3036
Step: 19051, loss: 2.994607, norm: 0.3360, time(ms): 797.37, token/sec:657522.62, hellaswag_acc: 0.3036
Step: 19052, loss: 3.011608, norm: 0.3264, time(ms): 797.46, token/sec:657451.26, hellaswag_acc: 0.3036
Step: 19053, loss: 3.003796, norm: 0.3167, time(ms): 804.94, token/sec:651337.81, hellaswag_acc: 0.3036
Step: 19054, loss: 2.991874, norm: 0.3261, time(ms): 799.38, token/sec:655866.09, hellaswag_acc: 0.3036
Step: 19055, loss: 3.040116, norm: 0.3130, time(ms): 795.59, token/sec:658989.01, hellaswag_acc: 0.3036
Step: 19056, loss: 3.022637, norm: 0.2929, time(ms): 802.46, token/sec:653347.29, hellaswag_acc: 0.3036
Step: 19057, loss: 3.033777, norm: 0.3062, time(ms): 801.89, token/sec:653812.53, hellaswag_acc: 0.3036
Step: 19058, loss: 3.039448, norm: 0.3154, time(ms): 794.87, token/sec:659586.14, hellaswag_acc: 0.3036
Step: 19059, loss: 3.090970, norm: 0.3023, time(ms): 799.15, token/sec:656058.24, hellaswag_acc: 0.3036
Step: 19060, loss: 3.037153, norm: 0.3043, time(ms): 803.41, token/sec:652581.83, hellaswag_acc: 0.3036
Step: 19061, loss: 3.123120, norm: 0.3209, time(ms): 802.82, token/sec:653058.19, hellaswag_acc: 0.3036
Step: 19062, loss: 3.074060, norm: 0.2971, time(ms): 795.43, token/sec:659127.08, hellaswag_acc: 0.3036
Step: 19063, loss: 3.038419, norm: 0.2880, time(ms): 796.42, token/sec:658301.90, hellaswag_acc: 0.3036
Step: 19064, loss: 3.087202, norm: 0.3244, time(ms): 803.00, token/sec:652914.51, hellaswag_acc: 0.3036
Step: 19065, loss: 3.040546, norm: 0.2864, time(ms): 803.36, token/sec:652618.24, hellaswag_acc: 0.3036
Step: 19066, loss: 2.997654, norm: 0.2776, time(ms): 798.94, token/sec:656228.57, hellaswag_acc: 0.3036
Step: 19067, loss: 3.066383, norm: 0.3070, time(ms): 795.22, token/sec:659299.60, hellaswag_acc: 0.3036
Step: 19068, loss: 3.092959, norm: 0.2888, time(ms): 803.02, token/sec:652893.19, hellaswag_acc: 0.3036
Step: 19069, loss: 3.025700, norm: 0.2967, time(ms): 802.05, token/sec:653684.45, hellaswag_acc: 0.3036
Step: 19070, loss: 3.036922, norm: 0.3047, time(ms): 790.65, token/sec:663110.19, hellaswag_acc: 0.3036
Step: 19071, loss: 3.039145, norm: 0.3081, time(ms): 803.28, token/sec:652685.45, hellaswag_acc: 0.3036
Step: 19072, loss: 3.062450, norm: 0.2918, time(ms): 362267.40, token/sec:1447.24, hellaswag_acc: 0.3036
